[
    {
        "id": "1",
        "title": "Wavelet Fourier Diffuser: Frequency-Aware Diffusion Model for Reinforcement Learning",
        "author": [
            "Yifu Luo",
            "Yongzhe Chang",
            "Xueqian Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19305",
        "abstract": "Diffusion probability models have shown significant promise in offline reinforcement learning by directly modeling trajectory sequences. However, existing approaches primarily focus on time-domain features while overlooking frequency-domain features, leading to frequency shift and degraded performance according to our observation. In this paper, we investigate the RL problem from a new perspective of the frequency domain. We first observe that time-domain-only approaches inadvertently introduce shifts in the low-frequency components of the frequency domain, which results in trajectory instability and degraded performance. To address this issue, we propose Wavelet Fourier Diffuser (WFDiffuser), a novel diffusion-based RL framework that integrates Discrete Wavelet Transform to decompose trajectories into low- and high-frequency components. To further enhance diffusion modeling for each component, WFDiffuser employs Short-Time Fourier Transform and cross attention mechanisms to extract frequency-domain features and facilitate cross-frequency interaction. Extensive experiment results on the D4RL benchmark demonstrate that WFDiffuser effectively mitigates frequency shift, leading to smoother, more stable trajectories and improved decision-making performance over existing methods.",
        "tags": [
            "Diffusion",
            "RL"
        ]
    },
    {
        "id": "2",
        "title": "Automated Item Neutralization for Non-Cognitive Scales: A Large Language Model Approach to Reducing Social-Desirability Bias",
        "author": [
            "Sirui Wu",
            "Daijin Yang"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19314",
        "abstract": "This study evaluates item neutralization assisted by the large language model (LLM) to reduce social desirability bias in personality assessment. GPT-o3 was used to rewrite the International Personality Item Pool Big Five Measure (IPIP-BFM-50), and 203 participants completed either the original or neutralized form along with the Marlowe-Crowne Social Desirability Scale. The results showed preserved reliability and a five-factor structure, with gains in Conscientiousness and declines in Agreeableness and Openness. The correlations with social desirability decreased for several items, but inconsistently. Configural invariance held, though metric and scalar invariance failed. Findings support AI neutralization as a potential but imperfect bias-reduction method.",
        "tags": [
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "3",
        "title": "FHIR-AgentBench: Benchmarking LLM Agents for Realistic Interoperable EHR Question Answering",
        "author": [
            "Gyubok Lee",
            "Elea Bach",
            "Eric Yang",
            "Tom Pollard",
            "Alistair Johnson",
            "Edward Choi",
            "Yugang jia",
            "Jong Ha Lee"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19319",
        "abstract": "The recent shift toward the Health Level Seven Fast Healthcare Interoperability Resources (HL7 FHIR) standard opens a new frontier for clinical AI, demanding LLM agents to navigate complex, resource-based data models instead of conventional structured health data. However, existing benchmarks have lagged behind this transition, lacking the realism needed to evaluate recent LLMs on interoperable clinical data. To bridge this gap, we introduce FHIR-AgentBench, a benchmark that grounds 2,931 real-world clinical questions in the HL7 FHIR standard. Using this benchmark, we systematically evaluate agentic frameworks, comparing different data retrieval strategies (direct FHIR API calls vs. specialized tools), interaction patterns (single-turn vs. multi-turn), and reasoning strategies (natural language vs. code generation). Our experiments highlight the practical challenges of retrieving data from intricate FHIR resources and the difficulty of reasoning over them, both of which critically affect question answering performance. We publicly release the FHIR-AgentBench dataset and evaluation suite (https://github.com/glee4810/FHIR-AgentBench) to promote reproducible research and the development of robust, reliable LLM agents for clinical applications.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "4",
        "title": "Readme_AI: Dynamic Context Construction for Large Language Models",
        "author": [
            "Millie Vyas",
            "Timothy Blattner",
            "Alden Dima"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19322",
        "abstract": "Despite being trained on significant amounts of data, Large Language Models (LLMs) can provide inaccurate or unreliable information in the context of a user's specific query. Given query-specific context significantly improves the usefulness of its responses. In this paper, we present a specification that can be used to dynamically build context for data sources. The data source owner creates the file containing metadata for LLMs to use when reasoning about dataset-related queries. To demonstrate our proposed specification, we created a prototype Readme_AI Model Context Protocol (MCP) server that retrieves the metadata from the data source and uses it to dynamically build context. Some features that make this specification dynamic are the extensible types that represent crawling web-pages, fetching data from data repositories, downloading and parsing publications, and general text. The context is formatted and grouped using user-specified tags that provide clear contextual information for the LLM to reason about the content. We demonstrate the capabilities of this early prototype by asking the LLM about the NIST-developed Hedgehog library, for which common LLMs often provides inaccurate and irrelevant responses containing hallucinations. With Readme_AI, the LLM receives enough context that it is now able to reason about the library and its use, and even generate code interpolated from examples that were included in the Readme_AI file provided by Hedgehog's developer. Our primary contribution is a extensible protocol for dynamically grounding LLMs in specialized, owner-provided data, enhancing responses from LLMs and reducing hallucinations. The source code for the Readme_AI tool is posted here: https://github.com/usnistgov/readme_ai .",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "5",
        "title": "How Much of Your Data Can Suck? Thresholds for Domain Performance and Emergent Misalignment in LLMs",
        "author": [
            "Jian Ouyang",
            "Arman T",
            "Ge Jin"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19325",
        "abstract": "This paper investigates the impact of incorrect data on the performance and safety of large language models (LLMs), specifically gpt-4o, during supervised fine-tuning (SFT). Although LLMs become increasingly vital across broad domains like finance, coding, law, and health, fine-tuning on incorrect data can lead to \"emergent misalignment,\" producing harmful or deceptive outputs unrelated to the intended task. We evaluate gpt-4o models fine-tuned with varying ratios (10\\% to 90\\% correct) of both obviously and subtly incorrect data across four domains: coding, finance, health, and legal. Our findings show that even modest amounts of incorrect data (10-25\\%) dramatically degrade domain performance and not moral alignment. A clear threshold of at least 50\\% correct data is needed for models to consistently recover strong performance, though they rarely match the robustness and safety of the base model, which exhibits near-perfect alignment and zero dangerous completions out-of-the-box. This research emphasizes that the cost of incorrect data is heavy, highlighting the critical need for extremely high-quality data curation or, alternatively, leveraging robust base models without unnecessary fine-tuning for high-stakes applications.",
        "tags": [
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "6",
        "title": "Unveiling the Merits and Defects of LLMs in Automatic Review Generation for Scientific Papers",
        "author": [
            "Ruochi Li",
            "Haoxuan Zhang",
            "Edward Gehringer",
            "Ting Xiao",
            "Junhua Ding",
            "Haihua Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19326",
        "abstract": "The surge in scientific submissions has placed increasing strain on the traditional peer-review process, prompting the exploration of large language models (LLMs) for automated review generation. While LLMs demonstrate competence in producing structured and coherent feedback, their capacity for critical reasoning, contextual grounding, and quality sensitivity remains limited. To systematically evaluate these aspects, we propose a comprehensive evaluation framework that integrates semantic similarity analysis and structured knowledge graph metrics to assess LLM-generated reviews against human-written counterparts. We construct a large-scale benchmark of 1,683 papers and 6,495 expert reviews from ICLR and NeurIPS in multiple years, and generate reviews using five LLMs. Our findings show that LLMs perform well in descriptive and affirmational content, capturing the main contributions and methodologies of the original work, with GPT-4o highlighted as an illustrative example, generating 15.74% more entities than human reviewers in the strengths section of good papers in ICLR 2025. However, they consistently underperform in identifying weaknesses, raising substantive questions, and adjusting feedback based on paper quality. GPT-4o produces 59.42% fewer entities than real reviewers in the weaknesses and increases node count by only 5.7% from good to weak papers, compared to 50% in human reviews. Similar trends are observed across all conferences, years, and models, providing empirical foundations for understanding the merits and defects of LLM-generated reviews and informing the development of future LLM-assisted reviewing tools. Data, code, and more detailed results are publicly available at https://github.com/RichardLRC/Peer-Review.",
        "tags": [
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "7",
        "title": "A systematic review of trial-matching pipelines using large language models",
        "author": [
            "Braxton A. Morrison",
            "Madhumita Sushil",
            "Jacob S. Young"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19327",
        "abstract": "Matching patients to clinical trial options is critical for identifying novel treatments, especially in oncology. However, manual matching is labor-intensive and error-prone, leading to recruitment delays. Pipelines incorporating large language models (LLMs) offer a promising solution. We conducted a systematic review of studies published between 2020 and 2025 from three academic databases and one preprint server, identifying LLM-based approaches to clinical trial matching. Of 126 unique articles, 31 met inclusion criteria. Reviewed studies focused on matching patient-to-criterion only (n=4), patient-to-trial only (n=10), trial-to-patient only (n=2), binary eligibility classification only (n=1) or combined tasks (n=14). Sixteen used synthetic data; fourteen used real patient data; one used both. Variability in datasets and evaluation metrics limited cross-study comparability. In studies with direct comparisons, the GPT-4 model consistently outperformed other models, even finely-tuned ones, in matching and eligibility extraction, albeit at higher cost. Promising strategies included zero-shot prompting with proprietary LLMs like the GPT-4o model, advanced retrieval methods, and fine-tuning smaller, open-source models for data privacy when incorporation of large models into hospital infrastructure is infeasible. Key challenges include accessing sufficiently large real-world data sets, and deployment-associated challenges such as reducing cost, mitigating risk of hallucinations, data leakage, and bias. This review synthesizes progress in applying LLMs to clinical trial matching, highlighting promising directions and key limitations. Standardized metrics, more realistic test sets, and attention to cost-efficiency and fairness will be critical for broader deployment.",
        "tags": [
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "8",
        "title": "How Model Size, Temperature, and Prompt Style Affect LLM-Human Assessment Score Alignment",
        "author": [
            "Julie Jung",
            "Max Lu",
            "Sina Chole Benker",
            "Dogus Darici"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19329",
        "abstract": "We examined how model size, temperature, and prompt style affect Large Language Models' (LLMs) alignment within itself, between models, and with human in assessing clinical reasoning skills. Model size emerged as a key factor in LLM-human score alignment. Study highlights the importance of checking alignments across multiple levels.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "9",
        "title": "Quantifying Compositionality of Classic and State-of-the-Art Embeddings",
        "author": [
            "Zhijin Guo",
            "Chenhao Xue",
            "Zhaozhen Xu",
            "Hongbo Bo",
            "Yuxuan Ye",
            "Janet B. Pierrehumbert",
            "Martha Lewis"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19332",
        "abstract": "For language models to generalize correctly to novel expressions, it is critical that they exploit access compositional meanings when this is justified. Even if we don't know what a \"pelp\" is, we can use our knowledge of numbers to understand that \"ten pelps\" makes more pelps than \"two pelps\". Static word embeddings such as Word2vec made strong, indeed excessive, claims about compositionality. The SOTA generative, transformer models and graph models, however, go too far in the other direction by providing no real limits on shifts in meaning due to context. To quantify the additive compositionality, we formalize a two-step, generalized evaluation that (i) measures the linearity between known entity attributes and their embeddings via canonical correlation analysis, and (ii) evaluates additive generalization by reconstructing embeddings for unseen attribute combinations and checking reconstruction metrics such as L2 loss, cosine similarity, and retrieval accuracy. These metrics also capture failure cases where linear composition breaks down. Sentences, knowledge graphs, and word embeddings are evaluated and tracked the compositionality across all layers and training stages. Stronger compositional signals are observed in later training stages across data modalities, and in deeper layers of the transformer-based model before a decline at the top layer. Code is available at https://github.com/Zhijin-Guo1/quantifying-compositionality.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "10",
        "title": "Pluralistic Off-policy Evaluation and Alignment",
        "author": [
            "Chengkai Huang",
            "Junda Wu",
            "Zhouhang Xie",
            "Yu Xia",
            "Rui Wang",
            "Tong Yu",
            "Subrata Mitra",
            "Julian McAuley",
            "Lina Yao"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19333",
        "abstract": "Personalized preference alignment for LLMs with diverse human preferences requires evaluation and alignment methods that capture pluralism. Most existing preference alignment datasets are logged under policies that differ substantially from the evaluated LLMs, and existing off-policy estimators focus solely on overall utility while ignoring preference pluralism. Extending Off-Policy Evaluation (OPE) to pluralistic preference alignment, therefore, remains an open question. Thus, we propose the Pluralistic Off-Policy Evaluation (POPE), the first framework for offline pluralistic preference evaluation and alignment in LLMs. POPE includes a unified reward function that combines (1) a collaborative utility component derived from human preference signals (e.g., upvotes or relevance scores) and (2) a diversity component inspired by entropy-based coverage measures, together reflecting pluralistic alignment. Furthermore, to estimate this reward from logged interactions, we derive decomposable inverse propensity scoring (IPS) estimators that separately evaluate relevance and diversity. Theoretically, we prove that our decomposed IPS estimators establish a lower bound on their variance. With the off-policy evaluated value function, we can directly enable off-policy optimization to further enhance pluralistic alignment. Empirical results demonstrate that POPE efficiently enhances pluralistic response generation and maintains the models' general capabilities on downstream tasks",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "11",
        "title": "Cognitive-Level Adaptive Generation via Capability-Aware Retrieval and Style Adaptation",
        "author": [
            "Qingsong Wang",
            "Tao Wu",
            "Wang Lin",
            "Yueying Feng",
            "Gongsheng Yuan",
            "Chang Yao",
            "Jingyuan Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19336",
        "abstract": "Large Language Models (LLMs) have demonstrated strong performance in open-ended generation tasks. However, they often struggle to adapt content to users with differing cognitive capacities, leading to a phenomenon we term cognitive misalignment. This issue arises in two forms: knowledge-level misalignment, where content is too complex or too simplistic relative to user understanding, and presentation-style misalignment, where the structure or tone hinders effective comprehension. To address these challenges, we propose the Cognitive-Level Alignment Framework (CLAF), a general-purpose generation framework that aligns both knowledge complexity and presentation style with user cognition. CLAF integrates a capability-aware retrieval module based on a hierarchical knowledge graph and a style optimization module guided by Bloom's taxonomy and preference learning. Additionally, a knowledge-controllable generation component ensures consistency and relevance throughout the output. To support training and evaluation, we construct SCALE, a cognitively annotated dataset containing responses at multiple comprehension levels per query. Empirical results show that CLAF enhances the adaptability and informativeness of LLM outputs across a range of user profiles, offering a robust solution to cognitive-level alignment in real-world applications.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "12",
        "title": "Benchmarking ChatGPT and DeepSeek in April 2025: A Novel Dual Perspective Sentiment Analysis Using Lexicon-Based and Deep Learning Approaches",
        "author": [
            "Maryam Mahdi Alhusseini",
            "Mohammad-Reza Feizi-Derakhshi"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19346",
        "abstract": "This study presents a novel dual-perspective approach to analyzing user reviews for ChatGPT and DeepSeek on the Google Play Store, integrating lexicon-based sentiment analysis (TextBlob) with deep learning classification models, including Convolutional Neural Networks (CNN) and Bidirectional Long Short Term Memory (Bi LSTM) Networks. Unlike prior research, which focuses on either lexicon-based strategies or predictive deep learning models in isolation, this study conducts an extensive investigation into user satisfaction with Large Language Model (LLM) based applications. A Dataset of 4,000 authentic user reviews was collected, which were carefully preprocessed and subjected to oversampling to achieve balanced classes. The balanced test set of 1,700 Reviews were used for model testing. Results from the experiments reveal that ChatGPT received significantly more positive sentiment than DeepSeek. Furthermore, deep learning based classification demonstrated superior performance over lexicon analysis, with CNN outperforming Bi-LSTM by achieving 96.41 percent accuracy and near perfect classification of negative reviews, alongside high F1-scores for neutral and positive sentiments. This research sets a new methodological standard for measuring sentiment in LLM-based applications and provides practical insights for developers and researchers seeking to improve user-centric AI system design.",
        "tags": [
            "DeepSeek",
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "13",
        "title": "Characterizing Knowledge Graph Tasks in LLM Benchmarks Using Cognitive Complexity Frameworks",
        "author": [
            "Sara Todorovikj",
            "Lars-Peter Meyer",
            "Michael Martin"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19347",
        "abstract": "Large Language Models (LLMs) are increasingly used for tasks involving Knowledge Graphs (KGs), whose evaluation typically focuses on accuracy and output correctness. We propose a complementary task characterization approach using three complexity frameworks from cognitive psychology. Applying this to the LLM-KG-Bench framework, we highlight value distributions, identify underrepresented demands and motivate richer interpretation and diversity for benchmark evaluation tasks.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "14",
        "title": "ShinkaEvolve: Towards Open-Ended And Sample-Efficient Program Evolution",
        "author": [
            "Robert Tjarko Lange",
            "Yuki Imajuku",
            "Edoardo Cetin"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19349",
        "abstract": "We introduce ShinkaEvolve: a new open-source framework leveraging large language models (LLMs) to advance scientific discovery with state-of-the-art performance and unprecedented efficiency. Recent advances in scaling inference time compute of LLMs have enabled significant progress in generalized scientific discovery. These approaches rely on evolutionary agentic harnesses that leverage LLMs as mutation operators to generate candidate solutions. However, current code evolution methods suffer from critical limitations: they are sample inefficient, requiring thousands of samples to identify effective solutions, and remain closed-source, hindering broad adoption and extension. ShinkaEvolve addresses these limitations, introducing three key innovations: a parent sampling technique balancing exploration and exploitation, code novelty rejection-sampling for efficient search space exploration, and a bandit-based LLM ensemble selection strategy. We evaluate ShinkaEvolve across diverse tasks, demonstrating consistent improvements in sample efficiency and solution quality. ShinkaEvolve discovers a new state-of-the-art circle packing solution using only 150 samples, designs high-performing agentic harnesses for AIME mathematical reasoning tasks, identifies improvements to ALE-Bench competitive programming solutions, and discovers novel mixture-of-expert load balancing loss functions that illuminate the space of optimization strategies. Our results demonstrate that ShinkaEvolve achieves broad applicability with exceptional sample efficiency. By providing open-source accessibility and cost-efficiency, this work democratizes open-ended discovery across diverse computational problems.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "15",
        "title": "TinyAC: Bringing Autonomic Computing Principles to Resource-Constrained Systems",
        "author": [
            "Wojciech Kalka",
            "Ruitao Xue",
            "Kamil Faber",
            "Aleksander Slominski",
            "Devki Jha",
            "Rajiv Ranjan",
            "Tomasz Szydlo"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19350",
        "abstract": "Autonomic Computing (AC) is a promising approach for developing intelligent and adaptive self-management systems at the deep network edge. In this paper, we present the problems and challenges related to the use of AC for IoT devices. Our proposed hybrid approach bridges bottom-up intelligence (TinyML and on-device learning) and top-down guidance (LLMs) to achieve a scalable and explainable approach for developing intelligent and adaptive self-management tiny systems. Moreover, we argue that TinyAC systems require self-adaptive features to handle problems that may occur during their operation. Finally, we identify gaps, discuss existing challenges and future research directions.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "16",
        "title": "RoadMind: Towards a Geospatial AI Expert for Disaster Response",
        "author": [
            "Ahmed El Fekih Zguir",
            "Ferda Ofli",
            "Muhammad Imran"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19354",
        "abstract": "Large Language Models (LLMs) have shown impressive performance across a range of natural language tasks, but remain limited in their ability to reason about geospatial data, particularly road networks, distances, and directions. This gap poses challenges in disaster scenarios, where spatial understanding is critical for tasks such as evacuation planning and resource allocation. In this work, we present RoadMind, a self-supervised framework that enhances the geospatial reasoning capabilities of LLMs using structured data from OpenStreetMap (OSM). Our automated pipeline extracts road infrastructure data for a given city and converts it into multiple supervision formats tailored to key spatial tasks. We pretrain and fine-tune LLMs on these representations using QLoRA adapters and 4-bit quantized models. We evaluate our approach on three disaster-prone cities with varying global representation, Los Angeles, Christchurch, and Manila, across tasks such as road segment identification, nearest road retrieval, and distance/direction estimation. Our results show that models trained via RoadMind significantly outperform strong baselines, including state-of-the-art LLMs equipped with advanced prompt engineering. This demonstrates the potential of structured geospatial data to enhance language models with robust spatial reasoning, enabling more effective offline AI systems for disaster response.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "17",
        "title": "Benchmarking and Improving LLM Robustness for Personalized Generation",
        "author": [
            "Chimaobi Okite",
            "Naihao Deng",
            "Kiran Bodipati",
            "Huaidian Hou",
            "Joyce Chai",
            "Rada Mihalcea"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19358",
        "abstract": "Recent years have witnessed a growing interest in personalizing the responses of large language models (LLMs). While existing evaluations primarily focus on whether a response aligns with a user's preferences, we argue that factuality is an equally important yet often overlooked dimension. In the context of personalization, we define a model as robust if its responses are both factually accurate and align with the user preferences. To assess this, we introduce PERG, a scalable framework for evaluating robustness in LLMs, along with a new dataset, PERGData. We evaluate fourteen models from five different model families using different prompting methods. Our findings show that current LLMs struggle with robust personalization: even the strongest models (GPT-4.1, LLaMA3-70B) fail to maintain correctness in 5% of previously successful cases without personalization, while smaller models (e.g., 7B-scale) can fail more than 20% of the time. Further analysis reveals that robustness is significantly affected by the nature of the query and the type of user preference. To mitigate these failures, we propose Pref-Aligner, a two-stage approach that improves robustness by an average of 25% across models. Our work highlights critical gaps in current evaluation practices and introduces tools and metrics to support more reliable, user-aligned LLM deployments.",
        "tags": [
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "18",
        "title": "Semantic Representation Attack against Aligned Large Language Models",
        "author": [
            "Jiawei Lian",
            "Jianhong Pan",
            "Lefan Wang",
            "Yi Wang",
            "Shaohui Mei",
            "Lap-Pui Chau"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19360",
        "abstract": "Large Language Models (LLMs) increasingly employ alignment techniques to prevent harmful outputs. Despite these safeguards, attackers can circumvent them by crafting prompts that induce LLMs to generate harmful content.\nCurrent methods typically target exact affirmative responses, such as ``Sure, here is...'', suffering from limited convergence, unnatural prompts, and high computational costs.\nWe introduce Semantic Representation Attack, a novel paradigm that fundamentally reconceptualizes adversarial objectives against aligned LLMs.\nRather than targeting exact textual patterns, our approach exploits the semantic representation space comprising diverse responses with equivalent harmful meanings.\nThis innovation resolves the inherent trade-off between attack efficacy and prompt naturalness that plagues existing methods.\nThe Semantic Representation Heuristic Search algorithm is proposed to efficiently generate semantically coherent and concise adversarial prompts by maintaining interpretability during incremental expansion.\nWe establish rigorous theoretical guarantees for semantic convergence and demonstrate that our method achieves unprecedented attack success rates (89.41\\% averaged across 18 LLMs, including 100\\% on 11 models) while maintaining stealthiness and efficiency.\nComprehensive experimental results confirm the overall superiority of our Semantic Representation Attack.\nThe code will be publicly available.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "19",
        "title": "The Inadequacy of Offline LLM Evaluations: A Need to Account for Personalization in Model Behavior",
        "author": [
            "Angelina Wang",
            "Daniel E. Ho",
            "Sanmi Koyejo"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19364",
        "abstract": "Standard offline evaluations for language models -- a series of independent, state-less inferences made by models -- fail to capture how language models actually behave in practice, where personalization fundamentally alters model behavior. For instance, identical benchmark questions to the same language model can produce markedly different responses when prompted to a state-less system, in one user's chat session, or in a different user's chat session. In this work, we provide empirical evidence showcasing this phenomenon by comparing offline evaluations to field evaluations conducted by having 800 real users of ChatGPT and Gemini pose benchmark and other provided questions to their chat interfaces.",
        "tags": [
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "20",
        "title": "LLM-Assisted Topic Reduction for BERTopic on Social Media Data",
        "author": [
            "Wannes Janssens",
            "Matthias Bogaert",
            "Dirk Van den Poel"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19365",
        "abstract": "The BERTopic framework leverages transformer embeddings and hierarchical clustering to extract latent topics from unstructured text corpora. While effective, it often struggles with social media data, which tends to be noisy and sparse, resulting in an excessive number of overlapping topics. Recent work explored the use of large language models for end-to-end topic modelling. However, these approaches typically require significant computational overhead, limiting their scalability in big data contexts. In this work, we propose a framework that combines BERTopic for topic generation with large language models for topic reduction. The method first generates an initial set of topics and constructs a representation for each. These representations are then provided as input to the language model, which iteratively identifies and merges semantically similar topics. We evaluate the approach across three Twitter/X datasets and four different language models. Our method outperforms the baseline approach in enhancing topic diversity and, in many cases, coherence, with some sensitivity to dataset characteristics and initial parameter selection.",
        "tags": [
            "LLM",
            "Transformer"
        ]
    },
    {
        "id": "21",
        "title": "Pipeline Parallelism is All You Need for Optimized Early-Exit Based Self-Speculative Decoding",
        "author": [
            "Ruanjun Li",
            "Ziheng Liu",
            "Yuanming Shi",
            "Jiawei Shao",
            "Chi Zhang",
            "Xuelong Li"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19368",
        "abstract": "Large language models (LLMs) deliver impressive generation quality, but incur very high inference cost because each output token is generated auto-regressively through all model layers. Early-exit based self-speculative decoding (EESD) has emerged to mitigate this cost. However, in practice, many approaches struggle to achieve the expected acceleration in such draft-then-verify paradigm even with a well-aligned early-exit head and selected exit position. Our analysis reveals that EESD only pays off when the vast majority of draft tokens are accepted by the LLM. Otherwise, the draft cost may overcome the acceleration gain and lead to a negative speedup. To mitigate this, we propose Pipeline-Parallel Self-Speculative Decoding (PPSD) that fully pipelines the draft and verification work so that no effort is wasted on failed predictions. It has two key innovations. We configure the model layers as a pipeline in which early-exit (draft) computations and remaining-layer (verification) computations overlap. We interleave drafting and verification per token. While the LLM is verifying the current token in its final layers, the early-exit path simultaneously drafts the next token. Such a verify-while-draft scheme keeps all units busy and validates tokens on-the-fly analogous to pipelining the speculation and verification stages. Empirical results confirm that PPSD achieves state-of-the-art acceleration in self-speculative LLM inference. On diverse benchmarks, PPSD achieves speedup ratios in the range of 2.01x~3.81x, which gains almost the optimal acceleration at the fixed acceptance rate and exit position, showcasing its advancement in providing efficient self-speculation.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "22",
        "title": "SLM-Based Agentic AI with P-C-G: Optimized for Korean Tool Use",
        "author": [
            "Changhyun Jeon",
            "Jinhee Park",
            "Jungwoo Choi",
            "Keonwoo Kim",
            "Jisu Kim",
            "Minji Hong"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19369",
        "abstract": "We propose a small-scale language model (SLM) based agent architecture, Planner-Caller-Generator (P-C-G), optimized for Korean tool use. P-C-G separates planning, calling, and generation by role: the Planner produces an initial batch plan with limited on-demand replanning; the Caller returns a normalized call object after joint schema-value validation; and the Generator integrates tool outputs to produce the final answer. We apply a Korean-first value policy to reduce execution failures caused by frequent Korean-to-English code switching in Korean settings. Evaluation assumes Korean queries and Korean tool/parameter specifications; it covers single-chain, multi-chain, missing-parameters, and missing-functions scenarios, and is conducted via an LLM-as-a-Judge protocol averaged over five runs under a unified I/O interface. Results show that P-C-G delivers competitive tool-use accuracy and end-to-end quality while reducing tokens and maintaining acceptable latency, indicating that role-specialized SLMs are a cost-effective alternative for Korean tool-use agents.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "23",
        "title": "Meow: End-to-End Outline Writing for Automatic Academic Survey",
        "author": [
            "Zhaoyu Ma",
            "Yuan Shan",
            "Jiahao Zhao",
            "Nan Xu",
            "Lei Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19370",
        "abstract": "As academic paper publication numbers grow exponentially, conducting in-depth surveys with LLMs automatically has become an inevitable trend. Outline writing, which aims to systematically organize related works, is critical for automated survey generation. Yet existing automatic survey methods treat outline writing as mere workflow steps in the overall pipeline. Such template-based workflows produce outlines that lack in-depth understanding of the survey topic and fine-grained styles. To address these limitations, we propose Meow, the first metadata-driven outline writing framework that produces organized and faithful outlines efficiently. Specifically, we first formulate outline writing as an end-to-end task that generates hierarchical structured outlines from paper metadata. We then curate a high-quality dataset of surveys from arXiv, bioRxiv, and medRxiv, and establish systematic evaluation metrics for outline quality assessment. Finally, we employ a two-stage training approach combining supervised fine-tuning and reinforcement learning. Our 8B reasoning model demonstrates strong performance with high structural fidelity and stylistic coherence.",
        "tags": [
            "LLM",
            "RL"
        ]
    },
    {
        "id": "24",
        "title": "How to inject knowledge efficiently? Knowledge Infusion Scaling Law for Pre-training Large Language Models",
        "author": [
            "Kangtao Lv",
            "Haibin Chen",
            "Yujin Yuan",
            "Langming Liu",
            "Shilei Liu",
            "Yongwei Wang",
            "Wenbo Su",
            "Bo Zheng"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19371",
        "abstract": "Large language models (LLMs) have attracted significant attention due to their impressive general capabilities across diverse downstream tasks. However, without domain-specific optimization, they often underperform on specialized knowledge benchmarks and even produce hallucination. Recent studies show that strategically infusing domain knowledge during pretraining can substantially improve downstream performance. A critical challenge lies in balancing this infusion trade-off: injecting too little domain-specific data yields insufficient specialization, whereas excessive infusion triggers catastrophic forgetting of previously acquired knowledge. In this work, we focus on the phenomenon of memory collapse induced by over-infusion. Through systematic experiments, we make two key observations, i.e. 1) Critical collapse point: each model exhibits a threshold beyond which its knowledge retention capabilities sharply degrade. 2) Scale correlation: these collapse points scale consistently with the model's size. Building on these insights, we propose a knowledge infusion scaling law that predicts the optimal amount of domain knowledge to inject into large LLMs by analyzing their smaller counterparts. Extensive experiments across different model sizes and pertaining token budgets validate both the effectiveness and generalizability of our scaling law.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "25",
        "title": "Uncertainty Quantification of Large Language Models using Approximate Bayesian Computation",
        "author": [
            "Mridul Sharma",
            "Adeetya Patel",
            "Zaneta D' Souza",
            "Samira Abbasgholizadeh Rahimi",
            "Siva Reddy",
            "Sreenath Madathil"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19375",
        "abstract": "Despite their widespread applications, Large Language Models (LLMs) often struggle to express uncertainty, posing a challenge for reliable deployment in high stakes and safety critical domains like clinical diagnostics. Existing standard baseline methods such as model logits and elicited probabilities produce overconfident and poorly calibrated estimates. In this work, we propose Approximate Bayesian Computation (ABC), a likelihood-free Bayesian inference, based approach that treats LLMs as a stochastic simulator to infer posterior distributions over predictive probabilities. We evaluate our ABC approach on two clinically relevant benchmarks: a synthetic oral lesion diagnosis dataset and the publicly available GretelAI symptom-to-diagnosis dataset. Compared to standard baselines, our approach improves accuracy by up to 46.9\\%, reduces Brier scores by 74.4\\%, and enhances calibration as measured by Expected Calibration Error (ECE) and predictive entropy.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "26",
        "title": "Learning from Observation: A Survey of Recent Advances",
        "author": [
            "Returaj Burnwal",
            "Hriday Mehta",
            "Nirav Pravinbhai Bhatt",
            "Balaraman Ravindran"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19379",
        "abstract": "Imitation Learning (IL) algorithms offer an efficient way to train an agent by mimicking an expert's behavior without requiring a reward function. IL algorithms often necessitate access to state and action information from expert demonstrations. Although expert actions can provide detailed guidance, requiring such action information may prove impractical for real-world applications where expert actions are difficult to obtain. To address this limitation, the concept of learning from observation (LfO) or state-only imitation learning (SOIL) has recently gained attention, wherein the imitator only has access to expert state visitation information. In this paper, we present a framework for LfO and use it to survey and classify existing LfO methods in terms of their trajectory construction, assumptions and algorithm's design choices. This survey also draws connections between several related fields like offline RL, model-based RL and hierarchical RL. Finally, we use our framework to identify open problems and suggest future research directions.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "27",
        "title": "TensLoRA: Tensor Alternatives for Low-Rank Adaptation",
        "author": [
            "Axel Marmoret",
            "Reda Bensaid",
            "Jonathan Lys",
            "Vincent Gripon",
            "FranÃ§ois Leduc-Primeau"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19391",
        "abstract": "Low-Rank Adaptation (LoRA) is widely used to efficiently adapt Transformers by adding trainable low-rank matrices to attention projections. While effective, these matrices are considered independent for each attention projection (Query, Key, and Value) and each layer. Recent extensions have considered joint, tensor-based adaptations, but only in limited forms and without a systematic framework. We introduce TensLoRA, a unified framework that aggregates LoRA updates into higher-order tensors and models a broad family of tensor-based low-rank adaptations. Our formulation generalizes existing tensor-based methods and enables mode-specific compression rates, allowing parameter budgets to be tailored according to the modality and task. Experiments on vision and language benchmarks reveal that the tensor construction directly impacts performance, sometimes better than standard LoRA under similar parameter counts.",
        "tags": [
            "LoRA"
        ]
    },
    {
        "id": "28",
        "title": "ROPA: Synthetic Robot Pose Generation for RGB-D Bimanual Data Augmentation",
        "author": [
            "Jason Chen",
            "I-Chun Arthur Liu",
            "Gaurav Sukhatme",
            "Daniel Seita"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19454",
        "abstract": "Training robust bimanual manipulation policies via imitation learning requires demonstration data with broad coverage over robot poses, contacts, and scene contexts. However, collecting diverse and precise real-world demonstrations is costly and time-consuming, which hinders scalability. Prior works have addressed this with data augmentation, typically for either eye-in-hand (wrist camera) setups with RGB inputs or for generating novel images without paired actions, leaving augmentation for eye-to-hand (third-person) RGB-D training with new action labels less explored. In this paper, we propose Synthetic Robot Pose Generation for RGB-D Bimanual Data Augmentation (ROPA), an offline imitation learning data augmentation method that fine-tunes Stable Diffusion to synthesize third-person RGB and RGB-D observations of novel robot poses. Our approach simultaneously generates corresponding joint-space action labels while employing constrained optimization to enforce physical consistency through appropriate gripper-to-object contact constraints in bimanual scenarios. We evaluate our method on 5 simulated and 3 real-world tasks. Our results across 2625 simulation trials and 300 real-world trials demonstrate that ROPA outperforms baselines and ablations, showing its potential for scalable RGB and RGB-D data augmentation in eye-to-hand bimanual manipulation. Our project website is available at: https://ropaaug.github.io/.",
        "tags": [
            "Diffusion",
            "Robotics"
        ]
    },
    {
        "id": "29",
        "title": "The Indispensable Role of User Simulation in the Pursuit of AGI",
        "author": [
            "Krisztian Balog",
            "ChengXiang Zhai"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19456",
        "abstract": "Progress toward Artificial General Intelligence (AGI) faces significant bottlenecks, particularly in rigorously evaluating complex interactive systems and acquiring the vast interaction data needed for training adaptive agents. This paper posits that user simulation -- creating computational agents that mimic human interaction with AI systems -- is not merely a useful tool, but is a critical catalyst required to overcome these bottlenecks and accelerate AGI development. We argue that realistic simulators provide the necessary environments for scalable evaluation, data generation for interactive learning, and fostering the adaptive capabilities central to AGI. Therefore, research into user simulation technology and intelligent task agents are deeply synergistic and must advance hand-in-hand. This article elaborates on the critical role of user simulation for AGI, explores the interdisciplinary nature of building realistic simulators, identifies key challenges including those posed by large language models, and proposes a future research agenda.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "30",
        "title": "CU-Multi: A Dataset for Multi-Robot Collaborative Perception",
        "author": [
            "Doncey Albin",
            "Daniel McGann",
            "Miles Mena",
            "Annika Thomas",
            "Harel Biggie",
            "Xuefei Sun",
            "Steve McGuire",
            "Jonathan P. How",
            "Christoffer Heckman"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19463",
        "abstract": "A central challenge for multi-robot systems is fusing independently gathered perception data into a unified representation. Despite progress in Collaborative SLAM (C-SLAM), benchmarking remains hindered by the scarcity of dedicated multi-robot datasets. Many evaluations instead partition single-robot trajectories, a practice that may only partially reflect true multi-robot operations and, more critically, lacks standardization, leading to results that are difficult to interpret or compare across studies. While several multi-robot datasets have recently been introduced, they mostly contain short trajectories with limited inter-robot overlap and sparse intra-robot loop closures. To overcome these limitations, we introduce CU-Multi, a dataset collected over multiple days at two large outdoor sites on the University of Colorado Boulder campus. CU-Multi comprises four synchronized runs with aligned start times and controlled trajectory overlap, replicating the distinct perspectives of a robot team. It includes RGB-D sensing, RTK GPS, semantic LiDAR, and refined ground-truth odometry. By combining overlap variation with dense semantic annotations, CU-Multi provides a strong foundation for reproducible evaluation in multi-robot collaborative perception tasks.",
        "tags": [
            "Robotics",
            "SLAM"
        ]
    },
    {
        "id": "31",
        "title": "Evaluation-Aware Reinforcement Learning",
        "author": [
            "Shripad Vilasrao Deshmukh",
            "Will Schwarzer",
            "Scott Niekum"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19464",
        "abstract": "Policy evaluation is often a prerequisite for deploying safety- and performance-critical systems. Existing evaluation approaches frequently suffer from high variance due to limited data and long-horizon tasks, or high bias due to unequal support or inaccurate environmental models. We posit that these challenges arise, in part, from the standard reinforcement learning (RL) paradigm of policy learning without explicit consideration of evaluation. As an alternative, we propose evaluation-aware reinforcement learning (EvA-RL), in which a policy is trained to maximize expected return while simultaneously minimizing expected evaluation error under a given value prediction scheme -- in other words, being \"easy\" to evaluate. We formalize a framework for EvA-RL and design an instantiation that enables accurate policy evaluation, conditioned on a small number of rollouts in an assessment environment that can be different than the deployment environment. However, our theoretical analysis and empirical results show that there is often a tradeoff between evaluation accuracy and policy performance when using a fixed value-prediction scheme within EvA-RL. To mitigate this tradeoff, we extend our approach to co-learn an assessment-conditioned state-value predictor alongside the policy. Empirical results across diverse discrete and continuous action domains demonstrate that EvA-RL can substantially reduce evaluation error while maintaining competitive returns. This work lays the foundation for a broad new class of RL methods that treat reliable evaluation as a first-class principle during training.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "32",
        "title": "Transformer Modeling for Both Scalability and Performance in Multivariate Time Series",
        "author": [
            "Hunjae Lee",
            "Corey Clark"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19471",
        "abstract": "Variable count is among the main scalability bottlenecks for transformer modeling in multivariate time series (MTS) data. On top of this, a growing consensus in the field points to indiscriminate inter-variable mixing as a potential source of noise-accumulation and performance degradation. This is likely exacerbated by sparsity of informative signals characteristic of many MTS systems coupled with representational misalignment stemming from indiscriminate information mixing between (heterogeneous) variables. While scalability and performance are often seen as competing interests in transformer design, we show that both can be improved simultaneously in MTS by strategically constraining the representational capacity of inter-variable mixing. Our proposed method, transformer with Delegate Token Attention (DELTAformer), constrains inter-variable modeling through what we call delegate tokens which are then used to perform full, unconstrained, inter-temporal modeling. Delegate tokens act as an implicit regularizer that forces the model to be highly selective about what inter-variable information is allowed to propagate through the network. Our results show that DELTAformer scales linearly with variable-count while actually outperforming standard transformers, achieving state-of-the-art performance across benchmarks and baselines. In addition, DELTAformer can focus on relevant signals better than standard transformers in noisy MTS environments and overall exhibit superior noise-resilience. Overall, results across various experiments confirm that by aligning our model design to leverage domain-specific challenges in MTS to our advantage, DELTAformer can simultaneously achieve linear scaling while actually improving its performance against standard, quadratic transformers.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "33",
        "title": "Crater Observing Bio-inspired Rolling Articulator (COBRA)",
        "author": [
            "Adarsh Salagame",
            "Henry Noyes",
            "Alireza Ramezani",
            "Eric Sihite",
            "Arash Kalantari"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19473",
        "abstract": "NASA aims to establish a sustainable human basecamp on the Moon as a stepping stone for future missions to Mars and beyond. The discovery of water ice on the Moon's craters located in permanently shadowed regions, which can provide drinking water, oxygen, and rocket fuel, is therefore of critical importance. However, current methods to access lunar ice deposits are limited. While rovers have been used to explore the lunar surface for decades, they face significant challenges in navigating harsh terrains, such as permanently shadowed craters, due to the high risk of immobilization. This report introduces COBRA (Crater Observing Bio-inspired Rolling Articulator), a multi-modal snake-style robot designed to overcome mobility challenges in Shackleton Crater's rugged environment. COBRA combines slithering and tumbling locomotion to adapt to various crater terrains. In snake mode, it uses sidewinding to traverse flat or low inclined surfaces, while in tumbling mode, it forms a circular barrel by linking its head and tail, enabling rapid movement with minimal energy on steep slopes. Equipped with an onboard computer, stereo camera, inertial measurement unit, and joint encoders, COBRA facilitates real-time data collection and autonomous operation. This paper highlights COBRAs robustness and efficiency in navigating extreme terrains through both simulations and experimental validation.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "34",
        "title": "OmniVLA: An Omni-Modal Vision-Language-Action Model for Robot Navigation",
        "author": [
            "Noriaki Hirose",
            "Catherine Glossop",
            "Dhruv Shah",
            "Sergey Levine"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19480",
        "abstract": "Humans can flexibly interpret and compose different goal specifications, such as language instructions, spatial coordinates, or visual references, when navigating to a destination. In contrast, most existing robotic navigation policies are trained on a single modality, limiting their adaptability to real-world scenarios where different forms of goal specification are natural and complementary. In this work, we present a training framework for robotic foundation models that enables omni-modal goal conditioning for vision-based navigation. Our approach leverages a high-capacity vision-language-action (VLA) backbone and trains with three primary goal modalities: 2D poses, egocentric images, and natural language, as well as their combinations, through a randomized modality fusion strategy. This design not only expands the pool of usable datasets but also encourages the policy to develop richer geometric, semantic, and visual representations. The resulting model, OmniVLA, achieves strong generalization to unseen environments, robustness to scarce modalities, and the ability to follow novel natural language instructions. We demonstrate that OmniVLA outperforms specialist baselines across modalities and offers a flexible foundation for fine-tuning to new modalities and tasks. We believe OmniVLA provides a step toward broadly generalizable and flexible navigation policies, and a scalable path for building omni-modal robotic foundation models. We present videos showcasing OmniVLA performance and will release its checkpoints and training code on our project page.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "35",
        "title": "Identifying and Addressing User-level Security Concerns in Smart Homes Using \"Smaller\" LLMs",
        "author": [
            "Hafijul Hoque Chowdhury",
            "Riad Ahmed Anonto",
            "Sourov Jajodia",
            "Suryadipta Majumdar",
            "Md. Shohrab Hossain"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19485",
        "abstract": "With the rapid growth of smart home IoT devices, users are increasingly exposed to various security risks, as evident from recent studies. While seeking answers to know more on those security concerns, users are mostly left with their own discretion while going through various sources, such as online blogs and technical manuals, which may render higher complexity to regular users trying to extract the necessary information. This requirement does not go along with the common mindsets of smart home users and hence threatens the security of smart homes furthermore. In this paper, we aim to identify and address the major user-level security concerns in smart homes. Specifically, we develop a novel dataset of Q&A from public forums, capturing practical security challenges faced by smart home users. We extract major security concerns in smart homes from our dataset by leveraging the Latent Dirichlet Allocation (LDA). We fine-tune relatively \"smaller\" transformer models, such as T5 and Flan-T5, on this dataset to build a QA system tailored for smart home security. Unlike larger models like GPT and Gemini, which are powerful but often resource hungry and require data sharing, smaller models are more feasible for deployment in resource-constrained or privacy-sensitive environments like smart homes. The dataset is manually curated and supplemented with synthetic data to explore its potential impact on model performance. This approach significantly improves the system's ability to deliver accurate and relevant answers, helping users address common security concerns with smart home IoT devices. Our experiments on real-world user concerns show that our work improves the performance of the base models.",
        "tags": [
            "GPT",
            "LLM",
            "Transformer"
        ]
    },
    {
        "id": "36",
        "title": "Supercomputing for High-speed Avoidance and Reactive Planning in Robots",
        "author": [
            "Kieran S. Lachmansingh",
            "JosÃ© R. GonzÃ¡lez-Estrada",
            "Ryan E. Grant",
            "Matthew K. X. J. Pan"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19486",
        "abstract": "This paper presents SHARP (Supercomputing for High-speed Avoidance and Reactive Planning), a proof-of-concept study demonstrating how high-performance computing (HPC) can enable millisecond-scale responsiveness in robotic control. While modern robots face increasing demands for reactivity in human--robot shared workspaces, onboard processors are constrained by size, power, and cost. Offloading to HPC offers massive parallelism for trajectory planning, but its feasibility for real-time robotics remains uncertain due to network latency and jitter. We evaluate SHARP in a stress-test scenario where a 7-DOF manipulator must dodge high-speed foam projectiles. Using a parallelized multi-goal A* search implemented with MPI on both local and remote HPC clusters, the system achieves mean planning latencies of 22.9 ms (local) and 30.0 ms (remote, ~300 km away), with avoidance success rates of 84% and 88%, respectively. These results show that when round-trip latency remains within the tens-of-milliseconds regime, HPC-side computation is no longer the bottleneck, enabling avoidance well below human reaction times. The SHARP results motivate hybrid control architectures: low-level reflexes remain onboard for safety, while bursty, high-throughput planning tasks are offloaded to HPC for scalability. By reporting per-stage timing and success rates, this study provides a reproducible template for assessing real-time feasibility of HPC-driven robotics. Collectively, SHARP reframes HPC offloading as a viable pathway toward dependable, reactive robots in dynamic environments.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "37",
        "title": "Estimating the Self-Consistency of LLMs",
        "author": [
            "Robert Nowak"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19489",
        "abstract": "Systems often repeat the same prompt to large language models (LLMs) and aggregate responses to improve reliability. This short note analyzes an estimator of the self-consistency of LLMs and the tradeoffs it induces under a fixed compute budget $B=mn$, where $m$ is the number of prompts sampled from the task distribution and $n$ is the number of repeated LLM calls per prompt; the resulting analysis favors a rough split $m,n\\propto\\sqrt{B}$.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "38",
        "title": "ArtiFree: Detecting and Reducing Generative Artifacts in Diffusion-based Speech Enhancement",
        "author": [
            "Bhawana Chhaglani",
            "Yang Gao",
            "Julius Richter",
            "Xilin Li",
            "Syavosh Zadissa",
            "Tarun Pruthi",
            "Andrew Lovitt"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19495",
        "abstract": "Diffusion-based speech enhancement (SE) achieves natural-sounding speech and strong generalization, yet suffers from key limitations like generative artifacts and high inference latency. In this work, we systematically study artifact prediction and reduction in diffusion-based SE. We show that variance in speech embeddings can be used to predict phonetic errors during inference. Building on these findings, we propose an ensemble inference method guided by semantic consistency across multiple diffusion runs. This technique reduces WER by 15% in low-SNR conditions, effectively improving phonetic accuracy and semantic plausibility. Finally, we analyze the effect of the number of diffusion steps, showing that adaptive diffusion steps balance artifact suppression and latency. Our findings highlight semantic priors as a powerful tool to guide generative SE toward artifact-free outputs.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "39",
        "title": "The Heterogeneous Multi-Agent Challenge",
        "author": [
            "Charles Dansereau",
            "Junior-Samuel Lopez-Yepez",
            "Karthik Soma",
            "Antoine Fagette"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19512",
        "abstract": "Multi-Agent Reinforcement Learning (MARL) is a growing research area which gained significant traction in recent years, extending Deep RL applications to a much wider range of problems. A particularly challenging class of problems in this domain is Heterogeneous Multi-Agent Reinforcement Learning (HeMARL), where agents with different sensors, resources, or capabilities must cooperate based on local information. The large number of real-world situations involving heterogeneous agents makes it an attractive research area, yet underexplored, as most MARL research focuses on homogeneous agents (e.g., a swarm of identical robots). In MARL and single-agent RL, standardized environments such as ALE and SMAC have allowed to establish recognized benchmarks to measure progress. However, there is a clear lack of such standardized testbed for cooperative HeMARL. As a result, new research in this field often uses simple environments, where most algorithms perform near optimally, or uses weakly heterogeneous MARL environments.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "40",
        "title": "Cognitive Load Limits in Large Language Models: Benchmarking Multi-Hop Reasoning",
        "author": [
            "Sai Teja Reddy Adapala"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19517",
        "abstract": "The scaling of Large Language Models (LLMs) has exposed a critical gap between their performance on static benchmarks and their fragility in dynamic, information-rich environments. While models excel at isolated tasks, the computational limits that govern their reasoning under cognitive load remain poorly understood. In this work, we introduce a formal theory of computational cognitive load, positing that extraneous, task-irrelevant information (Context Saturation) and interference from task-switching (Attentional Residue) are key mechanisms that degrade performance. We designed the Interleaved Cognitive Evaluation (ICE), a deconfounded benchmark to systematically manipulate these load factors on challenging multi-hop reasoning tasks. A comprehensive study (N = 10 replications per item across 200 questions) revealed significant performance variations across five instruction-tuned models. Smaller open-source architectures (Llama-3-8B-Instruct, Mistral-7B-Instruct-v0.2) exhibited baseline brittleness, achieving 0% accuracy (SEM = 0.0) across all conditions, including clean controls, on this high-intrinsic-load task. In contrast, Gemini-2.0-Flash-001 showed partial resilience, achieving 85% accuracy in control conditions, with a statistically significant degradation under context saturation ($\\beta = -0.003$ per % load, $p < 0.001$). These findings provide preliminary evidence that cognitive load is a key contributor to reasoning failures, supporting theories of hallucination-as-guessing under uncertainty. We conclude that dynamic, cognitive-aware stress testing, as exemplified by the ICE benchmark, is essential for evaluating the true resilience and safety of advanced AI systems.",
        "tags": [
            "LLM",
            "LLaMA"
        ]
    },
    {
        "id": "41",
        "title": "A Bimanual Gesture Interface for ROS-Based Mobile Manipulators Using TinyML and Sensor Fusion",
        "author": [
            "Najeeb Ahmed Bhuiyan",
            "M. Nasimul Huq",
            "Sakib H. Chowdhury",
            "Rahul Mangharam"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19521",
        "abstract": "Gesture-based control for mobile manipulators faces persistent challenges in reliability, efficiency, and intuitiveness. This paper presents a dual-hand gesture interface that integrates TinyML, spectral analysis, and sensor fusion within a ROS framework to address these limitations. The system uses left-hand tilt and finger flexion, captured using accelerometer and flex sensors, for mobile base navigation, while right-hand IMU signals are processed through spectral analysis and classified by a lightweight neural network. This pipeline enables TinyML-based gesture recognition to control a 7-DOF Kinova Gen3 manipulator. By supporting simultaneous navigation and manipulation, the framework improves efficiency and coordination compared to sequential methods. Key contributions include a bimanual control architecture, real-time low-power gesture recognition, robust multimodal sensor fusion, and a scalable ROS-based implementation. The proposed approach advances Human-Robot Interaction (HRI) for industrial automation, assistive robotics, and hazardous environments, offering a cost-effective, open-source solution with strong potential for real-world deployment and further optimization.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "42",
        "title": "Bioinspired SLAM Approach for Unmanned Surface Vehicle",
        "author": [
            "Fabio Coelho",
            "Joao Victor T. Borges",
            "Paulo Padrao",
            "Jose Fuentes",
            "Ramon R. Costa",
            "Liu Hsu",
            "Leonardo Bobadilla"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19522",
        "abstract": "This paper presents OpenRatSLAM2, a new version of OpenRatSLAM - a bioinspired SLAM framework based on computational models of the rodent hippocampus. OpenRatSLAM2 delivers low-computation-cost visual-inertial based SLAM, suitable for GPS-denied environments. Our contributions include a ROS2-based architecture, experimental results on new waterway datasets, and insights into system parameter tuning. This work represents the first known application of RatSLAM on USVs. The estimated trajectory was compared with ground truth data using the Hausdorff distance. The results show that the algorithm can generate a semimetric map with an error margin acceptable for most robotic applications.",
        "tags": [
            "SLAM"
        ]
    },
    {
        "id": "43",
        "title": "Score the Steps, Not Just the Goal: VLM-Based Subgoal Evaluation for Robotic Manipulation",
        "author": [
            "Ramy ElMallah",
            "Krish Chhajer",
            "Chi-Guhn Lee"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19524",
        "abstract": "Robot learning papers typically report a single binary success rate (SR), which obscures where a policy succeeds or fails along a multi-step manipulation task. We argue that subgoal-level reporting should become routine: for each trajectory, a vector of per-subgoal SRs that makes partial competence visible (e.g., grasp vs. pour). We propose a blueprint for StepEval, a cost-aware plug-in evaluation framework that utilizes vision-language models (VLMs) as automated judges of subgoal outcomes from recorded images or videos. Rather than proposing new benchmarks or APIs, our contribution is to outline design principles for a scalable, community-driven open-source project. In StepEval, the primary artifact for policy evaluation is the per-subgoal SR vector; however, other quantities (e.g., latency or cost estimates) are also considered for framework-optimization diagnostics to help the community tune evaluation efficiency and accuracy when ground-truth subgoal success labels are available. We discuss how such a framework can remain model-agnostic, support single- or multi-view inputs, and be lightweight enough to adopt across labs. The intended contribution is a shared direction: a minimal, extensible seed that invites open-source contributions, so that scoring the steps, not just the final goal, becomes a standard and reproducible practice.",
        "tags": [
            "Robotics",
            "VLM"
        ]
    },
    {
        "id": "44",
        "title": "Real-Time Reinforcement Learning for Dynamic Tasks with a Parallel Soft Robot",
        "author": [
            "James Avtges",
            "Jake Ketchum",
            "Millicent Schlafly",
            "Helena Young",
            "Taekyoung Kim",
            "Allison Pinosky",
            "Ryan L. Truby",
            "Todd D. Murphey"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19525",
        "abstract": "Closed-loop control remains an open challenge in soft robotics. The nonlinear responses of soft actuators under dynamic loading conditions limit the use of analytic models for soft robot control. Traditional methods of controlling soft robots underutilize their configuration spaces to avoid nonlinearity, hysteresis, large deformations, and the risk of actuator damage. Furthermore, episodic data-driven control approaches such as reinforcement learning (RL) are traditionally limited by sample efficiency and inconsistency across initializations. In this work, we demonstrate RL for reliably learning control policies for dynamic balancing tasks in real-time single-shot hardware deployments. We use a deformable Stewart platform constructed using parallel, 3D-printed soft actuators based on motorized handed shearing auxetic (HSA) structures. By introducing a curriculum learning approach based on expanding neighborhoods of a known equilibrium, we achieve reliable single-deployment balancing at arbitrary coordinates. In addition to benchmarking the performance of model-based and model-free methods, we demonstrate that in a single deployment, Maximum Diffusion RL is capable of learning dynamic balancing after half of the actuators are effectively disabled, by inducing buckling and by breaking actuators with bolt cutters. Training occurs with no prior data, in as fast as 15 minutes, with performance nearly identical to the fully-intact platform. Single-shot learning on hardware facilitates soft robotic systems reliably learning in the real world and will enable more diverse and capable soft robots.",
        "tags": [
            "3D",
            "Diffusion",
            "RL",
            "Robotics"
        ]
    },
    {
        "id": "45",
        "title": "Metriplectic Conditional Flow Matching for Dissipative Dynamics",
        "author": [
            "Ali Baheri",
            "Lars Lindemann"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19526",
        "abstract": "Metriplectic conditional flow matching (MCFM) learns dissipative dynamics without violating first principles. Neural surrogates often inject energy and destabilize long-horizon rollouts; MCFM instead builds the conservative-dissipative split into both the vector field and a structure preserving sampler. MCFM trains via conditional flow matching on short transitions, avoiding long rollout adjoints. In inference, a Strang-prox scheme alternates a symplectic update with a proximal metric step, ensuring discrete energy decay; an optional projection enforces strict decay when a trusted energy is available. We provide continuous and discrete time guarantees linking this parameterization and sampler to conservation, monotonic dissipation, and stable rollouts. On a controlled mechanical benchmark, MCFM yields phase portraits closer to ground truth and markedly fewer energy-increase and positive energy rate events than an equally expressive unconstrained neural flow, while matching terminal distributional fit.",
        "tags": [
            "Flow Matching"
        ]
    },
    {
        "id": "46",
        "title": "Semantic-Aware Fuzzing: An Empirical Framework for LLM-Guided, Reasoning-Driven Input Mutation",
        "author": [
            "Mengdi Lu",
            "Steven Ding",
            "Furkan Alaca",
            "Philippe Charland"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19533",
        "abstract": "Security vulnerabilities in Internet-of-Things devices, mobile platforms, and autonomous systems remain critical. Traditional mutation-based fuzzers -- while effectively explore code paths -- primarily perform byte- or bit-level edits without semantic reasoning. Coverage-guided tools such as AFL++ use dictionaries, grammars, and splicing heuristics to impose shallow structural constraints, leaving deeper protocol logic, inter-field dependencies, and domain-specific semantics unaddressed. Conversely, reasoning-capable large language models (LLMs) can leverage pretraining knowledge to understand input formats, respect complex constraints, and propose targeted mutations, much like an experienced reverse engineer or testing expert. However, lacking ground truth for \"correct\" mutation reasoning makes supervised fine-tuning impractical, motivating explorations of off-the-shelf LLMs via prompt-based few-shot learning. To bridge this gap, we present an open-source microservices framework that integrates reasoning LLMs with AFL++ on Google's FuzzBench, tackling asynchronous execution and divergent hardware demands (GPU- vs. CPU-intensive) of LLMs and fuzzers. We evaluate four research questions: (R1) How can reasoning LLMs be integrated into the fuzzing mutation loop? (R2) Do few-shot prompts yield higher-quality mutations than zero-shot? (R3) Can prompt engineering with off-the-shelf models improve fuzzing directly? and (R4) Which open-source reasoning LLMs perform best under prompt-only conditions? Experiments with Llama3.3, Deepseek-r1-Distill-Llama-70B, QwQ-32B, and Gemma3 highlight Deepseek as the most promising. Mutation effectiveness depends more on prompt complexity and model choice than shot count. Response latency and throughput bottlenecks remain key obstacles, offering directions for future work.",
        "tags": [
            "DeepSeek",
            "LLM",
            "LLaMA"
        ]
    },
    {
        "id": "47",
        "title": "DAWM: Diffusion Action World Models for Offline Reinforcement Learning via Action-Inferred Transitions",
        "author": [
            "Zongyue Li",
            "Xiao Han",
            "Yusong Li",
            "Niklas Strauss",
            "Matthias Schubert"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19538",
        "abstract": "Diffusion-based world models have demonstrated strong capabilities in synthesizing realistic long-horizon trajectories for offline reinforcement learning (RL). However, many existing methods do not directly generate actions alongside states and rewards, limiting their compatibility with standard value-based offline RL algorithms that rely on one-step temporal difference (TD) learning. While prior work has explored joint modeling of states, rewards, and actions to address this issue, such formulations often lead to increased training complexity and reduced performance in practice. We propose \\textbf{DAWM}, a diffusion-based world model that generates future state-reward trajectories conditioned on the current state, action, and return-to-go, paired with an inverse dynamics model (IDM) for efficient action inference. This modular design produces complete synthetic transitions suitable for one-step TD-based offline RL, enabling effective and computationally efficient training. Empirically, we show that conservative offline RL algorithms such as TD3BC and IQL benefit significantly from training on these augmented trajectories, consistently outperforming prior diffusion-based baselines across multiple tasks in the D4RL benchmark.",
        "tags": [
            "Diffusion",
            "RL"
        ]
    },
    {
        "id": "48",
        "title": "Do LLMs Encode Frame Semantics? Evidence from Frame Identification",
        "author": [
            "Jayanth Krishna Chundru",
            "Rudrashis Poddar",
            "Jie Cao",
            "Tianyu Jiang"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19540",
        "abstract": "We investigate whether large language models encode latent knowledge of frame semantics, focusing on frame identification, a core challenge in frame semantic parsing that involves selecting the appropriate semantic frame for a target word in context. Using the FrameNet lexical resource, we evaluate models under prompt-based inference and observe that they can perform frame identification effectively even without explicit supervision. To assess the impact of task-specific training, we fine-tune the model on FrameNet data, which substantially improves in-domain accuracy while generalizing well to out-of-domain benchmarks. Further analysis shows that the models can generate semantically coherent frame definitions, highlighting the model's internalized understanding of frame semantics.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "49",
        "title": "Autonomous Elemental Characterization Enabled by a Low Cost Robotic Platform Built Upon a Generalized Software Architecture",
        "author": [
            "Xuan Cao",
            "Yuxin Wu",
            "Michael L. Whittaker"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19541",
        "abstract": "Despite the rapidly growing applications of robots in industry, the use of robots to automate tasks in scientific laboratories is less prolific due to lack of generalized methodologies and high cost of hardware. This paper focuses on the automation of characterization tasks necessary for reducing cost while maintaining generalization, and proposes a software architecture for building robotic systems in scientific laboratory environment. A dual-layer (http://Socket.IO and ROS) action server design is the basic building block, which facilitates the implementation of a web-based front end for user-friendly operations and the use of ROS Behavior Tree for convenient task planning and execution. A robotic platform for automating mineral and material sample characterization is built upon the architecture, with an open source, low-cost three-axis computer numerical control gantry system serving as the main robot. A handheld laser induced breakdown spectroscopy (LIBS) analyzer is integrated with a 3D printed adapter, enabling automated 2D chemical mapping. We demonstrate the utility of automated chemical mapping by scanning of the surface of a spodumene-bearing pegmatite core sample with a 1071-point dense hyperspectral map acquired at a rate of 1520 bits per second. Automated LIBS scanning enables controlled chemical quantification in the laboratory that complements field-based measurements acquired with the same handheld device, linking resource exploration and processing steps in the supply chain for lithium-based battery materials.",
        "tags": [
            "3D",
            "Robotics"
        ]
    },
    {
        "id": "50",
        "title": "iFinder: Structured Zero-Shot Vision-Based LLM Grounding for Dash-Cam Video Reasoning",
        "author": [
            "Manyi Yao",
            "Bingbing Zhuang",
            "Sparsh Garg",
            "Amit Roy-Chowdhury",
            "Christian Shelton",
            "Manmohan Chandraker",
            "Abhishek Aich"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19552",
        "abstract": "Grounding large language models (LLMs) in domain-specific tasks like post-hoc dash-cam driving video analysis is challenging due to their general-purpose training and lack of structured inductive biases. As vision is often the sole modality available for such analysis (i.e., no LiDAR, GPS, etc.), existing video-based vision-language models (V-VLMs) struggle with spatial reasoning, causal inference, and explainability of events in the input video. To this end, we introduce iFinder, a structured semantic grounding framework that decouples perception from reasoning by translating dash-cam videos into a hierarchical, interpretable data structure for LLMs. iFinder operates as a modular, training-free pipeline that employs pretrained vision models to extract critical cues -- object pose, lane positions, and object trajectories -- which are hierarchically organized into frame- and video-level structures. Combined with a three-block prompting strategy, it enables step-wise, grounded reasoning for the LLM to refine a peer V-VLM's outputs and provide accurate reasoning. Evaluations on four public dash-cam video benchmarks show that iFinder's proposed grounding with domain-specific cues, especially object orientation and global context, significantly outperforms end-to-end V-VLMs on four zero-shot driving benchmarks, with up to 39% gains in accident reasoning accuracy. By grounding LLMs with driving domain-specific representations, iFinder offers a zero-shot, interpretable, and reliable alternative to end-to-end V-VLMs for post-hoc driving video understanding.",
        "tags": [
            "LLM",
            "VLM"
        ]
    },
    {
        "id": "51",
        "title": "Learning Dynamics of Deep Learning -- Force Analysis of Deep Neural Networks",
        "author": [
            "Yi Ren"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19554",
        "abstract": "This thesis explores how deep learning models learn over time, using ideas inspired by force analysis. Specifically, we zoom in on the model's training procedure to see how one training example affects another during learning, like analyzing how forces move objects. We break this influence into two parts: how similar the two examples are, and how strong the updating force is. This framework helps us understand a wide range of the model's behaviors in different real systems. For example, it explains why certain examples have non-trivial learning paths, why (and why not) some LLM finetuning methods work, and why simpler, more structured patterns tend to be learned more easily. We apply this approach to various learning tasks and uncover new strategies for improving model training. While the method is still developing, it offers a new way to interpret models' behaviors systematically.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "52",
        "title": "Confidence Calibration in Large Language Model-Based Entity Matching",
        "author": [
            "Iris Kamsteeg",
            "Juan Cardenas-Cartagena",
            "Floris van Beers",
            "Gineke ten Holt",
            "Tsegaye Misikir Tashu",
            "Matias Valdenegro-Toro"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19557",
        "abstract": "This research aims to explore the intersection of Large Language Models and confidence calibration in Entity Matching. To this end, we perform an empirical study to compare baseline RoBERTa confidences for an Entity Matching task against confidences that are calibrated using Temperature Scaling, Monte Carlo Dropout and Ensembles. We use the Abt-Buy, DBLP-ACM, iTunes-Amazon and Company datasets. The findings indicate that the proposed modified RoBERTa model exhibits a slight overconfidence, with Expected Calibration Error scores ranging from 0.0043 to 0.0552 across datasets. We find that this overconfidence can be mitigated using Temperature Scaling, reducing Expected Calibration Error scores by up to 23.83%.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "53",
        "title": "Uncertainty in Semantic Language Modeling with PIXELS",
        "author": [
            "Stefania Radu",
            "Marco Zullich",
            "Matias Valdenegro-Toro"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19563",
        "abstract": "Pixel-based language models aim to solve the vocabulary bottleneck problem in language modeling, but the challenge of uncertainty quantification remains open. The novelty of this work consists of analysing uncertainty and confidence in pixel-based language models across 18 languages and 7 scripts, all part of 3 semantically challenging tasks. This is achieved through several methods such as Monte Carlo Dropout, Transformer Attention, and Ensemble Learning. The results suggest that pixel-based models underestimate uncertainty when reconstructing patches. The uncertainty is also influenced by the script, with Latin languages displaying lower uncertainty. The findings on ensemble learning show better performance when applying hyperparameter tuning during the named entity recognition and question-answering tasks across 16 languages.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "54",
        "title": "Retrieval Augmented Generation based context discovery for ASR",
        "author": [
            "Dimitrios Siskos",
            "Stavros Papadopoulos",
            "Pablo Peso Parada",
            "Jisi Zhang",
            "Karthikeyan Saravanan",
            "Anastasios Drosou"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19567",
        "abstract": "This work investigates retrieval augmented generation as an efficient strategy for automatic context discovery in context-aware Automatic Speech Recognition (ASR) system, in order to improve transcription accuracy in the presence of rare or out-of-vocabulary terms. However, identifying the right context automatically remains an open challenge. This work proposes an efficient embedding-based retrieval approach for automatic context discovery in ASR. To contextualize its effectiveness, two alternatives based on large language models (LLMs) are also evaluated: (1) large language model (LLM)-based context generation via prompting, and (2) post-recognition transcript correction using LLMs. Experiments on the TED-LIUMv3, Earnings21 and SPGISpeech demonstrate that the proposed approach reduces WER by up to 17% (percentage difference) relative to using no-context, while the oracle context results in a reduction of up to 24.1%.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "55",
        "title": "ExPe: Exact Positional Encodings for Generative Transformer Models with Extrapolating Capabilities",
        "author": [
            "Aleksis Datseris",
            "Sylvia Vassileva",
            "Ivan Koychev",
            "Svetla Boytcheva"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19569",
        "abstract": "This paper introduces a novel approach to position embeddings in transformer models, named \"Exact Positional Embeddings\" (ExPE). An absolute positional embedding method that can extrapolate to sequences of lengths longer than the ones it was trained on. Traditional transformer models rely on absolute or relative position embeddings to incorporate positional information into token embeddings, which often struggle with extrapolation to sequences longer than those seen during training. Our proposed method utilizes a novel embedding strategy that encodes exact positional information by overriding specific dimensions of the embedding vectors, thereby enabling a more precise representation of token positions. The proposed approach not only maintains the integrity of the original embeddings but also enhances the model's ability to generalize to more extended sequences. In causal language modeling, our ExPE embeddings significantly reduce perplexity compared to rotary and sinusoidal embeddings, when tested on sequences longer than those used in training.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "56",
        "title": "Agentic Scene Policies: Unifying Space, Semantics, and Affordances for Robot Action",
        "author": [
            "Sacha Morin",
            "Kumaraditya Gupta",
            "Mahtab Sandhu",
            "Charlie Gauthier",
            "Francesco Argenziano",
            "Kirsty Ellis",
            "Liam Paull"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19571",
        "abstract": "Executing open-ended natural language queries is a core problem in robotics. While recent advances in imitation learning and vision-language-actions models (VLAs) have enabled promising end-to-end policies, these models struggle when faced with complex instructions and new scenes. An alternative is to design an explicit scene representation as a queryable interface between the robot and the world, using query results to guide downstream motion planning. In this work, we present Agentic Scene Policies (ASP), an agentic framework that leverages the advanced semantic, spatial, and affordance-based querying capabilities of modern scene representations to implement a capable language-conditioned robot policy. ASP can execute open-vocabulary queries in a zero-shot manner by explicitly reasoning about object affordances in the case of more complex skills. Through extensive experiments, we compare ASP with VLAs on tabletop manipulation problems and showcase how ASP can tackle room-level queries through affordance-guided navigation, and a scaled-up scene representation. (Project page: https://montrealrobotics.ca/agentic-scene-policies.github.io/)",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "57",
        "title": "Chasing Stability: Humanoid Running via Control Lyapunov Function Guided Reinforcement Learning",
        "author": [
            "Zachary Olkin",
            "Kejun Li",
            "William D. Compton",
            "Aaron D. Ames"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19573",
        "abstract": "Achieving highly dynamic behaviors on humanoid robots, such as running, requires controllers that are both robust and precise, and hence difficult to design. Classical control methods offer valuable insight into how such systems can stabilize themselves, but synthesizing real-time controllers for nonlinear and hybrid dynamics remains challenging. Recently, reinforcement learning (RL) has gained popularity for locomotion control due to its ability to handle these complex dynamics. In this work, we embed ideas from nonlinear control theory, specifically control Lyapunov functions (CLFs), along with optimized dynamic reference trajectories into the reinforcement learning training process to shape the reward. This approach, CLF-RL, eliminates the need to handcraft and tune heuristic reward terms, while simultaneously encouraging certifiable stability and providing meaningful intermediate rewards to guide learning. By grounding policy learning in dynamically feasible trajectories, we expand the robot's dynamic capabilities and enable running that includes both flight and single support phases. The resulting policy operates reliably on a treadmill and in outdoor environments, demonstrating robustness to disturbances applied to the torso and feet. Moreover, it achieves accurate global reference tracking utilizing only on-board sensors, making a critical step toward integrating these dynamic motions into a full autonomy stack.",
        "tags": [
            "RL",
            "Robotics"
        ]
    },
    {
        "id": "58",
        "title": "LLMs4All: A Review on Large Language Models for Research and Applications in Academic Disciplines",
        "author": [
            "Yanfang",
            "Zheyuan Zhang",
            "Tianyi Ma",
            "Zehong Wang",
            "Yiyang Li",
            "Shifu Hou",
            "Weixiang Sun",
            "Kaiwen Shi",
            "Yijun Ma",
            "Wei Song",
            "Ahmed Abbasi",
            "Ying Cheng",
            "Jane Cleland-Huang",
            "Steven Corcelli",
            "Patricia Culligan",
            "Robert Goulding",
            "Ming Hu",
            "Ting Hua",
            "John Lalor",
            "Fang Liu",
            "Tengfei Luo",
            "Ed Maginn",
            "Nuno Moniz",
            "Jason Rohr",
            "Brett Savoie",
            "Daniel Slate",
            "Tom Stapleford",
            "Matthew Webber",
            "Olaf Wiest",
            "Johnny Zhang",
            "Nitesh Chawla"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19580",
        "abstract": "Cutting-edge Artificial Intelligence (AI) techniques keep reshaping our view of the world. For example, Large Language Models (LLMs) based applications such as ChatGPT have shown the capability of generating human-like conversation on extensive topics. Due to the impressive performance on a variety of language-related tasks (e.g., open-domain question answering, translation, and document summarization), one can envision the far-reaching impacts that can be brought by the LLMs with broader real-world applications (e.g., customer service, education and accessibility, and scientific discovery). Inspired by their success, this paper will offer an overview of state-of-the-art LLMs and their integration into a wide range of academic disciplines, including: (1) arts, letters, and law (e.g., history, philosophy, political science, arts and architecture, law), (2) economics and business (e.g., finance, economics, accounting, marketing), and (3) science and engineering (e.g., mathematics, physics and mechanical engineering, chemistry and chemical engineering, life sciences and bioengineering, earth sciences and civil engineering, computer science and electrical engineering). Integrating humanity and technology, in this paper, we will explore how LLMs are shaping research and practice in these fields, while also discussing key limitations, open challenges, and future directions in the era of generative AI. The review of how LLMs are engaged across disciplines-along with key observations and insights-can help researchers and practitioners interested in exploiting LLMs to advance their works in diverse real-world applications.",
        "tags": [
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "59",
        "title": "Reverse Engineering User Stories from Code using Large Language Models",
        "author": [
            "Mohamed Ouf",
            "Haoyu Li",
            "Michael Zhang",
            "Mariam Guizani"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19587",
        "abstract": "User stories are essential in agile development, yet often missing or outdated in legacy and poorly documented systems. We investigate whether large language models (LLMs) can automatically recover user stories directly from source code and how prompt design impacts output quality. Using 1,750 annotated C++ snippets of varying complexity, we evaluate five state-of-the-art LLMs across six prompting strategies. Results show that all models achieve, on average, an F1 score of 0.8 for code up to 200 NLOC. Our findings show that a single illustrative example enables the smallest model (8B) to match the performance of a much larger 70B model. In contrast, structured reasoning via Chain-of-Thought offers only marginal gains, primarily for larger models.",
        "tags": [
            "CoT",
            "LLM"
        ]
    },
    {
        "id": "60",
        "title": "GuessingGame: Measuring the Informativeness of Open-Ended Questions in Large Language Models",
        "author": [
            "Dylan Hutson",
            "Daniel Vennemeyer",
            "Aneesh Deshmukh",
            "Justin Zhan",
            "Tianyu Jiang"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19593",
        "abstract": "We introduce GuessingGame, a protocol for evaluating large language models (LLMs) as strategic question-askers in open-ended, open-domain settings. A Guesser LLM identifies a hidden object by posing free-form questions to an Oracle without predefined choices or candidate lists. To measure question quality, we propose two information gain (IG) metrics: a Bayesian method that tracks belief updates over semantic concepts using LLM-scored relevance, and an entropy-based method that filters candidates via ConceptNet. Both metrics are model-agnostic and support post hoc analysis. Across 858 games with multiple models and prompting strategies, higher IG strongly predicts efficiency: a one-standard-deviation IG increase reduces expected game length by 43\\%. Prompting constraints guided by IG, such as enforcing question diversity, enable weaker models to significantly improve performance. These results show that question-asking in LLMs is both measurable and improvable, and crucial for interactive reasoning.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "61",
        "title": "Anatomy of a Feeling: Narrating Embodied Emotions via Large Vision-Language Models",
        "author": [
            "Mohammad Saim",
            "Phan Anh Duong",
            "Cat Luong",
            "Aniket Bhanderi",
            "Tianyu Jiang"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19595",
        "abstract": "The embodiment of emotional reactions from body parts contains rich information about our affective experiences. We propose a framework that utilizes state-of-the-art large vision-language models (LVLMs) to generate Embodied LVLM Emotion Narratives (ELENA). These are well-defined, multi-layered text outputs, primarily comprising descriptions that focus on the salient body parts involved in emotional reactions. We also employ attention maps and observe that contemporary models exhibit a persistent bias towards the facial region. Despite this limitation, we observe that our employed framework can effectively recognize embodied emotions in face-masked images, outperforming baselines without any fine-tuning. ELENA opens a new trajectory for embodied emotion analysis across the modality of vision and enriches modeling in an affect-aware setting.",
        "tags": [
            "VLM"
        ]
    },
    {
        "id": "62",
        "title": "Parameter-Efficient Multi-Task Learning via Progressive Task-Specific Adaptation",
        "author": [
            "Neeraj Gangwar",
            "Anshuka Rangi",
            "Rishabh Deshmukh",
            "Holakou Rahmanian",
            "Yesh Dattatreya",
            "Nickvash Kani"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19602",
        "abstract": "Parameter-efficient fine-tuning methods have emerged as a promising solution for adapting pre-trained models to various downstream tasks. While these methods perform well in single-task learning, extending them to multi-task learning exacerbates common challenges, such as task interference and negative transfer, due to the limited number of trainable parameters. To address these issues, we introduce progressive task-specific multi-task adaptation, a novel parameter-efficient approach for multi-task learning. This approach introduces adapter modules in a pre-trained model such that these modules are shared across all tasks in the initial layers and become progressively more task-specific in the later layers. The motivation is to reduce the conflicts among tasks by allowing transfer learning across all tasks in the initial layers and enabling task-specific learning toward the prediction heads. Additionally, we propose a gradient-based approach for computing task similarity and use this measure to allocate similar tasks to the shared adapter modules. Our task similarity method introduces minimal overhead in the pipeline. We evaluate our approach by adapting the Swin Transformer for dense prediction tasks. Experiments on the PASCAL and NYUD-v2 datasets demonstrate that our approach outperforms a fully fine-tuned multi-task model while requiring only one-fifth of the trainable parameters. This approach achieves better relative improvement to single-task fine-tuning while reducing the number of trainable parameters and surpasses the current state-of-the-art methods for parameter-efficient multi-task learning.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "63",
        "title": "Look as You Leap: Planning Simultaneous Motion and Perception for High-DOF Robots",
        "author": [
            "Qingxi Meng",
            "Emiliano Flores",
            "Carlos Quintero-PeÃ±a",
            "Peizhu Qian",
            "Zachary Kingston",
            "Shannan K. Hamlin",
            "Vaibhav Unhelkar",
            "Lydia E. Kavraki"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19610",
        "abstract": "In this work, we address the problem of planning robot motions for a high-degree-of-freedom (DoF) robot that effectively achieves a given perception task while the robot and the perception target move in a dynamic environment. Achieving navigation and perception tasks simultaneously is challenging, as these objectives often impose conflicting requirements. Existing methods that compute motion under perception constraints fail to account for obstacles, are designed for low-DoF robots, or rely on simplified models of perception. Furthermore, in dynamic real-world environments, robots must replan and react quickly to changes and directly evaluating the quality of perception (e.g., object detection confidence) is often expensive or infeasible at runtime. This problem is especially important in human-centered environments such as homes and hospitals, where effective perception is essential for safe and reliable operation. To address these challenges, we propose a GPU-parallelized perception-score-guided probabilistic roadmap planner with a neural surrogate model (PS-PRM). The planner explicitly incorporates the estimated quality of a perception task into motion planning for high-DoF robots. Our method uses a learned model to approximate perception scores and leverages GPU parallelism to enable efficient online replanning in dynamic settings. We demonstrate that our planner, evaluated on high-DoF robots, outperforms baseline methods in both static and dynamic environments in both simulation and real-robot experiments.",
        "tags": [
            "Detection",
            "Robotics"
        ]
    },
    {
        "id": "64",
        "title": "EgoBridge: Domain Adaptation for Generalizable Imitation from Egocentric Human Data",
        "author": [
            "Ryan Punamiya",
            "Dhruv Patel",
            "Patcharapong Aphiwetsa",
            "Pranav Kuppili",
            "Lawrence Y. Zhu",
            "Simar Kareer",
            "Judy Hoffman",
            "Danfei Xu"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19626",
        "abstract": "Egocentric human experience data presents a vast resource for scaling up end-to-end imitation learning for robotic manipulation. However, significant domain gaps in visual appearance, sensor modalities, and kinematics between human and robot impede knowledge transfer. This paper presents EgoBridge, a unified co-training framework that explicitly aligns the policy latent spaces between human and robot data using domain adaptation. Through a measure of discrepancy on the joint policy latent features and actions based on Optimal Transport (OT), we learn observation representations that not only align between the human and robot domain but also preserve the action-relevant information critical for policy learning. EgoBridge achieves a significant absolute policy success rate improvement by 44% over human-augmented cross-embodiment baselines in three real-world single-arm and bimanual manipulation tasks. EgoBridge also generalizes to new objects, scenes, and tasks seen only in human data, where baselines fail entirely. Videos and additional information can be found at https://ego-bridge.github.io",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "65",
        "title": "Mamba Modulation: On the Length Generalization of Mamba",
        "author": [
            "Peng Lu",
            "Jerry Huang",
            "Qiuhao Zeng",
            "Xinyu Wang",
            "Boxing Wang",
            "Philippe Langlais",
            "Yufei Cui"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19633",
        "abstract": "The quadratic complexity of the attention mechanism in Transformer models has motivated the development of alternative architectures with sub-quadratic scaling, such as state-space models. Among these, Mamba has emerged as a leading architecture, achieving state-of-the-art results across a range of language modeling tasks. However, Mamba's performance significantly deteriorates when applied to contexts longer than those seen during pre-training, revealing a sharp sensitivity to context length extension. Through detailed analysis, we attribute this limitation to the out-of-distribution behaviour of its state-space dynamics, particularly within the parameterization of the state transition matrix $\\mathbf{A}$. Unlike recent works which attribute this sensitivity to the vanished accumulation of discretization time steps, $\\exp(-\\sum_{t=1}^N\\Delta_t)$, we establish a connection between state convergence behavior as the input length approaches infinity and the spectrum of the transition matrix $\\mathbf{A}$, offering a well-founded explanation of its role in length extension. Next, to overcome this challenge, we propose an approach that applies spectrum scaling to pre-trained Mamba models to enable robust long-context generalization by selectively modulating the spectrum of $\\mathbf{A}$ matrices in each layer. We show that this can significantly improve performance in settings where simply modulating $\\Delta_t$ fails, validating our insights and providing avenues for better length generalization of state-space models with structured transition matrices.",
        "tags": [
            "Mamba",
            "SSMs",
            "Transformer"
        ]
    },
    {
        "id": "66",
        "title": "AutoSpec: An Agentic Framework for Automatically Drafting Patent Specification",
        "author": [
            "Ryan Shea",
            "Zhou Yu"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19640",
        "abstract": "Patents play a critical role in driving technological innovation by granting inventors exclusive rights to their inventions. However the process of drafting a patent application is often expensive and time-consuming, making it a prime candidate for automation. Despite recent advancements in language models, several challenges hinder the development of robust automated patent drafting systems. First, the information within a patent application is highly confidential, which often prevents the use of closed-source LLMs for automating this task. Second, the process of drafting a patent application is difficult for even the most advanced language models due to their long context, technical writing style, and specialized domain knowledge. To address these challenges, we introduce AutoSpec, a secure, agentic framework for Automatically drafting patent Specification. Our approach decomposes the drafting process into a sequence of manageable subtasks, each solvable by smaller, open-source language models enhanced with custom tools tailored for drafting patent specification. To assess our system, we design a novel evaluation protocol in collaboration with experienced patent attorneys. Our automatic and expert evaluations show that AutoSpec outperforms existing baselines on a patent drafting task.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "67",
        "title": "High Clockrate Free-space Optical In-Memory Computing",
        "author": [
            "Yuanhao Liang",
            "James Wang",
            "Kaiwen Xue",
            "Xinyi Ren",
            "Ran Yin",
            "Shaoyuan Ou",
            "Lian Zhou",
            "Yuan Li",
            "Tobias Heuser",
            "Niels Heermeier",
            "Ian Christen",
            "James A. Lott",
            "Stephan Reitzenstein",
            "Mengjie Yu",
            "Zaijun Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19642",
        "abstract": "The ability to process and act on data in real time is increasingly critical for applications ranging from autonomous vehicles, three-dimensional environmental sensing and remote robotics. However, the deployment of deep neural networks (DNNs) in edge devices is hindered by the lack of energy-efficient scalable computing hardware. Here, we introduce a fanout spatial time-of-flight optical neural network (FAST-ONN) that calculates billions of convolutions per second with ultralow latency and power consumption. This is enabled by the combination of high-speed dense arrays of vertical-cavity surface-emitting lasers (VCSELs) for input modulation with spatial light modulators of high pixel counts for in-memory weighting. In a three-dimensional optical system, parallel differential readout allows signed weight values accurate inference in a single shot. The performance is benchmarked with feature extraction in You-Only-Look-Once (YOLO) for convolution at 100 million frames per second (MFPS), and in-system backward propagation training with photonic reprogrammability. The VCSEL transmitters are implementable in any free-space optical computing systems to improve the clockrate to over gigahertz. The high scalability in device counts and channel parallelism enables a new avenue to scale up free space computing hardware.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "68",
        "title": "Are We Scaling the Right Thing? A System Perspective on Test-Time Scaling",
        "author": [
            "Youpeng Zhao",
            "Jinpeng LV",
            "Di Wu",
            "Jun Wang",
            "Christopher Gooley"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19645",
        "abstract": "Test-time scaling (TTS) has recently emerged as a promising direction to exploit the hidden reasoning capabilities of pre-trained large language models (LLMs). However, existing scaling methods narrowly focus on the compute-optimal Pareto-frontier, ignoring the simple fact that compute-optimal is not always system-optimal. In this work, we propose a system-driven perspective on TTS, analyzing how reasoning models scale against practical metrics, such as latency and cost-per-token. By evaluating the impact of popular optimizations such as tensor parallelism and speculative decoding, our preliminary analysis reveals the limitations of current methods and calls for a paradigm shift toward holistic, system-aware evaluations that capture the true essence of scaling laws at inference time.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "69",
        "title": "RIS-assisted Data Collection and Wireless Power Transfer in Low-altitude Wireless Networks",
        "author": [
            "Wenwen Xie",
            "Geng Sun",
            "Jiahui Li",
            "Jiacheng Wang",
            "Yinqiu Liu",
            "Dusit Niyato",
            "Dong In Kim",
            "Shiwen Mao"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19651",
        "abstract": "Low-altitude wireless networks (LAWNs) have become effective solutions for collecting data from low-power Internet-of-Things devices (IoTDs) in remote areas with limited communication infrastructure. However, some outdoor IoTDs deployed in such areas face both energy constraints and low-channel quality challenges, making it challenging to ensure timely data collection from these IoTDs in LAWNs. In this work, we investigate a reconfigurable intelligent surface (RIS)-assisted uncrewed aerial vehicle (UAV)-enabled data collection and wireless power transfer system in LAWN. Specifically, IoTDs first harvest energy from a low-altitude UAV, and then upload their data to the UAV by applying the time division multiple access (TDMA) protocol, supported by an RIS to improve the channel quality. To maintain satisfactory data freshness of the IoTDs and save energy for an energy-constrained UAV, we aim to minimize the age of information (AoI) and energy consumption of the UAV by jointly optimizing the RIS phase shits, UAV trajectory, charging time allocation, and binary IoTD scheduling. We propose a deep reinforcement learning (DRL)-based approach, namely the alternating optimization-improved parameterized deep Q-network (AO-IPDQN). Specifically, considering that RIS typically contains a large number of reflecting elements, we first adopt an alternating optimization (AO) method to optimize the RIS phase shifts to reduce the dimension of the action space. Then, we propose the improved parameterized deep Q-network (IPDQN) method to deal with the hybrid action space. Simulation results indicate that AO-IPDQN approach achieves excellent performance relative to multiple comparison methods across various simulation scenarios.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "70",
        "title": "Large Language Models for Pedestrian Safety: An Application to Predicting Driver Yielding Behavior at Unsignalized Intersections",
        "author": [
            "Yicheng Yang",
            "Zixian Li",
            "Jean Paul Bizimana",
            "Niaz Zafri",
            "Yongfeng Dong",
            "Tianyi Li"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19657",
        "abstract": "Pedestrian safety is a critical component of urban mobility and is strongly influenced by the interactions between pedestrian decision-making and driver yielding behavior at crosswalks. Modeling driver--pedestrian interactions at intersections requires accurately capturing the complexity of these behaviors. Traditional machine learning models often struggle to capture the nuanced and context-dependent reasoning required for these multifactorial interactions, due to their reliance on fixed feature representations and limited interpretability. In contrast, large language models (LLMs) are suited for extracting patterns from heterogeneous traffic data, enabling accurate modeling of driver-pedestrian interactions. Therefore, this paper leverages multimodal LLMs through a novel prompt design that incorporates domain-specific knowledge, structured reasoning, and few-shot prompting, enabling interpretable and context-aware inference of driver yielding behavior, as an example application of modeling pedestrian--driver interaction. We benchmarked state-of-the-art LLMs against traditional classifiers, finding that GPT-4o consistently achieves the highest accuracy and recall, while Deepseek-V3 excels in precision. These findings highlight the critical trade-offs between model performance and computational efficiency, offering practical guidance for deploying LLMs in real-world pedestrian safety systems.",
        "tags": [
            "DeepSeek",
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "71",
        "title": "RoboSSM: Scalable In-context Imitation Learning via State-Space Models",
        "author": [
            "Youngju Yoo",
            "Jiaheng Hu",
            "Yifeng Zhu",
            "Bo Liu",
            "Qiang Liu",
            "Roberto MartÃ­n-MartÃ­n",
            "Peter Stone"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19658",
        "abstract": "In-context imitation learning (ICIL) enables robots to learn tasks from prompts consisting of just a handful of demonstrations. By eliminating the need for parameter updates at deployment time, this paradigm supports few-shot adaptation to novel tasks. However, recent ICIL methods rely on Transformers, which have computational limitations and tend to underperform when handling longer prompts than those seen during training. In this work, we introduce RoboSSM, a scalable recipe for in-context imitation learning based on state-space models (SSM). Specifically, RoboSSM replaces Transformers with Longhorn -- a state-of-the-art SSM that provides linear-time inference and strong extrapolation capabilities, making it well-suited for long-context prompts. We evaluate our approach on the LIBERO benchmark and compare it against strong Transformer-based ICIL baselines. Experiments show that RoboSSM extrapolates effectively to varying numbers of in-context demonstrations, yields high performance on unseen tasks, and remains robust in long-horizon scenarios. These results highlight the potential of SSMs as an efficient and scalable backbone for ICIL. Our code is available at https://github.com/youngjuY/RoboSSM.",
        "tags": [
            "SSMs",
            "Transformer"
        ]
    },
    {
        "id": "72",
        "title": "Bias in the Picture: Benchmarking VLMs with Social-Cue News Images and LLM-as-Judge Assessment",
        "author": [
            "Aravind Narayanan",
            "Vahid Reza Khazaie",
            "Shaina Raza"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19659",
        "abstract": "Large vision-language models (VLMs) can jointly interpret images and text, but they are also prone to absorbing and reproducing harmful social stereotypes when visual cues such as age, gender, race, clothing, or occupation are present. To investigate these risks, we introduce a news-image benchmark consisting of 1,343 image-question pairs drawn from diverse outlets, which we annotated with ground-truth answers and demographic attributes (age, gender, race, occupation, and sports). We evaluate a range of state-of-the-art VLMs and employ a large language model (LLM) as judge, with human verification. Our findings show that: (i) visual context systematically shifts model outputs in open-ended settings; (ii) bias prevalence varies across attributes and models, with particularly high risk for gender and occupation; and (iii) higher faithfulness does not necessarily correspond to lower bias. We release the benchmark prompts, evaluation rubric, and code to support reproducible and fairness-aware multimodal assessment.",
        "tags": [
            "LLM",
            "VLM"
        ]
    },
    {
        "id": "73",
        "title": "Assertion Messages with Large Language Models (LLMs) for Code",
        "author": [
            "Ahmed Aljohani",
            "Anamul Haque Mollah",
            "Hyunsook Do"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19673",
        "abstract": "Assertion messages significantly enhance unit tests by clearly explaining the reasons behind test failures, yet they are frequently omitted by developers and automated test-generation tools. Despite recent advancements, Large Language Models (LLMs) have not been systematically evaluated for their ability to generate informative assertion messages. In this paper, we introduce an evaluation of four state-of-the-art Fill-in-the-Middle (FIM) LLMs - Qwen2.5-Coder-32B, Codestral-22B, CodeLlama-13B, and StarCoder - on a dataset of 216 Java test methods containing developer-written assertion messages. We find that Codestral-22B achieves the highest quality score of 2.76 out of 5 using a human-like evaluation approach, compared to 3.24 for manually written messages. Our ablation study shows that including descriptive test comments further improves Codestral's performance to 2.97, highlighting the critical role of context in generating clear assertion messages. Structural analysis demonstrates that all models frequently replicate developers' preferred linguistic patterns. We discuss the limitations of the selected models and conventional text evaluation metrics in capturing diverse assertion message structures. Our benchmark, evaluation results, and discussions provide an essential foundation for advancing automated, context-aware generation of assertion messages in test code. A replication package is available at https://doi.org/10.5281/zenodo.15293133",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "74",
        "title": "Thinking While Listening: Simple Test Time Scaling For Audio Classification",
        "author": [
            "Prateek Verma",
            "Mert Pilanci"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19676",
        "abstract": "We propose a framework that enables neural models to \"think while listening\" to everyday sounds, thereby enhancing audio classification performance. Motivated by recent advances in the reasoning capabilities of large language models, we address two central questions: (i) how can thinking be incorporated into existing audio classification pipelines to enable reasoning in the category space and improve performance, and (ii) can a new architecture be designed from the ground up to support both thinking and test-time scaling? We demonstrate that in both settings, our models exhibit improved classification accuracy. Leveraging test-time scaling, we observe consistent gains as the number of sampled traces increases. Furthermore, we evaluate two open-source reasoning models, GPT-OSS-20B and Qwen3-14B, showing that while such models are capable of zero-shot reasoning, a lightweight approach--retraining only the embedding matrix of a frozen, smaller model like GPT-2--can surpass the performance of billion-parameter text-based reasoning models.",
        "tags": [
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "75",
        "title": "Unmasking Fake Careers: Detecting Machine-Generated Career Trajectories via Multi-layer Heterogeneous Graphs",
        "author": [
            "Michiharu Yamashita",
            "Thanh Tran",
            "Delvin Ce Zhang",
            "Dongwon Lee"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19677",
        "abstract": "The rapid advancement of Large Language Models (LLMs) has enabled the generation of highly realistic synthetic data. We identify a new vulnerability, LLMs generating convincing career trajectories in fake resumes and explore effective detection methods. To address this challenge, we construct a dataset of machine-generated career trajectories using LLMs and various methods, and demonstrate that conventional text-based detectors perform poorly on structured career data. We propose CareerScape, a novel heterogeneous, hierarchical multi-layer graph framework that models career entities and their relations in a unified global graph built from genuine resumes. Unlike conventional classifiers that treat each instance independently, CareerScape employs a structure-aware framework that augments user-specific subgraphs with trusted neighborhood information from a global graph, enabling the model to capture both global structural patterns and local inconsistencies indicative of synthetic career paths. Experimental results show that CareerScape outperforms state-of-the-art baselines by 5.8-85.0% relatively, highlighting the importance of structure-aware detection for machine-generated content.",
        "tags": [
            "Detection",
            "LLM"
        ]
    },
    {
        "id": "76",
        "title": "Calibrated Reasoning: An Explanatory Verifier for Dynamic and Efficient Problem-Solving",
        "author": [
            "Anisha Garg",
            "Engin Tekin",
            "Yash More",
            "David Bick",
            "Nishit Neema",
            "Ganesh Venkatesh"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19681",
        "abstract": "Advanced test-time computing strategies are essential for scaling reasoning models, but their effectiveness is capped by the models' poor self-evaluation. We propose a pairwise Explanatory Verifier, trained via reinforcement learning (GRPO), that produces calibrated confidence scores and associated natural language reasoning for generated solutions. Our verifier improves the accuracy and efficiency of test-time strategies like best-of-n and self-reflection. Crucially, it excels at identifying challenging failure modes, such as when both candidate solutions are identically incorrect, succeeding where standard methods like majority voting fail.",
        "tags": [
            "GRPO",
            "RL"
        ]
    },
    {
        "id": "77",
        "title": "Enhancing Transformer-Based Vision Models: Addressing Feature Map Anomalies Through Novel Optimization Strategies",
        "author": [
            "Sumit Mamtani"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19687",
        "abstract": "Vision Transformers (ViTs) have demonstrated superior performance across a wide range of computer vision tasks. However, structured noise artifacts in their feature maps hinder downstream applications such as segmentation and depth estimation. We propose two novel and lightweight optimisation techniques- Structured Token Augmentation (STA) and Adaptive Noise Filtering (ANF)- to improve interpretability and mitigate these artefacts. STA enhances token diversity through spatial perturbations during tokenisation, while ANF applies learnable inline denoising between transformer layers. These methods are architecture-agnostic and evaluated across standard benchmarks, including ImageNet, Ade20k, and NYUv2. Experimental results show consistent improvements in visual quality and task performance, highlighting the practical effectiveness of our approach.",
        "tags": [
            "Depth Estimation",
            "Segmentation",
            "Transformer"
        ]
    },
    {
        "id": "78",
        "title": "Formal Safety Verification and Refinement for Generative Motion Planners via Certified Local Stabilization",
        "author": [
            "Devesh Nath",
            "Haoran Yin",
            "Glen Chou"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19688",
        "abstract": "We present a method for formal safety verification of learning-based generative motion planners. Generative motion planners (GMPs) offer advantages over traditional planners, but verifying the safety and dynamic feasibility of their outputs is difficult since neural network verification (NNV) tools scale only to a few hundred neurons, while GMPs often contain millions. To preserve GMP expressiveness while enabling verification, our key insight is to imitate the GMP by stabilizing references sampled from the GMP with a small neural tracking controller and then applying NNV to the closed-loop dynamics. This yields reachable sets that rigorously certify closed-loop safety, while the controller enforces dynamic feasibility. Building on this, we construct a library of verified GMP references and deploy them online in a way that imitates the original GMP distribution whenever it is safe to do so, improving safety without retraining. We evaluate across diverse planners, including diffusion, flow matching, and vision-language models, improving safety in simulation (on ground robots and quadcopters) and on hardware (differential-drive robot).",
        "tags": [
            "Diffusion",
            "Flow Matching",
            "Robotics",
            "VLM"
        ]
    },
    {
        "id": "79",
        "title": "From Prompt to Progression: Taming Video Diffusion Models for Seamless Attribute Transition",
        "author": [
            "Ling Lo",
            "Kelvin C.K. Chan",
            "Wen-Huang Cheng",
            "Ming-Hsuan Yang"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19690",
        "abstract": "Existing models often struggle with complex temporal changes, particularly when generating videos with gradual attribute transitions. The most common prompt interpolation approach for motion transitions often fails to handle gradual attribute transitions, where inconsistencies tend to become more pronounced. In this work, we propose a simple yet effective method to extend existing models for smooth and consistent attribute transitions, through introducing frame-wise guidance during the denoising process. Our approach constructs a data-specific transitional direction for each noisy latent, guiding the gradual shift from initial to final attributes frame by frame while preserving the motion dynamics of the video. Moreover, we present the Controlled-Attribute-Transition Benchmark (CAT-Bench), which integrates both attribute and motion dynamics, to comprehensively evaluate the performance of different models. We further propose two metrics to assess the accuracy and smoothness of attribute transitions. Experimental results demonstrate that our approach performs favorably against existing baselines, achieving visual fidelity, maintaining alignment with text prompts, and delivering seamless attribute transitions. Code and CATBench are released: https://github.com/lynn-ling-lo/Prompt2Progression.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "80",
        "title": "Diffusion-Based Impedance Learning for Contact-Rich Manipulation Tasks",
        "author": [
            "Noah Geiger",
            "Tamim Asfour",
            "Neville Hogan",
            "Johannes Lachner"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19696",
        "abstract": "Learning methods excel at motion generation in the information domain but are not primarily designed for physical interaction in the energy domain. Impedance Control shapes physical interaction but requires task-aware tuning by selecting feasible impedance parameters. We present Diffusion-Based Impedance Learning, a framework that combines both domains. A Transformer-based Diffusion Model with cross-attention to external wrenches reconstructs a simulated Zero-Force Trajectory (sZFT). This captures both translational and rotational task-space behavior. For rotations, we introduce a novel SLERP-based quaternion noise scheduler that ensures geometric consistency. The reconstructed sZFT is then passed to an energy-based estimator that updates stiffness and damping parameters. A directional rule is applied that reduces impedance along non task axes while preserving rigidity along task directions. Training data were collected for a parkour scenario and robotic-assisted therapy tasks using teleoperation with Apple Vision Pro. With only tens of thousands of samples, the model achieved sub-millimeter positional accuracy and sub-degree rotational accuracy. Its compact model size enabled real-time torque control and autonomous stiffness adaptation on a KUKA LBR iiwa robot. The controller achieved smooth parkour traversal within force and velocity limits and 30/30 success rates for cylindrical, square, and star peg insertions without any peg-specific demonstrations in the training data set. All code for the Transformer-based Diffusion Model, the robot controller, and the Apple Vision Pro telemanipulation framework is publicly available. These results mark an important step towards Physical AI, fusing model-based control for physical interaction with learning-based methods for trajectory generation.",
        "tags": [
            "Diffusion",
            "Robotics",
            "Transformer"
        ]
    },
    {
        "id": "81",
        "title": "Learning Contextual Retrieval for Robust Conversational Search",
        "author": [
            "Seunghan Yang",
            "Juntae Lee",
            "Jihwan Bang",
            "Kyuhong Shim",
            "Minsoo Kim",
            "Simyung Chang"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19700",
        "abstract": "Effective conversational search demands a deep understanding of user intent across multiple dialogue turns. Users frequently use abbreviations and shift topics in the middle of conversations, posing challenges for conventional retrievers. While query rewriting techniques improve clarity, they often incur significant computational cost due to additional autoregressive steps. Moreover, although LLM-based retrievers demonstrate strong performance, they are not explicitly optimized to track user intent in multi-turn settings, often failing under topic drift or contextual ambiguity. To address these limitations, we propose ContextualRetriever, a novel LLM-based retriever that directly incorporates conversational context into the retrieval process. Our approach introduces: (1) a context-aware embedding mechanism that highlights the current query within the dialogue history; (2) intent-guided supervision based on high-quality rewritten queries; and (3) a training strategy that preserves the generative capabilities of the base LLM. Extensive evaluations across multiple conversational search benchmarks demonstrate that ContextualRetriever significantly outperforms existing methods while incurring no additional inference overhead.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "82",
        "title": "Linear Transformers Implicitly Discover Unified Numerical Algorithms",
        "author": [
            "Patrick Lutz",
            "Aditya Gangrade",
            "Hadi Daneshmand",
            "Venkatesh Saligrama"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19702",
        "abstract": "We train a linear attention transformer on millions of masked-block matrix completion tasks: each prompt is masked low-rank matrix whose missing block may be (i) a scalar prediction target or (ii) an unseen kernel slice of NystrÃ¶m extrapolation. The model sees only input-output pairs and a mean-squared loss; it is given no normal equations, no handcrafted iterations, and no hint that the tasks are related. Surprisingly, after training, algebraic unrolling reveals the same parameter-free update rule across three distinct computational regimes (full visibility, rank-limited updates, and distributed computation). We prove that this rule achieves second-order convergence on full-batch problems, cuts distributed iteration complexity, and remains accurate with rank-limited attention. Thus, a transformer trained solely to patch missing blocks implicitly discovers a unified, resource-adaptive iterative solver spanning prediction, estimation, and NystrÃ¶m extrapolation, highlighting a powerful capability of in-context learning.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "83",
        "title": "TopoCut: Learning Multi-Step Cutting with Spectral Rewards and Discrete Diffusion Policies",
        "author": [
            "Liquan Wang",
            "Jiangjie Bian",
            "Eric Heiden",
            "Animesh Garg"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19712",
        "abstract": "Robotic manipulation tasks involving cutting deformable objects remain challenging due to complex topological behaviors, difficulties in perceiving dense object states, and the lack of efficient evaluation methods for cutting outcomes. In this paper, we introduce TopoCut, a comprehensive benchmark for multi-step robotic cutting tasks that integrates a cutting environment and generalized policy learning. TopoCut is built upon three core components: (1) We introduce a high-fidelity simulation environment based on a particle-based elastoplastic solver with compliant von Mises constitutive models, augmented by a novel damage-driven topology discovery mechanism that enables accurate tracking of multiple cutting pieces. (2) We develop a comprehensive reward design that integrates the topology discovery with a pose-invariant spectral reward model based on Laplace-Beltrami eigenanalysis, facilitating consistent and robust assessment of cutting quality. (3) We propose an integrated policy learning pipeline, where a dynamics-informed perception module predicts topological evolution and produces particle-wise, topology-aware embeddings to support PDDP (Particle-based Score-Entropy Discrete Diffusion Policy) for goal-conditioned policy learning. Extensive experiments demonstrate that TopoCut supports trajectory generation, scalable learning, precise evaluation, and strong generalization across diverse object geometries, scales, poses, and cutting goals.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "84",
        "title": "VIMD: Monocular Visual-Inertial Motion and Depth Estimation",
        "author": [
            "Saimouli Katragadda",
            "Guoquan Huang"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19713",
        "abstract": "Accurate and efficient dense metric depth estimation is crucial for 3D visual perception in robotics and XR. In this paper, we develop a monocular visual-inertial motion and depth (VIMD) learning framework to estimate dense metric depth by leveraging accurate and efficient MSCKF-based monocular visual-inertial motion tracking. At the core the proposed VIMD is to exploit multi-view information to iteratively refine per-pixel scale, instead of globally fitting an invariant affine model as in the prior work. The VIMD framework is highly modular, making it compatible with a variety of existing depth estimation backbones. We conduct extensive evaluations on the TartanAir and VOID datasets and demonstrate its zero-shot generalization capabilities on the AR Table dataset. Our results show that VIMD achieves exceptional accuracy and robustness, even with extremely sparse points as few as 10-20 metric depth points per image. This makes the proposed VIMD a practical solution for deployment in resource constrained settings, while its robust performance and strong generalization capabilities offer significant potential across a wide range of scenarios.",
        "tags": [
            "3D",
            "Depth Estimation",
            "Robotics"
        ]
    },
    {
        "id": "85",
        "title": "PolGS: Polarimetric Gaussian Splatting for Fast Reflective Surface Reconstruction",
        "author": [
            "Yufei Han",
            "Bowen Tie",
            "Heng Guo",
            "Youwei Lyu",
            "Si Li",
            "Boxin Shi",
            "Yunpeng Jia",
            "Zhanyu Ma"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19726",
        "abstract": "Efficient shape reconstruction for surfaces with complex reflectance properties is crucial for real-time virtual reality. While 3D Gaussian Splatting (3DGS)-based methods offer fast novel view rendering by leveraging their explicit surface representation, their reconstruction quality lags behind that of implicit neural representations, particularly in the case of recovering surfaces with complex reflective reflectance. To address these problems, we propose PolGS, a Polarimetric Gaussian Splatting model allowing fast reflective surface reconstruction in 10 minutes. By integrating polarimetric constraints into the 3DGS framework, PolGS effectively separates specular and diffuse components, enhancing reconstruction quality for challenging reflective materials. Experimental results on the synthetic and real-world dataset validate the effectiveness of our method.",
        "tags": [
            "3D",
            "Gaussian Splatting"
        ]
    },
    {
        "id": "86",
        "title": "Personality Vector: Modulating Personality of Large Language Models by Model Merging",
        "author": [
            "Seungjong Sun",
            "Seo Yeon Baek",
            "Jang Hyun Kim"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19727",
        "abstract": "Driven by the demand for personalized AI systems, there is growing interest in aligning the behavior of large language models (LLMs) with human traits such as personality. Previous attempts to induce personality in LLMs have shown promising results, but they struggle to capture the continuous and multidimensional nature of human traits. In this work, we propose a novel method for personality modulation in LLMs via model merging. Specifically, we construct personality vectors by subtracting the weights of a pre-trained model from those of the fine-tuned model on a given personality trait. By merging personality vectors, we enable LLMs to exhibit desired personality traits without additional training. Extensive experiments show that personality vectors enable continuous control over trait intensity and support the composition of multiple traits. Furthermore, personality vectors transfer across diverse downstream models, suggesting that they encode generalizable representations of personality. Our code is available at here.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "87",
        "title": "Gyges: Dynamic Cross-Instance Parallelism Transformation for Efficient LLM Inference",
        "author": [
            "Haoyu Chen",
            "Xue Li",
            "Kun Qian",
            "Yu Guan",
            "Jin Zhao",
            "Xin Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19729",
        "abstract": "Efficiently processing the dynamics of requests, especially the context length variance, is important in Large Language Model (LLM) serving scenarios. However, there is an intrinsic trade-off: while leveraging parallelism strategies, such as Tensor Parallelism (TP), can coordinate multiple GPUs to accommodate larger context lengths, it inevitably results in degraded overall throughput. In this paper, we propose Cross-Instance Parallelism Transformation (Gyges), which adaptively adjusts the parallelism strategies of running instances to align with the dynamics of incoming requests. We design (1) a page-friendly, header-centric layout to accelerate KV cache transformations; (2) dedicated weight padding to accelerate model weight transformations; and (3) a transformation-aware scheduler to cooperatively schedule requests and parallelism transformations, optimizing the overall performance. Evaluations using real-world traces show that Gyges improves throughput by 1.75x-6.57x compared to state-of-the-art solutions.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "88",
        "title": "CAMILA: Context-Aware Masking for Image Editing with Language Alignment",
        "author": [
            "Hyunseung Kim",
            "Chiho Choi",
            "Srikanth Malla",
            "Sai Prahladh Padmanabhan",
            "Saurabh Bagchi",
            "Joon Hee Choi"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19731",
        "abstract": "Text-guided image editing has been allowing users to transform and synthesize images through natural language instructions, offering considerable flexibility. However, most existing image editing models naively attempt to follow all user instructions, even if those instructions are inherently infeasible or contradictory, often resulting in nonsensical output. To address these challenges, we propose a context-aware method for image editing named as CAMILA (Context-Aware Masking for Image Editing with Language Alignment). CAMILA is designed to validate the contextual coherence between instructions and the image, ensuring that only relevant edits are applied to the designated regions while ignoring non-executable instructions. For comprehensive evaluation of this new method, we constructed datasets for both single- and multi-instruction image editing, incorporating the presence of infeasible requests. Our method achieves better performance and higher semantic alignment than state-of-the-art models, demonstrating its effectiveness in handling complex instruction challenges while preserving image integrity.",
        "tags": [
            "Image Editing"
        ]
    },
    {
        "id": "89",
        "title": "Trajectory Planning Using Safe Ellipsoidal Corridors as Projections of Orthogonal Trust Regions",
        "author": [
            "Akshay Jaitly",
            "Jon Arrizabalaga",
            "Guanrui Li"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19734",
        "abstract": "Planning collision free trajectories in complex environments remains a core challenge in robotics. Existing corridor based planners which rely on decomposition of the free space into collision free subsets scale poorly with environmental complexity and require explicit allocations of time windows to trajectory segments. We introduce a new trajectory parameterization that represents trajectories in a nonconvex collision free corridor as being in a convex cartesian product of balls. This parameterization allows us to decouple problem size from geometric complexity of the solution and naturally avoids explicit time allocation by allowing trajectories to evolve continuously inside ellipsoidal corridors. Building on this representation, we formulate the Orthogonal Trust Region Problem (Orth-TRP), a specialized convex program with separable block constraints, and develop a solver that exploits this parallel structure and the unique structure of each parallel subproblem for efficient optimization. Experiments on a quadrotor trajectory planning benchmark show that our approach produces smoother trajectories and lower runtimes than state-of-the-art corridor based planners, especially in highly complicated environments.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "90",
        "title": "UserRL: Training Interactive User-Centric Agent via Reinforcement Learning",
        "author": [
            "Cheng Qian",
            "Zuxin Liu",
            "Akshara Prabhakar",
            "Jielin Qiu",
            "Zhiwei Liu",
            "Haolin Chen",
            "Shirley Kokane",
            "Heng Ji",
            "Weiran Yao",
            "Shelby Heinecke",
            "Silvio Savarese",
            "Caiming Xiong",
            "Huan Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19736",
        "abstract": "Reinforcement learning (RL) has shown promise in training agentic models that move beyond static benchmarks to engage in dynamic, multi-turn interactions. Yet, the ultimate value of such agents lies in their ability to assist users, a setting where diversity and dynamics of user interaction pose challenges. In this work, we propose UserRL, a unified framework for training and evaluating user-centric abilities through standardized gym environments paired with simulated users. We systematically vary turn-level reward assignment and trajectory-level score calculation to analyze how different formulations affect learning under the GRPO algorithm. Our experiments across Qwen3 models reveal three key findings: (i) SFT cold start is critical for unlocking initial interaction ability and enabling sustained RL improvements; (ii) deliberate trajectory scoring yields more efficient and effective multi-turn interactions; and (iii) while stronger simulated users (e.g., GPT-4o) facilitates training, open-source simulators (e.g., Qwen3-32B) remain a cost-effective and transferable option. Together, these results highlight that careful design of reward shaping and user simulation choice is as crucial as model scale, and establish UserRL as a practical pathway for developing robust user-centric agentic models. All codes and data are public for future research.",
        "tags": [
            "GPT",
            "GRPO",
            "RL"
        ]
    },
    {
        "id": "91",
        "title": "HiCoLoRA: Addressing Context-Prompt Misalignment via Hierarchical Collaborative LoRA for Zero-Shot DST",
        "author": [
            "Shuyu Zhang",
            "Yifan Wei",
            "Xinru Wang",
            "Yanmin Zhu",
            "Yangfan He",
            "Yixuan Weng",
            "Bin Li"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19742",
        "abstract": "Zero-shot Dialog State Tracking (zs-DST) is essential for enabling Task-Oriented Dialog Systems (TODs) to generalize to new domains without costly data annotation. A central challenge lies in the semantic misalignment between dynamic dialog contexts and static prompts, leading to inflexible cross-layer coordination, domain interference, and catastrophic forgetting. To tackle this, we propose Hierarchical Collaborative Low-Rank Adaptation (HiCoLoRA), a framework that enhances zero-shot slot inference through robust prompt alignment. It features a hierarchical LoRA architecture for dynamic layer-specific processing (combining lower-layer heuristic grouping and higher-layer full interaction), integrates Spectral Joint Domain-Slot Clustering to identify transferable associations (feeding an Adaptive Linear Fusion Mechanism), and employs Semantic-Enhanced SVD Initialization (SemSVD-Init) to preserve pre-trained knowledge. Experiments on multi-domain datasets MultiWOZ and SGD show that HiCoLoRA outperforms baselines, achieving SOTA in zs-DST. Code is available at https://github.com/carsonz/HiCoLoRA.",
        "tags": [
            "LoRA"
        ]
    },
    {
        "id": "92",
        "title": "PART: Progressive Alignment Representation Training for Multilingual Speech-To-Text with LLMs",
        "author": [
            "Pei Zhang",
            "Andong Chen",
            "Xi Chen",
            "Baosong Yang",
            "Derek F. Wong",
            "Fei Huang"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19745",
        "abstract": "Large language models (LLMs) have expanded from text to speech, giving rise to Speech Large Models (SLMs) that support recognition, translation, and synthesis. A key challenge is aligning speech and text representations, which becomes harder in multilingual settings. Existing methods often freeze LLM parameters and train encoders on multilingual data, but this forces cross-language convergence and limits performance. We introduce Progressive Alignment Representation Training (PART), a multi-stage and multi-task framework that separates within-language from cross-language alignment. During cross-language training, LLM parameters are dynamically activated, and text-based tasks are later introduced to enhance multilingual understanding. Experiments on CommonVoice 15, Fleurs, Wenetspeech, and CoVoST2 show that PART surpasses conventional approaches, with analysis confirming its ability to balance language-specific distinctions and cross-language generalization. These results demonstrate PART's effectiveness and generality for multilingual speech modality alignment.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "93",
        "title": "Talking Head Generation via AU-Guided Landmark Prediction",
        "author": [
            "Shao-Yu Chang",
            "Jingyi Xu",
            "Hieu Le",
            "Dimitris Samaras"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19749",
        "abstract": "We propose a two-stage framework for audio-driven talking head generation with fine-grained expression control via facial Action Units (AUs). Unlike prior methods relying on emotion labels or implicit AU conditioning, our model explicitly maps AUs to 2D facial landmarks, enabling physically grounded, per-frame expression control. In the first stage, a variational motion generator predicts temporally coherent landmark sequences from audio and AU intensities. In the second stage, a diffusion-based synthesizer generates realistic, lip-synced videos conditioned on these landmarks and a reference image. This separation of motion and appearance improves expression accuracy, temporal stability, and visual realism. Experiments on the MEAD dataset show that our method outperforms state-of-the-art baselines across multiple metrics, demonstrating the effectiveness of explicit AU-to-landmark modeling for expressive talking head generation.",
        "tags": [
            "Diffusion",
            "Talking Head"
        ]
    },
    {
        "id": "94",
        "title": "Cuffless Blood Pressure Prediction from Speech Sentences using Deep Learning Methods",
        "author": [
            "Kainat"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19750",
        "abstract": "This research presents a novel method for noninvasive arterial blood pressure ABP prediction using speech signals employing a BERT based regression model Arterial blood pressure is a vital indicator of cardiovascular health and accurate monitoring is essential in preventing hypertension related complications Traditional cuff based methods often yield inconsistent results due to factors like whitecoat and masked hypertension Our approach leverages the acoustic characteristics of speech capturing voice features to establish correlations with blood pressure levels Utilizing advanced deep learning techniques we analyze speech signals to extract relevant patterns enabling real time monitoring without the discomfort of conventional methods In our study we employed a dataset comprising recordings from 95 participants ensuring diverse representation The BERT model was fine tuned on extracted features from speech leading to impressive performance metrics achieving a mean absolute error MAE of 136 mmHg for systolic blood pressure SBP and 124 mmHg for diastolic blood pressure DBP with R scores of 099 and 094 respectively These results indicate the models robustness in accurately predicting blood pressure levels Furthermore the training and validation loss analysis demonstrates effective learning and minimal overfitting Our findings suggest that integrating deep learning with speech analysis presents a viable alternative for blood pressure monitoring paving the way for improved applications in telemedicine and remote health monitoring By providing a user friendly and accurate method for blood pressure assessment this research has significant implications for enhancing patient care and proactive management of cardiovascular health",
        "tags": [
            "BERT"
        ]
    },
    {
        "id": "95",
        "title": "Beyond Human Demonstrations: Diffusion-Based Reinforcement Learning to Generate Data for VLA Training",
        "author": [
            "Rushuai Yang",
            "Hangxing Wei",
            "Ran Zhang",
            "Zhiyuan Feng",
            "Xiaoyu Chen",
            "Tong Li",
            "Chuheng Zhang",
            "Li Zhao",
            "Jiang Bian",
            "Xiu Su",
            "Yi Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19752",
        "abstract": "Vision-language-action (VLA) models have shown strong generalization across tasks and embodiments; however, their reliance on large-scale human demonstrations limits their scalability owing to the cost and effort of manual data collection. Reinforcement learning (RL) offers a potential alternative to generate demonstrations autonomously, yet conventional RL algorithms often struggle on long-horizon manipulation tasks with sparse rewards. In this paper, we propose a modified diffusion policy optimization algorithm to generate high-quality and low-variance trajectories, which contributes to a diffusion RL-powered VLA training pipeline. Our algorithm benefits from not only the high expressiveness of diffusion models to explore complex and diverse behaviors but also the implicit regularization of the iterative denoising process to yield smooth and consistent demonstrations. We evaluate our approach on the LIBERO benchmark, which includes 130 long-horizon manipulation tasks, and show that the generated trajectories are smoother and more consistent than both human demonstrations and those from standard Gaussian RL policies. Further, training a VLA model exclusively on the diffusion RL-generated data achieves an average success rate of 81.9%, which outperforms the model trained on human data by +5.3% and that on Gaussian RL-generated data by +12.6%. The results highlight our diffusion RL as an effective alternative for generating abundant, high-quality, and low-variance demonstrations for VLA models.",
        "tags": [
            "Diffusion",
            "RL"
        ]
    },
    {
        "id": "96",
        "title": "Can Audio Large Language Models Verify Speaker Identity?",
        "author": [
            "Yiming Ren",
            "Xuenan Xu",
            "Baoxiang Li",
            "Shuai Wang",
            "Chao Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19755",
        "abstract": "This paper investigates adapting Audio Large Language Models (ALLMs) for speaker verification (SV). We reformulate SV as an audio question-answering task and conduct comprehensive zero-shot evaluations on public benchmarks, showing that current ALLMs have limited zero-shot SV capability and often struggle in diverse acoustic conditions. To address this challenge, we perform supervised fine-tuning on speaker verification data. A rule-based hard pair sampling strategy is proposed to construct more challenging training pairs. Lightweight fine-tuning substantially improves the performance, though there is still a gap between ALLMs and conventional models. Then, we extend to text-dependent SV by jointly querying ALLMs to verify speaker identity and spoken content, yielding results competitive with cascaded ASR-SV systems. Our findings demonstrate that with proper adaptation, ALLMs hold substantial potential as a unified model for robust speaker verification systems, while maintaining the general audio understanding capabilities.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "97",
        "title": "Logics-Parsing Technical Report",
        "author": [
            "Xiangyang Chen",
            "Shuzhao Li",
            "Xiuwen Zhu",
            "Yongfan Chen",
            "Fan Yang",
            "Cheng Fang",
            "Lin Qu",
            "Xiaoxiao Xu",
            "Hu Wei",
            "Minggang Wu"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19760",
        "abstract": "Recent advances in Large Vision-Language models (LVLM) have spurred significant progress in document parsing task. Compared to traditional pipeline-based methods, end-to-end paradigms have shown their excellence in converting PDF images into structured outputs through integrated Optical Character Recognition (OCR), table recognition, mathematical formula recognition and so on. However, the absence of explicit analytical stages for document layouts and reading orders limits the LVLM's capability in handling complex document types such as multi-column newspapers or posters. To address this limitation, we propose in this report Logics-Parsing: an end-to-end LVLM-based model augmented with reinforcement learning. Our model incorporates meticulously designed reward mechanisms to optimize complex layout analysis and reading order inference. In addition, we expand the model's versatility by incorporating diverse data types such as chemical formulas and handwritten Chinese characters into supervised fine-tuning. Finally, to enable rigorous evaluation of our approach, we introduce LogicsParsingBench, a curated set of 1,078 page-level PDF images spanning nine major categories and over twenty sub-categories, which will be released later. Comprehensive experiments conducted on LogicsParsingBench have validated the efficacy and State-of-the-art (SOTA) performance of our proposed model across diverse document analysis scenarios. Project Page: https://github.com/alibaba/Logics-Parsing",
        "tags": [
            "RL",
            "VLM"
        ]
    },
    {
        "id": "98",
        "title": "The Conductor and the Engine: A Path Towards Co-Designed Reasoning",
        "author": [
            "Yuanxin Wang",
            "Pawel Filipczuk",
            "Anisha Garg",
            "Amaan Dhada",
            "Mohammad Hassanpour",
            "David Bick",
            "Ganesh Venkatesh"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19762",
        "abstract": "Modern LLM reasoning relies on extensive test-time computation, driven by internal model training and external agentic orchestration. However, this synergy is often inefficient, as model verbosity and poor instruction following lead to wasted compute. We analyze this capability-cost trade-off and introduce an optimized reasoning workflow (\\cepo) that empowers smaller open-source models to outperform models multiple times their size. We will open-source this workflow to enable further research. Our work demonstrates a clear path toward co-designing orchestration frameworks with the underlying model capabilities to unlock powerful reasoning in small-to-medium sized models.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "99",
        "title": "FusedANN: Convexified Hybrid ANN via Attribute-Vector Fusion",
        "author": [
            "Alireza Heidari",
            "Wei Zhang",
            "Ying Xiong"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19767",
        "abstract": "Vector search powers transformers technology, but real-world use demands hybrid queries that combine vector similarity with attribute filters (e.g., \"top document in category X, from 2023\"). Current solutions trade off recall, speed, and flexibility, relying on fragile index hacks that don't scale. We introduce FusedANN (Fused Attribute-Vector Nearest Neighbor), a geometric framework that elevates filtering to ANN optimization constraints and introduces a convex fused space via a Lagrangian-like relaxation. Our method jointly embeds attributes and vectors through transformer-based convexification, turning hard filters into continuous, weighted penalties that preserve top-k semantics while enabling efficient approximate search. We prove that FusedANN reduces to exact filtering under high selectivity, gracefully relaxes to semantically nearest attributes when exact matches are insufficient, and preserves downstream ANN alpha-approximation guarantees. Empirically, FusedANN improves query throughput by eliminating brittle filtering stages, achieving superior recall-latency tradeoffs on standard hybrid benchmarks without specialized index hacks, delivering up to 3 times higher throughput and better recall than state-of-the-art hybrid and graph-based systems. Theoretically, we provide explicit error bounds and parameter selection rules that make FusedANN practical for production. This establishes a principled, scalable, and verifiable bridge between symbolic constraints and vector similarity, unlocking a new generation of filtered retrieval systems for large, hybrid, and dynamic NLP/ML workloads.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "100",
        "title": "CHURRO: Making History Readable with an Open-Weight Large Vision-Language Model for High-Accuracy, Low-Cost Historical Text Recognition",
        "author": [
            "Sina J. Semnani",
            "Han Zhang",
            "Xinyan He",
            "Merve TekgÃ¼rler",
            "Monica S. Lam"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19768",
        "abstract": "Accurate text recognition for historical documents can greatly advance the study and preservation of cultural heritage. Existing vision-language models (VLMs), however, are designed for modern, standardized texts and are not equipped to read the diverse languages and scripts, irregular layouts, and frequent degradation found in historical materials.\nThis paper presents CHURRO, a 3B-parameter open-weight VLM specialized for historical text recognition. The model is trained on CHURRO-DS, the largest historical text recognition dataset to date. CHURRO-DS unifies 155 historical corpora comprising 99,491 pages, spanning 22 centuries of textual heritage across 46 language clusters, including historical variants and dead languages.\nWe evaluate several open-weight and closed VLMs and optical character recognition (OCR) systems on CHURRO-DS and find that CHURRO outperforms all other VLMs. On the CHURRO-DS test set, CHURRO achieves 82.3% (printed) and 70.1% (handwritten) normalized Levenshtein similarity, surpassing the second-best model, Gemini 2.5 Pro, by 1.4% and 6.5%, respectively, while being 15.5 times more cost-effective.\nBy releasing the model and dataset, we aim to enable community-driven research to improve the readability of historical texts and accelerate scholarship.",
        "tags": [
            "VLM"
        ]
    },
    {
        "id": "101",
        "title": "EnAnchored-X2X: English-Anchored Optimization for Many-to-Many Translation",
        "author": [
            "Sen Yang",
            "Yu Bao",
            "Yu Lu",
            "Jiajun Chen",
            "Shujian Huang",
            "Shanbo Cheng"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19770",
        "abstract": "Large language models (LLMs) have demonstrated strong machine translation capabilities for English-centric language pairs but underperform in direct non-English (x2x) translation. This work addresses this limitation through a synthetic data generation framework that leverages models' established English-to-x (en2x) capabilities. By extending English parallel corpora into omnidirectional datasets and developing an English-referenced quality evaluation proxy, we enable effective collection of high-quality x2x training data. Combined with preference-based optimization, our method achieves significant improvement across 72 x2x directions for widely used LLMs, while generalizing to enhance en2x performance. The results demonstrate that strategic exploitation of English-centric strengths can bootstrap comprehensive multilingual translation capabilities in LLMs. We release codes, datasets, and model checkpoints at https://github.com/NJUNLP/EAX",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "102",
        "title": "Frictional Q-Learning",
        "author": [
            "Hyunwoo Kim",
            "Hyo Kyung Lee"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19771",
        "abstract": "We draw an analogy between static friction in classical mechanics and extrapolation error in off-policy RL, and use it to formulate a constraint that prevents the policy from drifting toward unsupported actions. In this study, we present Frictional Q-learning, a deep reinforcement learning algorithm for continuous control, which extends batch-constrained reinforcement learning. Our algorithm constrains the agent's action space to encourage behavior similar to that in the replay buffer, while maintaining a distance from the manifold of the orthonormal action space. The constraint preserves the simplicity of batch-constrained, and provides an intuitive physical interpretation of extrapolation error. Empirically, we further demonstrate that our algorithm is robustly trained and achieves competitive performance across standard continuous control benchmarks.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "103",
        "title": "EfficienT-HDR: An Efficient Transformer-Based Framework via Multi-Exposure Fusion for HDR Reconstruction",
        "author": [
            "Yu-Shen Huang",
            "Tzu-Han Chen",
            "Cheng-Yen Hsiao",
            "Shaou-Gang Miaou"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19779",
        "abstract": "Achieving high-quality High Dynamic Range (HDR) imaging on resource-constrained edge devices is a critical challenge in computer vision, as its performance directly impacts downstream tasks such as intelligent surveillance and autonomous driving. Multi-Exposure Fusion (MEF) is a mainstream technique to achieve this goal; however, existing methods generally face the dual bottlenecks of high computational costs and ghosting artifacts, hindering their widespread deployment. To this end, this study proposes a light-weight Vision Transformer architecture designed explicitly for HDR reconstruction to overcome these limitations. This study is based on the Context-Aware Vision Transformer and begins by converting input images to the YCbCr color space to separate luminance and chrominance information. It then employs an Intersection-Aware Adaptive Fusion (IAAF) module to suppress ghosting effectively. To further achieve a light-weight design, we introduce Inverted Residual Embedding (IRE), Dynamic Tanh (DyT), and propose Enhanced Multi-Scale Dilated Convolution (E-MSDC) to reduce computational complexity at multiple levels. Our study ultimately contributes two model versions: a main version for high visual quality and a light-weight version with advantages in computational efficiency, both of which achieve an excellent balance between performance and image quality. Experimental results demonstrate that, compared to the baseline, the main version reduces FLOPS by approximately 67% and increases inference speed by more than fivefold on CPU and 2.5 times on an edge device. These results confirm that our method provides an efficient and ghost-free HDR imaging solution for edge devices, demonstrating versatility and practicality across various dynamic scenarios.",
        "tags": [
            "Transformer",
            "ViT"
        ]
    },
    {
        "id": "104",
        "title": "Faster, Smaller, and Smarter: Task-Aware Expert Merging for Online MoE Inference",
        "author": [
            "Ziyi Han",
            "Xutong Liu",
            "Ruiting Zhou",
            "Xiangxiang Dai",
            "John C.S. Lui"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19781",
        "abstract": "Sparse Mixture of Experts (SMoE) has become a preferred architecture for scaling Transformer capacity without increasing computational cost, as it activates only a small subset of experts for each input. However, deploying such an approach for \\textit{online inference} remains challenging due to the large size of a full SMoE model and the complexity of expert routing, especially in resource-constrained edge networks. Moreover, during the online inference, task information is often unavailable, making the task-level routing error-prone. In this work, we propose a novel tree-structured adaptive neural bandit router, \\texttt{Tanbr}, to enable efficient and reliable online MoE inference. Instead of relying on explicit task tags, \\texttt{Tanbr} estimates the task distribution over time from historical data and uses it to guide task-aware expert merging within a given pre-trained MoE. To handle the large continuous space of merging weights, \\texttt{Tanbr} employs a binary tree to progressively partition the space and generate finer candidate weights. It then applies a neural bandit to learn the non-linear mapping from merging weight to model performance and decides optimal expert merging. We prove that \\texttt{Tanbr} achieves a sublinear regret bound of {\\small $\\mathcal{O}(\\sqrt{T} \\log(T))$} over {\\small $T$} rounds, despite operating over a continuous decision space, matching regret bounds compared to existing methods. Extensive experiments show that \\texttt{Tanbr} reduces inference latency by at least {\\small $45\\%$} and memory usage by up to {\\small $25\\%$}, while maintaining a high accuracy compared to many state-of-the-art methods.",
        "tags": [
            "MoE",
            "Transformer"
        ]
    },
    {
        "id": "105",
        "title": "BiTAA: A Bi-Task Adversarial Attack for Object Detection and Depth Estimation via 3D Gaussian Splatting",
        "author": [
            "Yixun Zhang",
            "Feng Zhou",
            "Jianqin Yin"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19793",
        "abstract": "Camera-based perception is critical to autonomous driving yet remains vulnerable to task-specific adversarial manipulations in object detection and monocular depth estimation. Most existing 2D/3D attacks are developed in task silos, lack mechanisms to induce controllable depth bias, and offer no standardized protocol to quantify cross-task transfer, leaving the interaction between detection and depth underexplored. We present BiTAA, a bi-task adversarial attack built on 3D Gaussian Splatting that yields a single perturbation capable of simultaneously degrading detection and biasing monocular depth. Specifically, we introduce a dual-model attack framework that supports both full-image and patch settings and is compatible with common detectors and depth estimators, with optional expectation-over-transformation (EOT) for physical reality. In addition, we design a composite loss that couples detection suppression with a signed, magnitude-controlled log-depth bias within regions of interest (ROIs) enabling controllable near or far misperception while maintaining stable optimization across tasks. We also propose a unified evaluation protocol with cross-task transfer metrics and real-world evaluations, showing consistent cross-task degradation and a clear asymmetry between Det to Depth and from Depth to Det transfer. The results highlight practical risks for multi-task camera-only perception and motivate cross-task-aware defenses in autonomous driving scenarios.",
        "tags": [
            "3D",
            "Depth Estimation",
            "Detection",
            "Gaussian Splatting"
        ]
    },
    {
        "id": "106",
        "title": "Analysis of approximate linear programming solution to Markov decision problem with log barrier function",
        "author": [
            "Donghwan Lee",
            "Hyukjun Yang",
            "Bum Geun Park"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19800",
        "abstract": "There are two primary approaches to solving Markov decision problems (MDPs): dynamic programming based on the Bellman equation and linear programming (LP). Dynamic programming methods are the most widely used and form the foundation of both classical and modern reinforcement learning (RL). By contrast, LP-based methods have been less commonly employed, although they have recently gained attention in contexts such as offline RL. The relative underuse of the LP-based methods stems from the fact that it leads to an inequality-constrained optimization problem, which is generally more challenging to solve effectively compared with Bellman-equation-based methods. The purpose of this paper is to establish a theoretical foundation for solving LP-based MDPs in a more effective and practical manner. Our key idea is to leverage the log-barrier function, widely used in inequality-constrained optimization, to transform the LP formulation of the MDP into an unconstrained optimization problem. This reformulation enables approximate solutions to be obtained easily via gradient descent. While the method may appear simple, to the best of our knowledge, a thorough theoretical interpretation of this approach has not yet been developed. This paper aims to bridge this gap.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "107",
        "title": "VCRL: Variance-based Curriculum Reinforcement Learning for Large Language Models",
        "author": [
            "Guochao Jiang",
            "Wenfeng Feng",
            "Guofeng Quan",
            "Chuzhan Hao",
            "Yuewei Zhang",
            "Guohua Liu",
            "Hao Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19803",
        "abstract": "Policy-based reinforcement learning currently plays an important role in improving LLMs on mathematical reasoning tasks. However, existing rollout-based reinforcement learning methods (GRPO, DAPO, GSPO, etc.) fail to explicitly consider LLMs' learning ability for samples of different difficulty levels, which is contrary to the human cognitive process of mathematical reasoning tasks from easy to difficult. Intuitively, we find that the variance of the rollout group's reward in RLVR partly reflects the difficulty of the current sample for LLMs. Samples that are too easy or too difficult have a lower variance, while samples with moderate difficulty have a higher variance. Based on this, we propose VCRL, a curriculum reinforcement learning framework that dynamically controls the difficulty of training samples based on the variance of group rewards. Experiments on five mathematical benchmarks and two models reveal the advantages of VCRL over the current LLM RL baselines.",
        "tags": [
            "GRPO",
            "LLM",
            "RL"
        ]
    },
    {
        "id": "108",
        "title": "DynaFlow: Dynamics-embedded Flow Matching for Physically Consistent Motion Generation from State-only Demonstrations",
        "author": [
            "Sowoo Lee",
            "Dongyun Kang",
            "Jaehyun Park",
            "Hae-Won Park"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19804",
        "abstract": "This paper introduces DynaFlow, a novel framework that embeds a differentiable simulator directly into a flow matching model. By generating trajectories in the action space and mapping them to dynamically feasible state trajectories via the simulator, DynaFlow ensures all outputs are physically consistent by construction. This end-to-end differentiable architecture enables training on state-only demonstrations, allowing the model to simultaneously generate physically consistent state trajectories while inferring the underlying action sequences required to produce them. We demonstrate the effectiveness of our approach through quantitative evaluations and showcase its real-world applicability by deploying the generated actions onto a physical Go1 quadruped robot. The robot successfully reproduces diverse gait present in the dataset, executes long-horizon motions in open-loop control and translates infeasible kinematic demonstrations into dynamically executable, stylistic behaviors. These hardware experiments validate that DynaFlow produces deployable, highly effective motions on real-world hardware from state-only demonstrations, effectively bridging the gap between kinematic data and real-world execution.",
        "tags": [
            "Flow Matching",
            "Robotics"
        ]
    },
    {
        "id": "109",
        "title": "An Efficient Conditional Score-based Filter for High Dimensional Nonlinear Filtering Problems",
        "author": [
            "Zhijun Zeng",
            "Weiye Gan",
            "Junqing Chen",
            "Zuoqiang Shi"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19816",
        "abstract": "In many engineering and applied science domains, high-dimensional nonlinear filtering is still a challenging problem. Recent advances in score-based diffusion models offer a promising alternative for posterior sampling but require repeated retraining to track evolving priors, which is impractical in high dimensions. In this work, we propose the Conditional Score-based Filter (CSF), a novel algorithm that leverages a set-transformer encoder and a conditional diffusion model to achieve efficient and accurate posterior sampling without retraining. By decoupling prior modeling and posterior sampling into offline and online stages, CSF enables scalable score-based filtering across diverse nonlinear systems. Extensive experiments on benchmark problems show that CSF achieves superior accuracy, robustness, and efficiency across diverse nonlinear filtering scenarios.",
        "tags": [
            "Diffusion",
            "Transformer"
        ]
    },
    {
        "id": "110",
        "title": "On the Rate of Convergence of Kolmogorov-Arnold Network Regression Estimators",
        "author": [
            "Wei Liu",
            "Eleni Chatzi",
            "Zhilu Lai"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19830",
        "abstract": "Kolmogorov-Arnold Networks (KANs) offer a structured and interpretable framework for multivariate function approximation by composing univariate transformations through additive or multiplicative aggregation. This paper establishes theoretical convergence guarantees for KANs when the univariate components are represented by B-splines. We prove that both additive and hybrid additive-multiplicative KANs attain the minimax-optimal convergence rate $O(n^{-2r/(2r+1)})$ for functions in Sobolev spaces of smoothness $r$. We further derive guidelines for selecting the optimal number of knots in the B-splines. The theory is supported by simulation studies that confirm the predicted convergence rates. These results provide a theoretical foundation for using KANs in nonparametric regression and highlight their potential as a structured alternative to existing methods.",
        "tags": [
            "KAN"
        ]
    },
    {
        "id": "111",
        "title": "Polarity Detection of Sustainable Detection Goals in News Text",
        "author": [
            "Andrea Cadeddua",
            "Alessandro Chessa",
            "Vincenzo De Leo",
            "Gianni Fenu",
            "Francesco Osborne",
            "Diego Reforgiato Recupero",
            "Angelo Salatino",
            "Luca Secchi"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19833",
        "abstract": "The United Nations' Sustainable Development Goals (SDGs) provide a globally recognised framework for addressing critical societal, environmental, and economic challenges. Recent developments in natural language processing (NLP) and large language models (LLMs) have facilitated the automatic classification of textual data according to their relevance to specific SDGs. Nevertheless, in many applications, it is equally important to determine the directionality of this relevance; that is, to assess whether the described impact is positive, neutral, or negative. To tackle this challenge, we propose the novel task of SDG polarity detection, which assesses whether a text segment indicates progress toward a specific SDG or conveys an intention to achieve such progress. To support research in this area, we introduce SDG-POD, a benchmark dataset designed specifically for this task, combining original and synthetically generated data. We perform a comprehensive evaluation using six state-of-the-art large LLMs, considering both zero-shot and fine-tuned configurations. Our results suggest that the task remains challenging for the current generation of LLMs. Nevertheless, some fine-tuned models, particularly QWQ-32B, achieve good performance, especially on specific Sustainable Development Goals such as SDG-9 (Industry, Innovation and Infrastructure), SDG-12 (Responsible Consumption and Production), and SDG-15 (Life on Land). Furthermore, we demonstrate that augmenting the fine-tuning dataset with synthetically generated examples yields improved model performance on this task. This result highlights the effectiveness of data enrichment techniques in addressing the challenges of this resource-constrained domain. This work advances the methodological toolkit for sustainability monitoring and provides actionable insights into the development of efficient, high-performing polarity detection systems.",
        "tags": [
            "Detection",
            "LLM"
        ]
    },
    {
        "id": "112",
        "title": "TianHui: A Domain-Specific Large Language Model for Diverse Traditional Chinese Medicine Scenarios",
        "author": [
            "Ji Yin",
            "Menglan He",
            "Yujie Zhang",
            "Linshuai Zhang",
            "Tingting Ma",
            "Ce Tian",
            "Jie Wu",
            "Lin Xu",
            "Tao Jiang"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19834",
        "abstract": "Domain-specific LLMs in TCM face limitations in research settings due to constrained adaptability, insufficient evaluation datasets, and limited computational resources. This study presents TianHui, a specialized TCM LLM built through contextual data integration and domain knowledge fusion. We constructed a large-scale TCM corpus (0.97GB unsupervised data + 611,312 QA pairs) and employed a two-stage training strategy with QLoRA, DeepSpeed Stage 2, and Flash Attention 2. Evaluation on 12 benchmarks showed TianHui ranked top-three in all metrics for six datasets (APQ, TCMCD, HFR, HCCA, DHPE, TLAW) and achieved top results in the other six (TCMEE, APR, GCPMI, TCMKQA, TCMRC, ADTG). Optimal configuration was identified as LoRA rank=128, alpha=256, epoch=4, dropout=0.2, max length=2048. TianHui enables systematic preservation and scalable application of TCM knowledge. All resources are open-sourced.",
        "tags": [
            "Flash Attention",
            "LLM",
            "LoRA"
        ]
    },
    {
        "id": "113",
        "title": "BurstEngine: an Efficient Distributed Framework for Training Transformers on Extremely Long Sequences of over 1M Tokens",
        "author": [
            "Ao Sun",
            "Weilin Zhao",
            "Xu Han",
            "Cheng Yang",
            "Zhiyuan Liu",
            "Chuan Shi",
            "Maosong sun"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19836",
        "abstract": "Existing methods for training LLMs on long-sequence data, such as Tensor Parallelism and Context Parallelism, exhibit low Model FLOPs Utilization as sequence lengths and number of GPUs increase, especially when sequence lengths exceed 1M tokens. To address these challenges, we propose BurstEngine, an efficient framework designed to train LLMs on long-sequence data. BurstEngine introduces BurstAttention, an optimized distributed attention with lower communication cost than RingAttention. BurstAttention leverages topology-aware ring communication to fully utilize network bandwidth and incorporates fine-grained communication-computation overlap. Furthermore, BurstEngine introduces sequence-level selective checkpointing and fuses the language modeling head with the loss function to reduce memory cost. Additionally, BurstEngine introduces workload balance optimization for various types of attention masking. By integrating these optimizations, BurstEngine achieves a $1.2\\times$ speedup with much lower memory overhead than the state-of-the-art baselines when training LLMs on extremely long sequences of over 1M tokens. We have made our code publicly available on GitHub: https://github.com/thunlp/BurstEngine.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "114",
        "title": "LatentGuard: Controllable Latent Steering for Robust Refusal of Attacks and Reliable Response Generation",
        "author": [
            "Huizhen Shu",
            "Xuying Li",
            "Zhuo Li"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19839",
        "abstract": "Achieving robust safety alignment in large language models (LLMs) while preserving their utility remains a fundamental challenge. Existing approaches often struggle to balance comprehensive safety with fine-grained controllability at the representation level. We introduce LATENTGUARD, a novel three-stage framework that combines behavioral alignment with supervised latent space control for interpretable and precise safety steering. Our approach begins by fine-tuning an LLM on rationalized datasets containing both reasoning-enhanced refusal responses to adversarial prompts and reasoning-enhanced normal responses to benign queries, establishing robust behavioral priors across both safety-critical and utility-preserving scenarios. We then train a structured variational autoencoder (VAE) on intermediate MLP activations, supervised by multi-label annotations including attack types, attack methods, and benign indicators. This supervision enables the VAE to learn disentangled latent representations that capture distinct adversarial characteristics while maintaining semantic interpretability. Through targeted manipulation of learned latent dimensions, LATENTGUARD achieves selective refusal behavior, effectively blocking harmful requests while preserving helpfulness for legitimate use cases. Experiments on Qwen3-8B demonstrate significant improvements in both safety controllability and response interpretability without compromising utility. Cross-architecture validation on Mistral-7B confirms the generalizability of our latent steering approach, showing consistent effectiveness across different model families. Our results suggest that structured representation-level intervention offers a promising pathway toward building safer yet practical LLM systems.",
        "tags": [
            "LLM",
            "VAE"
        ]
    },
    {
        "id": "115",
        "title": "ThinkFake: Reasoning in Multimodal Large Language Models for AI-Generated Image Detection",
        "author": [
            "Tai-Ming Huang",
            "Wei-Tung Lin",
            "Kai-Lung Hua",
            "Wen-Huang Cheng",
            "Junichi Yamagishi",
            "Jun-Cheng Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19841",
        "abstract": "The increasing realism of AI-generated images has raised serious concerns about misinformation and privacy violations, highlighting the urgent need for accurate and interpretable detection methods. While existing approaches have made progress, most rely on binary classification without explanations or depend heavily on supervised fine-tuning, resulting in limited generalization. In this paper, we propose ThinkFake, a novel reasoning-based and generalizable framework for AI-generated image detection. Our method leverages a Multimodal Large Language Model (MLLM) equipped with a forgery reasoning prompt and is trained using Group Relative Policy Optimization (GRPO) reinforcement learning with carefully designed reward functions. This design enables the model to perform step-by-step reasoning and produce interpretable, structured outputs. We further introduce a structured detection pipeline to enhance reasoning quality and adaptability. Extensive experiments show that ThinkFake outperforms state-of-the-art methods on the GenImage benchmark and demonstrates strong zero-shot generalization on the challenging LOKI benchmark. These results validate our framework's effectiveness and robustness. Code will be released upon acceptance.",
        "tags": [
            "Detection",
            "GRPO",
            "LLM",
            "RL"
        ]
    },
    {
        "id": "116",
        "title": "PersONAL: Towards a Comprehensive Benchmark for Personalized Embodied Agents",
        "author": [
            "Filippo Ziliotto",
            "Jelin Raphael Akkara",
            "Alessandro Daniele",
            "Lamberto Ballan",
            "Luciano Serafini",
            "Tommaso Campari"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19843",
        "abstract": "Recent advances in Embodied AI have enabled agents to perform increasingly complex tasks and adapt to diverse environments. However, deploying such agents in realistic human-centered scenarios, such as domestic households, remains challenging, particularly due to the difficulty of modeling individual human preferences and behaviors. In this work, we introduce PersONAL (PERSonalized Object Navigation And Localization, a comprehensive benchmark designed to study personalization in Embodied AI. Agents must identify, retrieve, and navigate to objects associated with specific users, responding to natural-language queries such as \"find Lily's backpack\". PersONAL comprises over 2,000 high-quality episodes across 30+ photorealistic homes from the HM3D dataset. Each episode includes a natural-language scene description with explicit associations between objects and their owners, requiring agents to reason over user-specific semantics. The benchmark supports two evaluation modes: (1) active navigation in unseen environments, and (2) object grounding in previously mapped scenes. Experiments with state-of-the-art baselines reveal a substantial gap to human performance, highlighting the need for embodied agents capable of perceiving, reasoning, and memorizing over personalized information; paving the way towards real-world assistive robot.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "117",
        "title": "BoreaRL: A Multi-Objective Reinforcement Learning Environment for Climate-Adaptive Boreal Forest Management",
        "author": [
            "Kevin Bradley Dsouza",
            "Enoch Ofosu",
            "Daniel Chukwuemeka Amaogu",
            "JÃ©rÃ´me Pigeon",
            "Richard Boudreault",
            "Pooneh Maghoul",
            "Juan Moreno-Cruz",
            "Yuri Leonenko"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19846",
        "abstract": "Boreal forests store 30-40% of terrestrial carbon, much in climate-vulnerable permafrost soils, making their management critical for climate mitigation. However, optimizing forest management for both carbon sequestration and permafrost preservation presents complex trade-offs that current tools cannot adequately address. We introduce $\\textbf{BoreaRL}$, the first multi-objective reinforcement learning environment for climate-adaptive boreal forest management, featuring a physically-grounded simulator of coupled energy, carbon, and water fluxes. BoreaRL supports two training paradigms: site-specific mode for controlled studies and generalist mode for learning robust policies under environmental stochasticity. Through evaluation of multi-objective RL algorithms, we reveal a fundamental asymmetry in learning difficulty: carbon objectives are significantly easier to optimize than thaw (permafrost preservation) objectives, with thaw-focused policies showing minimal learning progress across both paradigms. In generalist settings, standard preference-conditioned approaches fail entirely, while a naive curriculum learning approach achieves superior performance by strategically selecting training episodes. Analysis of learned strategies reveals distinct management philosophies, where carbon-focused policies favor aggressive high-density coniferous stands, while effective multi-objective policies balance species composition and density to protect permafrost while maintaining carbon gains. Our results demonstrate that robust climate-adaptive forest management remains challenging for current MORL methods, establishing BoreaRL as a valuable benchmark for developing more effective approaches. We open-source BoreaRL to accelerate research in multi-objective RL for climate applications.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "118",
        "title": "Analyzing Generalization in Pre-Trained Symbolic Regression",
        "author": [
            "Henrik Voigt",
            "Paul Kahlmeyer",
            "Kai Lawonn",
            "Michael Habeck",
            "Joachim Giesen"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19849",
        "abstract": "Symbolic regression algorithms search a space of mathematical expressions for formulas that explain given data. Transformer-based models have emerged as a promising, scalable approach shifting the expensive combinatorial search to a large-scale pre-training phase. However, the success of these models is critically dependent on their pre-training data. Their ability to generalize to problems outside of this pre-training distribution remains largely unexplored. In this work, we conduct a systematic empirical study to evaluate the generalization capabilities of pre-trained, transformer-based symbolic regression. We rigorously test performance both within the pre-training distribution and on a series of out-of-distribution challenges for several state of the art approaches. Our findings reveal a significant dichotomy: while pre-trained models perform well in-distribution, the performance consistently degrades in out-of-distribution scenarios. We conclude that this generalization gap is a critical barrier for practitioners, as it severely limits the practical use of pre-trained approaches for real-world applications.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "119",
        "title": "Where Did I Leave My Glasses? Open-Vocabulary Semantic Exploration in Real-World Semi-Static Environments",
        "author": [
            "Benjamin Bogenberger",
            "Oliver Harrison",
            "Orrin Dahanaggamaarachchi",
            "Lukas Brunke",
            "Jingxing Qian",
            "Siqi Zhou",
            "Angela P. Schoellig"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19851",
        "abstract": "Robots deployed in real-world environments, such as homes, must not only navigate safely but also understand their surroundings and adapt to environment changes. To perform tasks efficiently, they must build and maintain a semantic map that accurately reflects the current state of the environment. Existing research on semantic exploration largely focuses on static scenes without persistent object-level instance tracking. A consistent map is, however, crucial for real-world robotic applications where objects in the environment can be removed, reintroduced, or shifted over time. In this work, to close this gap, we propose an open-vocabulary, semantic exploration system for semi-static environments. Our system maintains a consistent map by building a probabilistic model of object instance stationarity, systematically tracking semi-static changes, and actively exploring areas that have not been visited for a prolonged period of time. In addition to active map maintenance, our approach leverages the map's semantic richness with LLM-based reasoning for open-vocabulary object-goal navigation. This enables the robot to search more efficiently by prioritizing contextually relevant areas. We evaluate our approach across multiple real-world semi-static environments. Our system detects 95% of map changes on average, improving efficiency by more than 29% as compared to random and patrol baselines. Overall, our approach achieves a mapping precision within 2% of a fully rebuilt map while requiring substantially less exploration and further completes object goal navigation tasks about 14% faster than the next-best tested strategy (coverage patrolling). A video of our work can be found at http://tiny.cc/sem-explor-semi-static .",
        "tags": [
            "LLM",
            "Robotics"
        ]
    },
    {
        "id": "120",
        "title": "Eliminating stability hallucinations in llm-based tts models via attention guidance",
        "author": [
            "ShiMing Wang",
            "ZhiHao Du",
            "Yang Xiang",
            "TianYu Zhao",
            "Han Zhao",
            "Qian Chen",
            "XianGang Li",
            "HanJie Guo",
            "ZhenHua Ling"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19852",
        "abstract": "This paper focuses on resolving stability hallucinations (e.g., repetitive or omitted speech) in LLM-based Text-to-Speech (TTS) models by improving and leveraging the attention mechanism. First, we analyzed the alignment mechanism between text tokens and speech tokens in LLMs. We then proposed a metric termed the Optimal Alignment Score (OAS), which employs the Viterbi algorithm to evaluate text-speech alignment quality. Subsequently, OAS was integrated into the training of CosyVoice2 to assist LLMs in learning continuous, stable alignment. Additionally, the pre-trained attention value is employed to guide the training of the student CosyVoice2 via chain-of-thought (CoT), which further reduces stability hallucinations in synthesized speech. Experiments on the Seed-TTS-Eval and CV3-Eval test sets demonstrate that the proposed methods can effectively reduce the stability hallucinations of CosyVoice2 without introducing additional negative effects. The appendix is available at https://wsmzzz.github.io/llm_attn.",
        "tags": [
            "CoT",
            "LLM"
        ]
    },
    {
        "id": "121",
        "title": "SAGE:State-Aware Guided End-to-End Policy for Multi-Stage Sequential Tasks via Hidden Markov Decision Process",
        "author": [
            "BinXu Wu",
            "TengFei Zhang",
            "Chen Yang",
            "JiaHao Wen",
            "HaoCheng Li",
            "JingTian Ma",
            "Zhen Chen",
            "JingYuan Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19853",
        "abstract": "Multi-stage sequential (MSS) robotic manipulation tasks are prevalent and crucial in robotics. They often involve state ambiguity, where visually similar observations correspond to different actions. We present SAGE, a state-aware guided imitation learning framework that models tasks as a Hidden Markov Decision Process (HMDP) to explicitly capture latent task stages and resolve ambiguity. We instantiate the HMDP with a state transition network that infers hidden states, and a state-aware action policy that conditions on both observations and hidden states to produce actions, thereby enabling disambiguation across task stages. To reduce manual annotation effort, we propose a semi-automatic labeling pipeline combining active learning and soft label interpolation. In real-world experiments across multiple complex MSS tasks with state ambiguity, SAGE achieved 100% task success under the standard evaluation protocol, markedly surpassing the baselines. Ablation studies further show that such performance can be maintained with manual labeling for only about 13% of the states, indicating its strong effectiveness.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "122",
        "title": "L-Mosaics and Bounded Join-Semilattices in Isabelle/HOL",
        "author": [
            "Alessandro Linzi"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19854",
        "abstract": "We present a complete formalization in Isabelle/HOL of the object part of an equivalence between L-mosaics and bounded join-semilattices, employing an AI-assisted methodology that integrates large language models as reasoning assistants throughout the proof development process. The equivalence was originally established by Cangiotti, Linzi, and Talotti in their study of hypercompositional structures related to orthomodular lattices and quantum logic. Our formalization rigorously verifies the main theoretical result and demonstrates the mutual inverse property of the transformations establishing this equivalence. The development showcases both the mathematical depth of multivalued algebraic operations and the potential for AI-enhanced interactive theorem proving in tackling complex formalization projects.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "123",
        "title": "CollaPipe: Adaptive Segment-Optimized Pipeline Parallelism for Collaborative LLM Training in Heterogeneous Edge Networks",
        "author": [
            "Jiewei Chen",
            "Xiumei Deng",
            "Zehui Xiong",
            "Shaoyong Guo",
            "Xuesong Qiu",
            "Ping Wang",
            "Dusit Niyato"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19855",
        "abstract": "The increasing demand for intelligent mobile applications has made multi-agent collaboration with Transformer-based large language models (LLMs) essential in mobile edge computing (MEC) networks. However, training LLMs in such environments remains challenging due to heavy computation, high end-to-end latency, and limited model generalization. We introduce CollaPipe, a hybrid distributed learning framework that integrates collaborative pipeline parallelism with federated aggregation to support self-evolving intelligent networks. In CollaPipe, the encoder part is adaptively partitioned into variable-sized segments and deployed across mobile devices for pipeline-parallel training, while the decoder is deployed on edge servers to handle generative tasks. Then we perform global model update via federated aggregation. To enhance training efficiency, we formulate a joint optimization problem that adaptively allocates model segments, micro-batches, bandwidth, and transmission power. We derive and use a closed-form convergence bound to design an Dynamic Segment Scheduling and Resource Allocation (DSSDA) algorithm based on Lyapunov optimization, ensuring system stability under long-term constraints. Extensive experiments on downstream tasks with Transformer and BERT models show that CollaPipe improves computation efficiency by up to 15.09%, reduces end-to-end latency by at least 48.98%, and cuts single device memory usage by more than half, enabling online learning in heterogeneous and dynamic communication environments.",
        "tags": [
            "BERT",
            "LLM",
            "Transformer"
        ]
    },
    {
        "id": "124",
        "title": "Oversampling and Downsampling with Core-Boundary Awareness: A Data Quality-Driven Approach",
        "author": [
            "Samir Brahim Belhaouari",
            "Yunis Carreon Kahalan",
            "Humaira Shaffique",
            "Ismael Belhaouari",
            "Ashhadul Islam"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19856",
        "abstract": "The effectiveness of machine learning models, particularly in unbalanced classification tasks, is often hindered by the failure to differentiate between critical instances near the decision boundary and redundant samples concentrated in the core of the data distribution. In this paper, we propose a method to systematically identify and differentiate between these two types of data. Through extensive experiments on multiple benchmark datasets, we show that the boundary data oversampling method improves the F1 score by up to 10\\% on 96\\% of the datasets, whereas our core-aware reduction method compresses datasets up to 90\\% while preserving their accuracy, making it 10 times more powerful than the original dataset. Beyond imbalanced classification, our method has broader implications for efficient model training, particularly in computationally expensive domains such as Large Language Model (LLM) training. By prioritizing high-quality, decision-relevant data, our approach can be extended to text, multimodal, and self-supervised learning scenarios, offering a pathway to faster convergence, improved generalization, and significant computational savings. This work paves the way for future research in data-efficient learning, where intelligent sampling replaces brute-force expansion, driving the next generation of AI advancements. Our code is available as a Python package at https://pypi.org/project/adaptive-resampling/ .",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "125",
        "title": "SpecMamba: Accelerating Mamba Inference on FPGA with Speculative Decoding",
        "author": [
            "Linfeng Zhong",
            "Songqiang Xu",
            "Huifeng Wen",
            "Tong Xie",
            "Qingyu Guo",
            "Yuan Wang",
            "Meng Li"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19873",
        "abstract": "The growing demand for efficient long-sequence modeling on edge devices has propelled widespread adoption of State Space Models (SSMs) like Mamba, due to their superior computational efficiency and scalability. As its autoregressive generation process remains memory-bound, speculative decoding has been proposed that incorporates draft model generation and target model verification. However, directly applying speculative decoding to SSMs faces three key challenges: (1) hidden state backtracking difficulties, (2) tree-based parallel verification incompatibility, and (3) hardware workload mismatch. To address these challenges, we propose SpecMamba, the first FPGA-based accelerator for Mamba with speculative decoding, which features system, algorithm, and hardware co-design. At the system level, we present a memory-aware hybrid backtracking strategy to coordinate both models. At the algorithm level, we propose first-in-first-out (FIFO)-based tree verification with tiling to minimize memory access. At the hardware level, we customize a dataflow that computes linear layers in parallel and SSM layers in series to enable maximal overlapping. Implemented on AMD FPGA platforms (VHK158 and VCK190), SpecMamba achieves a 2.27x speedup over GPU baselines and a 2.85x improvement compared to prior FPGA solutions, while demonstrating 5.41x and 1.26x higher energy efficiency, respectively.",
        "tags": [
            "Mamba",
            "SSMs"
        ]
    },
    {
        "id": "126",
        "title": "Adaptive Guidance Semantically Enhanced via Multimodal LLM for Edge-Cloud Object Detection",
        "author": [
            "Yunqing Hu",
            "Zheming Yang",
            "Chang Zhao",
            "Wen Ji"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19875",
        "abstract": "Traditional object detection methods face performance degradation challenges in complex scenarios such as low-light conditions and heavy occlusions due to a lack of high-level semantic understanding. To address this, this paper proposes an adaptive guidance-based semantic enhancement edge-cloud collaborative object detection method leveraging Multimodal Large Language Models (MLLM), achieving an effective balance between accuracy and efficiency. Specifically, the method first employs instruction fine-tuning to enable the MLLM to generate structured scene descriptions. It then designs an adaptive mapping mechanism that dynamically converts semantic information into parameter adjustment signals for edge detectors, achieving real-time semantic enhancement. Within an edge-cloud collaborative inference framework, the system automatically selects between invoking cloud-based semantic guidance or directly outputting edge detection results based on confidence scores. Experiments demonstrate that the proposed method effectively enhances detection accuracy and efficiency in complex scenes. Specifically, it can reduce latency by over 79% and computational cost by 70% in low-light and highly occluded scenes while maintaining accuracy.",
        "tags": [
            "Detection",
            "LLM"
        ]
    },
    {
        "id": "127",
        "title": "Adaptive User Interest Modeling via Conditioned Denoising Diffusion For Click-Through Rate Prediction",
        "author": [
            "Qihang Zhao",
            "Xiaoyang Zheng",
            "Ben Chen",
            "Zhongbo Sun",
            "Chenyi Lei"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19876",
        "abstract": "User behavior sequences in search systems resemble \"interest fossils\", capturing genuine intent yet eroded by exposure bias, category drift, and contextual noise. Current methods predominantly follow an \"identify-aggregate\" paradigm, assuming sequences immutably reflect user preferences while overlooking the organic entanglement of noise and genuine interest. Moreover, they output static, context-agnostic representations, failing to adapt to dynamic intent shifts under varying Query-User-Item-Context conditions.\nTo resolve this dual challenge, we propose the Contextual Diffusion Purifier (CDP). By treating category-filtered behaviors as \"contaminated observations\", CDP employs a forward noising and conditional reverse denoising process guided by cross-interaction features (Query x User x Item x Context), controllably generating pure, context-aware interest representations that dynamically evolve with scenarios. Extensive offline/online experiments demonstrate the superiority of CDP over state-of-the-art methods.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "128",
        "title": "Advancing Universal Deep Learning for Electronic-Structure Hamiltonian Prediction of Materials",
        "author": [
            "Shi Yin",
            "Zujian Dai",
            "Xinyang Pan",
            "Lixin He"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19877",
        "abstract": "Deep learning methods for electronic-structure Hamiltonian prediction has offered significant computational efficiency advantages over traditional DFT methods, yet the diversity of atomic types, structural patterns, and the high-dimensional complexity of Hamiltonians pose substantial challenges to the generalization performance. In this work, we contribute on both the methodology and dataset sides to advance universal deep learning paradigm for Hamiltonian prediction. On the method side, we propose NextHAM, a neural E(3)-symmetry and expressive correction method for efficient and generalizable materials electronic-structure Hamiltonian prediction. First, we introduce the zeroth-step Hamiltonians, which can be efficiently constructed by the initial charge density of DFT, as informative descriptors of neural regression model in the input level and initial estimates of the target Hamiltonian in the output level, so that the regression model directly predicts the correction terms to the target ground truths, thereby significantly simplifying the input-output mapping for learning. Second, we present a neural Transformer architecture with strict E(3)-Symmetry and high non-linear expressiveness for Hamiltonian prediction. Third, we propose a novel training objective to ensure the accuracy performance of Hamiltonians in both real space and reciprocal space, preventing error amplification and the occurrence of \"ghost states\" caused by the large condition number of the overlap matrix. On the dataset side, we curate a high-quality broad-coverage large benchmark, namely Materials-HAM-SOC, comprising 17,000 material structures spanning 68 elements from six rows of the periodic table and explicitly incorporating SOC effects. Experimental results on Materials-HAM-SOC demonstrate that NextHAM achieves excellent accuracy and efficiency in predicting Hamiltonians and band structures.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "129",
        "title": "Do Before You Judge: Self-Reference as a Pathway to Better LLM Evaluation",
        "author": [
            "Wei-Hsiang Lin",
            "Sheng-Lun Wei",
            "Hen-Hsen Huang",
            "Hsin-Hsi Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19880",
        "abstract": "LLM-as-Judge frameworks are increasingly popular for AI evaluation, yet research findings on the relationship between models' generation and judgment abilities remain inconsistent. We investigate this relationship through systematic dataset- and instance-level analyses across 11 models and 21 diverse tasks. Despite both capabilities relying on the same underlying knowledge, our analyses reveal they are only weakly correlated, primarily due to LLMs' sensitivity to the responses being judged. To address this, we propose a self-reference-guided evaluation strategy that leverages a model's own answers as references. This approach significantly strengthens the correlation between generation and judgment abilities, offering a practical path to align these skills and providing a reliable proxy for model selection in evaluation tasks.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "130",
        "title": "Towards Self-Supervised Foundation Models for Critical Care Time Series",
        "author": [
            "Katja Naasunnguaq Jagd",
            "Rachael DeVries",
            "Ole Winther"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19885",
        "abstract": "Domain-specific foundation models for healthcare have expanded rapidly in recent years, yet foundation models for critical care time series remain relatively underexplored due to the limited size and availability of datasets. In this work, we introduce an early-stage pre-trained foundation model for critical care time-series based on the Bi-Axial Transformer (BAT), trained on pooled electronic health record datasets. We demonstrate effective transfer learning by fine-tuning the model on a dataset distinct from the training sources for mortality prediction, where it outperforms supervised baselines, particularly for small datasets ($<5,000$). These contributions highlight the potential of self-supervised foundation models for critical care times series to support generalizable and robust clinical applications in resource-limited settings.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "131",
        "title": "DSA, AIA, and LLMs: Approaches to conceptualizing and auditing moderation in LLM-based chatbots across languages and interfaces in the electoral contexts",
        "author": [
            "Natalia Stanusch",
            "Raziye Buse Cetin",
            "Salvatore Romano",
            "Miazia Schueler",
            "Meret Baumgartner",
            "Bastian August",
            "Alexandra Rosca"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19890",
        "abstract": "The integration of Large Language Models (LLMs) into chatbot-like search engines poses new challenges for governing, assessing, and scrutinizing the content output by these online entities, especially in light of the Digital Service Act (DSA). In what follows, we first survey the regulation landscape in which we can situate LLM-based chatbots and the notion of moderation. Second, we outline the methodological approaches to our study: a mixed-methods audit across chatbots, languages, and elections. We investigated Copilot, ChatGPT, and Gemini across ten languages in the context of the 2024 European Parliamentary Election and the 2024 US Presidential Election. Despite the uncertainty in regulatory frameworks, we propose a set of solutions on how to situate, study, and evaluate chatbot moderation.",
        "tags": [
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "132",
        "title": "D3Grasp: Diverse and Deformable Dexterous Grasping for General Objects",
        "author": [
            "Keyu Wang",
            "Bingcong Lu",
            "Zhengxue Cheng",
            "Hengdi Zhang",
            "Li Song"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19892",
        "abstract": "Achieving diverse and stable dexterous grasping for general and deformable objects remains a fundamental challenge in robotics, due to high-dimensional action spaces and uncertainty in perception. In this paper, we present D3Grasp, a multimodal perception-guided reinforcement learning framework designed to enable Diverse and Deformable Dexterous Grasping. We firstly introduce a unified multimodal representation that integrates visual and tactile perception to robustly grasp common objects with diverse properties. Second, we propose an asymmetric reinforcement learning architecture that exploits privileged information during training while preserving deployment realism, enhancing both generalization and sample efficiency. Third, we meticulously design a training strategy to synthesize contact-rich, penetration-free, and kinematically feasible grasps with enhanced adaptability to deformable and contact-sensitive objects. Extensive evaluations confirm that D3Grasp delivers highly robust performance across large-scale and diverse object categories, and substantially advances the state of the art in dexterous grasping for deformable and compliant objects, even under perceptual uncertainty and real-world disturbances. D3Grasp achieves an average success rate of 95.1% in real-world trials,outperforming prior methods on both rigid and deformable objects benchmarks.",
        "tags": [
            "RL",
            "Robotics"
        ]
    },
    {
        "id": "133",
        "title": "Future Policy Aware Preference Learning for Mathematical Reasoning",
        "author": [
            "Minjae Oh",
            "Yunho Choi",
            "Dongmin Choi",
            "Yohan Jo"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19893",
        "abstract": "Preference learning methods such as Direct Preference Optimization (DPO) have become standard for Large Language Model (LLM) post-training, yet they are often ineffective for mathematical reasoning. A key challenge is the large token overlap between preferred and dispreferred trajectories; lowering the probability of dispreferred trajectories also reduces the probability of shared useful tokens, leading to over-penalization and overall performance collapse. As a mitigation, existing algorithms include the probability of a trajectory under the current policy as a regularization term, which decreases the effect of the gradient when the probability is low. However, by the time this effect takes hold, useful tokens may have already been over-penalized as the model has begun to degrade. To address this, we propose Future Policy Aware (FPA) preference learning, which replaces the current policy with a future policy in the regularization term. This future policy is estimated via lightweight, logit-space extrapolation from a reference model toward the current model. FPA enables safer training by preemptively regularizing potentially problematic gradients. We apply FPA to DPO, RPO, and SimPER and evaluate them on the MATH and GSM8K benchmarks. FPA yields consistent performance gains, with the largest improvements observed with SimPER, achieving gains of up to 5.75%. We demonstrate that FPA provides proactive regularization while preserving the probability of shared, useful mathematical tokens, and enables longer, degradation-free training with negligible computational overhead. We will release our code publicly upon publication.",
        "tags": [
            "DPO",
            "LLM"
        ]
    },
    {
        "id": "134",
        "title": "PromptCoT 2.0: Scaling Prompt Synthesis for Large Language Model Reasoning",
        "author": [
            "Xueliang Zhao",
            "Wei Wu",
            "Jian Guan",
            "Zhuocheng Gong",
            "Lingpeng Kong"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19894",
        "abstract": "Large language models (LLMs) are evolving from conversational systems into strong reasoners for tasks such as Olympiad mathematics and competitive programming. While scaling parameters and test-time computation has driven progress, a key bottleneck is the lack of high-quality training problems: human-curated datasets are costly and limited, while existing synthetic corpora are often too easy or narrow. PromptCoT 1.0 showed that injecting rationales into prompt synthesis increases problem difficulty. Building on this, we present PromptCoT 2.0, a scalable framework that replaces hand-crafted heuristics with an expectation-maximization (EM) loop, where rationales are iteratively refined to guide prompt construction. This produces problems that are both harder and more diverse than prior corpora. The synthetic prompts support two post-training regimes: (1) Self-Play, where strong models improve autonomously via verifiable feedback without stronger teachers; and (2) Supervised Fine-Tuning (SFT), where weaker models learn from teacher-distilled traces. Extensive experiments demonstrate the effectiveness of this approach. In self-play, applying PromptCoT 2.0 to Qwen3-30B-A3B-Thinking-2507 sets new state-of-the-art results at the 30B scale, with +4.4, +4.8, and +5.3 on AIME 24/25 and HMMT 25, +6.1 and +5.0 on LiveCodeBench v5/v6, and +35 Elo on Codeforces. In SFT, training Qwen2.5-7B-Instruct solely on synthetic prompts boosts accuracy to 73.1 (AIME 24), 65.6 (AIME 25), and 53.4 (LiveCodeBench v5), surpassing models trained on human or hybrid data. Analyses further confirm that PromptCoT 2.0 yields fundamentally harder and distributionally distinct problems. These results establish prompt synthesis as a new axis for scaling reasoning and position PromptCoT 2.0 as a scalable foundation for future open-source models. The implementation is available at https://github.com/inclusionAI/PromptCoT.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "135",
        "title": "Aerial-Ground Image Feature Matching via 3D Gaussian Splatting-based Intermediate View Rendering",
        "author": [
            "Jiangxue Yu",
            "Hui Wang",
            "San Jiang",
            "Xing Zhang",
            "Dejin Zhang",
            "Qingquan Li"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19898",
        "abstract": "The integration of aerial and ground images has been a promising solution in 3D modeling of complex scenes, which is seriously restricted by finding reliable correspondences. The primary contribution of this study is a feature matching algorithm for aerial and ground images, whose core idea is to generate intermediate views to alleviate perspective distortions caused by the extensive viewpoint changes. First, by using aerial images only, sparse models are reconstructed through an incremental SfM (Structure from Motion) engine due to their large scene coverage. Second, 3D Gaussian Splatting is then adopted for scene rendering by taking as inputs sparse points and oriented images. For accurate view rendering, a render viewpoint determination algorithm is designed by using the oriented camera poses of aerial images, which is used to generate high-quality intermediate images that can bridge the gap between aerial and ground images. Third, with the aid of intermediate images, reliable feature matching is conducted for match pairs from render-aerial and render-ground images, and final matches can be generated by transmitting correspondences through intermediate views. By using real aerial and ground datasets, the validation of the proposed solution has been verified in terms of feature matching and scene rendering and compared comprehensively with widely used methods. The experimental results demonstrate that the proposed solution can provide reliable feature matches for aerial and ground images with an obvious increase in the number of initial and refined matches, and it can provide enough matches to achieve accurate ISfM reconstruction and complete 3DGS-based scene rendering.",
        "tags": [
            "3D",
            "Gaussian Splatting"
        ]
    },
    {
        "id": "136",
        "title": "WEST: LLM based Speech Toolkit for Speech Understanding, Generation, and Interaction",
        "author": [
            "Binbin Zhang",
            "Chengdong Liang",
            "Shuai Wang",
            "Xuelong Geng",
            "Zhao Guo",
            "Haoyu Li",
            "Hao Yin",
            "Xipeng Yang",
            "Pengshen Zhang",
            "Changwei Ma",
            "Lei Xie"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19902",
        "abstract": "In this paper, we present WEST(WE Speech Toolkit), a speech toolkit based on a large language model (LLM) for speech understanding, generation, and interaction. There are three key features of WEST: 1) Fully LLM-based: Standing on the shoulders of giants by reusing mature architectures, ecosystems (e.g., Hugging Face), and methods (e.g., sequence packing) from large models. 2) Full-stack: Supports tasks such as recognition, synthesis, understanding, dialogue, and multimodal capabilities, with extensibility to incorporate open-source models. 3) Simple and Stupid: A simple and stupid speech toolkit that everyone can Touch. In addition, WEST provides two types of recipes, models, and experimental results. The first is entirely based on open-source models and open-source data, allowing users to fully reproduce the experiments in this paper and serving as a verification system or minimal system baseline. The second is trained on massive data, offering superior performance so the user can directly apply it out of the box. WEST is publicly avilable at https://github.com/wenet-e2e/west/",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "137",
        "title": "GUIDE: A Diffusion-Based Autonomous Robot Exploration Framework Using Global Graph Inference",
        "author": [
            "Zijun Che",
            "Yinghong Zhang",
            "Shengyi Liang",
            "Boyu Zhou",
            "Jun Ma",
            "Jinni Zhou"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19916",
        "abstract": "Autonomous exploration in structured and complex indoor environments remains a challenging task, as existing methods often struggle to appropriately model unobserved space and plan globally efficient paths. To address these limitations, we propose GUIDE, a novel exploration framework that synergistically combines global graph inference with diffusion-based decision-making. We introduce a region-evaluation global graph representation that integrates both observed environmental data and predictions of unexplored areas, enhanced by a region-level evaluation mechanism to prioritize reliable structural inferences while discounting uncertain predictions. Building upon this enriched representation, a diffusion policy network generates stable, foresighted action sequences with significantly reduced denoising steps. Extensive simulations and real-world deployments demonstrate that GUIDE consistently outperforms state-of-the-art methods, achieving up to 18.3% faster coverage completion and a 34.9% reduction in redundant movements.",
        "tags": [
            "Diffusion",
            "Robotics"
        ]
    },
    {
        "id": "138",
        "title": "Beyond Language Barriers: Multi-Agent Coordination for Multi-Language Code Generation",
        "author": [
            "Micheline BÃ©nÃ©dicte Moumoula",
            "Serge Lionel Nikiema",
            "AlbÃ©rick Euraste Djire",
            "Abdoul Kader Kabore",
            "Jacques Klein",
            "TegawendÃ© F. Bissyande"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19918",
        "abstract": "Producing high-quality code across multiple programming languages is increasingly important as today's software systems are built on heterogeneous stacks. Large language models (LLMs) have advanced the state of automated programming, yet their proficiency varies sharply between languages, especially those with limited training data such as Rust, Perl, OCaml, and Erlang. Many current solutions including language-specific fine-tuning, multi-agent orchestration, transfer learning, and intermediate-representation pipelines still approach each target language in isolation, missing opportunities to share knowledge or exploit recurring cross-language patterns.\nXL-CoGen tackles this challenge with a coordinated multi-agent architecture that integrates intermediate representation, code generation, translation, and automated repair. Its distinguishing feature is a data-driven mechanism for selecting bridging languages: empirically derived transfer matrices identify the best intermediate languages based on demonstrated translation success rather than raw generation accuracy. The system performs early output validation, iteratively corrects errors, and reuses intermediate artifacts as contextual scaffolds for subsequent translations.\nExtensive experiments show that XL-CoGen yields notable improvements with 13 percentage-point gains over the strongest fine-tuned baseline and as much as 30 percentage points over existing single-language multi-agent methods. Ablation studies further demonstrate that compatibility-guided bridging significantly outperforms LLM-based heuristics, confirming the value of cumulative cross-language knowledge transfer.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "139",
        "title": "Exploration with Foundation Models: Capabilities, Limitations, and Hybrid Approaches",
        "author": [
            "Remo Sasso",
            "Michelangelo Conserva",
            "Dominik Jeurissen",
            "Paulo Rauber"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19924",
        "abstract": "Exploration in reinforcement learning (RL) remains challenging, particularly in sparse-reward settings. While foundation models possess strong semantic priors, their capabilities as zero-shot exploration agents in classic RL benchmarks are not well understood. We benchmark LLMs and VLMs on multi-armed bandits, Gridworlds, and sparse-reward Atari to test zero-shot exploration. Our investigation reveals a key limitation: while VLMs can infer high-level objectives from visual input, they consistently fail at precise low-level control: the \"knowing-doing gap\". To analyze a potential bridge for this gap, we investigate a simple on-policy hybrid framework in a controlled, best-case scenario. Our results in this idealized setting show that VLM guidance can significantly improve early-stage sample efficiency, providing a clear analysis of the potential and constraints of using foundation models to guide exploration rather than for end-to-end control.",
        "tags": [
            "LLM",
            "RL",
            "VLM"
        ]
    },
    {
        "id": "140",
        "title": "CON-QA: Privacy-Preserving QA using cloud LLMs in Contract Domain",
        "author": [
            "Ajeet Kumar Singh",
            "Rajsabi Surya",
            "Anurag Tripathi",
            "Santanu Choudhury",
            "Sudhir Bisane"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19925",
        "abstract": "As enterprises increasingly integrate cloud-based large language models (LLMs) such as ChatGPT and Gemini into their legal document workflows, protecting sensitive contractual information - including Personally Identifiable Information (PII) and commercially sensitive clauses - has emerged as a critical challenge. In this work, we propose CON-QA, a hybrid privacy-preserving framework designed specifically for secure question answering over enterprise contracts, effectively combining local and cloud-hosted LLMs. The CON-QA framework operates through three stages: (i) semantic query decomposition and query-aware document chunk retrieval using a locally deployed LLM analysis, (ii) anonymization of detected sensitive entities via a structured one-to-many mapping scheme, ensuring semantic coherence while preventing cross-session entity inference attacks, and (iii) anonymized response generation by a cloud-based LLM, with accurate reconstruction of the original answer locally using a session-consistent many-to-one reverse mapping. To rigorously evaluate CON-QA, we introduce CUAD-QA, a corpus of 85k question-answer pairs generated over 510 real-world CUAD contract documents, encompassing simple, complex, and summarization-style queries. Empirical evaluations, complemented by detailed human assessments, confirm that CON-QA effectively maintains both privacy and utility, preserves answer quality, maintains fidelity to legal clause semantics, and significantly mitigates privacy risks, demonstrating its practical suitability for secure, enterprise-level contract documents.",
        "tags": [
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "141",
        "title": "Documentation Retrieval Improves Planning Language Generation",
        "author": [
            "Renxiang Wang",
            "Li Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19931",
        "abstract": "Certain strong LLMs have shown promise for zero-shot formal planning by generating planning languages like PDDL. Yet, performance of most open-source models under 50B parameters has been reported to be close to zero due to the low-resource nature of these languages. We significantly improve their performance via a series of lightweight pipelines that integrates documentation retrieval with modular code generation and error refinement. With models like Llama-4-Maverick, our best pipeline improves plan correctness from 0\\% to over 80\\% on the common BlocksWorld domain. However, while syntactic errors are substantially reduced, semantic errors persist in more challenging domains, revealing fundamental limitations in current models' reasoning capabilities.\\footnote{Our code and data can be found at https://github.com/Nangxxxxx/PDDL-RAG",
        "tags": [
            "LLM",
            "LLaMA",
            "RAG"
        ]
    },
    {
        "id": "142",
        "title": "CapStARE: Capsule-based Spatiotemporal Architecture for Robust and Efficient Gaze Estimation",
        "author": [
            "Miren Samaniego",
            "Igor Rodriguez",
            "Elena Lazkano"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19936",
        "abstract": "We introduce CapStARE, a capsule-based spatio-temporal architecture for gaze estimation that integrates a ConvNeXt backbone, capsule formation with attention routing, and dual GRU decoders specialized for slow and rapid gaze dynamics. This modular design enables efficient part-whole reasoning and disentangled temporal modeling, achieving state-of-the-art performance on ETH-XGaze (3.36) and MPIIFaceGaze (2.65) while maintaining real-time inference (< 10 ms). The model also generalizes well to unconstrained conditions in Gaze360 (9.06) and human-robot interaction scenarios in RT-GENE (4.76), outperforming or matching existing methods with fewer parameters and greater interpretability. These results demonstrate that CapStARE offers a practical and robust solution for real-time gaze estimation in interactive systems. The related code and results for this article can be found on: https://github.com/toukapy/capsStare",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "143",
        "title": "GS-RoadPatching: Inpainting Gaussians via 3D Searching and Placing for Driving Scenes",
        "author": [
            "Guo Chen",
            "Jiarun Liu",
            "Sicong Du",
            "Chenming Wu",
            "Deqi Li",
            "Shi-Sheng Huang",
            "Guofeng Zhang",
            "Sheng Yang"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19937",
        "abstract": "This paper presents GS-RoadPatching, an inpainting method for driving scene completion by referring to completely reconstructed regions, which are represented by 3D Gaussian Splatting (3DGS). Unlike existing 3DGS inpainting methods that perform generative completion relying on 2D perspective-view-based diffusion or GAN models to predict limited appearance or depth cues for missing regions, our approach enables substitutional scene inpainting and editing directly through the 3DGS modality, extricating it from requiring spatial-temporal consistency of 2D cross-modals and eliminating the need for time-intensive retraining of Gaussians. Our key insight is that the highly repetitive patterns in driving scenes often share multi-modal similarities within the implicit 3DGS feature space and are particularly suitable for structural matching to enable effective 3DGS-based substitutional inpainting. Practically, we construct feature-embedded 3DGS scenes to incorporate a patch measurement method for abstracting local context at different scales and, subsequently, propose a structural search method to find candidate patches in 3D space effectively. Finally, we propose a simple yet effective substitution-and-fusion optimization for better visual harmony. We conduct extensive experiments on multiple publicly available datasets to demonstrate the effectiveness and efficiency of our proposed method in driving scenes, and the results validate that our method achieves state-of-the-art performance compared to the baseline methods in terms of both quality and interoperability. Additional experiments in general scenes also demonstrate the applicability of the proposed 3D inpainting strategy. The project page and code are available at: https://shanzhaguoo.github.io/GS-RoadPatching/",
        "tags": [
            "3D",
            "Diffusion",
            "GAN",
            "Gaussian Splatting",
            "Inpainting"
        ]
    },
    {
        "id": "144",
        "title": "Interpreting ResNet-based CLIP via Neuron-Attention Decomposition",
        "author": [
            "Edmund Bu",
            "Yossi Gandelsman"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19943",
        "abstract": "We present a novel technique for interpreting the neurons in CLIP-ResNet by decomposing their contributions to the output into individual computation paths. More specifically, we analyze all pairwise combinations of neurons and the following attention heads of CLIP's attention-pooling layer. We find that these neuron-head pairs can be approximated by a single direction in CLIP-ResNet's image-text embedding space. Leveraging this insight, we interpret each neuron-head pair by associating it with text. Additionally, we find that only a sparse set of the neuron-head pairs have a significant contribution to the output value, and that some neuron-head pairs, while polysemantic, represent sub-concepts of their corresponding neurons. We use these observations for two applications. First, we employ the pairs for training-free semantic segmentation, outperforming previous methods for CLIP-ResNet. Second, we utilize the contributions of neuron-head pairs to monitor dataset distribution shifts. Our results demonstrate that examining individual computation paths in neural networks uncovers interpretable units, and that such units can be utilized for downstream tasks.",
        "tags": [
            "CLIP",
            "Segmentation"
        ]
    },
    {
        "id": "145",
        "title": "Robot Trajectron V2: A Probabilistic Shared Control Framework for Navigation",
        "author": [
            "Pinhao Song",
            "Yurui Du",
            "Ophelie Saussus",
            "Sofie De Schrijver",
            "Irene Caprara",
            "Peter Janssen",
            "Renaud Detry"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19954",
        "abstract": "We propose a probabilistic shared-control solution for navigation, called Robot Trajectron V2 (RT-V2), that enables accurate intent prediction and safe, effective assistance in human-robot interaction. RT-V2 jointly models a user's long-term behavioral patterns and their noisy, low-dimensional control signals by combining a prior intent model with a posterior update that accounts for real-time user input and environmental context. The prior captures the multimodal and history-dependent nature of user intent using recurrent neural networks and conditional variational autoencoders, while the posterior integrates this with uncertain user commands to infer desired actions. We conduct extensive experiments to validate RT-V2 across synthetic benchmarks, human-computer interaction studies with keyboard input, and brain-machine interface experiments with non-human primates. Results show that RT-V2 outperforms the state of the art in intent estimation, provides safe and efficient navigation support, and adequately balances user autonomy with assistive intervention. By unifying probabilistic modeling, reinforcement learning, and safe optimization, RT-V2 offers a principled and generalizable approach to shared control for diverse assistive technologies.",
        "tags": [
            "RL",
            "Robotics"
        ]
    },
    {
        "id": "146",
        "title": "Interactive Semantic Segmentation for Phosphene Vision Neuroprosthetics",
        "author": [
            "Eleftherios Papadopoulos",
            "Yagmur GÃ¼Ã§lÃ¼tÃ¼rk"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19957",
        "abstract": "Visual impairments present significant challenges to individuals worldwide, impacting daily activities and quality of life. Visual neuroprosthetics offer a promising solution, leveraging advancements in technology to provide a simplified visual sense through devices comprising cameras, computers, and implanted electrodes. This study investigates user-centered design principles for a phosphene vision algorithm, utilizing feedback from visually impaired individuals to guide the development of a gaze-controlled semantic segmentation system. We conducted interviews revealing key design principles. These principles informed the implementation of a gaze-guided semantic segmentation algorithm using the Segment Anything Model (SAM). In a simulated phosphene vision environment, participants performed object detection tasks under SAM, edge detection, and normal vision conditions. SAM improved identification accuracy over edge detection, remained effective in complex scenes, and was particularly robust for specific object shapes. These findings demonstrate the value of user feedback and the potential of gaze-guided semantic segmentation to enhance neuroprosthetic vision.",
        "tags": [
            "Detection",
            "SAM",
            "Segmentation"
        ]
    },
    {
        "id": "147",
        "title": "Generalist Robot Manipulation beyond Action Labeled Data",
        "author": [
            "Alexander Spiridonov",
            "Jan-Nico Zaech",
            "Nikolay Nikolov",
            "Luc Van Gool",
            "Danda Pani Paudel"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19958",
        "abstract": "Recent advances in generalist robot manipulation leverage pre-trained Vision-Language Models (VLMs) and large-scale robot demonstrations to tackle diverse tasks in a zero-shot manner. A key challenge remains: scaling high-quality, action-labeled robot demonstration data, which existing methods rely on for robustness and generalization. To address this, we propose a method that benefits from videos without action labels - featuring humans and/or robots in action - enhancing open-vocabulary performance and enabling data-efficient learning of new tasks. Our method extracts dense, dynamic 3D point clouds at the hand or gripper location and uses a proposed 3D dynamics predictor for self-supervision. This predictor is then tuned to an action predictor using a smaller labeled dataset for action alignment. We show that our method not only learns from unlabeled human and robot demonstrations - improving downstream generalist robot policies - but also enables robots to learn new tasks without action labels (i.e., out-of-action generalization) in both real-world and simulated settings.",
        "tags": [
            "3D",
            "Robotics",
            "VLM"
        ]
    },
    {
        "id": "148",
        "title": "SynchroRaMa : Lip-Synchronized and Emotion-Aware Talking Face Generation via Multi-Modal Emotion Embedding",
        "author": [
            "Phyo Thet Yee",
            "Dimitrios Kollias",
            "Sudeepta Mishra",
            "Abhinav Dhall"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19965",
        "abstract": "Audio-driven talking face generation has received growing interest, particularly for applications requiring expressive and natural human-avatar interaction. However, most existing emotion-aware methods rely on a single modality (either audio or image) for emotion embedding, limiting their ability to capture nuanced affective cues. Additionally, most methods condition on a single reference image, restricting the model's ability to represent dynamic changes in actions or attributes across time. To address these issues, we introduce SynchroRaMa, a novel framework that integrates a multi-modal emotion embedding by combining emotional signals from text (via sentiment analysis) and audio (via speech-based emotion recognition and audio-derived valence-arousal features), enabling the generation of talking face videos with richer and more authentic emotional expressiveness and fidelity. To ensure natural head motion and accurate lip synchronization, SynchroRaMa includes an audio-to-motion (A2M) module that generates motion frames aligned with the input audio. Finally, SynchroRaMa incorporates scene descriptions generated by Large Language Model (LLM) as additional textual input, enabling it to capture dynamic actions and high-level semantic attributes. Conditioning the model on both visual and textual cues enhances temporal consistency and visual realism. Quantitative and qualitative experiments on benchmark datasets demonstrate that SynchroRaMa outperforms the state-of-the-art, achieving improvements in image quality, expression preservation, and motion realism. A user study further confirms that SynchroRaMa achieves higher subjective ratings than competing methods in overall naturalness, motion diversity, and video smoothness. Our project page is available at <https://novicemm.github.io/synchrorama>.",
        "tags": [
            "LLM",
            "Talking Face"
        ]
    },
    {
        "id": "149",
        "title": "An effective control of large systems of active particles: An application to evacuation problem",
        "author": [
            "Albina Klepach",
            "Egor E. Nuzhin",
            "Alexey A. Tsukanov",
            "Nikolay V. Brilliantov"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19972",
        "abstract": "Manipulation of large systems of active particles is a serious challenge across diverse domains, including crowd management, control of robotic swarms, and coordinated material transport. The development of advanced control strategies for complex scenarios is hindered, however, by the lack of scalability and robustness of the existing methods, in particular, due to the need of an individual control for each agent. One possible solution involves controlling a system through a leader or a group of leaders, which other agents tend to follow. Using such an approach we develop an effective control strategy for a leader, combining reinforcement learning (RL) with artificial forces acting on the system. To describe the guidance of active particles by a leader we introduce the generalized Vicsek model. This novel method is then applied to the problem of the effective evacuation by a robot-rescuer (leader) of large groups of people from hazardous places. We demonstrate, that while a straightforward application of RL yields suboptimal results, even for advanced architectures, our approach provides a robust and efficient evacuation strategy. The source code supporting this study is publicly available at: https://github.com/cinemere/evacuation.",
        "tags": [
            "RL",
            "Robotics"
        ]
    },
    {
        "id": "150",
        "title": "Faster Than SVD, Smarter Than SGD: The OPLoRA Alternating Update",
        "author": [
            "Abdulla Jasem Almansoori",
            "Maria Ivanova",
            "Andrey Veprikov",
            "Aleksandr Beznosikov",
            "Samuel HorvÃ¡th",
            "Martin TakÃ¡Ä"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19977",
        "abstract": "Low-Rank Adaptation (LoRA) fine-tunes large models by learning low-rank updates on top of frozen weights, dramatically reducing trainable parameters and memory. However, there is still a gap between full training with low-rank projections (SVDLoRA) and LoRA fine-tuning, indicating that LoRA steps can be further improved. In this study, we propose OPLoRA, a memory-efficient optimizer that closes this gap by casting LoRA optimization as an interpretable sub-problem and solving it efficiently with alternating least squares updates, where 1-2 alternating steps are empirically found to be sufficient to closely match truncated SVD without ever forming the full matrix. We also retrieve the recently proposed preconditioning methods for LoRA as a special case. OPLoRA supports momentum by maintaining a low-rank estimate using the same subroutine (LoRSum) for computing the step, with a memory budget of 3 times the number of LoRA parameters (i.e., same as Adam). We also propose an experimental scaled variant that uses the K-FAC metric, which could be of interest. Across a linear task, MNIST, CIFAR-100, and RoBERTa-base (MNLI), OPLoRA consistently approaches SVDLoRA's performance using significantly less memory.",
        "tags": [
            "LoRA"
        ]
    },
    {
        "id": "151",
        "title": "CamPVG: Camera-Controlled Panoramic Video Generation with Epipolar-Aware Diffusion",
        "author": [
            "Chenhao Ji",
            "Chaohui Yu",
            "Junyao Gao",
            "Fan Wang",
            "Cairong Zhao"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19979",
        "abstract": "Recently, camera-controlled video generation has seen rapid development, offering more precise control over video generation. However, existing methods predominantly focus on camera control in perspective projection video generation, while geometrically consistent panoramic video generation remains challenging. This limitation is primarily due to the inherent complexities in panoramic pose representation and spherical projection. To address this issue, we propose CamPVG, the first diffusion-based framework for panoramic video generation guided by precise camera poses. We achieve camera position encoding for panoramic images and cross-view feature aggregation based on spherical projection. Specifically, we propose a panoramic PlÃ¼cker embedding that encodes camera extrinsic parameters through spherical coordinate transformation. This pose encoder effectively captures panoramic geometry, overcoming the limitations of traditional methods when applied to equirectangular projections. Additionally, we introduce a spherical epipolar module that enforces geometric constraints through adaptive attention masking along epipolar lines. This module enables fine-grained cross-view feature aggregation, substantially enhancing the quality and consistency of generated panoramic videos. Extensive experiments demonstrate that our method generates high-quality panoramic videos consistent with camera trajectories, far surpassing existing methods in panoramic video generation.",
        "tags": [
            "Diffusion",
            "Video Generation"
        ]
    },
    {
        "id": "152",
        "title": "MeshMosaic: Scaling Artist Mesh Generation via Local-to-Global Assembly",
        "author": [
            "Rui Xu",
            "Tianyang Xue",
            "Qiujie Dong",
            "Le Wan",
            "Zhe Zhu",
            "Peng Li",
            "Zhiyang Dou",
            "Cheng Lin",
            "Shiqing Xin",
            "Yuan Liu",
            "Wenping Wang",
            "Taku Komura"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19995",
        "abstract": "Scaling artist-designed meshes to high triangle numbers remains challenging for autoregressive generative models. Existing transformer-based methods suffer from long-sequence bottlenecks and limited quantization resolution, primarily due to the large number of tokens required and constrained quantization granularity. These issues prevent faithful reproduction of fine geometric details and structured density patterns. We introduce MeshMosaic, a novel local-to-global framework for artist mesh generation that scales to over 100K triangles--substantially surpassing prior methods, which typically handle only around 8K faces. MeshMosaic first segments shapes into patches, generating each patch autoregressively and leveraging shared boundary conditions to promote coherence, symmetry, and seamless connectivity between neighboring regions. This strategy enhances scalability to high-resolution meshes by quantizing patches individually, resulting in more symmetrical and organized mesh density and structure. Extensive experiments across multiple public datasets demonstrate that MeshMosaic significantly outperforms state-of-the-art methods in both geometric fidelity and user preference, supporting superior detail representation and practical mesh generation for real-world applications.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "153",
        "title": "Choosing to Be Green: Advancing Green AI via Dynamic Model Selection",
        "author": [
            "Emilio Cruciani",
            "Roberto Verdecchia"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19996",
        "abstract": "Artificial Intelligence is increasingly pervasive across domains, with ever more complex models delivering impressive predictive performance. This fast technological advancement however comes at a concerning environmental cost, with state-of-the-art models - particularly deep neural networks and large language models - requiring substantial computational resources and energy. In this work, we present the intuition of Green AI dynamic model selection, an approach based on dynamic model selection that aims at reducing the environmental footprint of AI by selecting the most sustainable model while minimizing potential accuracy loss. Specifically, our approach takes into account the inference task, the environmental sustainability of available models, and accuracy requirements to dynamically choose the most suitable model. Our approach presents two different methods, namely Green AI dynamic model cascading and Green AI dynamic model routing. We demonstrate the effectiveness of our approach via a proof of concept empirical example based on a real-world dataset. Our results show that Green AI dynamic model selection can achieve substantial energy savings (up to ~25%) while substantially retaining the accuracy of the most energy greedy solution (up to ~95%). As conclusion, our preliminary findings highlight the potential that hybrid, adaptive model selection strategies withhold to mitigate the energy demands of modern AI systems without significantly compromising accuracy requirements.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "154",
        "title": "MultiSoundGen: Video-to-Audio Generation for Multi-Event Scenarios via SlowFast Contrastive Audio-Visual Pretraining and Direct Preference Optimization",
        "author": [
            "Jianxuan Yang",
            "Xiaoran Yang",
            "Lipan Zhang",
            "Xinyue Guo",
            "Zhao Wang",
            "Gongping Huang"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19999",
        "abstract": "Current video-to-audio (V2A) methods struggle in complex multi-event scenarios (video scenarios involving multiple sound sources, sound events, or transitions) due to two critical limitations. First, existing methods face challenges in precisely aligning intricate semantic information together with rapid dynamic features. Second, foundational training lacks quantitative preference optimization for semantic-temporal alignment and audio quality. As a result, it fails to enhance integrated generation quality in cluttered multi-event scenes. To address these core limitations, this study proposes a novel V2A framework: MultiSoundGen. It introduces direct preference optimization (DPO) into the V2A domain, leveraging audio-visual pretraining (AVP) to enhance performance in complex multi-event scenarios. Our contributions include two key innovations: the first is SlowFast Contrastive AVP (SF-CAVP), a pioneering AVP model with a unified dual-stream architecture. SF-CAVP explicitly aligns core semantic representations and rapid dynamic features of audio-visual data to handle multi-event complexity; second, we integrate the DPO method into V2A task and propose AVP-Ranked Preference Optimization (AVP-RPO). It uses SF-CAVP as a reward model to quantify and prioritize critical semantic-temporal matches while enhancing audio quality. Experiments demonstrate that MultiSoundGen achieves state-of-the-art (SOTA) performance in multi-event scenarios, delivering comprehensive gains across distribution matching, audio quality, semantic alignment, and temporal synchronization. The complete code and dataset will be released soon.",
        "tags": [
            "DPO"
        ]
    },
    {
        "id": "155",
        "title": "The Knowledge-Behaviour Disconnect in LLM-based Chatbots",
        "author": [
            "Jan Broersen"
        ],
        "pdf": "https://arxiv.org/pdf/2509.20004",
        "abstract": "Large language model-based artificial conversational agents (like ChatGPT) give answers to all kinds of questions, and often enough these answers are correct. Just on the basis of that capacity alone, we may attribute knowledge to them. But do these models use this knowledge as a basis for their own conversational behaviour? I argue this is not the case, and I will refer to this failure as a `disconnect'. I further argue this disconnect is fundamental in the sense that with more data and more training of the LLM on which a conversational chatbot is based, it will not disappear. The reason is, as I will claim, that the core technique used to train LLMs does not allow for the establishment of the connection we are after. The disconnect reflects a fundamental limitation on the capacities of LLMs, and explains the source of hallucinations. I will furthermore consider the ethical version of the disconnect (ethical conversational knowledge not being aligned with ethical conversational behaviour), since in this domain researchers have come up with several additional techniques to influence a chatbot's behaviour. I will discuss how these techniques do nothing to solve the disconnect and can make it worse.",
        "tags": [
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "156",
        "title": "DiffNator: Generating Structured Explanations of Time-Series Differences",
        "author": [
            "Kota Dohi",
            "Tomoya Nishida",
            "Harsh Purohit",
            "Takashi Endo",
            "Yohei Kawaguchi"
        ],
        "pdf": "https://arxiv.org/pdf/2509.20007",
        "abstract": "In many IoT applications, the central interest lies not in individual sensor signals but in their differences, yet interpreting such differences requires expert knowledge. We propose DiffNator, a framework for structured explanations of differences between two time series. We first design a JSON schema that captures the essential properties of such differences. Using the Time-series Observations of Real-world IoT (TORI) dataset, we generate paired sequences and train a model that combine a time-series encoder with a frozen LLM to output JSON-formatted explanations. Experimental results show that DiffNator generates accurate difference explanations and substantially outperforms both a visual question answering (VQA) baseline and a retrieval method using a pre-trained time-series encoder.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "157",
        "title": "Learning Robust Penetration-Testing Policies under Partial Observability: A systematic evaluation",
        "author": [
            "Raphael Simon",
            "Pieter Libin",
            "Wim Mees"
        ],
        "pdf": "https://arxiv.org/pdf/2509.20008",
        "abstract": "Penetration testing, the simulation of cyberattacks to identify security vulnerabilities, presents a sequential decision-making problem well-suited for reinforcement learning (RL) automation. Like many applications of RL to real-world problems, partial observability presents a major challenge, as it invalidates the Markov property present in Markov Decision Processes (MDPs). Partially Observable MDPs require history aggregation or belief state estimation to learn successful policies. We investigate stochastic, partially observable penetration testing scenarios over host networks of varying size, aiming to better reflect real-world complexity through more challenging and representative benchmarks. This approach leads to the development of more robust and transferable policies, which are crucial for ensuring reliable performance across diverse and unpredictable real-world environments. Using vanilla Proximal Policy Optimization (PPO) as a baseline, we compare a selection of PPO variants designed to mitigate partial observability, including frame-stacking, augmenting observations with historical information, and employing recurrent or transformer-based architectures. We conduct a systematic empirical analysis of these algorithms across different host network sizes. We find that this task greatly benefits from history aggregation. Converging three times faster than other approaches. Manual inspection of the learned policies by the algorithms reveals clear distinctions and provides insights that go beyond quantitative results.",
        "tags": [
            "PPO",
            "RL",
            "Transformer"
        ]
    },
    {
        "id": "158",
        "title": "Embodied AI: From LLMs to World Models",
        "author": [
            "Tongtong Feng",
            "Xin Wang",
            "Yu-Gang Jiang",
            "Wenwu Zhu"
        ],
        "pdf": "https://arxiv.org/pdf/2509.20021",
        "abstract": "Embodied Artificial Intelligence (AI) is an intelligent system paradigm for achieving Artificial General Intelligence (AGI), serving as the cornerstone for various applications and driving the evolution from cyberspace to physical systems. Recent breakthroughs in Large Language Models (LLMs) and World Models (WMs) have drawn significant attention for embodied AI. On the one hand, LLMs empower embodied AI via semantic reasoning and task decomposition, bringing high-level natural language instructions and low-level natural language actions into embodied cognition. On the other hand, WMs empower embodied AI by building internal representations and future predictions of the external world, facilitating physical law-compliant embodied interactions. As such, this paper comprehensively explores the literature in embodied AI from basics to advances, covering both LLM driven and WM driven works. In particular, we first present the history, key technologies, key components, and hardware systems of embodied AI, as well as discuss its development via looking from unimodal to multimodal angle. We then scrutinize the two burgeoning fields of embodied AI, i.e., embodied AI with LLMs/multimodal LLMs (MLLMs) and embodied AI with WMs, meticulously delineating their indispensable roles in end-to-end embodied cognition and physical laws-driven embodied interactions. Building upon the above advances, we further share our insights on the necessity of the joint MLLM-WM driven embodied AI architecture, shedding light on its profound significance in enabling complex tasks within physical worlds. In addition, we examine representative applications of embodied AI, demonstrating its wide applicability in real-world scenarios. Last but not least, we point out future research directions of embodied AI that deserve further investigation.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "159",
        "title": "Generative Adversarial Networks Applied for Privacy Preservation in Biometric-Based Authentication and Identification",
        "author": [
            "Lubos Mjachky",
            "Ivan Homoliak"
        ],
        "pdf": "https://arxiv.org/pdf/2509.20024",
        "abstract": "Biometric-based authentication systems are getting broadly adopted in many areas. However, these systems do not allow participating users to influence the way their data is used. Furthermore, the data may leak and can be misused without the users' knowledge. In this paper, we propose a new authentication method that preserves the privacy of individuals and is based on a generative adversarial network (GAN). Concretely, we suggest using the GAN for translating images of faces to a visually private domain (e.g., flowers or shoes). Classifiers, which are used for authentication purposes, are then trained on the images from the visually private domain. Based on our experiments, the method is robust against attacks and still provides meaningful utility.",
        "tags": [
            "GAN"
        ]
    },
    {
        "id": "160",
        "title": "MARG: MAstering Risky Gap Terrains for Legged Robots with Elevation Mapping",
        "author": [
            "Yinzhao Dong",
            "Ji Ma",
            "Liu Zhao",
            "Wanyue Li",
            "Peng Lu"
        ],
        "pdf": "https://arxiv.org/pdf/2509.20036",
        "abstract": "Deep Reinforcement Learning (DRL) controllers for quadrupedal locomotion have demonstrated impressive performance on challenging terrains, allowing robots to execute complex skills such as climbing, running, and jumping. However, existing blind locomotion controllers often struggle to ensure safety and efficient traversal through risky gap terrains, which are typically highly complex, requiring robots to perceive terrain information and select appropriate footholds during locomotion accurately. Meanwhile, existing perception-based controllers still present several practical limitations, including a complex multi-sensor deployment system and expensive computing resource requirements. This paper proposes a DRL controller named MAstering Risky Gap Terrains (MARG), which integrates terrain maps and proprioception to dynamically adjust the action and enhance the robot's stability in these tasks. During the training phase, our controller accelerates policy optimization by selectively incorporating privileged information (e.g., center of mass, friction coefficients) that are available in simulation but unmeasurable directly in real-world deployments due to sensor limitations. We also designed three foot-related rewards to encourage the robot to explore safe footholds. More importantly, a terrain map generation (TMG) model is proposed to reduce the drift existing in mapping and provide accurate terrain maps using only one LiDAR, providing a foundation for zero-shot transfer of the learned policy. The experimental results indicate that MARG maintains stability in various risky terrain tasks.",
        "tags": [
            "RL",
            "Robotics"
        ]
    },
    {
        "id": "161",
        "title": "Tokenization and Representation Biases in Multilingual Models on Dialectal NLP Tasks",
        "author": [
            "Vani Kanjirangat",
            "Tanja SamardÅ¾iÄ",
            "Ljiljana Dolamic",
            "Fabio Rinaldi"
        ],
        "pdf": "https://arxiv.org/pdf/2509.20045",
        "abstract": "Dialectal data are characterized by linguistic variation that appears small to humans but has a significant impact on the performance of models. This dialect gap has been related to various factors (e.g., data size, economic and social factors) whose impact, however, turns out to be inconsistent. In this work, we investigate factors impacting the model performance more directly: we correlate Tokenization Parity (TP) and Information Parity (IP), as measures of representational biases in pre-trained multilingual models, with the downstream performance. We compare state-of-the-art decoder-only LLMs with encoder-based models across three tasks: dialect classification, topic classification, and extractive question answering, controlling for varying scripts (Latin vs. non-Latin) and resource availability (high vs. low). Our analysis reveals that TP is a better predictor of the performance on tasks reliant on syntactic and morphological cues (e.g., extractive QA), while IP better predicts performance in semantic tasks (e.g., topic classification). Complementary analyses, including tokenizer behavior, vocabulary coverage, and qualitative insights, reveal that the language support claims of LLMs often might mask deeper mismatches at the script or token level.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "162",
        "title": "Diffusion-Augmented Contrastive Learning: A Noise-Robust Encoder for Biosignal Representations",
        "author": [
            "Rami Zewail"
        ],
        "pdf": "https://arxiv.org/pdf/2509.20048",
        "abstract": "Learning robust representations for biosignals is often hampered by the challenge of designing effective data http://augmentations.Traditional methods can fail to capture the complex variations inherent in physiological data. Within this context, we propose a novel hybrid framework, Diffusion-Augmented Contrastive Learning (DACL), that fuses concepts from diffusion models and supervised contrastive learning. The DACL framework operates on a latent space created by a lightweight Variational Autoencoder (VAE) trained on our novel Scattering Transformer (ST) features [12]. It utilizes the diffusion forward process as a principled data augmentation technique to generate multiple noisy views of these latent embeddings. A U-Net style encoder is then trained with a supervised contrastive objective to learn a representation that balances class discrimination with robustness to noise across various diffusion time steps. We evaluated this proof-of-concept method on the PhysioNet 2017 ECG dataset, achieving a competitive AUROC of 0.7815. This work establishes a new paradigm for representation learning by using the diffusion process itself to drive the contrastive objective, creating noise-invariant embeddings that demonstrate a strong foundation for class separability.",
        "tags": [
            "Diffusion",
            "Transformer",
            "VAE"
        ]
    },
    {
        "id": "163",
        "title": "Projective Kolmogorov Arnold Neural Networks (P-KANs): Entropy-Driven Functional Space Discovery for Interpretable Machine Learning",
        "author": [
            "Alastair Poole",
            "Stig McArthur",
            "Saravan Kumar"
        ],
        "pdf": "https://arxiv.org/pdf/2509.20049",
        "abstract": "Kolmogorov-Arnold Networks (KANs) relocate learnable nonlinearities from nodes to edges, demonstrating remarkable capabilities in scientific machine learning and interpretable modeling. However, current KAN implementations suffer from fundamental inefficiencies due to redundancy in high-dimensional spline parameter spaces, where numerous distinct parameterisations yield functionally equivalent behaviors. This redundancy manifests as a \"nuisance space\" in the model's Jacobian, leading to susceptibility to overfitting and poor generalization. We introduce Projective Kolmogorov-Arnold Networks (P-KANs), a novel training framework that guides edge function discovery towards interpretable functional representations through entropy-minimisation techniques from signal analysis and sparse dictionary learning. Rather than constraining functions to predetermined spaces, our approach maintains spline space flexibility while introducing \"gravitational\" terms that encourage convergence towards optimal functional representations. Our key insight recognizes that optimal representations can be identified through entropy analysis of projection coefficients, compressing edge functions to lower-parameter projective spaces (Fourier, Chebyshev, Bessel). P-KANs demonstrate superior performance across multiple domains, achieving up to 80% parameter reduction while maintaining representational capacity, significantly improved robustness to noise compared to standard KANs, and successful application to industrial automated fiber placement prediction. Our approach enables automatic discovery of mixed functional representations where different edges converge to different optimal spaces, providing both compression benefits and enhanced interpretability for scientific machine learning applications.",
        "tags": [
            "KAN"
        ]
    },
    {
        "id": "164",
        "title": "One Filters All: A Generalist Filter for State Estimation",
        "author": [
            "Shiqi Liu",
            "Wenhan Cao",
            "Chang Liu",
            "Zeyu He",
            "Tianyi Zhang",
            "Shengbo Eben Li"
        ],
        "pdf": "https://arxiv.org/pdf/2509.20051",
        "abstract": "Estimating hidden states in dynamical systems, also known as optimal filtering, is a long-standing problem in various fields of science and engineering. In this paper, we introduce a general filtering framework, \\textbf{LLM-Filter}, which leverages large language models (LLMs) for state estimation by embedding noisy observations with text prototypes. In various experiments for classical dynamical systems, we find that first, state estimation can significantly benefit from the reasoning knowledge embedded in pre-trained LLMs. By achieving proper modality alignment with the frozen LLM, LLM-Filter outperforms the state-of-the-art learning-based approaches. Second, we carefully design the prompt structure, System-as-Prompt (SaP), incorporating task instructions that enable the LLM to understand the estimation tasks. Guided by these prompts, LLM-Filter exhibits exceptional generalization, capable of performing filtering tasks accurately in changed or even unseen environments. We further observe a scaling-law behavior in LLM-Filter, where accuracy improves with larger model sizes and longer training times. These findings make LLM-Filter a promising foundation model of filtering.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "165",
        "title": "LLM Trainer: Automated Robotic Data Generating via Demonstration Augmentation using LLMs",
        "author": [
            "Abraham George",
            "Amir Barati Farimani"
        ],
        "pdf": "https://arxiv.org/pdf/2509.20070",
        "abstract": "We present LLM Trainer, a fully automated pipeline that leverages the world knowledge of Large Language Models (LLMs) to transform a small number of human demonstrations (as few as one) into a large robot dataset for imitation learning. Our approach decomposes demonstration generation into two steps: (1) offline demonstration annotation that extracts keyframes, salient objects, and pose-object relations; and (2) online keypose retargeting that adapts those keyframes to a new scene, given an initial observation. Using these modified keypoints, our system warps the original demonstration to generate a new trajectory, which is then executed, and the resulting demo, if successful, is saved. Because the annotation is reusable across scenes, we use Thompson sampling to optimize the annotation, significantly improving generation success rate. We evaluate our method on a range of tasks, and find that our data annotation method consistently outperforms expert-engineered baselines. We further show an ensemble policy that combines the optimized LLM feed-forward plan with a learned feedback imitation learning controller. Finally, we demonstrate hardware feasibility on a Franka Emika Panda robot. For additional materials and demonstration videos, please see the project website: https://sites.google.com/andrew.cmu.edu/llm-trainer",
        "tags": [
            "LLM",
            "Robotics"
        ]
    },
    {
        "id": "166",
        "title": "From Text to Talk: Audio-Language Model Needs Non-Autoregressive Joint Training",
        "author": [
            "Tianqiao Liu",
            "Xueyi Li",
            "Hao Wang",
            "Haoxuan Li",
            "Zhichao Chen",
            "Weiqi Luo",
            "Zitao Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2509.20072",
        "abstract": "Recent advances in large language models have attracted significant interest in extending their capabilities to multimodal scenarios, particularly for speech-in speech-out conversational systems. However, existing multimodal models handling interleaved audio and text, such as MOSHI require complex multi stage training pipelines, incurring substantial computational costs. Moreover, these models uniformly apply autoregressive generation to both text and audio tokens, overlooking a fundamental asymmetry in their dependency structures: while text tokens exhibit strong target target dependencies requiring causal ordering, audio tokens are predominantly driven by source target dependencies, where audio outputs primarily condition on source text rather than preceding audio tokens. In this work, we propose TtT, a unified audio-text modeling framework that integrates AR text generation with non-autoregressive audio diffusion within a single Transformer architecture initialized from a pretrained LLM.",
        "tags": [
            "Diffusion",
            "LLM",
            "TTT",
            "Transformer"
        ]
    },
    {
        "id": "167",
        "title": "SHMoAReg: Spark Deformable Image Registration via Spatial Heterogeneous Mixture of Experts and Attention Heads",
        "author": [
            "Yuxi Zheng",
            "Jianhui Feng",
            "Tianran Li",
            "Marius Staring",
            "Yuchuan Qiao"
        ],
        "pdf": "https://arxiv.org/pdf/2509.20073",
        "abstract": "Encoder-Decoder architectures are widely used in deep learning-based Deformable Image Registration (DIR), where the encoder extracts multi-scale features and the decoder predicts deformation fields by recovering spatial locations. However, current methods lack specialized extraction of features (that are useful for registration) and predict deformation jointly and homogeneously in all three directions. In this paper, we propose a novel expert-guided DIR network with Mixture of Experts (MoE) mechanism applied in both encoder and decoder, named SHMoAReg. Specifically, we incorporate Mixture of Attention heads (MoA) into encoder layers, while Spatial Heterogeneous Mixture of Experts (SHMoE) into the decoder layers. The MoA enhances the specialization of feature extraction by dynamically selecting the optimal combination of attention heads for each image token. Meanwhile, the SHMoE predicts deformation fields heterogeneously in three directions for each voxel using experts with varying kernel sizes. Extensive experiments conducted on two publicly available datasets show consistent improvements over various methods, with a notable increase from 60.58% to 65.58% in Dice score for the abdominal CT dataset. Furthermore, SHMoAReg enhances model interpretability by differentiating experts' utilities across/within different resolution layers. To the best of our knowledge, we are the first to introduce MoE mechanism into DIR tasks. The code will be released soon.",
        "tags": [
            "MoE"
        ]
    },
    {
        "id": "168",
        "title": "Queryable 3D Scene Representation: A Multi-Modal Framework for Semantic Reasoning and Robotic Task Planning",
        "author": [
            "Xun Li",
            "Rodrigo Santa Cruz",
            "Mingze Xi",
            "Hu Zhang",
            "Madhawa Perera",
            "Ziwei Wang",
            "Ahalya Ravendran",
            "Brandon J. Matthews",
            "Feng Xu",
            "Matt Adcock",
            "Dadong Wang",
            "Jiajun Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2509.20077",
        "abstract": "To enable robots to comprehend high-level human instructions and perform complex tasks, a key challenge lies in achieving comprehensive scene understanding: interpreting and interacting with the 3D environment in a meaningful way. This requires a smart map that fuses accurate geometric structure with rich, human-understandable semantics. To address this, we introduce the 3D Queryable Scene Representation (3D QSR), a novel framework built on multimedia data that unifies three complementary 3D representations: (1) 3D-consistent novel view rendering and segmentation from panoptic reconstruction, (2) precise geometry from 3D point clouds, and (3) structured, scalable organization via 3D scene graphs. Built on an object-centric design, the framework integrates with large vision-language models to enable semantic queryability by linking multimodal object embeddings, and supporting object-level retrieval of geometric, visual, and semantic information. The retrieved data are then loaded into a robotic task planner for downstream execution. We evaluate our approach through simulated robotic task planning scenarios in Unity, guided by abstract language instructions and using the indoor public dataset Replica. Furthermore, we apply it in a digital duplicate of a real wet lab environment to test QSR-supported robotic task planning for emergency response. The results demonstrate the framework's ability to facilitate scene understanding and integrate spatial and semantic reasoning, effectively translating high-level human instructions into precise robotic task planning in complex 3D environments.",
        "tags": [
            "3D",
            "Segmentation",
            "VLM"
        ]
    },
    {
        "id": "169",
        "title": "C-3TO: Continuous 3D Trajectory Optimization on Neural Euclidean Signed Distance Fields",
        "author": [
            "Guillermo Gil",
            "Jose Antonio Cobano",
            "Luis Merino",
            "Fernando Caballero"
        ],
        "pdf": "https://arxiv.org/pdf/2509.20084",
        "abstract": "This paper introduces a novel framework for continuous 3D trajectory optimization in cluttered environments, leveraging online neural Euclidean Signed Distance Fields (ESDFs). Unlike prior approaches that rely on discretized ESDF grids with interpolation, our method directly optimizes smooth trajectories represented by fifth-order polynomials over a continuous neural ESDF, ensuring precise gradient information throughout the entire trajectory. The framework integrates a two-stage nonlinear optimization pipeline that balances efficiency, safety and smoothness. Experimental results demonstrate that C-3TO produces collision-aware and dynamically feasible trajectories. Moreover, its flexibility in defining local window sizes and optimization parameters enables straightforward adaptation to diverse user's needs without compromising performance. By combining continuous trajectory parameterization with a continuously updated neural ESDF, C-3TO establishes a robust and generalizable foundation for safe and efficient local replanning in aerial robotics.",
        "tags": [
            "3D",
            "Robotics"
        ]
    },
    {
        "id": "170",
        "title": "OLaPh: Optimal Language Phonemizer",
        "author": [
            "Johannes Wirth"
        ],
        "pdf": "https://arxiv.org/pdf/2509.20086",
        "abstract": "Phonemization, the conversion of text into phonemes, is a key step in text-to-speech. Traditional approaches use rule-based transformations and lexicon lookups, while more advanced methods apply preprocessing techniques or neural networks for improved accuracy on out-of-domain vocabulary. However, all systems struggle with names, loanwords, abbreviations, and homographs. This work presents OLaPh (Optimal Language Phonemizer), a framework that combines large lexica, multiple NLP techniques, and compound resolution with a probabilistic scoring function. Evaluations in German and English show improved accuracy over previous approaches, including on a challenging dataset. To further address unresolved cases, we train a large language model on OLaPh-generated data, which achieves even stronger generalization and performance. Together, the framework and LLM improve phonemization consistency and provide a freely available resource for future research.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "171",
        "title": "Causal Understanding by LLMs: The Role of Uncertainty",
        "author": [
            "Oscar Lithgow-Serrano",
            "Vani Kanjirangat",
            "Alessandro Antonucci"
        ],
        "pdf": "https://arxiv.org/pdf/2509.20088",
        "abstract": "Recent papers show LLMs achieve near-random accuracy in causal relation classification, raising questions about whether such failures arise from limited pretraining exposure or deeper representational gaps. We investigate this under uncertainty-based evaluation, testing whether pretraining exposure to causal examples improves causal understanding >18K PubMed sentences -- half from The Pile corpus, half post-2024 -- across seven models (Pythia-1.4B/7B/12B, GPT-J-6B, Dolly-7B/12B, Qwen-7B). We analyze model behavior through: (i) causal classification, where the model identifies causal relationships in text, and (ii) verbatim memorization probing, where we assess whether the model prefers previously seen causal statements over their paraphrases. Models perform four-way classification (direct/conditional/correlational/no-relationship) and select between originals and their generated paraphrases. Results show almost identical accuracy on seen/unseen sentences (p > 0.05), no memorization bias (24.8% original selection), and output distribution over the possible options is almost flat, with entropic values near the maximum (1.35/1.39), confirming random guessing. Instruction-tuned models show severe miscalibration (Qwen: > 95% confidence, 32.8% accuracy, ECE=0.49). Conditional relations induce highest entropy (+11% vs. direct). These findings suggest that failures in causal understanding arise from the lack of structured causal representation, rather than insufficient exposure to causal examples during pretraining.",
        "tags": [
            "GPT",
            "LLM",
            "Qwen"
        ]
    },
    {
        "id": "172",
        "title": "Unleashing the Potential of the Semantic Latent Space in Diffusion Models for Image Dehazing",
        "author": [
            "Zizheng Yang",
            "Hu Yu",
            "Bing Li",
            "Jinghao Zhang",
            "Jie Huang",
            "Feng Zhao"
        ],
        "pdf": "https://arxiv.org/pdf/2509.20091",
        "abstract": "Diffusion models have recently been investigated as powerful generative solvers for image dehazing, owing to their remarkable capability to model the data distribution. However, the massive computational burden imposed by the retraining of diffusion models, coupled with the extensive sampling steps during the inference, limit the broader application of diffusion models in image dehazing. To address these issues, we explore the properties of hazy images in the semantic latent space of frozen pre-trained diffusion models, and propose a Diffusion Latent Inspired network for Image Dehazing, dubbed DiffLI$^2$D. Specifically, we first reveal that the semantic latent space of pre-trained diffusion models can represent the content and haze characteristics of hazy images, as the diffusion time-step changes. Building upon this insight, we integrate the diffusion latent representations at different time-steps into a delicately designed dehazing network to provide instructions for image dehazing. Our DiffLI$^2$D avoids re-training diffusion models and iterative sampling process by effectively utilizing the informative representations derived from the pre-trained diffusion models, which also offers a novel perspective for introducing diffusion models to image dehazing. Extensive experiments on multiple datasets demonstrate that the proposed method achieves superior performance to existing image dehazing methods. Code is available at https://github.com/aaaasan111/difflid.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "173",
        "title": "Integrated Framework for LLM Evaluation with Answer Generation",
        "author": [
            "Sujeong Lee",
            "Hayoung Lee",
            "Seongsoo Heo",
            "Wonik Choi"
        ],
        "pdf": "https://arxiv.org/pdf/2509.20097",
        "abstract": "Reliable evaluation of large language models is essential to ensure their applicability in practical scenarios. Traditional benchmark-based evaluation methods often rely on fixed reference answers, limiting their ability to capture important qualitative aspects of generated responses. To address these shortcomings, we propose an integrated evaluation framework called \\textit{self-refining descriptive evaluation with expert-driven diagnostics}, SPEED, which utilizes specialized functional experts to perform comprehensive, descriptive analyses of model outputs. Unlike conventional approaches, SPEED actively incorporates expert feedback across multiple dimensions, including hallucination detection, toxicity assessment, and lexical-contextual appropriateness. Experimental results demonstrate that SPEED achieves robust and consistent evaluation performance across diverse domains and datasets. Additionally, by employing relatively compact expert models, SPEED demonstrates superior resource efficiency compared to larger-scale evaluators. These findings illustrate that SPEED significantly enhances fairness and interpretability in LLM evaluations, offering a promising alternative to existing evaluation methodologies.",
        "tags": [
            "Detection",
            "LLM"
        ]
    },
    {
        "id": "174",
        "title": "Incomplete Data, Complete Dynamics: A Diffusion Approach",
        "author": [
            "Zihan Zhou",
            "Chenguang Wang",
            "Hongyi Ye",
            "Yongtao Guan",
            "Tianshu Yu"
        ],
        "pdf": "https://arxiv.org/pdf/2509.20098",
        "abstract": "Learning physical dynamics from data is a fundamental challenge in machine learning and scientific modeling. Real-world observational data are inherently incomplete and irregularly sampled, posing significant challenges for existing data-driven approaches. In this work, we propose a principled diffusion-based framework for learning physical systems from incomplete training samples. To this end, our method strategically partitions each such sample into observed context and unobserved query components through a carefully designed splitting strategy, then trains a conditional diffusion model to reconstruct the missing query portions given available contexts. This formulation enables accurate imputation across arbitrary observation patterns without requiring complete data supervision. Specifically, we provide theoretical analysis demonstrating that our diffusion training paradigm on incomplete data achieves asymptotic convergence to the true complete generative process under mild regularity conditions. Empirically, we show that our method significantly outperforms existing baselines on synthetic and real-world physical dynamics benchmarks, including fluid flows and weather systems, with particularly strong performance in limited and irregular observation regimes. These results demonstrate the effectiveness of our theoretically principled approach for learning and imputing partially observed dynamics.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "175",
        "title": "PEPS: Quantum-Inspired Reinforcement Learning for Coherent Reasoning Traces in LLMs",
        "author": [
            "Venkat Margapuri",
            "Garik Kazanjian",
            "Naren Kosaraju"
        ],
        "pdf": "https://arxiv.org/pdf/2509.20105",
        "abstract": "Large Language Models (LLMs) often struggle with maintaining coherent multi-step reasoning traces, particularly in tasks that require a structured logical flow. This work introduces a quantum-inspired approach to address the challenge by incorporating a fidelity-based reward derived from Projected Entangled Pair States (PEPS) into Proximal Policy Optimization. Unlike prior approaches that use direct supervision or contrastive objectives, the proposed method guides learning through structural consistency, offering a novel approach to enforce global coherence in generated reasoning traces. The proposed framework is evaluated using multiple coherence-determining metrics on diverse datasets such as GSM8K, StrategyQA, and EntailmentBank spanning arithmetic, intuitive, and entailment-based reasoning. Results show that the proposed quantum-inspired approach offers significant improvements over supervised, contrastive, and pretrained baseline approaches, highlighting the effectiveness of quantum-inspired fidelity as a foundation to improve reasoning trace coherence in LLMs.",
        "tags": [
            "LLM",
            "RL"
        ]
    },
    {
        "id": "176",
        "title": "Hyperspectral Adapter for Semantic Segmentation with Vision Foundation Models",
        "author": [
            "JuanaJuana Valeria Hurtado",
            "Rohit Mohan",
            "Abhinav Valada"
        ],
        "pdf": "https://arxiv.org/pdf/2509.20107",
        "abstract": "Hyperspectral imaging (HSI) captures spatial information along with dense spectral measurements across numerous narrow wavelength bands. This rich spectral content has the potential to facilitate robust robotic perception, particularly in environments with complex material compositions, varying illumination, or other visually challenging conditions. However, current HSI semantic segmentation methods underperform due to their reliance on architectures and learning frameworks optimized for RGB inputs. In this work, we propose a novel hyperspectral adapter that leverages pretrained vision foundation models to effectively learn from hyperspectral data. Our architecture incorporates a spectral transformer and a spectrum-aware spatial prior module to extract rich spatial-spectral features. Additionally, we introduce a modality-aware interaction block that facilitates effective integration of hyperspectral representations and frozen vision Transformer features through dedicated extraction and injection mechanisms. Extensive evaluations on three benchmark autonomous driving datasets demonstrate that our architecture achieves state-of-the-art semantic segmentation performance while directly using HSI inputs, outperforming both vision-based and hyperspectral segmentation methods. We make the code available at https://hyperspectraladapter.cs.uni-freiburg.de.",
        "tags": [
            "Segmentation",
            "Transformer",
            "ViT"
        ]
    },
    {
        "id": "177",
        "title": "Discrete Diffusion for Reflective Vision-Language-Action Models in Autonomous Driving",
        "author": [
            "Pengxiang Li",
            "Yinan Zheng",
            "Yue Wang",
            "Huimin Wang",
            "Hang Zhao",
            "Jingjing Liu",
            "Xianyuan Zhan",
            "Kun Zhan",
            "Xianpeng Lang"
        ],
        "pdf": "https://arxiv.org/pdf/2509.20109",
        "abstract": "End-to-End (E2E) solutions have emerged as a mainstream approach for autonomous driving systems, with Vision-Language-Action (VLA) models representing a new paradigm that leverages pre-trained multimodal knowledge from Vision-Language Models (VLMs) to interpret and interact with complex real-world environments. However, these methods remain constrained by the limitations of imitation learning, which struggles to inherently encode physical rules during training. Existing approaches often rely on complex rule-based post-refinement, employ reinforcement learning that remains largely limited to simulation, or utilize diffusion guidance that requires computationally expensive gradient calculations. To address these challenges, we introduce ReflectDrive, a novel learning-based framework that integrates a reflection mechanism for safe trajectory generation via discrete diffusion. We first discretize the two-dimensional driving space to construct an action codebook, enabling the use of pre-trained Diffusion Language Models for planning tasks through fine-tuning. Central to our approach is a safety-aware reflection mechanism that performs iterative self-correction without gradient computation. Our method begins with goal-conditioned trajectory generation to model multi-modal driving behaviors. Based on this, we apply local search methods to identify unsafe tokens and determine feasible solutions, which then serve as safe anchors for inpainting-based regeneration. Evaluated on the NAVSIM benchmark, ReflectDrive demonstrates significant advantages in safety-critical trajectory generation, offering a scalable and reliable solution for autonomous driving systems.",
        "tags": [
            "Diffusion",
            "Inpainting",
            "RL",
            "VLM"
        ]
    },
    {
        "id": "178",
        "title": "Comparative Study of Subjective Video Quality Assessment Test Methods in Crowdsourcing for Varied Use Cases",
        "author": [
            "Babak Naderi",
            "Ross Cutler"
        ],
        "pdf": "https://arxiv.org/pdf/2509.20118",
        "abstract": "In crowdsourced subjective video quality assessment, practitioners often face a choice between Absolute Category Rating (ACR), ACR with Hidden Reference (ACR-HR), and Comparison Category Rating (CCR). We conducted a P.910-compliant, side-by-side comparison across six studies using 15 talking-head sources of good and fair quality, processed with realistic degradations (blur, scaling, compression, freezing, and their combinations), as well as a practical bitrate-ladder task at 720p and 1080p resolutions. We evaluated statistical efficiency (standard deviations), economic efficiency, and decision agreement. Our results show that ACR-HR and ACR correlate strongly at the condition level, while CCR is more sensitive-capturing improvements beyond the reference. ACR-HR, however, exhibits compressed scale use, particularly for videos with fair source quality. ACR-HR is approximately twice as fast and cost-effective, with lower normalized variability, yet the choice of quality measurement method shifts saturation points and bitrate-ladder recommendations. Finally, we provide practical guidance on when to use each test method.",
        "tags": [
            "Talking Head"
        ]
    },
    {
        "id": "179",
        "title": "A Simple Data Augmentation Strategy for Text-in-Image Scientific VQA",
        "author": [
            "Belal Shoer",
            "Yova Kementchedjhieva"
        ],
        "pdf": "https://arxiv.org/pdf/2509.20119",
        "abstract": "Scientific visual question answering poses significant challenges for vision-language models due to the complexity of scientific figures and their multimodal context. Traditional approaches treat the figure and accompanying text (e.g., questions and answer options) as separate inputs. EXAMS-V introduced a new paradigm by embedding both visual and textual content into a single image. However, even state-of-the-art proprietary models perform poorly on this setup in zero-shot settings, underscoring the need for task-specific fine-tuning. To address the scarcity of training data in this \"text-in-image\" format, we synthesize a new dataset by converting existing separate image-text pairs into unified images. Fine-tuning a small multilingual multimodal model on a mix of our synthetic data and EXAMS-V yields notable gains across 13 languages, demonstrating strong average improvements and cross-lingual transfer.",
        "tags": [
            "VLM"
        ]
    },
    {
        "id": "180",
        "title": "Can LLMs Forecast Internet Traffic from Social Media?",
        "author": [
            "Jonatan Langlet",
            "Mariano Scazzariello",
            "Flavio Luciani",
            "Marta Burocchi",
            "Dejan KostiÄ",
            "Marco Chiesa"
        ],
        "pdf": "https://arxiv.org/pdf/2509.20123",
        "abstract": "Societal events shape the Internet's behavior. The death of a prominent public figure, a software launch, or a major sports match can trigger sudden demand surges that overwhelm peering points and content delivery networks. Although these events fall outside regular traffic patterns, forecasting systems still rely solely on those patterns and therefore miss these critical anomalies.\nThus, we argue for socio-technical systems that supplement technical measurements with an active understanding of the underlying drivers, including how events and collective behavior shape digital demands. We propose traffic forecasting using signals from public discourse, such as headlines, forums, and social media, as early demand indicators.\nTo validate our intuition, we present a proof-of-concept system that autonomously scrapes online discussions, infers real-world events, clusters and enriches them semantically, and correlates them with traffic measurements at a major Internet Exchange Point. This prototype predicted between 56-92% of society-driven traffic spikes after scraping a moderate amount of online discussions.\nWe believe this approach opens new research opportunities in cross-domain forecasting, scheduling, demand anticipation, and society-informed decision making.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "181",
        "title": "Probability Signature: Bridging Data Semantics and Embedding Structure in Language Models",
        "author": [
            "Junjie Yao",
            "Zhi-Qin John Xu"
        ],
        "pdf": "https://arxiv.org/pdf/2509.20124",
        "abstract": "The embedding space of language models is widely believed to capture the semantic relationships; for instance, embeddings of digits often exhibit an ordered structure that corresponds to their natural sequence. However, the mechanisms driving the formation of such structures remain poorly understood. In this work, we interpret the embedding structures via the data distribution. We propose a set of probability signatures that reflect the semantic relationships among tokens. Through experiments on the composite addition tasks using the linear model and feedforward network, combined with theoretical analysis of gradient flow dynamics, we reveal that these probability signatures significantly influence the embedding structures. We further generalize our analysis to large language models (LLMs) by training the Qwen2.5 architecture on the subsets of the Pile corpus. Our results show that the probability signatures are faithfully aligned with the embedding structures, particularly in capturing strong pairwise similarities among embeddings. Our work uncovers the mechanism of how data distribution guides the formation of embedding structures, establishing a novel understanding of the relationship between embedding organization and semantic patterns.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "182",
        "title": "KSDiff: Keyframe-Augmented Speech-Aware Dual-Path Diffusion for Facial Animation",
        "author": [
            "Tianle Lyu",
            "Junchuan Zhao",
            "Ye Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2509.20128",
        "abstract": "Audio-driven facial animation has made significant progress in multimedia applications, with diffusion models showing strong potential for talking-face synthesis. However, most existing works treat speech features as a monolithic representation and fail to capture their fine-grained roles in driving different facial motions, while also overlooking the importance of modeling keyframes with intense dynamics. To address these limitations, we propose KSDiff, a Keyframe-Augmented Speech-Aware Dual-Path Diffusion framework. Specifically, the raw audio and transcript are processed by a Dual-Path Speech Encoder (DPSE) to disentangle expression-related and head-pose-related features, while an autoregressive Keyframe Establishment Learning (KEL) module predicts the most salient motion frames. These components are integrated into a Dual-path Motion generator to synthesize coherent and realistic facial motions. Extensive experiments on HDTF and VoxCeleb demonstrate that KSDiff achieves state-of-the-art performance, with improvements in both lip synchronization accuracy and head-pose naturalness. Our results highlight the effectiveness of combining speech disentanglement with keyframe-aware diffusion for talking-head generation.",
        "tags": [
            "Diffusion",
            "Talking Face",
            "Talking Head"
        ]
    },
    {
        "id": "183",
        "title": "V-GameGym: Visual Game Generation for Code Large Language Models",
        "author": [
            "Wei Zhang",
            "Jack Yang",
            "Renshuai Tao",
            "Lingzheng Chai",
            "Shawn Guo",
            "Jiajun Wu",
            "Xiaoming Chen",
            "Ganqu Cui",
            "Ning Ding",
            "Xander Xu",
            "Hu Wei",
            "Bowen Zhou"
        ],
        "pdf": "https://arxiv.org/pdf/2509.20136",
        "abstract": "Code large language models have demonstrated remarkable capabilities in programming tasks, yet current benchmarks primarily focus on single modality rather than visual game development. Most existing code-related benchmarks evaluate syntax correctness and execution accuracy, overlooking critical game-specific metrics such as playability, visual aesthetics, and user engagement that are essential for real-world deployment. To address the gap between current LLM capabilities in algorithmic problem-solving and competitive programming versus the comprehensive requirements of practical game development, we present V-GameGym, a comprehensive benchmark comprising 2,219 high-quality samples across 100 thematic clusters derived from real-world repositories, adopting a novel clustering-based curation methodology to ensure both diversity and structural completeness. Further, we introduce a multimodal evaluation framework with an automated LLM-driven pipeline for visual code synthesis using complete UI sandbox environments. Our extensive analysis reveals that V-GameGym effectively bridges the gap between code generation accuracy and practical game development workflows, providing quantifiable quality metrics for visual programming and interactive element generation.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "184",
        "title": "Enhancing Requirement Traceability through Data Augmentation Using Large Language Models",
        "author": [
            "Jianzhang Zhang",
            "Jialong Zhou",
            "Nan Niu",
            "Chuang Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2509.20149",
        "abstract": "Requirements traceability is crucial in software engineering to ensure consistency between requirements and code. However, existing automated traceability methods are constrained by the scarcity of training data and challenges in bridging the semantic gap between artifacts. This study aims to address the data scarcity problem in requirements traceability by employing large language models (LLMs) for data augmentation. We propose a novel approach that utilizes prompt-based techniques with LLMs to generate augmented requirement-to-code trace links, thereby enhancing the training dataset. Four LLMs (Gemini 1.5 Pro, Claude 3, GPT-3.5, and GPT-4) were used, employing both zero-shot and few-shot templates. Moreover, we optimized the encoder component of the tracing model to improve its efficiency and adaptability to augmented data. The key contributions of this paper are: (1) proposing and evaluating four prompt templates for data augmentation; (2) providing a comparative analysis of four LLMs for generating trace links; (3) enhancing the model's encoder for improved adaptability to augmented datasets. Experimental results show that our approach significantly enhances model performance, achieving an F1 score improvement of up to 28.59%, thus demonstrating its effectiveness and potential for practical application.",
        "tags": [
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "185",
        "title": "Affective Computing and Emotional Data: Challenges and Implications in Privacy Regulations, The AI Act, and Ethics in Large Language Models",
        "author": [
            "Nicola Fabiano"
        ],
        "pdf": "https://arxiv.org/pdf/2509.20153",
        "abstract": "This paper examines the integration of emotional intelligence into artificial intelligence systems, with a focus on affective computing and the growing capabilities of Large Language Models (LLMs), such as ChatGPT and Claude, to recognize and respond to human emotions. Drawing on interdisciplinary research that combines computer science, psychology, and neuroscience, the study analyzes foundational neural architectures - CNNs for processing facial expressions and RNNs for sequential data, such as speech and text - that enable emotion recognition. It examines the transformation of human emotional experiences into structured emotional data, addressing the distinction between explicit emotional data collected with informed consent in research settings and implicit data gathered passively through everyday digital interactions. That raises critical concerns about lawful processing, AI transparency, and individual autonomy over emotional expressions in digital environments. The paper explores implications across various domains, including healthcare, education, and customer service, while addressing challenges of cultural variations in emotional expression and potential biases in emotion recognition systems across different demographic groups. From a regulatory perspective, the paper examines emotional data in the context of the GDPR and the EU AI Act frameworks, highlighting how emotional data may be considered sensitive personal data that requires robust safeguards, including purpose limitation, data minimization, and meaningful consent mechanisms.",
        "tags": [
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "186",
        "title": "CyberSOCEval: Benchmarking LLMs Capabilities for Malware Analysis and Threat Intelligence Reasoning",
        "author": [
            "Lauren Deason",
            "Adam Bali",
            "Ciprian Bejean",
            "Diana Bolocan",
            "James Crnkovich",
            "Ioana Croitoru",
            "Krishna Durai",
            "Chase Midler",
            "Calin Miron",
            "David Molnar",
            "Brad Moon",
            "Bruno Ostarcevic",
            "Alberto Peltea",
            "Matt Rosenberg",
            "Catalin Sandu",
            "Arthur Saputkin",
            "Sagar Shah",
            "Daniel Stan",
            "Ernest Szocs",
            "Shengye Wan",
            "Spencer Whitman",
            "Sven Krasser",
            "Joshua Saxe"
        ],
        "pdf": "https://arxiv.org/pdf/2509.20166",
        "abstract": "Today's cyber defenders are overwhelmed by a deluge of security alerts, threat intelligence signals, and shifting business context, creating an urgent need for AI systems to enhance operational security work. While Large Language Models (LLMs) have the potential to automate and scale Security Operations Center (SOC) operations, existing evaluations do not fully assess the scenarios most relevant to real-world defenders. This lack of informed evaluation impacts both AI developers and those applying LLMs to SOC automation. Without clear insight into LLM performance in real-world security scenarios, developers lack a north star for development, and users cannot reliably select the most effective models. Meanwhile, malicious actors are using AI to scale cyber attacks, highlighting the need for open source benchmarks to drive adoption and community-driven improvement among defenders and model developers. To address this, we introduce CyberSOCEval, a new suite of open source benchmarks within CyberSecEval 4. CyberSOCEval includes benchmarks tailored to evaluate LLMs in two tasks: Malware Analysis and Threat Intelligence Reasoning--core defensive domains with inadequate coverage in current benchmarks. Our evaluations show that larger, more modern LLMs tend to perform better, confirming the training scaling laws paradigm. We also find that reasoning models leveraging test time scaling do not achieve the same boost as in coding and math, suggesting these models have not been trained to reason about cybersecurity analysis, and pointing to a key opportunity for improvement. Finally, current LLMs are far from saturating our evaluations, showing that CyberSOCEval presents a significant challenge for AI developers to improve cyber defense capabilities.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "187",
        "title": "Probing Gender Bias in Multilingual LLMs: A Case Study of Stereotypes in Persian",
        "author": [
            "Ghazal Kalhor",
            "Behnam Bahrak"
        ],
        "pdf": "https://arxiv.org/pdf/2509.20168",
        "abstract": "Multilingual Large Language Models (LLMs) are increasingly used worldwide, making it essential to ensure they are free from gender bias to prevent representational harm. While prior studies have examined such biases in high-resource languages, low-resource languages remain understudied. In this paper, we propose a template-based probing methodology, validated against real-world data, to uncover gender stereotypes in LLMs. As part of this framework, we introduce the Domain-Specific Gender Skew Index (DS-GSI), a metric that quantifies deviations from gender parity. We evaluate four prominent models, GPT-4o mini, DeepSeek R1, Gemini 2.0 Flash, and Qwen QwQ 32B, across four semantic domains, focusing on Persian, a low-resource language with distinct linguistic features. Our results show that all models exhibit gender stereotypes, with greater disparities in Persian than in English across all domains. Among these, sports reflect the most rigid gender biases. This study underscores the need for inclusive NLP practices and provides a framework for assessing bias in other low-resource languages.",
        "tags": [
            "DeepSeek",
            "GPT",
            "LLM",
            "Qwen"
        ]
    },
    {
        "id": "188",
        "title": "Benchmarking Web API Integration Code Generation",
        "author": [
            "Daniel Maninger",
            "Leon Chemnitz",
            "Amir Molzam Sharifloo",
            "Jannis Brugger",
            "Mira Mezini"
        ],
        "pdf": "https://arxiv.org/pdf/2509.20172",
        "abstract": "API integration is a cornerstone of our digital infrastructure, enabling software systems to connect and interact. However, as shown by many studies, writing or generating correct code to invoke APIs, particularly web APIs, is challenging. Although large language models~(LLMs) have become popular in software development, their effectiveness in automating the generation of web API integration code remains unexplored. In order to address this, we present a dataset and evaluation pipeline designed to assess the ability of LLMs to generate web API invocation code. Our experiments with several open-source LLMs reveal that generating API invocations poses a significant challenge, resulting in hallucinated endpoints, incorrect argument usage, and other errors. None of the evaluated open-source models were able to solve more than 40% of the tasks.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "189",
        "title": "Thinking Augmented Pre-training",
        "author": [
            "Liang Wang",
            "Nan Yang",
            "Shaohan Huang",
            "Li Dong",
            "Furu Wei"
        ],
        "pdf": "https://arxiv.org/pdf/2509.20186",
        "abstract": "This paper introduces a simple and scalable approach to improve the data efficiency of large language model (LLM) training by augmenting existing text data with thinking trajectories. The compute for pre-training LLMs has been growing at an unprecedented rate, while the availability of high-quality data remains limited. Consequently, maximizing the utility of available data constitutes a significant research challenge. A primary impediment is that certain high-quality tokens are difficult to learn given a fixed model capacity, as the underlying rationale for a single token can be exceptionally complex and deep. To address this issue, we propose Thinking augmented Pre-Training (TPT), a universal methodology that augments text with automatically generated thinking trajectories. Such augmentation effectively increases the volume of the training data and makes high-quality tokens more learnable through step-by-step reasoning and decomposition. We apply TPT across diverse training configurations up to $100$B tokens, encompassing pre-training with both constrained and abundant data, as well as mid-training from strong open-source checkpoints. Experimental results indicate that our method substantially improves the performance of LLMs across various model sizes and families. Notably, TPT enhances the data efficiency of LLM pre-training by a factor of $3$. For a $3$B parameter model, it improves the post-training performance by over $10\\%$ on several challenging reasoning benchmarks.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "190",
        "title": "STAF: Leveraging LLMs for Automated Attack Tree-Based Security Test Generation",
        "author": [
            "Tanmay Khule",
            "Stefan Marksteiner",
            "Jose Alguindigue",
            "Hannes Fuchs",
            "Sebastian Fischmeister",
            "Apurva Narayan"
        ],
        "pdf": "https://arxiv.org/pdf/2509.20190",
        "abstract": "In modern automotive development, security testing is critical for safeguarding systems against increasingly advanced threats. Attack trees are widely used to systematically represent potential attack vectors, but generating comprehensive test cases from these trees remains a labor-intensive, error-prone task that has seen limited automation in the context of testing vehicular systems. This paper introduces STAF (Security Test Automation Framework), a novel approach to automating security test case generation. Leveraging Large Language Models (LLMs) and a four-step self-corrective Retrieval-Augmented Generation (RAG) framework, STAF automates the generation of executable security test cases from attack trees, providing an end-to-end solution that encompasses the entire attack surface. We particularly show the elements and processes needed to provide an LLM to actually produce sensible and executable automotive security test suites, along with the integration with an automated testing framework. We further compare our tailored approach with general purpose (vanilla) LLMs and the performance of different LLMs (namely GPT-4.1 and DeepSeek) using our approach. We also demonstrate the method of our operation step-by-step in a concrete case study. Our results show significant improvements in efficiency, accuracy, scalability, and easy integration in any workflow, marking a substantial advancement in automating automotive security testing methodologies. Using TARAs as an input for verfication tests, we create synergies by connecting two vital elements of a secure automotive development process.",
        "tags": [
            "DeepSeek",
            "GPT",
            "LLM",
            "RAG"
        ]
    },
    {
        "id": "191",
        "title": "Play by the Type Rules: Inferring Constraints for LLM Functions in Declarative Programs",
        "author": [
            "Parker Glenn",
            "Alfy Samuel",
            "Daben Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2509.20208",
        "abstract": "Integrating LLM powered operators in declarative query languages allows for the combination of cheap and interpretable functions with powerful, generalizable language model reasoning. However, in order to benefit from the optimized execution of a database query language like SQL, generated outputs must align with the rules enforced by both type checkers and database contents. Current approaches address this challenge with orchestrations consisting of many LLM-based post-processing calls to ensure alignment between generated outputs and database values, introducing performance bottlenecks. We perform a study on the ability of various sized open-source language models to both parse and execute functions within a query language based on SQL, showing that small language models can excel as function executors over hybrid data sources. Then, we propose an efficient solution to enforce the well-typedness of LLM functions, demonstrating 7% accuracy improvement on a multi-hop question answering dataset with 53% improvement in latency over comparable solutions. We make our implementation available at https://github.com/parkervg/blendsql",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "192",
        "title": "Q-Palette: Fractional-Bit Quantizers Toward Optimal Bit Allocation for Efficient LLM Deployment",
        "author": [
            "Deokjae Lee",
            "Hyun Oh Song"
        ],
        "pdf": "https://arxiv.org/pdf/2509.20214",
        "abstract": "We study weight-only post-training quantization (PTQ), which quantizes the weights of a large language model (LLM) without retraining, using little or no calibration data. Weight-only PTQ is crucial for reducing the memory footprint and latency of LLM inference, especially in memory-bound, small-batch inference scenarios, such as personalized inference on edge devices. Despite its importance, irregular weight distributions with heavy-tailed outliers in LLMs complicate quantization, recently motivating rotation-based methods that transform weights into near-Gaussian distributions, which are more regular with fewer outliers, thereby reducing quantization error. In this work, we first derive the information-theoretically optimal bit allocation for Gaussianized weights under given bit budgets, revealing that fine-grained fractional-bit quantizers approaching the Gaussian distortion-rate bound are essential to achieve near-optimal quantization performance. To bridge this theoretical insight and practical implementation, we introduce Q-Palette, a versatile collection of fractional-bit quantizers that range from trellis-coded quantizers offering near-optimal distortion to simpler vector and scalar quantizers optimized for faster inference, all efficiently implemented with optimized CUDA kernels across various bitwidths. Furthermore, leveraging Q-Palette as a foundational component, we propose a novel mixed-scheme quantization framework, jointly optimizing quantizer choices and layer fusion decisions given resource constraints. The code is available at https://github.com/snu-mllab/Q-Palette.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "193",
        "title": "The Cream Rises to the Top: Efficient Reranking Method for Verilog Code Generation",
        "author": [
            "Guang Yang",
            "Wei Zheng",
            "Xiang Chen",
            "Yifan Sun",
            "Fengji Zhang",
            "Terry Yue Zhuo"
        ],
        "pdf": "https://arxiv.org/pdf/2509.20215",
        "abstract": "LLMs face significant challenges in Verilog generation due to limited domain-specific knowledge. While sampling techniques improve pass@k metrics, hardware engineers need one trustworthy solution rather than uncertain candidates. To bridge this gap, we formulate it as a semantic alignment problem between requirements and Verilog implementations, and propose VCD-RNK, a discriminator model tailored for efficient Verilog code reranking. Specifically, VCD-RNKincorporates Verilog-specific reasoning by distilling expert knowledge across three dimensions: code semantic analysis, test case generation, and functional correctness assessment. By explicitly simulating the above reasoning processes during inference, VCD-RNK effectively avoids computationally intensive test execution in existing methods.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "194",
        "title": "Techno-Economic analysis for Smart Hangar inspection operations through Sensing and Localisation at scale",
        "author": [
            "Angelos Plastropoulos",
            "Nicolas P. Avdelidis",
            "Argyrios Zolotas"
        ],
        "pdf": "https://arxiv.org/pdf/2509.20229",
        "abstract": "The accuracy, resilience, and affordability of localisation are fundamental to autonomous robotic inspection within aircraft maintenance and overhaul (MRO) hangars. Hangars typically feature tall ceilings and are often made of materials such as metal. Due to its nature, it is considered a GPS-denied environment, with extensive multipath effects and stringent operational constraints that collectively create a uniquely challenging environment. This persistent gap highlights the need for domain-specific comparative studies, including rigorous cost, accuracy, and integration assessments, to inform a reliable and scalable deployment of a localisation system in the Smart Hangar. This paper presents the first techno-economic roadmap that benchmarks motion capture (MoCap), ultra-wideband (UWB), and a ceiling-mounted camera network across three operational scenarios: robot localisation, asset tracking, and surface defect detection within a 40x50 m hangar bay. A dual-layer optimisation for camera selection and positioning framework is introduced, which couples market-based camera-lens selection with an optimisation solver, producing camera layouts that minimise hardware while meeting accuracy targets. The roadmap equips MRO planners with an actionable method to balance accuracy, coverage, and budget, demonstrating that an optimised vision architecture has the potential to unlock robust and cost-effective sensing for next-generation Smart Hangars.",
        "tags": [
            "Detection",
            "Robotics"
        ]
    },
    {
        "id": "195",
        "title": "Beyond Sharp Minima: Robust LLM Unlearning via Feedback-Guided Multi-Point Optimization",
        "author": [
            "Wenhan Wu",
            "Zheyuan Liu",
            "Chongyang Gao",
            "Ren Wang",
            "Kaize Ding"
        ],
        "pdf": "https://arxiv.org/pdf/2509.20230",
        "abstract": "Current LLM unlearning methods face a critical security vulnerability that undermines their fundamental purpose: while they appear to successfully remove sensitive or harmful knowledge, this ``forgotten\" information remains precariously recoverable through relearning attacks. We identify that the root cause is that conventional methods optimizing the forgetting loss at individual data points will drive model parameters toward sharp minima in the loss landscape. In these unstable regions, even minimal parameter perturbations can drastically alter the model's behaviors. Consequently, relearning attacks exploit this vulnerability by using just a few fine-tuning samples to navigate the steep gradients surrounding these unstable regions, thereby rapidly recovering knowledge that was supposedly erased. This exposes a critical robustness gap between apparent unlearning and actual knowledge removal. To address this issue, we propose StableUN, a bi-level feedback-guided optimization framework that explicitly seeks more stable parameter regions via neighborhood-aware optimization. It integrates forgetting feedback, which uses adversarial perturbations to probe parameter neighborhoods, with remembering feedback to preserve model utility, aligning the two objectives through gradient projection. Experiments on WMDP and MUSE benchmarks demonstrate that our method is significantly more robust against both relearning and jailbreaking attacks while maintaining competitive utility performance.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "196",
        "title": "Investigating the Representation of Backchannels and Fillers in Fine-tuned Language Models",
        "author": [
            "Yu Wang",
            "Leyi Lao",
            "Langchu Huang",
            "Gabriel Skantze",
            "Yang Xu",
            "Hendrik Buschmeier"
        ],
        "pdf": "https://arxiv.org/pdf/2509.20237",
        "abstract": "Backchannels and fillers are important linguistic expressions in dialogue, but are under-represented in modern transformer-based language models (LMs). Our work studies the representation of them in language models using three fine-tuning strategies. The models are trained on three dialogue corpora in English and Japanese, where backchannels and fillers are preserved and annotated, to investigate how fine-tuning can help LMs learn their representations. We first apply clustering analysis to the learnt representation of backchannels and fillers, and have found increased silhouette scores in representations from fine-tuned models, which suggests that fine-tuning enables LMs to distinguish the nuanced semantic variation in different backchannel and filler use. We also use natural language generation (NLG) metrics to confirm that the utterances generated by fine-tuned language models resemble human-produced utterances more closely. Our findings suggest the potentials of transforming general LMs into conversational LMs that are more capable of producing human-like languages adequately.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "197",
        "title": "Energy Use of AI Inference: Efficiency Pathways and Test-Time Compute",
        "author": [
            "Felipe Oviedo",
            "Fiodar Kazhamiaka",
            "Esha Choukse",
            "Allen Kim",
            "Amy Luers",
            "Melanie Nakagawa",
            "Ricardo Bianchini",
            "Juan M. Lavista Ferres"
        ],
        "pdf": "https://arxiv.org/pdf/2509.20241",
        "abstract": "As AI inference scales to billions of queries and emerging reasoning and agentic workflows increase token demand, reliable estimates of per-query energy use are increasingly important for capacity planning, emissions accounting, and efficiency prioritization. Many public estimates are inconsistent and overstate energy use, because they extrapolate from limited benchmarks and fail to reflect efficiency gains achievable at scale. In this perspective, we introduce a bottom-up methodology to estimate the per-query energy of large-scale LLM systems based on token throughput. For models running on an H100 node under realistic workloads, GPU utilization and PUE constraints, we estimate a median energy per query of 0.34 Wh (IQR: 0.18-0.67) for frontier-scale models (>200 billion parameters). These results are consistent with measurements using production-scale configurations and show that non-production estimates and assumptions can overstate energy use by 4-20x. Extending to test-time scaling scenarios with 15x more tokens per typical query, the median energy rises 13x to 4.32 Wh, indicating that targeting efficiency in this regime will deliver the largest fleet-wide savings. We quantify achievable efficiency gains at the model, serving platform, and hardware levels, finding individual median reductions of 1.5-3.5x in energy per query, while combined advances can plausibly deliver 8-20x reductions. To illustrate the system-level impact, we estimate the baseline daily energy use of a deployment serving 1 billion queries to be 0.8 GWh/day. If 10% are long queries, demand could grow to 1.8 GWh/day. With targeted efficiency interventions, it falls to 0.9 GWh/day, similar to the energy footprint of web search at that scale. This echoes how data centers historically tempered energy growth through efficiency gains during the internet and cloud build-up.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "198",
        "title": "Dynamic Lagging for Time-Series Forecasting in E-Commerce Finance: Mitigating Information Loss with A Hybrid ML Architecture",
        "author": [
            "Abhishek Sharma",
            "Anat Parush",
            "Sumit Wadhwa",
            "Amihai Savir",
            "Anne Guinard",
            "Prateek Srivastava"
        ],
        "pdf": "https://arxiv.org/pdf/2509.20244",
        "abstract": "Accurate forecasting in the e-commerce finance domain is particularly challenging due to irregular invoice schedules, payment deferrals, and user-specific behavioral variability. These factors, combined with sparse datasets and short historical windows, limit the effectiveness of conventional time-series methods. While deep learning and Transformer-based models have shown promise in other domains, their performance deteriorates under partial observability and limited historical data. To address these challenges, we propose a hybrid forecasting framework that integrates dynamic lagged feature engineering and adaptive rolling-window representations with classical statistical models and ensemble learners. Our approach explicitly incorporates invoice-level behavioral modeling, structured lag of support data, and custom stability-aware loss functions, enabling robust forecasts in sparse and irregular financial settings. Empirical results demonstrate an approximate 5% reduction in MAPE compared to baseline models, translating into substantial financial savings. Furthermore, the framework enhances forecast stability over quarterly horizons and strengthens feature target correlation by capturing both short- and long-term patterns, leveraging user profile attributes, and simulating upcoming invoice behaviors. These findings underscore the value of combining structured lagging, invoice-level closure modeling, and behavioral insights to advance predictive accuracy in sparse financial time-series forecasting.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "199",
        "title": "4D Driving Scene Generation With Stereo Forcing",
        "author": [
            "Hao Lu",
            "Zhuang Ma",
            "Guangfeng Jiang",
            "Wenhang Ge",
            "Bohan Li",
            "Yuzhan Cai",
            "Wenzhao Zheng",
            "Yunpeng Zhang",
            "Yingcong Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2509.20251",
        "abstract": "Current generative models struggle to synthesize dynamic 4D driving scenes that simultaneously support temporal extrapolation and spatial novel view synthesis (NVS) without per-scene optimization. Bridging generation and novel view synthesis remains a major challenge. We present PhiGenesis, a unified framework for 4D scene generation that extends video generation techniques with geometric and temporal consistency. Given multi-view image sequences and camera parameters, PhiGenesis produces temporally continuous 4D Gaussian splatting representations along target 3D trajectories. In its first stage, PhiGenesis leverages a pre-trained video VAE with a novel range-view adapter to enable feed-forward 4D reconstruction from multi-view images. This architecture supports single-frame or video inputs and outputs complete 4D scenes including geometry, semantics, and motion. In the second stage, PhiGenesis introduces a geometric-guided video diffusion model, using rendered historical 4D scenes as priors to generate future views conditioned on trajectories. To address geometric exposure bias in novel views, we propose Stereo Forcing, a novel conditioning strategy that integrates geometric uncertainty during denoising. This method enhances temporal coherence by dynamically adjusting generative influence based on uncertainty-aware perturbations. Our experimental results demonstrate that our method achieves state-of-the-art performance in both appearance and geometric reconstruction, temporal generation and novel view synthesis (NVS) tasks, while simultaneously delivering competitive performance in downstream evaluations. Homepage is at \\href{https://jiangxb98.github.io/PhiGensis}{PhiGensis}.",
        "tags": [
            "3D",
            "Diffusion",
            "Gaussian Splatting",
            "VAE",
            "Video Generation"
        ]
    },
    {
        "id": "200",
        "title": "AnchDrive: Bootstrapping Diffusion Policies with Hybrid Trajectory Anchors for End-to-End Driving",
        "author": [
            "Jinhao Chai",
            "Anqing Jiang",
            "Hao Jiang",
            "Shiyi Mu",
            "Zichong Gu",
            "Shugong Xu"
        ],
        "pdf": "https://arxiv.org/pdf/2509.20253",
        "abstract": "End-to-end multi-modal planning has become a transformative paradigm in autonomous driving, effectively addressing behavioral multi-modality and the generalization challenge in long-tail scenarios. We propose AnchDrive, a framework for end-to-end driving that effectively bootstraps a diffusion policy to mitigate the high computational cost of traditional generative models. Rather than denoising from pure noise, AnchDrive initializes its planner with a rich set of hybrid trajectory anchors. These anchors are derived from two complementary sources: a static vocabulary of general driving priors and a set of dynamic, context-aware trajectories. The dynamic trajectories are decoded in real-time by a Transformer that processes dense and sparse perceptual features. The diffusion model then learns to refine these anchors by predicting a distribution of trajectory offsets, enabling fine-grained refinement. This anchor-based bootstrapping design allows for efficient generation of diverse, high-quality trajectories. Experiments on the NAVSIM benchmark confirm that AnchDrive sets a new state-of-the-art and shows strong gen?eralizability",
        "tags": [
            "Diffusion",
            "Transformer"
        ]
    },
    {
        "id": "201",
        "title": "HL-IK: A Lightweight Implementation of Human-Like Inverse Kinematics in Humanoid Arms",
        "author": [
            "Bingjie Chen",
            "Zihan Wang",
            "Zhe Han",
            "Guoping Pan",
            "Yi Cheng",
            "Houde Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2509.20263",
        "abstract": "Traditional IK methods for redundant humanoid manipulators emphasize end-effector (EE) tracking, frequently producing configurations that are valid mechanically but not human-like. We present Human-Like Inverse Kinematics (HL-IK), a lightweight IK framework that preserves EE tracking while shaping whole-arm configurations to appear human-like, without full-body sensing at runtime. The key idea is a learned elbow prior: using large-scale human motion data retargeted to the robot, we train a FiLM-modulated spatio-temporal attention network (FiSTA) to predict the next-step elbow pose from the EE target and a short history of EE-elbow http://states.This prediction is incorporated as a small residual alongside EE and smoothness terms in a standard Levenberg-Marquardt optimizer, making HL-IK a drop-in addition to numerical IK stacks. Over 183k simulation steps, HL-IK reduces arm-similarity position and direction error by 30.6% and 35.4% on average, and by 42.2% and 47.4% on the most challenging trajectories. Hardware teleoperation on a robot distinct from simulation further confirms the gains in anthropomorphism. HL-IK is simple to integrate, adaptable across platforms via our pipeline, and adds minimal computation, enabling human-like motions for humanoid robots. Project page: https://hl-ik.github.io/",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "202",
        "title": "Failure Modes of Maximum Entropy RLHF",
        "author": [
            "Ãmer Veysel ÃaÄatan",
            "BarÄ±Å AkgÃ¼n"
        ],
        "pdf": "https://arxiv.org/pdf/2509.20265",
        "abstract": "In this paper, we show that Simple Preference Optimization (SimPO) can be derived as Maximum Entropy Reinforcement Learning with length-normalized temperature, providing a theoretical foundation for this reference-free method. Motivated by SimPO's strong performance in offline preference optimization, we investigate whether Maximum Entropy RL can achieve similar results in online RLHF settings. Our experiments find that Maximum Entropy RL consistently exhibits overoptimization and unstable KL dynamics, even at very low learning rates. Unlike KL-constrained methods that maintain stable training, entropy regularization fails to prevent reward hacking and appears to correlate with overoptimization. Lastly, we discuss possible explanations for why SimPO succeeds in offline settings while Maximum Entropy RL struggles in online scenarios. Our findings suggest that reference-free approaches may face distinct challenges when applied to online or offline preference learning.",
        "tags": [
            "RL",
            "RLHF"
        ]
    },
    {
        "id": "203",
        "title": "Investigating Security Implications of Automatically Generated Code on the Software Supply Chain",
        "author": [
            "Xiaofan Li",
            "Xing Gao"
        ],
        "pdf": "https://arxiv.org/pdf/2509.20277",
        "abstract": "In recent years, various software supply chain (SSC) attacks have posed significant risks to the global community. Severe consequences may arise if developers integrate insecure code snippets that are vulnerable to SSC attacks into their products. Particularly, code generation techniques, such as large language models (LLMs), have been widely utilized in the developer community. However, LLMs are known to suffer from inherent issues when generating code, including fabrication, misinformation, and reliance on outdated training data, all of which can result in serious software supply chain threats. In this paper, we investigate the security threats to the SSC that arise from these inherent issues. We examine three categories of threats, including eleven potential SSC-related threats, related to external components in source code, and continuous integration configuration files. We find some threats in LLM-generated code could enable attackers to hijack software and workflows, while some others might cause potential hidden threats that compromise the security of the software over time. To understand these security impacts and severity, we design a tool, SSCGuard, to generate 439,138 prompts based on SSC-related questions collected online, and analyze the responses of four popular LLMs from GPT and Llama. Our results show that all identified SSC-related threats persistently exist. To mitigate these risks, we propose a novel prompt-based defense mechanism, namely Chain-of-Confirmation, to reduce fabrication, and a middleware-based defense that informs users of various SSC threats.",
        "tags": [
            "GPT",
            "LLM",
            "LLaMA"
        ]
    },
    {
        "id": "204",
        "title": "Instruction Boundary: Quantifying Biases in LLM Reasoning under Various Coverage",
        "author": [
            "Zipeng Ling",
            "Yuehao Tang",
            "Chen Huang",
            "Shuliang Liu",
            "Gaoyang Jiang",
            "Shenghong Fu",
            "Junqi Yang",
            "Yao Wan",
            "Jiawan Zhang",
            "Kejia Huang",
            "Xuming Hu"
        ],
        "pdf": "https://arxiv.org/pdf/2509.20278",
        "abstract": "Large-language-model (LLM) reasoning has long been regarded as a powerful tool for problem solving across domains, providing non-experts with valuable advice. However, their limitations - especially those stemming from prompt design - remain underexplored. Because users may supply biased or incomplete prompts - often unintentionally - LLMs can be misled, undermining reliability and creating risks. We refer to this vulnerability as the Instruction Boundary. To investigate the phenomenon, we distill it into eight concrete facets and introduce BiasDetector, a framework that measures biases arising from three instruction types: complete, redundant, and insufficient. We evaluate several mainstream LLMs and find that, despite high headline accuracy, substantial biases persist in many downstream tasks as a direct consequence of prompt coverage. Our empirical study confirms that LLM reasoning reliability can still be significantly improved. We analyze the practical impact of these biases and outline mitigation strategies. Our findings underscore the need for developers to tackle biases and for users to craft options carefully.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "205",
        "title": "Parse-Augment-Distill: Learning Generalizable Bimanual Visuomotor Policies from Single Human Video",
        "author": [
            "Georgios Tziafas",
            "Jiayun Zhang",
            "Hamidreza Kasaei"
        ],
        "pdf": "https://arxiv.org/pdf/2509.20286",
        "abstract": "Learning visuomotor policies from expert demonstrations is an important frontier in modern robotics research, however, most popular methods require copious efforts for collecting teleoperation data and struggle to generalize out-ofdistribution. Scaling data collection has been explored through leveraging human videos, as well as demonstration augmentation techniques. The latter approach typically requires expensive simulation rollouts and trains policies with synthetic image data, therefore introducing a sim-to-real gap. In parallel, alternative state representations such as keypoints have shown great promise for category-level generalization. In this work, we bring these avenues together in a unified framework: PAD (Parse-AugmentDistill), for learning generalizable bimanual policies from a single human video. Our method relies on three steps: (a) parsing a human video demo into a robot-executable keypoint-action trajectory, (b) employing bimanual task-and-motion-planning to augment the demonstration at scale without simulators, and (c) distilling the augmented trajectories into a keypoint-conditioned policy. Empirically, we showcase that PAD outperforms state-ofthe-art bimanual demonstration augmentation works relying on image policies with simulation rollouts, both in terms of success rate and sample/cost efficiency. We deploy our framework in six diverse real-world bimanual tasks such as pouring drinks, cleaning trash and opening containers, producing one-shot policies that generalize in unseen spatial arrangements, object instances and background distractors. Supplementary material can be found in the project webpage https://gtziafas.github.io/PAD_project/.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "206",
        "title": "When Judgment Becomes Noise: How Design Failures in LLM Judge Benchmarks Silently Undermine Validity",
        "author": [
            "Benjamin Feuer",
            "Chiung-Yi Tseng",
            "Astitwa Sarthak Lathe",
            "Oussama Elachqar",
            "John P Dickerson"
        ],
        "pdf": "https://arxiv.org/pdf/2509.20293",
        "abstract": "LLM-judged benchmarks are increasingly used to evaluate complex model behaviors, yet their design introduces failure modes absent in conventional ground-truth based benchmarks. We argue that without tight objectives and verifiable constructions, benchmark rankings can produce high-confidence rankings that are in fact largely noise. We introduce two mechanisms to diagnose these issues. Schematic adherence quantifies how much of a judge's overall verdict is explained by the explicit evaluation schema, revealing unexplained variance when judges deviate from their own rubric. Psychometric validity aggregates internal consistency and discriminant validity signals to quantify irreducible uncertainty in any benchmarking run. Applying these tools to Arena-Hard Auto, we find severe schema incoherence and factor collapse across popular judges: for example, unexplained variance exceeding 90 percent for DeepSeek-R1-32B and factor correlations above 0.93 for most criteria. We also show that the ELO-style aggregation used by Arena-Hard Auto collapses and masks genuine ranking uncertainty. Our results highlight design failures that undermine validity and offer actionable principles for building better-scoped, reliability-aware LLM-judged benchmarks. We release our code at https://anonymous.4open.science/r/judgment-to-noise-947D/README.md",
        "tags": [
            "DeepSeek",
            "LLM"
        ]
    },
    {
        "id": "207",
        "title": "FAST: Foreground-aware Diffusion with Accelerated Sampling Trajectory for Segmentation-oriented Anomaly Synthesis",
        "author": [
            "Xichen Xu",
            "Yanshu Wang",
            "Jinbao Wang",
            "Xiaoning Lei",
            "Guoyang Xie",
            "Guannan Jiang",
            "Zhichao Lu"
        ],
        "pdf": "https://arxiv.org/pdf/2509.20295",
        "abstract": "Industrial anomaly segmentation relies heavily on pixel-level annotations, yet real-world anomalies are often scarce, diverse, and costly to label. Segmentation-oriented industrial anomaly synthesis (SIAS) has emerged as a promising alternative; however, existing methods struggle to balance sampling efficiency and generation quality. Moreover, most approaches treat all spatial regions uniformly, overlooking the distinct statistical differences between anomaly and background areas. This uniform treatment hinders the synthesis of controllable, structure-specific anomalies tailored for segmentation tasks. In this paper, we propose FAST, a foreground-aware diffusion framework featuring two novel modules: the Anomaly-Informed Accelerated Sampling (AIAS) and the Foreground-Aware Reconstruction Module (FARM). AIAS is a training-free sampling algorithm specifically designed for segmentation-oriented industrial anomaly synthesis, which accelerates the reverse process through coarse-to-fine aggregation and enables the synthesis of state-of-the-art segmentation-oriented anomalies in as few as 10 steps. Meanwhile, FARM adaptively adjusts the anomaly-aware noise within the masked foreground regions at each sampling step, preserving localized anomaly signals throughout the denoising trajectory. Extensive experiments on multiple industrial benchmarks demonstrate that FAST consistently outperforms existing anomaly synthesis methods in downstream segmentation tasks. We release the code at: https://anonymous.4open.science/r/NeurIPS-938.",
        "tags": [
            "Diffusion",
            "Segmentation"
        ]
    },
    {
        "id": "208",
        "title": "mindmap: Spatial Memory in Deep Feature Maps for 3D Action Policies",
        "author": [
            "Remo Steiner",
            "Alexander Millane",
            "David Tingdahl",
            "Clemens Volk",
            "Vikram Ramasamy",
            "Xinjie Yao",
            "Peter Du",
            "Soha Pouya",
            "Shiwei Sheng"
        ],
        "pdf": "https://arxiv.org/pdf/2509.20297",
        "abstract": "End-to-end learning of robot control policies, structured as neural networks, has emerged as a promising approach to robotic manipulation. To complete many common tasks, relevant objects are required to pass in and out of a robot's field of view. In these settings, spatial memory - the ability to remember the spatial composition of the scene - is an important competency. However, building such mechanisms into robot learning systems remains an open research problem. We introduce mindmap (Spatial Memory in Deep Feature Maps for 3D Action Policies), a 3D diffusion policy that generates robot trajectories based on a semantic 3D reconstruction of the environment. We show in simulation experiments that our approach is effective at solving tasks where state-of-the-art approaches without memory mechanisms struggle. We release our reconstruction system, training code, and evaluation tasks to spur research in this direction.",
        "tags": [
            "3D",
            "Diffusion",
            "Robotics"
        ]
    },
    {
        "id": "209",
        "title": "Multilingual Hope Speech Detection: A Comparative Study of Logistic Regression, mBERT, and XLM-RoBERTa with Active Learning",
        "author": [
            "T. O. Abiola",
            "K. D. Abiodun",
            "O. E. Olumide",
            "O. O. Adebanji",
            "O. Hiram Calvo",
            "Grigori Sidorov"
        ],
        "pdf": "https://arxiv.org/pdf/2509.20315",
        "abstract": "Hope speech language that fosters encouragement and optimism plays a vital role in promoting positive discourse online. However, its detection remains challenging, especially in multilingual and low-resource settings. This paper presents a multilingual framework for hope speech detection using an active learning approach and transformer-based models, including mBERT and XLM-RoBERTa. Experiments were conducted on datasets in English, Spanish, German, and Urdu, including benchmark test sets from recent shared tasks. Our results show that transformer models significantly outperform traditional baselines, with XLM-RoBERTa achieving the highest overall accuracy. Furthermore, our active learning strategy maintained strong performance even with small annotated datasets. This study highlights the effectiveness of combining multilingual transformers with data-efficient training strategies for hope speech detection.",
        "tags": [
            "Detection",
            "Transformer"
        ]
    },
    {
        "id": "210",
        "title": "SIM-CoT: Supervised Implicit Chain-of-Thought",
        "author": [
            "Xilin Wei",
            "Xiaoran Liu",
            "Yuhang Zang",
            "Xiaoyi Dong",
            "Yuhang Cao",
            "Jiaqi Wang",
            "Xipeng Qiu",
            "Dahua Lin"
        ],
        "pdf": "https://arxiv.org/pdf/2509.20317",
        "abstract": "Implicit Chain-of-Thought (CoT) methods present a promising, token-efficient alternative to explicit CoT reasoning in Large Language Models (LLMs), but a persistent performance gap has limited the application of implicit CoT. We identify a core latent instability issue by scaling the computational budget of implicit CoT approaches: as we increase the number of implicit reasoning tokens to enhance performance, the training process often becomes unstable and collapses. Our analysis reveals that this instability arises from the latent representations becoming homogeneous and losing their semantic diversity, a failure caused by insufficient step-level supervision in existing implicit CoT approaches. To address this issue, we propose SIM-CoT, a plug-and-play training module that introduces step-level supervision to stabilize and enrich the latent reasoning space. Specifically, SIM-CoT employs an auxiliary decoder during training to align each implicit token with its corresponding explicit reasoning step, ensuring that latent states capture distinct and meaningful information. The proposed auxiliary decoder is removed during inference, preserving the computational efficiency of implicit CoT methods with no added overhead. In addition, the auxiliary decoder affords interpretability of implicit reasoning by projecting each latent token onto an explicit reasoning vocabulary, enabling per-step visualization of semantic roles and diagnosis. SIM-CoT significantly enhances both the in-domain accuracy and out-of-domain stability of various implicit CoT methods, boosting baselines like Coconut by +8.2% on GPT-2 and CODI by +3.0% on LLaMA-3.1 8B. Demonstrating strong scalability, SIM-CoT also surpasses the explicit CoT baseline on GPT-2 by 2.1% with 2.3\\times greater token efficiency, while substantially closing the performance gap on larger models like LLaMA-3.1 8B.",
        "tags": [
            "CoT",
            "GPT",
            "LLM",
            "LLaMA"
        ]
    },
    {
        "id": "211",
        "title": "Z-Scores: A Metric for Linguistically Assessing Disfluency Removal",
        "author": [
            "Maria Teleki",
            "Sai Janjur",
            "Haoran Liu",
            "Oliver Grabner",
            "Ketan Verma",
            "Thomas Docog",
            "Xiangjue Dong",
            "Lingfeng Shi",
            "Cong Wang",
            "Stephanie Birkelbach",
            "Jason Kim",
            "Yin Zhang",
            "James Caverlee"
        ],
        "pdf": "https://arxiv.org/pdf/2509.20319",
        "abstract": "Evaluating disfluency removal in speech requires more than aggregate token-level scores. Traditional word-based metrics such as precision, recall, and F1 (E-Scores) capture overall performance but cannot reveal why models succeed or fail. We introduce Z-Scores, a span-level linguistically-grounded evaluation metric that categorizes system behavior across distinct disfluency types (EDITED, INTJ, PRN). Our deterministic alignment module enables robust mapping between generated text and disfluent transcripts, allowing Z-Scores to expose systematic weaknesses that word-level metrics obscure. By providing category-specific diagnostics, Z-Scores enable researchers to identify model failure modes and design targeted interventions -- such as tailored prompts or data augmentation -- yielding measurable performance improvements. A case study with LLMs shows that Z-Scores uncover challenges with INTJ and PRN disfluencies hidden in aggregate F1, directly informing model refinement strategies.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "212",
        "title": "DRES: Benchmarking LLMs for Disfluency Removal",
        "author": [
            "Maria Teleki",
            "Sai Janjur",
            "Haoran Liu",
            "Oliver Grabner",
            "Ketan Verma",
            "Thomas Docog",
            "Xiangjue Dong",
            "Lingfeng Shi",
            "Cong Wang",
            "Stephanie Birkelbach",
            "Jason Kim",
            "Yin Zhang",
            "James Caverlee"
        ],
        "pdf": "https://arxiv.org/pdf/2509.20321",
        "abstract": "Disfluencies -- such as \"um,\" \"uh,\" interjections, parentheticals, and edited statements -- remain a persistent challenge for speech-driven systems, degrading accuracy in command interpretation, summarization, and conversational agents. We introduce DRES (Disfluency Removal Evaluation Suite), a controlled text-level benchmark that establishes a reproducible semantic upper bound for this task. DRES builds on human-annotated Switchboard transcripts, isolating disfluency removal from ASR errors and acoustic variability. We systematically evaluate proprietary and open-source LLMs across scales, prompting strategies, and architectures. Our results reveal that (i) simple segmentation consistently improves performance, even for long-context models; (ii) reasoning-oriented models tend to over-delete fluent tokens; and (iii) fine-tuning achieves near state-of-the-art precision and recall but harms generalization abilities. We further present a set of LLM-specific error modes and offer nine practical recommendations (R1-R9) for deploying disfluency removal in speech-driven pipelines. DRES provides a reproducible, model-agnostic foundation for advancing robust spoken-language systems.",
        "tags": [
            "LLM",
            "Segmentation"
        ]
    },
    {
        "id": "213",
        "title": "VisualMimic: Visual Humanoid Loco-Manipulation via Motion Tracking and Generation",
        "author": [
            "Shaofeng Yin",
            "Yanjie Ze",
            "Hong-Xing Yu",
            "C. Karen Liu",
            "Jiajun Wu"
        ],
        "pdf": "https://arxiv.org/pdf/2509.20322",
        "abstract": "Humanoid loco-manipulation in unstructured environments demands tight integration of egocentric perception and whole-body control. However, existing approaches either depend on external motion capture systems or fail to generalize across diverse tasks. We introduce VisualMimic, a visual sim-to-real framework that unifies egocentric vision with hierarchical whole-body control for humanoid robots. VisualMimic combines a task-agnostic low-level keypoint tracker -- trained from human motion data via a teacher-student scheme -- with a task-specific high-level policy that generates keypoint commands from visual and proprioceptive input. To ensure stable training, we inject noise into the low-level policy and clip high-level actions using human motion statistics. VisualMimic enables zero-shot transfer of visuomotor policies trained in simulation to real humanoid robots, accomplishing a wide range of loco-manipulation tasks such as box lifting, pushing, football dribbling, and kicking. Beyond controlled laboratory settings, our policies also generalize robustly to outdoor environments. Videos are available at: https://visualmimic.github.io .",
        "tags": [
            "CLIP"
        ]
    },
    {
        "id": "214",
        "title": "RAG Security and Privacy: Formalizing the Threat Model and Attack Surface",
        "author": [
            "Atousa Arzanipour",
            "Rouzbeh Behnia",
            "Reza Ebrahimi",
            "Kaushik Dutta"
        ],
        "pdf": "https://arxiv.org/pdf/2509.20324",
        "abstract": "Retrieval-Augmented Generation (RAG) is an emerging approach in natural language processing that combines large language models (LLMs) with external document retrieval to produce more accurate and grounded responses. While RAG has shown strong potential in reducing hallucinations and improving factual consistency, it also introduces new privacy and security challenges that differ from those faced by traditional LLMs. Existing research has demonstrated that LLMs can leak sensitive information through training data memorization or adversarial prompts, and RAG systems inherit many of these vulnerabilities. At the same time, reliance of RAG on an external knowledge base opens new attack surfaces, including the potential for leaking information about the presence or content of retrieved documents, or for injecting malicious content to manipulate model behavior. Despite these risks, there is currently no formal framework that defines the threat landscape for RAG systems. In this paper, we address a critical gap in the literature by proposing, to the best of our knowledge, the first formal threat model for retrieval-RAG systems. We introduce a structured taxonomy of adversary types based on their access to model components and data, and we formally define key threat vectors such as document-level membership inference and data poisoning, which pose serious privacy and integrity risks in real-world deployments. By establishing formal definitions and attack models, our work lays the foundation for a more rigorous and principled understanding of privacy and security in RAG systems.",
        "tags": [
            "LLM",
            "RAG"
        ]
    },
    {
        "id": "215",
        "title": "Video models are zero-shot learners and reasoners",
        "author": [
            "ThaddÃ¤us Wiedemer",
            "Yuxuan Li",
            "Paul Vicol",
            "Shixiang Shane Gu",
            "Nick Matarese",
            "Kevin Swersky",
            "Been Kim",
            "Priyank Jaini",
            "Robert Geirhos"
        ],
        "pdf": "https://arxiv.org/pdf/2509.20328",
        "abstract": "The remarkable zero-shot capabilities of Large Language Models (LLMs) have propelled natural language processing from task-specific models to unified, generalist foundation models. This transformation emerged from simple primitives: large, generative models trained on web-scale data. Curiously, the same primitives apply to today's generative video models. Could video models be on a trajectory towards general-purpose vision understanding, much like LLMs developed general-purpose language understanding? We demonstrate that Veo 3 can solve a broad variety of tasks it wasn't explicitly trained for: segmenting objects, detecting edges, editing images, understanding physical properties, recognizing object affordances, simulating tool use, and more. These abilities to perceive, model, and manipulate the visual world enable early forms of visual reasoning like maze and symmetry solving. Veo's emergent zero-shot capabilities indicate that video models are on a path to becoming unified, generalist vision foundation models.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "216",
        "title": "BBoE: Leveraging Bundle of Edges for Kinodynamic Bidirectional Motion Planning",
        "author": [
            "Srikrishna Bangalore Raghu",
            "Alessandro Roncone"
        ],
        "pdf": "https://arxiv.org/pdf/2509.20333",
        "abstract": "In this work, we introduce BBoE, a bidirectional, kinodynamic, sampling-based motion planner that consistently and quickly finds low-cost solutions in environments with varying obstacle clutter. The algorithm combines exploration and exploitation while relying on precomputed robot state traversals, resulting in efficient convergence towards the goal. Our key contributions include: i) a strategy to navigate through obstacle-rich spaces by sorting and sequencing preprocessed forward propagations; and ii) BBoE, a robust bidirectional kinodynamic planner that utilizes this strategy to produce fast and feasible solutions. The proposed framework reduces planning time, diminishes solution cost and increases success rate in comparison to previous approaches.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "217",
        "title": "Uncovering Graph Reasoning in Decoder-only Transformers with Circuit Tracing",
        "author": [
            "Xinnan Dai",
            "Chung-Hsiang Lo",
            "Kai Guo",
            "Shenglai Zeng",
            "Dongsheng Luo",
            "Jiliang Tang"
        ],
        "pdf": "https://arxiv.org/pdf/2509.20336",
        "abstract": "Transformer-based LLMs demonstrate strong performance on graph reasoning tasks, yet their internal mechanisms remain underexplored. To uncover these reasoning process mechanisms in a fundamental and unified view, we set the basic decoder-only transformers and explain them using the circuit-tracer framework. Through this lens, we visualize reasoning traces and identify two core mechanisms in graph reasoning: token merging and structural memorization, which underlie both path reasoning and substructure extraction tasks. We further quantify these behaviors and analyze how they are influenced by graph density and model size. Our study provides a unified interpretability framework for understanding structural reasoning in decoder-only Transformers.",
        "tags": [
            "LLM",
            "Transformer"
        ]
    },
    {
        "id": "218",
        "title": "Adaptive Event-Triggered Policy Gradient for Multi-Agent Reinforcement Learning",
        "author": [
            "Umer Siddique",
            "Abhinav Sinha",
            "Yongcan Cao"
        ],
        "pdf": "https://arxiv.org/pdf/2509.20338",
        "abstract": "Conventional multi-agent reinforcement learning (MARL) methods rely on time-triggered execution, where agents sample and communicate actions at fixed intervals. This approach is often computationally expensive and communication-intensive. To address this limitation, we propose ET-MAPG (Event-Triggered Multi-Agent Policy Gradient reinforcement learning), a framework that jointly learns an agent's control policy and its event-triggering policy. Unlike prior work that decouples these mechanisms, ET-MAPG integrates them into a unified learning process, enabling agents to learn not only what action to take but also when to execute it. For scenarios with inter-agent communication, we introduce AET-MAPG, an attention-based variant that leverages a self-attention mechanism to learn selective communication patterns. AET-MAPG empowers agents to determine not only when to trigger an action but also with whom to communicate and what information to exchange, thereby optimizing coordination. Both methods can be integrated with any policy gradient MARL algorithm. Extensive experiments across diverse MARL benchmarks demonstrate that our approaches achieve performance comparable to state-of-the-art, time-triggered baselines while significantly reducing both computational load and communication overhead.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "219",
        "title": "Process-Informed Forecasting of Complex Thermal Dynamics in Pharmaceutical Manufacturing",
        "author": [
            "Ramona Rubini",
            "Siavash Khodakarami",
            "Aniruddha Bora",
            "George Em Karniadakis",
            "Michele Dassisti"
        ],
        "pdf": "https://arxiv.org/pdf/2509.20349",
        "abstract": "Accurate time-series forecasting for complex physical systems is the backbone of modern industrial monitoring and control. While deep learning models excel at capturing complex dynamics, currently, their deployment is limited due to physical inconsistency and robustness, hence constraining their reliability in regulated environments. We introduce process-informed forecasting (PIF) models for temperature in pharmaceutical lyophilization. We investigate a wide range of models, from classical ones such as Autoregressive Integrated Moving Average Model (ARIMA) and Exponential Smoothing Model (ETS), to modern deep learning architectures, including Kolmogorov-Arnold Networks (KANs). We compare three different loss function formulations that integrate a process-informed trajectory prior: a fixed-weight loss, a dynamic uncertainty-based loss, and a Residual-Based Attention (RBA) mechanism. We evaluate all models not only for accuracy and physical consistency but also for robustness to sensor noise. Furthermore, we test the practical generalizability of the best model in a transfer learning scenario on a new process. Our results show that PIF models outperform their data-driven counterparts in terms of accuracy, physical plausibility and noise resilience. This work provides a roadmap for developing reliable and generalizable forecasting solutions for critical applications in the pharmaceutical manufacturing landscape.",
        "tags": [
            "KAN"
        ]
    },
    {
        "id": "220",
        "title": "Language Models that Think, Chat Better",
        "author": [
            "Adithya Bhaskar",
            "Xi Ye",
            "Danqi Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2509.20357",
        "abstract": "Reinforcement learning with verifiable rewards (RLVR) improves language model reasoning by using rule-based rewards in verifiable domains such as mathematics and code. However, RLVR leads to limited generalization for open-ended tasks -- such as writing outline essays or making meal plans -- where humans reason routinely. This paper shows that the RLVR paradigm is effective beyond verifiable domains, and introduces **RL** with **M**odel-rewarded **T**hinking (**RLMT**) for general-purpose chat capabilities. Using diverse real-world prompts, RLMT requires LMs to generate long CoT reasoning before response, and optimizes them with online RL against a preference-based reward model used in RLHF. Across 40 training runs on Llama-3.1-8B and Qwen-2.5-7B (both base and instruct) and multiple optimization algorithms (DPO, PPO, and GRPO), RLMT consistently outperforms standard RLHF pipelines. This includes substantial gains of 3-7 points on three chat benchmarks (AlpacaEval2, WildBench, and ArenaHardV2), along with 1-3 point improvements on other tasks like creative writing and general knowledge. Our best 8B model surpasses GPT-4o in chat and creative writing and rivals Claude-3.7-Sonnet (Thinking). RLMT can also be applied directly to base models without an SFT stage, akin to R1-Zero training. Remarkably, with only 7K prompts, Llama-3.1-8B base trained with our RLMT recipe outperforms Llama-3.1-8B-Instruct post-trained with a complex multi-staged pipeline with 25M+ examples. We close with qualitative and quantitative analyses of how trained models plan their responses. Our results rethink the post-training pipeline and call upon future work to understand and employ thinking more broadly.",
        "tags": [
            "CoT",
            "DPO",
            "GPT",
            "GRPO",
            "LLaMA",
            "PPO",
            "Qwen",
            "RL",
            "RLHF"
        ]
    },
    {
        "id": "221",
        "title": "PhysCtrl: Generative Physics for Controllable and Physics-Grounded Video Generation",
        "author": [
            "Chen Wang",
            "Chuhao Chen",
            "Yiming Huang",
            "Zhiyang Dou",
            "Yuan Liu",
            "Jiatao Gu",
            "Lingjie Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2509.20358",
        "abstract": "Existing video generation models excel at producing photo-realistic videos from text or images, but often lack physical plausibility and 3D controllability. To overcome these limitations, we introduce PhysCtrl, a novel framework for physics-grounded image-to-video generation with physical parameters and force control. At its core is a generative physics network that learns the distribution of physical dynamics across four materials (elastic, sand, plasticine, and rigid) via a diffusion model conditioned on physics parameters and applied forces. We represent physical dynamics as 3D point trajectories and train on a large-scale synthetic dataset of 550K animations generated by physics simulators. We enhance the diffusion model with a novel spatiotemporal attention block that emulates particle interactions and incorporates physics-based constraints during training to enforce physical plausibility. Experiments show that PhysCtrl generates realistic, physics-grounded motion trajectories which, when used to drive image-to-video models, yield high-fidelity, controllable videos that outperform existing methods in both visual quality and physical plausibility. Project Page: https://cwchenwang.github.io/physctrl",
        "tags": [
            "3D",
            "Diffusion",
            "Video Generation"
        ]
    },
    {
        "id": "222",
        "title": "EditVerse: Unifying Image and Video Editing and Generation with In-Context Learning",
        "author": [
            "Xuan Ju",
            "Tianyu Wang",
            "Yuqian Zhou",
            "He Zhang",
            "Qing Liu",
            "Nanxuan Zhao",
            "Zhifei Zhang",
            "Yijun Li",
            "Yuanhao Cai",
            "Shaoteng Liu",
            "Daniil Pakhomov",
            "Zhe Lin",
            "Soo Ye Kim",
            "Qiang Xu"
        ],
        "pdf": "https://arxiv.org/pdf/2509.20360",
        "abstract": "Recent advances in foundation models highlight a clear trend toward unification and scaling, showing emergent capabilities across diverse domains. While image generation and editing have rapidly transitioned from task-specific to unified frameworks, video generation and editing remain fragmented due to architectural limitations and data scarcity. In this work, we introduce EditVerse, a unified framework for image and video generation and editing within a single model. By representing all modalities, i.e., text, image, and video, as a unified token sequence, EditVerse leverages self-attention to achieve robust in-context learning, natural cross-modal knowledge transfer, and flexible handling of inputs and outputs with arbitrary resolutions and durations. To address the lack of video editing training data, we design a scalable data pipeline that curates 232K video editing samples and combines them with large-scale image and video datasets for joint training. Furthermore, we present EditVerseBench, the first benchmark for instruction-based video editing covering diverse tasks and resolutions. Extensive experiments and user studies demonstrate that EditVerse achieves state-of-the-art performance, surpassing existing open-source and commercial models, while exhibiting emergent editing and generation abilities across modalities.",
        "tags": [
            "Video Editing",
            "Video Generation"
        ]
    },
    {
        "id": "223",
        "title": "A Federated Fine-Tuning Paradigm of Foundation Models in Heterogenous Wireless Networks",
        "author": [
            "Jingyi Wang",
            "Zhongyuan Zhao",
            "Qingtian Wang",
            "Zexu Li",
            "Yue Wang",
            "Tony Q. S. Quek"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19306",
        "abstract": "Edge intelligence has emerged as a promising strategy to deliver low-latency and ubiquitous services for mobile devices. Recent advances in fine-tuning mechanisms of foundation models have enabled edge intelligence by integrating low-rank adaptation (LoRA) with federated learning. However, in wireless networks, the device heterogeneity and resource constraints on edge devices pose great threats to the performance of federated fine-tuning. To tackle these issues, we propose to optimize federated fine-tuning in heterogenous wireless networks via online learning. First, the framework of switching-based federated fine-tuning in wireless networks is provided. The edge devices switches to LoRA modules dynamically for federated fine-tuning with base station to jointly mitigate the impact of device heterogeneity and transmission unreliability. Second, a tractable upper bound on the inference risk gap is derived based on theoretical analysis. To improve the generalization capability, we formulate a non-convex mixed-integer programming problem with long-term constraints, and decouple it into model switching, transmit power control, and bandwidth allocation subproblems. An online optimization algorithm is developed to solve the problems with polynomial computational complexity. Finally, the simulation results on the SST-2 and QNLI data sets demonstrate the performance gains in test accuracy and energy efficiency.",
        "tags": [
            "LoRA"
        ]
    },
    {
        "id": "224",
        "title": "Scensory: Automated Real-Time Fungal Identification and Spatial Mapping",
        "author": [
            "Yanbaihui Liu",
            "Erica Babusci",
            "Claudia K. Gunsch",
            "Boyuan Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19318",
        "abstract": "Indoor fungal contamination poses significant risks to public health, yet existing detection methods are slow, costly, and lack spatial resolution. Conventional approaches rely on laboratory analysis or high-concentration sampling, making them unsuitable for real-time monitoring and scalable deployment. We introduce \\textbf{\\textit{Scensory}}, a robot-enabled olfactory system that simultaneously identifies fungal species and localizes their spatial origin using affordable volatile organic compound (VOC) sensor arrays and deep learning. Our key idea is that temporal VOC dynamics encode both chemical and spatial signatures, which we decode through neural architectures trained on robot-automated data collection. We demonstrate two operational modes: a passive multi-array configuration for environmental monitoring, and a mobile single-array configuration for active source tracking. Across five fungal species, our system achieves up to 89.85\\% accuracy in species detection and 87.31\\% accuracy in localization under ambient conditions, where each prediction only takes 3--7\\,s sensor inputs. Additionally, by computationally analyzing model behavior, we can uncover key biochemical signatures without additional laboratory experiments. Our approach enables real-time, spatially aware fungal monitoring and establishes a scalable and affordable framework for autonomous environmental sensing.",
        "tags": [
            "Detection",
            "Robotics"
        ]
    },
    {
        "id": "225",
        "title": "Holographic Transformers for Complex-Valued Signal Processing: Integrating Phase Interference into Self-Attention",
        "author": [
            "Enhao Huang",
            "Zhiyu Zhang",
            "Tianxiang Xu",
            "Chunshu Xia",
            "Kaichun Hu",
            "Yuchen Yang",
            "Tongtong Pan",
            "Dong Dong",
            "Zhan Qin"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19331",
        "abstract": "Complex-valued signals encode both amplitude and phase, yet most deep models treat attention as real-valued correlation, overlooking interference effects. We introduce the Holographic Transformer, a physics-inspired architecture that incorporates wave interference principles into self-attention. Holographic attention modulates interactions by relative phase and coherently superimposes values, ensuring consistency between amplitude and phase. A dual-headed decoder simultaneously reconstructs the input and predicts task outputs, preventing phase collapse when losses prioritize magnitude over phase. We demonstrate that holographic attention implements a discrete interference operator and maintains phase consistency under linear mixing. Experiments on PolSAR image classification and wireless channel prediction show strong performance, achieving high classification accuracy and F1 scores, low regression error, and increased robustness to phase perturbations. These results highlight that enforcing physical consistency in attention leads to generalizable improvements in complex-valued learning and provides a unified, physics-based framework for coherent signal modeling. The code is available at https://github.com/EonHao/Holographic-Transformers.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "226",
        "title": "Joint Channel Estimation and Computation Offloading in Fluid Antenna-assisted MEC Networks",
        "author": [
            "Ying Ju",
            "Mingdong Li",
            "Haoyu Wang",
            "Lei Liu",
            "Youyang Qu",
            "Mianxiong Dong",
            "Victor C. M. Leung",
            "Chau Yuen"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19340",
        "abstract": "With the emergence of fluid antenna (FA) in wireless communications, the capability to dynamically adjust port positions offers substantial benefits in spatial diversity and spectrum efficiency, which are particularly valuable for mobile edge computing (MEC) systems. Therefore, we propose an FA-assisted MEC offloading framework to minimize system delay. This framework faces two severe challenges, which are the complexity of channel estimation due to dynamic port configuration and the inherent non-convexity of the joint optimization problem. Firstly, we propose Information Bottleneck Metric-enhanced Channel Compressed Sensing (IBM-CCS), which advances FA channel estimation by integrating information relevance into the sensing process and capturing key features of FA channels effectively. Secondly, to address the non-convex and high-dimensional optimization problem in FA-assisted MEC systems, which includes FA port selection, beamforming, power control, and resource allocation, we propose a game theory-assisted Hierarchical Twin-Dueling Multi-agent Algorithm (HiTDMA) based offloading scheme, where the hierarchical structure effectively decouples and coordinates the optimization tasks between the user side and the base station side. Crucially, the game theory effectively reduces the dimensionality of power control variables, allowing deep reinforcement learning (DRL) agents to achieve improved optimization efficiency. Numerical results confirm that the proposed scheme significantly reduces system delay and enhances offloading performance, outperforming benchmarks. Additionally, the IBM-CCS channel estimation demonstrates superior accuracy and robustness under varying port densities, contributing to efficient communication under imperfect CSI.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "227",
        "title": "A Statistical Mixture-of-Experts Framework for EMG Artifact Removal in EEG: Empirical Insights and a Proof-of-Concept Application",
        "author": [
            "Benjamin J. Choi",
            "Griffin Milsap",
            "Clara A. Scholl",
            "Francesco Tenore",
            "Mattson Ogg"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19385",
        "abstract": "Effective control of neural interfaces is limited by poor signal quality. While neural network-based electroencephalography (EEG) denoising methods for electromyogenic (EMG) artifacts have improved in recent years, current state-of-the-art (SOTA) models perform suboptimally in settings with high noise. To address the shortcomings of current machine learning (ML)-based denoising algorithms, we present a signal filtration algorithm driven by a new mixture-of-experts (MoE) framework. Our algorithm leverages three new statistical insights into the EEG-EMG denoising problem: (1) EMG artifacts can be partitioned into quantifiable subtypes to aid downstream MoE classification, (2) local experts trained on narrower signal-to-noise ratio (SNR) ranges can achieve performance increases through specialization, and (3) correlation-based objective functions, in conjunction with rescaling algorithms, can enable faster convergence in a neural network-based denoising context. We empirically demonstrate these three insights into EMG artifact removal and use our findings to create a new downstream MoE denoising algorithm consisting of convolutional (CNN) and recurrent (RNN) neural networks. We tested all results on a major benchmark dataset (EEGdenoiseNet) collected from 67 subjects. We found that our MoE denoising model achieved competitive overall performance with SOTA ML denoising algorithms and superior lower bound performance in high noise settings. These preliminary results highlight the promise of our MoE framework for enabling advances in EMG artifact removal for EEG processing, especially in high noise settings. Further research and development will be necessary to assess our MoE framework on a wider range of real-world test cases and explore its downstream potential to unlock more effective neural interfaces.",
        "tags": [
            "MoE",
            "RNN"
        ]
    },
    {
        "id": "228",
        "title": "Anchored Langevin Algorithms",
        "author": [
            "Mert Gurbuzbalaban",
            "Hoang M. Nguyen",
            "Xicheng Zhang",
            "Lingjiong Zhu"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19455",
        "abstract": "Standard first-order Langevin algorithms such as the unadjusted Langevin algorithm (ULA) are obtained by discretizing the Langevin diffusion and are widely used for sampling in machine learning because they scale to high dimensions and large datasets. However, they face two key limitations: (i) they require differentiable log-densities, excluding targets with non-differentiable components; and (ii) they generally fail to sample heavy-tailed targets. We propose anchored Langevin dynamics, a unified approach that accommodates non-differentiable targets and certain classes of heavy-tailed distributions. The method replaces the original potential with a smooth reference potential and modifies the Langevin diffusion via multiplicative scaling. We establish non-asymptotic guarantees in the 2-Wasserstein distance to the target distribution and provide an equivalent formulation derived via a random time change of the Langevin diffusion. We provide numerical experiments to illustrate the theory and practical performance of our proposed approach.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "229",
        "title": "Stochastic Path Planning in Correlated Obstacle Fields",
        "author": [
            "Li Zhou",
            "Elvan Ceyhan"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19559",
        "abstract": "We introduce the Stochastic Correlated Obstacle Scene (SCOS) problem, a navigation setting with spatially correlated obstacles of uncertain blockage status, realistically constrained sensors that provide noisy readings and costly disambiguation. Modeling the spatial correlation with Gaussian Random Field (GRF), we develop Bayesian belief updates that refine blockage probabilities, and use the posteriors to reduce search space for efficiency. To find the optimal traversal policy, we propose a novel two-stage learning framework. An offline phase learns a robust base policy via optimistic policy iteration augmented with information bonus to encourage exploration in informative regions, followed by an online rollout policy with periodic base updates via a Bayesian mechanism for information adaptation. This framework supports both Monte Carlo point estimation and distributional reinforcement learning (RL) to learn full cost distributions, leading to stronger uncertainty quantification. We establish theoretical benefits of correlation-aware updating and convergence property under posterior sampling. Comprehensive empirical evaluations across varying obstacle densities, sensor capabilities demonstrate consistent performance gains over baselines. This framework addresses navigation challenges in environments with adversarial interruptions or clustered natural hazards.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "230",
        "title": "Frame-Stacked Local Transformers For Efficient Multi-Codebook Speech Generation",
        "author": [
            "Roy Fejgin",
            "Paarth Neekhara",
            "Xuesong Yang",
            "Edresson Casanova",
            "Ryan Langman Jaehyeon Kim",
            "Subhankar Ghosh",
            "Shehzeen Hussain",
            "Jason Li"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19592",
        "abstract": "Speech generation models based on large language models (LLMs) typically operate on discrete acoustic codes, which differ fundamentally from text tokens due to their multicodebook structure. At each timestep, models must predict N codebook entries jointly, introducing dependencies that challenge simple parallel prediction approaches. Parallel prediction assumes independence among codebooks, yielding efficient decoding but often at the cost of reduced fidelity. To address this, hierarchical strategies employ a local transformer (LT) to refine predictions and capture intra-timestep dependencies. In this work, we systematically investigate two LT architectures: an autoregressive transformer that generates codebooks sequentially, and a MaskGIT-based transformer that performs iterative masked prediction. Both designs further enable frame stacking, where the primary transformer predicts multiple frames jointly, and the LT decodes their codebooks, offering improvements in speed without compromising perceptual quality. Through extensive analysis, we characterize the tradeoffs between parallel and iterative sampling strategies across different throughput and quality regimes. Finally, we propose practical guidelines for selecting decoding strategies based on deployment priorities such as computational efficiency and synthesis fidelity.",
        "tags": [
            "LLM",
            "Transformer"
        ]
    },
    {
        "id": "231",
        "title": "Advancing Speech Summarization in Multi-modal LLMs with Reinforcement Learning",
        "author": [
            "Shaoshi Ling",
            "Gang Liu",
            "Guoli Ye",
            "Jinyu Li"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19631",
        "abstract": "Speech summarization is a critical component of spoken content understanding, particularly in the era of rapidly growing spoken and audiovisual data. Recent advances in multi-modal large language models (MLLMs), leveraging the power of LLMs, enable generating textual summaries directly from speech without intermediate transcriptions, while supporting controllable styles and zero-shot generalization. However, open-source MLLMs continue to lag behind the state-of-the-art text-based LLMs, limiting their practical deployment for speech summarization. In this work, we present a novel multi-stage reinforcement learning training framework to enhance the speech summarization capabilities in MLLMs. Our model delivers substantial improvements over strong baselines, outperforms much larger MLLMs, and significantly narrows the gap with state-of-the-art text-based LLMs.",
        "tags": [
            "LLM",
            "RL"
        ]
    },
    {
        "id": "232",
        "title": "Diffusion and Flow-based Copulas: Forgetting and Remembering Dependencies",
        "author": [
            "David Huk",
            "Theodoros Damoulas"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19707",
        "abstract": "Copulas are a fundamental tool for modelling multivariate dependencies in data, forming the method of choice in diverse fields and applications. However, the adoption of existing models for multimodal and high-dimensional dependencies is hindered by restrictive assumptions and poor scaling. In this work, we present methods for modelling copulas based on the principles of diffusions and flows. We design two processes that progressively forget inter-variable dependencies while leaving dimension-wise distributions unaffected, provably defining valid copulas at all times. We show how to obtain copula models by learning to remember the forgotten dependencies from each process, theoretically recovering the true copula at optimality. The first instantiation of our framework focuses on direct density estimation, while the second specialises in expedient sampling. Empirically, we demonstrate the superior performance of our proposed methods over state-of-the-art copula approaches in modelling complex and high-dimensional dependencies from scientific datasets and images. Our work enhances the representational power of copula models, empowering applications and paving the way for their adoption on larger scales and more challenging domains.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "233",
        "title": "Dynamically Optimal Unraveling Schemes for Simulating Lindblad Equations",
        "author": [
            "Yu Cao",
            "Mingfeng He",
            "Xiantao Li"
        ],
        "pdf": "https://arxiv.org/pdf/2509.19887",
        "abstract": "Stochastic unraveling schemes are powerful computational tools for simulating Lindblad equations, offering significant reductions in memory requirements. However, this advantage is accompanied by increased stochastic uncertainty, and the question of optimal unraveling remains open. In this work, we investigate unraveling schemes driven by Brownian motion or Poisson processes and present a comprehensive parametric characterization of these approaches. For the case of a single Lindblad operator and one noise term, this parametric family provides a complete description for unraveling scheme with pathwise norm-preservation. We further analytically derive dynamically optimal quantum state diffusion (DO-QSD) and dynamically optimal quantum jump process (DO-QJP) that minimize the short-time growth of the variance of an observable. Compared to jump process ansatz, DO-QSD offers two notable advantages: firstly, the variance for DO-QSD can be rigorously shown not to exceed that of any jump-process ansatz locally in time; secondly, it has very simple expressions. Numerical results demonstrate that the proposed DO-QSD scheme may achieve substantial reductions in the variance of observables and the resulting simulation error.",
        "tags": [
            "Diffusion"
        ]
    }
]