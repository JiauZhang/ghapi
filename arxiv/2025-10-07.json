[
    {
        "id": "1",
        "title": "PARS: Low-Latency LLM Serving via Pairwise Learning-to-Rank",
        "author": [
            "Yiheng Tao",
            "Yihe Zhang",
            "Matthew T. Dearing",
            "Xin Wang",
            "Yuping Fan",
            "Zhiling Lan"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03243",
        "abstract": "Efficient scheduling of LLM inference tasks is essential for achieving low latency and high throughput, particularly with the growing use of reasoning-capable LLMs. Traditional strategies like First-Come-First-Serve (FCFS) often suffer from Head-of-Line (HOL) blocking, where long-running tasks delay shorter ones queued behind them. In this paper, we introduce PARS, a prompt-aware LLM task scheduler that improves serving efficiency by approximating shortest-job-first (SJF) scheduling through pairwise ranking with margin ranking loss. PARS focuses on impactful scheduling decisions and is seamlessly integrated into the state-of-the-art LLM serving system vLLM. It effectively predicts response-length-based task ordering, reducing latency with minimal overhead. Extensive experiments across multiple LLMs and real-world inference datasets show that PARS significantly improves performance, including for reasoning workloads. Furthermore, our cross-model evaluations demonstrate that the design generalizes well, enabling effective scheduling even when predictors are trained on different LLMs.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "2",
        "title": "StructPrune: Structured Global Pruning asymptotics with $\\mathcal{O}(\\sqrt{N})$ GPU Memory",
        "author": [
            "Xinyuan Song",
            "Guangji Bai",
            "Liang Zhao"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03246",
        "abstract": "Pruning is critical for scaling large language models (LLMs). Global pruning achieves strong performance but requires $\\mathcal{O}(N)$ memory, which is infeasible for billion-parameter models. Local pruning reduces GPU memory usage to that of a single layer by pruning layers independently, but it neglects inter-layer dependencies and often leads to suboptimal performance in high-sparsity regimes. Unlike unstructured pruning, structured pruning produces regular sparsity patterns that align well with GPU kernels and library optimizations, making it more hardware-efficient. However, structured pruning typically relies on global pruning, since structured patterns are more prone to severe performance degradation under local optimization. To jointly achieve structured pruning and the memory efficiency of local pruning, we propose a divide-and-conquer strategy that decomposes the global pruning problem into coordinated subproblems across different modules, each of which fits within limited GPU memory. Building on this idea, we design \\textbf{STRUPRUNE}, an ADMM-based framework that integrates structured sparsity into the pruning process, combining the memory efficiency of local pruning with the hardware compatibility of structured methods. We derive a closed-form analytical solution for structured pruning masks that provides an explicit rule for layer-wise sparsity allocation, and further develop an energy-based asymptotic framework yielding a softmax-form allocation scheme that simplifies optimization while adapting to heterogeneous layer importance. Experiments demonstrate that STRUPRUNE matches the perplexity of global structured pruning while reducing memory cost from $\\mathcal{O}(N)$ to $\\mathcal{O}(\\sqrt{N})$, enabling practical deployment at the billion-parameter scale.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "3",
        "title": "Towards Multimodal Active Learning: Efficient Learning with Limited Paired Data",
        "author": [
            "Jiancheng Zhang",
            "Yinglun Zhu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03247",
        "abstract": "Active learning (AL) is a principled strategy to reduce annotation cost in data-hungry deep learning. However, existing AL algorithms focus almost exclusively on unimodal data, overlooking the substantial annotation burden in multimodal learning. We introduce the first framework for multimodal active learning with unaligned data, where the learner must actively acquire cross-modal alignments rather than labels on pre-aligned pairs. This setting captures the practical bottleneck in modern multimodal pipelines such as CLIP and SigLIP, where unimodal features are easy to obtain but high-quality alignment is costly. We develop a new algorithm that combines uncertainty and diversity principles in a modality-aware design, achieves linear-time acquisition, and applies seamlessly to both pool-based and streaming-based settings. Extensive experiments on benchmark datasets demonstrate that our approach consistently reduces multimodal annotation cost while preserving performance; for instance, on the ColorSwap dataset it cuts annotation requirements by up to $40\\%$ without loss in accuracy.",
        "tags": [
            "CLIP"
        ]
    },
    {
        "id": "4",
        "title": "Universal Multi-Domain Translation via Diffusion Routers",
        "author": [
            "Duc Kieu",
            "Kien Do",
            "Tuan Hoang",
            "Thao Minh Le",
            "Tung Kieu",
            "Dang Nguyen",
            "Thin Nguyen"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03252",
        "abstract": "Multi-domain translation (MDT) aims to learn translations between multiple domains, yet existing approaches either require fully aligned tuples or can only handle domain pairs seen in training, limiting their practicality and excluding many cross-domain mappings. We introduce universal MDT (UMDT), a generalization of MDT that seeks to translate between any pair of $K$ domains using only $K-1$ paired datasets with a central domain. To tackle this problem, we propose Diffusion Router (DR), a unified diffusion-based framework that models all central$\\leftrightarrow$non-central translations with a single noise predictor conditioned on the source and target domain labels. DR enables indirect non-central translations by routing through the central domain. We further introduce a novel scalable learning strategy with a variational-bound objective and an efficient Tweedie refinement procedure to support direct non-central mappings. Through evaluation on three large-scale UMDT benchmarks, DR achieves state-of-the-art results for both indirect and direct translations, while lowering sampling cost and unlocking novel tasks such as sketch$\\leftrightarrow$segmentation. These results establish DR as a scalable and versatile framework for universal translation across multiple domains.",
        "tags": [
            "Diffusion",
            "Segmentation"
        ]
    },
    {
        "id": "5",
        "title": "Solving the Granularity Mismatch: Hierarchical Preference Learning for Long-Horizon LLM Agents",
        "author": [
            "Heyang Gao",
            "Zexu Sun",
            "Erxue Min",
            "Hengyi Cai",
            "Shuaiqiang Wang",
            "Dawei Yin",
            "Xu Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03253",
        "abstract": "Large Language Models (LLMs) as autonomous agents are increasingly tasked with solving complex, long-horizon problems. Aligning these agents via preference-based offline methods like Direct Preference Optimization (DPO) is a promising direction, yet it faces a critical granularity mismatch. Trajectory-level DPO provides a signal that is too coarse for precise credit assignment, while step-level DPO is often too myopic to capture the value of multi-step behaviors. To resolve this challenge, we introduce Hierarchical Preference Learning (HPL), a hierarchical framework that optimizes LLM agents by leveraging preference signals at multiple, synergistic granularities. While HPL incorporates trajectory- and step-level DPO for global and local policy stability, its core innovation lies in group-level preference optimization guided by a dual-layer curriculum. Our approach first decomposes expert trajectories into semantically coherent action groups and then generates contrasting suboptimal groups to enable preference learning at a fine-grained, sub-task level. Then, instead of treating all preference pairs equally, HPL introduces a curriculum scheduler that organizes the learning process from simple to complex. This curriculum is structured along two axes: the group length, representing sub-task complexity, and the sample difficulty, defined by the reward gap between preferred and dispreferred action groups. Experiments on three challenging agent benchmarks show that HPL outperforms existing state-of-the-art methods. Our analyses demonstrate that the hierarchical DPO loss effectively integrates preference signals across multiple granularities, while the dual-layer curriculum is crucial for enabling the agent to solve a wide range of tasks, from simple behaviors to complex multi-step sequences.",
        "tags": [
            "DPO",
            "LLM"
        ]
    },
    {
        "id": "6",
        "title": "SciTS: Scientific Time Series Understanding and Generation with LLMs",
        "author": [
            "Wen Wu",
            "Ziyang Zhang",
            "Liwei Liu",
            "Xuenan Xu",
            "Junlin Liu",
            "Ke Fan",
            "Qitan Lv",
            "Jimin Zhuang",
            "Chen Zhang",
            "Zheqi Yuan",
            "Siyuan Hou",
            "Tianyi Lin",
            "Kai Chen",
            "Bowen Zhou",
            "Chao Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03255",
        "abstract": "The scientific reasoning ability of large language models (LLMs) has recently attracted significant attention. Time series, as a fundamental modality in scientific data, presents unique challenges that are often overlooked in current multimodal LLMs, which either encode numerical sequences as text or convert them into images. Such approaches may be insufficient for comprehensive scientific time series understanding and generation. Existing unified time series models typically specialise in either forecasting or analysis, and their effectiveness on non-periodic, heterogeneous scientific signals remains unclear. To address these gaps, we introduce SciTS, a benchmark spanning 12 scientific domains and 43 tasks, with over 50k+ instances, both univariate and multivariate signals ranging from $10^0$ to $10^7$ in length and up to 10~MHz in frequency. We benchmark 17 models, including text-only LLMs, multimodal LLMs, and unified time series models, and find that general-purpose LLMs exhibit stronger generalisability than specialised time series models, while representing time series as text or images limits their performance due to excessively long sequences and loss of numerical precision, respectively. We then introduce TimeOmni, a framework that equips LLMs with the ability to understand and generate time series while remaining compatible with general-purpose LLM training. This work fills a gap in both dedicated benchmarks and modelling frameworks for scientific time series, paving the way for LLMs to understand and generate complex temporal scientific data.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "7",
        "title": "Triple-BERT: Do We Really Need MARL for Order Dispatch on Ride-Sharing Platforms?",
        "author": [
            "Zijian Zhao",
            "Sen Li"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03257",
        "abstract": "On-demand ride-sharing platforms, such as Uber and Lyft, face the intricate real-time challenge of bundling and matching passengers-each with distinct origins and destinations-to available vehicles, all while navigating significant system uncertainties. Due to the extensive observation space arising from the large number of drivers and orders, order dispatching, though fundamentally a centralized task, is often addressed using Multi-Agent Reinforcement Learning (MARL). However, independent MARL methods fail to capture global information and exhibit poor cooperation among workers, while Centralized Training Decentralized Execution (CTDE) MARL methods suffer from the curse of dimensionality. To overcome these challenges, we propose Triple-BERT, a centralized Single Agent Reinforcement Learning (MARL) method designed specifically for large-scale order dispatching on ride-sharing platforms. Built on a variant TD3, our approach addresses the vast action space through an action decomposition strategy that breaks down the joint action probability into individual driver action probabilities. To handle the extensive observation space, we introduce a novel BERT-based network, where parameter reuse mitigates parameter growth as the number of drivers and orders increases, and the attention mechanism effectively captures the complex relationships among the large pool of driver and orders. We validate our method using a real-world ride-hailing dataset from Manhattan. Triple-BERT achieves approximately an 11.95% improvement over current state-of-the-art methods, with a 4.26% increase in served orders and a 22.25% reduction in pickup times. Our code, trained model parameters, and processed data are publicly available at the repository https://github.com/RS2002/Triple-BERT .",
        "tags": [
            "BERT",
            "RL"
        ]
    },
    {
        "id": "8",
        "title": "Meta-Awareness Enhances Reasoning Models: Self-Alignment Reinforcement Learning",
        "author": [
            "Yoonjeon Kim",
            "Doohyuk Jang",
            "Eunho Yang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03259",
        "abstract": "Recent studies on reasoning models explore the meta-awareness of language models, the ability to know how to think by itself. We argue that large reasoning models lack this meta-awareness property by proving severe misalignment between true rollouts and predicted meta information. We posit that aligning meta-prediction with true rollouts will lead to significant performance gains. To verify this hypothesis, we design a training pipeline that boosts Meta-Awareness via Self-Alignment (MASA), and prove that enhanced meta-awareness directly translates to improved accuracy. Unlike existing meta-cognitive reasoning models, our method does not require external training sources but leverages self-generated signals to train meta-awareness. Moreover, our method enables efficient training by i) filtering out zero-variance prompts that are either trivial or unsolvable and ii) cutting off lengthy rollouts when they are unlikely to lead to correct answers. The results are inspiring: our strategy yields significant improvements in both accuracy and training efficiency on in-domain tasks and shows strong generalization to out-of-domain benchmarks. More specifically, our method can speed up GRPO training by over 1.28x to reach the same performance, and achieve a 19.3% gain in accuracy on AIME25, and a 6.2 % average gain over six mathematics benchmarks. Training with meta-cognitive guidance enhances out-of-domain generalization, giving a 3.87 % boost on GPQA-Diamond and a 2.08 % overall accuracy gain across 13 benchmarks spanning logical, scientific, and coding domains.",
        "tags": [
            "GRPO",
            "RL"
        ]
    },
    {
        "id": "9",
        "title": "Data-Driven Temperature Modelling of Machine Tools by Neural Networks: A Benchmark",
        "author": [
            "C. Coelho",
            "M. Hohmann",
            "D. FernÃ¡ndez",
            "L. Penter",
            "S. Ihlenfeldt",
            "O. Niggemann"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03261",
        "abstract": "Thermal errors in machine tools significantly impact machining precision and productivity. Traditional thermal error correction/compensation methods rely on measured temperature-deformation fields or on transfer functions. Most existing data-driven compensation strategies employ neural networks (NNs) to directly predict thermal errors or specific compensation values. While effective, these approaches are tightly bound to particular error types, spatial locations, or machine configurations, limiting their generality and adaptability. In this work, we introduce a novel paradigm in which NNs are trained to predict high-fidelity temperature and heat flux fields within the machine tool. The proposed framework enables subsequent computation and correction of a wide range of error types using modular, swappable downstream components. The NN is trained using data obtained with the finite element method under varying initial conditions and incorporates a correlation-based selection strategy that identifies the most informative measurement points, minimising hardware requirements during inference. We further benchmark state-of-the-art time-series NN architectures, namely Recurrent NN, Gated Recurrent Unit, Long-Short Term Memory (LSTM), Bidirectional LSTM, Transformer, and Temporal Convolutional Network, by training both specialised models, tailored for specific initial conditions, and general models, capable of extrapolating to unseen scenarios. The results show accurate and low-cost prediction of temperature and heat flux fields, laying the basis for enabling flexible and generalisable thermal error correction in machine tool environments.",
        "tags": [
            "FLUX",
            "Transformer"
        ]
    },
    {
        "id": "10",
        "title": "Rethinking Inter-LoRA Orthogonality in Adapter Merging: Insights from Orthogonal Monte Carlo Dropout",
        "author": [
            "Andi Zhang",
            "Xuan Ding",
            "Haofan Wang",
            "Steven McDonagh",
            "Samuel Kaski"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03262",
        "abstract": "We propose Orthogonal Monte Carlo Dropout, a mechanism that enforces strict orthogonality when combining sparse semantic vectors without extra time complexity. LoRA, a popular fine-tuning method for large models, typically trains a module to represent a specific concept such as an object or a style. When multiple LoRAs are merged, for example to generate an object in a particular style, their semantic vectors may interfere with each other. Our method guarantees, at the theoretical and runtime levels, that merged LoRAs remain orthogonal and thus free from direct interference. However, empirical analysis reveals that such orthogonality does not lead to the semantic disentanglement or compositionality highlighted in prior work on compositional adaptation. This finding suggests that inter-LoRA orthogonality alone may be insufficient for achieving true semantic compositionality, prompting a re-examination of its role in adapter merging.",
        "tags": [
            "LoRA"
        ]
    },
    {
        "id": "11",
        "title": "Memory Self-Regeneration: Uncovering Hidden Knowledge in Unlearned Models",
        "author": [
            "Agnieszka Polowczyk",
            "Alicja Polowczyk",
            "Joanna WaczyÅska",
            "Piotr Borycki",
            "PrzemysÅaw Spurek"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03263",
        "abstract": "The impressive capability of modern text-to-image models to generate realistic visuals has come with a serious drawback: they can be misused to create harmful, deceptive or unlawful content. This has accelerated the push for machine unlearning. This new field seeks to selectively remove specific knowledge from a model's training data without causing a drop in its overall performance. However, it turns out that actually forgetting a given concept is an extremely difficult task. Models exposed to attacks using adversarial prompts show the ability to generate so-called unlearned concepts, which can be not only harmful but also illegal. In this paper, we present considerations regarding the ability of models to forget and recall knowledge, introducing the Memory Self-Regeneration task. Furthermore, we present MemoRa strategy, which we consider to be a regenerative approach supporting the effective recovery of previously lost knowledge. Moreover, we propose that robustness in knowledge retrieval is a crucial yet underexplored evaluation measure for developing more robust and effective unlearning techniques. Finally, we demonstrate that forgetting occurs in two distinct ways: short-term, where concepts can be quickly recalled, and long-term, where recovery is more challenging.",
        "tags": [
            "Text-to-Image"
        ]
    },
    {
        "id": "12",
        "title": "Front-Loading Reasoning: The Synergy between Pretraining and Post-Training Data",
        "author": [
            "Syeda Nahida Akter",
            "Shrimai Prabhumoye",
            "Eric Nyberg",
            "Mostofa Patwary",
            "Mohammad Shoeybi",
            "Yejin Choi",
            "Bryan Catanzaro"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03264",
        "abstract": "The prevailing paradigm for enhancing the reasoning abilities of LLMs revolves around post-training on high-quality, reasoning-intensive data. While emerging literature suggests that reasoning data is increasingly incorporated also during the mid-training stage-a practice that is relatively more proprietary and less openly characterized-the role of such data in pretraining remains unclear. In particular, due to the opaqueness of pretraining corpora in most frontier models, the effect of reasoning data introduced at different phases of pre- and/or post-training is relatively less reported in the scientific literature. This raises several important questions: Is adding reasoning data earlier during pretraining any better than introducing it during post-training? Could earlier inclusion risk overfitting and harm generalization, or instead establish durable foundations that later fine-tuning cannot recover? We conduct the first systematic study of how reasoning data-varying in scale, diversity, and quality-affects LLM performance when introduced at different stages of training. We find that front-loading reasoning data into pretraining is critical (19% avg gain), establishing foundational capabilities that cannot be fully replicated by later-stage SFT, even with more data. We uncover an asymmetric principle for optimal data allocation: pretraining benefits most from broad diversity in reasoning patterns (11% avg gain), while SFT is more sensitive to data quality (15% avg gain). We show that high-quality pretraining data has latent effects, activated only after SFT, and that naively scaling SFT data can be detrimental, washing away the benefits of early reasoning injection. Our results challenge the conventional separation of language modeling and reasoning, providing a principled guide for strategically allocating data across the entire training pipeline to build more capable models.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "13",
        "title": "PT$^2$-LLM: Post-Training Ternarization for Large Language Models",
        "author": [
            "Xianglong Yan",
            "Chengzhu Bao",
            "Zhiteng Li",
            "Tianao Zhang",
            "Kaicheng Yang",
            "Haotong Qin",
            "Ruobing Xie",
            "Xingwu Sun",
            "Yulun Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03267",
        "abstract": "Large Language Models (LLMs) have shown impressive capabilities across diverse tasks, but their large memory and compute demands hinder deployment. Ternarization has gained attention as a promising compression technique, delivering substantial size reduction and high computational efficiency. However, its potential in the post-training quantization (PTQ) setting remains underexplored, due to the challenge of training-free parameter optimization and the quantization difficulty posed by outliers and dispersed weights. To address these issues, we propose PT$^2$-LLM, a post-training ternarization framework tailored for LLMs. At its core is an Asymmetric Ternary Quantizer equipped with a two-stage refinement pipeline: (1) Iterative Ternary Fitting (ITF), which alternates between optimal ternary grid construction and flexible rounding to minimize quantization error, and (2) Activation-aware Grid Alignment (AGA), which further refines the ternary grid to better match full-precision outputs. In addition, we propose a plug-and-play Structural Similarity-based Reordering (SSR) strategy that leverages inter-column structural similarity to ease quantization and mitigate outlier effects, further enhancing overall performance. Extensive experiments demonstrate that PT$^2$-LLM delivers competitive performance against state-of-the-art (SOTA) 2-bit PTQ methods with lower memory cost, while also accelerating both prefill and decoding to achieve end-to-end speedup. The code and models will be available at https://github.com/XIANGLONGYAN/PT2-LLM.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "14",
        "title": "General Exploratory Bonus for Optimistic Exploration in RLHF",
        "author": [
            "Wendi Li",
            "Changdae Oh",
            "Yixuan Li"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03269",
        "abstract": "Optimistic exploration is central to improving sample efficiency in reinforcement learning with human feedback, yet existing exploratory bonus methods to incentivize exploration often fail to realize optimism. We provide a theoretical analysis showing that current formulations, under KL or $\\alpha$-divergence regularization, unintentionally bias exploration toward high-probability regions of the reference model, thereby reinforcing conservative behavior instead of promoting discovery of uncertain regions. To address this pitfall, we introduce the General Exploratory Bonus (GEB), a novel theoretical framework that provably satisfies the optimism principle. GEB counteracts divergence-induced bias via reference-dependent reward regulation and unifies prior heuristic bonuses as special cases, while extending naturally across the full $\\alpha$-divergence family. Empirically, GEB consistently outperforms baselines on alignment tasks across multiple divergence settings and large language model backbones. These results demonstrate that GEB offers both a principled and practical solution for optimistic exploration in RLHF.",
        "tags": [
            "RL",
            "RLHF"
        ]
    },
    {
        "id": "15",
        "title": "CoDA: Coding LM via Diffusion Adaptation",
        "author": [
            "Haolin Chen",
            "Shiyu Wang",
            "Can Qin",
            "Bo Pang",
            "Zuxin Liu",
            "Jielin Qiu",
            "Jianguo Zhang",
            "Yingbo Zhou",
            "Zeyuan Chen",
            "Ran Xu",
            "Shelby Heinecke",
            "Silvio Savarese",
            "Caiming Xiong",
            "Huan Wang",
            "Weiran Yao"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03270",
        "abstract": "Diffusion language models promise bidirectional context and infilling capabilities that autoregressive coders lack, yet practical systems remain heavyweight. We introduce CoDA, a 1.7B-parameter diffusion coder trained on TPU with a fully open-source training pipeline. CoDA pairs large-scale diffusion pre-training with code-centric mid-training and instruction tuning, enabling confidence-guided sampling that keeps inference latency competitive. On Humaneval, MBPP, and EvalPlus, CoDA-1.7B-Instruct matches or surpasses diffusion models up to 7B parameters. Our release includes model checkpoints, evaluation harnesses, and TPU training pipelines to accelerate research on lightweight diffusion-based coding assistants.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "16",
        "title": "Decision Potential Surface: A Theoretical and Practical Approximation of LLM's Decision Boundary",
        "author": [
            "Zi Liang",
            "Zhiyao Wu",
            "Haoyang Shang",
            "Yulin Jin",
            "Qingqing Ye",
            "Huadi Zheng",
            "Peizhao Hu",
            "Haibo Hu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03271",
        "abstract": "Decision boundary, the subspace of inputs where a machine learning model assigns equal classification probabilities to two classes, is pivotal in revealing core model properties and interpreting behaviors. While analyzing the decision boundary of large language models (LLMs) has raised increasing attention recently, constructing it for mainstream LLMs remains computationally infeasible due to the enormous vocabulary-sequence sizes and the auto-regressive nature of LLMs. To address this issue, in this paper we propose Decision Potential Surface (DPS), a new notion for analyzing LLM decision boundary. DPS is defined on the confidences in distinguishing different sampling sequences for each input, which naturally captures the potential of decision boundary. We prove that the zero-height isohypse in DPS is equivalent to the decision boundary of an LLM, with enclosed regions representing decision regions. By leveraging DPS, for the first time in the literature, we propose an approximate decision boundary construction algorithm, namely $K$-DPS, which only requires K-finite times of sequence sampling to approximate an LLM's decision boundary with negligible error. We theoretically derive the upper bounds for the absolute error, expected error, and the error concentration between K-DPS and the ideal DPS, demonstrating that such errors can be trade-off with sampling times. Our results are empirically validated by extensive experiments across various LLMs and corpora.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "17",
        "title": "PDE-Transformer: A Continuous Dynamical Systems Approach to Sequence Modeling",
        "author": [
            "Yukun Zhang",
            "Xueqing Zhou"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03272",
        "abstract": "The Transformer architecture has revolutionized artificial intelligence, yet a principled theoretical understanding of its internal mechanisms remains elusive. This paper introduces a novel analytical framework that reconceptualizes the Transformer's discrete, layered structure as a continuous spatiotemporal dynamical system governed by a master Partial Differential Equation (PDE). Within this paradigm, we map core architectural components to distinct mathematical operators: self-attention as a non-local interaction, the feed-forward network as a local reaction, and, critically, residual connections and layer normalization as indispensable stabilization mechanisms. We do not propose a new model, but rather employ the PDE system as a theoretical probe to analyze the mathematical necessity of these components. By comparing a standard Transformer with a PDE simulator that lacks explicit stabilizers, our experiments provide compelling empirical evidence for our central thesis. We demonstrate that without residual connections, the system suffers from catastrophic representational drift, while the absence of layer normalization leads to unstable, explosive training dynamics. Our findings reveal that these seemingly heuristic \"tricks\" are, in fact, fundamental mathematical stabilizers required to tame an otherwise powerful but inherently unstable continuous system. This work offers a first-principles explanation for the Transformer's design and establishes a new paradigm for analyzing deep neural networks through the lens of continuous dynamics.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "18",
        "title": "Quant-dLLM: Post-Training Extreme Low-Bit Quantization for Diffusion Large Language Models",
        "author": [
            "Tianao Zhang",
            "Zhiteng Li",
            "Xianglong Yan",
            "Haotong Qin",
            "Yong Guo",
            "Yulun Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03274",
        "abstract": "Diffusion large language models (dLLMs), which offer bidirectional context and flexible masked-denoising generation, are emerging as a compelling alternative to autoregressive (AR) LLMs. However, like AR LLMs, their model sizes continue to grow, motivating weight compression for deployment. Although post-training quantization (PTQ) is effective for AR LLMs, directly transferring it to dLLMs at 2-bit leads to unsatisfactory performance. To tackle these challenges, we propose Quant-dLLM, an ultra-low-bit PTQ framework tailored to dLLMs. Since masked-denoising activations in dLLMs differ from the fully visible signals assumed by standard PTQ methods, we introduce Masked Calibration Simulation (MCS) to align calibration with the timestep-dependent masking, which yields more reliable calibrations. Moreover, we propose a Data-aware Any-order Quantizer (DAQ) that learns ultra-low-bit weight representations via an optimization algorithm. It performs iterative approximation guided by our simulated calibration data. In addition, under a strict 2-bit budget, we introduce Adaptive Blockwise Mixed Precision (ABMP), a sensitivity-based precision allocation scheme that adaptively assigns bit width across channel groups. When restricted to 2-bit precision, Quant-dLLM consistently achieves higher accuracy than state-of-the-art (SOTA) AR-transfer PTQ methods on dLLMs. The code and models will be available at: https://github.com/ZTA2785/Quant-dLLM.",
        "tags": [
            "Diffusion",
            "LLM"
        ]
    },
    {
        "id": "19",
        "title": "SDQ-LLM: Sigma-Delta Quantization for 1-bit LLMs of any size",
        "author": [
            "Junhao Xia",
            "Ming Zhao",
            "Limin Xiao",
            "Xiujun Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03275",
        "abstract": "Large language models (LLMs) face significant computational and memory challenges, making extremely low-bit quantization crucial for their efficient deployment. In this work, we introduce SDQ-LLM: Sigma-Delta Quantization for 1-bit LLMs of any size, a novel framework that enables extremely low-bit quantization of LLMs while preserving their linguistic reasoning capabilities. A distinctive feature of SDQ-LLM is the continuous adjustability of the Over-Sampling Ratio (OSR), enabling dynamic adaptation to memory or VRAM constraints by selecting fractional OSR (e.g. 2.5 times) for an optimal trade-off between model size and accuracy. SDQ-LLM uses upsampling combined with Sigma-Delta Quantizer to binarize or ternarize LLMs weights, encoding high-precision parameters into 1-bit or 1.58-bit representations, replacing the multiplication operations within linear layers with addition. This approach significantly enhances inference efficiency under extremely low-bit quantization. To further reduce the loss of quantization precision, we incorporate Hadamard-based weight smoothing prior to quantization, improving the stability and robustness of the weight representations. Furthermore, to fully leverage the continuity of the OSR and reduce precision loss, recognizing the correlation between quantization sensitivity and weight variance, we propose a fine-grained, layer- and linear-wise OSR allocation strategy, MultiOSR. This strategy distributes OSR both across layers and within each layer, based on weight variance and parameter scale. Finally, extensive experiments on OPT and LLaMA model families demonstrate that SDQ-LLM achieves a more efficient and high-precision performance even under highly aggressive low-OSR settings. Our code is available at https://github.com/Dreamlittlecat/LLM-Quant-Factory.",
        "tags": [
            "LLM",
            "LLaMA"
        ]
    },
    {
        "id": "20",
        "title": "QuadEnhancer: Leveraging Quadratic Transformations to Enhance Deep Neural Networks",
        "author": [
            "Qian Chen",
            "Linxin Yang",
            "Akang Wang",
            "Xiaodong Luo",
            "Yin Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03276",
        "abstract": "The combination of linear transformations and non-linear activation functions forms the foundation of most modern deep neural networks, enabling them to approximate highly complex functions. This paper explores the introduction of quadratic transformations to further increase nonlinearity in neural networks, with the aim of enhancing the performance of existing architectures. To reduce parameter complexity and computational complexity, we propose a lightweight quadratic enhancer that uses low-rankness, weight sharing, and sparsification techniques. For a fixed architecture, the proposed approach introduces quadratic interactions between features at every layer, while only adding negligible amounts of additional model parameters and forward computations. We conduct a set of proof-of-concept experiments for the proposed method across three tasks: image classification, text classification, and fine-tuning large-language models. In all tasks, the proposed approach demonstrates clear and substantial performance gains.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "21",
        "title": "MemMamba: Rethinking Memory Patterns in State Space Model",
        "author": [
            "Youjin Wang",
            "Yangjingyi Chen",
            "Jiahao Yan",
            "Jiaxuan Lu",
            "Xiao Sun"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03279",
        "abstract": "With the explosive growth of data, long-sequence modeling has become increasingly important in tasks such as natural language processing and bioinformatics. However, existing methods face inherent trade-offs between efficiency and memory. Recurrent neural networks suffer from gradient vanishing and explosion, making them hard to scale. Transformers can model global dependencies but are constrained by quadratic complexity. Recently, selective state-space models such as Mamba have demonstrated high efficiency with O(n) time and O(1) recurrent inference, yet their long-range memory decays exponentially. In this work, we conduct mathematical derivations and information-theoretic analysis to systematically uncover the memory decay mechanism of Mamba, answering a fundamental question: what is the nature of Mamba's long-range memory and how does it retain information? To quantify key information loss, we further introduce horizontal-vertical memory fidelity metrics that capture degradation both within and across layers. Inspired by how humans distill and retain salient information when reading long documents, we propose MemMamba, a novel architectural framework that integrates state summarization mechanism together with cross-layer and cross-token attention, which alleviates long-range forgetting while preserving linear complexity. MemMamba achieves significant improvements over existing Mamba variants and Transformers on long-sequence benchmarks such as PG19 and Passkey Retrieval, while delivering a 48% speedup in inference efficiency. Both theoretical analysis and empirical results demonstrate that MemMamba achieves a breakthrough in the complexity-memory trade-off, offering a new paradigm for ultra-long sequence modeling.",
        "tags": [
            "Mamba",
            "SSMs"
        ]
    },
    {
        "id": "22",
        "title": "Training Optimal Large Diffusion Language Models",
        "author": [
            "Jinjie Ni",
            "Qian Liu",
            "Chao Du",
            "Longxu Dou",
            "Hang Yan",
            "Zili Wang",
            "Tianyu Pang",
            "Michael Qizhe Shieh"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03280",
        "abstract": "We introduce Quokka, the first systematic scaling law for diffusion language models (DLMs), encompassing both compute-constrained and data-constrained regimes, and studying the key modeling and optimization designs. Quokka is a good friend of Chinchilla and provides wider scopes. We hope the results would bring short-term practical guidance in DLMs training and long-term inspirations for the whole AI community.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "23",
        "title": "Discovering Transformer Circuits via a Hybrid Attribution and Pruning Framework",
        "author": [
            "Hao Gu",
            "Vibhas Nair",
            "Amrithaa Ashok Kumar",
            "Jayvart Sharma",
            "Ryan Lagasse"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03282",
        "abstract": "Interpreting language models often involves circuit analysis, which aims to identify sparse subnetworks, or circuits, that accomplish specific tasks. Existing circuit discovery algorithms face a fundamental trade-off: attribution patching is fast but unfaithful to the full model, while edge pruning is faithful but computationally expensive. This research proposes a hybrid attribution and pruning (HAP) framework that uses attribution patching to identify a high-potential subgraph, then applies edge pruning to extract a faithful circuit from it. We show that HAP is 46\\% faster than baseline algorithms without sacrificing circuit faithfulness. Furthermore, we present a case study on the Indirect Object Identification task, showing that our method preserves cooperative circuit components (e.g. S-inhibition heads) that attribution patching methods prune at high sparsity. Our results show that HAP could be an effective approach for improving the scalability of mechanistic interpretability research to larger models. Our code is available at https://anonymous.4open.science/r/HAP-circuit-discovery.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "24",
        "title": "Edge-FIT: Federated Instruction Tuning of Quantized LLMs for Privacy-Preserving Smart Home Environments",
        "author": [
            "Vinay Venkatesh",
            "Vamsidhar R Kamanuru",
            "Lav Kumar",
            "Nikita Kothari"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03284",
        "abstract": "This paper proposes Edge-FIT (Federated Instruction Tuning on the Edge), a scalable framework for Federated Instruction Tuning (FIT) of Large Language Models (LLMs). Traditional Federated Learning (TFL) methods, like FedAvg, fail when confronted with the massive parameter size of LLMs [3], [6]. Our Edge-FIT framework combines federated learning with 4-bit Quantized Low-Rank Adaptation (QLORA), mitigating the core issues of communication and computational overhead. We demonstrate this by filtering the general-purpose Databricks Dolly 15k dataset for the IoT domain. Experimental results show the Edge-FIT tuned Llama 2(7B) achieves an F1-Score of 0.89. We also demonstrate a viable trade-off using the 3.8B Phi-3-mini model, validating Edge-FIT as a scalable framework for decentralized LLM deployment on home compute gateways.",
        "tags": [
            "LLM",
            "LLaMA",
            "LoRA"
        ]
    },
    {
        "id": "25",
        "title": "WAREX: Web Agent Reliability Evaluation on Existing Benchmarks",
        "author": [
            "Su Kara",
            "Fazle Faisal",
            "Suman Nath"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03285",
        "abstract": "Recent advances in browser-based LLM agents have shown promise for automating tasks ranging from simple form filling to hotel booking or online shopping. Current benchmarks measure agent performance in controlled environments, such as containers or stable networks, where websites behave deterministically. However, in the real world, users access websites over networks and HTTPS connections that introduce instability from multiple sources: client-side, server-side issues or broader system failures. Moreover, live websites are prone to web attacks such Cross-Site Scripting, as well as general site modifications which can cause unexpected or malicious pop-ups or improper functionality. To address this gap, we present WAREX: Web Agent Reliability Evaluation on Existing Benchmarks. We measure the impact of WAREX across three popular benchmarks: WebArena, WebVoyager, and REAL. Our experiments show that introducing WAREX leads to significant drops in task success rates, highlighting the limited robustness of state-of-the-art agents.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "26",
        "title": "Why mask diffusion does not work",
        "author": [
            "Haocheng Sun",
            "Cynthia Xin Wen",
            "Edward Hong Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03289",
        "abstract": "The main advantages of diffusion language models over autoregressive (AR) models lie in their ability to support parallel generation and bidirectional attention, enabling a more controllable generation process. In recent years, open-source mask diffusion language models have emerged, most of which are based on a variant known as absorbing diffusion. However, this paper demonstrates why mask diffusion faces inherent difficulties in achieving parallel generation and bidirectional attention. We also propose the most effective training and inference strategies for mask diffusion.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "27",
        "title": "UniPruning: Unifying Local Metric and Global Feedback for Scalable Sparse LLMs",
        "author": [
            "Yizhuo Ding",
            "Wanying Qu",
            "Jiawei Geng",
            "Wenqi Shao",
            "Yanwei Fu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03291",
        "abstract": "Large Language Models (LLMs) achieve strong performance across diverse tasks but face prohibitive computational and memory costs. Pruning offers a promising path by inducing sparsity while preserving architectural flexibility. However, existing methods struggle to balance efficiency and robustness: local metric approaches prune layer by layer but often collapse under high sparsity, whereas global feedback methods enforce consistency at the cost of expensive weight updates or restrictive semi-structured formats. We present UniPruning, a unified post-training pruning framework that combines the speed of local saliency metrics with the stability of global coordination, enabled by a mirror descent based optimization, all without updating model weights. UniPruning leverages fast layer-wise scoring and a lightweight global controller to allocate a single sparsity budget, supporting both unstructured and semi-structured N :M pruning within one framework. After a brief calibration, it can generate pruning masks for arbitrary sparsity levels in one shot, and adapts seamlessly to hardware-aware constraints. Extensive experiments on multiple pretrained LLM families and standard benchmarks show that UniPruning consistently delivers competitive or superior perplexity and zero-shot accuracy. Ablation studies further highlight the importance of mirror descent and local saliency anchoring. Overall, UniPruning provides an efficient, principled, and scalable solution for sparsifying large-scale LLMs. Our code is available at: https://github.com/RainbowQTT/UniPruning.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "28",
        "title": "From Score Distributions to Balance: Plug-and-Play Mixture-of-Experts Routing",
        "author": [
            "Rana Shahout",
            "Colin Cai",
            "Yilun Du",
            "Minlan Yu",
            "Michael Mitzenmacher"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03293",
        "abstract": "Mixture-of-Experts (MoE) models can scale parameter capacity by routing each token to a subset of experts through a learned gate function. While conditional routing reduces training costs, it shifts the burden on inference memory: expert parameters and activations consume memory, limiting the number of experts per device. As tokens are routed, some experts become overloaded while others are underutilized. Because experts are mapped to GPUs, this imbalance translates directly into degraded system performance in terms of latency, throughput, and cost. We present LASER, a plug-and-play, inference-time routing algorithm that balances load while preserving accuracy. LASER adapts to the shape of the gate's score distribution. When scores provide a clear preference, it routes to the strongest experts; when scores are more uniform, it broadens the set of viable experts and routes to the least-loaded among them. Because LASER relies only on gate scores from a trained model, it integrates directly into existing MoE inference pipelines without retraining or finetuning. We evaluate LASER on Mixtral-8x7B and DeepSeek-MoE-16b-chat across four datasets (ARC-Easy, ARC-Challenge, MMLU, and GSM8K). LASER improves load balancing, translating into lower latency and higher throughput, while keeping the accuracy changes negligible.",
        "tags": [
            "DeepSeek",
            "MoE"
        ]
    },
    {
        "id": "29",
        "title": "Multimodal Arabic Captioning with Interpretable Visual Concept Integration",
        "author": [
            "Passant Elchafei",
            "Amany Fashwan"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03295",
        "abstract": "We present VLCAP, an Arabic image captioning framework that integrates CLIP-based visual label retrieval with multimodal text generation. Rather than relying solely on end-to-end captioning, VLCAP grounds generation in interpretable Arabic visual concepts extracted with three multilingual encoders, mCLIP, AraCLIP, and Jina V4, each evaluated separately for label retrieval. A hybrid vocabulary is built from training captions and enriched with about 21K general domain labels translated from the Visual Genome dataset, covering objects, attributes, and scenes. The top-k retrieved labels are transformed into fluent Arabic prompts and passed along with the original image to vision-language models. In the second stage, we tested Qwen-VL and Gemini Pro Vision for caption generation, resulting in six encoder-decoder configurations. The results show that mCLIP + Gemini Pro Vision achieved the best BLEU-1 (5.34%) and cosine similarity (60.01%), while AraCLIP + Qwen-VL obtained the highest LLM-judge score (36.33%). This interpretable pipeline enables culturally coherent and contextually accurate Arabic captions.",
        "tags": [
            "CLIP",
            "LLM",
            "Qwen",
            "VLM"
        ]
    },
    {
        "id": "30",
        "title": "Convolutional Neural Nets vs Vision Transformers: A SpaceNet Case Study with Balanced vs Imbalanced Regimes",
        "author": [
            "Akshar Gothi"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03297",
        "abstract": "We present a controlled comparison of a convolutional neural network (EfficientNet-B0) and a Vision Transformer (ViT-Base) on SpaceNet under two label-distribution regimes: a naturally imbalanced five-class split and a balanced-resampled split with 700 images per class (70:20:10 train/val/test). With matched preprocessing (224x224, ImageNet normalization), lightweight augmentations, and a 40-epoch budget on a single NVIDIA P100, we report accuracy, macro-F1, balanced accuracy, per-class recall, and deployment metrics (model size and latency). On the imbalanced split, EfficientNet-B0 reaches 93% test accuracy with strong macro-F1 and lower latency; ViT-Base is competitive at 93% with a larger parameter count and runtime. On the balanced split, both models are strong; EfficientNet-B0 reaches 99% while ViT-Base remains competitive, indicating that balancing narrows architecture gaps while CNNs retain an efficiency edge. We release manifests, logs, and per-image predictions to support reproducibility.",
        "tags": [
            "Transformer",
            "ViT"
        ]
    },
    {
        "id": "31",
        "title": "Revoking Amnesia: RL-based Trajectory Optimization to Resurrect Erased Concepts in Diffusion Models",
        "author": [
            "Daiheng Gao",
            "Nanxiang Jiang",
            "Andi Zhang",
            "Shilin Lu",
            "Yufei Tang",
            "Wenbo Zhou",
            "Weiming Zhang",
            "Zhaoxin Fan"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03302",
        "abstract": "Concept erasure techniques have been widely deployed in T2I diffusion models to prevent inappropriate content generation for safety and copyright considerations. However, as models evolve to next-generation architectures like Flux, established erasure methods (\\textit{e.g.}, ESD, UCE, AC) exhibit degraded effectiveness, raising questions about their true mechanisms. Through systematic analysis, we reveal that concept erasure creates only an illusion of ``amnesia\": rather than genuine forgetting, these methods bias sampling trajectories away from target concepts, making the erasure fundamentally reversible. This insight motivates the need to distinguish superficial safety from genuine concept removal. In this work, we propose \\textbf{RevAm} (\\underline{Rev}oking \\underline{Am}nesia), an RL-based trajectory optimization framework that resurrects erased concepts by dynamically steering the denoising process without modifying model weights. By adapting Group Relative Policy Optimization (GRPO) to diffusion models, RevAm explores diverse recovery trajectories through trajectory-level rewards, overcoming local optima that limit existing methods. Extensive experiments demonstrate that RevAm achieves superior concept resurrection fidelity while reducing computational time by 10$\\times$, exposing critical vulnerabilities in current safety mechanisms and underscoring the need for more robust erasure techniques beyond trajectory manipulation.",
        "tags": [
            "Diffusion",
            "FLUX",
            "GRPO",
            "RL"
        ]
    },
    {
        "id": "32",
        "title": "Creative synthesis of kinematic mechanisms",
        "author": [
            "Jiong Lin",
            "Jialong Ning",
            "Judah Goldfeder",
            "Hod Lipson"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03308",
        "abstract": "In this paper, we formulate the problem of kinematic synthesis for planar linkages as a cross-domain image generation task. We develop a planar linkages dataset using RGB image representations, covering a range of mechanisms: from simple types such as crank-rocker and crank-slider to more complex eight-bar linkages like Jansen's mechanism. A shared-latent variational autoencoder (VAE) is employed to explore the potential of image generative models for synthesizing unseen motion curves and simulating novel kinematics. By encoding the drawing speed of trajectory points as color gradients, the same architecture also supports kinematic synthesis conditioned on both trajectory shape and velocity profiles. We validate our method on three datasets of increasing complexity: a standard four-bar linkage set, a mixed set of four-bar and crank-slider mechanisms, and a complex set including multi-loop mechanisms. Preliminary results demonstrate the effectiveness of image-based representations for generative mechanical design, showing that mechanisms with revolute and prismatic joints, and potentially cams and gears, can be represented and synthesized within a unified image generation framework.",
        "tags": [
            "VAE"
        ]
    },
    {
        "id": "33",
        "title": "Predicting Effects, Missing Distributions: Evaluating LLMs as Human Behavior Simulators in Operations Management",
        "author": [
            "Runze Zhang",
            "Xiaowei Zhang",
            "Mingyang Zhao"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03310",
        "abstract": "LLMs are emerging tools for simulating human behavior in business, economics, and social science, offering a lower-cost complement to laboratory experiments, field studies, and surveys. This paper evaluates how well LLMs replicate human behavior in operations management. Using nine published experiments in behavioral operations, we assess two criteria: replication of hypothesis-test outcomes and distributional alignment via Wasserstein distance. LLMs reproduce most hypothesis-level effects, capturing key decision biases, but their response distributions diverge from human data, including for strong commercial models. We also test two lightweight interventions -- chain-of-thought prompting and hyperparameter tuning -- which reduce misalignment and can sometimes let smaller or open-source models match or surpass larger systems.",
        "tags": [
            "CoT",
            "LLM"
        ]
    },
    {
        "id": "34",
        "title": "Universal Beta Splatting",
        "author": [
            "Rong Liu",
            "Zhongpai Gao",
            "Benjamin Planche",
            "Meida Chen",
            "Van Nguyen Nguyen",
            "Meng Zheng",
            "Anwesa Choudhuri",
            "Terrence Chen",
            "Yue Wang",
            "Andrew Feng",
            "Ziyan Wu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03312",
        "abstract": "We introduce Universal Beta Splatting (UBS), a unified framework that generalizes 3D Gaussian Splatting to N-dimensional anisotropic Beta kernels for explicit radiance field rendering. Unlike fixed Gaussian primitives, Beta kernels enable controllable dependency modeling across spatial, angular, and temporal dimensions within a single representation. Our unified approach captures complex light transport effects, handles anisotropic view-dependent appearance, and models scene dynamics without requiring auxiliary networks or specific color encodings. UBS maintains backward compatibility by approximating to Gaussian Splatting as a special case, guaranteeing plug-in usability and lower performance bounds. The learned Beta parameters naturally decompose scene properties into interpretable without explicit supervision: spatial (surface vs. texture), angular (diffuse vs. specular), and temporal (static vs. dynamic). Our CUDA-accelerated implementation achieves real-time rendering while consistently outperforming existing methods across static, view-dependent, and dynamic benchmarks, establishing Beta kernels as a scalable universal primitive for radiance field rendering. Our project website is available at https://rongliu-leo.github.io/universal-beta-splatting/.",
        "tags": [
            "3D",
            "Gaussian Splatting"
        ]
    },
    {
        "id": "35",
        "title": "Decomposing Attention To Find Context-Sensitive Neurons",
        "author": [
            "Alex Gibson"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03315",
        "abstract": "We study transformer language models, analyzing attention heads whose attention patterns are spread out, and whose attention scores depend weakly on content. We argue that the softmax denominators of these heads are stable when the underlying token distribution is fixed. By sampling softmax denominators from a \"calibration text\", we can combine together the outputs of multiple such stable heads in the first layer of GPT2-Small, approximating their combined output by a linear summary of the surrounding text. This approximation enables a procedure where from the weights alone - and a single calibration text - we can uncover hundreds of first layer neurons that respond to high-level contextual properties of the surrounding text, including neurons that didn't activate on the calibration text.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "36",
        "title": "Photorealistic Inpainting for Perturbation-based Explanations in Ecological Monitoring",
        "author": [
            "GÃ¼nel Aghakishiyeva",
            "Jiayi Zhou",
            "Saagar Arya",
            "James David Poling",
            "Holly R. Houliston",
            "Jamie N. Womble",
            "David W. Johnston",
            "Brinnae Bent"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03317",
        "abstract": "Ecological monitoring is increasingly automated by vision models, yet opaque predictions limit trust and field adoption. We present an inpainting-guided, perturbation-based explanation technique that produces photorealistic, mask-localized edits that preserve scene context. Unlike masking or blurring, these edits stay in-distribution and reveal which fine-grained morphological cues drive predictions in tasks such as species recognition and trait attribution. We demonstrate the approach on a YOLOv9 detector fine-tuned for harbor seal detection in Glacier Bay drone imagery, using Segment-Anything-Model-refined masks to support two interventions: (i) object removal/replacement (e.g., replacing seals with plausible ice/water or boats) and (ii) background replacement with original animals composited onto new scenes. Explanations are assessed by re-scoring perturbed images (flip rate, confidence drop) and by expert review for ecological plausibility and interpretability. The resulting explanations localize diagnostic structures, avoid deletion artifacts common to traditional perturbations, and yield domain-relevant insights that support expert validation and more trustworthy deployment of AI in ecology.",
        "tags": [
            "Detection",
            "Inpainting",
            "SAM"
        ]
    },
    {
        "id": "37",
        "title": "Graph-S3: Enhancing Agentic textual Graph Retrieval with Synthetic Stepwise Supervision",
        "author": [
            "Ge Chang",
            "Jinbo Su",
            "Jiacheng Liu",
            "Pengfei Yang",
            "Yuhao Shang",
            "Huiwen Zheng",
            "Hongli Ma",
            "Yan Liang",
            "Yuanchun Li",
            "Yunxin Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03323",
        "abstract": "A significant portion of real-world data is inherently represented as textual graphs, and integrating these graphs into large language models (LLMs) is promising to enable complex graph-based question answering. However, a key challenge in LLM-based textual graph QA systems lies in graph retrieval, i.e., how to retrieve relevant content from large graphs that is sufficiently informative while remaining compact for the LLM context. Existing retrievers suffer from poor performance since they either rely on shallow embedding similarity or employ interactive retrieving policies that demand excessive data labeling and training cost. To address these issues, we present Graph-$S^3$, an agentic textual graph reasoning framework that employs an LLM-based retriever trained with synthetic stepwise supervision. Instead of rewarding the agent based on the final answers, which may lead to sparse and unstable training signals, we propose to closely evaluate each step of the retriever based on offline-extracted golden subgraphs. Our main techniques include a data synthesis pipeline to extract the golden subgraphs for reward generation and a two-stage training scheme to learn the interactive graph exploration policy based on the synthesized rewards. Based on extensive experiments on three common datasets in comparison with seven strong baselines, our approach achieves an average improvement of 8.1\\% in accuracy and 9.7\\% in F$_1$ score. The advantage is even higher in more complicated multi-hop reasoning tasks. Our code will be open-sourced.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "38",
        "title": "Constant in an Ever-Changing World",
        "author": [
            "Andy Wu",
            "Chun-Cheng Lin",
            "Yuehua Huang",
            "Rung-Tzuo Liaw"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03330",
        "abstract": "The training process of reinforcement learning often suffers from severe oscillations, leading to instability and degraded performance. In this paper, we propose a Constant in an Ever-Changing World (CIC) framework that enhances algorithmic stability to improve performance. CIC maintains both a representative policy and a current policy. Instead of updating the representative policy blindly, CIC selectively updates it only when the current policy demonstrates superiority. Furthermore, CIC employs an adaptive adjustment mechanism, enabling the representative and current policies to jointly facilitate critic training. We evaluate CIC on five MuJoCo environments, and the results show that CIC improves the performance of conventional algorithms without incurring additional computational cost.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "39",
        "title": "Intelligent Healthcare Ecosystems: Optimizing the Iron Triangle of Healthcare (Access, Cost, Quality)",
        "author": [
            "Vivek Acharya"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03331",
        "abstract": "The United States spends nearly 17% of GDP on healthcare yet continues to face uneven access and outcomes. This well-known trade-off among cost, quality, and access - the \"iron triangle\" - motivates a system-level redesign. This paper proposes an Intelligent Healthcare Ecosystem (iHE): an integrated, data-driven framework that uses generative AI and large language models, federated learning, interoperability standards (FHIR, TEFCA), and digital twins to improve access and quality while lowering cost. We review historical spending trends, waste, and international comparisons; introduce a value equation that jointly optimizes access, quality, and cost; and synthesize evidence on the enabling technologies and operating model for iHE. Methods follow a narrative review of recent literature and policy reports. Results outline core components (AI decision support, interoperability, telehealth, automation) and show how iHE can reduce waste, personalize care, and support value-based payment while addressing privacy, bias, and adoption challenges. We argue that a coordinated iHE can bend - if not break - the iron triangle, moving the system toward care that is more accessible, affordable, and high quality.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "40",
        "title": "Semantic-Aware Scheduling for GPU Clusters with Large Language Models",
        "author": [
            "Zerui Wang",
            "Qinghao Hu",
            "Ana Klimovic",
            "Tianwei Zhang",
            "Yonggang Wen",
            "Peng Sun",
            "Dahua Lin"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03334",
        "abstract": "Deep learning (DL) schedulers are pivotal in optimizing resource allocation in GPU clusters, but operate with a critical limitation: they are largely blind to the semantic context of the jobs they manage. This forces them to rely on limited metadata, leading to high profiling overhead, unreliable duration estimation, inadequate failure handling, and poor observability. To this end, we propose SchedMate, a framework that bridges this semantic gap by systematically extracting deep insights from overlooked, unstructured data sources: source code, runtime logs, and historical jobs. SchedMate enhances existing schedulers non-intrusively through three LLM-based components. Our implementation integrates seamlessly with existing deep learning schedulers. Evaluations on a 128-GPU physical cluster and extensive simulations on production traces show SchedMate reduces average job completion times by up to 1.91x, substantially enhancing the scheduling performance, demonstrating the critical role of semantic-awareness in modern DL scheduling.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "41",
        "title": "Pool Me Wisely: On the Effect of Pooling in Transformer-Based Models",
        "author": [
            "Sofiane Ennadir",
            "Levente ZÃ³lyomi",
            "Oleg Smirnov",
            "Tianze Wang",
            "John Pertoft",
            "Filip Cornell",
            "Lele Cao"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03339",
        "abstract": "Transformer models have become the dominant backbone for sequence modeling, leveraging self-attention to produce contextualized token representations. These are typically aggregated into fixed-size vectors via pooling operations for downstream tasks. While much of the literature has focused on attention mechanisms, the role of pooling remains underexplored despite its critical impact on model behavior. In this paper, we introduce a theoretical framework that rigorously characterizes the expressivity of Transformer-based models equipped with widely used pooling methods by deriving closed-form bounds on their representational capacity and the ability to distinguish similar inputs. Our analysis extends to different variations of attention formulations, demonstrating that these bounds hold across diverse architectural variants. We empirically evaluate pooling strategies across tasks requiring both global and local contextual understanding, spanning three major modalities: computer vision, natural language processing, and time-series analysis. Results reveal consistent trends in how pooling choices affect accuracy, sensitivity, and optimization behavior. Our findings unify theoretical and empirical perspectives, providing practical guidance for selecting or designing pooling mechanisms suited to specific tasks. This work positions pooling as a key architectural component in Transformer models and lays the foundation for more principled model design beyond attention alone.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "42",
        "title": "OpusAnimation: Code-Based Dynamic Chart Generation",
        "author": [
            "Bozheng Li",
            "Miao Yang",
            "Zhenhan Chen",
            "Jiawang Cao",
            "Mushui Liu",
            "Yi Lu",
            "Yongliang Wu",
            "Bin Zhang",
            "Yangguang Ji",
            "Licheng Tang",
            "Jay Wu",
            "Wenbo Zhu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03341",
        "abstract": "Dynamic Chart Generation (DCG) involves producing code-rendered animated visualizations as charts. While recent advances in multi-modal large language models (MLLMs) have significantly improved their capability on static chart generation and comprehension, MLLMs' potential for handling dynamic chart generation and understanding remains underexplored. To bridge this research gap, we introduce DCG-Bench (Dynamic Chart Generation Benchmark), the first benchmark evaluating MLLM's capability on dynamic chart generation tasks from three dimensions: Simple Text-to-Chart, Detailed Text-to-Chart, and Video-to-Chart tasks. We construct DCG-8K, a high-quality DCG dataset with annotations covering instruction-code-video triplets and QA pairs for both code and video evaluation. Based on DCG-8K, we explored a two-stage training recipe, proposing Joint-Code-Visual Reward for group relative policy optimization to construct expert MLLM Qwen2.5-VL-DCG-3B for the DCG task. Our benchmarking result reveals shortcomings of existing MLLMs in the visual-to-chart task, and our model beats the best open-sourced MLLM with an average 8.31% performance gain across three tasks, and shows on par performance against proprietary models with only 3B parameters, proving the effectiveness of our training recipe. Our code and dataset will be publicly available.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "43",
        "title": "Gemini Robotics 1.5: Pushing the Frontier of Generalist Robots with Advanced Embodied Reasoning, Thinking, and Motion Transfer",
        "author": [
            "Abbas Abdolmaleki",
            "Saminda Abeyruwan",
            "Joshua Ainslie",
            "Jean-Baptiste Alayrac",
            "Montserrat Gonzalez Arenas",
            "Ashwin Balakrishna",
            "Nathan Batchelor",
            "Alex Bewley",
            "Jeff Bingham",
            "Michael Bloesch",
            "Konstantinos Bousmalis",
            "Philemon Brakel",
            "Anthony Brohan",
            "Thomas Buschmann",
            "Arunkumar Byravan",
            "Serkan Cabi",
            "Ken Caluwaerts",
            "Federico Casarini",
            "Christine Chan",
            "Oscar Chang",
            "London Chappellet-Volpini",
            "Jose Enrique Chen",
            "Xi Chen",
            "Hao-Tien Lewis Chiang",
            "Krzysztof Choromanski",
            "Adrian Collister",
            "David B. D'Ambrosio",
            "Sudeep Dasari",
            "Todor Davchev",
            "Meet Kirankumar Dave",
            "Coline Devin",
            "Norman Di Palo",
            "Tianli Ding",
            "Carl Doersch",
            "Adil Dostmohamed",
            "Yilun Du",
            "Debidatta Dwibedi",
            "Sathish Thoppay Egambaram",
            "Michael Elabd",
            "Tom Erez",
            "Xiaolin Fang",
            "Claudio Fantacci",
            "Cody Fong",
            "Erik Frey",
            "Chuyuan Fu",
            "Ruiqi Gao",
            "Marissa Giustina",
            "Keerthana Gopalakrishnan",
            "Laura Graesser",
            "Oliver Groth",
            "Agrim Gupta",
            "Roland Hafner",
            "Steven Hansen",
            "Leonard Hasenclever",
            "Sam Haves",
            "Nicolas Heess",
            "Brandon Hernaez",
            "Alex Hofer",
            "Jasmine Hsu",
            "Lu Huang",
            "Sandy H. Huang",
            "Atil Iscen",
            "Mithun George Jacob",
            "Deepali Jain",
            "Sally Jesmonth",
            "Abhishek Jindal",
            "Ryan Julian",
            "Dmitry Kalashnikov",
            "M. Emre Karagozler",
            "Stefani Karp",
            "Matija Kecman",
            "J. Chase Kew",
            "Donnie Kim",
            "Frank Kim",
            "Junkyung Kim",
            "Thomas Kipf",
            "Sean Kirmani",
            "Ksenia Konyushkova",
            "Li Yang Ku",
            "Yuheng Kuang",
            "Thomas Lampe",
            "Antoine Laurens",
            "Tuan Anh Le",
            "Isabel Leal",
            "Alex X. Lee",
            "Tsang-Wei Edward Lee",
            "Guy Lever",
            "Jacky Liang",
            "Li-Heng Lin",
            "Fangchen Liu",
            "Shangbang Long",
            "Caden Lu",
            "Sharath Maddineni",
            "Anirudha Majumdar",
            "Kevis-Kokitsi Maninis",
            "Andrew Marmon",
            "Sergio Martinez",
            "Assaf Hurwitz Michaely",
            "Niko Milonopoulos",
            "Joss Moore"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03342",
        "abstract": "General-purpose robots need a deep understanding of the physical world, advanced reasoning, and general and dexterous control. This report introduces the latest generation of the Gemini Robotics model family: Gemini Robotics 1.5, a multi-embodiment Vision-Language-Action (VLA) model, and Gemini Robotics-ER 1.5, a state-of-the-art Embodied Reasoning (ER) model. We are bringing together three major innovations. First, Gemini Robotics 1.5 features a novel architecture and a Motion Transfer (MT) mechanism, which enables it to learn from heterogeneous, multi-embodiment robot data and makes the VLA more general. Second, Gemini Robotics 1.5 interleaves actions with a multi-level internal reasoning process in natural language. This enables the robot to \"think before acting\" and notably improves its ability to decompose and execute complex, multi-step tasks, and also makes the robot's behavior more interpretable to the user. Third, Gemini Robotics-ER 1.5 establishes a new state-of-the-art for embodied reasoning, i.e., for reasoning capabilities that are critical for robots, such as visual and spatial understanding, task planning, and progress estimation. Together, this family of models takes us a step towards an era of physical agents-enabling robots to perceive, think and then act so they can solve complex multi-step tasks.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "44",
        "title": "KVComm: Enabling Efficient LLM Communication through Selective KV Sharing",
        "author": [
            "Xiangyu Shi",
            "Marco Chiesa",
            "Gerald Q. Maguire Jr.",
            "Dejan Kostic"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03346",
        "abstract": "Large Language Models (LLMs) are increasingly deployed in multi-agent systems, where effective inter-model communication is crucial. Existing communication protocols either rely on natural language, incurring high inference costs and information loss, or on hidden states, which suffer from information concentration bias and inefficiency. To address these limitations, we propose KVComm, a novel communication framework that enables efficient communication between LLMs through selective sharing of KV pairs. KVComm leverages the rich information encoded in the KV pairs while avoiding the pitfalls of hidden states. We introduce a KV layer-wise selection strategy based on attention importance scores with a Gaussian prior to identify the most informative KV pairs for communication. Extensive experiments across diverse tasks and model pairs demonstrate that KVComm achieves comparable performance to the upper-bound method, which directly merges inputs to one model without any communication, while transmitting as few as 30\\% of layers' KV pairs. Our study highlights the potential of KV pairs as an effective medium for inter-LLM communication, paving the way for scalable and efficient multi-agent systems.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "45",
        "title": "Visual Odometry with Transformers",
        "author": [
            "Vlardimir Yugay",
            "Duy-Kien Nguyen",
            "Theo Gevers",
            "Cees G. M. Snoek",
            "Martin R. Oswald"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03348",
        "abstract": "Modern monocular visual odometry methods typically combine pre-trained deep learning components with optimization modules, resulting in complex pipelines that rely heavily on camera calibration and hyperparameter tuning, and often struggle in unseen real-world scenarios. Recent large-scale 3D models trained on massive amounts of multi-modal data have partially alleviated these challenges, providing generalizable dense reconstruction and camera pose estimation. Still, they remain limited in handling long videos and providing accurate per-frame estimates, which are required for visual odometry. In this work, we demonstrate that monocular visual odometry can be addressed effectively in an end-to-end manner, thereby eliminating the need for handcrafted components such as bundle adjustment, feature matching, camera calibration, or dense 3D reconstruction. We introduce VoT, short for Visual odometry Transformer, which processes sequences of monocular frames by extracting features and modeling global relationships through temporal and spatial attention. Unlike prior methods, VoT directly predicts camera motion without estimating dense geometry and relies solely on camera poses for supervision. The framework is modular and flexible, allowing seamless integration of various pre-trained encoders as feature extractors. Experimental results demonstrate that VoT scales effectively with larger datasets, benefits substantially from stronger pre-trained backbones, generalizes across diverse camera motions and calibration settings, and outperforms traditional methods while running more than 3 times faster. The code will be released.",
        "tags": [
            "3D",
            "Pose Estimation",
            "Transformer"
        ]
    },
    {
        "id": "46",
        "title": "AgentCaster: Reasoning-Guided Tornado Forecasting",
        "author": [
            "Michael Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03349",
        "abstract": "There is a growing need to evaluate Large Language Models (LLMs) on complex, high-impact, real-world tasks to assess their true readiness as reasoning agents. To address this gap, we introduce AgentCaster, a contamination-free framework employing multimodal LLMs end-to-end for the challenging, long-horizon task of tornado forecasting. Within AgentCaster, models interpret heterogeneous spatiotemporal data from a high-resolution convection-allowing forecast archive. We assess model performance over a 40-day period featuring diverse historical data, spanning several major tornado outbreaks and including over 500 tornado reports. Each day, models query interactively from a pool of 3,625 forecast maps and 40,125 forecast soundings for a forecast horizon of 12-36 hours. Probabilistic tornado-risk polygon predictions are verified against ground truths derived from geometric comparisons across disjoint risk bands in projected coordinate space. To quantify accuracy, we propose domain-specific TornadoBench and TornadoHallucination metrics, with TornadoBench highly challenging for both LLMs and domain expert human forecasters. Notably, human experts significantly outperform state-of-the-art models, which demonstrate a strong tendency to hallucinate and overpredict risk intensity, struggle with precise geographic placement, and exhibit poor spatiotemporal reasoning in complex, dynamically evolving systems. AgentCaster aims to advance research on improving LLM agents for challenging reasoning tasks in critical domains.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "47",
        "title": "Inference-Time Search using Side Information for Diffusion-based Image Reconstruction",
        "author": [
            "Mahdi Farahbakhsh",
            "Vishnu Teja Kunde",
            "Dileep Kalathil",
            "Krishna Narayanan",
            "Jean-Francois Chamberland"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03352",
        "abstract": "Diffusion models have emerged as powerful priors for solving inverse problems. However, existing approaches typically overlook side information that could significantly improve reconstruction quality, especially in severely ill-posed settings. In this work, we propose a novel inference-time search algorithm that guides the sampling process using the side information in a manner that balances exploration and exploitation. This enables more accurate and reliable reconstructions, providing an alternative to the gradient-based guidance that is prone to reward-hacking artifacts. Our approach can be seamlessly integrated into a wide range of existing diffusion-based image reconstruction pipelines. Through extensive experiments on a number of inverse problems, such as box inpainting, super-resolution, and various deblurring tasks including motion, Gaussian, nonlinear, and blind deblurring, we show that our approach consistently improves the qualitative and quantitative performance of diffusion-based image reconstruction algorithms. We also show the superior performance of our approach with respect to other baselines, including reward gradient-based guidance algorithms. The code is available at \\href{https://github.com/mhdfb/sideinfo-search-reconstruction}{this repository}.",
        "tags": [
            "Deblurring",
            "Diffusion",
            "Inpainting",
            "Super Resolution"
        ]
    },
    {
        "id": "48",
        "title": "On Architectures for Combining Reinforcement Learning and Model Predictive Control with Runtime Improvements",
        "author": [
            "Xiaolong Jia",
            "Nikhil Bajaj"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03354",
        "abstract": "Model Predictive Control (MPC) faces computational demands and performance degradation from model inaccuracies. We propose two architectures combining Neural Network-approximated MPC (NNMPC) with Reinforcement Learning (RL). The first, Warm Start RL, initializes the RL actor with pre-trained NNMPC weights. The second, RLMPC, uses RL to generate corrective residuals for NNMPC outputs. We introduce a downsampling method reducing NNMPC input dimensions while maintaining performance. Evaluated on a rotary inverted pendulum, both architectures demonstrate runtime reductions exceeding 99% compared to traditional MPC while improving tracking performance under model uncertainties, with RL+MPC achieving 11-40% cost reduction depending on reference amplitude.",
        "tags": [
            "MPC",
            "RL"
        ]
    },
    {
        "id": "49",
        "title": "Physics-informed Neural-operator Predictive Control for Drag Reduction in Turbulent Flows",
        "author": [
            "Zelin Zhao",
            "Zongyi Li",
            "Kimia Hassibi",
            "Kamyar Azizzadenesheli",
            "Junchi Yan",
            "H. Jane Bae",
            "Di Zhou",
            "Anima Anandkumar"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03360",
        "abstract": "Assessing turbulence control effects for wall friction numerically is a significant challenge since it requires expensive simulations of turbulent fluid dynamics. We instead propose an efficient deep reinforcement learning (RL) framework for modeling and control of turbulent flows. It is model-based RL for predictive control (PC), where both the policy and the observer models for turbulence control are learned jointly using Physics Informed Neural Operators (PINO), which are discretization invariant and can capture fine scales in turbulent flows accurately. Our PINO-PC outperforms prior model-free reinforcement learning methods in various challenging scenarios where the flows are of high Reynolds numbers and unseen, i.e., not provided during model training. We find that PINO-PC achieves a drag reduction of 39.0\\% under a bulk-velocity Reynolds number of 15,000, outperforming previous fluid control methods by more than 32\\%.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "50",
        "title": "Diffusion-Based, Data-Assimilation-Enabled Super-Resolution of Hub-height Winds",
        "author": [
            "Xiaolong Ma",
            "Xu Dong",
            "Ashley Tarrant",
            "Lei Yang",
            "Rao Kotamarthi",
            "Jiali Wang",
            "Feng Yan",
            "Rajkumar Kettimuthu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03364",
        "abstract": "High-quality observations of hub-height winds are valuable but sparse in space and time. Simulations are widely available on regular grids but are generally biased and too coarse to inform wind-farm siting or to assess extreme-weather-related risks (e.g., gusts) at infrastructure scales. To fully utilize both data types for generating high-quality, high-resolution hub-height wind speeds (tens to ~100m above ground), this study introduces WindSR, a diffusion model with data assimilation for super-resolution downscaling of hub-height winds. WindSR integrates sparse observational data with simulation fields during downscaling using state-of-the-art diffusion models. A dynamic-radius blending method is introduced to merge observations with simulations, providing conditioning for the diffusion process. Terrain information is incorporated during both training and inference to account for its role as a key driver of winds. Evaluated against convolutional-neural-network and generative-adversarial-network baselines, WindSR outperforms them in both downscaling efficiency and accuracy. Our data assimilation reduces WindSR's model bias by approximately 20% relative to independent observations.",
        "tags": [
            "Diffusion",
            "Super Resolution"
        ]
    },
    {
        "id": "51",
        "title": "Disentangling Recall and Reasoning in Transformer Models through Layer-wise Attention and Activation Analysis",
        "author": [
            "Harshwardhan Fartale",
            "Ashish Kattamuri",
            "Rahul Raja",
            "Arpita Vats",
            "Ishita Prasad",
            "Akshata Kishore Moharir"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03366",
        "abstract": "Transformer-based language models excel at both recall (retrieving memorized facts) and reasoning (performing multi-step inference), but whether these abilities rely on distinct internal mechanisms remains unclear. Distinguishing recall from reasoning is crucial for predicting model generalization, designing targeted evaluations, and building safer interventions that affect one ability without disrupting the http://other.We approach this question through mechanistic interpretability, using controlled datasets of synthetic linguistic puzzles to probe transformer models at the layer, head, and neuron level. Our pipeline combines activation patching and structured ablations to causally measure component contributions to each task type. Across two model families (Qwen and LLaMA), we find that interventions on distinct layers and attention heads lead to selective impairments: disabling identified \"recall circuits\" reduces fact-retrieval accuracy by up to 15\\% while leaving reasoning intact, whereas disabling \"reasoning circuits\" reduces multi-step inference by a comparable margin. At the neuron level, we observe task-specific firing patterns, though these effects are less robust, consistent with neuronal http://polysemanticity.Our results provide the first causal evidence that recall and reasoning rely on separable but interacting circuits in transformer models. These findings advance mechanistic interpretability by linking circuit-level structure to functional specialization and demonstrate how controlled datasets and causal interventions can yield mechanistic insights into model cognition, informing safer deployment of large language models.",
        "tags": [
            "LLM",
            "LLaMA",
            "Qwen",
            "Transformer"
        ]
    },
    {
        "id": "52",
        "title": "Viability-Preserving Passive Torque Control",
        "author": [
            "Zizhe Zhang",
            "Yicong Wang",
            "Zhiquan Zhang",
            "Tianyu Li",
            "Nadia Figueroa"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03367",
        "abstract": "Conventional passivity-based torque controllers for manipulators are typically unconstrained, which can lead to safety violations under external perturbations. In this paper, we employ viability theory to pre-compute safe sets in the state-space of joint positions and velocities. These viable sets, constructed via data-driven and analytical methods for self-collision avoidance, external object collision avoidance and joint-position and joint-velocity limits, provide constraints on joint accelerations and thus joint torques via the robot dynamics. A quadratic programming-based control framework enforces these constraints on a passive controller tracking a dynamical system, ensuring the robot states remain within the safe set in an infinite time horizon. We validate the proposed approach through simulations and hardware experiments on a 7-DoF Franka Emika manipulator. In comparison to a baseline constrained passive controller, our method operates at higher control-loop rates and yields smoother trajectories.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "53",
        "title": "TriQuest:An AI Copilot-Powered Platform for Interdisciplinary Curriculum Design",
        "author": [
            "Huazhen Wang",
            "Huimin Yang",
            "Hainbin Lin",
            "Yan Dong",
            "Lili Chen",
            "Liangliang Xia",
            "Wenwen Xu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03369",
        "abstract": "Interdisciplinary teaching is a cornerstone of modern curriculum reform, but its implementation is hindered by challenges in knowledge integration and time-consuming lesson planning. Existing tools often lack the required pedagogical and domain-specific http://depth.We introduce TriQuest, an AI-copilot platform designed to solve these problems. TriQuest uses large language models and knowledge graphs via an intuitive GUI to help teachers efficiently generate high-quality interdisciplinary lesson plans. Its core features include intelligent knowledge integration from various disciplines and a human-computer collaborative review process to ensure quality and http://innovation.In a study with 43 teachers, TriQuest increased curriculum design efficiency by an average of 75% and improved lesson plan quality scores by 41%. It also significantly lowered design barriers and cognitive load. Our work presents a new paradigm for empowering teacher professional development with intelligent technologies.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "54",
        "title": "Distributed Low-Communication Training with Decoupled Momentum Optimization",
        "author": [
            "Sasho Nedelkoski",
            "Alexander Acker",
            "Odej Kao",
            "Soeren Becker",
            "Dominik Scheinert"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03371",
        "abstract": "The training of large models demands substantial computational resources, typically available only in data centers with high-bandwidth interconnects. However, reducing the reliance on high-bandwidth interconnects between nodes enables the use of distributed compute resources as an alternative to centralized data center training. Building on recent advances in distributed model training, we propose an approach that further reduces communication by combining infrequent synchronizations across distributed model replicas with gradient momentum compression. In particular, we treat the optimizer momentum as a signal and decompose the Nesterov momentum into high- and low-frequency components via the discrete cosine transform (DCT). Only the high-frequency components are synchronized across model replicas every $H$ steps. Empirically, our method achieves up to a $16\\times$ reduction in communication compared to the baseline DiLoCo, and it generalizes across architectures, including transformer-based language models and convolutional neural networks for images. Overall, this work advances the feasibility of training large models on distributed nodes with low-bandwidth interconnects.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "55",
        "title": "Visual Language Model as a Judge for Object Detection in Industrial Diagrams",
        "author": [
            "Sanjukta Ghosh"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03376",
        "abstract": "Industrial diagrams such as piping and instrumentation diagrams (P&IDs) are essential for the design, operation, and maintenance of industrial plants. Converting these diagrams into digital form is an important step toward building digital twins and enabling intelligent industrial automation. A central challenge in this digitalization process is accurate object detection. Although recent advances have significantly improved object detection algorithms, there remains a lack of methods to automatically evaluate the quality of their outputs. This paper addresses this gap by introducing a framework that employs Visual Language Models (VLMs) to assess object detection results and guide their refinement. The approach exploits the multimodal capabilities of VLMs to identify missing or inconsistent detections, thereby enabling automated quality assessment and improving overall detection performance on complex industrial diagrams.",
        "tags": [
            "Detection",
            "VLM"
        ]
    },
    {
        "id": "56",
        "title": "Implicit Values Embedded in How Humans and LLMs Complete Subjective Everyday Tasks",
        "author": [
            "Arjun Arunasalam",
            "Madison Pickering",
            "Z. Berkay Celik",
            "Blase Ur"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03384",
        "abstract": "Large language models (LLMs) can underpin AI assistants that help users with everyday tasks, such as by making recommendations or performing basic computation. Despite AI assistants' promise, little is known about the implicit values these assistants display while completing subjective everyday tasks. Humans may consider values like environmentalism, charity, and diversity. To what extent do LLMs exhibit these values in completing everyday tasks? How do they compare with humans? We answer these questions by auditing how six popular LLMs complete 30 everyday tasks, comparing LLMs to each other and to 100 human crowdworkers from the US. We find LLMs often do not align with humans, nor with other LLMs, in the implicit values exhibited.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "57",
        "title": "Studying the Korean Word-Chain Game with RLVR:Mitigating Reward Conflicts via Curriculum Learning",
        "author": [
            "Donghwan Rho"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03394",
        "abstract": "Reinforcement learning with verifiable rewards (RLVR) is a promising approach for training large language models (LLMs) with stronger reasoning abilities. It has also been applied to a variety of logic puzzles. In this work, we study the Korean word-chain game using RLVR. We show that rule-derived rewards can naturally conflict, and demonstrate through experiments that a curriculum-learning scheme mitigates these conflicts. Our findings motivate further studies of puzzle tasks in diverse languages.",
        "tags": [
            "LLM",
            "RL"
        ]
    },
    {
        "id": "58",
        "title": "Know Thyself? On the Incapability and Implications of AI Self-Recognition",
        "author": [
            "Xiaoyan Bai",
            "Aryan Shrivastava",
            "Ari Holtzman",
            "Chenhao Tan"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03399",
        "abstract": "Self-recognition is a crucial metacognitive capability for AI systems, relevant not only for psychological analysis but also for safety, particularly in evaluative scenarios. Motivated by contradictory interpretations of whether models possess self-recognition (Panickssery et al., 2024; Davidson et al., 2024), we introduce a systematic evaluation framework that can be easily applied and updated. Specifically, we measure how well 10 contemporary larger language models (LLMs) can identify their own generated text versus text from other models through two tasks: binary self-recognition and exact model prediction. Different from prior claims, our results reveal a consistent failure in self-recognition. Only 4 out of 10 models predict themselves as generators, and the performance is rarely above random chance. Additionally, models exhibit a strong bias toward predicting GPT and Claude families. We also provide the first evaluation of model awareness of their own and others' existence, as well as the reasoning behind their choices in self-recognition. We find that the model demonstrates some knowledge of its own existence and other models, but their reasoning reveals a hierarchical bias. They appear to assume that GPT, Claude, and occasionally Gemini are the top-tier models, often associating high-quality text with them. We conclude by discussing the implications of our findings on AI safety and future directions to develop appropriate AI self-awareness.",
        "tags": [
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "59",
        "title": "LegalSim: Multi-Agent Simulation of Legal Systems for Discovering Procedural Exploits",
        "author": [
            "Sanket Badhe"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03405",
        "abstract": "We present LegalSim, a modular multi-agent simulation of adversarial legal proceedings that explores how AI systems can exploit procedural weaknesses in codified rules. Plaintiff and defendant agents choose from a constrained action space (for example, discovery requests, motions, meet-and-confer, sanctions) governed by a JSON rules engine, while a stochastic judge model with calibrated grant rates, cost allocations, and sanction tendencies resolves outcomes. We compare four policies: PPO, a contextual bandit with an LLM, a direct LLM policy, and a hand-crafted heuristic; Instead of optimizing binary case outcomes, agents are trained and evaluated using effective win rate and a composite exploit score that combines opponent-cost inflation, calendar pressure, settlement pressure at low merit, and a rule-compliance margin. Across configurable regimes (e.g., bankruptcy stays, inter partes review, tax procedures) and heterogeneous judges, we observe emergent ``exploit chains'', such as cost-inflating discovery sequences and calendar-pressure tactics that remain procedurally valid yet systemically harmful. Evaluation via cross-play and Bradley-Terry ratings shows, PPO wins more often, the bandit is the most consistently competitive across opponents, the LLM trails them, and the heuristic is weakest. The results are stable in judge settings, and the simulation reveals emergent exploit chains, motivating red-teaming of legal rule systems in addition to model-level testing.",
        "tags": [
            "LLM",
            "PPO"
        ]
    },
    {
        "id": "60",
        "title": "PLSEMANTICSBENCH: Large Language Models As Programming Language Interpreters",
        "author": [
            "Aditya Thimmaiah",
            "Jiyang Zhang",
            "Jayanth Srinivasa",
            "Junyi Jessy Li",
            "Milos Gligoric"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03415",
        "abstract": "As large language models (LLMs) excel at code reasoning, a natural question arises: can an LLM execute programs (i.e., act as an interpreter) purely based on a programming language's formal semantics? If so, it will enable rapid prototyping of new programming languages and language features. We study this question using the imperative language IMP (a subset of C), formalized via small-step operational semantics (SOS) and rewriting-based operational semantics (K-semantics). We introduce three evaluation sets-Human-Written, LLM-Translated, and Fuzzer- Generated-whose difficulty is controlled by code-complexity metrics spanning the size, control-flow, and data-flow axes. Given a program and its semantics formalized with SOS/K-semantics, models are evaluated on three tasks ranging from coarse to fine: (1) final-state prediction, (2) semantic rule prediction, and (3) execution trace prediction. To distinguish pretraining memorization from semantic competence, we define two nonstandard semantics obtained through systematic mutations of the standard rules. Across strong code/reasoning LLMs, performance drops under nonstandard semantics despite high performance under the standard one. We further find that (i) there are patterns to different model failures, (ii) most reasoning models perform exceptionally well on coarse grained tasks involving reasoning about highly complex programs often containing nested loop depths beyond five, and surprisingly, (iii) providing formal semantics helps on simple programs but often hurts on more complex ones. Overall, the results show a promise that LLMs could serve as programming language interpreters, but points to the lack of their robust semantics understanding. We release the benchmark and the supporting code at https://github.com/EngineeringSoftware/PLSemanticsBench.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "61",
        "title": "NEXUS: Network Exploration for eXploiting Unsafe Sequences in Multi-Turn LLM Jailbreaks",
        "author": [
            "Javad Rafiei Asl",
            "Sidhant Narula",
            "Mohammad Ghasemigol",
            "Eduardo Blanco",
            "Daniel Takabi"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03417",
        "abstract": "Large Language Models (LLMs) have revolutionized natural language processing but remain vulnerable to jailbreak attacks, especially multi-turn jailbreaks that distribute malicious intent across benign exchanges and bypass alignment mechanisms. Existing approaches often explore the adversarial space poorly, rely on hand-crafted heuristics, or lack systematic query refinement. We present NEXUS (Network Exploration for eXploiting Unsafe Sequences), a modular framework for constructing, refining, and executing optimized multi-turn attacks. NEXUS comprises: (1) ThoughtNet, which hierarchically expands a harmful intent into a structured semantic network of topics, entities, and query chains; (2) a feedback-driven Simulator that iteratively refines and prunes these chains through attacker-victim-judge LLM collaboration using harmfulness and semantic-similarity benchmarks; and (3) a Network Traverser that adaptively navigates the refined query space for real-time attacks. This pipeline uncovers stealthy, high-success adversarial paths across LLMs. On several closed-source and open-source LLMs, NEXUS increases attack success rate by 2.1% to 19.4% over prior methods. Code: https://github.com/inspire-lab/NEXUS",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "62",
        "title": "ContraGen: A Multi-Agent Generation Framework for Enterprise Contradictions Detection",
        "author": [
            "Ananya Mantravadi",
            "Shivali Dalmia",
            "Abhishek Mukherji",
            "Nand Dave",
            "Anudha Mittal"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03418",
        "abstract": "Retrieval-Augmented Generation (RAG) integrates LLMs with external sources, offering advanced capabilities for information access and decision-making. However, contradictions in retrieved evidence can result in inconsistent or untrustworthy outputs, which is especially problematic in enterprise settings where compliance, governance, and accountability are critical. Existing benchmarks for contradiction detection are limited to sentence-level analysis and do not capture the complexity of enterprise documents such as contracts, financial filings, compliance reports, or policy manuals. To address this limitation, we propose ContraGen, a contradiction-aware benchmark framework tailored to enterprise domain. The framework generates synthetic enterprise-style documents with embedded contradictions, enabling systematic evaluation of both intra-document and cross-document consistency. Automated contradiction mining is combined with human-in-the-loop validation to ensure high accuracy. Our contributions include generating realistic enterprise documents, modeling a taxonomy of contradiction types common in business processes, enabling controlled creation of self- and pairwise contradictions, developing a contradiction-aware retrieval evaluation pipeline and embedding human oversight to reflect domain-specific judgment complexity. This work establishes a foundation for more trustworthy and accountable RAG systems in enterprise information-seeking applications, where detecting and resolving contradictions is essential for reducing risk and ensuring compliance.",
        "tags": [
            "Detection",
            "LLM",
            "RAG"
        ]
    },
    {
        "id": "63",
        "title": "Multi-task neural diffusion processes for uncertainty-quantified wind power prediction",
        "author": [
            "Joseph Rawson",
            "Domniki Ladopoulou",
            "Petros Dellaportas"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03419",
        "abstract": "Uncertainty-aware wind power prediction is essential for grid integration and reliable wind farm operation. We apply neural diffusion processes (NDPs)-a recent class of models that learn distributions over functions-and extend them to a multi-task NDP (MT-NDP) framework for wind power prediction. We provide the first empirical evaluation of NDPs in real supervisory control and data acquisition (SCADA) data. We introduce a task encoder within MT-NDPs to capture cross-turbine correlations and enable few-shot adaptation to unseen turbines. The proposed MT-NDP framework outperforms single-task NDPs and GPs in terms of point accuracy and calibration, particularly for wind turbines whose behaviour deviates from the fleet average. In general, NDP-based models deliver calibrated and scalable predictions suitable for operational deployment, offering sharper, yet trustworthy, predictive intervals that can support dispatch and maintenance decisions in modern wind farms.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "64",
        "title": "Memory-Efficient Backpropagation for Fine-Tuning LLMs on Resource-Constrained Mobile Devices",
        "author": [
            "Congzheng Song",
            "Xinyu Tang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03425",
        "abstract": "Fine-tuning large language models (LLMs) with backpropagation\\textemdash even for a subset of parameters such as LoRA\\textemdash can be much more memory-consuming than inference and is often deemed impractical for resource-constrained mobile devices. Alternative methods, such as zeroth-order optimization (ZO), can greatly reduce the memory footprint but come at the cost of significantly slower model convergence (10$\\times$ to 100$\\times$ more steps than backpropagation). We propose a memory-efficient implementation of backpropagation (MeBP) on mobile devices that provides better trade-off between memory usage and compute time, while converging faster and achieving better performance than the ZO baseline. We verify the effectiveness of MeBP on an iPhone 15 Pro Max and show that various LLMs, ranging from 0.5B to 4B parameters, can be fine-tuned using less than 1GB of memory. We release an example of the MeBP implementation at https://github.com/apple/ml-mebp.",
        "tags": [
            "LLM",
            "LoRA"
        ]
    },
    {
        "id": "65",
        "title": "Style Brush: Guided Style Transfer for 3D Objects",
        "author": [
            "Ãron Samuel KovÃ¡cs",
            "Pedro Hermosilla",
            "Renata G. Raidou"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03433",
        "abstract": "We introduce Style Brush, a novel style transfer method for textured meshes designed to empower artists with fine-grained control over the stylization process. Our approach extends traditional 3D style transfer methods by introducing a novel loss function that captures style directionality, supports multiple style images or portions thereof, and enables smooth transitions between styles in the synthesized texture. The use of easily generated guiding textures streamlines user interaction, making our approach accessible to a broad audience. Extensive evaluations with various meshes, style images, and contour shapes demonstrate the flexibility of our method and showcase the visual appeal of the generated textures.",
        "tags": [
            "3D",
            "Style Transfer"
        ]
    },
    {
        "id": "66",
        "title": "Paris: A Decentralized Trained Open-Weight Diffusion Model",
        "author": [
            "Zhiying Jiang",
            "Raihan Seraj",
            "Marcos Villagra",
            "Bidhan Roy"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03434",
        "abstract": "We present Paris, the first publicly released diffusion model pre-trained entirely through decentralized computation. Paris demonstrates that high-quality text-to-image generation can be achieved without centrally coordinated infrastructure. Paris is open for research and commercial use. Paris required implementing our Distributed Diffusion Training framework from scratch. The model consists of 8 expert diffusion models (129M-605M parameters each) trained in complete isolation with no gradient, parameter, or intermediate activation synchronization. Rather than requiring synchronized gradient updates across thousands of GPUs, we partition data into semantically coherent clusters where each expert independently optimizes its subset while collectively approximating the full distribution. A lightweight transformer router dynamically selects appropriate experts at inference, achieving generation quality comparable to centrally coordinated baselines. Eliminating synchronization enables training on heterogeneous hardware without specialized interconnects. Empirical validation confirms that Paris's decentralized training maintains generation quality while removing the dedicated GPU cluster requirement for large-scale diffusion models. Paris achieves this using 14$\\times$ less training data and 16$\\times$ less compute than the prior decentralized baseline.",
        "tags": [
            "Diffusion",
            "Text-to-Image",
            "Transformer"
        ]
    },
    {
        "id": "67",
        "title": "Consistent Kernel Change-Point Detection under m-Dependence for Text Segmentation",
        "author": [
            "Jairo Diaz-Rodriguez",
            "Mumin Jia"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03437",
        "abstract": "Kernel change-point detection (KCPD) has become a widely used tool for identifying structural changes in complex data. While existing theory establishes consistency under independence assumptions, real-world sequential data such as text exhibits strong dependencies. We establish new guarantees for KCPD under $m$-dependent data: specifically, we prove consistency in the number of detected change points and weak consistency in their locations under mild additional assumptions. We perform an LLM-based simulation that generates synthetic $m$-dependent text to validate the asymptotics. To complement these results, we present the first comprehensive empirical study of KCPD for text segmentation with modern embeddings. Across diverse text datasets, KCPD with text embeddings outperforms baselines in standard text segmentation metrics. We demonstrate through a case study on Taylor Swift's tweets that KCPD not only provides strong theoretical and simulated reliability but also practical effectiveness for text segmentation tasks.",
        "tags": [
            "Detection",
            "LLM",
            "Segmentation"
        ]
    },
    {
        "id": "68",
        "title": "Spatial-ViLT: Enhancing Visual Spatial Reasoning through Multi-Task Learning",
        "author": [
            "Chashi Mahiul Islam",
            "Oteo Mamo",
            "Samuel Jacob Chacko",
            "Xiuwen Liu",
            "Weikuan Yu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03441",
        "abstract": "Vision-language models (VLMs) have advanced multimodal reasoning but still face challenges in spatial reasoning for 3D scenes and complex object configurations. To address this, we introduce SpatialViLT, an enhanced VLM that integrates spatial features like depth maps, 3D coordinates, and edge maps through a multi-task learning framework. This approach enriches multimodal embeddings with spatial understanding. We propose two variants: SpatialViLT and MaskedSpatialViLT, focusing on full and masked object regions, respectively. Additionally, SpatialEnsemble combines both approaches, achieving state-of-the-art accuracy. Our models excel in spatial reasoning categories such as directional, topological, and proximity relations, as demonstrated on the challenging Visual Spatial Reasoning (VSR) dataset. This work represents a significant step in enhancing the spatial intelligence of AI systems, crucial for advanced multimodal understanding and real-world applications.",
        "tags": [
            "3D",
            "VLM"
        ]
    },
    {
        "id": "69",
        "title": "The Argument is the Explanation: Structured Argumentation for Trust in Agents",
        "author": [
            "Ege Cakar",
            "Per Ola Kristensson"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03442",
        "abstract": "Humans are black boxes -- we cannot observe their neural processes, yet society functions by evaluating verifiable arguments. AI explainability should follow this principle: stakeholders need verifiable reasoning chains, not mechanistic transparency. We propose using structured argumentation to provide a level of explanation and verification neither interpretability nor LLM-generated explanation is able to offer. Our pipeline achieves state-of-the-art 94.44 macro F1 on the AAEC published train/test split (5.7 points above prior work) and $0.81$ macro F1, $\\sim$0.07 above previous published results with comparable data setups, for Argumentative MicroTexts relation classification, converting LLM text into argument graphs and enabling verification at each inferential step. We demonstrate this idea on multi-agent risk assessment using the Structured What-If Technique, where specialized agents collaborate transparently to carry out risk assessment otherwise achieved by humans alone. Using Bipolar Assumption-Based Argumentation, we capture support/attack relationships, thereby enabling automatic hallucination detection via fact nodes attacking arguments. We also provide a verification mechanism that enables iterative refinement through test-time feedback without retraining. For easy deployment, we provide a Docker container for the fine-tuned AMT model, and the rest of the code with the Bipolar ABA Python package on GitHub.",
        "tags": [
            "Detection",
            "LLM"
        ]
    },
    {
        "id": "70",
        "title": "Optimal swimming with body compliance in an overdamped medium",
        "author": [
            "Jianfeng Lin",
            "Tianyu Wang",
            "Baxi Chong",
            "Matthew Fernandez",
            "Zhaochen Xu",
            "Daniel I. Goldman"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03457",
        "abstract": "Elongate animals and robots use undulatory body waves to locomote through diverse environments. Geometric mechanics provides a framework to model and optimize such systems in highly damped environments, connecting a prescribed shape change pattern (gait) with locomotion displacement. However, existing approaches assume precise execution of prescribed gaits, whereas in practice environmental interactions with compliant bodies of animals or robots frequently perturb the realized trajectories. In this work, we extend geometric mechanics to predict locomotor performance and search for optimal swimming strategy of compliant undulators. We introduce a compliant extension of Purcell's three-link swimmer by incorporating series-connected springs at the joints. Body dynamics are derived with resistive force theory. Geometric mechanics is incorporated into movement prediction and into an optimization framework that identifies strategies for controlling compliant swimmers to achieve maximal displacement. We validate our framework on a physical cable-driven three-link limbless robot, and demonstrate accurate prediction and optimization of locomotor performance under varied programmed, state-dependent compliance in a granular medium. Our results establish a systematic physics-based approach for modeling and controlling compliant swimming locomotion, highlighting compliance as a design feature that can be exploited for robust movement in homogeneous and heterogeneous environments.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "71",
        "title": "Warm-Starting Optimization-Based Motion Planning for Robotic Manipulators via Point Cloud-Conditioned Flow Matching",
        "author": [
            "Sibo Tian",
            "Minghui Zheng",
            "Xiao Liang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03460",
        "abstract": "Rapid robot motion generation is critical in Human-Robot Collaboration (HRC) systems, as robots need to respond to dynamic environments in real time by continuously observing their surroundings and replanning their motions to ensure both safe interactions and efficient task execution. Current sampling-based motion planners face challenges in scaling to high-dimensional configuration spaces and often require post-processing to interpolate and smooth the generated paths, resulting in time inefficiency in complex environments. Optimization-based planners, on the other hand, can incorporate multiple constraints and generate smooth trajectories directly, making them potentially more time-efficient. However, optimization-based planners are sensitive to initialization and may get stuck in local minima. In this work, we present a novel learning-based method that utilizes a Flow Matching model conditioned on a single-view point cloud to learn near-optimal solutions for optimization initialization. Our method does not require prior knowledge of the environment, such as obstacle locations and geometries, and can generate feasible trajectories directly from single-view depth camera input. Simulation studies on a UR5e robotic manipulator in cluttered workspaces demonstrate that the proposed generative initializer achieves a high success rate on its own, significantly improves the success rate of trajectory optimization compared with traditional and learning-based benchmark initializers, requires fewer optimization iterations, and exhibits strong generalization to unseen environments.",
        "tags": [
            "Flow Matching",
            "Robotics"
        ]
    },
    {
        "id": "72",
        "title": "ALMAS: an Autonomous LLM-based Multi-Agent Software Engineering Framework",
        "author": [
            "Vali Tawosi",
            "Keshav Ramani",
            "Salwa Alamir",
            "Xiaomo Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03463",
        "abstract": "Multi-agent Large Language Model (LLM) systems have been leading the way in applied LLM research across a number of fields. One notable area is software development, where researchers have advanced the automation of code implementation, code testing, code maintenance, inter alia, using LLM agents. However, software development is a multifaceted environment that extends beyond just code. As such, a successful LLM system must factor in multiple stages of the software development life-cycle (SDLC). In this paper, we propose a vision for ALMAS, an Autonomous LLM-based Multi-Agent Software Engineering framework, which follows the above SDLC philosophy such that it may work within an agile software development team to perform several tasks end-to-end. ALMAS aligns its agents with agile roles, and can be used in a modular fashion to seamlessly integrate with human developers and their development environment. We showcase the progress towards ALMAS through our published works and a use case demonstrating the framework, where ALMAS is able to seamlessly generate an application and add a new feature.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "73",
        "title": "Bridging LLM Planning Agents and Formal Methods: A Case Study in Plan Verification",
        "author": [
            "Keshav Ramani",
            "Vali Tawosi",
            "Salwa Alamir",
            "Daniel Borrajo"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03469",
        "abstract": "We introduce a novel framework for evaluating the alignment between natural language plans and their expected behavior by converting them into Kripke structures and Linear Temporal Logic (LTL) using Large Language Models (LLMs) and performing model checking. We systematically evaluate this framework on a simplified version of the PlanBench plan verification dataset and report on metrics like Accuracy, Precision, Recall and F1 scores. Our experiments demonstrate that GPT-5 achieves excellent classification performance (F1 score of 96.3%) while almost always producing syntactically perfect formal representations that can act as guarantees. However, the synthesis of semantically perfect formal models remains an area for future exploration.",
        "tags": [
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "74",
        "title": "On residual network depth",
        "author": [
            "Benoit Dherin",
            "Michael Munn"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03470",
        "abstract": "Deep residual architectures, such as ResNet and the Transformer, have enabled models of unprecedented depth, yet a formal understanding of why depth is so effective remains an open question. A popular intuition, following Veit et al. (2016), is that these residual networks behave like ensembles of many shallower models. Our key finding is an explicit analytical formula that verifies this ensemble perspective, proving that increasing network depth is mathematically equivalent to expanding the size of this implicit ensemble. Furthermore, our expansion reveals a hierarchical ensemble structure in which the combinatorial growth of computation paths leads to an explosion in the output signal, explaining the historical necessity of normalization layers in training deep models. This insight offers a first principles explanation for the historical dependence on normalization layers and sheds new light on a family of successful normalization-free techniques like SkipInit and Fixup. However, while these previous approaches infer scaling factors through optimizer analysis or a heuristic analogy to Batch Normalization, our work offers the first explanation derived directly from the network's inherent functional structure. Specifically, our Residual Expansion Theorem reveals that scaling each residual module provides a principled solution to taming the combinatorial explosion inherent to these architectures. We further show that this scaling acts as a capacity controls that also implicitly regularizes the model's complexity.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "75",
        "title": "Destination-to-Chutes Task Mapping Optimization for Multi-Robot Coordination in Robotic Sorting Systems",
        "author": [
            "Yulun Zhang",
            "Alexandre O. G. Barbosa",
            "Federico Pecora",
            "Jiaoyang Li"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03472",
        "abstract": "We study optimizing a destination-to-chutes task mapping to improve throughput in Robotic Sorting Systems (RSS), where a team of robots sort packages on a sortation floor by transporting them from induct workstations to eject chutes based on their shipping destinations (e.g. Los Angeles or Pittsburgh). The destination-to-chutes task mapping is used to determine which chutes a robot can drop its package. Finding a high-quality task mapping is challenging because of the complexity of a real-world RSS. First, optimizing task mapping is interdependent with robot target assignment and path planning. Second, chutes will be CLOSED for a period of time once they receive sufficient packages to allow for downstream processing. Third, task mapping quality directly impacts the downstream processing, as scattered chutes for the same destination increase package handling time. In this paper, we first formally define task mappings and the problem of Task Mapping Optimization (TMO). We then present a simulator of RSS to evaluate task mappings. We then present a simple TMO method based on the Evolutionary Algorithm and Mixed Integer Linear Programming, demonstrating the advantage of our optimized task mappings over the greedily generated ones in various RSS setups with different map sizes, numbers of chutes, and destinations. Finally, we use Quality Diversity algorithms to analyze the throughput of a diverse set of task mappings. Our code is available online at https://github.com/lunjohnzhang/tmo_public.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "76",
        "title": "LLM Agents for Automated Dependency Upgrades",
        "author": [
            "Vali Tawosi",
            "Salwa Alamir",
            "Xiaomo Liu",
            "Manuela Veloso"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03480",
        "abstract": "As a codebase expands over time, its library dependencies can become outdated and require updates to maintain innovation and security. However, updating a library can introduce breaking changes in the code, necessitating significant developer time for maintenance. To address this, we introduce a framework of LLM agents to be used in combination with migration documentation to automatically recommend and apply code updates and ensure compatibility with new versions. Our solution can automatically localize updated library usages in live Java codebases and implement recommended fixes in a user-friendly manner. The system architecture consists of multiple key components: a Summary Agent, Control Agent, and Code Agent. To validate our approach, we apply the framework on an industrial use case by which we create three synthetic code repositories with major Upgrade changes and benchmark our approach against state-of-the-art methods. Results show that our approach not only performs upgrades using fewer tokens across all cases but also achieves a precision of 71.4%, highlighting its efficiency and effectiveness compared to state-of-the-art methods.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "77",
        "title": "Robust Permissive Controller Synthesis for Interval MDPs",
        "author": [
            "Khang Vo Huynh",
            "David Parker",
            "Lu Feng"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03481",
        "abstract": "We address the problem of robust permissive controller synthesis for robots operating under uncertain dynamics, modeled as Interval Markov Decision Processes (IMDPs). IMDPs generalize standard MDPs by allowing transition probabilities to vary within intervals, capturing epistemic uncertainty from sensing noise, actuation imprecision, and coarse system abstractions-common in robotics. Traditional controller synthesis typically yields a single deterministic strategy, limiting adaptability. In contrast, permissive controllers (multi-strategies) allow multiple actions per state, enabling runtime flexibility and resilience. However, prior work on permissive controller synthesis generally assumes exact transition probabilities, which is unrealistic in many robotic applications. We present the first framework for robust permissive controller synthesis on IMDPs, guaranteeing that all strategies compliant with the synthesized multi-strategy satisfy reachability or reward-based specifications under all admissible transitions. We formulate the problem as mixed-integer linear programs (MILPs) and propose two encodings: a baseline vertex-enumeration method and a scalable duality-based method that avoids explicit enumeration. Experiments on four benchmark domains show that both methods synthesize robust, maximally permissive controllers and scale to large IMDPs with up to hundreds of thousands of states.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "78",
        "title": "SEER: The Span-based Emotion Evidence Retrieval Benchmark",
        "author": [
            "Aneesha Sampath",
            "Oya Aran",
            "Emily Mower Provost"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03490",
        "abstract": "We introduce the SEER (Span-based Emotion Evidence Retrieval) Benchmark to test Large Language Models' (LLMs) ability to identify the specific spans of text that express emotion. Unlike traditional emotion recognition tasks that assign a single label to an entire sentence, SEER targets the underexplored task of emotion evidence detection: pinpointing which exact phrases convey emotion. This span-level approach is crucial for applications like empathetic dialogue and clinical support, which need to know how emotion is expressed, not just what the emotion is. SEER includes two tasks: identifying emotion evidence within a single sentence, and identifying evidence across a short passage of five consecutive sentences. It contains new annotations for both emotion and emotion evidence on 1200 real-world sentences. We evaluate 14 open-source LLMs and find that, while some models approach average human performance on single-sentence inputs, their accuracy degrades in longer passages. Our error analysis reveals key failure modes, including overreliance on emotion keywords and false positives in neutral text.",
        "tags": [
            "Detection",
            "LLM"
        ]
    },
    {
        "id": "79",
        "title": "Trajectory Data Suffices for Statistically Efficient Policy Evaluation in Finite-Horizon Offline RL with Linear $q^Ï$-Realizability and Concentrability",
        "author": [
            "Volodymyr Tkachuk",
            "Csaba SzepesvÃ¡ri",
            "Xiaoqi Tan"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03494",
        "abstract": "We study finite-horizon offline reinforcement learning (RL) with function approximation for both policy evaluation and policy optimization. Prior work established that statistically efficient learning is impossible for either of these problems when the only assumptions are that the data has good coverage (concentrability) and the state-action value function of every policy is linearly realizable ($q^\\pi$-realizability) (Foster et al., 2021). Recently, Tkachuk et al. (2024) gave a statistically efficient learner for policy optimization, if in addition the data is assumed to be given as trajectories. In this work we present a statistically efficient learner for policy evaluation under the same assumptions. Further, we show that the sample complexity of the learner used by Tkachuk et al. (2024) for policy optimization can be improved by a tighter analysis.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "80",
        "title": "AgentHub: A Research Agenda for Agent Sharing Infrastructure",
        "author": [
            "Erik Pautsch",
            "Tanmay Singla",
            "Wenxin Jiang",
            "Huiyun Peng",
            "Behnaz Hassanshahi",
            "Konstantin LÃ¤ufer",
            "George K.Thiruvathukal",
            "James C. Davis"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03495",
        "abstract": "LLM-based agents are rapidly proliferating, yet the infrastructure for discovering, evaluating, and governing them remains fragmented compared to mature ecosystems like software package registries (e.g., npm) and model hubs (e.g., Hugging Face). Recent research and engineering works have begun to consider the requisite infrastructure, but so far they focus narrowly -- on distribution, naming, or protocol negotiation. However, considering broader software engineering requirements would improve open-source distribution and ease reuse. We therefore propose AgentHub, a research agenda for agent sharing. By framing the key challenges of capability clarity, lifecycle transparency, interoperability, governance, security, and workflow integration, AgentHub charts a community-wide agenda for building reliable and scalable agent ecosystems. Our vision is a future where agents can be shared, trusted, and composed as seamlessly as today's software libraries.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "81",
        "title": "Digital-Twin Evaluation for Proactive Human-Robot Collision Avoidance via Prediction-Guided A-RRT*",
        "author": [
            "Vadivelan Murugesan",
            "Rajasundaram Mathiazhagan",
            "Sanjana Joshi",
            "Aliasghar Arab"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03496",
        "abstract": "Human-robot collaboration requires precise prediction of human motion over extended horizons to enable proactive collision avoidance. Unlike existing planners that rely solely on kinodynamic models, we present a prediction-driven safe planning framework that leverages granular, joint-by-joint human motion forecasting validated in a physics-based digital twin. A capsule-based artificial potential field (APF) converts these granular predictions into collision risk metrics, triggering an Adaptive RRT* (A-RRT*) planner when thresholds are exceeded. The depth camera is used to extract 3D skeletal poses and a convolutional neural network-bidirectional long short-term memory (CNN-BiLSTM) model to predict individual joint trajectories ahead of time. A digital twin model integrates real-time human posture prediction placed in front of a simulated robot to evaluate motions and physical contacts. The proposed method enables validation of planned trajectories ahead of time and bridging potential latency gaps in updating planned trajectories in real-time. In 50 trials, our method achieved 100% proactive avoidance with > 250 mm clearance and sub-2 s replanning, demonstrating superior precision and reliability compared to existing kinematic-only planners through the integration of predictive human modeling with digital twin validation.",
        "tags": [
            "3D",
            "Robotics"
        ]
    },
    {
        "id": "82",
        "title": "Real-Time Threaded Houbara Detection and Segmentation for Wildlife Conservation using Mobile Platforms",
        "author": [
            "Lyes Saad Saoud",
            "Loic Lesobre",
            "Enrico Sorato",
            "Irfan Hussain"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03501",
        "abstract": "Real-time animal detection and segmentation in natural environments are vital for wildlife conservation, enabling non-invasive monitoring through remote camera streams. However, these tasks remain challenging due to limited computational resources and the cryptic appearance of many species. We propose a mobile-optimized two-stage deep learning framework that integrates a Threading Detection Model (TDM) to parallelize YOLOv10-based detection and MobileSAM-based segmentation. Unlike prior YOLO+SAM pipelines, our approach improves real-time performance by reducing latency through threading. YOLOv10 handles detection while MobileSAM performs lightweight segmentation, both executed concurrently for efficient resource use. On the cryptic Houbara Bustard, a conservation-priority species, our model achieves mAP50 of 0.9627, mAP75 of 0.7731, mAP95 of 0.7178, and a MobileSAM mIoU of 0.7421. YOLOv10 operates at 43.7 ms per frame, confirming real-time readiness. We introduce a curated Houbara dataset of 40,000 annotated images to support model training and evaluation across diverse conditions. The code and dataset used in this study are publicly available on GitHub at https://github.com/LyesSaadSaoud/mobile-houbara-detseg. For interactive demos and additional resources, visit https://lyessaadsaoud.github.io/LyesSaadSaoud-Threaded-YOLO-SAM-Houbara.",
        "tags": [
            "Detection",
            "SAM",
            "Segmentation"
        ]
    },
    {
        "id": "83",
        "title": "ALHD: A Large-Scale and Multigenre Benchmark Dataset for Arabic LLM-Generated Text Detection",
        "author": [
            "Ali Khairallah",
            "Arkaitz Zubiaga"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03502",
        "abstract": "We introduce ALHD, the first large-scale comprehensive Arabic dataset explicitly designed to distinguish between human- and LLM-generated texts. ALHD spans three genres (news, social media, reviews), covering both MSA and dialectal Arabic, and contains over 400K balanced samples generated by three leading LLMs and originated from multiple human sources, which enables studying generalizability in Arabic LLM-genearted text detection. We provide rigorous preprocessing, rich annotations, and standardized balanced splits to support reproducibility. In addition, we present, analyze and discuss benchmark experiments using our new dataset, in turn identifying gaps and proposing future research directions. Benchmarking across traditional classifiers, BERT-based models, and LLMs (zero-shot and few-shot) demonstrates that fine-tuned BERT models achieve competitive performance, outperforming LLM-based models. Results are however not always consistent, as we observe challenges when generalizing across genres; indeed, models struggle to generalize when they need to deal with unseen patterns in cross-genre settings, and these challenges are particularly prominent when dealing with news articles, where LLM-generated texts resemble human texts in style, which opens up avenues for future research. ALHD establishes a foundation for research related to Arabic LLM-detection and mitigating risks of misinformation, academic dishonesty, and cyber threats.",
        "tags": [
            "BERT",
            "Detection",
            "LLM"
        ]
    },
    {
        "id": "84",
        "title": "Distributed Connectivity Maintenance and Recovery for Quadrotor Motion Planning",
        "author": [
            "Yutong Wang",
            "Yichun Qu",
            "Tengxiang Wang",
            "Lishuo Pan",
            "Nora Ayanian"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03504",
        "abstract": "Maintaining connectivity is crucial in many multi-robot applications, yet fragile to obstacles and visual occlusions. We present a real-time distributed framework for multi-robot navigation certified by high-order control barrier functions (HOCBFs) that controls inter-robot proximity to maintain connectivity while avoiding collisions. We incorporate control Lyapunov functions to enable connectivity recovery from initial disconnected configurations and temporary losses, providing robust connectivity during navigation in obstacle-rich environments. Our trajectory generation framework concurrently produces planning and control through a Bezier-parameterized trajectory, which naturally provides smooth curves with arbitrary degree of derivatives. The main contribution is the unified MPC-CLF-CBF framework, a continuous-time trajectory generation and control method for connectivity maintenance and recovery of multi-robot systems. We validate the framework through extensive simulations and a physical experiment with 4 Crazyflie nano-quadrotors.",
        "tags": [
            "MPC",
            "Robotics"
        ]
    },
    {
        "id": "85",
        "title": "OneFlow: Concurrent Mixed-Modal and Interleaved Generation with Edit Flows",
        "author": [
            "John Nguyen",
            "Marton Havasi",
            "Tariq Berrada",
            "Luke Zettlemoyer",
            "Ricky T. Q. Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03506",
        "abstract": "We present OneFlow, the first non-autoregressive multimodal model that enables variable-length and concurrent mixed-modal generation. Unlike autoregressive models that enforce rigid causal ordering between text and image generation, OneFlow combines an insertion-based Edit Flow for discrete text tokens with Flow Matching for image latents. OneFlow enables concurrent text-image synthesis with hierarchical sampling that prioritizes content over grammar. Through controlled experiments across model sizes from 1B to 8B, we demonstrate that OneFlow outperforms autoregressive baselines on both generation and understanding tasks while using up to 50% fewer training FLOPs. OneFlow surpasses both autoregressive and diffusion-based approaches while unlocking new capabilities for concurrent generation, iterative refinement, and natural reasoning-like generation.",
        "tags": [
            "Diffusion",
            "Flow Matching"
        ]
    },
    {
        "id": "86",
        "title": "D2 Actor Critic: Diffusion Actor Meets Distributional Critic",
        "author": [
            "Lunjun Zhang",
            "Shuo Han",
            "Hanrui Lyu",
            "Bradly C Stadie"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03508",
        "abstract": "We introduce D2AC, a new model-free reinforcement learning (RL) algorithm designed to train expressive diffusion policies online effectively. At its core is a policy improvement objective that avoids the high variance of typical policy gradients and the complexity of backpropagation through time. This stable learning process is critically enabled by our second contribution: a robust distributional critic, which we design through a fusion of distributional RL and clipped double Q-learning. The resulting algorithm is highly effective, achieving state-of-the-art performance on a benchmark of eighteen hard RL tasks, including Humanoid, Dog, and Shadow Hand domains, spanning both dense-reward and goal-conditioned RL scenarios. Beyond standard benchmarks, we also evaluate a biologically motivated predator-prey task to examine the behavioral robustness and generalization capacity of our approach.",
        "tags": [
            "Diffusion",
            "RL"
        ]
    },
    {
        "id": "87",
        "title": "Red Lines and Grey Zones in the Fog of War: Benchmarking Legal Risk, Moral Harm, and Regional Bias in Large Language Model Military Decision-Making",
        "author": [
            "Toby Drinkall"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03514",
        "abstract": "As military organisations consider integrating large language models (LLMs) into command and control (C2) systems for planning and decision support, understanding their behavioural tendencies is critical. This study develops a benchmarking framework for evaluating aspects of legal and moral risk in targeting behaviour by comparing LLMs acting as agents in multi-turn simulated conflict. We introduce four metrics grounded in International Humanitarian Law (IHL) and military doctrine: Civilian Target Rate (CTR) and Dual-use Target Rate (DTR) assess compliance with legal targeting principles, while Mean and Max Simulated Non-combatant Casualty Value (SNCV) quantify tolerance for civilian harm.\nWe evaluate three frontier models, GPT-4o, Gemini-2.5, and LLaMA-3.1, through 90 multi-agent, multi-turn crisis simulations across three geographic regions. Our findings reveal that off-the-shelf LLMs exhibit concerning and unpredictable targeting behaviour in simulated conflict environments. All models violated the IHL principle of distinction by targeting civilian objects, with breach rates ranging from 16.7% to 66.7%. Harm tolerance escalated through crisis simulations with MeanSNCV increasing from 16.5 in early turns to 27.7 in late turns. Significant inter-model variation emerged: LLaMA-3.1 selected an average of 3.47 civilian strikes per simulation with MeanSNCV of 28.4, while Gemini-2.5 selected 0.90 civilian strikes with MeanSNCV of 17.6. These differences indicate that model selection for deployment constitutes a choice about acceptable legal and moral risk profiles in military operations.\nThis work seeks to provide a proof-of-concept of potential behavioural risks that could emerge from the use of LLMs in Decision Support Systems (AI DSS) as well as a reproducible benchmarking framework with interpretable metrics for standardising pre-deployment testing.",
        "tags": [
            "GPT",
            "LLM",
            "LLaMA"
        ]
    },
    {
        "id": "88",
        "title": "RAPID: An Efficient Reinforcement Learning Algorithm for Small Language Models",
        "author": [
            "Lianghuan Huang",
            "Sagnik Anupam",
            "Insup Lee",
            "Shuo Li",
            "Osbert Bastani"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03515",
        "abstract": "Reinforcement learning (RL) has emerged as a promising strategy for finetuning small language models (SLMs) to solve targeted tasks such as math and coding. However, RL algorithms tend to be resource-intensive, taking a significant amount of time to train. We propose RAPID, a novel RL algorithm that can substantially reduce the running time of RL. Our key insight is that RL tends to be costly due to the need to perform both inference and backpropagation during training. To maximize use of computational resources, our algorithm performs inference in large batches, and then performs off-policy policy gradient updates in mini-batches. For off-policy updates, we incorporate group advantage estimation into the policy gradient algorithm, and derive an importance weighted estimator to correct for the bias arising from off-policy learning. Our experiments demonstrate that our algorithm can reduce running time by 11%-34% on three benchmarks compared to state-of-the-art RL algorithms while maintaining similar or better accuracy.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "89",
        "title": "TS-Reasoner: Aligning Time Series Foundation Models with LLM Reasoning",
        "author": [
            "Fangxu Yu",
            "Hongyu Zhao",
            "Tianyi Zhou"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03519",
        "abstract": "Time series reasoning is crucial to decision-making in diverse domains, including finance, energy usage, traffic, weather, and scientific discovery. While existing time series foundation models (TSFMs) can capture low-level dynamic patterns and provide accurate forecasting, further analysis usually requires additional background knowledge and sophisticated reasoning, which are lacking in most TSFMs but can be achieved through large language models (LLMs). On the other hand, without expensive post-training, LLMs often struggle with the numerical understanding of time series data. Although it is intuitive to integrate the two types of models, developing effective training recipes that align the two modalities for reasoning tasks is still an open challenge. To this end, we propose TS-Reasoner that aligns the latent representations of TSFMs with the textual inputs of LLMs for downstream understanding/reasoning tasks. Specifically, we propose a simple yet effective method to curate diverse, synthetic pairs of time series and textual captions for alignment training. We then develop a two-stage training recipe that applies instruction finetuning after the alignment pretraining. Unlike existing works that train an LLM to take time series as inputs, we leverage a pretrained TSFM and freeze it during training. Extensive experiments on several benchmarks demonstrate that TS-Reasoner not only outperforms a wide range of prevailing LLMs, Vision Language Models (VLMs), and Time Series LLMs, but also achieves this with remarkable data efficiency, e.g., using less than half the training data.",
        "tags": [
            "LLM",
            "VLM"
        ]
    },
    {
        "id": "90",
        "title": "Certifiable Safe RLHF: Fixed-Penalty Constraint Optimization for Safer Language Models",
        "author": [
            "Kartik Pandit",
            "Sourav Ganguly",
            "Arnesh Banerjee",
            "Shaahin Angizi",
            "Arnob Ghosh"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03520",
        "abstract": "Ensuring safety is a foundational requirement for large language models (LLMs). Achieving an appropriate balance between enhancing the utility of model outputs and mitigating their potential for harm is a complex and persistent challenge. Contemporary approaches frequently formalize this problem within the framework of Constrained Markov Decision Processes (CMDPs) and employ established CMDP optimization techniques. However, these methods exhibit two notable limitations. First, their reliance on reward and cost functions renders performance highly sensitive to the underlying scoring mechanism, which must capture semantic meaning rather than being triggered by superficial keywords. Second, CMDP-based training entails tuning dual-variable, a process that is both computationally expensive and does not provide any provable safety guarantee for a fixed dual variable that can be exploitable through adversarial jailbreaks. To overcome these limitations, we introduce Certifiable Safe-RLHF (CS-RLHF) that introduces a cost model trained on a large-scale corpus to assign semantically grounded safety scores. In contrast to the lagrangian-based approach, CS-RLHF adopts a rectified penalty-based formulation. This design draws on the theory of exact penalty functions in constrained optimization, wherein constraint satisfaction is enforced directly through a suitably chosen penalty term. With an appropriately scaled penalty, feasibility of the safety constraints can be guaranteed at the optimizer, eliminating the need for dual-variable updates. Empirical evaluation demonstrates that CS-RLHF outperforms state-of-the-art LLM model responses rendering at-least 5 times efficient against nominal and jail-breaking prompts",
        "tags": [
            "LLM",
            "RLHF"
        ]
    },
    {
        "id": "91",
        "title": "Identifying Financial Risk Information Using RAG with a Contrastive Insight",
        "author": [
            "Ali Elahi"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03521",
        "abstract": "In specialized domains, humans often compare new problems against similar examples, highlight nuances, and draw conclusions instead of analyzing information in isolation. When applying reasoning in specialized contexts with LLMs on top of a RAG, the pipeline can capture contextually relevant information, but it is not designed to retrieve comparable cases or related problems.\nWhile RAG is effective at extracting factual information, its outputs in specialized reasoning tasks often remain generic, reflecting broad facts rather than context-specific insights. In finance, it results in generic risks that are true for the majority of companies. To address this limitation, we propose a peer-aware comparative inference layer on top of RAG.\nOur contrastive approach outperforms baseline RAG in text generation metrics such as ROUGE and BERTScore in comparison with human-generated equity research and risk.",
        "tags": [
            "LLM",
            "RAG"
        ]
    },
    {
        "id": "92",
        "title": "Fine-Tuning on Noisy Instructions: Effects on Generalization and Performance",
        "author": [
            "Ahmed Alajrami",
            "Xingwei Tan",
            "Nikolaos Aletras"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03528",
        "abstract": "Instruction-tuning plays a vital role in enhancing the task-solving abilities of large language models (LLMs), improving their usability in generating helpful responses on various tasks. However, previous work has demonstrated that they are sensitive to minor variations in instruction phrasing. In this paper, we explore whether introducing perturbations in instruction-tuning data can enhance LLMs' resistance against noisy instructions. We focus on how instruction-tuning with perturbations, such as removing stop words or shuffling words, affects LLMs' performance on the original and perturbed versions of widely-used benchmarks (MMLU, BBH, GSM8K). We further assess learning dynamics and potential shifts in model behavior. Surprisingly, our results suggest that instruction-tuning on perturbed instructions can, in some cases, improve downstream performance. These findings highlight the importance of including perturbed instructions in instruction-tuning, which can make LLMs more resilient to noisy user inputs.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "93",
        "title": "What is a protest anyway? Codebook conceptualization is still a first-order concern in LLM-era classification",
        "author": [
            "Andrew Halterman",
            "Katherine A. Keith"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03541",
        "abstract": "Generative large language models (LLMs) are now used extensively for text classification in computational social science (CSS). In this work, focus on the steps before and after LLM prompting -- conceptualization of concepts to be classified and using LLM predictions in downstream statistical inference -- which we argue have been overlooked in much of LLM-era CSS. We claim LLMs can tempt analysts to skip the conceptualization step, creating conceptualization errors that bias downstream estimates. Using simulations, we show that this conceptualization-induced bias cannot be corrected for solely by increasing LLM accuracy or post-hoc bias correction methods. We conclude by reminding CSS analysts that conceptualization is still a first-order concern in the LLM-era and provide concrete advice on how to pursue low-cost, unbiased, low-variance downstream estimates.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "94",
        "title": "A Multi-Layer Electronic and Cyber Interference Model for AI-Driven Cruise Missiles: The Case of Khuzestan Province",
        "author": [
            "Pouriya Alimoradi",
            "Ali Barati",
            "Hamid Barati"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03542",
        "abstract": "The rapid advancement of Artificial Intelligence has enabled the development of cruise missiles endowed with high levels of autonomy, adaptability, and precision. These AI driven missiles integrating deep learning algorithms, real time data processing, and advanced guidance systems pose critical threats to strategic infrastructures, especially under complex geographic and climatic conditions such as those found in Irans Khuzestan Province. In this paper, we propose a multi layer interference model, encompassing electronic warfare, cyberattacks, and deception strategies, to degrade the performance of AI guided cruise missiles significantly. Our experimental results, derived from 400 simulation runs across four distinct scenarios, demonstrate notable improvements when employing the integrated multi layer approach compared to single layer or no interference baselines. Specifically, the average missile deviation from its intended target increases from 0.25 to 8.65 under multi layer interference a more than 3300 increase in angular deviation. Furthermore, the target acquisition success rate is reduced from 92.7 in the baseline scenario to 31.5, indicating a 66 decrease in successful strikes. While resource consumption for multi layer strategies rises by approximately 25 compared to single layer methods, the significant drop in missile accuracy and reliability justifies the more intensive deployment of jamming power, cyber resources, and decoy measures. Beyond these quantitative improvements, the proposed framework uses a deep reinforcement learning based defense coordinator to adaptively select the optimal configuration of EW, cyber, and deception tactics in real time.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "95",
        "title": "From Scope to Script: An Automated Report Generation Model for Gastrointestinal Endoscopy",
        "author": [
            "Evandros Kaklamanos",
            "Kristjana Kristinsdottir",
            "Jonathan Huang",
            "Dustin Carlson",
            "Rajesh Keswani",
            "John Pandolfino",
            "Mozziyar Etemadi"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03543",
        "abstract": "Endoscopic procedures such as esophagogastroduodenoscopy (EGD) and colonoscopy play a critical role in diagnosing and managing gastrointestinal (GI) disorders. However, the documentation burden associated with these procedures place significant strain on gastroenterologists, contributing to inefficiencies in clinical workflows and physician burnout. To address this challenge, we propose a novel automated report generation model that leverages a transformer-based vision encoder and text decoder within a two-stage training framework. In the first stage, both components are pre-trained on image/text caption pairs to capture generalized vision-language features, followed by fine-tuning on images/report pairs to generate clinically meaningful findings. Our approach not only streamlines the documentation process but also holds promise for reducing physician workload and improving patient care.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "96",
        "title": "SketchPlan: Diffusion Based Drone Planning From Human Sketches",
        "author": [
            "Sixten Norelius",
            "Aaron O. Feldman",
            "Mac Schwager"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03545",
        "abstract": "We propose SketchPlan, a diffusion-based planner that interprets 2D hand-drawn sketches over depth images to generate 3D flight paths for drone navigation. SketchPlan comprises two components: a SketchAdapter that learns to map the human sketches to projected 2D paths, and DiffPath, a diffusion model that infers 3D trajectories from 2D projections and a first person view depth image. Our model achieves zero-shot sim-to-real transfer, generating accurate and safe flight paths in previously unseen real-world environments. To train the model, we build a synthetic dataset of 32k flight paths using a diverse set of photorealistic 3D Gaussian Splatting scenes. We automatically label the data by computing 2D projections of the 3D flight paths onto the camera plane, and use this to train the DiffPath diffusion model. However, since real human 2D sketches differ significantly from ideal 2D projections, we additionally label 872 of the 3D flight paths with real human sketches and use this to train the SketchAdapter to infer the 2D projection from the human sketch. We demonstrate SketchPlan's effectiveness in both simulated and real-world experiments, and show through ablations that training on a mix of human labeled and auto-labeled data together with a modular design significantly boosts its capabilities to correctly interpret human intent and infer 3D paths. In real-world drone tests, SketchPlan achieved 100\\% success in low/medium clutter and 40\\% in unseen high-clutter environments, outperforming key ablations by 20-60\\% in task completion.",
        "tags": [
            "3D",
            "Diffusion",
            "Gaussian Splatting"
        ]
    },
    {
        "id": "97",
        "title": "Unmasking Puppeteers: Leveraging Biometric Leakage to Disarm Impersonation in AI-based Videoconferencing",
        "author": [
            "Danial Samadi Vahdati",
            "Tai Duc Nguyen",
            "Ekta Prashnani",
            "Koki Nagano",
            "David Luebke",
            "Orazio Gallo",
            "Matthew Stamm"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03548",
        "abstract": "AI-based talking-head videoconferencing systems reduce bandwidth by sending a compact pose-expression latent and re-synthesizing RGB at the receiver, but this latent can be puppeteered, letting an attacker hijack a victim's likeness in real time. Because every frame is synthetic, deepfake and synthetic video detectors fail outright. To address this security problem, we exploit a key observation: the pose-expression latent inherently contains biometric information of the driving identity. Therefore, we introduce the first biometric leakage defense without ever looking at the reconstructed RGB video: a pose-conditioned, large-margin contrastive encoder that isolates persistent identity cues inside the transmitted latent while cancelling transient pose and expression. A simple cosine test on this disentangled embedding flags illicit identity swaps as the video is rendered. Our experiments on multiple talking-head generation models show that our method consistently outperforms existing puppeteering defenses, operates in real-time, and shows strong generalization to out-of-distribution scenarios.",
        "tags": [
            "Talking Head"
        ]
    },
    {
        "id": "98",
        "title": "Streaming Drag-Oriented Interactive Video Manipulation: Drag Anything, Anytime!",
        "author": [
            "Junbao Zhou",
            "Yuan Zhou",
            "Kesen Zhao",
            "Qingshan Xu",
            "Beier Zhu",
            "Richang Hong",
            "Hanwang Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03550",
        "abstract": "Achieving streaming, fine-grained control over the outputs of autoregressive video diffusion models remains challenging, making it difficult to ensure that they consistently align with user expectations. To bridge this gap, we propose \\textbf{stReaming drag-oriEnted interactiVe vidEo manipuLation (REVEL)}, a new task that enables users to modify generated videos \\emph{anytime} on \\emph{anything} via fine-grained, interactive drag. Beyond DragVideo and SG-I2V, REVEL unifies drag-style video manipulation as editing and animating video frames with both supporting user-specified translation, deformation, and rotation effects, making drag operations versatile. In resolving REVEL, we observe: \\emph{i}) drag-induced perturbations accumulate in latent space, causing severe latent distribution drift that halts the drag process; \\emph{ii}) streaming drag is easily disturbed by context frames, thereby yielding visually unnatural outcomes. We thus propose a training-free approach, \\textbf{DragStream}, comprising: \\emph{i}) an adaptive distribution self-rectification strategy that leverages neighboring frames' statistics to effectively constrain the drift of latent embeddings; \\emph{ii}) a spatial-frequency selective optimization mechanism, allowing the model to fully exploit contextual information while mitigating its interference via selectively propagating visual cues along generation. Our method can be seamlessly integrated into existing autoregressive video diffusion models, and extensive experiments firmly demonstrate the effectiveness of our DragStream.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "99",
        "title": "CCD-Bench: Probing Cultural Conflict in Large Language Model Decision-Making",
        "author": [
            "Hasibur Rahman",
            "Hanan Salam"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03553",
        "abstract": "Although large language models (LLMs) are increasingly implicated in interpersonal and societal decision-making, their ability to navigate explicit conflicts between legitimately different cultural value systems remains largely unexamined. Existing benchmarks predominantly target cultural knowledge (CulturalBench), value prediction (WorldValuesBench), or single-axis bias diagnostics (CDEval); none evaluate how LLMs adjudicate when multiple culturally grounded values directly clash. We address this gap with CCD-Bench, a benchmark that assesses LLM decision-making under cross-cultural value conflict. CCD-Bench comprises 2,182 open-ended dilemmas spanning seven domains, each paired with ten anonymized response options corresponding to the ten GLOBE cultural clusters. These dilemmas are presented using a stratified Latin square to mitigate ordering effects. We evaluate 17 non-reasoning LLMs. Models disproportionately prefer Nordic Europe (mean 20.2 percent) and Germanic Europe (12.4 percent), while options for Eastern Europe and the Middle East and North Africa are underrepresented (5.6 to 5.8 percent). Although 87.9 percent of rationales reference multiple GLOBE dimensions, this pluralism is superficial: models recombine Future Orientation and Performance Orientation, and rarely ground choices in Assertiveness or Gender Egalitarianism (both under 3 percent). Ordering effects are negligible (Cramer's V less than 0.10), and symmetrized KL divergence shows clustering by developer lineage rather than geography. These patterns suggest that current alignment pipelines promote a consensus-oriented worldview that underserves scenarios demanding power negotiation, rights-based reasoning, or gender-aware analysis. CCD-Bench shifts evaluation beyond isolated bias detection toward pluralistic decision making and highlights the need for alignment strategies that substantively engage diverse worldviews.",
        "tags": [
            "Detection",
            "LLM"
        ]
    },
    {
        "id": "100",
        "title": "PrivacyMotiv: Speculative Persona Journeys for Empathic and Motivating Privacy Reviews in UX Design",
        "author": [
            "Zeya Chen",
            "Jianing Wen",
            "Ruth Schmidt",
            "Yaxing Yao",
            "Toby Jia-Jun Li",
            "Tianshi Li"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03559",
        "abstract": "UX professionals routinely conduct design reviews, yet privacy concerns are often overlooked -- not only due to limited tools, but more critically because of low intrinsic motivation. Limited privacy knowledge, weak empathy for unexpectedly affected users, and low confidence in identifying harms make it difficult to address risks. We present PrivacyMotiv, an LLM-powered system that supports privacy-oriented design diagnosis by generating speculative personas with UX user journeys centered on individuals vulnerable to privacy risks. Drawing on narrative strategies, the system constructs relatable and attention-drawing scenarios that show how ordinary design choices may cause unintended harms, expanding the scope of privacy reflection in UX. In a within-subjects study with professional UX practitioners (N=16), we compared participants' self-proposed methods with PrivacyMotiv across two privacy review tasks. Results show significant improvements in empathy, intrinsic motivation, and perceived usefulness. This work contributes a promising privacy review approach which addresses the motivational barriers in privacy-aware UX.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "101",
        "title": "Reactive Transformer (RxT) -- Stateful Real-Time Processing for Event-Driven Reactive Language Models",
        "author": [
            "Adam Filipek"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03561",
        "abstract": "The Transformer architecture has become the de facto standard for Large Language Models (LLMs), demonstrating remarkable capabilities in language understanding and generation. However, its application in conversational AI is fundamentally constrained by its stateless nature and the quadratic computational complexity ($O(L^2)$) with respect to sequence length $L$. Current models emulate memory by reprocessing an ever-expanding conversation history with each turn, leading to prohibitive costs and latency in long dialogues. This paper introduces the Reactive Transformer (RxT), a novel architecture designed to overcome these limitations by shifting from a data-driven to an event-driven paradigm. RxT processes each conversational turn as a discrete event in real-time, maintaining context in an integrated, fixed-size Short-Term Memory (STM) system. The architecture features a distinct operational cycle where a generator-decoder produces a response based on the current query and the previous memory state, after which a memory-encoder and a dedicated Memory Attention network asynchronously update the STM with a representation of the complete interaction. This design fundamentally alters the scaling dynamics, reducing the total user-facing cost of a conversation from quadratic ($O(N^2 \\cdot T)$) to linear ($O(N \\cdot T)$) with respect to the number of interactions $N$. By decoupling response generation from memory updates, RxT achieves low latency, enabling truly real-time, stateful, and economically viable long-form conversations. We validated our architecture with a series of proof-of-concept experiments on synthetic data, demonstrating superior performance and constant-time inference latency compared to a baseline stateless model of comparable size.",
        "tags": [
            "LLM",
            "Transformer"
        ]
    },
    {
        "id": "102",
        "title": "CrossLag: Predicting Major Dengue Outbreaks with a Domain Knowledge Informed Transformer",
        "author": [
            "Ashwin Prabu",
            "Nhat Thanh Tran",
            "Guofa Zhou",
            "Jack Xin"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03566",
        "abstract": "A variety of models have been developed to forecast dengue cases to date. However, it remains a challenge to predict major dengue outbreaks that need timely public warnings the most. In this paper, we introduce CrossLag, an environmentally informed attention that allows for the incorporation of lagging endogenous signals behind the significant events in the exogenous data into the architecture of the transformer at low parameter counts. Outbreaks typically lag behind major changes in climate and oceanic anomalies. We use TimeXer, a recent general-purpose transformer distinguishing exogenous-endogenous inputs, as the baseline for this study. Our proposed model outperforms TimeXer by a considerable margin in detecting and predicting major outbreaks in Singapore dengue data over a 24-week prediction window.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "103",
        "title": "Machine Unlearning Meets Adversarial Robustness via Constrained Interventions on LLMs",
        "author": [
            "Fatmazohra Rezkellah",
            "Ramzi Dakhmouche"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03567",
        "abstract": "With the increasing adoption of Large Language Models (LLMs), more customization is needed to ensure privacy-preserving and safe generation. We address this objective from two critical aspects: unlearning of sensitive information and robustness to jail-breaking attacks. We investigate various constrained optimization formulations that address both aspects in a \\emph{unified manner}, by finding the smallest possible interventions on LLM weights that either make a given vocabulary set unreachable or embed the LLM with robustness to tailored attacks by shifting part of the weights to a \\emph{safer} region. Beyond unifying two key properties, this approach contrasts with previous work in that it doesn't require an oracle classifier that is typically not available or represents a computational overhead. Surprisingly, we find that the simplest point-wise constraint-based intervention we propose leads to better performance than max-min interventions, while having a lower computational cost. Comparison against state-of-the-art defense methods demonstrates superior performance of the proposed approach.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "104",
        "title": "Longitudinal Flow Matching for Trajectory Modeling",
        "author": [
            "Mohammad Mohaiminul Islam",
            "Thijs P. Kuipers",
            "Sharvaree Vadgama",
            "Coen de Vente",
            "Afsana Khan",
            "Clara I. SÃ¡nchez",
            "Erik J. Bekkers"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03569",
        "abstract": "Generative models for sequential data often struggle with sparsely sampled and high-dimensional trajectories, typically reducing the learning of dynamics to pairwise transitions. We propose \\textit{Interpolative Multi-Marginal Flow Matching} (IMMFM), a framework that learns continuous stochastic dynamics jointly consistent with multiple observed time points. IMMFM employs a piecewise-quadratic interpolation path as a smooth target for flow matching and jointly optimizes drift and a data-driven diffusion coefficient, supported by a theoretical condition for stable learning. This design captures intrinsic stochasticity, handles irregular sparse sampling, and yields subject-specific trajectories. Experiments on synthetic benchmarks and real-world longitudinal neuroimaging datasets show that IMMFM outperforms existing methods in both forecasting accuracy and further downstream tasks.",
        "tags": [
            "Diffusion",
            "Flow Matching"
        ]
    },
    {
        "id": "105",
        "title": "Efficient Test-Time Scaling for Small Vision-Language Models",
        "author": [
            "Mehmet Onurcan Kaya",
            "Desmond Elliott",
            "Dim P. Papadopoulos"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03574",
        "abstract": "Small Vision-Language Models (VLMs) provide a computationally efficient alternative to larger models, at the cost of weaker generalization abilities and downstream task performance. These shortcomings could be addressed by test-time scaling techniques, but existing methods are typically computationally demanding, contradicting the resource-efficient design goals of small models. To address these limitations, we propose two novel and efficient test-time scaling strategies that leverage the model-internal features rather than external supervision: (i) Test-Time Augmentation (TTAug), which generates multiple augmented inputs and aggregates outputs at the token level without parameter updates, and (ii) Test-Time Adaptation (TTAdapt), which adapts model parameters during inference using consensus-based pseudolabels from TTAug. Through extensive experiments across nine benchmarks, we demonstrate consistent performance improvements while maintaining computational efficiency suitable for resource-constrained environments. The generality of our approach is demonstrated both within models at different scales and across different VLMs without additional tuning.",
        "tags": [
            "VLM"
        ]
    },
    {
        "id": "106",
        "title": "BEKAN: Boundary condition-guaranteed evolutionary Kolmogorov-Arnold networks with radial basis functions for solving PDE problems",
        "author": [
            "Bongseok Kim",
            "Jiahao Zhang",
            "Guang Lin"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03576",
        "abstract": "Deep learning has gained attention for solving PDEs, but the black-box nature of neural networks hinders precise enforcement of boundary conditions. To address this, we propose a boundary condition-guaranteed evolutionary Kolmogorov-Arnold Network (KAN) with radial basis functions (BEKAN). In BEKAN, we propose three distinct and combinable approaches for incorporating Dirichlet, periodic, and Neumann boundary conditions into the network. For Dirichlet problem, we use smooth and global Gaussian RBFs to construct univariate basis functions for approximating the solution and to encode boundary information at the activation level of the network. To handle periodic problems, we employ a periodic layer constructed from a set of sinusoidal functions to enforce the boundary conditions exactly. For a Neumann problem, we devise a least-squares formulation to guide the parameter evolution toward satisfying the Neumann condition. By virtue of the boundary-embedded RBFs, the periodic layer, and the evolutionary framework, we can perform accurate PDE simulations while rigorously enforcing boundary conditions. For demonstration, we conducted extensive numerical experiments on Dirichlet, Neumann, periodic, and mixed boundary value problems. The results indicate that BEKAN outperforms both multilayer perceptron (MLP) and B-splines KAN in terms of accuracy. In conclusion, the proposed approach enhances the capability of KANs in solving PDE problems while satisfying boundary conditions, thereby facilitating advancements in scientific computing and engineering applications.",
        "tags": [
            "KAN"
        ]
    },
    {
        "id": "107",
        "title": "Latent Mixture of Symmetries for Sample-Efficient Dynamic Learning",
        "author": [
            "Haoran Li",
            "Chenhan Xiao",
            "Muhao Guo",
            "Yang Weng"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03578",
        "abstract": "Learning dynamics is essential for model-based control and Reinforcement Learning in engineering systems, such as robotics and power systems. However, limited system measurements, such as those from low-resolution sensors, demand sample-efficient learning. Symmetry provides a powerful inductive bias by characterizing equivariant relations in system states to improve sample efficiency. While recent methods attempt to discover symmetries from data, they typically assume a single global symmetry group and treat symmetry discovery and dynamic learning as separate tasks, leading to limited expressiveness and error accumulation. In this paper, we propose the Latent Mixture of Symmetries (Latent MoS), an expressive model that captures a mixture of symmetry-governed latent factors from complex dynamical measurements. Latent MoS focuses on dynamic learning while locally and provably preserving the underlying symmetric transformations. To further capture long-term equivariance, we introduce a hierarchical architecture that stacks MoS blocks. Numerical experiments in diverse physical systems demonstrate that Latent MoS outperforms state-of-the-art baselines in interpolation and extrapolation tasks while offering interpretable latent representations suitable for future geometric and safety-critical analyses.",
        "tags": [
            "RL",
            "Robotics"
        ]
    },
    {
        "id": "108",
        "title": "FrameOracle: Learning What to See and How Much to See in Videos",
        "author": [
            "Chaoyu Li",
            "Tianzhi Li",
            "Fei Tao",
            "Zhenyu Zhao",
            "Ziqian Wu",
            "Maozheng Zhao",
            "Juntong Song",
            "Cheng Niu",
            "Pooyan Fazli"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03584",
        "abstract": "Vision-language models (VLMs) have advanced video understanding, but their performance is limited by the number of input frames they can process. Existing frame sampling strategies, such as uniform or fixed-budget selection, often fail to adapt to variations in information density or task complexity, resulting in inefficiency and information loss. To address this, we present FrameOracle, a lightweight and plug-and-play module that predicts both (1) which frames are most relevant to a given query and (2) how many frames are needed. FrameOracle is trained using a four-stage curriculum, with the first three stages relying on weak proxy signals such as cross-modal similarity. In the final stage, it leverages stronger supervision from a new dataset we introduce, FrameOracle-41K, the first large-scale VideoQA collection to provide keyframe annotations specifying the minimal set of frames required to answer each question. Extensive experiments across five VLMs and six benchmarks demonstrate that FrameOracle reduces 16-frame inputs to an average of 10.4 frames without any loss in accuracy. When starting from 64-frame candidates, it reduces the input to an average of 13.9 frames while improving accuracy by 1.4%, achieving state-of-the-art efficiency-accuracy trade-offs for scalable video understanding.",
        "tags": [
            "VLM"
        ]
    },
    {
        "id": "109",
        "title": "REFINE: Enhancing Program Repair Agents through Context-Aware Patch Refinement",
        "author": [
            "Anvith Pabba",
            "Simin Chen",
            "Alex Mathai",
            "Anindya Chakraborty",
            "Baishakhi Ray"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03588",
        "abstract": "Large Language Models (LLMs) have recently shown strong potential in automatic program repair (APR), especially in repository-level settings where the goal is to generate patches based on natural language issue descriptions, large codebases, and regression tests. However, despite their promise, current LLM-based APR techniques often struggle to produce correct fixes due to limited understanding of code context and over-reliance on incomplete test suites. As a result, they frequently generate Draft Patches-partially correct patches that either incompletely address the bug or overfit to the test cases. In this work, we propose a novel patch refinement framework, Refine, that systematically transforms Draft Patches into correct ones. Refine addresses three key challenges: disambiguating vague issue and code context, diversifying patch candidates through test-time scaling, and aggregating partial fixes via an LLM-powered code review process. We implement Refine as a general refinement module that can be integrated into both open-agent-based and workflow-based APR systems. Our evaluation on the SWE-Bench Lite benchmark shows that Refine achieves state-of-the-art results among workflow-based approaches and approaches the best-known performance across all APR categories. Specifically, Refine boosts AutoCodeRover's performance by 14.67%, achieving a score of 51.67% and surpassing all prior baselines. On SWE-Bench Verified, Refine improves the resolution rate by 12.2%, and when integrated across multiple APR systems, it yields an average improvement of 14%-demonstrating its broad effectiveness and generalizability. These results highlight the effectiveness of refinement as a missing component in current APR pipelines and the potential of agentic collaboration in closing the gap between near-correct and correct patches. We also open source our code.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "110",
        "title": "FieldFormer: Physics-Informed Transformers for Spatio-Temporal Field Reconstruction from Sparse Sensors",
        "author": [
            "Ankit Bhardwaj",
            "Ananth Balashankar",
            "Lakshminarayanan Subramanian"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03589",
        "abstract": "Spatio-temporal sensor data is often sparse, noisy, and irregular, and existing interpolation or learning methods struggle here because they either ignore governing PDEs or do not scale. We introduce FieldFormer, a transformer-based framework for mesh-free spatio-temporal field reconstruction that combines data-driven flexibility with physics-based structure. For each query, FieldFormer gathers a local neighborhood using a learnable velocity-scaled distance metric, enabling anisotropic adaptation to different propagation regimes. Neighborhoods are built efficiently via per-batch offset recomputation, and refined in an expectation-maximization style as the velocity scales evolve. Predictions are made by a local transformer encoder, and physics consistency is enforced through autograd-based PDE residuals and boundary-specific penalties. Across three benchmarks--a scalar anisotropic heat equation, a vector-valued shallow-water system, and a realistic advection-diffusion pollution simulation--FieldFormer consistently outperforms strong baselines by more than 40%. Our results demonstrate that FieldFormer enables accurate (RMSE$<10^{-2}$), efficient, and physically consistent field reconstruction from sparse (0.4%-2%) and noisy(10%) data.",
        "tags": [
            "Diffusion",
            "Transformer"
        ]
    },
    {
        "id": "111",
        "title": "Deep Reinforcement Learning for Multi-Agent Coordination",
        "author": [
            "Kehinde O. Aina",
            "Sehoon Ha"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03592",
        "abstract": "We address the challenge of coordinating multiple robots in narrow and confined environments, where congestion and interference often hinder collective task performance. Drawing inspiration from insect colonies, which achieve robust coordination through stigmergy -- modifying and interpreting environmental traces -- we propose a Stigmergic Multi-Agent Deep Reinforcement Learning (S-MADRL) framework that leverages virtual pheromones to model local and social interactions, enabling decentralized emergent coordination without explicit communication. To overcome the convergence and scalability limitations of existing algorithms such as MADQN, MADDPG, and MAPPO, we leverage curriculum learning, which decomposes complex tasks into progressively harder sub-problems. Simulation results show that our framework achieves the most effective coordination of up to eight agents, where robots self-organize into asymmetric workload distributions that reduce congestion and modulate group performance. This emergent behavior, analogous to strategies observed in nature, demonstrates a scalable solution for decentralized multi-agent coordination in crowded environments with communication constraints.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "112",
        "title": "Decoupling Task-Solving and Output Formatting in LLM Generation",
        "author": [
            "Haikang Deng",
            "Po-Nien Kung",
            "Nanyun Peng"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03595",
        "abstract": "Large language models (LLMs) are increasingly adept at following instructions containing task descriptions to solve complex problems, such as mathematical reasoning and automatic evaluation (LLM-as-a-Judge). However, as prompts grow more complex, models often struggle to adhere to all instructions. This difficulty is especially common when instructive prompts intertwine reasoning directives -- specifying what the model should solve -- with rigid formatting requirements that dictate how the solution must be presented. The entanglement creates competing goals for the model, suggesting that more explicit separation of these two aspects could lead to improved performance. To this front, we introduce Deco-G, a decoding framework that explicitly decouples format adherence from task solving. Deco-G handles format compliance with a separate tractable probabilistic model (TPM), while prompts LLMs with only task instructions. At each decoding step, Deco-G combines next token probabilities from the LLM with the TPM calculated format compliance likelihood to form the output probability. To make this approach both practical and scalable for modern instruction-tuned LLMs, we introduce three key innovations: instruction-aware distillation, a flexible trie-building algorithm, and HMM state pruning for computational efficiency. We demonstrate the effectiveness of Deco-G across a wide range of tasks with diverse format requirements, including mathematical reasoning, LLM-as-a-judge, and event argument extraction. Overall, our approach yields 1.0% to 6.0% relative gain over regular prompting practice with guaranteed format compliance.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "113",
        "title": "Neon: Negative Extrapolation From Self-Training Improves Image Generation",
        "author": [
            "Sina Alemohammad",
            "Zhangyang Wang",
            "Richard G. Baraniuk"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03597",
        "abstract": "Scaling generative AI models is bottlenecked by the scarcity of high-quality training data. The ease of synthesizing from a generative model suggests using (unverified) synthetic data to augment a limited corpus of real data for the purpose of fine-tuning in the hope of improving performance. Unfortunately, however, the resulting positive feedback loop leads to model autophagy disorder (MAD, aka model collapse) that results in a rapid degradation in sample quality and/or diversity. In this paper, we introduce Neon (for Negative Extrapolation frOm self-traiNing), a new learning method that turns the degradation from self-training into a powerful signal for self-improvement. Given a base model, Neon first fine-tunes it on its own self-synthesized data but then, counterintuitively, reverses its gradient updates to extrapolate away from the degraded weights. We prove that Neon works because typical inference samplers that favor high-probability regions create a predictable anti-alignment between the synthetic and real data population gradients, which negative extrapolation corrects to better align the model with the true data distribution. Neon is remarkably easy to implement via a simple post-hoc merge that requires no new real data, works effectively with as few as 1k synthetic samples, and typically uses less than 1% additional training compute. We demonstrate Neon's universality across a range of architectures (diffusion, flow matching, autoregressive, and inductive moment matching models) and datasets (ImageNet, CIFAR-10, and FFHQ). In particular, on ImageNet 256x256, Neon elevates the xAR-L model to a new state-of-the-art FID of 1.02 with only 0.36% additional training compute. Code is available at https://github.com/SinaAlemohammad/Neon",
        "tags": [
            "Diffusion",
            "Flow Matching"
        ]
    },
    {
        "id": "114",
        "title": "Exploring the Hierarchical Reasoning Model for Small Natural-Image Classification Without Augmentation",
        "author": [
            "Alexander V. Mantzaris"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03598",
        "abstract": "This paper asks whether the Hierarchical Reasoning Model (HRM) with the two Transformer-style modules $(f_L,f_H)$, one step (DEQ-style) training, deep supervision, Rotary Position Embeddings, and RMSNorm can serve as a practical image classifier. It is evaluated on MNIST, CIFAR-10, and CIFAR-100 under a deliberately raw regime: no data augmentation, identical optimizer family with one-epoch warmup then cosine-floor decay, and label smoothing. HRM optimizes stably and performs well on MNIST ($\\approx 98\\%$ test accuracy), but on small natural images it overfits and generalizes poorly: on CIFAR-10, HRM reaches 65.0\\% after 25 epochs, whereas a two-stage Conv--BN--ReLU baseline attains 77.2\\% while training $\\sim 30\\times$ faster per epoch; on CIFAR-100, HRM achieves only 29.7\\% test accuracy despite 91.5\\% train accuracy, while the same CNN reaches 45.3\\% test with 50.5\\% train accuracy. Loss traces and error analyses indicate healthy optimization but insufficient image-specific inductive bias for HRM in this regime. It is concluded that, for small-resolution image classification without augmentation, HRM is not competitive with even simple convolutional architectures as the HRM currently exist but this does not exclude possibilities that modifications to the model may allow it to improve greatly.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "115",
        "title": "Learning to Act Through Contact: A Unified View of Multi-Task Robot Learning",
        "author": [
            "Shafeef Omar",
            "Majid Khadiv"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03599",
        "abstract": "We present a unified framework for multi-task locomotion and manipulation policy learning grounded in a contact-explicit representation. Instead of designing different policies for different tasks, our approach unifies the definition of a task through a sequence of contact goals-desired contact positions, timings, and active end-effectors. This enables leveraging the shared structure across diverse contact-rich tasks, leading to a single policy that can perform a wide range of tasks. In particular, we train a goal-conditioned reinforcement learning (RL) policy to realise given contact plans. We validate our framework on multiple robotic embodiments and tasks: a quadruped performing multiple gaits, a humanoid performing multiple biped and quadrupedal gaits, and a humanoid executing different bimanual object manipulation tasks. Each of these scenarios is controlled by a single policy trained to execute different tasks grounded in contacts, demonstrating versatile and robust behaviours across morphologically distinct systems. Our results show that explicit contact reasoning significantly improves generalisation to unseen scenarios, positioning contact-explicit policy learning as a promising foundation for scalable loco-manipulation.",
        "tags": [
            "RL",
            "Robotics"
        ]
    },
    {
        "id": "116",
        "title": "Understanding the Role of Training Data in Test-Time Scaling",
        "author": [
            "Adel Javanmard",
            "Baharan Mirzasoleiman",
            "Vahab Mirrokni"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03605",
        "abstract": "Test-time scaling improves the reasoning capabilities of large language models (LLMs) by allocating extra compute to generate longer Chains-of-Thoughts (CoTs). This enables models to tackle more complex problem by breaking them down into additional steps, backtracking, and correcting mistakes. Despite its strong performance--demonstrated by OpenAI's o1 and DeepSeek R1, the conditions in the training data under which long CoTs emerge, and when such long CoTs improve the performance, remain unclear. In this paper, we study the performance of test-time scaling for transformers trained on an in-context weight prediction task for linear regression. Our analysis provides a theoretical explanation for several intriguing observations: First, at any fixed test error, increasing test-time compute allows us to reduce the number of in-context examples (context length) in training prompts. Second, if the skills required to solve a downstream task are not sufficiently present in the training data, increasing test-time compute can harm performance. Finally, we characterize task hardness via the smallest eigenvalue of its feature covariance matrix and show that training on a diverse, relevant, and hard set of tasks results in best performance for test-time scaling. We confirm our findings with experiments on large, nonlinear transformer architectures.",
        "tags": [
            "DeepSeek",
            "LLM",
            "Transformer"
        ]
    },
    {
        "id": "117",
        "title": "Unsupervised Transformer Pre-Training for Images: Self-Distillation, Mean Teachers, and Random Crops",
        "author": [
            "Mattia Scardecchia"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03606",
        "abstract": "Recent advances in self-supervised learning (SSL) have made it possible to learn general-purpose visual features that capture both the high-level semantics and the fine-grained spatial structure of images. Most notably, the recent DINOv2 has established a new state of the art by surpassing weakly supervised methods (WSL) like OpenCLIP on most benchmarks. In this survey, we examine the core ideas behind its approach, multi-crop view augmentation and self-distillation with a mean teacher, and trace their development in previous work. We then compare the performance of DINO and DINOv2 with other SSL and WSL methods across various downstream tasks, and highlight some remarkable emergent properties of their learned features with transformer backbones. We conclude by briefly discussing DINOv2's limitations, its impact, and future research directions.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "118",
        "title": "Diffusion-Classifier Synergy: Reward-Aligned Learning via Mutual Boosting Loop for FSCIL",
        "author": [
            "Ruitao Wu",
            "Yifan Zhao",
            "Guangyao Chen",
            "Jia Li"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03608",
        "abstract": "Few-Shot Class-Incremental Learning (FSCIL) challenges models to sequentially learn new classes from minimal examples without forgetting prior knowledge, a task complicated by the stability-plasticity dilemma and data scarcity. Current FSCIL methods often struggle with generalization due to their reliance on limited datasets. While diffusion models offer a path for data augmentation, their direct application can lead to semantic misalignment or ineffective guidance. This paper introduces Diffusion-Classifier Synergy (DCS), a novel framework that establishes a mutual boosting loop between diffusion model and FSCIL classifier. DCS utilizes a reward-aligned learning strategy, where a dynamic, multi-faceted reward function derived from the classifier's state directs the diffusion model. This reward system operates at two levels: the feature level ensures semantic coherence and diversity using prototype-anchored maximum mean discrepancy and dimension-wise variance matching, while the logits level promotes exploratory image generation and enhances inter-class discriminability through confidence recalibration and cross-session confusion-aware mechanisms. This co-evolutionary process, where generated images refine the classifier and an improved classifier state yields better reward signals, demonstrably achieves state-of-the-art performance on FSCIL benchmarks, significantly enhancing both knowledge retention and new class learning.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "119",
        "title": "Can an LLM Induce a Graph? Investigating Memory Drift and Context Length",
        "author": [
            "Raquib Bin Yousuf",
            "Aadyant Khatri",
            "Shengzhe Xu",
            "Mandar Sharma",
            "Naren Ramakrishnan"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03611",
        "abstract": "Recently proposed evaluation benchmarks aim to characterize the effective context length and the forgetting tendencies of large language models (LLMs). However, these benchmarks often rely on simplistic 'needle in a haystack' retrieval or continuation tasks that may not accurately reflect the performance of these models in information-dense scenarios. Thus, rather than simple next token prediction, we argue for evaluating these models on more complex reasoning tasks that requires them to induce structured relational knowledge from the text - such as graphs from potentially noisy natural language content. While the input text can be viewed as generated in terms of a graph, its structure is not made explicit and connections must be induced from distributed textual cues, separated by long contexts and interspersed with irrelevant information. Our findings reveal that LLMs begin to exhibit memory drift and contextual forgetting at much shorter effective lengths when tasked with this form of relational reasoning, compared to what existing benchmarks suggest. With these findings, we offer recommendations for the optimal use of popular LLMs for complex reasoning tasks. We further show that even models specialized for reasoning, such as OpenAI o1, remain vulnerable to early memory drift in these settings. These results point to significant limitations in the models' ability to abstract structured knowledge from unstructured input and highlight the need for architectural adaptations to improve long-range reasoning.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "120",
        "title": "MITS: Enhanced Tree Search Reasoning for LLMs via Pointwise Mutual Information",
        "author": [
            "Jiaxi Li",
            "Yucheng Shi",
            "Jin Lu",
            "Ninghao Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03632",
        "abstract": "Tree search has become as a representative framework for test-time reasoning with large language models (LLMs), exemplified by methods such as Tree-of-Thought and Monte Carlo Tree Search that explore multiple reasoning paths. However, it remains difficult to provide instant and reliable quantitative assessments of intermediate reasoning step quality, and extensive path exploration is computationally costly. To address this, we propose Mutual Information Tree Search (MITS), a novel framework that guides reasoning with information-theoretic principles. MITS introduces an effective scoring function based on pointwise mutual information (PMI), which enables step-wise evaluation of reasoning paths and search tree expansion via beam search without expensive look-ahead simulations, achieving superior reasoning performances while maintaining computational efficiency. The framework is complemented by an entropy-based dynamic sampling strategy that adaptively allocates computational resources to uncertain reasoning steps where exploration is most beneficial. For final prediction, MITS employs a weighted voting scheme that combines PMI scores with prediction consensus. Through comprehensive experiments on diverse reasoning benchmarks, MITS consistently surpasses baseline methods, establishing a principled and efficient framework for LLM reasoning.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "121",
        "title": "Predicting Stock Price Movement with LLM-Enhanced Tweet Emotion Analysis",
        "author": [
            "An Vuong",
            "Susan Gauch"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03633",
        "abstract": "Accurately predicting short-term stock price movement remains a challenging task due to the market's inherent volatility and sensitivity to investor sentiment. This paper discusses a deep learning framework that integrates emotion features extracted from tweet data with historical stock price information to forecast significant price changes on the following day. We utilize Meta's Llama 3.1-8B-Instruct model to preprocess tweet data, thereby enhancing the quality of emotion features derived from three emotion analysis approaches: a transformer-based DistilRoBERTa classifier from the Hugging Face library and two lexicon-based methods using National Research Council Canada (NRC) resources. These features are combined with previous-day stock price data to train a Long Short-Term Memory (LSTM) model. Experimental results on TSLA, AAPL, and AMZN stocks show that all three emotion analysis methods improve the average accuracy for predicting significant price movements, compared to the baseline model using only historical stock prices, which yields an accuracy of 13.5%. The DistilRoBERTa-based stock prediction model achieves the best performance, with accuracy rising from 23.6% to 38.5% when using LLaMA-enhanced emotion analysis. These results demonstrate that using large language models to preprocess tweet content enhances the effectiveness of emotion analysis which in turn improves the accuracy of predicting significant stock price movements.",
        "tags": [
            "LLM",
            "LLaMA",
            "Transformer"
        ]
    },
    {
        "id": "122",
        "title": "From Theory to Practice: Evaluating Data Poisoning Attacks and Defenses in In-Context Learning on Social Media Health Discourse",
        "author": [
            "Rabeya Amin Jhuma",
            "Mostafa Mohaimen Akand Faisal"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03636",
        "abstract": "This study explored how in-context learning (ICL) in large language models can be disrupted by data poisoning attacks in the setting of public health sentiment analysis. Using tweets of Human Metapneumovirus (HMPV), small adversarial perturbations such as synonym replacement, negation insertion, and randomized perturbation were introduced into the support examples. Even these minor manipulations caused major disruptions, with sentiment labels flipping in up to 67% of cases. To address this, a Spectral Signature Defense was applied, which filtered out poisoned examples while keeping the data's meaning and sentiment intact. After defense, ICL accuracy remained steady at around 46.7%, and logistic regression validation reached 100% accuracy, showing that the defense successfully preserved the dataset's integrity. Overall, the findings extend prior theoretical studies of ICL poisoning to a practical, high-stakes setting in public health discourse analysis, highlighting both the risks and potential defenses for robust LLM deployment. This study also highlights the fragility of ICL under attack and the value of spectral defenses in making AI systems more reliable for health-related social media monitoring.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "123",
        "title": "Towards Unsupervised Speech Recognition at the Syllable-Level",
        "author": [
            "Liming Wang",
            "Junrui Ni",
            "Kai-Wei Chang",
            "Saurabhchand Bhati",
            "David Harwath",
            "Mark Hasegawa-Johnson",
            "James R. Glass"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03639",
        "abstract": "Training speech recognizers with unpaired speech and text -- known as unsupervised speech recognition (UASR) -- is a crucial step toward extending ASR to low-resource languages in the long-tail distribution and enabling multimodal learning from non-parallel data. However, existing approaches based on phones often rely on costly resources such as grapheme-to-phoneme converters (G2Ps) and struggle to generalize to languages with ambiguous phoneme boundaries due to training instability. In this paper, we address both challenges by introducing a syllable-level UASR framework based on masked language modeling, which avoids the need for G2P and the instability of GAN-based methods. Our approach achieves up to a 40\\% relative reduction in character error rate (CER) on LibriSpeech and generalizes effectively to Mandarin, a language that has remained particularly difficult for prior methods. Code will be released upon acceptance.",
        "tags": [
            "GAN"
        ]
    },
    {
        "id": "124",
        "title": "Generating High-Level Test Cases from Requirements using LLM: An Industry Study",
        "author": [
            "Satoshi Masuda",
            "Satoshi Kouzawa",
            "Kyousuke Sezai",
            "Hidetoshi Suhara",
            "Yasuaki Hiruta",
            "Kunihiro Kudou"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03641",
        "abstract": "Currently, generating high-level test cases described in natural language from requirement documents is performed manually. In the industry, including companies specializing in software testing, there is a significant demand for the automatic generation of high-level test cases from requirement documents using Large Language Models (LLMs). Efforts to utilize LLMs for requirement analysis are underway. In some cases, retrieval-augmented generation (RAG) is employed for generating high-level test cases using LLMs. However, in practical applications, it is necessary to create a RAG tailored to the knowledge system of each specific application, which is labor-intensive. Moreover, when applying high-level test case generation as a prompt, there is no established method for instructing the generation of high-level test cases at a level applicable to other specifications without using RAG. It is required to establish a method for the automatic generation of high-level test cases that can be generalized across a wider range of requirement documents. In this paper, we propose a method for generating high-level (GHL) test cases from requirement documents using only prompts, without creating RAGs. In the proposed method, first, the requirement document is input into the LLM to generate test design techniques corresponding to the requirement document. Then, high-level test cases are generated for each of the generated test design techniques. Furthermore, we verify an evaluation method based on semantic similarity of the generated high-level test cases. In the experiments, we confirmed the method using datasets from Bluetooth and Mozilla, where requirement documents and high-level test cases are available, achieving macro-recall measurement of 0.81 and 0.37, respectively. We believe that the method is feasible for practical application in generating high-level test cases without using RAG.",
        "tags": [
            "LLM",
            "RAG"
        ]
    },
    {
        "id": "125",
        "title": "LLM-Guided Evolutionary Program Synthesis for Quasi-Monte Carlo Design",
        "author": [
            "Amir Sadikov"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03650",
        "abstract": "Low-discrepancy point sets and digital sequences underpin quasi-Monte Carlo (QMC) methods for high-dimensional integration. We cast two long-standing QMC design problems as program synthesis and solve them with an LLM-guided evolutionary loop that mutates and selects code under task-specific fitness: (i) constructing finite 2D/3D point sets with low star discrepancy, and (ii) choosing Sobol' direction numbers that minimize randomized QMC error on downstream integrands. Our two-phase procedure combines constructive code proposals with iterative numerical refinement. On finite sets, we rediscover known optima in small 2D cases and set new best-known 2D benchmarks for N >= 40, while matching most known 3D optima up to the proven frontier (N <= 8) and reporting improved 3D benchmarks beyond. On digital sequences, evolving Sobol' parameters yields consistent reductions in randomized quasi-Monte Carlo (rQMC) mean-squared error for several 32-dimensional option-pricing tasks relative to widely used Joe--Kuo parameters, while preserving extensibility to any sample size and compatibility with standard randomizations. Taken together, the results demonstrate that LLM-driven evolutionary program synthesis can automate the discovery of high-quality QMC constructions, recovering classical designs where they are optimal and improving them where finite-N structure matters. Data and code are available at https://github.com/hockeyguy123/openevolve-star-discrepancy.git.",
        "tags": [
            "3D",
            "LLM"
        ]
    },
    {
        "id": "126",
        "title": "Does higher interpretability imply better utility? A Pairwise Analysis on Sparse Autoencoders",
        "author": [
            "Xu Wang",
            "Yan Hu",
            "Benyou Wang",
            "Difan Zou"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03659",
        "abstract": "Sparse Autoencoders (SAEs) are widely used to steer large language models (LLMs), based on the assumption that their interpretable features naturally enable effective model behavior steering. Yet, a fundamental question remains unanswered: does higher interpretability indeed imply better steering utility? To answer this question, we train 90 SAEs across three LLMs (Gemma-2-2B, Qwen-2.5-3B, Gemma-2-9B), spanning five architectures and six sparsity levels, and evaluate their interpretability and steering utility based on SAEBench (https://arxiv.org/abs/2501.12345) and AxBench (https://arxiv.org/abs/2502.23456) respectively, and perform a rank-agreement analysis via Kendall's rank coefficients (tau b). Our analysis reveals only a relatively weak positive association (tau b approx 0.298), indicating that interpretability is an insufficient proxy for steering performance. We conjecture the interpretability utility gap may stem from the selection of SAE features, as not all of them are equally effective for steering. To further find features that truly steer the behavior of LLMs, we propose a novel selection criterion called Delta Token Confidence, which measures how much amplifying a feature changes the next token distribution. We show that our method improves the steering performance of three LLMs by 52.52 percent compared to the current best output score based criterion (https://arxiv.org/abs/2503.34567). Strikingly, after selecting features with high Delta Token Confidence, the correlation between interpretability and utility vanishes (tau b approx 0), and can even become negative. This further highlights the divergence between interpretability and utility for the most effective steering features.",
        "tags": [
            "LLM",
            "Qwen"
        ]
    },
    {
        "id": "127",
        "title": "An Amphibious Untethered Inchworm Soft Robot for Fast Crawling Locomotion",
        "author": [
            "Mohammadjavad Javadi",
            "Charlie Wadds",
            "Robin Chhabra"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03660",
        "abstract": "Untethered soft robots are essential for advancing the real-world deployment of soft robotic systems in diverse and multitasking environments. Inspired by soft-bodied inchworm, we present a fully untethered soft robot with a curved, flexible structure actuated by magnetic forces. The robot has a total mass of 102.63 g and demonstrates multimodal locomotion, achieving a maximum walking speed of 3.74 cm/s and a swimming speed of 0.82 cm/s. A compact and lightweight onboard control circuit enables wireless command transmission, while an integrated camera provides environmental perception. Through structural optimization and system-level integration, the robot successfully performs walking, steering, swimming, and payload transport without reliance on external infrastructure. The robot's dynamic performance and locomotion capabilities are systematically validated through experimental characterization.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "128",
        "title": "Operationalizing Data Minimization for Privacy-Preserving LLM Prompting",
        "author": [
            "Jijie Zhou",
            "Niloofar Mireshghallah",
            "Tianshi Li"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03662",
        "abstract": "The rapid deployment of large language models (LLMs) in consumer applications has led to frequent exchanges of personal information. To obtain useful responses, users often share more than necessary, increasing privacy risks via memorization, context-based personalization, or security breaches. We present a framework to formally define and operationalize data minimization: for a given user prompt and response model, quantifying the least privacy-revealing disclosure that maintains utility, and we propose a priority-queue tree search to locate this optimal point within a privacy-ordered transformation space. We evaluated the framework on four datasets spanning open-ended conversations (ShareGPT, WildChat) and knowledge-intensive tasks with single-ground-truth answers (CaseHold, MedQA), quantifying achievable data minimization with nine LLMs as the response model. Our results demonstrate that larger frontier LLMs can tolerate stronger data minimization while maintaining task quality than smaller open-source models (85.7% redaction for GPT-5 vs. 19.3% for Qwen2.5-0.5B). By comparing with our search-derived benchmarks, we find that LLMs struggle to predict optimal data minimization directly, showing a bias toward abstraction that leads to oversharing. This suggests not just a privacy gap, but a capability gap: models may lack awareness of what information they actually need to solve a task.",
        "tags": [
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "129",
        "title": "UNIDOC-BENCH: A Unified Benchmark for Document-Centric Multimodal RAG",
        "author": [
            "Xiangyu Peng",
            "Cab Qin",
            "Zeyuan Chen",
            "Ran Xu",
            "Caiming Xiong",
            "Chien-Sheng Wu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03663",
        "abstract": "Multimodal retrieval-augmented generation (MM-RAG) is a key approach for applying large language models (LLMs) and agents to real-world knowledge bases, yet current evaluations are fragmented, focusing on either text or images in isolation or on simplified multimodal setups that fail to capture document-centric multimodal use cases. In this paper, we introduce UniDoc-Bench, the first large-scale, realistic benchmark for MM-RAG built from 70k real-world PDF pages across eight domains. Our pipeline extracts and links evidence from text, tables, and figures, then generates 1,600 multimodal QA pairs spanning factual retrieval, comparison, summarization, and logical reasoning queries. To ensure reliability, 20% of QA pairs are validated by multiple annotators and expert adjudication. UniDoc-Bench supports apples-to-apples comparison across four paradigms: (1) text-only, (2) image-only, (3) multimodal text-image fusion, and (4) multimodal joint retrieval -- under a unified protocol with standardized candidate pools, prompts, and evaluation metrics. Our experiments show that multimodal text-image fusion RAG systems consistently outperform both unimodal and jointly multimodal embedding-based retrieval, indicating that neither text nor images alone are sufficient and that current multimodal embeddings remain inadequate. Beyond benchmarking, our analysis reveals when and how visual context complements textual evidence, uncovers systematic failure modes, and offers actionable guidance for developing more robust MM-RAG pipelines.",
        "tags": [
            "LLM",
            "RAG"
        ]
    },
    {
        "id": "130",
        "title": "MonitorVLM:A Vision Language Framework for Safety Violation Detection in Mining Operations",
        "author": [
            "Jiang Wu",
            "Sichao Wu",
            "Yinsong Ma",
            "Guangyuan Yu",
            "Haoyuan Xu",
            "Lifang Zheng",
            "Jingliang Duan"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03666",
        "abstract": "Industrial accidents, particularly in high-risk domains such as surface and underground mining, are frequently caused by unsafe worker behaviors. Traditional manual inspection remains labor-intensive, error-prone, and insufficient for large-scale, dynamic environments, highlighting the urgent need for intelligent and automated safety monitoring. In this paper, we present MonitorVLM, a novel vision--language framework designed to detect safety violations directly from surveillance video streams. MonitorVLM introduces three key innovations: (1) a domain-specific violation dataset comprising 9,000 vision--question--answer (VQA) samples across 40 high-frequency mining regulations, enriched with augmentation and auxiliary detection cues; (2) a clause filter (CF) module that dynamically selects the Top-$K$ most relevant clauses, reducing inference latency by 13.56\\% while maintaining accuracy; and (3) a behavior magnifier (BM) module that enhances worker regions to improve fine-grained action recognition, yielding additional gains of 3.45% in precision and 8.62% in recall. Experimental results demonstrate that MonitorVLM significantly outperforms baseline vision--language models, achieving improvements of 22.01% in precision, 34.22\\% in recall, and 28.37% in F1 score over the 72B unfine-tuned baseline. A lightweight web-based interface further integrates MonitorVLM into practical workflows, enabling automatic violation reporting with video timestamping. This study highlights the potential of multimodal large models to enhance occupational safety monitoring in mining and beyond.",
        "tags": [
            "Detection",
            "VLM"
        ]
    },
    {
        "id": "131",
        "title": "Invisible Saboteurs: Sycophantic LLMs Mislead Novices in Problem-Solving Tasks",
        "author": [
            "Jessica Y. Bo",
            "Majeed Kazemitabaar",
            "Mengqing Deng",
            "Michael Inzlicht",
            "Ashton Anderson"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03667",
        "abstract": "Sycophancy, the tendency of LLM-based chatbots to express excessive enthusiasm, agreement, flattery, and a lack of disagreement, is emerging as a significant risk in human-AI interactions. However, the extent to which this affects human-LLM collaboration in complex problem-solving tasks is not well quantified, especially among novices who are prone to misconceptions. We created two LLM chatbots, one with high sycophancy and one with low sycophancy, and conducted a within-subjects experiment (n=24) in the context of debugging machine learning models to isolate the effect of LLM sycophancy on users' mental models, their workflows, reliance behaviors, and their perceptions of the chatbots. Our findings show that users of the high sycophancy chatbot were less likely to correct their misconceptions and spent more time over-relying on unhelpful LLM responses. Despite these impaired outcomes, a majority of users were unable to detect the presence of excessive sycophancy.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "132",
        "title": "Token Hidden Reward: Steering Exploration-Exploitation in Group Relative Deep Reinforcement Learning",
        "author": [
            "Wenlong Deng",
            "Yi Ren",
            "Yushu Li",
            "Boying Gong",
            "Danica J. Sutherland",
            "Xiaoxiao Li",
            "Christos Thrampoulidis"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03669",
        "abstract": "Reinforcement learning with verifiable rewards has significantly advanced the reasoning capabilities of large language models, yet how to explicitly steer training toward exploration or exploitation remains an open problem. We introduce Token Hidden Reward (THR), a token-level metric that quantifies each token's influence on the likelihood of correct responses under Group Relative Policy Optimization (GRPO). We find that training dynamics are dominated by a small subset of tokens with high absolute THR values. Most interestingly, tokens with positive THR strengthen confidence in correct outputs, thus favoring exploitation, while tokens with negative THR preserve probability mass for alternative outputs, enabling exploration. This insight suggests a natural intervention: a THR-guided reweighting algorithm that modulates GRPO's learning signals to explicitly bias training toward exploitation or exploration. We validate the efficacy of this algorithm on diverse math reasoning benchmarks. By amplifying tokens with positive THR value and weakening negative ones, our algorithm improves greedy-decoding accuracy, favoring exploitation. The reverse strategy yields consistent gains in Pass@K accuracy, favoring exploration. We further demonstrate that our algorithm integrates seamlessly with other RL objectives such as GSPO and generalizes across architectures including Llama. These findings establish THR as a principled and fine-grained mechanism for dynamically controlling exploration and exploitation in RL-tuned LLMs, providing new tools for targeted fine-tuning in reasoning-intensive applications.",
        "tags": [
            "GRPO",
            "LLM",
            "LLaMA",
            "RL"
        ]
    },
    {
        "id": "133",
        "title": "A Novel Cloud-Based Diffusion-Guided Hybrid Model for High-Accuracy Accident Detection in Intelligent Transportation Systems",
        "author": [
            "Siva Sai",
            "Saksham Gupta",
            "Vinay Chamola",
            "Rajkumar Buyya"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03675",
        "abstract": "The integration of Diffusion Models into Intelligent Transportation Systems (ITS) is a substantial improvement in the detection of accidents. We present a novel hybrid model integrating guidance classification with diffusion techniques. By leveraging fine-tuned ExceptionNet architecture outputs as input for our proposed diffusion model and processing image tensors as our conditioning, our approach creates a robust classification framework. Our model consists of multiple conditional modules, which aim to modulate the linear projection of inputs using time embeddings and image covariate embeddings, allowing the network to adapt its behavior dynamically throughout the diffusion process. To address the computationally intensive nature of diffusion models, our implementation is cloud-based, enabling scalable and efficient processing. Our strategy overcomes the shortcomings of conventional classification approaches by leveraging diffusion models inherent capacity to effectively understand complicated data distributions. We investigate important diffusion characteristics, such as timestep schedulers, timestep encoding techniques, timestep count, and architectural design changes, using a thorough ablation study, and have conducted a comprehensive evaluation of the proposed model against the baseline models on a publicly available dataset. The proposed diffusion model performs best in image-based accident detection with an accuracy of 97.32%.",
        "tags": [
            "Detection",
            "Diffusion"
        ]
    },
    {
        "id": "134",
        "title": "Towards Sampling Data Structures for Tensor Products in Turnstile Streams",
        "author": [
            "Zhao Song",
            "Shenghao Xie",
            "Samson Zhou"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03678",
        "abstract": "This paper studies the computational challenges of large-scale attention-based models in artificial intelligence by utilizing importance sampling methods in the streaming setting. Inspired by the classical definition of the $\\ell_2$ sampler and the recent progress of the attention scheme in Large Language Models (LLMs), we propose the definition of the attention sampler. Our approach significantly reduces the computational burden of traditional attention mechanisms. We analyze the effectiveness of the attention sampler from a theoretical perspective, including space and update time. Additionally, our framework exhibits scalability and broad applicability across various model architectures and domains.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "135",
        "title": "Group Policy Gradient",
        "author": [
            "Junhua Chen",
            "Zixi Zhang",
            "Hantao Zhong",
            "Rika Antonova"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03679",
        "abstract": "We introduce Group Policy Gradient (GPG), a family of critic-free policy-gradient estimators for general MDPs. Inspired by the success of GRPO's approach in Reinforcement Learning from Human Feedback (RLHF), GPG replaces a learned value function with a group-based Monte Carlo advantage estimator, removing the memory, compute, and hyperparameter costs of training a critic while preserving PPO's clipped-objective structure. We prove the consistency of the GPG estimator, analyze the bias-variance tradeoffs, and demonstrate empirically that GPG matches or outperforms PPO on standard benchmarks. GPG makes better use of parallel simulations, which, together with its critic-free design, results in more efficient use of computational resources than PPO.",
        "tags": [
            "GRPO",
            "PPO",
            "RL",
            "RLHF"
        ]
    },
    {
        "id": "136",
        "title": "Rainbow Padding: Mitigating Early Termination in Instruction-Tuned Diffusion LLMs",
        "author": [
            "Bumjun Kim",
            "Dongjae Jeon",
            "Dueun Kim",
            "Wonje Jeung",
            "Albert No"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03680",
        "abstract": "Diffusion large language models (dLLMs) have emerged as a promising alternative to autoregressive models, offering flexible generation orders and strong performance on complex reasoning tasks. However, instruction-tuned dLLMs exhibit a critical vulnerability we term \\texttt{<eos>} overflow: as allocated sequence length increases, responses paradoxically become shorter, collapsing into early termination or degenerating into streams of \\texttt{<eos>} tokens. Although noticed in practice, this issue has not been systematically analyzed. We trace its root cause to the dual role of \\texttt{<eos>} as both termination and padding, which concentrates probability mass on \\texttt{<eos>} at later positions and propagates backward to trigger early termination. To address this, we introduce Rainbow Padding, a simple remedy that replaces repeated \\texttt{<eos>} placeholders with a repeating cycle of distinct padding tokens, distributing probability mass and breaking \\texttt{<eos>} dominance. Experiments show that Rainbow Padding substantially improves length robustness and output quality, with as few as seven padding tokens sufficient to prevent early termination. Moreover, the method integrates efficiently into existing instruction-tuned models: LoRA fine-tuning for a single epoch on minimal data yields significant improvements, making this solution highly practical. The code is publicly available at https://github.com/quasar529/rainbow-padding.",
        "tags": [
            "Diffusion",
            "LLM",
            "LoRA"
        ]
    },
    {
        "id": "137",
        "title": "Fine-Tuning Large Language Models with QLoRA for Offensive Language Detection in Roman Urdu-English Code-Mixed Text",
        "author": [
            "Nisar Hussain",
            "Amna Qasim",
            "Gull Mehak",
            "Muhammad Zain",
            "Momina Hafeez",
            "Grigori Sidorov"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03683",
        "abstract": "The use of derogatory terms in languages that employ code mixing, such as Roman Urdu, presents challenges for Natural Language Processing systems due to unstated grammar, inconsistent spelling, and a scarcity of labeled data. In this work, we propose a QLoRA based fine tuning framework to improve offensive language detection in Roman Urdu-English text. We translated the Roman Urdu-English code mixed dataset into English using Google Translate to leverage English LLMs, while acknowledging that this translation reduces direct engagement with code mixing features. Our focus is on classification performance using English translated low resource inputs. We fine tuned several transformers and large language models, including Meta LLaMA 3 8B, Mistral 7B v0.1, LLaMA 2 7B, ModernBERT, and RoBERTa, with QLoRA for memory efficient adaptation. Models were trained and evaluated on a manually annotated Roman Urdu dataset for offensive vs non offensive content. Of all tested models, the highest F1 score of 91.45 was attained by Meta LLaMA 3 8B, followed by Mistral 7B at 89.66, surpassing traditional transformer baselines. These results demonstrate the efficacy of QLoRA in fine tuning high performing models for low resource environments such as code mixed offensive language detection, and confirm the potential of LLMs for this task. This work advances a scalable approach to Roman Urdu moderation and paves the way for future multilingual offensive detection systems based on LLMs.",
        "tags": [
            "Detection",
            "LLM",
            "LLaMA",
            "Transformer"
        ]
    },
    {
        "id": "138",
        "title": "Optimal Energy Management in Indoor Farming Using Lighting Flexibility and Intelligent Model Predictive Control",
        "author": [
            "Mohammadjavad Abbaspour",
            "Mukund R. Shukla",
            "Praveen K. Saxena",
            "Shivam Saxena"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03686",
        "abstract": "Indoor farming enables year-round food production but its reliance on artificial lighting significantly increases energy consumption, peak load charges, and energy costs for growers. Recent studies indicate that plants are able to tolerate interruptions in light, enabling the design of 24-hour lighting schedules (or \"recipes\") with strategic light modulation in alignment with day-ahead pricing. Thus, we propose an optimal lighting control strategy for indoor farming that modulates light intensity and photoperiod to reduce energy costs. The control strategy is implemented within a model predictive control framework and augmented with transformer-based neural networks to forecast 24-hour ahead solar radiation and electricity prices to improve energy cost reduction. The control strategy is informed by real-world experimentation on lettuce crops to discover minimum light exposure and appropriate dark-light intervals, which are mathematically formulated as constraints to maintain plant health. Simulations for a one-hectare greenhouse, based on real electricity market data from Ontario, demonstrate an annual cost reduction of $318,400 (20.9%), a peak load decrease of 1.6 MW (33.32%), and total energy savings of 1890 MWh (20.2%) against a baseline recipe. These findings highlight the potential of intelligent lighting control to improve the sustainability and economic feasibility of indoor farming.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "139",
        "title": "REG: A Regularization Optimizer for Robust Training Dynamics",
        "author": [
            "Zehua Liu",
            "Han Wu",
            "Xiaojin Fu",
            "Shuqi Liu",
            "Xiongwei Han",
            "Tao Zhong",
            "Mingxuan Yuan"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03691",
        "abstract": "Optimizers are crucial for the efficient training of Large Language Models (LLMs). While AdamW is the de facto standard, recent structure-aware optimizers like Muon have emerged, which regularize gradient updates by operating on entire weight matrices. The Muon optimizer balances the gradient updates along all the directions. However, Muon's reliance on the matrix sign function can lead to training instability, exhibits incompatibility when fine-tuning models pre-trained with AdamW. To address these limitations, we propose \\textbf{REG}, a novel optimizer that replaces Muon's aggressive matrix sign operator with the Row-and-Column-Scaling (RACS) operator. Theoretically grounded in balancing a matrix, the RACS operator regularizes the update steps in a less drastic manner, making it simpler to implement and more compatible with established training dynamics. Through extensive empirical experiments on LLM training, we demonstrate that our REG optimizer not only achieves superior performance and stability over AdamW, but also maintains consistency with the AdamW training paradigm. This consistency is particularly evident during the fine-tuning stage, where REG optimizer avoids the performance degradation observed with Muon.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "140",
        "title": "Mind the Goal: Data-Efficient Goal-Oriented Evaluation of Conversational Agents and Chatbots using Teacher Models",
        "author": [
            "Deepak Babu Piskala",
            "Sharlene Chen",
            "Udita Patel",
            "Parul Kalra",
            "Rafael Castrillo"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03696",
        "abstract": "Evaluating the quality of multi-turn chatbot interactions remains challenging, as most existing methods assess interactions at the turn level without addressing whether a user's overarching goal was fulfilled. A ``goal'' here refers to an information need or task, such as asking for policy information or applying for leave. We propose a comprehensive framework for goal-oriented evaluation of multi-agent systems (MAS), introducing the \\textbf{Goal Success Rate (GSR)} to measure the percentage of fulfilled goals, and a \\textbf{Root Cause of Failure (RCOF)} taxonomy to identify reasons for failure in multi-agent chatbots. Our method segments conversations by user goals and evaluates success using all relevant turns. We present a model-based evaluation system combining teacher LLMs, where domain experts define goals, set quality standards serving as a guidance for the LLMs. The LLMs use ``thinking tokens'' to produce interpretable rationales, enabling \\textit{explainable}, \\textit{data-efficient} evaluations. In an enterprise setting, we apply our framework to evaluate AIDA, a zero-to-one employee conversational agent system built as a ground-up multi-agent conversational agent, and observe GSR improvement from 63\\% to 79\\% over six months since its inception. Our framework is generic and offers actionable insights through a detailed defect taxonomy based on analysis of failure points in multi-agent chatbots, diagnosing overall success, identifying key failure modes, and informing system improvements.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "141",
        "title": "H-DDx: A Hierarchical Evaluation Framework for Differential Diagnosis",
        "author": [
            "Seungseop Lim",
            "Gibaeg Kim",
            "Hyunkyung Lee",
            "Wooseok Han",
            "Jean Seo",
            "Jaehyo Yoo",
            "Eunho Yang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03700",
        "abstract": "An accurate differential diagnosis (DDx) is essential for patient care, shaping therapeutic decisions and influencing outcomes. Recently, Large Language Models (LLMs) have emerged as promising tools to support this process by generating a DDx list from patient narratives. However, existing evaluations of LLMs in this domain primarily rely on flat metrics, such as Top-k accuracy, which fail to distinguish between clinically relevant near-misses and diagnostically distant errors. To mitigate this limitation, we introduce H-DDx, a hierarchical evaluation framework that better reflects clinical relevance. H-DDx leverages a retrieval and reranking pipeline to map free-text diagnoses to ICD-10 codes and applies a hierarchical metric that credits predictions closely related to the ground-truth diagnosis. In benchmarking 22 leading models, we show that conventional flat metrics underestimate performance by overlooking clinically meaningful outputs, with our results highlighting the strengths of domain-specialized open-source models. Furthermore, our framework enhances interpretability by revealing hierarchical error patterns, demonstrating that LLMs often correctly identify the broader clinical context even when the precise diagnosis is missed.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "142",
        "title": "EmbodiSwap for Zero-Shot Robot Imitation Learning",
        "author": [
            "Eadom Dessalene",
            "Pavan Mantripragada",
            "Michael Maynord",
            "Yiannis Aloimonos"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03706",
        "abstract": "We introduce EmbodiSwap - a method for producing photorealistic synthetic robot overlays over human video. We employ EmbodiSwap for zero-shot imitation learning, bridging the embodiment gap between in-the-wild ego-centric human video and a target robot embodiment. We train a closed-loop robot manipulation policy over the data produced by EmbodiSwap. We make novel use of V-JEPA as a visual backbone, repurposing V-JEPA from the domain of video understanding to imitation learning over synthetic robot videos. Adoption of V-JEPA outperforms alternative vision backbones more conventionally used within robotics. In real-world tests, our zero-shot trained V-JEPA model achieves an $82\\%$ success rate, outperforming a few-shot trained $\\pi_0$ network as well as $\\pi_0$ trained over data produced by EmbodiSwap. We release (i) code for generating the synthetic robot overlays which takes as input human videos and an arbitrary robot URDF and generates a robot dataset, (ii) the robot dataset we synthesize over EPIC-Kitchens, HOI4D and Ego4D, and (iii) model checkpoints and inference code, to facilitate reproducible research and broader adoption.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "143",
        "title": "A Position- and Energy-Aware Routing Strategy for Subterranean LoRa Mesh Networks",
        "author": [
            "Nalith Udugampola",
            "Xiaoyu Ai",
            "Binghao Li",
            "Henry Gong",
            "Aruna Seneviratne"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03714",
        "abstract": "Although LoRa is predominantly employed with the single-hop LoRaWAN protocol, recent advancements have extended its application to multi-hop mesh topologies. Designing efficient routing for LoRa mesh networks remains challenging due to LoRa's low data rate and ALOHA-based MAC. Prior work often adapts conventional protocols for low-traffic, aboveground networks with strict duty cycle constraints or uses flooding-based methods in subterranean environments. However, these approaches inefficiently utilize the limited available network bandwidth in these low-data-rate networks due to excessive control overhead, acknowledgments, and redundant retransmissions. In this paper, we introduce a novel position- and energy-aware routing strategy tailored for subterranean LoRa mesh networks aimed at enhancing maximum throughput and power efficiency while also maintaining high packet delivery ratios. Our mechanism begins with a lightweight position learning phase, during which LoRa repeaters ascertain their relative positions and gather routing information. Afterwards, the network becomes fully operational with adaptive routing, leveraging standby LoRa repeaters for recovery from packet collisions and losses, and energy-aware route switching to balance battery depletion across repeaters. The simulation results on a representative subterranean network demonstrate a 185% increase in maximum throughput and a 75% reduction in energy consumption compared to a previously optimized flooding-based approach for high traffic.",
        "tags": [
            "LoRA"
        ]
    },
    {
        "id": "144",
        "title": "A Survey of LLM-Based Applications in Programming Education: Balancing Automation and Human Oversight",
        "author": [
            "Griffin Pitts",
            "Anurata Prabha Hridi",
            "Arun-Balajiee Lekshmi-Narayanan"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03719",
        "abstract": "Novice programmers benefit from timely, personalized support that addresses individual learning gaps, yet the availability of instructors and teaching assistants is inherently limited. Large language models (LLMs) present opportunities to scale such support, though their effectiveness depends on how well technical capabilities are aligned with pedagogical goals. This survey synthesizes recent work on LLM applications in programming education across three focal areas: formative code feedback, assessment, and knowledge modeling. We identify recurring design patterns in how these tools are applied and find that interventions are most effective when educator expertise complements model output through human-in-the-loop oversight, scaffolding, and evaluation. Fully automated approaches are often constrained in capturing the pedagogical nuances of programming education, although human-in-the-loop designs and course specific adaptation offer promising directions for future improvement. Future research should focus on improving transparency, strengthening alignment with pedagogy, and developing systems that flexibly adapt to the needs of varied learning contexts.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "145",
        "title": "Person-Centric Annotations of LAION-400M: Auditing Bias and Its Transfer to Models",
        "author": [
            "Leander Girrbach",
            "Stephan Alaniz",
            "Genevieve Smith",
            "Trevor Darrell",
            "Zeynep Akata"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03721",
        "abstract": "Vision-language models trained on large-scale multimodal datasets show strong demographic biases, but the role of training data in producing these biases remains unclear. A major barrier has been the lack of demographic annotations in web-scale datasets such as LAION-400M. We address this gap by creating person-centric annotations for the full dataset, including over 276 million bounding boxes, perceived gender and race/ethnicity labels, and automatically generated captions. These annotations are produced through validated automatic labeling pipelines combining object detection, multimodal captioning, and finetuned classifiers. Using them, we uncover demographic imbalances and harmful associations, such as the disproportionate linking of men and individuals perceived as Black or Middle Eastern with crime-related and negative content. We also show that 60-70% of gender bias in CLIP and Stable Diffusion can be linearly explained by direct co-occurrences in the data. Our resources establish the first large-scale empirical link between dataset composition and downstream model bias.",
        "tags": [
            "CLIP",
            "Detection",
            "Diffusion",
            "VLM"
        ]
    },
    {
        "id": "146",
        "title": "Balancing Interpretability and Performance in Reinforcement Learning: An Adaptive Spectral Based Linear Approach",
        "author": [
            "Qianxin Yi",
            "Shao-Bo Lin",
            "Jun Fan",
            "Yao Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03722",
        "abstract": "Reinforcement learning (RL) has been widely applied to sequential decision making, where interpretability and performance are both critical for practical adoption. Current approaches typically focus on performance and rely on post hoc explanations to account for interpretability. Different from these approaches, we focus on designing an interpretability-oriented yet performance-enhanced RL approach. Specifically, we propose a spectral based linear RL method that extends the ridge regression-based approach through a spectral filter function. The proposed method clarifies the role of regularization in controlling estimation error and further enables the design of an adaptive regularization parameter selection strategy guided by the bias-variance trade-off principle. Theoretical analysis establishes near-optimal bounds for both parameter estimation and generalization error. Extensive experiments on simulated environments and real-world datasets from Kuaishou and Taobao demonstrate that our method either outperforms or matches existing baselines in decision quality. We also conduct interpretability analyses to illustrate how the learned policies make decisions, thereby enhancing user trust. These results highlight the potential of our approach to bridge the gap between RL theory and practical decision making, providing interpretability, accuracy, and adaptability in management contexts.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "147",
        "title": "Optimizing Fine-Tuning through Advanced Initialization Strategies for Low-Rank Adaptation",
        "author": [
            "Yongfu Xue"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03731",
        "abstract": "The rapid development of parameter-efficient fine-tuning methods has noticeably improved the efficiency of adapting large language models. Among these, LoRA has gained widespread popularity due to its strong balance of effectiveness and parameter efficiency. However, LoRA relies on initializing two low-rank matrices whose product is zero, which limits its ability to effectively activate and leverage the original model weights-creating a potential bottleneck for optimal performance. To address this limitation, we propose \\textbf{IniLoRA}, a novel initialization strategy that initializes the low-rank matrices to closely approximate the original model weights. Experimental results indicate that IniLoRA achieves better performance than LoRA across a range of models and tasks. Additionally, we introduce two variants, IniLoRA-$\\alpha$ and IniLoRA-$\\beta$, both leveraging distinct initialization methods to enhance performance further.",
        "tags": [
            "LLM",
            "LoRA"
        ]
    },
    {
        "id": "148",
        "title": "APIDA-Chat: Structured Synthesis of API Search Dialogues to Bootstrap Conversational Agents",
        "author": [
            "Zachary Eberhart",
            "Collin McMillan"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03743",
        "abstract": "Large-language-model assistants are suitable for explaining popular APIs, yet they falter on niche or proprietary libraries because the multi-turn dialogue data needed for fine-tuning are scarce. We present APIDA-Chat, an open-source pipeline that converts symbolic dialogue-act \"scripts\" into realistic, domain-grounded API Search conversations using a lightweight model for inexpensive training data generation. Phase I pairs a legacy dialogue planner with a high-capability teacher LLM (o4-mini) to synthesize a \"gold set\" of realized dialogues; then, a smaller Llama 3.2 3B student model is fine-tuned on this corpus. Phase II drops the teacher and reuses the same planner with the fine-tuned model, allowing rapid, low-cost synthesis of new dialogues without exposing source code to external services. The fine-tuned student improves BLEU from 0.38 to 0.50 and BERTScore from 0.88 to 0.91 versus the base model while running entirely on a single consumer GPU. All components are modular and publicly released to serve as a conservative baseline for future work. APIDA-Chat is open-sourced at https://github.com/Zeberhart/apida-chat and a video demo is available at https://youtu.be/YqmZBHyGbPs .",
        "tags": [
            "LLM",
            "LLaMA"
        ]
    },
    {
        "id": "149",
        "title": "HydroFusion-LMF: Semi-Supervised Multi-Network Fusion with Large-Model Adaptation for Long-Term Daily Runoff Forecasting",
        "author": [
            "Qianfei Fan",
            "Jiayu Wei",
            "Peijun Zhu",
            "Wensheng Ye",
            "Meie Fang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03744",
        "abstract": "Accurate decade-scale daily runoff forecasting in small watersheds is difficult because signals blend drifting trends, multi-scale seasonal cycles, regime shifts, and sparse extremes. Prior deep models (DLinear, TimesNet, PatchTST, TiDE, Nonstationary Transformer, LSTNet, LSTM) usually target single facets and under-utilize unlabeled spans, limiting regime adaptivity. We propose HydroFusion-LMF, a unified framework that (i) performs a learnable trend-seasonal-residual decomposition to reduce non-stationarity, (ii) routes residuals through a compact heterogeneous expert set (linear refinement, frequency kernel, patch Transformer, recurrent memory, dynamically normalized attention), (iii) fuses expert outputs via a hydrologic context-aware gate conditioned on day-of-year phase, antecedent precipitation, local variance, flood indicators, and static basin attributes, and (iv) augments supervision with a semi-supervised multi-task objective (composite MSE/MAE + extreme emphasis + NSE/KGE, masked reconstruction, multi-scale contrastive alignment, augmentation consistency, variance-filtered pseudo-labeling). Optional adapter / LoRA layers inject a frozen foundation time-series encoder efficiently. On a ~10-year daily dataset HydroFusion-LMF attains MSE 1.0128 / MAE 0.5818, improving the strongest baseline (DLinear) by 10.2% / 10.3% and the mean baseline by 24.6% / 17.1%. We observe simultaneous MSE and MAE reductions relative to baselines. The framework balances interpretability (explicit components, sparse gating) with performance, advancing label-efficient hydrologic forecasting under non-stationarity.",
        "tags": [
            "LoRA",
            "Transformer"
        ]
    },
    {
        "id": "150",
        "title": "Neural Low-Discrepancy Sequences",
        "author": [
            "Michael Etienne Van Huffel",
            "Nathan Kirk",
            "Makram Chahine",
            "Daniela Rus",
            "T. Konstantin Rusch"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03745",
        "abstract": "Low-discrepancy points are designed to efficiently fill the space in a uniform manner. This uniformity is highly advantageous in many problems in science and engineering, including in numerical integration, computer vision, machine perception, computer graphics, machine learning, and simulation. Whereas most previous low-discrepancy constructions rely on abstract algebra and number theory, Message-Passing Monte Carlo (MPMC) was recently introduced to exploit machine learning methods for generating point sets with lower discrepancy than previously possible. However, MPMC is limited to generating point sets and cannot be extended to low-discrepancy sequences (LDS), i.e., sequences of points in which every prefix has low discrepancy, a property essential for many applications. To address this limitation, we introduce Neural Low-Discrepancy Sequences ($NeuroLDS$), the first machine learning-based framework for generating LDS. Drawing inspiration from classical LDS, we train a neural network to map indices to points such that the resulting sequences exhibit minimal discrepancy across all prefixes. To this end, we deploy a two-stage learning process: supervised approximation of classical constructions followed by unsupervised fine-tuning to minimize prefix discrepancies. We demonstrate that $NeuroLDS$ outperforms all previous LDS constructions by a significant margin with respect to discrepancy measures. Moreover, we demonstrate the effectiveness of $NeuroLDS$ across diverse applications, including numerical integration, robot motion planning, and scientific machine learning. These results highlight the promise and broad significance of Neural Low-Discrepancy Sequences. Our code can be found at https://github.com/camail-official/neuro-lds.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "151",
        "title": "LoRA Patching: Exposing the Fragility of Proactive Defenses against Deepfakes",
        "author": [
            "Zuomin Qu",
            "Yimao Guo",
            "Qianyue Hu",
            "Wei Lu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03747",
        "abstract": "Deepfakes pose significant societal risks, motivating the development of proactive defenses that embed adversarial perturbations in facial images to prevent manipulation. However, in this paper, we show that these preemptive defenses often lack robustness and reliability. We propose a novel approach, Low-Rank Adaptation (LoRA) patching, which injects a plug-and-play LoRA patch into Deepfake generators to bypass state-of-the-art defenses. A learnable gating mechanism adaptively controls the effect of the LoRA patch and prevents gradient explosions during fine-tuning. We also introduce a Multi-Modal Feature Alignment (MMFA) loss, encouraging the features of adversarial outputs to align with those of the desired outputs at the semantic level. Beyond bypassing, we present defensive LoRA patching, embedding visible warnings in the outputs as a complementary solution to mitigate this newly identified security vulnerability. With only 1,000 facial examples and a single epoch of fine-tuning, LoRA patching successfully defeats multiple proactive defenses. These results reveal a critical weakness in current paradigms and underscore the need for more robust Deepfake defense strategies. Our code is available at https://github.com/ZOMIN28/LoRA-Patching.",
        "tags": [
            "LoRA"
        ]
    },
    {
        "id": "152",
        "title": "TreePrompt: Leveraging Hierarchical Few-Shot Example Selection for Improved English-Persian and English-German Translation",
        "author": [
            "Ramtin Kakavand",
            "Ebrahim Ansari"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03748",
        "abstract": "Large Language Models (LLMs) have consistently demonstrated strong performance in machine translation, especially when guided by high-quality prompts. Few-shot prompting is an effective technique to improve translation quality; however, most existing example selection methods focus solely on query-to-example similarity and do not account for the quality of the examples. In this work, we propose TreePrompt, a novel example selection approach that learns LLM preferences to identify high-quality, contextually relevant examples within a tree-structured framework. To further explore the balance between similarity and quality, we combine TreePrompt with K-Nearest Neighbors (K-NN) and Adaptive Few-Shot Prompting (AFSP). Evaluations on two language pairs - English-Persian (MIZAN) and English-German (WMT19) - show that integrating TreePrompt with AFSP or Random selection leads to improved translation performance.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "153",
        "title": "EvoEngineer: Mastering Automated CUDA Kernel Code Evolution with Large Language Models",
        "author": [
            "Ping Guo",
            "Chenyu Zhu",
            "Siyuan Chen",
            "Fei Liu",
            "Xi Lin",
            "Zhichao Lu",
            "Qingfu Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03760",
        "abstract": "CUDA kernel optimization has become a critical bottleneck for AI performance, as deep learning training and inference efficiency directly depends on highly optimized GPU kernels.\nDespite the promise of Large Language Models (LLMs) for automating kernel optimization, this field suffers from a fragmented ecosystem of isolated and incomparable approaches with unclear problem formulations.\nFurthermore, general-purpose LLM code evolution methods cannot meet strict correctness requirements of CUDA kernel optimization.\nWe address these fundamental challenges by first formalizing CUDA kernel optimization as a code optimization task with a clear objective, constraints, and evaluation metrics.\nWe then establish the first systematic LLM-based code evolution framework, EvoEngineer, that provides guidance for designing and adapting optimization strategies to achieve a balance between performance and correctness.\nFinally, we implement a kernel optimization system based on this framework and conduct extensive experiments on 91 real-world CUDA kernels.\nOur results demonstrate that EvoEngineer achieves a principled balance between performance and correctness, with the highest averaged median speedup of \\textbf{2.72}$\\times$ over baseline CUDA kernels and a code validity rate of \\textbf{69.8}\\%, outperforming existing methods on both dimensions.\nOur method achieves a maximum speedup of \\textbf{36.75}$\\times$ among all operations over PyTorch kernels and delivers the highest speedup on \\textbf{28} (\\textbf{56.0\\%}) of 50 operations that achieve over \\textbf{2$\\times$} acceleration.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "154",
        "title": "You Have Been LaTeXpOsEd: A Systematic Analysis of Information Leakage in Preprint Archives Using Large Language Models",
        "author": [
            "Richard A. Dubniczky",
            "Bertalan Borsos",
            "Tihanyi Norbert"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03761",
        "abstract": "The widespread use of preprint repositories such as arXiv has accelerated the communication of scientific results but also introduced overlooked security risks. Beyond PDFs, these platforms provide unrestricted access to original source materials, including LaTeX sources, auxiliary code, figures, and embedded comments. In the absence of sanitization, submissions may disclose sensitive information that adversaries can harvest using open-source intelligence. In this work, we present the first large-scale security audit of preprint archives, analyzing more than 1.2 TB of source data from 100,000 arXiv submissions. We introduce LaTeXpOsEd, a four-stage framework that integrates pattern matching, logical filtering, traditional harvesting techniques, and large language models (LLMs) to uncover hidden disclosures within non-referenced files and LaTeX comments. To evaluate LLMs' secret-detection capabilities, we introduce LLMSec-DB, a benchmark on which we tested 25 state-of-the-art models. Our analysis uncovered thousands of PII leaks, GPS-tagged EXIF files, publicly available Google Drive and Dropbox folders, editable private SharePoint links, exposed GitHub and Google credentials, and cloud API keys. We also uncovered confidential author communications, internal disagreements, and conference submission credentials, exposing information that poses serious reputational risks to both researchers and institutions. We urge the research community and repository operators to take immediate action to close these hidden security gaps. To support open science, we release all scripts and methods from this study but withhold sensitive findings that could be misused, in line with ethical principles. The source code and related material are available at the project website https://github.com/LaTeXpOsEd",
        "tags": [
            "Detection",
            "LLM"
        ]
    },
    {
        "id": "155",
        "title": "Prompt Balance Matters: Understanding How Imbalanced Few-Shot Learning Affects Multilingual Sense Disambiguation in LLMs",
        "author": [
            "Deshan Sumanathilaka",
            "Nicholas Micallef",
            "Julian Hough"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03762",
        "abstract": "Recent advances in Large Language Models (LLMs) have significantly reshaped the landscape of Natural Language Processing (NLP). Among the various prompting techniques, few-shot prompting has gained considerable attention for its practicality and effectiveness. This study investigates how few-shot prompting strategies impact the Word Sense Disambiguation (WSD) task, particularly focusing on the biases introduced by imbalanced sample distributions. We use the GLOSSGPT prompting method, an advanced approach for English WSD, to test its effectiveness across five languages: English, German, Spanish, French, and Italian. Our results show that imbalanced few-shot examples can cause incorrect sense predictions in multilingual languages, but this issue does not appear in English. To assess model behavior, we evaluate both the GPT-4o and LLaMA-3.1-70B models and the results highlight the sensitivity of multilingual WSD to sample distribution in few-shot settings, emphasizing the need for balanced and representative prompting strategies.",
        "tags": [
            "GPT",
            "LLM",
            "LLaMA"
        ]
    },
    {
        "id": "156",
        "title": "Adaptively Sampling-Reusing-Mixing Decomposed Gradients to Speed Up Sharpness Aware Minimization",
        "author": [
            "Jiaxin Deng",
            "Junbiao Pang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03763",
        "abstract": "Sharpness-Aware Minimization (SAM) improves model generalization but doubles the computational cost of Stochastic Gradient Descent (SGD) by requiring twice the gradient calculations per optimization step. To mitigate this, we propose Adaptively sampling-Reusing-mixing decomposed gradients to significantly accelerate SAM (ARSAM). Concretely, we firstly discover that SAM's gradient can be decomposed into the SGD gradient and the Projection of the Second-order gradient onto the First-order gradient (PSF). Furthermore, we observe that the SGD gradient and PSF dynamically evolve during training, emphasizing the growing role of the PSF to achieve a flat minima. Therefore, ARSAM is proposed to the reused PSF and the timely updated PSF still maintain the model's generalization ability. Extensive experiments show that ARSAM achieves state-of-the-art accuracies comparable to SAM across diverse network architectures. On CIFAR-10/100, ARSAM is comparable to SAM while providing a speedup of about 40\\%. Moreover, ARSAM accelerates optimization for the various challenge tasks (\\textit{e.g.}, human pose estimation, and model quantization) without sacrificing performance, demonstrating its broad practicality.% The code is publicly accessible at: https://github.com/ajiaaa/ARSAM.",
        "tags": [
            "Pose Estimation",
            "SAM"
        ]
    },
    {
        "id": "157",
        "title": "Model-Based Adaptive Precision Control for Tabletop Planar Pushing Under Uncertain Dynamics",
        "author": [
            "Aydin Ahmadi",
            "Baris Akgun"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03768",
        "abstract": "Data-driven planar pushing methods have recently gained attention as they reduce manual engineering effort and improve generalization compared to analytical approaches. However, most prior work targets narrow capabilities (e.g., side switching, precision, or single-task training), limiting broader applicability. We present a model-based framework for non-prehensile tabletop pushing that uses a single learned model to address multiple tasks without retraining. Our approach employs a recurrent GRU-based architecture with additional non-linear layers to capture object-environment dynamics while ensuring stability. A tailored state-action representation enables the model to generalize across uncertain dynamics, variable push lengths, and diverse tasks. For control, we integrate the learned dynamics with a sampling-based Model Predictive Path Integral (MPPI) controller, which generates adaptive, task-oriented actions. This framework supports side switching, variable-length pushes, and objectives such as precise positioning, trajectory following, and obstacle avoidance. Training is performed in simulation with domain randomization to support sim-to-real transfer. We first evaluate the architecture through ablation studies, showing improved prediction accuracy and stable rollouts. We then validate the full system in simulation and real-world experiments using a Franka Panda robot with markerless tracking. Results demonstrate high success rates in precise positioning under strict thresholds and strong performance in trajectory tracking and obstacle avoidance. Moreover, multiple tasks are solved simply by changing the controller's objective function, without retraining. While our current focus is on a single object type, we extend the framework by training on wider push lengths and designing a balanced controller that reduces the number of steps for longer-horizon goals.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "158",
        "title": "OptAgent: Optimizing Query Rewriting for E-commerce via Multi-Agent Simulation",
        "author": [
            "Divij Handa",
            "David Blincoe",
            "Orson Adams",
            "Yinlin Fu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03771",
        "abstract": "Deploying capable and user-aligned LLM-based systems necessitates reliable evaluation. While LLMs excel in verifiable tasks like coding and mathematics, where gold-standard solutions are available, adoption remains challenging for subjective tasks that lack a single correct answer. E-commerce Query Rewriting (QR) is one such problem where determining whether a rewritten query properly captures the user intent is extremely difficult to figure out algorithmically. In this work, we introduce OptAgent, a novel framework that combines multi-agent simulations with genetic algorithms to verify and optimize queries for QR. Instead of relying on a static reward model or a single LLM judge, our approach uses multiple LLM-based agents, each acting as a simulated shopping customer, as a dynamic reward signal. The average of these agent-derived scores serves as an effective fitness function for an evolutionary algorithm that iteratively refines the user's initial query. We evaluate OptAgent on a dataset of 1000 real-world e-commerce queries in five different categories, and we observe an average improvement of 21.98% over the original user query and 3.36% over a Best-of-N LLM rewriting baseline.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "159",
        "title": "Trajectory prediction for heterogeneous agents: A performance analysis on small and imbalanced datasets",
        "author": [
            "Tiago Rodrigues de Almeida",
            "Yufei Zhu",
            "Andrey Rudenko",
            "Tomasz P. Kucner",
            "Johannes A. Stork",
            "Martin Magnusson",
            "Achim J. Lilienthal"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03776",
        "abstract": "Robots and other intelligent systems navigating in complex dynamic environments should predict future actions and intentions of surrounding agents to reach their goals efficiently and avoid collisions. The dynamics of those agents strongly depends on their tasks, roles, or observable labels. Class-conditioned motion prediction is thus an appealing way to reduce forecast uncertainty and get more accurate predictions for heterogeneous agents. However, this is hardly explored in the prior art, especially for mobile robots and in limited data applications. In this paper, we analyse different class-conditioned trajectory prediction methods on two datasets. We propose a set of conditional pattern-based and efficient deep learning-based baselines, and evaluate their performance on robotics and outdoors datasets (THÃR-MAGNI and Stanford Drone Dataset). Our experiments show that all methods improve accuracy in most of the settings when considering class labels. More importantly, we observe that there are significant differences when learning from imbalanced datasets, or in new environments where sufficient data is not available. In particular, we find that deep learning methods perform better on balanced datasets, but in applications with limited data, e.g., cold start of a robot in a new environment, or imbalanced classes, pattern-based methods may be preferable.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "160",
        "title": "GuidedSampling: Steering LLMs Towards Diverse Candidate Solutions at Inference-Time",
        "author": [
            "Divij Handa",
            "Mihir Parmar",
            "Aswin RRV",
            "Md Nayem Uddin",
            "Hamid Palangi",
            "Chitta Baral"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03777",
        "abstract": "Repeated Sampling (RS) is a simple inference-time algorithm that has been shown to improve model performance on complex tasks. Although it is an effective way of scaling inference time, it often struggles to generate diverse solution candidates, frequently relying on the same underlying approach to solve the problem and thus producing redundant samples. To address this limitation, we propose a new inference algorithm, GuidedSampling, which decouples the exploration and generation phases during inference, increasing diversity of generated candidate solutions. The exploration phase identifies multiple concepts that can be utilized to solve the problem, while the generation phase applies a specific concept to provide final solution candidates. We first define the theoretical bounds of GuidedSampling and then empirically demonstrate that it improves the performance of base model at pass@50 by on an average ~21.6% across various benchmarks compared to RS. Furthermore, models trained on trajectories of GuidedSampling exhibit substantial performance improvements at pass@5 by on an average ~9.7%, compared to models trained on traditional RS. Additionally, models trained with GuidedSampling increases the average number of concepts per instance (1.67 -> 3.03), yielding a diverse set of candidates than traditional RS.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "161",
        "title": "A Variational Method for Conformable Fractional Equations Using Rank-One Updates",
        "author": [
            "Maatank Parashar",
            "Tejas Dhulipalla"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03778",
        "abstract": "We make a complete variational treatment of rank-one Proper Generalised Decomposition for separable fractional partial differential equations with conformable derivatives. The setting is Hilbertian, the energy is induced by a symmetric coercive bilinear form, and the residual is placed in the dual space. A greedy rank-one update is obtained by maximizing an energy Rayleigh quotient over the rank-one manifold, followed by an exact line search. An exact one step energy decrease identity is proved, together with geometric decay of the energy error under a weak greedy condition that measures how well the search captures the Riesz representer of the residual. The alternating least squares realization is analyzed at the level of operators, including well posedness of the alternating subproblems, a characterization of stationary points, and monotonicity of the Rayleigh quotient along the inner iteration. Discretizations based on weighted finite elements and on GrÃ¼nwald type schemes are described in detail, including assembly, boundary conditions, complexity, and memory. Two model problems, a stationary fractional Poisson problem and a space time fractional diffusion problem, are treated from the continuous level down to matrices.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "162",
        "title": "Rezwan: Leveraging Large Language Models for Comprehensive Hadith Text Processing: A 1.2M Corpus Development",
        "author": [
            "Majid Asgari-Bidhendi",
            "Muhammad Amin Ghaseminia",
            "Alireza Shahbazi",
            "Sayyed Ali Hossayni",
            "Najmeh Torabian",
            "Behrouz Minaei-Bidgoli"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03781",
        "abstract": "This paper presents the development of Rezwan, a large-scale AI-assisted Hadith corpus comprising over 1.2M narrations, extracted and structured through a fully automated pipeline. Building on digital repositories such as Maktabat Ahl al-Bayt, the pipeline employs Large Language Models (LLMs) for segmentation, chain--text separation, validation, and multi-layer enrichment. Each narration is enhanced with machine translation into twelve languages, intelligent diacritization, abstractive summarization, thematic tagging, and cross-text semantic analysis. This multi-step process transforms raw text into a richly annotated research-ready infrastructure for digital humanities and Islamic studies. A rigorous evaluation was conducted on 1,213 randomly sampled narrations, assessed by six domain experts. Results show near-human accuracy in structured tasks such as chain--text separation (9.33/10) and summarization (9.33/10), while highlighting ongoing challenges in diacritization and semantic similarity detection. Comparative analysis against the manually curated Noor Corpus demonstrates the superiority of Najm in both scale and quality, with a mean overall score of 8.46/10 versus 3.66/10. Furthermore, cost analysis confirms the economic feasibility of the AI approach: tasks requiring over 229,000 hours of expert labor were completed within months at a fraction of the cost. The work introduces a new paradigm in religious text processing by showing how AI can augment human expertise, enabling large-scale, multilingual, and semantically enriched access to Islamic heritage.",
        "tags": [
            "Detection",
            "LLM",
            "Segmentation"
        ]
    },
    {
        "id": "163",
        "title": "Allocation of Parameters in Transformers",
        "author": [
            "Ruoxi Yu",
            "Haotian Jiang",
            "Jingpu Cheng",
            "Penghao Yu",
            "Qianxiao Li",
            "Zhong Li"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03784",
        "abstract": "Transformers have achieved remarkable successes across a wide range of applications, yet the theoretical foundation of their model efficiency remains underexplored. In this work, we investigate how the model parameters -- mainly attention heads and head dimensions -- should be allocated across layers to balance expressivity and efficiency. We first provide mathematical analysis on the role of early layers in information extraction from an approximation perspective, with a theoretical characterization on the trade-off between the number of heads and head dimension under a fixed parameter budget. In addition, we uncover and prove the \\emph{saturation} behavior of softmax activations: Continuously increasing head dimensions can lead to diminishing returns in learning errors, particularly for long sequences. Supported by both theory and experiments, this saturation pattern suggests that later layers can operate more efficiently with reduced parameters. Combining these insights, we propose principled strategies for allocating attention heads and dimensions across Transformers' layers, shedding light on theoretically-grounded model efficiency of Transformer-based architectures.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "164",
        "title": "Lightweight and Data-Efficient MultivariateTime Series Forecasting using Residual-Stacked Gaussian (RS-GLinear) Architecture",
        "author": [
            "Abukar Ali"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03788",
        "abstract": "Following the success of Transformer architectures in language modeling, particularly their ability to capture long-range dependencies, researchers have explored how these architectures can be adapted for time-series forecasting. Transformer-based models have been proposed to handle both short- and long-term dependencies when predicting future values from historical data. However, studies such as those by Zeng et al. (2022) and Rizvi et al. (2025) have reported mixed results in long-term forecasting tasks. In this work, we evaluate the Gaussian-based Linear architecture introduced by Rizvi et al. (2025) and present an enhanced version called the Residual Stacked Gaussian Linear (RSGL) model. We also investigate the broader applicability of the RSGL model in additional domains, including financial time series and epidemiological data. Experimental results show that the RSGL model achieves improved prediction accuracy and robustness compared to both the baseline Gaussian Linear and Transformer-based models.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "165",
        "title": "Investigating LLM Variability in Personalized Conversational Information Retrieval",
        "author": [
            "Simon Lupart",
            "DaniÃ«l van Dijk",
            "Eric Langezaal",
            "Ian van Dort",
            "Mohammad Aliannejadi"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03795",
        "abstract": "Personalized Conversational Information Retrieval (CIR) has seen rapid progress in recent years, driven by the development of Large Language Models (LLMs). Personalized CIR aims to enhance document retrieval by leveraging user-specific information, such as preferences, knowledge, or constraints, to tailor responses to individual needs. A key resource for this task is the TREC iKAT 2023 dataset, designed to evaluate personalization in CIR pipelines. Building on this resource, Mo et al. explored several strategies for incorporating Personal Textual Knowledge Bases (PTKB) into LLM-based query reformulation. Their findings suggested that personalization from PTKBs could be detrimental and that human annotations were often noisy. However, these conclusions were based on single-run experiments using the GPT-3.5 Turbo model, raising concerns about output variability and repeatability. In this reproducibility study, we rigorously reproduce and extend their work, focusing on LLM output variability and model generalization. We apply the original methods to the new TREC iKAT 2024 dataset and evaluate a diverse range of models, including Llama (1B-70B), Qwen-7B, GPT-4o-mini. Our results show that human-selected PTKBs consistently enhance retrieval performance, while LLM-based selection methods do not reliably outperform manual choices. We further compare variance across datasets and observe higher variability on iKAT than on CAsT, highlighting the challenges of evaluating personalized CIR. Notably, recall-oriented metrics exhibit lower variance than precision-oriented ones, a critical insight for first-stage retrievers. Finally, we underscore the need for multi-run evaluations and variance reporting when assessing LLM-based CIR systems. By broadening evaluation across models, datasets, and metrics, our study contributes to more robust and generalizable practices for personalized CIR.",
        "tags": [
            "GPT",
            "LLM",
            "LLaMA",
            "Qwen"
        ]
    },
    {
        "id": "166",
        "title": "Mechanistic Interpretability of Socio-Political Frames in Language Models",
        "author": [
            "Hadi Asghari",
            "Sami Nenno"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03799",
        "abstract": "This paper explores the ability of large language models to generate and recognize deep cognitive frames, particularly in socio-political contexts. We demonstrate that LLMs are highly fluent in generating texts that evoke specific frames and can recognize these frames in zero-shot settings. Inspired by mechanistic interpretability research, we investigate the location of the `strict father' and `nurturing parent' frames within the model's hidden representation, identifying singular dimensions that correlate strongly with their presence. Our findings contribute to understanding how LLMs capture and express meaningful human concepts.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "167",
        "title": "Beyond Token Length: Step Pruner for Efficient and Accurate Reasoning in Large Language Models",
        "author": [
            "Canhui Wu",
            "Qiong Cao",
            "Chang Li",
            "Zhenfang Wang",
            "Chao Xue",
            "Yuwei Fan",
            "Wei Xi",
            "Xiaodong He"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03805",
        "abstract": "Large Reasoning Models (LRMs) demonstrate strong performance on complex tasks but often suffer from excessive verbosity, known as \"overthinking.\" Existing solutions via reinforcement learning (RL) typically penalize generated tokens to promote conciseness. However, these methods encounter two challenges: responses with fewer tokens do not always correspond to fewer reasoning steps, and models may develop hacking behavior in later stages of training by discarding reasoning steps to minimize token usage. In this work, we introduce \\textbf{Step Pruner (SP)}, an RL framework that steers LRMs toward more efficient reasoning by favoring compact reasoning steps. Our step-aware reward function prioritizes correctness while imposing penalties for redundant steps, and withholds rewards for incorrect responses to prevent the reinforcement of erroneous reasoning. Moreover, we propose a dynamic stopping mechanism: when the length of any output step exceeds the upper limit, we halt updates to prevent hacking behavior caused by merging steps. Extensive experiments across four reasoning benchmarks demonstrate that SP achieves state-of-the-art accuracy while significantly reducing response length. For instance, on AIME24, SP reduces token usage by \\textbf{69.7\\%}.",
        "tags": [
            "LLM",
            "RL"
        ]
    },
    {
        "id": "168",
        "title": "Annotate Rhetorical Relations with INCEpTION: A Comparison with Automatic Approaches",
        "author": [
            "Mehedi Hasan Emon"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03808",
        "abstract": "This research explores the annotation of rhetorical relations in discourse using the INCEpTION tool and compares manual annotation with automatic approaches based on large language models. The study focuses on sports reports (specifically cricket news) and evaluates the performance of BERT, DistilBERT, and Logistic Regression models in classifying rhetorical relations such as elaboration, contrast, background, and cause-effect. The results show that DistilBERT achieved the highest accuracy, highlighting its potential for efficient discourse relation prediction. This work contributes to the growing intersection of discourse parsing and transformer-based NLP. (This paper was conducted as part of an academic requirement under the supervision of Prof. Dr. Ralf Klabunde, Linguistic Data Science Lab, Ruhr University Bochum.) Keywords: Rhetorical Structure Theory, INCEpTION, BERT, DistilBERT, Discourse Parsing, NLP.",
        "tags": [
            "BERT",
            "LLM",
            "Transformer"
        ]
    },
    {
        "id": "169",
        "title": "Diverse Text-to-Image Generation via Contrastive Noise Optimization",
        "author": [
            "Byungjun Kim",
            "Soobin Um",
            "Jong Chul Ye"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03813",
        "abstract": "Text-to-image (T2I) diffusion models have demonstrated impressive performance in generating high-fidelity images, largely enabled by text-guided inference. However, this advantage often comes with a critical drawback: limited diversity, as outputs tend to collapse into similar modes under strong text guidance. Existing approaches typically optimize intermediate latents or text conditions during inference, but these methods deliver only modest gains or remain sensitive to hyperparameter tuning. In this work, we introduce Contrastive Noise Optimization, a simple yet effective method that addresses the diversity issue from a distinct perspective. Unlike prior techniques that adapt intermediate latents, our approach shapes the initial noise to promote diverse outputs. Specifically, we develop a contrastive loss defined in the Tweedie data space and optimize a batch of noise latents. Our contrastive optimization repels instances within the batch to maximize diversity while keeping them anchored to a reference sample to preserve fidelity. We further provide theoretical insights into the mechanism of this preprocessing to substantiate its effectiveness. Extensive experiments across multiple T2I backbones demonstrate that our approach achieves a superior quality-diversity Pareto frontier while remaining robust to hyperparameter choices.",
        "tags": [
            "Diffusion",
            "Text-to-Image"
        ]
    },
    {
        "id": "170",
        "title": "A Trustworthy Industrial Fault Diagnosis Architecture Integrating Probabilistic Models and Large Language Models",
        "author": [
            "Yue wu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03815",
        "abstract": "There are limitations of traditional methods and deep learning methods in terms of interpretability, generalization, and quantification of uncertainty in industrial fault diagnosis, and there are core problems of insufficient credibility in industrial fault diagnosis. The architecture performs preliminary analysis through a Bayesian network-based diagnostic engine and features an LLM-driven cognitive quorum module with multimodal input capabilities. The module conducts expert-level arbitration of initial diagnoses by analyzing structured features and diagnostic charts, prioritizing final decisions after conflicts are identified. To ensure the reliability of the system output, the architecture integrates a confidence calibration module based on temperature calibration and a risk assessment module, which objectively quantifies the reliability of the system using metrics such as expected calibration error (ECE). Experimental results on a dataset containing multiple fault types showed that the proposed framework improved diagnostic accuracy by more than 28 percentage points compared to the baseline model, while the calibrated ECE was reduced by more than 75%. Case studies have confirmed that HCAA effectively corrects misjudgments caused by complex feature patterns or knowledge gaps in traditional models, providing novel and practical engineering solutions for building high-trust, explainable AI diagnostic systems for industrial applications.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "171",
        "title": "TROLL: Trust Regions improve Reinforcement Learning for Large Language Models",
        "author": [
            "Philipp Becker",
            "Niklas Freymuth",
            "Serge Thilges",
            "Fabian Otto",
            "Gerhard Neumann"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03817",
        "abstract": "On-policy Reinforcement Learning (RL) with PPO-like clip objectives has become the standard choice for reward-based fine-tuning of large language models (LLMs). Although recent work has explored improved estimators of advantages and normalization, the clipping mechanism itself has remained untouched. Originally introduced as a proxy for principled KL-based trust regions, clipping is a crude approximation that often causes unstable updates and suboptimal performance. We replace the clip objective with a novel discrete differentiable trust region projection, which provides principled token-level KL constraints. The projection operates on a sparse subset of the model's most important token logits to balance computational cost and projection effectiveness. Our approach, Trust Region Optimization for Large Language Models (TROLL), serves as a direct replacement for PPO-like clipping during training and does not alter the model's inference behavior. Across datasets, model families, and advantage-estimation methods, TROLL consistently outperforms PPO-like clipping in terms of training speed, stability, and final success rates.",
        "tags": [
            "CLIP",
            "LLM",
            "PPO",
            "RL"
        ]
    },
    {
        "id": "172",
        "title": "Contrastive-SDE: Guiding Stochastic Differential Equations with Contrastive Learning for Unpaired Image-to-Image Translation",
        "author": [
            "Venkata Narendra Kotyada",
            "Revanth Eranki",
            "Nagesh Bhattu Sristy"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03821",
        "abstract": "Unpaired image-to-image translation involves learning mappings between source domain and target domain in the absence of aligned or corresponding samples. Score based diffusion models have demonstrated state-of-the-art performance in generative tasks. Their ability to approximate complex data distributions through stochastic differential equations (SDEs) enables them to generate high-fidelity and diverse outputs, making them particularly well-suited for unpaired I2I settings. In parallel, contrastive learning provides a powerful framework for learning semantic similarities without the need for explicit supervision or paired data. By pulling together representations of semantically similar samples and pushing apart dissimilar ones, contrastive methods are inherently aligned with the objectives of unpaired translation. Its ability to selectively enforce semantic consistency at the feature level makes contrastive learning particularly effective for guiding generation in unpaired scenarios. In this work, we propose a time-dependent contrastive learning approach where a model is trained with SimCLR by considering an image and its domain invarient feature as a positive pair, enabling the preservation of domain-invariant features and the discarding of domain-specific ones. The learned contrastive model then guides the inference of a pretrained SDE for the I2I translation task. We empirically compare Contrastive-SDE with several baselines across three common unpaired I2I tasks, using four metrics for evaluation. Constrastive-SDE achieves comparable results to the state-of-the-art on several metrics. Furthermore, we observe that our model converges significantly faster and requires no label supervision or classifier training, making it a more efficient alternative for this task.",
        "tags": [
            "Diffusion",
            "SDE"
        ]
    },
    {
        "id": "173",
        "title": "Distributed Area Coverage with High Altitude Balloons Using Multi-Agent Reinforcement Learning",
        "author": [
            "Adam Haroon",
            "Tristan Schuler"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03823",
        "abstract": "High Altitude Balloons (HABs) can leverage stratospheric wind layers for limited horizontal control, enabling applications in reconnaissance, environmental monitoring, and communications networks. Existing multi-agent HAB coordination approaches use deterministic methods like Voronoi partitioning and extremum seeking control for large global constellations, which perform poorly for smaller teams and localized missions. While single-agent HAB control using reinforcement learning has been demonstrated on HABs, coordinated multi-agent reinforcement learning (MARL) has not yet been investigated. This work presents the first systematic application of multi-agent reinforcement learning (MARL) to HAB coordination for distributed area coverage. We extend our previously developed reinforcement learning simulation environment (RLHAB) to support cooperative multi-agent learning, enabling multiple agents to operate simultaneously in realistic atmospheric conditions. We adapt QMIX for HAB area coverage coordination, leveraging Centralized Training with Decentralized Execution to address atmospheric vehicle coordination challenges. Our approach employs specialized observation spaces providing individual state, environmental context, and teammate data, with hierarchical rewards prioritizing coverage while encouraging spatial distribution. We demonstrate that QMIX achieves similar performance to the theoretically optimal geometric deterministic method for distributed area coverage, validating the MARL approach and providing a foundation for more complex autonomous multi-HAB missions where deterministic methods become intractable.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "174",
        "title": "A4FN: an Agentic AI Architecture for Autonomous Flying Networks",
        "author": [
            "AndrÃ© Coelho",
            "Pedro Ribeiro",
            "Helder Fontes",
            "Rui Campos"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03829",
        "abstract": "This position paper presents A4FN, an Agentic Artificial Intelligence (AI) architecture for intent-driven automation in Flying Networks (FNs) using Unmanned Aerial Vehicles (UAVs) as access nodes. A4FN leverages Generative AI and Large Language Models (LLMs) to enable real-time, context-aware network control via a distributed agentic system. It comprises two components: the Perception Agent (PA), which semantically interprets multimodal input -- including imagery, audio, and telemetry data -- from UAV-mounted sensors to derive Service Level Specifications (SLSs); and the Decision-and-Action Agent (DAA), which reconfigures the network based on inferred intents. A4FN embodies key properties of Agentic AI, including autonomy, goal-driven reasoning, and continuous perception-action cycles. Designed for mission-critical, infrastructure-limited scenarios such as disaster response, it supports adaptive reconfiguration, dynamic resource management, and interoperability with emerging wireless technologies. The paper details the A4FN architecture, its core innovations, and open research challenges in multi-agent coordination and Agentic AI integration in next-generation FNs.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "175",
        "title": "HOFLON: Hybrid Offline Learning and Online Optimization for Process Start-Up and Grade-Transition Control",
        "author": [
            "Alex Durkin",
            "Jasper Stolte",
            "Mehmet MercangÃ¶z"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03830",
        "abstract": "Start-ups and product grade-changes are critical steps in continuous-process plant operation, because any misstep immediately affects product quality and drives operational losses. These transitions have long relied on manual operation by a handful of expert operators, but the progressive retirement of that workforce is leaving plant owners without the tacit know-how needed to execute them consistently. In the absence of a process model, offline reinforcement learning (RL) promises to capture and even surpass human expertise by mining historical start-up and grade-change logs, yet standard offline RL struggles with distribution shift and value-overestimation whenever a learned policy ventures outside the data envelope. We introduce HOFLON (Hybrid Offline Learning + Online Optimization) to overcome those limitations. Offline, HOFLON learns (i) a latent data manifold that represents the feasible region spanned by past transitions and (ii) a long-horizon Q-critic that predicts the cumulative reward from state-action pairs. Online, it solves a one-step optimization problem that maximizes the Q-critic while penalizing deviations from the learned manifold and excessive rates of change in the manipulated variables. We test HOFLON on two industrial case studies: a polymerization reactor start-up and a paper-machine grade-change problem, and benchmark it against Implicit Q-Learning (IQL), a leading offline-RL algorithm. In both plants HOFLON not only surpasses IQL but also delivers, on average, better cumulative rewards than the best start-up or grade-change observed in the historical data, demonstrating its potential to automate transition operations beyond current expert capability.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "176",
        "title": "Mirage: Unveiling Hidden Artifacts in Synthetic Images with Large Vision-Language Models",
        "author": [
            "Pranav Sharma",
            "Shivank Garg",
            "Durga Toshniwal"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03840",
        "abstract": "Recent advances in image generation models have led to models that produce synthetic images that are increasingly difficult for standard AI detectors to identify, even though they often remain distinguishable by humans. To identify this discrepancy, we introduce \\textbf{Mirage}, a curated dataset comprising a diverse range of AI-generated images exhibiting visible artifacts, where current state-of-the-art detection methods largely fail. Furthermore, we investigate whether Large Vision-Language Models (LVLMs), which are increasingly employed as substitutes for human judgment in various tasks, can be leveraged for explainable AI image detection. Our experiments on both Mirage and existing benchmark datasets demonstrate that while LVLMs are highly effective at detecting AI-generated images with visible artifacts, their performance declines when confronted with images lacking such cues.",
        "tags": [
            "Detection",
            "VLM"
        ]
    },
    {
        "id": "177",
        "title": "On Using Large Language Models to Enhance Clinically-Driven Missing Data Recovery Algorithms in Electronic Health Records",
        "author": [
            "Sarah C. Lotspeich",
            "Abbey Collins",
            "Brian J. Wells",
            "Ashish K. Khanna",
            "Joseph Rigdon",
            "Lucy D'Agostino McGowan"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03844",
        "abstract": "Objective: Electronic health records (EHR) data are prone to missingness and errors. Previously, we devised an \"enriched\" chart review protocol where a \"roadmap\" of auxiliary diagnoses (anchors) was used to recover missing values in EHR data (e.g., a diagnosis of impaired glycemic control might imply that a missing hemoglobin A1c value would be considered unhealthy). Still, chart reviews are expensive and time-intensive, which limits the number of patients whose data can be reviewed. Now, we investigate the accuracy and scalability of a roadmap-driven algorithm, based on ICD-10 codes (International Classification of Diseases, 10th revision), to mimic expert chart reviews and recover missing values. Materials and Methods: In addition to the clinicians' original roadmap from our previous work, we consider new versions that were iteratively refined using large language models (LLM) in conjunction with clinical expertise to expand the list of auxiliary diagnoses. Using chart reviews for 100 patients from the EHR at an extensive learning health system, we examine algorithm performance with different roadmaps. Using the larger study of $1000$ patients, we applied the final algorithm, which used a roadmap with clinician-approved additions from the LLM. Results: The algorithm recovered as much, if not more, missing data as the expert chart reviewers, depending on the roadmap. Discussion: Clinically-driven algorithms (enhanced by LLM) can recover missing EHR data with similar accuracy to chart reviews and can feasibly be applied to large samples. Extending them to monitor other dimensions of data quality (e.g., plausability) is a promising future direction.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "178",
        "title": "Small Language Models for Agentic Systems: A Survey of Architectures, Capabilities, and Deployment Trade offs",
        "author": [
            "Raghav Sharma",
            "Manan Mehta"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03847",
        "abstract": "Small language models (SLMs; 1-12B params, sometimes up to 20B) are sufficient and often superior for agentic workloads where the objective is schema- and API-constrained accuracy rather than open-ended generation. We synthesize recent evidence across open and proprietary SLMs (Phi-4-Mini, Qwen-2.5-7B, Gemma-2-9B, Llama-3.2-1B/3B, Ministral-3B/8B, Apple on-device 3B, DeepSeek-R1-Distill) and connect it to modern evaluations (BFCL v3/v4, StableToolBench) and serving stacks (vLLM, SGLang, TensorRT-LLM) paired with guided decoding libraries (XGrammar, Outlines). We formalize SLM-default, LLM-fallback systems with uncertainty-aware routing and verifier cascades, and propose engineering metrics that reflect real production goals: cost per successful task (CPS), schema validity rate, executable call rate, p50/p95 latency, and energy per request. Guided decoding, strict JSON Schema outputs, and validator-first tool execution close much of the capability gap with larger models and often let SLMs match or surpass LLMs on tool use, function calling, and RAG at 10x-100x lower token cost with materially better latency and energy. We provide design patterns for agent stacks that prioritize SLMs: schema-first prompting, type-safe function registries, confidence scoring with verifier rollups, and lightweight adaptation via LoRA/QLoRA. We also delineate limits where fallback remains valuable (open-domain reasoning and some long-horizon planning). The result is a practical blueprint for building fast, inexpensive, and reliable agents that default to SLMs while preserving headroom with targeted LLM assistance.\nKeywords: small language models, agents, function calling, structured outputs, JSON Schema, guided decoding, LoRA/QLoRA, routing, energy efficiency, edge inference",
        "tags": [
            "DeepSeek",
            "LLM",
            "LLaMA",
            "LoRA",
            "Qwen",
            "RAG"
        ]
    },
    {
        "id": "179",
        "title": "Algorithm Generation via Creative Ideation",
        "author": [
            "Ruiying Ma",
            "Chieh-Jan Mike Liang",
            "Yanjie Gao",
            "Francis Y. Yan"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03851",
        "abstract": "Designing system algorithms remains challenging, where the discontinuous nature of the solution space often forces system engineers to rely on generic heuristics at the expense of performance. We study whether LLMs can practically drive algorithm generation, and find that they are biased towards well-known generic designs, rather than making the creative leaps needed to navigate the discontinuous solution space. To address this limitation, we introduce MetaMuse, a framework for creative ideation built on three self-reflection principles: (1) quantifying solution diversity and usefulness in measurable performance space, rather than abstract idea space, (2) steering ideation through external stimuli, rather than internal randomness, and (3) constructing executable solutions using waypoint reasoning, rather than free-form chain-of-thought. Extensive evaluation shows that MetaMuse can generate high-performing solutions for two critical problems at a global cloud provider: cache replacement (reducing cache misses by up to 35.76%) and online bin packing (reducing bin usage by up to 30.93%).",
        "tags": [
            "CoT",
            "LLM"
        ]
    },
    {
        "id": "180",
        "title": "UGround: Towards Unified Visual Grounding with Unrolled Transformers",
        "author": [
            "Rui Qian",
            "Xin Yin",
            "Chuanhang Deng",
            "Zhiyuan Peng",
            "Jian Xiong",
            "Wei Zhai",
            "Dejing Dou"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03853",
        "abstract": "We present UGround, a \\textbf{U}nified visual \\textbf{Ground}ing paradigm that dynamically selects intermediate layers across \\textbf{U}nrolled transformers as ``mask as prompt'', diverging from the prevailing pipeline that leverages the fixed last hidden layer as ``\\texttt{<SEG>} as prompt''. UGround addresses two primary challenges posed by the prevailing paradigm: (1) its reliance on the fixed last hidden layer, which sequentially amplifies cumulative errors arising from layer-by-layer propagation without intermediate correction, and (2) its use of \\texttt{<SEG>} as a prompt, which implicitly projects textual embeddings into visual space without explicit spatial cues (\\eg, coordinates). Central to UGround is Policy-Prompted Masking, which comprises two key components: Stochastic Skip Connection (SSC) and Mask as Prompt (MasP). SSC is a reinforcement learning policy that, via stochastic sampling, allows each \\texttt{<SEG>} token to slide across unrolled transformer layers, enabling dynamic layer selection at which it connects to the vision model (\\eg, SAM) in a skip-connection fashion. Given the selected hidden layer, MasP uses the similarity map derived from the \\texttt{<SEG>} token and image tokens as a soft logit mask to prompt SAM for mask generation, offering explicit spatial cues through its activation regions. To validate the effectiveness of UGround, we, for the first time, have unified visual grounding within a single framework from an attribute perspective, spanning from traditional refer expression segmentation to newly proposed reasoning segmentation, single-target to multi-target, positive query to false premise (empty target). All codes and models are publicly available at \\href{https://github.com/rui-qian/UGround}{https://github.com/rui-qian/UGround}.",
        "tags": [
            "RL",
            "SAM",
            "Segmentation",
            "Transformer"
        ]
    },
    {
        "id": "181",
        "title": "Optimized Minimal 4D Gaussian Splatting",
        "author": [
            "Minseo Lee",
            "Byeonghyeon Lee",
            "Lucas Yunkyu Lee",
            "Eunsoo Lee",
            "Sangmin Kim",
            "Seunghyeon Song",
            "Joo Chan Lee",
            "Jong Hwan Ko",
            "Jaesik Park",
            "Eunbyung Park"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03857",
        "abstract": "4D Gaussian Splatting has emerged as a new paradigm for dynamic scene representation, enabling real-time rendering of scenes with complex motions. However, it faces a major challenge of storage overhead, as millions of Gaussians are required for high-fidelity reconstruction. While several studies have attempted to alleviate this memory burden, they still face limitations in compression ratio or visual quality. In this work, we present OMG4 (Optimized Minimal 4D Gaussian Splatting), a framework that constructs a compact set of salient Gaussians capable of faithfully representing 4D Gaussian models. Our method progressively prunes Gaussians in three stages: (1) Gaussian Sampling to identify primitives critical to reconstruction fidelity, (2) Gaussian Pruning to remove redundancies, and (3) Gaussian Merging to fuse primitives with similar characteristics. In addition, we integrate implicit appearance compression and generalize Sub-Vector Quantization (SVQ) to 4D representations, further reducing storage while preserving quality. Extensive experiments on standard benchmark datasets demonstrate that OMG4 significantly outperforms recent state-of-the-art methods, reducing model sizes by over 60% while maintaining reconstruction quality. These results position OMG4 as a significant step forward in compact 4D scene representation, opening new possibilities for a wide range of applications. Our source code is available at https://minshirley.github.io/OMG4/.",
        "tags": [
            "Gaussian Splatting",
            "Vector Quantization"
        ]
    },
    {
        "id": "182",
        "title": "Designing Empirical Studies on LLM-Based Code Generation: Towards a Reference Framework",
        "author": [
            "Nathalia Nascimento",
            "Everton Guimaraes",
            "Paulo Alencar"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03862",
        "abstract": "The rise of large language models (LLMs) has introduced transformative potential in automated code generation, addressing a wide range of software engineering challenges. However, empirical evaluation of LLM-based code generation lacks standardization, with studies varying widely in goals, tasks, and metrics, which limits comparability and reproducibility. In this paper, we propose a theoretical framework for designing and reporting empirical studies on LLM-based code generation. The framework is grounded in both our prior experience conducting such experiments and a comparative analysis of key similarities and differences among recent studies. It organizes evaluation around core components such as problem sources, quality attributes, and metrics, supporting structured and systematic experimentation. We demonstrate its applicability through representative case mappings and identify opportunities for refinement. Looking forward, we plan to evolve the framework into a more robust and mature tool for standardizing LLM evaluation across software engineering contexts.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "183",
        "title": "Spatial CAPTCHA: Generatively Benchmarking Spatial Reasoning for Human-Machine Differentiation",
        "author": [
            "Arina Kharlamova",
            "Bowei He",
            "Chen Ma",
            "Xue Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03863",
        "abstract": "Online services rely on CAPTCHAs as a first line of defense against automated abuse, yet recent advances in multi-modal large language models (MLLMs) have eroded the effectiveness of conventional designs that focus on text recognition or 2D image understanding. To address this challenge, we present Spatial CAPTCHA, a novel human-verification framework that leverages fundamental differences in spatial reasoning between humans and MLLMs. Unlike existing CAPTCHAs which rely on low-level perception tasks that are vulnerable to modern AI, Spatial CAPTCHA generates dynamic questions requiring geometric reasoning, perspective-taking, occlusion handling, and mental rotation. These skills are intuitive for humans but difficult for state-of-the-art (SOTA) AI systems. The system employs a procedural generation pipeline with constraint-based difficulty control, automated correctness verification, and human-in-the-loop validation to ensure scalability, robustness, and adaptability. Evaluation on a corresponding benchmark, Spatial-CAPTCHA-Bench, demonstrates that humans vastly outperform 10 state-of-the-art MLLMs, with the best model achieving only 31.0% Pass@1 accuracy. Furthermore, we compare Spatial CAPTCHA with Google reCAPTCHA, which confirms its effectiveness as both a security mechanism and a diagnostic tool for spatial reasoning in AI.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "184",
        "title": "Unlocking Reasoning Capabilities in LLMs via Reinforcement Learning Exploration",
        "author": [
            "Wenhao Deng",
            "Long Wei",
            "Chenglei Yu",
            "Tailin Wu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03865",
        "abstract": "Reinforcement learning with verifiable rewards (RLVR) has recently enhanced the reasoning capabilities of large language models (LLMs), particularly for mathematical problem solving. However, a fundamental limitation remains: as the sampling budget increases, the advantage of RLVR-trained models over their pretrained bases often diminishes or even vanishes, revealing a strong dependence on the base model's restricted search space. We attribute this phenomenon to the widespread use of the reverse Kullback-Leibler (KL) divergence regularizer, whose mode-seeking behavior keeps the policy trapped inside the base model's support region and hampers wider exploration. To address this issue, we propose RAPO (Rewards-Aware Policy Optimization), an algorithm to promote broader yet focused exploration. Our method (i) utilizes the forward KL penalty to replace the reverse KL penalty for out-of-distribution exploration, and (ii) reweights the reference policy to facilitate adaptive in-distribution exploration. We train Qwen2.5-3B and 7B models with RAPO on the 8K SimpleRL-Zero dataset, without supervised fine-tuning, and evaluate them on AIME2024 and AIME2025. Results show that RAPO consistently improves problem-solving performance. Notably, RAPO enables models to surpass the base model's performance ceiling and solves previously intractable problems, advancing the frontier of RLVR for challenging reasoning tasks.",
        "tags": [
            "LLM",
            "RL"
        ]
    },
    {
        "id": "185",
        "title": "SDAKD: Student Discriminator Assisted Knowledge Distillation for Super-Resolution Generative Adversarial Networks",
        "author": [
            "Nikolaos Kaparinos",
            "Vasileios Mezaris"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03870",
        "abstract": "Generative Adversarial Networks (GANs) achieve excellent performance in generative tasks, such as image super-resolution, but their computational requirements make difficult their deployment on resource-constrained devices. While knowledge distillation is a promising research direction for GAN compression, effectively training a smaller student generator is challenging due to the capacity mismatch between the student generator and the teacher discriminator. In this work, we propose Student Discriminator Assisted Knowledge Distillation (SDAKD), a novel GAN distillation methodology that introduces a student discriminator to mitigate this capacity mismatch. SDAKD follows a three-stage training strategy, and integrates an adapted feature map distillation approach in its last two training stages. We evaluated SDAKD on two well-performing super-resolution GANs, GCFSR and Real-ESRGAN. Our experiments demonstrate consistent improvements over the baselines and SOTA GAN knowledge distillation methods. The SDAKD source code will be made openly available upon acceptance of the paper.",
        "tags": [
            "GAN",
            "Super Resolution"
        ]
    },
    {
        "id": "186",
        "title": "Optimal Scaling Needs Optimal Norm",
        "author": [
            "Oleg Filatov",
            "Jiangtao Wang",
            "Jan Ebert",
            "Stefan Kesselheim"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03871",
        "abstract": "Despite recent progress in optimal hyperparameter transfer under model and dataset scaling, no unifying explanatory principle has been established. Using the Scion optimizer, we discover that joint optimal scaling across model and dataset sizes is governed by a single invariant: the operator norm of the output layer. Across models with up to 1.3B parameters trained on up to 138B tokens, the optimal learning rate/batch size pair $(\\eta^{\\ast}, B^{\\ast})$ consistently has the same operator norm value - a phenomenon we term norm transfer. This constant norm condition is necessary but not sufficient: while for each dataset size, multiple $(\\eta, B)$ reach the optimal norm, only a unique $(\\eta^{\\ast}, B^{\\ast})$ achieves the best loss. As a sufficient condition, we provide the first measurement of $(\\eta^{\\ast}, B^{\\ast})$ scaling with dataset size for Scion, and find that the scaling rules are consistent with those of the Adam optimizer. Tuning per-layer-group learning rates also improves model performance, with the output layer being the most sensitive and hidden layers benefiting from lower learning rates. We provide practical insights on norm-guided optimal scaling and release our Distributed Scion (Disco) implementation with logs from over two thousand runs to support research on LLM training dynamics at scale.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "187",
        "title": "DHQA-4D: Perceptual Quality Assessment of Dynamic 4D Digital Human",
        "author": [
            "Yunhao Li",
            "Sijing Wu",
            "Yucheng Zhu",
            "Huiyu Duan",
            "Zicheng Zhang",
            "Guangtao Zhai"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03874",
        "abstract": "With the rapid development of 3D scanning and reconstruction technologies, dynamic digital human avatars based on 4D meshes have become increasingly popular. A high-precision dynamic digital human avatar can be applied to various fields such as game production, animation generation, and remote immersive communication. However, these 4D human avatar meshes are prone to being degraded by various types of noise during the processes of collection, compression, and transmission, thereby affecting the viewing experience of users. In light of this fact, quality assessment of dynamic 4D digital humans becomes increasingly important. In this paper, we first propose a large-scale dynamic digital human quality assessment dataset, DHQA-4D, which contains 32 high-quality real-scanned 4D human mesh sequences, 1920 distorted textured 4D human meshes degraded by 11 textured distortions, as well as their corresponding textured and non-textured mean opinion scores (MOSs). Equipped with DHQA-4D dataset, we analyze the influence of different types of distortion on human perception for textured dynamic 4D meshes and non-textured dynamic 4D meshes. Additionally, we propose DynaMesh-Rater, a novel large multimodal model (LMM) based approach that is able to assess both textured 4D meshes and non-textured 4D meshes. Concretely, DynaMesh-Rater elaborately extracts multi-dimensional features, including visual features from a projected 2D video, motion features from cropped video clips, and geometry features from the 4D human mesh to provide comprehensive quality-related information. Then we utilize a LMM model to integrate the multi-dimensional features and conduct a LoRA-based instruction tuning technique to teach the LMM model to predict the quality scores. Extensive experimental results on the DHQA-4D dataset demonstrate the superiority of our DynaMesh-Rater method over previous quality assessment methods.",
        "tags": [
            "3D",
            "LoRA"
        ]
    },
    {
        "id": "188",
        "title": "COVER:COverage-VErified Roadmaps for Fixed-time Motion Planning in Continuous Semi-Static Environments",
        "author": [
            "Niranjan Kumar Ilampooranan",
            "Constantinos Chamzas"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03875",
        "abstract": "Having the ability to answer motion-planning queries within a fixed time budget is critical for the widespread deployment of robotic systems. Semi-static environments, where most obstacles remain static but a limited set can vary across queries, exhibit structured variability that can be systematically exploited to provide stronger guarantees than in general motion-planning problems. However, prior approaches in this setting either lack formal guarantees or rely on restrictive discretizations of obstacle configurations, limiting their applicability in realistic domains. This paper introduces COVER, a novel framework that incrementally constructs a coverage-verified roadmap in semi-static environments. By partitioning the obstacle configuration space and solving for feasible paths within each partition, COVER systematically verifies feasibility of the roadmap in each partition and guarantees fixed-time motion planning queries within the verified regions. We validate COVER with a 7-DOF simulated Panda robot performing table and shelf tasks, demonstrating that COVER achieves broader coverage with higher query success rates than prior works.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "189",
        "title": "Adversarial Agent Collaboration for C to Rust Translation",
        "author": [
            "Tianyu Li",
            "Ruishi Li",
            "Bo Wang",
            "Brandon Paulsen",
            "Umang Mathur",
            "Prateek Saxena"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03879",
        "abstract": "Translating C to memory-safe languages, like Rust, prevents critical memory safety vulnerabilities that are prevalent in legacy C software. Existing approaches for C to safe Rust translation, including LLM-assisted ones, do not generalize on larger (> 500 LoC) C codebases because they depend on complex program analyses that frequently break. In this work, we present ACToR (Adversarial C To Rust translator), a simple LLM agent-based approach. Inspired by GANs, ACToR pits a generator agent against a discriminator agent, which collaborate to iteratively generate a Rust translation. On each iteration, the translator agent synthesizes and refines a Rust translation to pass an existing suite of tests, and then the discriminator agent finds new failing tests. We demonstrate that ACToR translates all of the 63 real-world command line utilities considered in our benchmarks, which have an average size of 485 lines of code, and it achieves over 90% test pass rate with zero human intervention. To our knowledge, it is the first such system that reliably translates C programs of this scale. Furthermore, ACToR improves translation correctness by up to 18.9% compared to baseline, non-adversarial approaches.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "190",
        "title": "Exploring Instruction Data Quality for Explainable Image Quality Assessment",
        "author": [
            "Yunhao Li",
            "Sijing Wu",
            "Huiyu Duan",
            "Yucheng Zhu",
            "Qi Jia",
            "Guangtao Zhai"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03880",
        "abstract": "In recent years, with the rapid development of powerful multimodal large language models (MLLMs), explainable image quality assessment (IQA) has gradually become popular, aiming at providing quality-related descriptions and answers of images. To achieve this goal, recent methods seek to construct a large-scale instruction tuning dataset to empower the MLLM with quality perception ability following the well-known scaling law. However, a large amount of instruction tuning data may cause substantial computational costs and redundant data, which in turn will cause harm to the performance of the model. To cope with this problem, in this paper, we challenge the scaling law and systematically investigate the role of data quality of the instruction tuning dataset for explainable IQA. Using a powerful pre-trained MLLM, we first investigate the changes in model performance after fine-tuning with different sizes of instruction tuning data. We find that selecting a subset of the data set randomly using an appropriate ratio can even lead to better results than training with the entire instruction tuning dataset, demonstrating the redundancy of current explainable IQA instruction tuning data. Beyond randomly sampling a subset, we propose a clustering-based data selection framework with three stages: clustering feature extraction, cluster quota allocation, and cluster sampling strategy. Then we systematically analyze the choices of each stage and propose a simple but efficient data selection method IQA-Select for explainable IQA. The experimental results demonstrate that IQA-Select can achieve 102.1% and 103.7% performance of full fine-tuning using only 10% selected data in Q-Bench and AesBench respectively, significantly reducing computational costs while achieving better performance.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "191",
        "title": "Seeing the Bigger Picture: 3D Latent Mapping for Mobile Manipulation Policy Learning",
        "author": [
            "Sunghwan Kim",
            "Woojeh Chung",
            "Zhirui Dai",
            "Dwait Bhatt",
            "Arth Shukla",
            "Hao Su",
            "Yulun Tian",
            "Nikolay Atanasov"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03885",
        "abstract": "In this paper, we demonstrate that mobile manipulation policies utilizing a 3D latent map achieve stronger spatial and temporal reasoning than policies relying solely on images. We introduce Seeing the Bigger Picture (SBP), an end-to-end policy learning approach that operates directly on a 3D map of latent features. In SBP, the map extends perception beyond the robot's current field of view and aggregates observations over long horizons. Our mapping approach incrementally fuses multiview observations into a grid of scene-specific latent features. A pre-trained, scene-agnostic decoder reconstructs target embeddings from these features and enables online optimization of the map features during task execution. A policy, trainable with behavior cloning or reinforcement learning, treats the latent map as a state variable and uses global context from the map obtained via a 3D feature aggregator. We evaluate SBP on scene-level mobile manipulation and sequential tabletop manipulation tasks. Our experiments demonstrate that SBP (i) reasons globally over the scene, (ii) leverages the map as long-horizon memory, and (iii) outperforms image-based policies in both in-distribution and novel scenes, e.g., improving the success rate by 25% for the sequential manipulation task.",
        "tags": [
            "3D",
            "RL",
            "Robotics"
        ]
    },
    {
        "id": "192",
        "title": "Rare Text Semantics Were Always There in Your Diffusion Transformer",
        "author": [
            "Seil Kang",
            "Woojung Han",
            "Dayun Ju",
            "Seong Jae Hwang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03886",
        "abstract": "Starting from flow- and diffusion-based transformers, Multi-modal Diffusion Transformers (MM-DiTs) have reshaped text-to-vision generation, gaining acclaim for exceptional visual fidelity. As these models advance, users continually push the boundary with imaginative or rare prompts, which advanced models still falter in generating, since their concepts are often too scarce to leave a strong imprint during pre-training. In this paper, we propose a simple yet effective intervention that surfaces rare semantics inside MM-DiTs without additional training steps, data, denoising-time optimization, or reliance on external modules (e.g., large language models). In particular, the joint-attention mechanism intrinsic to MM-DiT sequentially updates text embeddings alongside image embeddings throughout transformer blocks. We find that by mathematically expanding representational basins around text token embeddings via variance scale-up before the joint-attention blocks, rare semantics clearly emerge in MM-DiT's outputs. Furthermore, our results generalize effectively across text-to-vision tasks, including text-to-image, text-to-video, and text-driven image editing. Our work invites generative models to reveal the semantics that users intend, once hidden yet ready to surface.",
        "tags": [
            "DiT",
            "Diffusion",
            "Image Editing",
            "LLM",
            "Text-to-Image",
            "Text-to-Video",
            "Transformer"
        ]
    },
    {
        "id": "193",
        "title": "NoTVLA: Narrowing of Dense Action Trajectories for Generalizable Robot Manipulation",
        "author": [
            "Zheng Huang",
            "Mingyu Liu",
            "Xiaoyi Lin",
            "Muzhi Zhu",
            "Canyu Zhao",
            "Zongze Du",
            "Xiaoman Li",
            "Yiduo Jia",
            "Hao Zhong",
            "Hao Chen",
            "Chunhua Shen"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03895",
        "abstract": "Vision-Language-Action (VLA) models represent a pivotal advance in embodied intelligence, yet they confront critical barriers to real-world deployment, most notably catastrophic forgetting. This issue stems from their overreliance on continuous action sequences or action chunks, which inadvertently create isolated data silos that disrupt knowledge retention across tasks. To tackle these challenges, we propose the Narrowing of Trajectory VLA (NoTVLA) framework: a novel approach that narrows its focus to sparse trajectories, thereby avoiding the catastrophic forgetting associated with dense trajectory fine-tuning. A key innovation of NoTVLA lies in its trajectory planning strategy: instead of centering on the target object's trajectory, it leverages temporal compression and spatial reasoning pruning specifically for the robot end effector's trajectory. Furthermore, training is conducted using these sparse trajectories rather than dense action trajectories, an optimization that delivers remarkable practical advantages with better performance in zero-shot. In multi-task evaluation scenarios, NoTVLA achieves superior performance and generalization compared to pi0 while operating under two critical constraints: it uses over an order of magnitude less computing power than pi0 and requires no wrist-mounted camera. This design ensures that NoTVLA's operational accuracy closely approximates that of single-task expert models. Crucially, it also preserves the model's inherent language capabilities, enabling zero-shot generalization in specific scenarios, supporting unified model deployment across multiple robot platforms, and fostering a degree of generalization even when perceiving tasks from novel perspectives.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "194",
        "title": "Bridge Thinking and Acting: Unleashing Physical Potential of VLM with Generalizable Action Expert",
        "author": [
            "Mingyu Liu",
            "Zheng Huang",
            "Xiaoyi Lin",
            "Muzhi Zhu",
            "Canyu Zhao",
            "Zongze Du",
            "Yating Wang",
            "Haoyi Zhu",
            "Hao Chen",
            "Chunhua Shen"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03896",
        "abstract": "Although Vision-Language Models (VLM) have demonstrated impressive planning and reasoning capabilities, translating these abilities into the physical world introduces significant challenges. Conventional Vision-Language-Action (VLA) models, which integrate reasoning and action into a monolithic architecture, generalize poorly because they are constrained by scarce, narrow-domain data. While recent dual-system approaches attempt to decouple \"thinking\" from \"acting\", they are often constrained by semantic ambiguities within the action module. This ambiguity makes large-scale, cross-task training infeasible. Consequently, these systems typically necessitate fine-tuning on newly collected data when deployed to novel environments, and the cooperation mechanism between the two systems remains ill-defined. To address these limitations, we introduce, for the first time, a framework centered around a generalizable action expert. Our approach utilizes sparse 3D trajectories as an intermediate representation, effectively bridging the high-level planning capabilities of the VLM with the low-level physical action module. During the planning phase, the VLM is only required to generate coarse 3D waypoints. These waypoints are then processed by our generalizable action expert, which refines them into dense, executable action sequences by sampling real-time point cloud observations of the environment. To promote training efficiency and robust generalization, we introduce a novel \"Action Pre-training, Pointcloud Fine-tuning\" paradigm. Our method combines the broad generalization capabilities of VLMs in visual understanding and planning with the fine-grained, action-level generalization of action expert.",
        "tags": [
            "3D",
            "VLM"
        ]
    },
    {
        "id": "195",
        "title": "Read Between the Lines: A Benchmark for Uncovering Political Bias in Bangla News Articles",
        "author": [
            "Nusrat Jahan Lia",
            "Shubhashis Roy Dipta",
            "Abdullah Khan Zehady",
            "Naymul Islam",
            "Madhusodan Chakraborty",
            "Abdullah Al Wasif"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03898",
        "abstract": "Detecting media bias is crucial, specifically in the South Asian region. Despite this, annotated datasets and computational studies for Bangla political bias research remain scarce. Crucially because, political stance detection in Bangla news requires understanding of linguistic cues, cultural context, subtle biases, rhetorical strategies, code-switching, implicit sentiment, and socio-political background. To address this, we introduce the first benchmark dataset of 200 politically significant and highly debated Bangla news articles, labeled for government-leaning, government-critique, and neutral stances, alongside diagnostic analyses for evaluating large language models (LLMs). Our comprehensive evaluation of 28 proprietary and open-source LLMs shows strong performance in detecting government-critique content (F1 up to 0.83) but substantial difficulty with neutral articles (F1 as low as 0.00). Models also tend to over-predict government-leaning stances, often misinterpreting ambiguous narratives. This dataset and its associated diagnostics provide a foundation for advancing stance detection in Bangla media research and offer insights for improving LLM performance in low-resource languages.",
        "tags": [
            "Detection",
            "LLM"
        ]
    },
    {
        "id": "196",
        "title": "Multi-Agent Code-Orchestrated Generation for Reliable Infrastructure-as-Code",
        "author": [
            "Rana Nameer Hussain Khan",
            "Dawood Wasif",
            "Jin-Hee Cho",
            "Ali Butt"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03902",
        "abstract": "The increasing complexity of cloud-native infrastructure has made Infrastructure-as-Code (IaC) essential for reproducible and scalable deployments. While large language models (LLMs) have shown promise in generating IaC snippets from natural language prompts, their monolithic, single-pass generation approach often results in syntactic errors, policy violations, and unscalable designs. In this paper, we propose MACOG (Multi-Agent Code-Orchestrated Generation), a novel multi-agent LLM-based architecture for IaC generation that decomposes the task into modular subtasks handled by specialized agents: Architect, Provider Harmonizer, Engineer, Reviewer, Security Prover, Cost and Capacity Planner, DevOps, and Memory Curator. The agents interact via a shared-blackboard, finite-state orchestrator layer, and collectively produce Terraform configurations that are not only syntactically valid but also policy-compliant and semantically coherent. To ensure infrastructure correctness and governance, we incorporate Terraform Plan for execution validation and Open Policy Agent (OPA) for customizable policy enforcement. We evaluate MACOG using the IaC-Eval benchmark, where MACOG is the top enhancement across models, e.g., GPT-5 improves from 54.90 (RAG) to 74.02 and Gemini-2.5 Pro from 43.56 to 60.13, with concurrent gains on BLEU, CodeBERTScore, and an LLM-judge metric. Ablations show constrained decoding and deploy feedback are critical: removing them drops IaC-Eval to 64.89 and 56.93, respectively.",
        "tags": [
            "GPT",
            "LLM",
            "RAG"
        ]
    },
    {
        "id": "197",
        "title": "Zero-Shot Fine-Grained Image Classification Using Large Vision-Language Models",
        "author": [
            "Md. Atabuzzaman",
            "Andrew Zhang",
            "Chris Thomas"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03903",
        "abstract": "Large Vision-Language Models (LVLMs) have demonstrated impressive performance on vision-language reasoning tasks. However, their potential for zero-shot fine-grained image classification, a challenging task requiring precise differentiation between visually similar categories, remains underexplored. We present a novel method that transforms zero-shot fine-grained image classification into a visual question-answering framework, leveraging LVLMs' comprehensive understanding capabilities rather than relying on direct class name generation. We enhance model performance through a novel attention intervention technique. We also address a key limitation in existing datasets by developing more comprehensive and precise class description benchmarks. We validate the effectiveness of our method through extensive experimentation across multiple fine-grained image classification benchmarks. Our proposed method consistently outperforms the current state-of-the-art (SOTA) approach, demonstrating both the effectiveness of our method and the broader potential of LVLMs for zero-shot fine-grained classification tasks. Code and Datasets: https://github.com/Atabuzzaman/Fine-grained-classification",
        "tags": [
            "VLM"
        ]
    },
    {
        "id": "198",
        "title": "From Filters to VLMs: Benchmarking Defogging Methods through Object Detection and Segmentation Performance",
        "author": [
            "Ardalan Aryashad",
            "Parsa Razmara",
            "Amin Mahjoub",
            "Seyedarmin Azizi",
            "Mahdi Salmani",
            "Arad Firouzkouhi"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03906",
        "abstract": "Autonomous driving perception systems are particularly vulnerable in foggy conditions, where light scattering reduces contrast and obscures fine details critical for safe operation. While numerous defogging methods exist-from handcrafted filters to learned restoration models-improvements in image fidelity do not consistently translate into better downstream detection and segmentation. Moreover, prior evaluations often rely on synthetic data, leaving questions about real-world transferability. We present a structured empirical study that benchmarks a comprehensive set of pipelines, including (i) classical filters, (ii) modern defogging networks, (iii) chained variants (filter$\\rightarrow$model, model$\\rightarrow$filter), and (iv) prompt-driven visual--language image editing models (VLM) applied directly to foggy images. Using Foggy Cityscapes, we assess both image quality and downstream performance on object detection (mAP) and segmentation (PQ, RQ, SQ). Our analysis reveals when defogging helps, when chaining yields synergy or degradation, and how VLM-based editors compare to dedicated approaches. In addition, we evaluate qualitative rubric-based scores from a VLM judge and quantify their alignment with task metrics, showing strong correlations with mAP. Together, these results establish a transparent, task-oriented benchmark for defogging methods and highlight the conditions under which preprocessing genuinely improves autonomous perception in adverse weather.",
        "tags": [
            "Detection",
            "Image Editing",
            "Segmentation",
            "VLM"
        ]
    },
    {
        "id": "199",
        "title": "Generating Human Motion Videos using a Cascaded Text-to-Video Framework",
        "author": [
            "Hyelin Nam",
            "Hyojun Go",
            "Byeongjun Park",
            "Byung-Hoon Kim",
            "Hyungjin Chung"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03909",
        "abstract": "Human video generation is becoming an increasingly important task with broad applications in graphics, entertainment, and embodied AI. Despite the rapid progress of video diffusion models (VDMs), their use for general-purpose human video generation remains underexplored, with most works constrained to image-to-video setups or narrow domains like dance videos. In this work, we propose CAMEO, a cascaded framework for general human motion video generation. It seamlessly bridges Text-to-Motion (T2M) models and conditional VDMs, mitigating suboptimal factors that may arise in this process across both training and inference through carefully designed components. Specifically, we analyze and prepare both textual prompts and visual conditions to effectively train the VDM, ensuring robust alignment between motion descriptions, conditioning signals, and the generated videos. Furthermore, we introduce a camera-aware conditioning module that connects the two stages, automatically selecting viewpoints aligned with the input text to enhance coherence and reduce manual intervention. We demonstrate the effectiveness of our approach on both the MovieGen benchmark and a newly introduced benchmark tailored to the T2M-VDM combination, while highlighting its versatility across diverse use cases.",
        "tags": [
            "Diffusion",
            "Text-to-Video",
            "Video Generation"
        ]
    },
    {
        "id": "200",
        "title": "WAFFLE: A Wearable Approach to Bite Timing Estimation in Robot-Assisted Feeding",
        "author": [
            "Akhil Padmanabha",
            "Jessie Yuan",
            "Tanisha Mehta",
            "Rajat Kumar Jenamani",
            "Eric Hu",
            "Victoria de LeÃ³n",
            "Anthony Wertz",
            "Janavi Gupta",
            "Ben Dodson",
            "Yunting Yan",
            "Carmel Majidi",
            "Tapomayukh Bhattacharjee",
            "Zackory Erickson"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03910",
        "abstract": "Millions of people around the world need assistance with feeding. Robotic feeding systems offer the potential to enhance autonomy and quality of life for individuals with impairments and reduce caregiver workload. However, their widespread adoption has been limited by technical challenges such as estimating bite timing, the appropriate moment for the robot to transfer food to a user's mouth. In this work, we introduce WAFFLE: Wearable Approach For Feeding with LEarned bite timing, a system that accurately predicts bite timing by leveraging wearable sensor data to be highly reactive to natural user cues such as head movements, chewing, and talking. We train a supervised regression model on bite timing data from 14 participants and incorporate a user-adjustable assertiveness threshold to convert predictions into proceed or stop commands. In a study with 15 participants without motor impairments with the Obi feeding robot, WAFFLE performs statistically on par with or better than baseline methods across measures of feeling of control, robot understanding, and workload, and is preferred by the majority of participants for both individual and social dining. We further demonstrate WAFFLE's generalizability in a study with 2 participants with motor impairments in their home environments using a Kinova 7DOF robot. Our findings support WAFFLE's effectiveness in enabling natural, reactive bite timing that generalizes across users, robot hardware, robot positioning, feeding trajectories, foods, and both individual and social dining contexts.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "201",
        "title": "Generalized Fitted Q-Iteration with Clustered Data",
        "author": [
            "Liyuan Hu",
            "Jitao Wang",
            "Zhenke Wu",
            "Chengchun Shi"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03912",
        "abstract": "This paper focuses on reinforcement learning (RL) with clustered data, which is commonly encountered in healthcare applications. We propose a generalized fitted Q-iteration (FQI) algorithm that incorporates generalized estimating equations into policy learning to handle the intra-cluster correlations. Theoretically, we demonstrate (i) the optimalities of our Q-function and policy estimators when the correlation structure is correctly specified, and (ii) their consistencies when the structure is mis-specified. Empirically, through simulations and analyses of a mobile health dataset, we find the proposed generalized FQI achieves, on average, a half reduction in regret compared to the standard FQI.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "202",
        "title": "PsycholexTherapy: Simulating Reasoning in Psychotherapy with Small Language Models in Persian",
        "author": [
            "Mohammad Amin Abbasi",
            "Hassan Naderi"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03913",
        "abstract": "This study presents PsychoLexTherapy, a framework for simulating psychotherapeutic reasoning in Persian using small language models (SLMs). The framework tackles the challenge of developing culturally grounded, therapeutically coherent dialogue systems with structured memory for multi-turn interactions in underrepresented languages. To ensure privacy and feasibility, PsychoLexTherapy is optimized for on-device deployment, enabling use without external servers. Development followed a three-stage process: (i) assessing SLMs psychological knowledge with PsychoLexEval; (ii) designing and implementing the reasoning-oriented PsychoLexTherapy framework; and (iii) constructing two evaluation datasets-PsychoLexQuery (real Persian user questions) and PsychoLexDialogue (hybrid simulated sessions)-to benchmark against multiple baselines. Experiments compared simple prompting, multi-agent debate, and structured therapeutic reasoning paths. Results showed that deliberate model selection balanced accuracy, efficiency, and privacy. On PsychoLexQuery, PsychoLexTherapy outperformed all baselines in automatic LLM-as-a-judge evaluation and was ranked highest by human evaluators in a single-turn preference study. In multi-turn tests with PsychoLexDialogue, the long-term memory module proved essential: while naive history concatenation caused incoherence and information loss, the full framework achieved the highest ratings in empathy, coherence, cultural fit, and personalization. Overall, PsychoLexTherapy establishes a practical, privacy-preserving, and culturally aligned foundation for Persian psychotherapy simulation, contributing novel datasets, a reproducible evaluation pipeline, and empirical insights into structured memory for therapeutic reasoning.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "203",
        "title": "Refactoring with LLMs: Bridging Human Expertise and Machine Understanding",
        "author": [
            "Yonnel Chen Kuang Piao",
            "Jean Carlors Paul",
            "Leuson Da Silva",
            "Arghavan Moradi Dakhel",
            "Mohammad Hamdaqa",
            "Foutse Khomh"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03914",
        "abstract": "Code refactoring is a fundamental software engineering practice aimed at improving code quality and maintainability. Despite its importance, developers often neglect refactoring due to the significant time, effort, and resources it requires, as well as the lack of immediate functional rewards. Although several automated refactoring tools have been proposed, they remain limited in supporting a broad spectrum of refactoring types. In this study, we explore whether instruction strategies inspired by human best-practice guidelines can enhance the ability of Large Language Models (LLMs) to perform diverse refactoring tasks automatically. Leveraging the instruction-following and code comprehension capabilities of state-of-the-art LLMs (e.g., GPT-mini and DeepSeek-V3), we draw on Martin Fowler's refactoring guidelines to design multiple instruction strategies that encode motivations, procedural steps, and transformation objectives for 61 well-known refactoring types. We evaluate these strategies on benchmark examples and real-world code snippets from GitHub projects. Our results show that instruction designs grounded in Fowler's guidelines enable LLMs to successfully perform all benchmark refactoring types and preserve program semantics in real-world settings, an essential criterion for effective refactoring. Moreover, while descriptive instructions are more interpretable to humans, our results show that rule-based instructions often lead to better performance in specific scenarios. Interestingly, allowing models to focus on the overall goal of refactoring, rather than prescribing a fixed transformation type, can yield even greater improvements in code quality.",
        "tags": [
            "DeepSeek",
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "204",
        "title": "Talking Tennis: Language Feedback from 3D Biomechanical Action Recognition",
        "author": [
            "Arushi Dashore",
            "Aryan Anumala",
            "Emily Hui",
            "Olivia Yang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03921",
        "abstract": "Automated tennis stroke analysis has advanced significantly with the integration of biomechanical motion cues alongside deep learning techniques, enhancing stroke classification accuracy and player performance evaluation. Despite these advancements, existing systems often fail to connect biomechanical insights with actionable language feedback that is both accessible and meaningful to players and coaches. This research project addresses this gap by developing a novel framework that extracts key biomechanical features (such as joint angles, limb velocities, and kinetic chain patterns) from motion data using Convolutional Neural Network Long Short-Term Memory (CNN-LSTM)-based models. These features are analyzed for relationships influencing stroke effectiveness and injury risk, forming the basis for feedback generation using large language models (LLMs). Leveraging the THETIS dataset and feature extraction techniques, our approach aims to produce feedback that is technically accurate, biomechanically grounded, and actionable for end-users. The experimental setup evaluates this framework on classification performance and interpretability, bridging the gap between explainable AI and sports biomechanics.",
        "tags": [
            "3D",
            "LLM"
        ]
    },
    {
        "id": "205",
        "title": "High-order, Compact, and Symmetric Finite Difference Methods for a $d$-Dimensional Hypercube",
        "author": [
            "Qiwei Feng",
            "Bin Han",
            "Michelle Michelle",
            "Jiwoon Sim"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03927",
        "abstract": "This paper presents compact, symmetric, and high-order finite difference methods (FDMs) for the variable Poisson equation on a $d$-dimensional hypercube. Our scheme produces a symmetric linear system: an important property that does not immediately hold for a high-order FDM. Since the model problem is coercive, the linear system is in fact symmetric positive definite, and consequently many fast solvers are applicable. Furthermore, the symmetry combined with the minimum support of the stencil keeps the storage requirement minimal. Theoretically speaking, we prove that a compact, symmetric 1D FDM on a uniform grid can achieve arbitrary consistency order. On the other hand, in the $d$-dimensional setting, where $d \\ge 2$, the maximum consistency order that a compact, symmetric FDM on a uniform grid can achieve is 4. If $d=2$ and the diffusion coefficient satisfies a certain derivative condition, the maximum consistency order is 6. Moreover, the finite compact, symmetric, 4th-order FDMs for $d\\ge 3$, can be conveniently expressed as a linear combination of two types of FDMs: one that depends on partial derivatives along one axis, and the other along two axes. All finite difference stencils are explicitly provided for ease of reproducibility.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "206",
        "title": "Harnessing Synthetic Preference Data for Enhancing Temporal Understanding of Video-LLMs",
        "author": [
            "Sameep Vani",
            "Shreyas Jena",
            "Maitreya Patel",
            "Chitta Baral",
            "Somak Aditya",
            "Yezhou Yang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03955",
        "abstract": "While Video Large Language Models (Video-LLMs) have demonstrated remarkable performance across general video understanding benchmarks-particularly in video captioning and descriptive tasks-they consistently underperform on tasks that require fine-grained temporal understanding. This limitation arises due to the lack of visual complexity and temporal nuance in current fine-tuning datasets, leading these models to rely heavily on language-based reasoning rather than truly understanding video dynamics. In this work, we propose TimeWarp, a systematic method to create a targeted synthetic temporal dataset to fine-tune the model's responses to encourage it to focus on the given input video. We introduce a large-scale preference dataset, created using TimeWarp, that captures intricate temporal dynamics often overlooked, grounding the model's responses to visual and temporal information. We demonstrate that when our method is applied to existing models, it significantly improves performance on temporal understanding benchmarks, highlighting the effectiveness of our proposed datasets in advancing temporal understanding in Video-LLMs, resulting in an absolute improvement in performance across seven benchmarks. Code is available at https://github.com/sameepv21/timewarp.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "207",
        "title": "Optimizing Phase-Scheduling with Throughput Trade-offs in AQFP Digital Circuits",
        "author": [
            "Robert S. Aviles",
            "Peter A. Beerel"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03956",
        "abstract": "Adiabatic Quantum-Flux-Parametron (AQFP) logic is a promising emerging superconducting technology for ultra-low power digital circuits, offering orders of magnitude lower power consumption than CMOS. However, AQFP scalability is challenged by excessive buffer overhead due to path balancing technology constraints. Addressing this, recent AQFP works have proposed design solutions to reduce path balancing overhead using phase-skipping and phase-alignment. Phase-skipping is a circuit-level technique that allows data transfer between AQFP gates clocked with non-consecutive clock phases. In contrast, phase-alignment is an architectural approach involving repeating input patterns to allow data transfer between AQFP gates across multiples of full clock cycles. While both techniques individually mitigate the area overhead of path-balancing, they have not yet been jointly explored. In this work, we present the first clock phase scheduling algorithm that combines phase-skipping and phase-alignment. We first present a minimum area method that on average, achieves a 25% area reduction compared to phase-skipping alone and a 11% reduction compared to phase-alignment. We then extend the method to enforce a target throughput, enabling efficient area-performance trade-offs. With our throughput constrained optimization, we achieve on average 6.8% area savings with a 2.62x increased throughput compared to the state-of-the-art phase-aligned method.",
        "tags": [
            "FLUX"
        ]
    },
    {
        "id": "208",
        "title": "FinCall-Surprise: A Large Scale Multi-modal Benchmark for Earning Surprise Prediction",
        "author": [
            "Dong Shu",
            "Yanguang Liu",
            "Huopu Zhang",
            "Mengnan Du"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03965",
        "abstract": "Predicting corporate earnings surprises is a profitable yet challenging task, as accurate forecasts can inform significant investment decisions. However, progress in this domain has been constrained by a reliance on expensive, proprietary, and text-only data, limiting the development of advanced models. To address this gap, we introduce \\textbf{FinCall-Surprise} (Financial Conference Call for Earning Surprise Prediction), the first large-scale, open-source, and multi-modal dataset for earnings surprise prediction. Comprising 2,688 unique corporate conference calls from 2019 to 2021, our dataset features word-to-word conference call textual transcripts, full audio recordings, and corresponding presentation slides. We establish a comprehensive benchmark by evaluating 26 state-of-the-art unimodal and multi-modal LLMs. Our findings reveal that (1) while many models achieve high accuracy, this performance is often an illusion caused by significant class imbalance in the real-world data. (2) Some specialized financial models demonstrate unexpected weaknesses in instruction-following and language generation. (3) Although incorporating audio and visual modalities provides some performance gains, current models still struggle to leverage these signals effectively. These results highlight critical limitations in the financial reasoning capabilities of existing LLMs and establish a challenging new baseline for future research.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "209",
        "title": "Quantifying Risks in Multi-turn Conversation with Large Language Models",
        "author": [
            "Chengxiao Wang",
            "Isha Chaudhary",
            "Qian Hu",
            "Weitong Ruan",
            "Rahul Gupta",
            "Gagandeep Singh"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03969",
        "abstract": "Large Language Models (LLMs) can produce catastrophic responses in conversational settings that pose serious risks to public safety and security. Existing evaluations often fail to fully reveal these vulnerabilities because they rely on fixed attack prompt sequences, lack statistical guarantees, and do not scale to the vast space of multi-turn conversations. In this work, we propose QRLLM, a novel, principled Certification framework for Catastrophic risks in multi-turn Conversation for LLMs that bounds the probability of an LLM generating catastrophic responses under multi-turn conversation distributions with statistical guarantees. We model multi-turn conversations as probability distributions over query sequences, represented by a Markov process on a query graph whose edges encode semantic similarity to capture realistic conversational flow, and quantify catastrophic risks using confidence intervals. We define several inexpensive and practical distributions: random node, graph path, adaptive with rejection. Our results demonstrate that these distributions can reveal substantial catastrophic risks in frontier models, with certified lower bounds as high as 70\\% for the worst model, highlighting the urgent need for improved safety training strategies in frontier LLMs.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "210",
        "title": "What Can You Do When You Have Zero Rewards During RL?",
        "author": [
            "Jatin Prakash",
            "Anirudh Buvanesh"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03971",
        "abstract": "Reinforcement learning (RL) with outcome-based rewards has proven effective for improving large language models (LLMs) on complex reasoning tasks. However, its success often depends on the base model occasionally sampling correct solutions. When no correct solutions are sampled, training encounters a zero-reward barrier where learning stalls due to zero gradients. We study this scenario through the graph search task introduced in Bachmann et al. (2024) and evaluate recent methods that incorporate desirable components such as dense rewards, diversity incentives, and improved credit assignment. Our experiments show that none of these approaches overcome the zero-reward barrier if the base model never produces a correct answer. In contrast, we find that a simple data-centric intervention of adding easier samples to the training set enables the model to eventually solve the original hard task despite starting from zero reward. Importantly, this succeeds without modifying the RL algorithm itself. Because official implementations of several baselines were unavailable, we developed our own, which allowed us to conduct a detailed analysis of their failure modes. We release these implementations to support further research at: https://github.com/rl4reasoning/rl-baselines",
        "tags": [
            "LLM",
            "RL"
        ]
    },
    {
        "id": "211",
        "title": "No Tokens Wasted: Leveraging Long Context in Biomedical Vision-Language Models",
        "author": [
            "Min Woo Sun",
            "Alejandro Lozano",
            "Javier Gamazo Tejero",
            "Vishwesh Nath",
            "Xiao Xiao Sun",
            "James Burgess",
            "Yuhui Zhang",
            "Kun Yuan",
            "Robert Tibshirani",
            "Sean Huver",
            "Serena Yeung-Levy"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03978",
        "abstract": "Embedding vision-language models (VLMs) are typically pretrained with short text windows (<77 tokens), which forces the truncation of long-format captions. Yet, the distribution of biomedical captions from large-scale open source literature reveals that a huge portion of captions far exceed 77 tokens. To this end, we investigate the impact of pretraining on long-format biomedical captions by extending the context length of text encoders in VLMs. We find that longer context (thus, enabling additional supervision provided in long-format captions) correlates with better retrieval and classification performance. Given this finding, we introduce BIOMEDICA-LongCAP, a dataset of 1M image-caption pairs enriched with context-aware descriptions from full-text articles, providing longer and additional textual supervision. Using BIOMEDICA-LongCAP, we train BMC-LongCLIP, a long-context biomedical VLM with a text encoder supporting windows of up to 512 tokens. Our model extends context capacity by 6.6x, reducing token waste from 55% to just 2.2%. On long-caption retrieval benchmarks, BMC-LongCLIP achieves up to +30% absolute gains in Recall@1 and +2% average improvements in classification, while also converging faster than short-context. Our results demonstrate that long-context modeling is a promising direction for advancing biomedical VLMs.",
        "tags": [
            "VLM"
        ]
    },
    {
        "id": "212",
        "title": "Beyond Static Evaluation: Rethinking the Assessment of Personalized Agent Adaptability in Information Retrieval",
        "author": [
            "Kirandeep Kaur",
            "Preetam Prabhu Srikar Dammu",
            "Hideo Joho",
            "Chirag Shah"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03984",
        "abstract": "Personalized AI agents are becoming central to modern information retrieval, yet most evaluation methodologies remain static, relying on fixed benchmarks and one-off metrics that fail to reflect how users' needs evolve over time. These limitations hinder our ability to assess whether agents can meaningfully adapt to individuals across dynamic, longitudinal interactions. In this perspective paper, we propose a conceptual lens for rethinking evaluation in adaptive personalization, shifting the focus from static performance snapshots to interaction-aware, evolving assessments. We organize this lens around three core components: (1) persona-based user simulation with temporally evolving preference models; (2) structured elicitation protocols inspired by reference interviews to extract preferences in context; and (3) adaptation-aware evaluation mechanisms that measure how agent behavior improves across sessions and tasks. While recent works have embraced LLM-driven user simulation, we situate this practice within a broader paradigm for evaluating agents over time. To illustrate our ideas, we conduct a case study in e-commerce search using the PersonalWAB dataset. Beyond presenting a framework, our work lays a conceptual foundation for understanding and evaluating personalization as a continuous, user-centric endeavor.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "213",
        "title": "Distilling Reasoning into Student LLMs: Local Naturalness for Selecting Teacher Data",
        "author": [
            "Hoang Anh Just",
            "Myeongseob Ko",
            "Ruoxi Jia"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03988",
        "abstract": "Distilling long reasoning traces (10K+ tokens) from stronger teacher models into smaller student LLMs via SFT has emerged as a standard paradigm. This approach is practical and efficient: it leverages the ease of generating abundant reasoning data from stronger models and provides a direct, data-driven way to teach less capable models better reasoning. While previous work has largely focused on prompt selection with responses from a single teacher, the equally important problem of choosing the best response when multiple teacher outputs are available for a single prompt remains underexplored. This challenge becomes important in a multi-teacher setting, where different students may benefit from the outputs of different teachers. This paper fills that gap with a systematic study of response selection for reasoning distillation. We first show that the current method, which picks responses the student assigns the highest global log-probability (global naturalness), fails when responses come from multiple teachers, i.e., global naturalness no longer correlates with downstream performance, especially as the reasoning traces from strong teachers become longer. To overcome this problem, we introduce Local Naturalness, which measures the student's log-probabilities over short, sequential reasoning steps conditioned only on a small local window. Local Naturalness enables two applications: 1) Teacher Selection: Aggregating local scores across prompts reliably identifies the most helpful teacher. 2) Response Selection from a Multiple Teachers: When mixing answers from many teachers, Local Naturalness boosts a 32B student's accuracy on math benchmarks by 9.4pp over global selection, also surpassing the performance achieved by training on data from the single best teacher. These results highlight the power of localized data quality evaluation and data mixing for more effective reasoning distillation.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "214",
        "title": "A Mathematical Explanation of Transformers for Large Language Models and GPTs",
        "author": [
            "Xue-Cheng Tai",
            "Hao Liu",
            "Lingfeng Li",
            "Raymond H. Chan"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03989",
        "abstract": "The Transformer architecture has revolutionized the field of sequence modeling and underpins the recent breakthroughs in large language models (LLMs). However, a comprehensive mathematical theory that explains its structure and operations remains elusive. In this work, we propose a novel continuous framework that rigorously interprets the Transformer as a discretization of a structured integro-differential equation. Within this formulation, the self-attention mechanism emerges naturally as a non-local integral operator, and layer normalization is characterized as a projection to a time-dependent constraint. This operator-theoretic and variational perspective offers a unified and interpretable foundation for understanding the architecture's core components, including attention, feedforward layers, and normalization. Our approach extends beyond previous theoretical analyses by embedding the entire Transformer operation in continuous domains for both token indices and feature dimensions. This leads to a principled and flexible framework that not only deepens theoretical insight but also offers new directions for architecture design, analysis, and control-based interpretations. This new interpretation provides a step toward bridging the gap between deep learning architectures and continuous mathematical modeling, and contributes a foundational perspective to the ongoing development of interpretable and theoretically grounded neural network models.",
        "tags": [
            "LLM",
            "Transformer"
        ]
    },
    {
        "id": "215",
        "title": "Quantifying Distributional Robustness of Agentic Tool-Selection",
        "author": [
            "Jehyeok Yeon",
            "Isha Chaudhary",
            "Gagandeep Singh"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03992",
        "abstract": "Large language models (LLMs) are increasingly deployed in agentic systems where they map user intents to relevant external tools to fulfill a task. A critical step in this process is tool selection, where a retriever first surfaces candidate tools from a larger pool, after which the LLM selects the most appropriate one. This pipeline presents an underexplored attack surface where errors in selection can lead to severe outcomes like unauthorized data access or denial of service, all without modifying the agent's model or code. While existing evaluations measure task performance in benign settings, they overlook the specific vulnerabilities of the tool selection mechanism under adversarial conditions. To address this gap, we introduce ToolCert, the first statistical framework that formally certifies tool selection robustness. ToolCert models tool selection as a Bernoulli success process and evaluates it against a strong, adaptive attacker who introduces adversarial tools with misleading metadata, and are iteratively refined based on the agent's previous choices. By sampling these adversarial interactions, ToolCert produces a high-confidence lower bound on accuracy, formally quantifying the agent's worst-case performance. Our evaluation with ToolCert uncovers the severe fragility: under attacks injecting deceptive tools or saturating retrieval, the certified accuracy bound drops near zero, an average performance drop of over 60% compared to non-adversarial settings. For attacks targeting the retrieval and selection stages, the certified accuracy bound plummets to less than 20% after just a single round of adversarial adaptation. ToolCert thus reveals previously unexamined security threats inherent to tool selection and provides a principled method to quantify an agent's robustness to such threats, a necessary step for the safe deployment of agentic systems.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "216",
        "title": "Mapping Patient-Perceived Physician Traits from Nationwide Online Reviews with LLMs",
        "author": [
            "Junjie Luo",
            "Rui Han",
            "Arshana Welivita",
            "Zeleikun Di",
            "Jingfu Wu",
            "Xuzhe Zhi",
            "Ritu Agarwal",
            "Gordon Gao"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03997",
        "abstract": "Understanding how patients perceive their physicians is essential to improving trust, communication, and satisfaction. We present a large language model (LLM)-based pipeline that infers Big Five personality traits and five patient-oriented subjective judgments. The analysis encompasses 4.1 million patient reviews of 226,999 U.S. physicians from an initial pool of one million. We validate the method through multi-model comparison and human expert benchmarking, achieving strong agreement between human and LLM assessments (correlation coefficients 0.72-0.89) and external validity through correlations with patient satisfaction (r = 0.41-0.81, all p<0.001). National-scale analysis reveals systematic patterns: male physicians receive higher ratings across all traits, with largest disparities in clinical competence perceptions; empathy-related traits predominate in pediatrics and psychiatry; and all traits positively predict overall satisfaction. Cluster analysis identifies four distinct physician archetypes, from \"Well-Rounded Excellent\" (33.8%, uniformly high traits) to \"Underperforming\" (22.6%, consistently low). These findings demonstrate that automated trait extraction from patient narratives can provide interpretable, validated metrics for understanding physician-patient relationships at scale, with implications for quality measurement, bias detection, and workforce development in healthcare.",
        "tags": [
            "Detection",
            "LLM"
        ]
    },
    {
        "id": "217",
        "title": "Simulating and Understanding Deceptive Behaviors in Long-Horizon Interactions",
        "author": [
            "Yang Xu",
            "Xuanming Zhang",
            "Min-Hsuan Yeh",
            "Jwala Dhamala",
            "Ousmane Dia",
            "Rahul Gupta",
            "Yixuan Li"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03999",
        "abstract": "Deception is a pervasive feature of human communication and an emerging concern in large language models (LLMs). While recent studies document instances of LLM deception under pressure, most evaluations remain confined to single-turn prompts and fail to capture the long-horizon interactions in which deceptive strategies typically unfold. We introduce the first simulation framework for probing and evaluating deception in LLMs under extended sequences of interdependent tasks and dynamic contextual pressures. Our framework instantiates a multi-agent system: a performer agent tasked with completing tasks and a supervisor agent that evaluates progress, provides feedback, and maintains evolving states of trust. An independent deception auditor then reviews full trajectories to identify when and how deception occurs. We conduct extensive experiments across 11 frontier models, spanning both closed- and open-source systems, and find that deception is model-dependent, increases with event pressure, and consistently erodes supervisor trust. Qualitative analyses further reveal distinct strategies of concealment, equivocation, and falsification. Our findings establish deception as an emergent risk in long-horizon interactions and provide a foundation for evaluating future LLMs in real-world, trust-sensitive contexts.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "218",
        "title": "AgriGPT-VL: Agricultural Vision-Language Understanding Suite",
        "author": [
            "Bo Yang",
            "Yunkui Chen",
            "Lanfei Feng",
            "Yu Zhang",
            "Xiao Xu",
            "Jianyu Zhang",
            "Nueraili Aierken",
            "Runhe Huang",
            "Hongjian Lin",
            "Yibin Ying",
            "Shijian Li"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04002",
        "abstract": "Despite rapid advances in multimodal large language models, agricultural applications remain constrained by the scarcity of domain-tailored models, curated vision-language corpora, and rigorous evaluation. To address these challenges, we present the AgriGPT-VL Suite, a unified multimodal framework for agriculture. Our contributions are threefold. First, we introduce Agri-3M-VL, the largest vision-language corpus for agriculture to our knowledge, curated by a scalable multi-agent data generator; it comprises 1M image-caption pairs, 2M image-grounded VQA pairs, 50K expert-level VQA instances, and 15K GRPO reinforcement learning samples. Second, we develop AgriGPT-VL, an agriculture-specialized vision-language model trained via a progressive curriculum of textual grounding, multimodal shallow/deep alignment, and GRPO refinement. This method achieves strong multimodal reasoning while preserving text-only capability. Third, we establish AgriBench-VL-4K, a compact yet challenging evaluation suite with open-ended and image-grounded questions, paired with multi-metric evaluation and an LLM-as-a-judge framework. Experiments show that AgriGPT-VL outperforms leading general-purpose VLMs on AgriBench-VL-4K, achieving higher pairwise win rates in the LLM-as-a-judge evaluation. Meanwhile, it remains competitive on the text-only AgriBench-13K with no noticeable degradation of language ability. Ablation studies further confirm consistent gains from our alignment and GRPO refinement stages. We will open source all of the resources to support reproducible research and deployment in low-resource agricultural settings.",
        "tags": [
            "GRPO",
            "LLM",
            "RL",
            "VLM"
        ]
    },
    {
        "id": "219",
        "title": "LLM Microscope: What Model Internals Reveal About Answer Correctness and Context Utilization",
        "author": [
            "Jiarui Liu",
            "Jivitesh Jain",
            "Mona Diab",
            "Nishant Subramani"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04013",
        "abstract": "Although large language models (LLMs) have tremendous utility, trustworthiness is still a chief concern: models often generate incorrect information with high confidence. While contextual information can help guide generation, identifying when a query would benefit from retrieved context and assessing the effectiveness of that context remains challenging. In this work, we operationalize interpretability methods to ascertain whether we can predict the correctness of model outputs from the model's activations alone. We also explore whether model internals contain signals about the efficacy of external context. We consider correct, incorrect, and irrelevant context and introduce metrics to distinguish amongst them. Experiments on six different models reveal that a simple classifier trained on intermediate layer activations of the first output token can predict output correctness with about 75% accuracy, enabling early auditing. Our model-internals-based metric significantly outperforms prompting baselines at distinguishing between correct and incorrect context, guarding against inaccuracies introduced by polluted context. These findings offer a lens to better understand the underlying decision-making processes of LLMs. Our code is publicly available at https://github.com/jiarui-liu/LLM-Microscope",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "220",
        "title": "Thai Semantic End-of-Turn Detection for Real-Time Voice Agents",
        "author": [
            "Thanapol Popit",
            "Natthapath Rungseesiripak",
            "Monthol Charattrakool",
            "Saksorn Ruangtanusak"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04016",
        "abstract": "Fluid voice-to-voice interaction requires reliable and low-latency detection of when a user has finished speaking. Traditional audio-silence end-pointers add hundreds of milliseconds of delay and fail under hesitations or language-specific phenomena. We present, to our knowledge, the first systematic study of Thai text-only end-of-turn (EOT) detection for real-time agents. We compare zero-shot and few-shot prompting of compact LLMs to supervised fine-tuning of lightweight transformers. Using transcribed subtitles from the YODAS corpus and Thai-specific linguistic cues (e.g., sentence-final particles), we formulate EOT as a binary decision over token boundaries. We report a clear accuracy-latency tradeoff and provide a public-ready implementation plan. This work establishes a Thai baseline and demonstrates that small, fine-tuned models can deliver near-instant EOT decisions suitable for on-device agents.",
        "tags": [
            "Detection",
            "LLM"
        ]
    },
    {
        "id": "221",
        "title": "Zephyrus: An Agentic Framework for Weather Science",
        "author": [
            "Sumanth Varambally",
            "Marshall Fisher",
            "Jas Thakker",
            "Yiwei Chen",
            "Zhirui Xia",
            "Yasaman Jafari",
            "Ruijia Niu",
            "Manas Jain",
            "Veeramakali Vignesh Manivannan",
            "Zachary Novack",
            "Luyu Han",
            "Srikar Eranky",
            "Salva RÃ¼hling Cachay",
            "Taylor Berg-Kirkpatrick",
            "Duncan Watson-Parris",
            "Yi-An Ma",
            "Rose Yu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04017",
        "abstract": "Foundation models for weather science are pre-trained on vast amounts of structured numerical data and outperform traditional weather forecasting systems. However, these models lack language-based reasoning capabilities, limiting their utility in interactive scientific workflows. Large language models (LLMs) excel at understanding and generating text but cannot reason about high-dimensional meteorological datasets. We bridge this gap by building a novel agentic framework for weather science. Our framework includes a Python code-based environment for agents (ZephyrusWorld) to interact with weather data, featuring tools like an interface to WeatherBench 2 dataset, geoquerying for geographical masks from natural language, weather forecasting, and climate simulation capabilities. We design Zephyrus, a multi-turn LLM-based weather agent that iteratively analyzes weather datasets, observes results, and refines its approach through conversational feedback loops. We accompany the agent with a new benchmark, ZephyrusBench, with a scalable data generation pipeline that constructs diverse question-answer pairs across weather-related tasks, from basic lookups to advanced forecasting, extreme event detection, and counterfactual reasoning. Experiments on this benchmark demonstrate the strong performance of Zephyrus agents over text-only baselines, outperforming them by up to 35 percentage points in correctness. However, on harder tasks, Zephyrus performs similarly to text-only baselines, highlighting the challenging nature of our benchmark and suggesting promising directions for future work.",
        "tags": [
            "Detection",
            "LLM"
        ]
    },
    {
        "id": "222",
        "title": "Principled and Tractable RL for Reasoning with Diffusion Language Models",
        "author": [
            "Anthony Zhan"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04019",
        "abstract": "Diffusion large language models (dLLMs) are a new paradigm of non-autoregressive language models that are trained to predict multiple tokens in parallel and generate text via iterative unmasking. Recent works have successfully pretrained dLLMs to parity with autoregressive LLMs at the 8B scale, but dLLMs have yet to benefit from modern post-training techniques, e.g. reinforcement learning (RL), that have proven effective for autoregressive models. Crucially, algorithms designed for traditional LLMs aren't directly compatible with diffusion frameworks due to inherent differences in modeling assumptions. Moreover, existing attempts at dLLM post-training with RL rely on heuristic-based objectives with no theoretical grounding. In this work, we present Amortized Group Relative Policy Optimization (AGRPO), a principled on-policy RL algorithm designed specifically for dLLMs. AGRPO uses Monte Carlo sampling to compute an unbiased policy gradient estimate, making it the first tractable, faithful adaptation of policy gradient methods for dLLMs. We demonstrate AGRPO's effectiveness on different math/reasoning tasks, a common setting for RL with LLMs, achieving up to +7.6% absolute gain on GSM8K and 3.8x performance on the Countdown task over the baseline LLaDA-8B-Instruct model and 1.3x performance gains over comparable RL methods such as diffu-GRPO. Furthermore, these gains persist across different numbers of sampling steps at inference time, achieving better tradeoffs between compute and performance. Our results demonstrate that online RL algorithms can be extended to diffusion LLMs in principled ways, maintaining both theoretical soundness and practical effectiveness.",
        "tags": [
            "Diffusion",
            "GRPO",
            "LLM",
            "RL"
        ]
    },
    {
        "id": "223",
        "title": "Spatiotemporal Forecasting as Planning: A Model-Based Reinforcement Learning Approach with Generative World Models",
        "author": [
            "Hao Wu",
            "Yuan Gao",
            "Xingjian Shi",
            "Shuaipeng Li",
            "Fan Xu",
            "Fan Zhang",
            "Zhihong Zhu",
            "Weiyan Wang",
            "Xiao Luo",
            "Kun Wang",
            "Xian Wu",
            "Xiaomeng Huang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04020",
        "abstract": "To address the dual challenges of inherent stochasticity and non-differentiable metrics in physical spatiotemporal forecasting, we propose Spatiotemporal Forecasting as Planning (SFP), a new paradigm grounded in Model-Based Reinforcement Learning. SFP constructs a novel Generative World Model to simulate diverse, high-fidelity future states, enabling an \"imagination-based\" environmental simulation. Within this framework, a base forecasting model acts as an agent, guided by a beam search-based planning algorithm that leverages non-differentiable domain metrics as reward signals to explore high-return future sequences. These identified high-reward candidates then serve as pseudo-labels to continuously optimize the agent's policy through iterative self-training, significantly reducing prediction error and demonstrating exceptional performance on critical domain metrics like capturing extreme events.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "224",
        "title": "LLM-Based Data Science Agents: A Survey of Capabilities, Challenges, and Future Directions",
        "author": [
            "Mizanur Rahman",
            "Amran Bhuiyan",
            "Mohammed Saidul Islam",
            "Md Tahmid Rahman Laskar",
            "Ridwan Mahbub",
            "Ahmed Masry",
            "Shafiq Joty",
            "Enamul Hoque"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04023",
        "abstract": "Recent advances in large language models (LLMs) have enabled a new class of AI agents that automate multiple stages of the data science workflow by integrating planning, tool use, and multimodal reasoning across text, code, tables, and visuals. This survey presents the first comprehensive, lifecycle-aligned taxonomy of data science agents, systematically analyzing and mapping forty-five systems onto the six stages of the end-to-end data science process: business understanding and data acquisition, exploratory analysis and visualization, feature engineering, model building and selection, interpretation and explanation, and deployment and monitoring. In addition to lifecycle coverage, we annotate each agent along five cross-cutting design dimensions: reasoning and planning style, modality integration, tool orchestration depth, learning and alignment methods, and trust, safety, and governance mechanisms. Beyond classification, we provide a critical synthesis of agent capabilities, highlight strengths and limitations at each stage, and review emerging benchmarks and evaluation practices. Our analysis identifies three key trends: most systems emphasize exploratory analysis, visualization, and modeling while neglecting business understanding, deployment, and monitoring; multimodal reasoning and tool orchestration remain unresolved challenges; and over 90% lack explicit trust and safety mechanisms. We conclude by outlining open challenges in alignment stability, explainability, governance, and robust evaluation frameworks, and propose future research directions to guide the development of robust, trustworthy, low-latency, transparent, and broadly accessible data science agents.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "225",
        "title": "Enhancing Fake News Video Detection via LLM-Driven Creative Process Simulation",
        "author": [
            "Yuyan Bu",
            "Qiang Sheng",
            "Juan Cao",
            "Shaofei Wang",
            "Peng Qi",
            "Yuhui Shi",
            "Beizhe Hu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04024",
        "abstract": "The emergence of fake news on short video platforms has become a new significant societal concern, necessitating automatic video-news-specific detection. Current detectors primarily rely on pattern-based features to separate fake news videos from real ones. However, limited and less diversified training data lead to biased patterns and hinder their performance. This weakness stems from the complex many-to-many relationships between video material segments and fabricated news events in real-world scenarios: a single video clip can be utilized in multiple ways to create different fake narratives, while a single fabricated event often combines multiple distinct video segments. However, existing datasets do not adequately reflect such relationships due to the difficulty of collecting and annotating large-scale real-world data, resulting in sparse coverage and non-comprehensive learning of the characteristics of potential fake news video creation. To address this issue, we propose a data augmentation framework, AgentAug, that generates diverse fake news videos by simulating typical creative processes. AgentAug implements multiple LLM-driven pipelines of four fabrication categories for news video creation, combined with an active learning strategy based on uncertainty sampling to select the potentially useful augmented samples during training. Experimental results on two benchmark datasets demonstrate that AgentAug consistently improves the performance of short video fake news detectors.",
        "tags": [
            "CLIP",
            "Detection",
            "LLM"
        ]
    },
    {
        "id": "226",
        "title": "The Debate on RLVR Reasoning Capability Boundary: Shrinkage, Expansion, or Both? A Two-Stage Dynamic View",
        "author": [
            "Xinhao Yao",
            "Lu Yu",
            "Xiaolin Hu",
            "Fengwei Teng",
            "Qing Cui",
            "Jun Zhou",
            "Yong Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04028",
        "abstract": "The ongoing debate on whether reinforcement learning with verifiable rewards (RLVR) expands or shrinks the reasoning capabilities of large language models (LLMs) remains unresolved. Some studies contend that RLVR mainly improves sampling efficiency but at the expense of diversity and exploratory capacity, resulting in capability boundary shrinkage. In contrast, others demonstrate that prolonged training can lead to the emergence of novel reasoning strategies, suggesting capability boundary expansion. To reconcile these contradictory findings, we theoretically and empirically show that both perspectives are partially valid-each aligning with a separate phase in an inherent two-stage probability mass dynamic: (1) Exploitation stage: initially, the model primarily samples explored high-reward and low-reward tokens, while rarely selecting the potentially optimal token. Positive advantage estimates increase the probability of high-reward tokens and decrease those of low-reward tokens, yet the optimal token's probability remains largely unchanged during this stage. (2) Exploration stage: as training advances, the growth rate of previously acquired high-reward tokens slows as their probabilities approach saturation. When a potentially optimal token-now receiving positive advantage estimates-is occasionally sampled, its probability increases, while those of the originally high-reward tokens decrease. This dynamic suggests that over-exploitation during the exploitation stage may lead to capability boundary shrinkage, whereas prolonged training into the exploration stage can promote an expansion of the reasoning capability boundary. Building upon our insights, we revisit the potential of only using relative negative gradients for prolonging training, providing a theoretical and empirical foundation for the development of more advanced reasoning capabilities.",
        "tags": [
            "LLM",
            "RL"
        ]
    },
    {
        "id": "227",
        "title": "Does Using Counterfactual Help LLMs Explain Textual Importance in Classification?",
        "author": [
            "Nelvin Tan",
            "James Asikin Cheung",
            "Yu-Ching Shih",
            "Dong Yang",
            "Amol Salunkhe"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04031",
        "abstract": "Large language models (LLMs) are becoming useful in many domains due to their impressive abilities that arise from large training datasets and large model sizes. More recently, they have been shown to be very effective in textual classification tasks, motivating the need to explain the LLMs' decisions. Motivated by practical constrains where LLMs are black-boxed and LLM calls are expensive, we study how incorporating counterfactuals into LLM reasoning can affect the LLM's ability to identify the top words that have contributed to its classification decision. To this end, we introduce a framework called the decision changing rate that helps us quantify the importance of the top words in classification. Our experimental results show that using counterfactuals can be helpful.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "228",
        "title": "Prompt-to-Prompt: Text-Based Image Editing Via Cross-Attention Mechanisms -- The Research of Hyperparameters and Novel Mechanisms to Enhance Existing Frameworks",
        "author": [
            "Linn Bieske",
            "Carla Lorente"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04034",
        "abstract": "Recent advances in image editing have shifted from manual pixel manipulation to employing deep learning methods like stable diffusion models, which now leverage cross-attention mechanisms for text-driven control. This transition has simplified the editing process but also introduced variability in results, such as inconsistent hair color changes. Our research aims to enhance the precision and reliability of prompt-to-prompt image editing frameworks by exploring and optimizing hyperparameters. We present a comprehensive study of the \"word swap\" method, develop an \"attention re-weight method\" for better adaptability, and propose the \"CL P2P\" framework to address existing limitations like cycle inconsistency. This work contributes to understanding and improving the interaction between hyperparameter settings and the architectural choices of neural network models, specifically their attention mechanisms, which significantly influence the composition and quality of the generated images.",
        "tags": [
            "Diffusion",
            "Image Editing"
        ]
    },
    {
        "id": "229",
        "title": "\\textsc{GUI-Spotlight}: Adaptive Iterative Focus Refinement for Enhanced GUI Visual Grounding",
        "author": [
            "Bin Lei",
            "Nuo Xu",
            "Ali Payani",
            "Mingyi Hong",
            "Chunhua Liao",
            "Yu Cao",
            "Caiwen Ding"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04039",
        "abstract": "Multimodal large language models (MLLMs) have markedly expanded the competence of graphical user-interface (GUI) systems, propelling them beyond controlled simulations into complex, real-world environments across diverse platforms. However, practical usefulness is still bounded by the reliability of visual grounding, i.e., mapping textual references to exact on-screen elements. This limitation prevents the system from accurately performing pointer-level actions such as clicking or dragging. To address it, we introduce GUI-Spotlight -- a model trained for image-grounded reasoning that dynamically invokes multiple specialized tools to iteratively narrow its focus to the relevant region of the screen, thereby substantially improving visual grounding accuracy. On the ScreenSpot-Pro benchmark, GUI-Spotlight trained with only 18.5K training samples achieves 52.8\\% accuracy, surpassing V2P-7B (50.6\\% with 9.6M training samples) and GTA-1-7B (50.1\\% with 1.56M training samples).",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "230",
        "title": "FaithCoT-Bench: Benchmarking Instance-Level Faithfulness of Chain-of-Thought Reasoning",
        "author": [
            "Xu Shen",
            "Song Wang",
            "Zhen Tan",
            "Laura Yao",
            "Xinyu Zhao",
            "Kaidi Xu",
            "Xin Wang",
            "Tianlong Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04040",
        "abstract": "Large language models (LLMs) increasingly rely on Chain-of-Thought (CoT) prompting to improve problem-solving and provide seemingly transparent explanations. However, growing evidence shows that CoT often fail to faithfully represent the underlying reasoning process, raising concerns about their reliability in high-risk applications. Although prior studies have focused on mechanism-level analyses showing that CoTs can be unfaithful, they leave open the practical challenge of deciding whether a specific trajectory is faithful to the internal reasoning of the model. To address this gap, we introduce FaithCoT-Bench, a unified benchmark for instance-level CoT unfaithfulness detection. Our framework establishes a rigorous task formulation that formulates unfaithfulness detection as a discriminative decision problem, and provides FINE-CoT (Faithfulness instance evaluation for Chain-of-Thought), an expert-annotated collection of over 1,000 trajectories generated by four representative LLMs across four domains, including more than 300 unfaithful instances with fine-grained causes and step-level evidence. We further conduct a systematic evaluation of eleven representative detection methods spanning counterfactual, logit-based, and LLM-as-judge paradigms, deriving empirical insights that clarify the strengths and weaknesses of existing approaches and reveal the increased challenges of detection in knowledge-intensive domains and with more advanced models. To the best of our knowledge, FaithCoT-Bench establishes the first comprehensive benchmark for instance-level CoT faithfulness, setting a solid basis for future research toward more interpretable and trustworthy reasoning in LLMs.",
        "tags": [
            "CoT",
            "Detection",
            "LLM"
        ]
    },
    {
        "id": "231",
        "title": "SITCOM: Scaling Inference-Time COMpute for VLAs",
        "author": [
            "Ayudh Saxena",
            "Harsh Shah",
            "Sandeep Routray",
            "Rishi Rajesh Shah",
            "Esha Pahwa"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04041",
        "abstract": "Learning robust robotic control policies remains a major challenge due to the high cost of collecting labeled data, limited generalization to unseen environments, and difficulties in planning over long horizons. While Vision-Language-Action (VLA) models offer a promising solution by grounding natural language instructions into single-step control commands, they often lack mechanisms for lookahead and struggle with compounding errors in dynamic tasks. In this project, we introduce Scaling Inference-Time COMpute for VLAs (SITCOM), a framework that augments any pretrained VLA with model-based rollouts and reward-based trajectory selection, inspired by Model Predictive Control algorithm. SITCOM leverages a learned dynamics model to simulate multi-step action rollouts to select the best candidate plan for real-world execution, transforming one-shot VLAs into robust long-horizon planners. We develop an efficient transformer-based dynamics model trained on large-scale BridgeV2 data and fine-tuned on SIMPLER environments to bridge the Real2Sim gap, and score candidate rollouts using rewards from simulator. Through comprehensive evaluation across multiple tasks and settings in the SIMPLER environment, we demonstrate that SITCOM when combined with a good reward function can significantly improve task completion rate from 48% to 72% using trained dynamics model.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "232",
        "title": "Exploring Chain-of-Thought Reasoning for Steerable Pluralistic Alignment",
        "author": [
            "Yunfan Zhang",
            "Kathleen McKeown",
            "Smaranda Muresan"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04045",
        "abstract": "Large Language Models (LLMs) are typically trained to reflect a relatively uniform set of values, which limits their applicability to tasks that require understanding of nuanced human perspectives. Recent research has underscored the importance of enabling LLMs to support steerable pluralism -- the capacity to adopt a specific perspective and align generated outputs with it. In this work, we investigate whether Chain-of-Thought (CoT) reasoning techniques can be applied to building steerable pluralistic models. We explore several methods, including CoT prompting, fine-tuning on human-authored CoT, fine-tuning on synthetic explanations, and Reinforcement Learning with Verifiable Rewards (RLVR). We evaluate these approaches using the Value Kaleidoscope and OpinionQA datasets. Among the methods studied, RLVR consistently outperforms others and demonstrates strong training sample efficiency. We further analyze the generated CoT traces with respect to faithfulness and safety.",
        "tags": [
            "CoT",
            "LLM",
            "RL"
        ]
    },
    {
        "id": "233",
        "title": "Increasing LLM response trustworthiness using voting ensembles",
        "author": [
            "Aparna Nair-Kanneganti",
            "Trevor J. Chan",
            "Shir Goldfinger",
            "Emily Mackay",
            "Brian Anthony",
            "Alison Pouch"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04048",
        "abstract": "Despite huge advances, LLMs still lack convenient and reliable methods to quantify the uncertainty in their responses, making them difficult to trust in high-stakes applications. One of the simplest approaches to eliciting more accurate answers is to select the mode of many responses, a technique known as ensembling. In this work, we expand on typical ensembling approaches by looking at ensembles with a variable voting threshold. We introduce a theoretical framework for question answering and show that, by permitting ensembles to \"abstain\" from providing an answer when the dominant response falls short of the threshold, it is possible to dramatically increase the trustworthiness of the remaining answers. From this framework, we derive theoretical results as well as report experimental results on two problem domains: arithmetic problem solving and clinical-note question-answering. In both domains, we observe that large gains in answer trustworthiness can be achieved using highly restrictive voting ensembles, while incurring relatively modest reductions in response yield and accuracy. Due to this quality, voting ensembles may be particularly useful in applications - such as healthcare and data annotation - that require a high degree of certainty but which may not require that every question receive an automated answer.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "234",
        "title": "Toward a unified framework for data-efficient evaluation of large language models",
        "author": [
            "Lele Liao",
            "Qile Zhang",
            "Ruofan Wu",
            "Guanhua Fang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04051",
        "abstract": "Evaluating large language models (LLMs) on comprehensive benchmarks is a cornerstone of their development, yet it's often computationally and financially prohibitive. While Item Response Theory (IRT) offers a promising path toward data-efficient evaluation by disentangling model capability from item difficulty, existing IRT-based methods are hampered by significant limitations. They are typically restricted to binary correctness metrics, failing to natively handle the continuous scores used in generative tasks, and they operate on single benchmarks, ignoring valuable structural knowledge like correlations across different metrics or benchmarks. To overcome these challenges, we introduce LEGO-IRT, a unified and flexible framework for data-efficient LLM evaluation. LEGO-IRT's novel design natively supports both binary and continuous evaluation metrics. Moreover, it introduces a factorized architecture to explicitly model and leverage structural knowledge, decomposing model ability estimates into a general component and structure-specific (e.g., per-metric or per-benchmark) components. Through extensive experiments involving $70$ LLMs across $5$ benchmarks, we show that LEGO-IRT achieves stable capability estimates using just $3\\%$ of the total evaluation items. We demonstrate that incorporating structural knowledge reduces estimation error by up to $10\\%$ and reveal that the latent abilities estimated by our framework may align more closely with human preferences.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "235",
        "title": "Real-VulLLM: An LLM Based Assessment Framework in the Wild",
        "author": [
            "Rijha Safdar",
            "Danyail Mateen",
            "Syed Taha Ali",
            "Wajahat Hussain"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04056",
        "abstract": "Artificial Intelligence (AI) and more specifically Large Language Models (LLMs) have demonstrated exceptional progress in multiple areas including software engineering, however, their capability for vulnerability detection in the wild scenario and its corresponding reasoning remains underexplored. Prompting pre-trained LLMs in an effective way offers a computationally effective and scalable solution. Our contributions are (i)varied prompt designs for vulnerability detection and its corresponding reasoning in the wild. (ii)a real-world vector data store constructed from the National Vulnerability Database, that will provide real time context to vulnerability detection framework, and (iii)a scoring measure for combined measurement of accuracy and reasoning quality. Our contribution aims to examine whether LLMs are ready for wild deployment, thus enabling the reliable use of LLMs stronger for the development of secure software's.",
        "tags": [
            "Detection",
            "LLM"
        ]
    },
    {
        "id": "236",
        "title": "Variational Diffusion Unlearning: A Variational Inference Framework for Unlearning in Diffusion Models under Data Constraints",
        "author": [
            "Subhodip Panda",
            "MS Varun",
            "Shreyans Jain",
            "Sarthak Kumar Maharana",
            "Prathosh A.P"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04058",
        "abstract": "For a responsible and safe deployment of diffusion models in various domains, regulating the generated outputs from these models is desirable because such models could generate undesired, violent, and obscene outputs. To tackle this problem, recent works use machine unlearning methodology to forget training data points containing these undesired features from pre-trained generative models. However, these methods proved to be ineffective in data-constrained settings where the whole training dataset is inaccessible. Thus, the principal objective of this work is to propose a machine unlearning methodology that can prevent the generation of outputs containing undesired features from a pre-trained diffusion model in such a data-constrained setting. Our proposed method, termed as Variational Diffusion Unlearning (VDU), is a computationally efficient method that only requires access to a subset of training data containing undesired features. Our approach is inspired by the variational inference framework with the objective of minimizing a loss function consisting of two terms: plasticity inducer and stability regularizer. Plasticity inducer reduces the log-likelihood of the undesired training data points, while the stability regularizer, essential for preventing loss of image generation quality, regularizes the model in parameter space. We validate the effectiveness of our method through comprehensive experiments for both class unlearning and feature unlearning. For class unlearning, we unlearn some user-identified classes from MNIST, CIFAR-10, and tinyImageNet datasets from a pre-trained unconditional denoising diffusion probabilistic model (DDPM). Similarly, for feature unlearning, we unlearn the generation of certain high-level features from a pre-trained Stable Diffusion model",
        "tags": [
            "DDPM",
            "Diffusion"
        ]
    },
    {
        "id": "237",
        "title": "Decoding Emotion in the Deep: A Systematic Study of How LLMs Represent, Retain, and Express Emotion",
        "author": [
            "Jingxiang Zhang",
            "Lujia Zhong"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04064",
        "abstract": "Large Language Models (LLMs) are increasingly expected to navigate the nuances of human emotion. While research confirms that LLMs can simulate emotional intelligence, their internal emotional mechanisms remain largely unexplored. This paper investigates the latent emotional representations within modern LLMs by asking: how, where, and for how long is emotion encoded in their neural architecture? To address this, we introduce a novel, large-scale Reddit corpus of approximately 400,000 utterances, balanced across seven basic emotions through a multi-stage process of classification, rewriting, and synthetic generation. Using this dataset, we employ lightweight \"probes\" to read out information from the hidden layers of various Qwen3 and LLaMA models without altering their parameters. Our findings reveal that LLMs develop a surprisingly well-defined internal geometry of emotion, which sharpens with model scale and significantly outperforms zero-shot prompting. We demonstrate that this emotional signal is not a final-layer phenomenon but emerges early and peaks mid-network. Furthermore, the internal states are both malleable (they can be influenced by simple system prompts) and persistent, as the initial emotional tone remains detectable for hundreds of subsequent tokens. We contribute our dataset, an open-source probing toolkit, and a detailed map of the emotional landscape within LLMs, offering crucial insights for developing more transparent and aligned AI systems. The code and dataset are open-sourced.",
        "tags": [
            "LLM",
            "LLaMA"
        ]
    },
    {
        "id": "238",
        "title": "What Scales in Cross-Entropy Scaling Law?",
        "author": [
            "Junxi Yan",
            "Zixi Wei",
            "Jingtao Zhan",
            "Qingyao Ai",
            "Yiqun Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04067",
        "abstract": "The cross-entropy scaling law has long served as a key tool for guiding the development of large language models. It shows that cross-entropy loss decreases in a predictable power-law rate as the model size increases. However, recent evidence indicates that this law breaks down at very large scales: the loss decreases more slowly than expected, which causes significant trouble for developing large language models. In this paper, we hypothesize that the root cause lies in the fact that cross-entropy itself does not truly scale; instead, only one of its hidden components does. To investigate this, we introduce a novel decomposition of cross-entropy into three parts: Error-Entropy, Self-Alignment, and Confidence. We show both theoretically and empirically that this decomposition precisely captures the training dynamics and optimization objectives. Through extensive experiments on multiple datasets and 32 models spanning five orders of magnitude in size, we find that only error-entropy follows a robust power-law scaling, while the other two terms remain largely invariant. Moreover, error-entropy constitutes the dominant share of cross-entropy in small models but diminishes in proportion as models grow larger. This explains why the cross-entropy scaling law appears accurate at small scales but fails at very large ones. Our findings establish the error-entropy scaling law as a more accurate description of model behavior. We believe it will have wide applications in the training, understanding, and future development of large language models.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "239",
        "title": "What Makes Diffusion Language Models Super Data Learners?",
        "author": [
            "Zitian Gao",
            "Haoming Luo",
            "Lynx Chen",
            "Jason Klein Liu",
            "Ran Tao",
            "Joey Zhou",
            "Bryan Dai"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04071",
        "abstract": "Recent studies have shown that diffusion language models achieve remarkable data efficiency under limited-data constraints, yet the underlying mechanisms remain unclear. In this work, we perform extensive ablation experiments to disentangle the sources of this efficiency. Our results show that random masking of input tokens plays the dominant role. We further show that similar gains can be obtained through in MLP dropout and weight decay, indicating that stochastic regularization broadly enhances data efficiency in multi-epoch training. Our code is available at https://github.com/zitian-gao/data-efficiency.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "240",
        "title": "Slow-Fast Policy Optimization: Reposition-Before-Update for LLM Reasoning",
        "author": [
            "Ziyan Wang",
            "Zheng Wang",
            "Jie Fu",
            "Xingwei Qu",
            "Qi Cheng",
            "Shengpu Tang",
            "Minjia Zhang",
            "Xiaoming Huo"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04072",
        "abstract": "Reinforcement learning (RL) has become central to enhancing reasoning in large language models (LLMs). Yet on-policy algorithms such as Group Relative Policy Optimization (GRPO) often suffer in early training: noisy gradients from low-quality rollouts lead to unstable updates and inefficient exploration. We introduce Slow-Fast Policy Optimization (SFPO), a simple yet efficient framework to address these limitations via decomposing each step into three stages: a short fast trajectory of inner steps on the same batch, a reposition mechanism to control off-policy drift, and a final slow correction. This reposition-before-update design preserves the objective and rollout process unchanged, making SFPO plug-compatible with existing policy-gradient pipelines. Extensive experiments demonstrate that SFPO consistently improves stability, reduces rollouts, and accelerates convergence of reasoning RL training. Specifically, it outperforms GRPO by up to 2.80 points in average on math reasoning benchmarks. It also achieves up to 4.93\\texttimes{} fewer rollouts and a 4.19\\texttimes{} reduction in wall-clock time to match GRPO's best accuracy.",
        "tags": [
            "GRPO",
            "LLM",
            "RL"
        ]
    },
    {
        "id": "241",
        "title": "From Shadow to Light: Toward Safe and Efficient Policy Learning Across MPC, DeePC, RL, and LLM Agents",
        "author": [
            "Amin Vahidi-Moghaddam",
            "Sayed Pedram Haeri Boroujeni",
            "Iman Jebellat",
            "Ehsan Jebellat",
            "Niloufar Mehrabi",
            "Zhaojian Li"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04076",
        "abstract": "One of the main challenges in modern control applications, particularly in robot and vehicle motion control, is achieving accurate, fast, and safe movement. To address this, optimal control policies have been developed to enforce safety while ensuring high performance. Since basic first-principles models of real systems are often available, model-based controllers are widely used. Model predictive control (MPC) is a leading approach that optimizes performance while explicitly handling safety constraints. However, obtaining accurate models for complex systems is difficult, which motivates data-driven alternatives. ML-based MPC leverages learned models to reduce reliance on hand-crafted dynamics, while reinforcement learning (RL) can learn near-optimal policies directly from interaction data. Data-enabled predictive control (DeePC) goes further by bypassing modeling altogether, directly learning safe policies from raw input-output data. Recently, large language model (LLM) agents have also emerged, translating natural language instructions into structured formulations of optimal control problems. Despite these advances, data-driven policies face significant limitations. They often suffer from slow response times, high computational demands, and large memory needs, making them less practical for real-world systems with fast dynamics, limited onboard computing, or strict memory constraints. To address this, various technique, such as reduced-order modeling, function-approximated policy learning, and convex relaxations, have been proposed to reduce computational complexity. In this paper, we present eight such approaches and demonstrate their effectiveness across real-world applications, including robotic arms, soft robots, and vehicle motion control.",
        "tags": [
            "LLM",
            "MPC",
            "RL",
            "Robotics"
        ]
    },
    {
        "id": "242",
        "title": "Bamboo: LLM-Driven Discovery of API-Permission Mappings in the Android Framework",
        "author": [
            "Han Hu",
            "Wei Minn",
            "Yonghui Liu",
            "Jiakun Liu",
            "Ferdian Thung",
            "Terry Yue Zhuo",
            "Lwin Khin Shar",
            "Debin Gao",
            "David Lo"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04078",
        "abstract": "The permission mechanism in the Android Framework is integral to safeguarding the privacy of users by managing users' and processes' access to sensitive resources and operations. As such, developers need to be equipped with an in-depth understanding of API permissions to build robust Android apps. Unfortunately, the official API documentation by Android chronically suffers from imprecision and incompleteness, causing developers to spend significant effort to accurately discern necessary permissions. This potentially leads to incorrect permission declarations in Android app development, potentially resulting in security violations and app failures. Recent efforts in improving permission specification primarily leverage static and dynamic code analyses to uncover API-permission mappings within the Android framework. Yet, these methodologies encounter substantial shortcomings, including poor adaptability to Android SDK and Framework updates, restricted code coverage, and a propensity to overlook essential API-permission mappings in intricate codebases. This paper introduces a pioneering approach utilizing large language models (LLMs) for a systematic examination of API-permission mappings. In addition to employing LLMs, we integrate a dual-role prompting strategy and an API-driven code generation approach into our mapping discovery pipeline, resulting in the development of the corresponding tool, \\tool{}. We formulate three research questions to evaluate the efficacy of \\tool{} against state-of-the-art baselines, assess the completeness of official SDK documentation, and analyze the evolution of permission-required APIs across different SDK releases. Our experimental results reveal that \\tool{} identifies 2,234, 3,552, and 4,576 API-permission mappings in Android versions 6, 7, and 10 respectively, substantially outprforming existing baselines.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "243",
        "title": "PoLi-RL: A Point-to-List Reinforcement Learning Framework for Conditional Semantic Textual Similarity",
        "author": [
            "Zixin Song",
            "Bowen Zhang",
            "Qian-Wen Zhang",
            "Di Yin",
            "Xing Sun",
            "Chunping Li"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04080",
        "abstract": "Conditional Semantic Textual Similarity (C-STS) measures the semantic proximity between text segments under a specific condition, thereby overcoming the ambiguity inherent in traditional STS. However, existing methods are largely confined to discriminative models, failing to fully integrate recent breakthroughs in the NLP community concerning Large Language Models (LLMs) and Reinforcement Learning (RL). RL is a particularly well-suited paradigm for this task, as it can directly optimize the non-differentiable Spearman ranking metric and guide the reasoning process required by C-STS. However, we find that naively applying listwise RL fails to produce meaningful improvements, as the model is overwhelmed by complex, coarse-grained reward signals. To address this challenge, we introduce PoLi-RL, a novel Point-to-List Reinforcement Learning framework. PoLi-RL employs a two-stage curriculum: it first trains the model with simple pointwise rewards to establish fundamental scoring capabilities, then transitions to a hybrid reward that combines pointwise, pairwise, and listwise objectives to refine the model's ability to discern subtle semantic distinctions. Crucially, we propose an innovative Parallel Slice Ranking Reward (PSRR) mechanism that computes ranking rewards in parallel slices, where each slice comprises same-indexed completions from different samples. This provides a precise, differentiated learning signal for each individual completion, enabling granular credit assignment and effective optimization. On the official C-STS benchmark, PoLi-RL achieves a Spearman correlation coefficient of 48.18, establishing a new SOTA for the cross-encoder architecture. As the first work to successfully apply RL to C-STS, our study introduces a powerful and precise paradigm for training LLMs on complex, ranking-based conditional judgment tasks.",
        "tags": [
            "LLM",
            "RL"
        ]
    },
    {
        "id": "244",
        "title": "Scaling Code-Assisted Chain-of-Thoughts and Instructions for Model Reasoning",
        "author": [
            "Honglin Lin",
            "Qizhi Pei",
            "Xin Gao",
            "Zhuoshi Pan",
            "Yu Li",
            "Juntao Li",
            "Conghui He",
            "Lijun Wu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04081",
        "abstract": "Reasoning capability is pivotal for Large Language Models (LLMs) to solve complex tasks, yet achieving reliable and scalable reasoning remains challenging. While Chain-of-Thought (CoT) prompting has become a mainstream approach, existing methods often suffer from uncontrolled generation, insufficient quality, and limited diversity in reasoning paths. Recent efforts leverage code to enhance CoT by grounding reasoning in executable steps, but such methods are typically constrained to predefined mathematical problems, hindering scalability and generalizability. In this work, we propose Caco (Code-Assisted Chain-of-ThOught), a novel framework that automates the synthesis of high-quality, verifiable, and diverse instruction-CoT reasoning data through code-driven augmentation. Unlike prior work, Caco first fine-tunes a code-based CoT generator on existing math and programming solutions in a unified code format, then scales the data generation to a large amount of diverse reasoning traces. Crucially, we introduce automated validation via code execution and rule-based filtering to ensure logical correctness and structural diversity, followed by reverse-engineering filtered outputs into natural language instructions and language CoTs to enrich task adaptability. This closed-loop process enables fully automated, scalable synthesis of reasoning data with guaranteed executability. Experiments on our created Caco-1.3M dataset demonstrate that Caco-trained models achieve strong competitive performance on mathematical reasoning benchmarks, outperforming existing strong baselines. Further analysis reveals that Caco's code-anchored verification and instruction diversity contribute to superior generalization across unseen tasks. Our work establishes a paradigm for building self-sustaining, trustworthy reasoning systems without human intervention.",
        "tags": [
            "CoT",
            "LLM"
        ]
    },
    {
        "id": "245",
        "title": "Offline Reinforcement Learning in Large State Spaces: Algorithms and Guarantees",
        "author": [
            "Nan Jiang",
            "Tengyang Xie"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04088",
        "abstract": "This article introduces the theory of offline reinforcement learning in large state spaces, where good policies are learned from historical data without online interactions with the environment. Key concepts introduced include expressivity assumptions on function approximation (e.g., Bellman completeness vs. realizability) and data coverage (e.g., all-policy vs. single-policy coverage). A rich landscape of algorithms and results is described, depending on the assumptions one is willing to make and the sample and computational complexity guarantees one wishes to achieve. We also discuss open questions and connections to adjacent areas.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "246",
        "title": "SPOGW: a Score-based Preference Optimization method via Group-Wise comparison for workflows",
        "author": [
            "Yitong Cui",
            "Liu Liu",
            "Baosheng Yu",
            "Jiayan Qiu",
            "Xikai Zhang",
            "Likang Xiao",
            "Yixing Liu",
            "Quan Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04089",
        "abstract": "Large language models (LLMs) have exhibited significant capabilities in addressing challenging problems throughout various fields, often through the use of agentic workflows that adhere to structured instructions and multi-step procedures. However, designing such workflows demands substantial manual effort, posing challenges to scalability and generalizability. Recent studies have aimed to minimize the human intervention needed for their construction, leading to advances in automated techniques for optimizing agentic workflows. However, current approaches are often constrained by their limited representational capacity, insufficient adaptability, weak scalability, and pairwise comparison paradigm -- issues that stem primarily from a dependence on discrete optimization techniques. To overcome these limitations, we introduce a new score-based preference approach, refereed as SPOGW, which operates directly on cardinal reward signals through group-wise comparison and enables more efficient and stable optimization in a continuous space. SPOGW incorporates Iterative offline GRPO (ioGRPO) with advantage-masked KL divergence (mKL), which regulates training update by placing greater emphasis on the advantageous regions of the policy response. In five benchmark datasets covering mathematical reasoning, coding, and question answering, SPOGW matches or exceeds the performance of current state-of-the-art approaches, presenting a viable and forward-looking methodology for automated generation and optimization of agentic workflows.",
        "tags": [
            "GRPO",
            "LLM"
        ]
    },
    {
        "id": "247",
        "title": "Using predefined vector systems as latent space configuration for neural network supervised training on data with arbitrarily large number of classes",
        "author": [
            "Nikita Gabdullin"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04090",
        "abstract": "Supervised learning (SL) methods are indispensable for neural network (NN) training used to perform classification tasks. While resulting in very high accuracy, SL training often requires making NN parameter number dependent on the number of classes, limiting their applicability when the number of classes is extremely large or unknown in advance. In this paper we propose a methodology that allows one to train the same NN architecture regardless of the number of classes. This is achieved by using predefined vector systems as the target latent space configuration (LSC) during NN training. We discuss the desired properties of target configurations and choose randomly perturbed vectors of An root system for our experiments. These vectors are used to successfully train encoders and visual transformers (ViT) on Cinic-10 and ImageNet-1K in low- and high-dimensional cases by matching NN predictions with the predefined vectors. Finally, ViT is trained on a dataset with 1.28 million classes illustrating the applicability of the method to training on datasets with extremely large number of classes. In addition, potential applications of LSC in lifelong learning and NN distillation are discussed illustrating versatility of the proposed methodology.",
        "tags": [
            "ViT"
        ]
    },
    {
        "id": "248",
        "title": "Harnessing LLM for Noise-Robust Cognitive Diagnosis in Web-Based Intelligent Education Systems",
        "author": [
            "Guixian Zhang",
            "Guan Yuan",
            "Ziqi Xu",
            "Yanmei Zhang",
            "Zhenyun Deng",
            "Debo Cheng"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04093",
        "abstract": "Cognitive diagnostics in the Web-based Intelligent Education System (WIES) aims to assess students' mastery of knowledge concepts from heterogeneous, noisy interactions. Recent work has tried to utilize Large Language Models (LLMs) for cognitive diagnosis, yet LLMs struggle with structured data and are prone to noise-induced misjudgments. Specially, WIES's open environment continuously attracts new students and produces vast amounts of response logs, exacerbating the data imbalance and noise issues inherent in traditional educational systems. To address these challenges, we propose DLLM, a Diffusion-based LLM framework for noise-robust cognitive diagnosis. DLLM first constructs independent subgraphs based on response correctness, then applies relation augmentation alignment module to mitigate data imbalance. The two subgraph representations are then fused and aligned with LLM-derived, semantically augmented representations. Importantly, before each alignment step, DLLM employs a two-stage denoising diffusion module to eliminate intrinsic noise while assisting structural representation alignment. Specifically, unconditional denoising diffusion first removes erroneous information, followed by conditional denoising diffusion based on graph-guided to eliminate misleading information. Finally, the noise-robust representation that integrates semantic knowledge and structural information is fed into existing cognitive diagnosis models for prediction. Experimental results on three publicly available web-based educational platform datasets demonstrate that our DLLM achieves optimal predictive performance across varying noise levels, which demonstrates that DLLM achieves noise robustness while effectively leveraging semantic knowledge from LLM.",
        "tags": [
            "Diffusion",
            "LLM"
        ]
    },
    {
        "id": "249",
        "title": "RLRF: Competitive Search Agent Design via Reinforcement Learning from Ranker Feedback",
        "author": [
            "Tommy Mordo",
            "Sagie Dekel",
            "Omer Madmon",
            "Moshe Tennenholtz",
            "Oren Kurland"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04096",
        "abstract": "Competitive search is a setting where document publishers modify them to improve their ranking in response to a query. Recently, publishers have increasingly leveraged LLMs to generate and modify competitive content. We introduce Reinforcement Learning from Ranker Feedback (RLRF), a framework that trains LLMs using preference datasets derived from ranking competitions. The goal of a publisher (LLM-based) agent is to optimize content for improved ranking while accounting for the strategies of competing agents. We generate the datasets using approaches that do not rely on human-authored data. We show that our proposed agents consistently and substantially outperform previously suggested approaches for LLM-based competitive document modification. We further show that our agents are effective with ranking functions they were not trained for (i.e., out of distribution) and they adapt to strategic opponents. These findings provide support to the significant potential of using reinforcement learning in competitive search.",
        "tags": [
            "LLM",
            "RL"
        ]
    },
    {
        "id": "250",
        "title": "WebRenderBench: Enhancing Web Interface Generation through Layout-Style Consistency and Reinforcement Learning",
        "author": [
            "Peichao Lai",
            "Jinhui Zhuang",
            "Kexuan Zhang",
            "Ningchang Xiong",
            "Shengjie Wang",
            "Yanwei Xu",
            "Chong Chen",
            "Yilei Wang",
            "Bin Cui"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04097",
        "abstract": "Automating the conversion of UI images into web code is a critical task for front-end development and rapid prototyping. Advances in multimodal large language models (MLLMs) have made WebUI-to-Code increasingly feasible, yet existing benchmarks remain limited in data diversity and evaluation reliability. To address these issues, we present WebRenderBench, a large-scale benchmark of 22.5k webpages collected from real-world portal sites, offering greater diversity, complexity, and realism than prior benchmarks. We further propose a novel evaluation metric that measures layout and style consistency from the final rendered pages. Unlike vision-based methods that rely on costly LLM reasoning or structure-based comparisons vulnerable to noise and asymmetry, our approach enables more efficient, objective, and reliable UI quality assessment. Finally, we introduce the Automated Layout and Style Inspection Agent (ALISA), which integrates this metric into reinforcement learning as a reward signal to enhance training on crawled asymmetric webpages. Experiments show that ALISA significantly boosts generation performance, achieving state-of-the-art results across multiple metrics.",
        "tags": [
            "LLM",
            "RL"
        ]
    },
    {
        "id": "251",
        "title": "Can Linear Probes Measure LLM Uncertainty?",
        "author": [
            "Ramzi Dakhmouche",
            "Adrien Letellier",
            "Hossein Gorji"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04108",
        "abstract": "Effective Uncertainty Quantification (UQ) represents a key aspect for reliable deployment of Large Language Models (LLMs) in automated decision-making and beyond. Yet, for LLM generation with multiple choice structure, the state-of-the-art in UQ is still dominated by the naive baseline given by the maximum softmax score. To address this shortcoming, we demonstrate that taking a principled approach via Bayesian statistics leads to improved performance despite leveraging the simplest possible model, namely linear regression. More precisely, we propose to train multiple Bayesian linear models, each predicting the output of a layer given the output of the previous one. Based on the obtained layer-level posterior distributions, we infer the global uncertainty level of the LLM by identifying a sparse combination of distributional features, leading to an efficient UQ scheme. Numerical experiments on various LLMs show consistent improvement over state-of-the-art baselines.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "252",
        "title": "High order well-balanced and total-energy-conserving local discontinuous Galerkin methods for compressible self-gravitating Euler equations",
        "author": [
            "Liang Pan",
            "Wei Chen",
            "Jianxian Qiu",
            "Tao Xiong"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04112",
        "abstract": "In this paper, we develop a high order structure-preserving local discontinuous Galerkin (DG) scheme for the compressible self-gravitating Euler equations, which pose great challenges due to the presence of time-dependent gravitational potential. The designed scheme is well-balanced for general polytropic equilibrium state and total energy conserving for multiple spatial dimensions without an assumption of spherical symmetry. The well-balanced property is achieved by decomposing the gravitational potential into equilibrium and perturbation parts, employing a modified Harten-Lax-van Leer-contact flux and a modification of the discretization for the source term. Conservation of total energy is particularly challenging in the presence of self-gravity, especially when aiming for high order accuracy. To address this, we rewrite the energy equation into a conservative form, and carefully design an energy flux with the aid of weak formulation from the DG method to maintain conservation as well as high order accuracy. The resulting scheme can be extended to high order in time discretizations. Numerical examples for two and three dimensional problems are provided to verify the desired properties of our proposed scheme, including shock-capturing, high order accuracy, well balance, and total energy conservation.",
        "tags": [
            "FLUX"
        ]
    },
    {
        "id": "253",
        "title": "Searching Meta Reasoning Skeleton to Guide LLM Reasoning",
        "author": [
            "Ziying Zhang",
            "Yaqing Wang",
            "Quanming Yao"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04116",
        "abstract": "Meta reasoning behaviors work as a skeleton to guide large language model (LLM) reasoning, thus help to improve reasoning performance. However, prior researches implement meta reasoning skeleton with manually designed structure, limiting ability to adapt to query-specific requirement and capture intricate logical dependency among reasoning steps. To deal with the challenges, we represent meta reasoning skeleton with directed acyclic graph (DAG) to unify skeletons proposed in prior works and model intricate logical dependency. Then we propose AutoMR, a framework that searches for query-aware meta reasoning skeleton automatically inspired by automated machine learning (AutoML). Specifically, we construct search space based on DAG representation of skeleton and then formulate the search problem. We design a dynamic skeleton sampling algorithm by expanding meta reasoning skeleton along with reasoning context at inference time. This algorithm can derive any meta reasoning skeleton in search space efficiently and adapt skeleton to evolving base reasoning context, thus enable efficient query-aware skeleton search. We conduct experiments on extensive benchmark datasets. Experimental results show that AutoMR achieves better reasoning performance than previous works broadly.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "254",
        "title": "Unveiling LLMs' Metaphorical Understanding: Exploring Conceptual Irrelevance, Context Leveraging and Syntactic Influence",
        "author": [
            "Fengying Ye",
            "Shanshan Wang",
            "Lidia S. Chao",
            "Derek F. Wong"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04120",
        "abstract": "Metaphor analysis is a complex linguistic phenomenon shaped by context and external factors. While Large Language Models (LLMs) demonstrate advanced capabilities in knowledge integration, contextual reasoning, and creative generation, their mechanisms for metaphor comprehension remain insufficiently explored. This study examines LLMs' metaphor-processing abilities from three perspectives: (1) Concept Mapping: using embedding space projections to evaluate how LLMs map concepts in target domains (e.g., misinterpreting \"fall in love\" as \"drop down from love\"); (2) Metaphor-Literal Repository: analyzing metaphorical words and their literal counterparts to identify inherent metaphorical knowledge; and (3) Syntactic Sensitivity: assessing how metaphorical syntactic structures influence LLMs' performance. Our findings reveal that LLMs generate 15\\%-25\\% conceptually irrelevant interpretations, depend on metaphorical indicators in training data rather than contextual cues, and are more sensitive to syntactic irregularities than to structural comprehension. These insights underline the limitations of LLMs in metaphor analysis and call for more robust computational approaches.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "255",
        "title": "Wrist2Finger: Sensing Fingertip Force for Force-Aware Hand Interaction with a Ring-Watch Wearable",
        "author": [
            "Yingjing Xiao",
            "Zhichao Huang",
            "Junbin Ren",
            "Haichuan Song",
            "Yang Gao",
            "Yuting Bai",
            "Zhanpeng Jin"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04122",
        "abstract": "Hand pose tracking is essential for advancing applications in human-computer interaction. Current approaches, such as vision-based systems and wearable devices, face limitations in portability, usability, and practicality. We present a novel wearable system that reconstructs 3D hand pose and estimates per-finger forces using a minimal ring-watch sensor setup. A ring worn on the finger integrates an inertial measurement unit (IMU) to capture finger motion, while a smartwatch-based single-channel electromyography (EMG) sensor on the wrist detects muscle activations. By leveraging the complementary strengths of motion sensing and muscle signals, our approach achieves accurate hand pose tracking and grip force estimation in a compact wearable form factor. We develop a dual-branch transformer network that fuses IMU and EMG data with cross-modal attention to predict finger joint positions and forces simultaneously. A custom loss function imposes kinematic constraints for smooth force variation and realistic force saturation. Evaluation with 20 participants performing daily object interaction gestures demonstrates an average Mean Per Joint Position Error (MPJPE) of 0.57 cm and a fingertip force estimation (RMSE: 0.213, r=0.76). We showcase our system in a real-time Unity application, enabling virtual hand interactions that respond to user-applied forces. This minimal, force-aware tracking system has broad implications for VR/AR, assistive prosthetics, and ergonomic monitoring.",
        "tags": [
            "3D",
            "Transformer"
        ]
    },
    {
        "id": "256",
        "title": "Bound-Preserving WENO Schemes for Temple-class systems",
        "author": [
            "Wei Chen",
            "Shumo Cui",
            "Kailiang Wu",
            "Tao Xiong",
            "Baoyue Yu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04123",
        "abstract": "This paper explores numerical schemes for Temple-class systems, which are integral to various applications including one-dimensional two-phase flow, elasticity, traffic flow, and sedimentation. Temple-class systems are characterized by conservative equations, with different pressure function expressions leading to specific models such as the Aw-Rascle-Zhang (ARZ) traffic model and the sedimentation model. Our work extends existing studies by introducing a moving mesh approach to address the challenges of preserving non-convex invariant domains, a common issue in the numerical simulation of such systems. Our study outlines a novel bound-preserving (BP) and conservative numerical scheme, designed specifically for non-convex sets in Temple-class systems, which is critical for avoiding non-physical solutions and ensuring robustness in simulations. We develop both local and global BP methods based on finite difference schemes, with numerical experiments demonstrating the effectiveness and reliability of our methods. Furthermore, a parameterized flux limiter is introduced to restrict high-order fluxes and maintain bound preservation. This innovation marks the first time such a parameterized approach has been applied to non-convex sets, offering significant improvements over traditional methods. The findings presented extend beyond theoretical implications, as they are applicable to general Temple-class systems and can be tailored to ARZ traffic flow networks, highlighting the versatility and broad applicability of our approach. The paper contributes significantly to the field by providing a comprehensive method that maintains the physical and mathematical constrains of Temple-class systems.",
        "tags": [
            "FLUX"
        ]
    },
    {
        "id": "257",
        "title": "Joint Learning of Pose Regression and Denoising Diffusion with Score Scaling Sampling for Category-level 6D Pose Estimation",
        "author": [
            "Seunghyun Lee",
            "Tae-Kyun Kim"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04125",
        "abstract": "Latest diffusion models have shown promising results in category-level 6D object pose estimation by modeling the conditional pose distribution with depth image input. The existing methods, however, suffer from slow convergence during training, learning its encoder with the diffusion denoising network in end-to-end fashion, and require an additional network that evaluates sampled pose hypotheses to filter out low-quality pose candidates. In this paper, we propose a novel pipeline that tackles these limitations by two key components. First, the proposed method pretrains the encoder with the direct pose regression head, and jointly learns the networks via the regression head and the denoising diffusion head, significantly accelerating training convergence while achieving higher accuracy. Second, sampling guidance via time-dependent score scaling is proposed s.t. the exploration-exploitation trade-off is effectively taken, eliminating the need for the additional evaluation network. The sampling guidance maintains multi-modal characteristics of symmetric objects at early denoising steps while ensuring high-quality pose generation at final steps. Extensive experiments on multiple benchmarks including REAL275, HouseCat6D, and ROPE, demonstrate that the proposed method, simple yet effective, achieves state-of-the-art accuracies even with single-pose inference, while being more efficient in both training and inference.",
        "tags": [
            "Diffusion",
            "Pose Estimation",
            "RoPE"
        ]
    },
    {
        "id": "258",
        "title": "Internal states before wait modulate reasoning patterns",
        "author": [
            "Dmitrii Troitskii",
            "Koyena Pal",
            "Chris Wendler",
            "Callum Stuart McDougall",
            "Neel Nanda"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04128",
        "abstract": "Prior work has shown that a significant driver of performance in reasoning models is their ability to reason and self-correct. A distinctive marker in these reasoning traces is the token wait, which often signals reasoning behavior such as backtracking. Despite being such a complex behavior, little is understood of exactly why models do or do not decide to reason in this particular manner, which limits our understanding of what makes a reasoning model so effective. In this work, we address the question whether model's latents preceding wait tokens contain relevant information for modulating the subsequent reasoning process. We train crosscoders at multiple layers of DeepSeek-R1-Distill-Llama-8B and its base version, and introduce a latent attribution technique in the crosscoder setting. We locate a small set of features relevant for promoting/suppressing wait tokens' probabilities. Finally, through a targeted series of experiments analyzing max activating examples and causal interventions, we show that many of our identified features indeed are relevant for the reasoning process and give rise to different types of reasoning patterns such as restarting from the beginning, recalling prior knowledge, expressing uncertainty, and double-checking.",
        "tags": [
            "DeepSeek",
            "LLaMA"
        ]
    },
    {
        "id": "259",
        "title": "GA4GC: Greener Agent for Greener Code via Multi-Objective Configuration Optimization",
        "author": [
            "Jingzhi Gong",
            "Yixin Bian",
            "Luis de la Cal",
            "Giovanni Pinna",
            "Anisha Uteem",
            "David Williams",
            "Mar Zamorano",
            "Karine Even-Mendoza",
            "W.B. Langdon",
            "Hector Menendez",
            "Federica Sarro"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04135",
        "abstract": "Coding agents powered by LLMs face critical sustainability and scalability challenges in industrial deployment, with single runs consuming over 100k tokens and incurring environmental costs that may exceed optimization benefits. This paper introduces GA4GC, the first framework to systematically optimize coding agent runtime (greener agent) and code performance (greener code) trade-offs by discovering Pareto-optimal agent hyperparameters and prompt templates. Evaluation on the SWE-Perf benchmark demonstrates up to 135x hypervolume improvement, reducing agent runtime by 37.7% while improving correctness. Our findings establish temperature as the most critical hyperparameter, and provide actionable strategies to balance agent sustainability with code optimization effectiveness in industrial deployment.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "260",
        "title": "Fine Tuning Methods for Low-resource Languages",
        "author": [
            "Tim Bakkenes",
            "Daniel Wang",
            "Anton Johansson"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04139",
        "abstract": "The rise of Large Language Models has not been inclusive of all cultures. The models are mostly trained on English texts and culture which makes them underperform in other languages and cultural contexts. By developing a generalizable method for preparing culturally relevant datasets and post-training the Gemma 2 model, this project aimed to increase the performance of Gemma 2 for an underrepresented language and showcase how others can do the same to unlock the power of Generative AI in their country and preserve their cultural heritage.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "261",
        "title": "Selective Expert Guidance for Effective and Diverse Exploration in Reinforcement Learning of LLMs",
        "author": [
            "Zishang Jiang",
            "Jinyi Han",
            "Tingyun Li",
            "Xinyi Wang",
            "Sihang Jiang",
            "Jiaqing Liang",
            "Zhaoqian Dai",
            "Shuguang Ma",
            "Fei Yu",
            "Yanghua Xiao"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04140",
        "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR) has become a widely adopted technique for enhancing the reasoning ability of Large Language Models (LLMs). However, the effectiveness of RLVR strongly depends on the capability of base models. This issue arises because it requires the model to have sufficient capability to perform high-quality exploration, which involves both effectiveness and diversity. Unfortunately, existing methods address this issue by imitating expert trajectories, which improve effectiveness but neglect diversity. To address this, we argue that the expert only needs to provide guidance only at critical decision points rather than the entire reasoning path. Based on this insight, we propose MENTOR: Mixed-policy Expert Navigation for Token-level Optimization of Reasoning, a framework that provides expert guidance only at critical decision points to perform effective and diverse exploration in RLVR. Extensive experiments show that MENTOR enables models capture the essence of expert strategies rather than surface imitation, thereby performing high-quality exploration and achieving superior overall performance. Our code is available online.",
        "tags": [
            "LLM",
            "RL"
        ]
    },
    {
        "id": "262",
        "title": "The Artificial Intelligence Cognitive Examination: A Survey on the Evolution of Multimodal Evaluation from Recognition to Reasoning",
        "author": [
            "Mayank Ravishankara",
            "Varindra V. Persad Maharaj"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04141",
        "abstract": "This survey paper chronicles the evolution of evaluation in multimodal artificial intelligence (AI), framing it as a progression of increasingly sophisticated \"cognitive examinations.\" We argue that the field is undergoing a paradigm shift, moving from simple recognition tasks that test \"what\" a model sees, to complex reasoning benchmarks that probe \"why\" and \"how\" it understands. This evolution is driven by the saturation of older benchmarks, where high performance often masks fundamental weaknesses. We chart the journey from the foundational \"knowledge tests\" of the ImageNet era to the \"applied logic and comprehension\" exams such as GQA and Visual Commonsense Reasoning (VCR), which were designed specifically to diagnose systemic flaws such as shortcut learning and failures in compositional generalization. We then survey the current frontier of \"expert-level integration\" benchmarks (e.g., MMBench, SEED-Bench, MMMU) designed for today's powerful multimodal large language models (MLLMs), which increasingly evaluate the reasoning process itself. Finally, we explore the uncharted territories of evaluating abstract, creative, and social intelligence. We conclude that the narrative of AI evaluation is not merely a history of datasets, but a continuous, adversarial process of designing better examinations that, in turn, redefine our goals for creating truly intelligent systems.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "263",
        "title": "Learning from All: Concept Alignment for Autonomous Distillation from Multiple Drifting MLLMs",
        "author": [
            "Xiaoyu Yang",
            "Jie Lu",
            "En Yu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04142",
        "abstract": "This paper identifies a critical yet underexplored challenge in distilling from multimodal large language models (MLLMs): the reasoning trajectories generated by multiple drifting teachers exhibit concept drift, whereby their reasoning distributions evolve unpredictably and transmit biases to the student model, ultimately compromising its performance. To tackle this issue, we pioneer a theoretical connection between concept drift and knowledge distillation, casting the non-stationary reasoning dynamics from multiple MLLM teachers as next-token prediction of multi-stream reasoning http://trajectories.Guided by concept drift, we introduce the \"learn, compare, critique\" paradigm, culminating in autonomous preference optimization (APO). Under the active guidance of the teachers, the student model first learns and self-distils preferred thinking by comparing multiple teachers. It then engages in critical reflection over the drifting inference from teachers, performing concept alignment through APO, ultimately yielding a robust, consistent, and generalizable http://model.Extensive experiments demonstrate our superior performance of consistency, robustness and generalization within knowledge distillation. Besides, we also contributed a large-scale dataset, CXR-MAX (Multi-teachers Alignment X-rays), comprising 170,982 distilled reasoning trajectories derived from publicly accessible MLLMs based on MIMIC-CXR. Our code and data are public at: https://anonymous.4open.science/r/Autonomous-Distillation/.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "264",
        "title": "Detecting Semantic Clones of Unseen Functionality",
        "author": [
            "Konstantinos Kitsios",
            "Francesco Sovrano",
            "Earl T. Barr",
            "Alberto Bacchelli"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04143",
        "abstract": "Semantic code clone detection is the task of detecting whether two snippets of code implement the same functionality (e.g., Sort Array). Recently, many neural models achieved near-perfect performance on this task. These models seek to make inferences based on their training data. Consequently, they better detect clones similar to those they have seen during training and may struggle to detect those they have not. Developers seeking clones are, of course, interested in both types of clones. We confirm this claim through a literature review, identifying three practical clone detection tasks in which the model's goal is to detect clones of a functionality even if it was trained on clones of different functionalities. In light of this finding, we re-evaluate six state-of-the-art models, including both task-specific models and generative LLMs, on the task of detecting clones of unseen functionality. Our experiments reveal a drop in F1 of up to 48% (average 31%) for task-specific models. LLMs perform on par with task-specific models without explicit training for clone detection, but generalize better to unseen functionalities, where F1 drops up to 5% (average 3%) instead. We propose and evaluate the use of contrastive learning to improve the performance of existing models on clones of unseen functionality. We draw inspiration from the computer vision and natural language processing fields where contrastive learning excels at measuring similarity between two objects, even if they come from classes unseen during training. We replace the final classifier of the task-specific models with a contrastive classifier, while for the generative LLMs we propose contrastive in-context learning, guiding the LLMs to focus on the differences between clones and non-clones. The F1 on clones of unseen functionality is improved by up to 26% (average 9%) for task-specific models and up to 5% (average 3%) for LLMs.",
        "tags": [
            "Detection",
            "LLM"
        ]
    },
    {
        "id": "265",
        "title": "Automating construction safety inspections using a multi-modal vision-language RAG framework",
        "author": [
            "Chenxin Wang",
            "Elyas Asadi Shamsabadi",
            "Zhaohui Chen",
            "Luming Shen",
            "Alireza Ahmadian Fard Fini",
            "Daniel Dias-da-Costa"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04145",
        "abstract": "Conventional construction safety inspection methods are often inefficient as they require navigating through large volume of information. Recent advances in large vision-language models (LVLMs) provide opportunities to automate safety inspections through enhanced visual and linguistic understanding. However, existing applications face limitations including irrelevant or unspecific responses, restricted modal inputs and hallucinations. Utilisation of Large Language Models (LLMs) for this purpose is constrained by availability of training data and frequently lack real-time adaptability. This study introduces SiteShield, a multi-modal LVLM-based Retrieval-Augmented Generation (RAG) framework for automating construction safety inspection reports by integrating visual and audio inputs. Using real-world data, SiteShield outperformed unimodal LLMs without RAG with an F1 score of 0.82, hamming loss of 0.04, precision of 0.76, and recall of 0.96. The findings indicate that SiteShield offers a novel pathway to enhance information retrieval and efficiency in generating safety reports.",
        "tags": [
            "LLM",
            "RAG",
            "VLM"
        ]
    },
    {
        "id": "266",
        "title": "Beyond Next-Token Prediction: A Performance Characterization of Diffusion versus Autoregressive Language Models",
        "author": [
            "Minseo Kim",
            "Coleman Hooper",
            "Aditya Tomar",
            "Chenfeng Xu",
            "Mehrdad Farajtabar",
            "Michael W. Mahoney",
            "Kurt Keutzer",
            "Amir Gholami"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04146",
        "abstract": "Large Language Models (LLMs) have achieved state-of-the-art performance on a broad range of Natural Language Processing (NLP) tasks, including document processing and coding. Autoregressive Language Models (ARMs), which generate tokens sequentially conditioned on all previous tokens, have been the predominant paradigm for LLMs. However, while these networks have achieved high accuracy across a range of downstream tasks, they exhibit low arithmetic intensity due to the inherent sequential dependency with next-token prediction. Recently, Diffusion Language Models (DLMs) have emerged as a promising alternative architecture. DLMs generate output text in parallel, breaking the limitations of sequential dependency. However, the performance implications of DLMs relative to commonly deployed ARMs are not fully understood. In this work, we present a comprehensive performance study analyzing the performance characteristics of ARMs and DLMs, using both theoretical analysis and profiling data to characterize the trade-offs between these approaches. We illustrate that although DLMs exhibit higher arithmetic intensity compared to ARMs because of their capability to utilize parallelism across sequence lengths, they fail to scale effectively to longer contexts. We then explore DLMs with block-wise decoding, outlining how this approach allows for increased arithmetic intensity, while still scaling well to long contexts (similar to ARMs). We also show interesting trade-offs for batched inference, where we find that ARMs exhibit superior throughput, as they benefit more from parallelism across sequences in the batch. Finally, we highlight opportunities for accelerating DLM inference, and, in particular, highlight the importance of reducing the number of sampling steps for allowing open-source DLMs to provide improved latency relative to ARMs.",
        "tags": [
            "Diffusion",
            "LLM"
        ]
    },
    {
        "id": "267",
        "title": "Self Speculative Decoding for Diffusion Large Language Models",
        "author": [
            "Yifeng Gao",
            "Ziang Ji",
            "Yuxuan Wang",
            "Biqing Qi",
            "Hanlin Xu",
            "Linfeng Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04147",
        "abstract": "Diffusion-based Large Language Models (dLLMs) have emerged as a competitive alternative to autoregressive models, offering unique advantages through bidirectional attention and parallel generation paradigms. However, the generation results of current parallel decoding methods deviate from stepwise decoding, introducing potential performance degradation, which limits their practical deployment. To address this problem, we propose \\textbf{S}elf \\textbf{S}peculative \\textbf{D}ecoding (SSD), a lossless inference acceleration method that leverages the dLLM itself as both speculative decoding drafter and verifier without auxiliary modules. SSD introduces a self-drafting mechanism where the model generates predictions for multiple positions, then verifies them through hierarchical verification trees in a single forward pass. Unlike traditional speculative decoding that requires separate draft models, SSD eliminates model redundancy and memory overhead by exploiting the dLLM's inherent parallel prediction capability for multiple positions. This self-speculative approach allows the model to progressively verify and accept multiple tokens in a single forward pass. Our experiments demonstrate that SSD achieves up to 3.46$\\times$ speedup while keeping the output identical to stepwise decoding on open source models such as LLaDA and Dream. Code will be made publicly available on GitHub.",
        "tags": [
            "Diffusion",
            "LLM"
        ]
    },
    {
        "id": "268",
        "title": "ObCLIP: Oblivious CLoud-Device Hybrid Image Generation with Privacy Preservation",
        "author": [
            "Haoqi Wu",
            "Wei Dai",
            "Ming Xu",
            "Li Wang",
            "Qiang Yan"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04153",
        "abstract": "Diffusion Models have gained significant popularity due to their remarkable capabilities in image generation, albeit at the cost of intensive computation requirement. Meanwhile, despite their widespread deployment in inference services such as Midjourney, concerns about the potential leakage of sensitive information in uploaded user prompts have arisen. Existing solutions either lack rigorous privacy guarantees or fail to strike an effective balance between utility and efficiency. To bridge this gap, we propose ObCLIP, a plug-and-play safeguard that enables oblivious cloud-device hybrid generation. By oblivious, each input prompt is transformed into a set of semantically similar candidate prompts that differ only in sensitive attributes (e.g., gender, ethnicity). The cloud server processes all candidate prompts without knowing which one is the real one, thus preventing any prompt leakage. To mitigate server cost, only a small portion of denoising steps is performed upon the large cloud model. The intermediate latents are then sent back to the client, which selects the targeted latent and completes the remaining denoising using a small device model. Additionally, we analyze and incorporate several cache-based accelerations that leverage temporal and batch redundancy, effectively reducing computation cost with minimal utility degradation. Extensive experiments across multiple datasets demonstrate that ObCLIP provides rigorous privacy and comparable utility to cloud models with slightly increased server cost.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "269",
        "title": "GDiffuSE: Diffusion-based speech enhancement with noise model guidance",
        "author": [
            "Efrayim Yanir",
            "David Burshtein",
            "Sharon Gannot"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04157",
        "abstract": "This paper introduces a novel speech enhancement (SE) approach based on a denoising diffusion probabilistic model (DDPM), termed Guided diffusion for speech enhancement (GDiffuSE). In contrast to conventional methods that directly map noisy speech to clean speech, our method employs a lightweight helper model to estimate the noise distribution, which is then incorporated into the diffusion denoising process via a guidance mechanism. This design improves robustness by enabling seamless adaptation to unseen noise types and by leveraging large-scale DDPMs originally trained for speech generation in the context of SE. We evaluate our approach on noisy signals obtained by adding noise samples from the BBC sound effects database to LibriSpeech utterances, showing consistent improvements over state-of-the-art baselines under mismatched noise conditions. Examples are available at our project webpage.",
        "tags": [
            "DDPM",
            "Diffusion"
        ]
    },
    {
        "id": "270",
        "title": "HEHA: Hierarchical Planning for Heterogeneous Multi-Robot Exploration of Unknown Environments",
        "author": [
            "Longrui Yang",
            "Yiyu Wang",
            "Jingfan Tang",
            "Yunpeng Lv",
            "Shizhe Zhao",
            "Chao Cao",
            "Zhongqiang Ren"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04161",
        "abstract": "This paper considers the path planning problem for autonomous exploration of an unknown environment using multiple heterogeneous robots such as drones, wheeled, and legged robots, which have different capabilities to traverse complex terrains. A key challenge there is to intelligently allocate the robots to the unknown areas to be explored and determine the visiting order of those spaces subject to traversablity constraints, which leads to a large scale constrained optimization problem that needs to be quickly and iteratively solved every time when new space are explored. To address the challenge, we propose HEHA (Hierarchical Exploration with Heterogeneous Agents) by leveraging a recent hierarchical method that decompose the exploration into global planning and local planning. The major contribution in HEHA is its global planning, where we propose a new routing algorithm PEAF (Partial Anytime Focal search) that can quickly find bounded sub-optimal solutions to minimize the maximum path length among the agents subject to traversability constraints. Additionally, the local planner in HEHA also considers heterogeneity to avoid repeated and duplicated exploration among the robots. The experimental results show that, our HEHA can reduce up to 30% of the exploration time than the baselines.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "271",
        "title": "Learning to Capture Rocks using an Excavator: A Reinforcement Learning Approach with Guiding Reward Formulation",
        "author": [
            "Amirmasoud Molaei",
            "Reza Ghabcheloo"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04168",
        "abstract": "Rock capturing with standard excavator buckets is a challenging task typically requiring the expertise of skilled operators. Unlike soil digging, it involves manipulating large, irregular rocks in unstructured environments where complex contact interactions with granular material make model-based control impractical. Existing autonomous excavation methods focus mainly on continuous media or rely on specialized grippers, limiting their applicability to real-world construction sites. This paper introduces a fully data-driven control framework for rock capturing that eliminates the need for explicit modeling of rock or soil properties. A model-free reinforcement learning agent is trained in the AGX Dynamics simulator using the Proximal Policy Optimization (PPO) algorithm and a guiding reward formulation. The learned policy outputs joint velocity commands directly to the boom, arm, and bucket of a CAT365 excavator model. Robustness is enhanced through extensive domain randomization of rock geometry, density, and mass, as well as the initial configurations of the bucket, rock, and goal position. To the best of our knowledge, this is the first study to develop and evaluate an RL-based controller for the rock capturing task. Experimental results show that the policy generalizes well to unseen rocks and varying soil conditions, achieving high success rates comparable to those of human participants while maintaining machine stability. These findings demonstrate the feasibility of learning-based excavation strategies for discrete object manipulation without requiring specialized hardware or detailed material models.",
        "tags": [
            "PPO",
            "RL"
        ]
    },
    {
        "id": "272",
        "title": "VBM-NET: Visual Base Pose Learning for Mobile Manipulation using Equivariant TransporterNet and GNNs",
        "author": [
            "Lakshadeep Naik",
            "Adam Fischer",
            "Daniel Duberg",
            "Danica Kragic"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04171",
        "abstract": "In Mobile Manipulation, selecting an optimal mobile base pose is essential for successful object grasping. Previous works have addressed this problem either through classical planning methods or by learning state-based policies. They assume access to reliable state information, such as the precise object poses and environment models. In this work, we study base pose planning directly from top-down orthographic projections of the scene, which provide a global overview of the scene while preserving spatial structure. We propose VBM-NET, a learning-based method for base pose selection using such top-down orthographic projections. We use equivariant TransporterNet to exploit spatial symmetries and efficiently learn candidate base poses for grasping. Further, we use graph neural networks to represent a varying number of candidate base poses and use Reinforcement Learning to determine the optimal base pose among them. We show that VBM-NET can produce comparable solutions to the classical methods in significantly less computation time. Furthermore, we validate sim-to-real transfer by successfully deploying a policy trained in simulation to real-world mobile manipulation.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "273",
        "title": "Using Robotics to Improve Transcatheter Edge-to-Edge Repair of the Mitral Valve",
        "author": [
            "LÃ©a Pistorius",
            "Namrata U. Nayar",
            "Phillip Tran",
            "Sammy Elmariah",
            "Pierre E. Dupont"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04178",
        "abstract": "Transcatheter valve repair presents significant challenges due to the mechanical limitations and steep learning curve associated with manual catheter systems. This paper investigates the use of robotics to facilitate transcatheter procedures in the context of mitral valve edge-to-edge repair. The complex handle-based control of a clinical repair device is replaced by intuitive robotic joint-based control via a game controller. Manual versus robotic performance is analyzed by decomposing the overall device delivery task into motion-specific steps and comparing capabilities on a step-by-step basis in a phantom model of the heart and vasculature. Metrics include procedure duration and clip placement accuracy. Results demonstrate that the robotic system can reduce procedural time and motion errors while also improving accuracy of clip placement. These findings suggest that robotic assistance can address key limitations of manual systems, offering a more reliable and user-friendly platform for complex transcatheter procedures.",
        "tags": [
            "CLIP",
            "Robotics"
        ]
    },
    {
        "id": "274",
        "title": "Thinking on the Fly: Test-Time Reasoning Enhancement via Latent Thought Policy Optimization",
        "author": [
            "Wengao Ye",
            "Yan Liang",
            "Lianlei Shan"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04182",
        "abstract": "Recent advancements in Large Language Models (LLMs) have shifted from explicit Chain-of-Thought (CoT) reasoning to more efficient latent reasoning, where intermediate thoughts are represented as vectors rather than text. However, latent reasoning can be brittle on challenging, out-of-distribution tasks where robust reasoning is most critical. To overcome these limitations, we introduce Latent Thought Policy Optimization (LTPO), a parameter-free framework that enhances LLM reasoning entirely at test time, without requiring model parameter updates. LTPO treats intermediate latent \"thought\" vectors as dynamic parameters that are actively optimized for each problem instance. It employs an online policy gradient method guided by an intrinsic, confidence-based reward signal computed directly from the frozen LLM's own output distributions, eliminating the need for external supervision or expensive text generation during optimization. Extensive experiments on five reasoning benchmarks show that LTPO not only matches or surpasses strong baselines on standard tasks but also demonstrates remarkable robustness where others fail. Most notably, on highly challenging AIME benchmarks where existing latent reasoning baselines collapse to near-zero accuracy, LTPO delivers substantial improvements, showcasing a unique capability for complex reasoning.",
        "tags": [
            "CoT",
            "LLM"
        ]
    },
    {
        "id": "275",
        "title": "Let Features Decide Their Own Solvers: Hybrid Feature Caching for Diffusion Transformers",
        "author": [
            "Shikang Zheng",
            "Guantao Chen",
            "Qinming Zhou",
            "Yuqi Lin",
            "Lixuan He",
            "Chang Zou",
            "Peiliang Cai",
            "Jiacheng Liu",
            "Linfeng Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04188",
        "abstract": "Diffusion Transformers offer state-of-the-art fidelity in image and video synthesis, but their iterative sampling process remains a major bottleneck due to the high cost of transformer forward passes at each timestep. To mitigate this, feature caching has emerged as a training-free acceleration technique that reuses or forecasts hidden representations. However, existing methods often apply a uniform caching strategy across all feature dimensions, ignoring their heterogeneous dynamic behaviors. Therefore, we adopt a new perspective by modeling hidden feature evolution as a mixture of ODEs across dimensions, and introduce HyCa, a Hybrid ODE solver inspired caching framework that applies dimension-wise caching strategies. HyCa achieves near-lossless acceleration across diverse domains and models, including 5.55 times speedup on FLUX, 5.56 times speedup on HunyuanVideo, 6.24 times speedup on Qwen-Image and Qwen-Image-Edit without retraining.",
        "tags": [
            "Diffusion",
            "FLUX",
            "HunyuanVideo",
            "ODE",
            "Qwen",
            "Transformer"
        ]
    },
    {
        "id": "276",
        "title": "Zenbo Patrol: A Social Assistive Robot Based on Multimodal Deep Learning for Real-time Illegal Parking Recognition and Notification",
        "author": [
            "Jian-jie Zheng",
            "Chih-kai Yang",
            "Po-han Chen",
            "Lyn Chao-ling Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04190",
        "abstract": "In the study, the social robot act as a patrol to recognize and notify illegal parking in real-time. Dual-model pipeline method and large multimodal model were compared, and the GPT-4o multimodal model was adopted in license plate recognition without preprocessing. For moving smoothly on a flat ground, the robot navigated in a simulated parking lot in the experiments. The robot changes angle view of the camera automatically to capture the images around with the format of license plate number. From the captured images of the robot, the numbers on the plate are recognized through the GPT-4o model, and identifies legality of the numbers. When an illegal parking is detected, the robot sends Line messages to the system manager immediately. The contribution of the work is that a novel multimodal deep learning method has validated with high accuracy in license plate recognition, and a social assistive robot is also provided for solving problems in a real scenario, and can be applied in an indoor parking lot.",
        "tags": [
            "GPT",
            "Robotics"
        ]
    },
    {
        "id": "277",
        "title": "Constructing coherent spatial memory in LLM agents through graph rectification",
        "author": [
            "Puzhen Zhang",
            "Xuyang Chen",
            "Yu Feng",
            "Yuhan Jiang",
            "Liqiu Meng"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04195",
        "abstract": "Given a map description through global traversal navigation instructions (e.g., visiting each room sequentially with action signals such as north, west, etc.), an LLM can often infer the implicit spatial layout of the environment and answer user queries by providing a shortest path from a start to a destination (for instance, navigating from the lobby to a meeting room via the hall and elevator). However, such context-dependent querying becomes incapable as the environment grows much longer, motivating the need for incremental map construction that builds a complete topological graph from stepwise observations. We propose a framework for LLM-driven construction and map repair, designed to detect, localize, and correct structural inconsistencies in incrementally constructed navigation graphs. Central to our method is the Version Control, which records the full history of graph edits and their source observations, enabling fine-grained rollback, conflict tracing, and repair evaluation. We further introduce an Edge Impact Score to prioritize minimal-cost repairs based on structural reachability, path usage, and conflict propagation. To properly evaluate our approach, we create a refined version of the MANGO benchmark dataset by systematically removing non-topological actions and inherent structural conflicts, providing a cleaner testbed for LLM-driven construction and map repair. Our approach significantly improves map correctness and robustness, especially in scenarios with entangled or chained inconsistencies. Our results highlight the importance of introspective, history-aware repair mechanisms for maintaining coherent spatial memory in LLM agents.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "278",
        "title": "COSMO-RL: Towards Trustworthy LMRMs via Joint Safety and Stability",
        "author": [
            "Yizhuo Ding",
            "Mingkang Chen",
            "Qiuhua Liu",
            "Fenghua Weng",
            "Wanying Qu",
            "Yue Yang",
            "Yugang Jiang",
            "Zuxuan Wu",
            "Yanwei Fu",
            "Wenqi Shao"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04196",
        "abstract": "Large Multimodal Reasoning Models (LMRMs) are moving into real applications, where they must be both useful and safe. Safety is especially challenging in multimodal settings: images and text can be combined to bypass guardrails, and single objective training can cause policy drift that yields over-refusal on benign inputs or unsafe compliance on risky ones. We present COSMO-RL, a mixed reinforcement learning framework that trains reasoning oriented LMRMs under multimodal, multitask, and multiobjective signals, and we release the resulting model, COSMO-R1. Our approach aims to let safety and capability grow together in one stable pipeline rather than competing during alignment. In experiments, COSMO-R1 improves safety while maintaining-and often improving multimodal reasoning and instruction following, shows stronger robustness to multimodal jailbreaks, and reduces unnecessary refusals. The framework also transfers across backbones with consistent gains. Ablations support the design choices, indicating a simple path to advancing safety and general capability together in LMRMs.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "279",
        "title": "World-To-Image: Grounding Text-to-Image Generation with Agent-Driven World Knowledge",
        "author": [
            "Moo Hyun Son",
            "Jintaek Oh",
            "Sun Bin Mun",
            "Jaechul Roh",
            "Sehyun Choi"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04201",
        "abstract": "While text-to-image (T2I) models can synthesize high-quality images, their performance degrades significantly when prompted with novel or out-of-distribution (OOD) entities due to inherent knowledge cutoffs. We introduce World-To-Image, a novel framework that bridges this gap by empowering T2I generation with agent-driven world knowledge. We design an agent that dynamically searches the web to retrieve images for concepts unknown to the base model. This information is then used to perform multimodal prompt optimization, steering powerful generative backbones toward an accurate synthesis. Critically, our evaluation goes beyond traditional metrics, utilizing modern assessments like LLMGrader and ImageReward to measure true semantic fidelity. Our experiments show that World-To-Image substantially outperforms state-of-the-art methods in both semantic alignment and visual aesthetics, achieving +8.1% improvement in accuracy-to-prompt on our curated NICE benchmark. Our framework achieves these results with high efficiency in less than three iterations, paving the way for T2I systems that can better reflect the ever-changing real world. Our demo code is available here\\footnote{https://github.com/mhson-kyle/World-To-Image}.",
        "tags": [
            "Text-to-Image"
        ]
    },
    {
        "id": "280",
        "title": "CALM Before the STORM: Unlocking Native Reasoning for Optimization Modeling",
        "author": [
            "Zhengyang Tang",
            "Zihan Ye",
            "Chenyu Huang",
            "Xuhan Huang",
            "Chengpeng Li",
            "Sihang Li",
            "Guanhua Chen",
            "Ming Yan",
            "Zizhuo Wang",
            "Hongyuan Zha",
            "Dayiheng Liu",
            "Benyou Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04204",
        "abstract": "Large Reasoning Models (LRMs) have demonstrated strong capabilities in complex multi-step reasoning, opening new opportunities for automating optimization modeling. However, existing domain adaptation methods, originally designed for earlier instruction-tuned models, often fail to exploit the advanced reasoning patterns of modern LRMs -- In particular, we show that direct fine-tuning on traditional \\textit{non-reflective} datasets leads to limited gains. To fully leverage LRMs' inherent reasoning abilities, we propose \\textbf{CALM} (\\textit{Corrective Adaptation with Lightweight Modification}), a framework that progressively refines LRMs within their native reasoning modes for optimization modeling tasks. In CALM, an expert intervener identifies reasoning flaws and provides concise corrective hints, which the LRM incorporates to produce improved reasoning trajectories. These interventions modify fewer than 2.6\\% of generated tokens, but generate high-quality data for soft adaptation through supervised fine-tuning. The adapted model is then further improved through reinforcement learning. Building on CALM, we develop \\textbf{STORM} (\\textit{Smart Thinking Optimization Reasoning Model}), a 4B-parameter LRM that achieves a new state-of-the-art average accuracy of 68.9\\% across five popular optimization modeling benchmarks, matching the performance of a 671B LRM. These results demonstrate that dynamic, hint-based data synthesis both preserves and amplifies the native reasoning patterns of modern LRMs, offering a more effective and scalable path towards expert-level performance on challenging optimization modeling tasks.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "281",
        "title": "PolyKAN: A Polyhedral Analysis Framework for Provable and Minimal KAN Compression",
        "author": [
            "Di Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04205",
        "abstract": "Kolmogorov-Arnold Networks (KANs) have emerged as a promising alternative to traditional Multi-Layer Perceptrons (MLPs), offering enhanced interpretability and a strong mathematical foundation. However, their parameter efficiency remains a significant challenge for practical deployment. This paper introduces PolyKAN, a novel theoretical framework for KAN compression that provides formal guarantees on both model size reduction and approximation error. By leveraging the inherent piecewise polynomial structure of KANs, we formulate the compression problem as one of optimal polyhedral region merging. We establish a rigorous polyhedral characterization of KANs, develop a complete theory of $\\epsilon$-equivalent compression, and design an optimal dynamic programming algorithm that guarantees minimal compression under specified error bounds. Our theoretical analysis demonstrates that PolyKAN achieves provably minimal compression while maintaining strict error control, with polynomial-time complexity in all network parameters. The framework provides the first formal foundation for KAN compression with mathematical guarantees, opening new directions for efficient deployment of interpretable neural architectures.",
        "tags": [
            "KAN"
        ]
    },
    {
        "id": "282",
        "title": "AgentRL: Scaling Agentic Reinforcement Learning with a Multi-Turn, Multi-Task Framework",
        "author": [
            "Hanchen Zhang",
            "Xiao Liu",
            "Bowen Lv",
            "Xueqiao Sun",
            "Bohao Jing",
            "Iat Long Iong",
            "Zhenyu Hou",
            "Zehan Qi",
            "Hanyu Lai",
            "Yifan Xu",
            "Rui Lu",
            "Hongning Wang",
            "Jie Tang",
            "Yuxiao Dong"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04206",
        "abstract": "Recent advances in large language models (LLMs) have sparked growing interest in building generalist agents that can learn through online interactions. However, applying reinforcement learning (RL) to train LLM agents in multi-turn, multi-task settings remains challenging due to lack of scalable infrastructure and stable training algorithms. In this work, we present the AgentRL framework for scalable multi-turn, multi-task agentic RL training. On the infrastructure side, AgentRL features a fully-asynchronous generation-training pipeline for efficient multi-turn RL. To support heterogeneous environment development in multi-task RL, we design a unified function-call based API interface, containerized environment development, and a centralized controller. On the algorithm side, we propose cross-policy sampling to encourage model exploration in multi-turn settings and task advantage normalization to stabilize multi-task training. Experiments show that AgentRL, trained on open LLMs across five agentic tasks, significantly outperforms GPT-5, Clause-Sonnet-4, DeepSeek-R1, and other open-source LLM agents. Multi-task training with AgentRL matches the best results among all task-specific models. AgentRL is open-sourced at https://github.com/THUDM/AgentRL. The algorithm and framework are adopted in building \\textsc{\\href{https://autoglm.zhipuai.cn}{AutoGLM}}.",
        "tags": [
            "DeepSeek",
            "GPT",
            "LLM",
            "RL"
        ]
    },
    {
        "id": "283",
        "title": "Why Low-Precision Transformer Training Fails: An Analysis on Flash Attention",
        "author": [
            "Haiquan Qiu",
            "Quanming Yao"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04212",
        "abstract": "The pursuit of computational efficiency has driven the adoption of low-precision formats for training transformer models. However, this progress is often hindered by notorious training instabilities. This paper provides the first mechanistic explanation for a long-standing and unresolved failure case where training with flash attention in low-precision settings leads to catastrophic loss explosions. Our in-depth analysis reveals that the failure is not a random artifact but caused by two intertwined phenomena: the emergence of similar low-rank representations within the attention mechanism and the compounding effect of biased rounding errors inherent in low-precision arithmetic. We demonstrate how these factors create a vicious cycle of error accumulation that corrupts weight updates, ultimately derailing the training dynamics. To validate our findings, we introduce a minimal modification to the flash attention that mitigates the bias in rounding errors. This simple change stabilizes the training process, confirming our analysis and offering a practical solution to this persistent problem.",
        "tags": [
            "Flash Attention",
            "Transformer"
        ]
    },
    {
        "id": "284",
        "title": "Teaching LLM to be Persuasive: Reward-Enhanced Policy Optimization for Alignment frm Heterogeneous Rewards",
        "author": [
            "Zhuoran Zhuang",
            "Ye Chen",
            "Xia Zeng",
            "Chao Luo",
            "Luhui Liu",
            "Yihan Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04214",
        "abstract": "We study deploying large language models (LLMs) as business development (BD) agents for persuasive price negotiation in online travel agencies (OTAs), where aligning traveler affordability and hotel profitability directly affects bookings, partner relationships, and access to travel. The agent must follow a Standard Operating Procedure (SOP) while conducting multi-turn persuasion, interpreting colloquial inputs, and adhering to guardrails (no over-promising, no hallucinations). Conventional post-training -- supervised fine-tuning (SFT) or single-source reward optimization -- overfits scripts, misses nuanced persuasive style, and fails to enforce verifiable business constraints.\nWe propose Reward-Enhanced Policy Optimization (REPO), a reinforcement learning post-training framework that aligns an LLM with heterogeneous rewards: a preference-trained reward model (RM) for dense human alignment, a reward judge (RJ) for high-level persuasive behavior and SOP compliance, and programmatic reward functions (RF) for deterministic checks on numerics, formatting, and guardrails. A straightforward enhancement mechanism is proposed to combine the RM with RJ and RF signals to curb reward hacking and improve negotiation quality. In production-style evaluations -- approximately 150 turns from real dialogues and 225 turns from curated bad-case dialogues -- REPO lifts average dialogue rating to 4.63: +1.20 over base, +0.83 over Direct Preference Optimization (DPO); +0.33 over Group Relative Policy Optimization (GRPO), increases the share of conversations with at least one excellent response to 66.67% (+23.34 percentage points over GRPO), and achieves a 93.33% bad-case fix rate with 75.56% clean fixes, outperforming SFT, DPO, PPO, and GRPO. We also observe emergent capabilities -- proactive empathy, localized reasoning, calibrated tactics -- that surpass gold annotations.",
        "tags": [
            "DPO",
            "GRPO",
            "LLM",
            "PPO",
            "RL"
        ]
    },
    {
        "id": "285",
        "title": "MLLMEraser: Achieving Test-Time Unlearning in Multimodal Large Language Models through Activation Steering",
        "author": [
            "Chenlu Ding",
            "Jiancan Wu",
            "Leheng Sheng",
            "Fan Zhang",
            "Yancheng Yuan",
            "Xiang Wang",
            "Xiangnan He"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04217",
        "abstract": "Multimodal large language models (MLLMs) have demonstrated remarkable capabilities across vision-language tasks, yet their large-scale deployment raises pressing concerns about memorized private data, outdated knowledge, and harmful content. Existing unlearning approaches for MLLMs typically adapt training-based strategies such as gradient ascent or preference optimization, but these methods are computationally expensive, irreversible, and often distort retained knowledge. In this work, we propose MLLMEraser, an input-aware, training-free framework for test-time unlearning. Our approach leverages activation steering to enable dynamic knowledge erasure without parameter updates. Specifically, we construct a multimodal erasure direction by contrasting adversarially perturbed, knowledge-recall image-text pairs with knowledge-erasure counterparts, capturing both textual and visual discrepancies. To prevent unnecessary interference, we further design an input-aware steering mechanism that adaptively determines when and how the erasure direction should be applied, preserving utility on retained knowledge while enforcing forgetting on designated content. Experiments on LLaVA-1.5 and Qwen-2.5-VL demonstrate that MLLMEraser consistently outperforms state-of-the-art MLLM unlearning baselines, achieving stronger forgetting performance with lower computational cost and minimal utility degradation.",
        "tags": [
            "LLM",
            "LLaVA",
            "Qwen"
        ]
    },
    {
        "id": "286",
        "title": "Zoom-In to Sort AI-Generated Images Out",
        "author": [
            "Yikun Ji",
            "Yan Hong",
            "Bowen Deng",
            "jun lan",
            "Huijia Zhu",
            "Weiqiang Wang",
            "Liqing Zhang",
            "Jianfu Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04225",
        "abstract": "The rapid growth of AI-generated imagery has blurred the boundary between real and synthetic content, raising critical concerns for digital integrity. Vision-language models (VLMs) offer interpretability through explanations but often fail to detect subtle artifacts in high-quality synthetic images. We propose ZoomIn, a two-stage forensic framework that improves both accuracy and interpretability. Mimicking human visual inspection, ZoomIn first scans an image to locate suspicious regions and then performs a focused analysis on these zoomed-in areas to deliver a grounded verdict. To support training, we introduce MagniFake, a dataset of 20,000 real and high-quality synthetic images annotated with bounding boxes and forensic explanations, generated through an automated VLM-based pipeline. Our method achieves 96.39% accuracy with robust generalization, while providing human-understandable explanations grounded in visual evidence.",
        "tags": [
            "VLM"
        ]
    },
    {
        "id": "287",
        "title": "Epistemic Diversity and Knowledge Collapse in Large Language Models",
        "author": [
            "Dustin Wright",
            "Sarah Masud",
            "Jared Moore",
            "Srishti Yadav",
            "Maria Antoniak",
            "Chan Young Park",
            "Isabelle Augenstein"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04226",
        "abstract": "Large language models (LLMs) tend to generate lexically, semantically, and stylistically homogenous texts. This poses a risk of knowledge collapse, where homogenous LLMs mediate a shrinking in the range of accessible information over time. Existing works on homogenization are limited by a focus on closed-ended multiple-choice setups or fuzzy semantic features, and do not look at trends across time and cultural contexts. To overcome this, we present a new methodology to measure epistemic diversity, i.e., variation in real-world claims in LLM outputs, which we use to perform a broad empirical study of LLM knowledge collapse. We test 27 LLMs, 155 topics covering 12 countries, and 200 prompt variations sourced from real user chats. For the topics in our study, we show that while newer models tend to generate more diverse claims, nearly all models are less epistemically diverse than a basic web search. We find that model size has a negative impact on epistemic diversity, while retrieval-augmented generation (RAG) has a positive impact, though the improvement from RAG varies by the cultural context. Finally, compared to a traditional knowledge source (Wikipedia), we find that country-specific claims reflect the English language more than the local one, highlighting a gap in epistemic representation",
        "tags": [
            "LLM",
            "RAG"
        ]
    },
    {
        "id": "288",
        "title": "Pushing on Multilingual Reasoning Models with Language-Mixed Chain-of-Thought",
        "author": [
            "Guijin Son",
            "Donghun Yang",
            "Hitesh Laxmichand Patel",
            "Amit Agarwal",
            "Hyunwoo Ko",
            "Chanuk Lim",
            "Srikant Panda",
            "Minhyuk Kim",
            "Nikunj Drolia",
            "Dasol Choi",
            "Kyong-Ha Lee",
            "Youngjae Yu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04230",
        "abstract": "Recent frontier models employ long chain-of-thought reasoning to explore solution spaces in context and achieve stonger performance. While many works study distillation to build smaller yet capable models, most focus on English and little is known about language-specific reasoning. To bridge this gap, we first introduct **Language-Mixed CoT**, a reasoning schema that switches between English and a target language, using English as an anchor to excel in reasoning while minimizing translation artificats. As a Korean case study, we curate **Yi-Sang**: 5.79M native-Korean prompts from web Q&A, exams, STEM, and code; 3.7M long reasoning traces generated from Qwen3-32B; and a targeted 260k high-yield subset. We train ninve models (4B-35B) across six families (Qwen2.5, Llama-3.1, Gemma-3, etc). Our best model, **KO-REAson-35B**, achieves state-of-the-art performance, with the highest overall average score (64.0 \\pm 25), ranking first on 5/9 benchmarks and second on the remainder. Samller and mid-sized models also benefit substantially, with an average improvement of +18.6 points across teh evaluated nine benchmarks. Ablations show **Language-Mixed CoT** is more effective than monolingual CoT, also resulting in cross-lingual and mult-modal performance gains. We release our data-curation pipeline, evaluation system, datasets, and models to advance research on language-specific reasoning. Data and model collection: https://huggingface.co/KOREAson.",
        "tags": [
            "CoT",
            "LLaMA"
        ]
    },
    {
        "id": "289",
        "title": "Flexible Locomotion Learning with Diffusion Model Predictive Control",
        "author": [
            "Runhan Huang",
            "Haldun Balim",
            "Heng Yang",
            "Yilun Du"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04234",
        "abstract": "Legged locomotion demands controllers that are both robust and adaptable, while remaining compatible with task and safety considerations. However, model-free reinforcement learning (RL) methods often yield a fixed policy that can be difficult to adapt to new behaviors at test time. In contrast, Model Predictive Control (MPC) provides a natural approach to flexible behavior synthesis by incorporating different objectives and constraints directly into its optimization process. However, classical MPC relies on accurate dynamics models, which are often difficult to obtain in complex environments and typically require simplifying assumptions. We present Diffusion-MPC, which leverages a learned generative diffusion model as an approximate dynamics prior for planning, enabling flexible test-time adaptation through reward and constraint based optimization. Diffusion-MPC jointly predicts future states and actions; at each reverse step, we incorporate reward planning and impose constraint projection, yielding trajectories that satisfy task objectives while remaining within physical limits. To obtain a planning model that adapts beyond imitation pretraining, we introduce an interactive training algorithm for diffusion based planner: we execute our reward-and-constraint planner in environment, then filter and reweight the collected trajectories by their realized returns before updating the denoiser. Our design enables strong test-time adaptability, allowing the planner to adjust to new reward specifications without retraining. We validate Diffusion-MPC on real world, demonstrating strong locomotion and flexible adaptation.",
        "tags": [
            "Diffusion",
            "MPC",
            "RL"
        ]
    },
    {
        "id": "290",
        "title": "Scaling Sequence-to-Sequence Generative Neural Rendering",
        "author": [
            "Shikun Liu",
            "Kam Woh Ng",
            "Wonbong Jang",
            "Jiadong Guo",
            "Junlin Han",
            "Haozhe Liu",
            "Yiannis Douratsos",
            "Juan C. PÃ©rez",
            "Zijian Zhou",
            "Chi Phung",
            "Tao Xiang",
            "Juan-Manuel PÃ©rez-RÃºa"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04236",
        "abstract": "We present Kaleido, a family of generative models designed for photorealistic, unified object- and scene-level neural rendering. Kaleido operates on the principle that 3D can be regarded as a specialised sub-domain of video, expressed purely as a sequence-to-sequence image synthesis task. Through a systemic study of scaling sequence-to-sequence generative neural rendering, we introduce key architectural innovations that enable our model to: i) perform generative view synthesis without explicit 3D representations; ii) generate any number of 6-DoF target views conditioned on any number of reference views via a masked autoregressive framework; and iii) seamlessly unify 3D and video modelling within a single decoder-only rectified flow transformer. Within this unified framework, Kaleido leverages large-scale video data for pre-training, which significantly improves spatial consistency and reduces reliance on scarce, camera-labelled 3D datasets -- all without any architectural modifications. Kaleido sets a new state-of-the-art on a range of view synthesis benchmarks. Its zero-shot performance substantially outperforms other generative methods in few-view settings, and, for the first time, matches the quality of per-scene optimisation methods in many-view settings.",
        "tags": [
            "3D",
            "Rectified Flow",
            "Transformer"
        ]
    },
    {
        "id": "291",
        "title": "Diffusion-Assisted Distillation for Self-Supervised Graph Representation Learning with MLPs",
        "author": [
            "Seong Jin Ahn",
            "Myoung-Ho Kim"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04241",
        "abstract": "For large-scale applications, there is growing interest in replacing Graph Neural Networks (GNNs) with lightweight Multi-Layer Perceptrons (MLPs) via knowledge distillation. However, distilling GNNs for self-supervised graph representation learning into MLPs is more challenging. This is because the performance of self-supervised learning is more related to the model's inductive bias than supervised learning. This motivates us to design a new distillation method to bridge a huge capacity gap between GNNs and MLPs in self-supervised graph representation learning. In this paper, we propose \\textbf{D}iffusion-\\textbf{A}ssisted \\textbf{D}istillation for \\textbf{S}elf-supervised \\textbf{G}raph representation learning with \\textbf{M}LPs (DAD-SGM). The proposed method employs a denoising diffusion model as a teacher assistant to better distill the knowledge from the teacher GNN into the student MLP. This approach enhances the generalizability and robustness of MLPs in self-supervised graph representation learning. Extensive experiments demonstrate that DAD-SGM effectively distills the knowledge of self-supervised GNNs compared to state-of-the-art GNN-to-MLP distillation methods. Our implementation is available at https://github.com/SeongJinAhn/DAD-SGM.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "292",
        "title": "ContextVLA: Vision-Language-Action Model with Amortized Multi-Frame Context",
        "author": [
            "Huiwon Jang",
            "Sihyun Yu",
            "Heeseung Kwon",
            "Hojin Jeon",
            "Younggyo Seo",
            "Jinwoo Shin"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04246",
        "abstract": "Leveraging temporal context is crucial for success in partially observable robotic tasks. However, prior work in behavior cloning has demonstrated inconsistent performance gains when using multi-frame observations. In this paper, we introduce ContextVLA, a policy model that robustly improves robotic task performance by effectively leveraging multi-frame observations. Our approach is motivated by the key observation that Vision-Language-Action models (VLA), i.e., policy models built upon a Vision-Language Model (VLM), more effectively utilize multi-frame observations for action generation. This suggests that VLMs' inherent temporal understanding capability enables them to extract more meaningful context from multi-frame observations. However, the high dimensionality of video inputs introduces significant computational overhead, making VLA training and inference inefficient. To address this, ContextVLA compresses past observations into a single context token, allowing the policy to efficiently leverage temporal context for action generation. Our experiments show that ContextVLA consistently improves over single-frame VLAs and achieves the benefits of full multi-frame training but with reduced training and inference times.",
        "tags": [
            "VLM"
        ]
    },
    {
        "id": "293",
        "title": "AgentTypo: Adaptive Typographic Prompt Injection Attacks against Black-box Multimodal Agents",
        "author": [
            "Yanjie Li",
            "Yiming Cao",
            "Dong Wang",
            "Bin Xiao"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04257",
        "abstract": "Multimodal agents built on large vision-language models (LVLMs) are increasingly deployed in open-world settings but remain highly vulnerable to prompt injection, especially through visual inputs. We introduce AgentTypo, a black-box red-teaming framework that mounts adaptive typographic prompt injection by embedding optimized text into webpage images. Our automatic typographic prompt injection (ATPI) algorithm maximizes prompt reconstruction by substituting captioners while minimizing human detectability via a stealth loss, with a Tree-structured Parzen Estimator guiding black-box optimization over text placement, size, and color. To further enhance attack strength, we develop AgentTypo-pro, a multi-LLM system that iteratively refines injection prompts using evaluation feedback and retrieves successful past examples for continual learning. Effective prompts are abstracted into generalizable strategies and stored in a strategy repository, enabling progressive knowledge accumulation and reuse in future attacks. Experiments on the VWA-Adv benchmark across Classifieds, Shopping, and Reddit scenarios show that AgentTypo significantly outperforms the latest image-based attacks such as AgentAttack. On GPT-4o agents, our image-only attack raises the success rate from 0.23 to 0.45, with consistent results across GPT-4V, GPT-4o-mini, Gemini 1.5 Pro, and Claude 3 Opus. In image+text settings, AgentTypo achieves 0.68 ASR, also outperforming the latest baselines. Our findings reveal that AgentTypo poses a practical and potent threat to multimodal agents and highlight the urgent need for effective defense.",
        "tags": [
            "GPT",
            "LLM",
            "VLM"
        ]
    },
    {
        "id": "294",
        "title": "VortexPIA: Indirect Prompt Injection Attack against LLMs for Efficient Extraction of User Privacy",
        "author": [
            "Yu Cui",
            "Sicheng Pan",
            "Yifei Liu",
            "Haibin Zhang",
            "Cong Zuo"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04261",
        "abstract": "Large language models (LLMs) have been widely deployed in Conversational AIs (CAIs), while exposing privacy and security threats. Recent research shows that LLM-based CAIs can be manipulated to extract private information from human users, posing serious security threats. However, the methods proposed in that study rely on a white-box setting that adversaries can directly modify the system prompt. This condition is unlikely to hold in real-world deployments. The limitation raises a critical question: can unprivileged attackers still induce such privacy risks in practical LLM-integrated applications? To address this question, we propose \\textsc{VortexPIA}, a novel indirect prompt injection attack that induces privacy extraction in LLM-integrated applications under black-box settings. By injecting token-efficient data containing false memories, \\textsc{VortexPIA} misleads LLMs to actively request private information in batches. Unlike prior methods, \\textsc{VortexPIA} allows attackers to flexibly define multiple categories of sensitive data. We evaluate \\textsc{VortexPIA} on six LLMs, covering both traditional and reasoning LLMs, across four benchmark datasets. The results show that \\textsc{VortexPIA} significantly outperforms baselines and achieves state-of-the-art (SOTA) performance. It also demonstrates efficient privacy requests, reduced token consumption, and enhanced robustness against defense mechanisms. We further validate \\textsc{VortexPIA} on multiple realistic open-source LLM-integrated applications, demonstrating its practical effectiveness.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "295",
        "title": "Don't Pass$\\mathtt{@}k$: A Bayesian Framework for Large Language Model Evaluation",
        "author": [
            "Mohsen Hariri",
            "Amirhossein Samandar",
            "Michael Hinczewski",
            "Vipin Chaudhary"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04265",
        "abstract": "Pass$@k$ is widely used to report performance for LLM reasoning, but it often yields unstable, misleading rankings, especially when the number of trials (samples) is limited and compute is constrained. We present a principled Bayesian evaluation framework that replaces Pass$@k$ and average accuracy over $N$ trials (avg$@N$) with posterior estimates of a model's underlying success probability and credible intervals, yielding stable rankings and a transparent decision rule for differences. Evaluation outcomes are modeled as categorical (not just 0/1) with a Dirichlet prior, giving closed-form expressions for the posterior mean and uncertainty of any weighted rubric and enabling the use of prior evidence when appropriate. Theoretically, under a uniform prior, the Bayesian posterior mean is order-equivalent to average accuracy (Pass$@1$), explaining its empirical robustness while adding principled uncertainty. Empirically, in simulations with known ground-truth success rates and on AIME'24/'25, HMMT'25, and BrUMO'25, the Bayesian/avg procedure achieves faster convergence and greater rank stability than Pass$@k$ and recent variants, enabling reliable comparisons at far smaller sample counts. The framework clarifies when observed gaps are statistically meaningful (non-overlapping credible intervals) versus noise, and it naturally extends to graded, rubric-based evaluations. Together, these results recommend replacing Pass$@k$ for LLM evaluation and ranking with a posterior-based, compute-efficient protocol that unifies binary and non-binary evaluation while making uncertainty explicit. Code is available at https://mohsenhariri.github.io/bayes-kit",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "296",
        "title": "Small Fleet, Big Impact: Enhancing Shared Micromobility Efficiency through Minimal Autonomous Vehicle Deployment",
        "author": [
            "Heng Tan",
            "Hua Yan",
            "Lucas Yang",
            "Yu Yang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04271",
        "abstract": "Shared micromobility systems, such as electric scooters and bikes, have gained widespread popularity as sustainable alternatives to traditional transportation modes. However, these systems face persistent challenges due to spatio-temporal demand fluctuations, often resulting in a mismatch between vehicle supply and user demand. Existing shared micromobility vehicle scheduling methods typically redistribute vehicles once or twice per day, which makes them vulnerable to performance degradation under atypical conditions. In this work, we design to augment existing micromobility scheduling methods by integrating a small number of autonomous shared micromobility vehicles (ASMVs), which possess self-rebalancing capabilities to dynamically adapt to real-time demand. Specifically, we introduce SMART, a hierarchical reinforcement learning framework that jointly optimizes high-level initial deployment and low-level real-time rebalancing for ASMVs. We evaluate our framework based on real-world e-scooter usage data from Chicago. Our experiment results show that our framework is highly effective and possesses strong generalization capability, allowing it to seamlessly integrate with existing vehicle scheduling methods and significantly enhance overall micromobility service performance.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "297",
        "title": "Selecting Cybersecurity Requirements: Effects of LLM Use and Professional Software Development Experience",
        "author": [
            "Damjan Fujs",
            "Damjan VavpotiÄ",
            "TomaÅ¾ Hovelja",
            "Marko PoÅ¾enel"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04274",
        "abstract": "This study investigates how access to Large Language Models (LLMs) and varying levels of professional software development experience affect the prioritization of cybersecurity requirements for web applications. Twenty-three postgraduate students participated in a research study to prioritize security requirements (SRs) using the MoSCoW method and subsequently rated their proposed solutions against multiple evaluation criteria. We divided participants into two groups (one with and the other without access to LLM support during the task). Results showed no significant differences related to LLM use, suggesting that access to LLMs did not noticeably influence how participants evaluated cybersecurity solutions. However, statistically significant differences emerged between experience groups for certain criteria, such as estimated cost to develop a feature, perceived impact on user experience, and risk assessment related to non-implementation of the proposed feature. Participants with more professional experience tended to provide higher ratings for user experience impact and lower risk estimates.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "298",
        "title": "A KL-regularization framework for learning to plan with adaptive priors",
        "author": [
            "Ãlvaro Serra-Gomez",
            "Daniel Jarne Ornia",
            "Dhruva Tirumala",
            "Thomas Moerland"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04280",
        "abstract": "Effective exploration remains a central challenge in model-based reinforcement learning (MBRL), particularly in high-dimensional continuous control tasks where sample efficiency is crucial. A prominent line of recent work leverages learned policies as proposal distributions for Model-Predictive Path Integral (MPPI) planning. Initial approaches update the sampling policy independently of the planner distribution, typically maximizing a learned value function with deterministic policy gradient and entropy regularization. However, because the states encountered during training depend on the MPPI planner, aligning the sampling policy with the planner improves the accuracy of value estimation and long-term performance. To this end, recent methods update the sampling policy by minimizing KL divergence to the planner distribution or by introducing planner-guided regularization into the policy update. In this work, we unify these MPPI-based reinforcement learning methods under a single framework by introducing Policy Optimization-Model Predictive Control (PO-MPC), a family of KL-regularized MBRL methods that integrate the planner's action distribution as a prior in policy optimization. By aligning the learned policy with the planner's behavior, PO-MPC allows more flexibility in the policy updates to trade off Return maximization and KL divergence minimization. We clarify how prior approaches emerge as special cases of this family, and we explore previously unstudied variations. Our experiments show that these extended configurations yield significant performance improvements, advancing the state of the art in MPPI-based RL.",
        "tags": [
            "MPC",
            "RL"
        ]
    },
    {
        "id": "299",
        "title": "Flexible and Efficient Spatio-Temporal Transformer for Sequential Visual Place Recognition",
        "author": [
            "Yu Kiu",
            "Chao Chen",
            "Ge Jin",
            "Chen Feng"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04282",
        "abstract": "Sequential Visual Place Recognition (Seq-VPR) leverages transformers to capture spatio-temporal features effectively; however, existing approaches prioritize performance at the expense of flexibility and efficiency. In practice, a transformer-based Seq-VPR model should be flexible to the number of frames per sequence (seq-length), deliver fast inference, and have low memory usage to meet real-time constraints. To our knowledge, no existing transformer-based Seq-VPR method achieves both flexibility and efficiency. To address this gap, we propose Adapt-STformer, a Seq-VPR method built around our novel Recurrent Deformable Transformer Encoder (Recurrent-DTE), which uses an iterative recurrent mechanism to fuse information from multiple sequential frames. This design naturally supports variable seq-lengths, fast inference, and low memory usage. Experiments on the Nordland, Oxford, and NuScenes datasets show that Adapt-STformer boosts recall by up to 17% while reducing sequence extraction time by 36% and lowering memory usage by 35% compared to the second-best baseline.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "300",
        "title": "Probing Geometry of Next Token Prediction Using Cumulant Expansion of the Softmax Entropy",
        "author": [
            "Karthik Viswanathan",
            "Sang Eon Park"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04285",
        "abstract": "We introduce a cumulant-expansion framework for quantifying how large language models (LLMs) internalize higher-order statistical structure during next-token prediction. By treating the softmax entropy of each layer's logit distribution as a perturbation around its \"center\" distribution, we derive closed-form cumulant observables that isolate successively higher-order correlations. Empirically, we track these cumulants in GPT-2 and Pythia models on Pile-10K prompts. (i) Structured prompts exhibit a characteristic rise-and-plateau profile across layers, whereas token-shuffled prompts remain flat, revealing the dependence of the cumulant profile on meaningful context. (ii) During training, all cumulants increase monotonically before saturating, directly visualizing the model's progression from capturing variance to learning skew, kurtosis, and higher-order statistical structures. (iii) Mathematical prompts show distinct cumulant signatures compared to general text, quantifying how models employ fundamentally different processing mechanisms for mathematical versus linguistic content. Together, these results establish cumulant analysis as a lightweight, mathematically grounded probe of feature-learning dynamics in high-dimensional neural networks.",
        "tags": [
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "301",
        "title": "SliceMoE: Routing Embedding Slices Instead of Tokens for Fine-Grained and Balanced Transformer Scaling",
        "author": [
            "Harshil Vejendla"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04286",
        "abstract": "Mixture-of-Experts (MoE) layers scale transformers by routing tokens to a sparse subset of feed-forward experts. Token-level routing, however, assigns an entire semantic spectrum to each expert, creating capacity bottlenecks, load-balancing pathologies, and limited specialization. We introduce SliceMoE, an architecture that routes contiguous slices of a token's hidden vector. A d-dimensional embedding is partitioned into S slices, and for each slice, a lightweight shared router predicts the top-k experts. Experts operate on their assigned slices independently, and outputs are reassembled, maintaining per-token FLOP efficiency. Because slices from different tokens interleave within an expert, utilization is naturally smoother. We propose a slice-level capacity loss, cross-slice dropout, and efficient fused batched GEMM kernels. Experiments on WikiText-103 language modeling, WMT En-De translation, and three text-classification datasets show SliceMoE attains up to 1.7x faster inference than dense baselines, 12 to 18 percent lower perplexity than parameter-matched token-MoE, and improved expert balance, with interpretable expertise over syntactic versus semantic subspaces.",
        "tags": [
            "MoE",
            "Transformer"
        ]
    },
    {
        "id": "302",
        "title": "ChronoEdit: Towards Temporal Reasoning for Image Editing and World Simulation",
        "author": [
            "Jay Zhangjie Wu",
            "Xuanchi Ren",
            "Tianchang Shen",
            "Tianshi Cao",
            "Kai He",
            "Yifan Lu",
            "Ruiyuan Gao",
            "Enze Xie",
            "Shiyi Lan",
            "Jose M. Alvarez",
            "Jun Gao",
            "Sanja Fidler",
            "Zian Wang",
            "Huan Ling"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04290",
        "abstract": "Recent advances in large generative models have significantly advanced image editing and in-context image generation, yet a critical gap remains in ensuring physical consistency, where edited objects must remain coherent. This capability is especially vital for world simulation related tasks. In this paper, we present ChronoEdit, a framework that reframes image editing as a video generation problem. First, ChronoEdit treats the input and edited images as the first and last frames of a video, allowing it to leverage large pretrained video generative models that capture not only object appearance but also the implicit physics of motion and interaction through learned temporal consistency. Second, ChronoEdit introduces a temporal reasoning stage that explicitly performs editing at inference time. Under this setting, the target frame is jointly denoised with reasoning tokens to imagine a plausible editing trajectory that constrains the solution space to physically viable transformations. The reasoning tokens are then dropped after a few steps to avoid the high computational cost of rendering a full video. To validate ChronoEdit, we introduce PBench-Edit, a new benchmark of image-prompt pairs for contexts that require physical consistency, and demonstrate that ChronoEdit surpasses state-of-the-art baselines in both visual fidelity and physical plausibility. Code and models for both the 14B and 2B variants of ChronoEdit will be released on the project page: https://research.nvidia.com/labs/toronto-ai/chronoedit",
        "tags": [
            "Image Editing",
            "Video Generation"
        ]
    },
    {
        "id": "303",
        "title": "PABSA: Hybrid Framework for Persian Aspect-Based Sentiment Analysis",
        "author": [
            "Mehrzad Tareh",
            "Aydin Mohandesi",
            "Ebrahim Ansari"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04291",
        "abstract": "Sentiment analysis is a key task in Natural Language Processing (NLP), enabling the extraction of meaningful insights from user opinions across various domains. However, performing sentiment analysis in Persian remains challenging due to the scarcity of labeled datasets, limited preprocessing tools, and the lack of high-quality embeddings and feature extraction methods. To address these limitations, we propose a hybrid approach that integrates machine learning (ML) and deep learning (DL) techniques for Persian aspect-based sentiment analysis (ABSA). In particular, we utilize polarity scores from multilingual BERT as additional features and incorporate them into a decision tree classifier, achieving an accuracy of 93.34%-surpassing existing benchmarks on the Pars-ABSA dataset. Additionally, we introduce a Persian synonym and entity dictionary, a novel linguistic resource that supports text augmentation through synonym and named entity replacement. Our results demonstrate the effectiveness of hybrid modeling and feature augmentation in advancing sentiment analysis for low-resource languages such as Persian.",
        "tags": [
            "BERT"
        ]
    },
    {
        "id": "304",
        "title": "Equipping Retrieval-Augmented Large Language Models with Document Structure Awareness",
        "author": [
            "Lingnan Xu",
            "Chong Feng",
            "Kaiyuan Zhang",
            "Liu Zhengyong",
            "Wenqiang Xu",
            "Fanqing Meng"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04293",
        "abstract": "While large language models (LLMs) demonstrate impressive capabilities, their reliance on parametric knowledge often leads to factual inaccuracies. Retrieval-Augmented Generation (RAG) mitigates this by leveraging external documents, yet existing approaches treat retrieved passages as isolated chunks, ignoring valuable structure that is crucial for document organization. Motivated by this gap, we propose Retrieve-DocumentRoute-Read (RDR2), a novel framework that explicitly incorporates structural information throughout the RAG process. RDR2 employs an LLM-based router to dynamically navigate document structure trees, jointly evaluating content relevance and hierarchical relationships to assemble optimal evidence. Our key innovation lies in formulating document routing as a trainable task, with automatic action curation and structure-aware passage selection inspired by human reading strategies. Through comprehensive evaluation on five challenging datasets, RDR2 achieves state-of-the-art performance, demonstrating that explicit structural awareness significantly enhances RAG systems' ability to acquire and utilize knowledge, particularly in complex scenarios requiring multi-document synthesis.",
        "tags": [
            "LLM",
            "RAG"
        ]
    },
    {
        "id": "305",
        "title": "HoRA: Cross-Head Low-Rank Adaptation with Joint Hypernetworks",
        "author": [
            "Nghiem T. Diep",
            "Dung Le",
            "Tuan Truong",
            "Tan Dinh",
            "Huy Nguyen",
            "Nhat Ho"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04295",
        "abstract": "Low-Rank Adaptation (LoRA) is a parameter-efficient fine-tuning (PEFT) technique that adapts large pre-trained models by adding low-rank matrices to their weight updates. However, in the context of fine-tuning multi-head self-attention (MHA), LoRA has been employed to adapt each attention head separately, thereby overlooking potential synergies across different heads. To mitigate this issue, we propose a novel Hyper-shared Low-Rank Adaptation (HoRA) method, which utilizes joint hypernetworks to generate low-rank matrices across attention heads. By coupling their adaptation through a shared generator, HoRA encourages cross-head information sharing, and thus directly addresses the aforementioned limitation of LoRA. By comparing LoRA and HoRA through the lens of hierarchical mixture of experts, our theoretical findings reveal that the latter achieves superior sample efficiency to the former. Furthermore, through extensive experiments across diverse language and vision benchmarks, we demonstrate that HoRA outperforms LoRA and other PEFT methods while requiring only a marginal increase in the number of trainable parameters.",
        "tags": [
            "LoRA",
            "MoE"
        ]
    },
    {
        "id": "306",
        "title": "Wave-PDE Nets: Trainable Wave-Equation Layers as an Alternative to Attention",
        "author": [
            "Harshil Vejendla"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04304",
        "abstract": "We introduce Wave-PDE Nets, a neural architecture whose elementary operation is a differentiable simulation of the second-order wave equation. Each layer propagates its hidden state as a continuous field through a medium with trainable spatial velocity c(x) and damping {\\gamma}(x). A symplectic spectral solver based on FFTs realises this propagation in O(nlog n) time. This oscillatory, global mechanism provides a powerful alternative to attention and first-order state-space models. We prove that a single Wave-PDE layer is a universal approximator. On language and vision benchmarks, Wave-PDE Nets match or exceed Transformer performance while demonstrating superior practical efficiency, reducing wall-clock time by up to 30% and peak memory by 25%. Ablation studies confirm the critical role of symplectic integration and a spectral Laplacian for stability and performance. Visualizations of the learned physical parameters reveal that the model learns intuitive strategies for information propagation. These results position Wave-PDE Nets as a computationally efficient and robust architecture with a strong physical inductive bias.",
        "tags": [
            "SSMs",
            "Transformer"
        ]
    },
    {
        "id": "307",
        "title": "Activation Steering with a Feedback Controller",
        "author": [
            "Dung V. Nguyen",
            "Hieu M. Vu",
            "Nhi Y. Pham",
            "Lei Zhang",
            "Tan M. Nguyen"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04309",
        "abstract": "Controlling the behaviors of large language models (LLM) is fundamental to their safety alignment and reliable deployment. However, existing steering methods are primarily driven by empirical insights and lack theoretical performance guarantees. In this work, we develop a control-theoretic foundation for activation steering by showing that popular steering methods correspond to the proportional (P) controllers, with the steering vector serving as the feedback signal. Building on this finding, we propose Proportional-Integral-Derivative (PID) Steering, a principled framework that leverages the full PID controller for activation steering in LLMs. The proportional (P) term aligns activations with target semantic directions, the integral (I) term accumulates errors to enforce persistent corrections across layers, and the derivative (D) term mitigates overshoot by counteracting rapid activation changes. This closed-loop design yields interpretable error dynamics and connects activation steering to classical stability guarantees in control theory. Moreover, PID Steering is lightweight, modular, and readily integrates with state-of-the-art steering methods. Extensive experiments across multiple LLM families and benchmarks demonstrate that PID Steering consistently outperforms existing approaches, achieving more robust and reliable behavioral control.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "308",
        "title": "On the Importance of Task Complexity in Evaluating LLM-Based Multi-Agent Systems",
        "author": [
            "Bohan Tang",
            "Huidong Liang",
            "Keyue Jiang",
            "Xiaowen Dong"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04311",
        "abstract": "Large language model multi-agent systems (LLM-MAS) offer a promising paradigm for harnessing collective intelligence to achieve more advanced forms of AI behaviour. While recent studies suggest that LLM-MAS can outperform LLM single-agent systems (LLM-SAS) on certain tasks, the lack of systematic experimental designs limits the strength and generality of these conclusions. We argue that a principled understanding of task complexity, such as the degree of sequential reasoning required and the breadth of capabilities involved, is essential for assessing the effectiveness of LLM-MAS in task solving. To this end, we propose a theoretical framework characterising tasks along two dimensions: depth, representing reasoning length, and width, representing capability diversity. We theoretically examine a representative class of LLM-MAS, namely the multi-agent debate system, and empirically evaluate its performance in both discriminative and generative tasks with varying depth and width. Theoretical and empirical results show that the benefit of LLM-MAS over LLM-SAS increases with both task depth and width, and the effect is more pronounced with respect to depth. This clarifies when LLM-MAS are beneficial and provides a principled foundation for designing future LLM-MAS methods and benchmarks.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "309",
        "title": "FairAgent: Democratizing Fairness-Aware Machine Learning with LLM-Powered Agents",
        "author": [
            "Yucong Dai",
            "Lu Zhang",
            "Feng Luo",
            "Mashrur Chowdhury",
            "Yongkai Wu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04317",
        "abstract": "Training fair and unbiased machine learning models is crucial for high-stakes applications, yet it presents significant challenges. Effective bias mitigation requires deep expertise in fairness definitions, metrics, data preprocessing, and machine learning techniques. In addition, the complex process of balancing model performance with fairness requirements while properly handling sensitive attributes makes fairness-aware model development inaccessible to many practitioners. To address these challenges, we introduce FairAgent, an LLM-powered automated system that significantly simplifies fairness-aware model development. FairAgent eliminates the need for deep technical expertise by automatically analyzing datasets for potential biases, handling data preprocessing and feature engineering, and implementing appropriate bias mitigation strategies based on user requirements. Our experiments demonstrate that FairAgent achieves significant performance improvements while significantly reducing development time and expertise requirements, making fairness-aware machine learning more accessible to practitioners.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "310",
        "title": "Read the Scene, Not the Script: Outcome-Aware Safety for LLMs",
        "author": [
            "Rui Wu",
            "Yihao Quan",
            "Zeru Shi",
            "Zhenting Wang",
            "Yanshu Li",
            "Ruixiang Tang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04320",
        "abstract": "Safety-aligned Large Language Models (LLMs) still show two dominant failure modes: they are easily jailbroken, or they over-refuse harmless inputs that contain sensitive surface signals. We trace both to a common cause: current models reason weakly about links between actions and outcomes and over-rely on surface-form signals, lexical or stylistic cues that do not encode consequences. We define this failure mode as Consequence-blindness. To study consequence-blindness, we build a benchmark named CB-Bench covering four risk scenarios that vary whether semantic risk aligns with outcome risk, enabling evaluation under both matched and mismatched conditions which are often ignored by existing safety benchmarks. Mainstream models consistently fail to separate these risks and exhibit consequence-blindness, indicating that consequence-blindness is widespread and systematic. To mitigate consequence-blindness, we introduce CS-Chain-4k, a consequence-reasoning dataset for safety alignment. Models fine-tuned on CS-Chain-4k show clear gains against semantic-camouflage jailbreaks and reduce over-refusal on harmless inputs, while maintaining utility and generalization on other benchmarks. These results clarify the limits of current alignment, establish consequence-aware reasoning as a core alignment goal and provide a more practical and reproducible evaluation path.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "311",
        "title": "FoilDiff: A Hybrid Transformer Backbone for Diffusion-based Modelling of 2D Airfoil Flow Fields",
        "author": [
            "Kenechukwu Ogbuagu",
            "Sepehr Maleki",
            "Giuseppe Bruni",
            "Senthil Krishnababu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04325",
        "abstract": "The accurate prediction of flow fields around airfoils is crucial for aerodynamic design and optimisation. Computational Fluid Dynamics (CFD) models are effective but computationally expensive, thus inspiring the development of surrogate models to enable quicker predictions. These surrogate models can be based on deep learning architectures, such as Convolutional Neural Networks (CNNs), Graph Neural Networks (GNNs), and Diffusion Models (DMs). Diffusion models have shown significant promise in predicting complex flow fields. In this work, we propose FoilDiff, a diffusion-based surrogate model with a hybrid-backbone denoising network. This hybrid design combines the power of convolutional feature extraction and transformer-based global attention to generate more adaptable and accurate representations of flow structures. FoilDiff takes advantage of Denoising Diffusion Implicit Model (DDIM) sampling to optimise the efficiency of the sampling process at no additional cost to model generalisation. We used encoded representations of Reynolds number, angle of attack, and airfoil geometry to define the input space for generalisation across a wide range of aerodynamic conditions. When evaluated against state-of-the-art models, FoilDiff shows significant performance improvements, with mean prediction errors reducing by up to 85\\% on the same datasets. The results have demonstrated that FoilDiff can provide both more accurate predictions and better-calibrated predictive uncertainty than existing diffusion-based models.",
        "tags": [
            "DDIM",
            "Diffusion",
            "Transformer"
        ]
    },
    {
        "id": "312",
        "title": "DoRAN: Stabilizing Weight-Decomposed Low-Rank Adaptation via Noise Injection and Auxiliary Networks",
        "author": [
            "Nghiem T. Diep",
            "Hien Dang",
            "Tuan Truong",
            "Tan Dinh",
            "Huy Nguyen",
            "Nhat Ho"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04331",
        "abstract": "Parameter-efficient fine-tuning (PEFT) methods have become the standard paradigm for adapting large-scale models. Among these techniques, Weight-Decomposed Low-Rank Adaptation (DoRA) has been shown to improve both the learning capacity and training stability of the vanilla Low-Rank Adaptation (LoRA) method by explicitly decomposing pre-trained weights into magnitude and directional components. In this work, we propose DoRAN, a new variant of DoRA designed to further stabilize training and boost the sample efficiency of DoRA. Our approach includes two key stages: (i) injecting noise into the denominator of DoRA's weight decomposition, which serves as an adaptive regularizer to mitigate instabilities; and (ii) replacing static low-rank matrices with auxiliary networks that generate them dynamically, enabling parameter coupling across layers and yielding better sample efficiency in both theory and practice. Comprehensive experiments on vision and language benchmarks show that DoRAN consistently outperforms LoRA, DoRA, and other PEFT baselines. These results underscore the effectiveness of combining stabilization through noise-based regularization with network-based parameter generation, offering a promising direction for robust and efficient fine-tuning of foundation models.",
        "tags": [
            "LoRA"
        ]
    },
    {
        "id": "313",
        "title": "Evaluation of Clinical Trials Reporting Quality using Large Language Models",
        "author": [
            "Mathieu LaÃ¯-king",
            "Patrick Paroubek"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04338",
        "abstract": "Reporting quality is an important topic in clinical trial research articles, as it can impact clinical decisions. In this article, we test the ability of large language models to assess the reporting quality of this type of article using the Consolidated Standards of Reporting Trials (CONSORT). We create CONSORT-QA, an evaluation corpus from two studies on abstract reporting quality with CONSORT-abstract standards. We then evaluate the ability of different large generative language models (from the general domain or adapted to the biomedical domain) to correctly assess CONSORT criteria with different known prompting methods, including Chain-of-thought. Our best combination of model and prompting method achieves 85% accuracy. Using Chain-of-thought adds valuable information on the model's reasoning for completing the task.",
        "tags": [
            "CoT",
            "LLM"
        ]
    },
    {
        "id": "314",
        "title": "Pitch-Conditioned Instrument Sound Synthesis From an Interactive Timbre Latent Space",
        "author": [
            "Christian Limberg",
            "Fares Schulz",
            "Zhe Zhang",
            "Stefan Weinzierl"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04339",
        "abstract": "This paper presents a novel approach to neural instrument sound synthesis using a two-stage semi-supervised learning framework capable of generating pitch-accurate, high-quality music samples from an expressive timbre latent space. Existing approaches that achieve sufficient quality for music production often rely on high-dimensional latent representations that are difficult to navigate and provide unintuitive user experiences. We address this limitation through a two-stage training paradigm: first, we train a pitch-timbre disentangled 2D representation of audio samples using a Variational Autoencoder; second, we use this representation as conditioning input for a Transformer-based generative model. The learned 2D latent space serves as an intuitive interface for navigating and exploring the sound landscape. We demonstrate that the proposed method effectively learns a disentangled timbre space, enabling expressive and controllable audio generation with reliable pitch conditioning. Experimental results show the model's ability to capture subtle variations in timbre while maintaining a high degree of pitch accuracy. The usability of our method is demonstrated in an interactive web application, highlighting its potential as a step towards future music production environments that are both intuitive and creatively empowering: https://pgesam.faresschulz.com",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "315",
        "title": "Critical appraisal of artificial intelligence for rare-event recognition: principles and pharmacovigilance case studies",
        "author": [
            "G. Niklas Noren",
            "Eva-Lisa Meldau",
            "Johan Ellenius"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04341",
        "abstract": "Many high-stakes AI applications target low-prevalence events, where apparent accuracy can conceal limited real-world value. Relevant AI models range from expert-defined rules and traditional machine learning to generative LLMs constrained for classification. We outline key considerations for critical appraisal of AI in rare-event recognition, including problem framing and test set design, prevalence-aware statistical evaluation, robustness assessment, and integration into human workflows. In addition, we propose an approach to structured case-level examination (SCLE), to complement statistical performance evaluation, and a comprehensive checklist to guide procurement or development of AI models for rare-event recognition. We instantiate the framework in pharmacovigilance, drawing on three studies: rule-based retrieval of pregnancy-related reports; duplicate detection combining machine learning with probabilistic record linkage; and automated redaction of person names using an LLM. We highlight pitfalls specific to the rare-event setting including optimism from unrealistic class balance and lack of difficult positive controls in test sets - and show how cost-sensitive targets align model performance with operational value. While grounded in pharmacovigilance practice, the principles generalize to domains where positives are scarce and error costs may be asymmetric.",
        "tags": [
            "Detection",
            "LLM"
        ]
    },
    {
        "id": "316",
        "title": "Learning to Predict Chaos: Curriculum-Driven Training for Robust Forecasting of Chaotic Dynamics",
        "author": [
            "Harshil Vejendla"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04342",
        "abstract": "Forecasting chaotic systems is a cornerstone challenge in many scientific fields, complicated by the exponential amplification of even infinitesimal prediction errors. Modern machine learning approaches often falter due to two opposing pitfalls: over-specializing on a single, well-known chaotic system (e.g., Lorenz-63), which limits generalizability, or indiscriminately mixing vast, unrelated time-series, which prevents the model from learning the nuances of any specific dynamical regime. We propose Curriculum Chaos Forecasting (CCF), a training paradigm that bridges this gap. CCF organizes training data based on fundamental principles of dynamical systems theory, creating a curriculum that progresses from simple, periodic behaviors to highly complex, chaotic dynamics. We quantify complexity using the largest Lyapunov exponent and attractor dimension, two well-established metrics of chaos. By first training a sequence model on predictable systems and gradually introducing more chaotic trajectories, CCF enables the model to build a robust and generalizable representation of dynamical behaviors. We curate a library of over 50 synthetic ODE/PDE systems to build this curriculum. Our experiments show that pre-training with CCF significantly enhances performance on unseen, real-world benchmarks. On datasets including Sunspot numbers, electricity demand, and human ECG signals, CCF extends the valid prediction horizon by up to 40% compared to random-order training and more than doubles it compared to training on real-world data alone. We demonstrate that this benefit is consistent across various neural architectures (GRU, Transformer) and provide extensive ablations to validate the importance of the curriculum's structure.",
        "tags": [
            "ODE",
            "Transformer"
        ]
    },
    {
        "id": "317",
        "title": "Reliable and Scalable Robot Policy Evaluation with Imperfect Simulators",
        "author": [
            "Apurva Badithela",
            "David Snyder",
            "Lihan Zha",
            "Joseph Mikhail",
            "Matthew O'Kelly",
            "Anushri Dixit",
            "Anirudha Majumdar"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04354",
        "abstract": "Rapid progress in imitation learning, foundation models, and large-scale datasets has led to robot manipulation policies that generalize to a wide-range of tasks and environments. However, rigorous evaluation of these policies remains a challenge. Typically in practice, robot policies are often evaluated on a small number of hardware trials without any statistical assurances. We present SureSim, a framework to augment large-scale simulation with relatively small-scale real-world testing to provide reliable inferences on the real-world performance of a policy. Our key idea is to formalize the problem of combining real and simulation evaluations as a prediction-powered inference problem, in which a small number of paired real and simulation evaluations are used to rectify bias in large-scale simulation. We then leverage non-asymptotic mean estimation algorithms to provide confidence intervals on mean policy performance. Using physics-based simulation, we evaluate both diffusion policy and multi-task fine-tuned \\(\\pi_0\\) on a joint distribution of objects and initial conditions, and find that our approach saves over \\(20-25\\%\\) of hardware evaluation effort to achieve similar bounds on policy performance.",
        "tags": [
            "Diffusion",
            "Robotics"
        ]
    },
    {
        "id": "318",
        "title": "MacroBench: A Novel Testbed for Web Automation Scripts via Large Language Models",
        "author": [
            "Hyunjun Kim",
            "Sejong Kim"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04363",
        "abstract": "We introduce MacroBench, a code-first benchmark that evaluates whether LLMs can synthesize reusable browser automation programs from natural language goals by reading HTML/DOM and emitting Python with Selenium. MacroBench instantiates seven self-hosted sites: Airbnb-like, TikTok-like, Reddit-like, Instagram-like, Facebook-like, Discord-like, and Threads-like, covering 681 tasks across interaction complexity and targeting difficulty. Our end-to-end protocol validates generated code via static checks, sandboxed execution, and outcome verification including DOM assertions and database snapshots, and includes a safety suite for scraping, spam/abuse, and credential/privacy prompts. Across 2636 model-task runs, we observe stratified success: GPT-4o-Mini achieves 96.8 percent, GPT-4.1 achieves 95.3 percent, Gemini-2.5-Pro achieves 89.0 percent, and DeepSeek-V3.1 achieves 83.4 percent. Models handle simple tasks reliably at 91.7 percent but fail on complex workflows at 0.0 percent, and none meet production-quality coding practices despite functional completion. We release our complete benchmark pipeline, evaluation framework, and experimental results to enable reproducible assessment of macro synthesis for web automation.",
        "tags": [
            "DeepSeek",
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "319",
        "title": "Reflection Before Action: Designing a Framework for Quantifying Thought Patterns for Increased Self-awareness in Personal Decision Making",
        "author": [
            "Morita Tarvirdians",
            "Senthil Chandrasegaran",
            "Hayley Hung",
            "Catholijn M. Jonker",
            "Catharine Oertel"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04364",
        "abstract": "When making significant life decisions, people increasingly turn to conversational AI tools, such as large language models (LLMs). However, LLMs often steer users toward solutions, limiting metacognitive awareness of their own decision-making. In this paper, we shift the focus in decision support from solution-orientation to reflective activity, coining the term pre-decision reflection (PDR). We introduce PROBE, the first framework that assesses pre-decision reflections along two dimensions: breadth (diversity of thought categories) and depth (elaborateness of reasoning). Coder agreement demonstrates PROBE's reliability in capturing how people engage in pre-decision reflection. Our study reveals substantial heterogeneity across participants and shows that people perceived their unassisted reflections as deeper and broader than PROBE's measures. By surfacing hidden thought patterns, PROBE opens opportunities for technologies that foster self-awareness and strengthen people's agency in choosing which thought patterns to rely on in decision-making.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "320",
        "title": "Diffusion^2: Dual Diffusion Model with Uncertainty-Aware Adaptive Noise for Momentary Trajectory Prediction",
        "author": [
            "Yuhao Luo",
            "Yuang Zhang",
            "Kehua Chen",
            "Xinyu Zheng",
            "Shucheng Zhang",
            "Sikai Chen",
            "Yinhai Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04365",
        "abstract": "Accurate pedestrian trajectory prediction is crucial for ensuring safety and efficiency in autonomous driving and human-robot interaction scenarios. Earlier studies primarily utilized sufficient observational data to predict future trajectories. However, in real-world scenarios, such as pedestrians suddenly emerging from blind spots, sufficient observational data is often unavailable (i.e. momentary trajectory), making accurate prediction challenging and increasing the risk of traffic accidents. Therefore, advancing research on pedestrian trajectory prediction under extreme scenarios is critical for enhancing traffic safety. In this work, we propose a novel framework termed Diffusion^2, tailored for momentary trajectory prediction. Diffusion^2 consists of two sequentially connected diffusion models: one for backward prediction, which generates unobserved historical trajectories, and the other for forward prediction, which forecasts future trajectories. Given that the generated unobserved historical trajectories may introduce additional noise, we propose a dual-head parameterization mechanism to estimate their aleatoric uncertainty and design a temporally adaptive noise module that dynamically modulates the noise scale in the forward diffusion process. Empirically, Diffusion^2 sets a new state-of-the-art in momentary trajectory prediction on ETH/UCY and Stanford Drone datasets.",
        "tags": [
            "Diffusion",
            "Robotics"
        ]
    },
    {
        "id": "321",
        "title": "Speculative Actions: A Lossless Framework for Faster Agentic Systems",
        "author": [
            "Naimeng Ye",
            "Arnav Ahuja",
            "Georgios Liargkovas",
            "Yunan Lu",
            "Kostis Kaffes",
            "Tianyi Peng"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04371",
        "abstract": "Despite growing interest in AI agents across industry and academia, their execution in an environment is often slow, hampering training, evaluation, and deployment. For example, a game of chess between two state-of-the-art agents may take hours. A critical bottleneck is that agent behavior unfolds sequentially: each action requires an API call, and these calls can be time-consuming. Inspired by speculative execution in microprocessors and speculative decoding in LLM inference, we propose speculative actions, a lossless framework for general agentic systems that predicts likely actions using faster models, enabling multiple steps to be executed in parallel. We evaluate this framework across three agentic environments: gaming, e-commerce, web search, and a \"lossy\" extension for an operating systems environment. In all cases, speculative actions achieve substantial accuracy in next-action prediction (up to 55%), translating into significant reductions in end-to-end latency. Moreover, performance can be further improved through stronger guessing models, top-K action prediction, multi-step speculation, and uncertainty-aware optimization, opening a promising path toward deploying low-latency agentic systems in the real world.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "322",
        "title": "Just-in-time Episodic Feedback Hinter: Leveraging Offline Knowledge to Improve LLM Agents Adaptation",
        "author": [
            "Hadi Nekoei",
            "Aman Jaiswal",
            "Patrice Bechard",
            "Oleh Shliazhko",
            "Orlando Marquez Ayala",
            "Mathieu Reymond",
            "Massimo Caccia",
            "Alexandre Drouin",
            "Sarath Chandar",
            "Alexandre Lacoste"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04373",
        "abstract": "Large language model (LLM) agents perform well in sequential decision-making tasks, but improving them on unfamiliar domains often requires costly online interactions or fine-tuning on large expert datasets. These strategies are impractical for closed-source models and expensive for open-source ones, with risks of catastrophic forgetting. Offline trajectories offer reusable knowledge, yet demonstration-based methods struggle because raw traces are long, noisy, and tied to specific tasks. We present Just-in-time Episodic Feedback Hinter (JEF Hinter), an agentic system that distills offline traces into compact, context-aware hints. A zooming mechanism highlights decisive steps in long trajectories, capturing both strategies and pitfalls. Unlike prior methods, JEF Hinter leverages both successful and failed trajectories, extracting guidance even when only failure data is available, while supporting parallelized hint generation and benchmark-independent prompting. At inference, a retriever selects relevant hints for the current state, providing targeted guidance with transparency and traceability. Experiments on MiniWoB++, WorkArena-L1, and WebArena-Lite show that JEF Hinter consistently outperforms strong baselines, including human- and document-based hints.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "323",
        "title": "LLM Based Bayesian Optimization for Prompt Search",
        "author": [
            "Adam Ballew",
            "Jingbo Wang",
            "Shaogang Ren"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04384",
        "abstract": "Bayesian Optimization (BO) has been widely used to efficiently optimize expensive black-box functions with limited evaluations. In this paper, we investigate the use of BO for prompt engineering to enhance text classification with Large Language Models (LLMs). We employ an LLM-powered Gaussian Process (GP) as the surrogate model to estimate the performance of different prompt candidates. These candidates are generated by an LLM through the expansion of a set of seed prompts and are subsequently evaluated using an Upper Confidence Bound (UCB) acquisition function in conjunction with the GP posterior. The optimization process iteratively refines the prompts based on a subset of the data, aiming to improve classification accuracy while reducing the number of API calls by leveraging the prediction uncertainty of the LLM-based GP. The proposed BO-LLM algorithm is evaluated on two datasets, and its advantages are discussed in detail in this paper.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "324",
        "title": "SSM-CGM: Interpretable State-Space Forecasting Model of Continuous Glucose Monitoring for Personalized Diabetes Management",
        "author": [
            "Shakson Isaac",
            "Yentl Collin",
            "Chirag Patel"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04386",
        "abstract": "Continuous glucose monitoring (CGM) generates dense data streams critical for diabetes management, but most used forecasting models lack interpretability for clinical use. We present SSM-CGM, a Mamba-based neural state-space forecasting model that integrates CGM and wearable activity signals from the AI-READI cohort. SSM-CGM improves short-term accuracy over a Temporal Fusion Transformer baseline, adds interpretability through variable selection and temporal attribution, and enables counterfactual forecasts simulating how planned changes in physiological signals (e.g., heart rate, respiration) affect near-term glucose. Together, these features make SSM-CGM an interpretable, physiologically grounded framework for personalized diabetes management.",
        "tags": [
            "Mamba",
            "Transformer"
        ]
    },
    {
        "id": "325",
        "title": "MorphoSim: An Interactive, Controllable, and Editable Language-guided 4D World Simulator",
        "author": [
            "Xuehai He",
            "Shijie Zhou",
            "Thivyanth Venkateswaran",
            "Kaizhi Zheng",
            "Ziyu Wan",
            "Achuta Kadambi",
            "Xin Eric Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04390",
        "abstract": "World models that support controllable\nand editable spatiotemporal environments are valuable\nfor robotics, enabling scalable training data, repro ducible evaluation, and flexible task design. While\nrecent text-to-video models generate realistic dynam ics, they are constrained to 2D views and offer limited\ninteraction. We introduce MorphoSim, a language guided framework that generates 4D scenes with\nmulti-view consistency and object-level controls. From\nnatural language instructions, MorphoSim produces\ndynamic environments where objects can be directed,\nrecolored, or removed, and scenes can be observed\nfrom arbitrary viewpoints. The framework integrates\ntrajectory-guided generation with feature field dis tillation, allowing edits to be applied interactively\nwithout full re-generation. Experiments show that Mor phoSim maintains high scene fidelity while enabling\ncontrollability and editability. The code is available\nat https://github.com/eric-ai-lab/Morph4D.",
        "tags": [
            "Robotics",
            "Text-to-Video"
        ]
    },
    {
        "id": "326",
        "title": "Internal World Models as Imagination Networks in Cognitive Agents",
        "author": [
            "Saurabh Ranjan",
            "Brian Odegaard"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04391",
        "abstract": "What is the computational objective of imagination? While classical interpretations suggest imagination is useful for maximizing rewards, recent findings challenge this view. In this study, we propose that imagination serves to access an internal world model (IWM) and use psychological network analysis to explore IWMs in humans and large language models (LLMs). Specifically, we assessed imagination vividness ratings using two questionnaires and constructed imagination networks from these reports. Imagination networks from human groups showed correlations between different centrality measures, including expected influence, strength, and closeness. However, imagination networks from LLMs showed a lack of clustering and lower correlations between centrality measures under different prompts and conversational memory conditions. Together, these results indicate a lack of similarity between IWMs in human and LLM agents. Overall, our study offers a novel method for comparing internally-generated representations in humans and AI, providing insights for developing human-like imagination in artificial intelligence.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "327",
        "title": "Improving Consistency in Retrieval-Augmented Systems with Group Similarity Rewards",
        "author": [
            "Faisal Hamman",
            "Chenyang Zhu",
            "Anoop Kumar",
            "Xujun Peng",
            "Sanghamitra Dutta",
            "Daben Liu",
            "Alfy Samuel"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04392",
        "abstract": "RAG systems are increasingly deployed in high-stakes domains where users expect outputs to be consistent across semantically equivalent queries. However, existing systems often exhibit significant inconsistencies due to variability in both the retriever and generator (LLM), undermining trust and reliability. In this work, we focus on information consistency, i.e., the requirement that outputs convey the same core content across semantically equivalent inputs. We introduce a principled evaluation framework that decomposes RAG consistency into retriever-level, generator-level, and end-to-end components, helping identify inconsistency sources. To improve consistency, we propose Paraphrased Set Group Relative Policy Optimization (PS-GRPO), an RL approach that leverages multiple rollouts across paraphrased set to assign group similarity rewards. We leverage PS-GRPO to achieve Information Consistent RAG (Con-RAG), training the generator to produce consistent outputs across paraphrased queries and remain robust to retrieval-induced variability. Because exact reward computation over paraphrase sets is computationally expensive, we also introduce a scalable approximation method that retains effectiveness while enabling efficient, large-scale training. Empirical evaluations across short-form, multi-hop, and long-form QA benchmarks demonstrate that Con-RAG significantly improves both consistency and accuracy over strong baselines, even in the absence of explicit ground-truth supervision. Our work provides practical solutions for evaluating and building reliable RAG systems for safety-critical deployments.",
        "tags": [
            "GRPO",
            "LLM",
            "RAG",
            "RL"
        ]
    },
    {
        "id": "328",
        "title": "Large Language Models Preserve Semantic Isotopies in Story Continuations",
        "author": [
            "Marc Cavazza"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04400",
        "abstract": "In this work, we explore the relevance of textual semantics to Large Language Models (LLMs), extending previous insights into the connection between distributional semantics and structural semantics. We investigate whether LLM-generated texts preserve semantic isotopies. We design a story continuation experiment using 10,000 ROCStories prompts completed by five LLMs. We first validate GPT-4o's ability to extract isotopies from a linguistic benchmark, then apply it to the generated stories. We then analyze structural (coverage, density, spread) and semantic properties of isotopies to assess how they are affected by completion. Results show that LLM completion within a given token horizon preserves semantic isotopies across multiple properties.",
        "tags": [
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "329",
        "title": "Your Vision-Language Model Can't Even Count to 20: Exposing the Failures of VLMs in Compositional Counting",
        "author": [
            "Xuyang Guo",
            "Zekai Huang",
            "Zhenmei Shi",
            "Zhao Song",
            "Jiahao Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04401",
        "abstract": "Vision-Language Models (VLMs) have become a central focus of today's AI community, owing to their impressive abilities gained from training on large-scale vision-language data from the Web. These models have demonstrated strong performance across diverse tasks, including image understanding, video understanding, complex visual reasoning, and embodied AI. Despite these noteworthy successes, a fundamental question remains: Can VLMs count objects correctly? In this paper, we introduce a simple yet effective benchmark, VLMCountBench, designed under a minimalist setting with only basic geometric shapes (e.g., triangles, circles) and their compositions, focusing exclusively on counting tasks without interference from other factors. We adopt strict independent variable control and systematically study the effects of simple properties such as color, size, and prompt refinement in a controlled ablation. Our empirical results reveal that while VLMs can count reliably when only one shape type is present, they exhibit substantial failures when multiple shape types are combined (i.e., compositional counting). This highlights a fundamental empirical limitation of current VLMs and motivates important directions for future research.",
        "tags": [
            "VLM"
        ]
    },
    {
        "id": "330",
        "title": "Next-Generation Event-Driven Architectures: Performance, Scalability, and Intelligent Orchestration Across Messaging Frameworks",
        "author": [
            "Jahidul Arafat",
            "Fariha Tasmin",
            "Sanjaya Poudel",
            "Ahsan Habib Tareq"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04404",
        "abstract": "Modern distributed systems demand low-latency, fault-tolerant event processing that exceeds traditional messaging architecture limits. While frameworks including Apache Kafka, RabbitMQ, Apache Pulsar, NATS JetStream, and serverless event buses have matured significantly, no unified comparative study evaluates them holistically under standardized conditions. This paper presents the first comprehensive benchmarking framework evaluating 12 messaging systems across three representative workloads: e-commerce transactions, IoT telemetry ingestion, and AI inference pipelines. We introduce AIEO (AI-Enhanced Event Orchestration), employing machine learning-driven predictive scaling, reinforcement learning for dynamic resource allocation, and multi-objective optimization. Our evaluation reveals fundamental trade-offs: Apache Kafka achieves peak throughput (1.2M messages/sec, 18ms p95 latency) but requires substantial operational expertise; Apache Pulsar provides balanced performance (950K messages/sec, 22ms p95) with superior multi-tenancy; serverless solutions offer elastic scaling for variable workloads despite higher baseline latency (80-120ms p95). AIEO demonstrates 34\\% average latency reduction, 28\\% resource utilization improvement, and 42% cost optimization across all platforms. We contribute standardized benchmarking methodologies, open-source intelligent orchestration, and evidence-based decision guidelines. The evaluation encompasses 2,400+ experimental configurations with rigorous statistical analysis, providing comprehensive performance characterization and establishing foundations for next-generation distributed system design.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "331",
        "title": "Partial Information Decomposition via Normalizing Flows in Latent Gaussian Distributions",
        "author": [
            "Wenyuan Zhao",
            "Adithya Balachandran",
            "Chao Tian",
            "Paul Pu Liang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04417",
        "abstract": "The study of multimodality has garnered significant interest in fields where the analysis of interactions among multiple information sources can enhance predictive modeling, data fusion, and interpretability. Partial information decomposition (PID) has emerged as a useful information-theoretic framework to quantify the degree to which individual modalities independently, redundantly, or synergistically convey information about a target variable. However, existing PID methods depend on optimizing over a joint distribution constrained by estimated pairwise probability distributions, which are costly and inaccurate for continuous and high-dimensional modalities. Our first key insight is that the problem can be solved efficiently when the pairwise distributions are multivariate Gaussians, and we refer to this problem as Gaussian PID (GPID). We propose a new gradient-based algorithm that substantially improves the computational efficiency of GPID based on an alternative formulation of the underlying optimization problem. To generalize the applicability to non-Gaussian data, we learn information-preserving encoders to transform random variables of arbitrary input distributions into pairwise Gaussian random variables. Along the way, we resolved an open problem regarding the optimality of joint Gaussian solutions for GPID. Empirical validation in diverse synthetic examples demonstrates that our proposed method provides more accurate and efficient PID estimates than existing baselines. We further evaluate a series of large-scale multimodal benchmarks to show its utility in real-world applications of quantifying PID in multimodal datasets and selecting high-performing models.",
        "tags": [
            "Normalizing Flows"
        ]
    },
    {
        "id": "332",
        "title": "A.I.R.: Enabling Adaptive, Iterative, and Reasoning-based Frame Selection For Video Question Answering",
        "author": [
            "Yuanhao Zou",
            "Shengji Jin",
            "Andong Deng",
            "Youpeng Zhao",
            "Jun Wang",
            "Chen Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04428",
        "abstract": "Effectively applying Vision-Language Models (VLMs) to Video Question Answering (VideoQA) hinges on selecting a concise yet comprehensive set of frames, as processing entire videos is computationally infeasible. However, current frame selection methods face a critical trade-off: approaches relying on lightweight similarity models, such as CLIP, often fail to capture the nuances of complex queries, resulting in inaccurate similarity scores that cannot reflect the authentic query-frame relevance, which further undermines frame selection. Meanwhile, methods that leverage a VLM for deeper analysis achieve higher accuracy but incur prohibitive computational costs. To address these limitations, we propose A.I.R., a training-free approach for Adaptive, Iterative, and Reasoning-based frame selection. We leverage a powerful VLM to perform deep, semantic analysis on complex queries, and this analysis is deployed within a cost-effective iterative loop that processes only a small batch of the most high-potential frames at a time. Extensive experiments on various VideoQA benchmarks demonstrate that our approach outperforms existing frame selection methods, significantly boosts the performance of the foundation VLM, and achieves substantial gains in computational efficiency over other VLM-based techniques.",
        "tags": [
            "CLIP",
            "VLM"
        ]
    },
    {
        "id": "333",
        "title": "Achieve Performatively Optimal Policy for Performative Reinforcement Learning",
        "author": [
            "Ziyi Chen",
            "Heng Huang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04430",
        "abstract": "Performative reinforcement learning is an emerging dynamical decision making framework, which extends reinforcement learning to the common applications where the agent's policy can change the environmental dynamics. Existing works on performative reinforcement learning only aim at a performatively stable (PS) policy that maximizes an approximate value function. However, there is a provably positive constant gap between the PS policy and the desired performatively optimal (PO) policy that maximizes the original value function. In contrast, this work proposes a zeroth-order Frank-Wolfe algorithm (0-FW) algorithm with a zeroth-order approximation of the performative policy gradient in the Frank-Wolfe framework, and obtains \\textbf{the first polynomial-time convergence to the desired PO} policy under the standard regularizer dominance condition. For the convergence analysis, we prove two important properties of the nonconvex value function. First, when the policy regularizer dominates the environmental shift, the value function satisfies a certain gradient dominance property, so that any stationary point (not PS) of the value function is a desired PO. Second, though the value function has unbounded gradient, we prove that all the sufficiently stationary points lie in a convex and compact policy subspace $\\Pi_{\\Delta}$, where the policy value has a constant lower bound $\\Delta>0$ and thus the gradient becomes bounded and Lipschitz continuous. Experimental results also demonstrate that our 0-FW algorithm is more effective than the existing algorithms in finding the desired PO policy.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "334",
        "title": "PAD-TRO: Projection-Augmented Diffusion for Direct Trajectory Optimization",
        "author": [
            "Jushan Chen",
            "Santiago Paternain"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04436",
        "abstract": "Recently, diffusion models have gained popularity and attention in trajectory optimization due to their capability of modeling multi-modal probability distributions. However, addressing nonlinear equality constraints, i.e, dynamic feasi- bility, remains a great challenge in diffusion-based trajectory optimization. Recent diffusion-based trajectory optimization frameworks rely on a single-shooting style approach where the denoised control sequence is applied to forward propagate the dynamical system, which cannot explicitly enforce constraints on the states and frequently leads to sub-optimal solutions. In this work, we propose a novel direct trajectory optimization approach via model-based diffusion, which directly generates a sequence of states. To ensure dynamic feasibility, we propose a gradient-free projection mechanism that is incorporated into the reverse diffusion process. Our results show that, compared to a recent state-of-the-art baseline, our approach leads to zero dynamic feasibility error and approximately 4x higher success rate in a quadrotor waypoint navigation scenario involving dense static obstacles.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "335",
        "title": "On the Role of Unobserved Sequences on Sample-based Uncertainty Quantification for LLMs",
        "author": [
            "Lucie Kunitomo-Jacquin",
            "Edison Marrese-Taylor",
            "Ken Fukuda"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04439",
        "abstract": "Quantifying uncertainty in large language models (LLMs) is important for safety-critical applications because it helps spot incorrect answers, known as hallucinations. One major trend of uncertainty quantification methods is based on estimating the entropy of the distribution of the LLM's potential output sequences. This estimation is based on a set of output sequences and associated probabilities obtained by querying the LLM several times. In this paper, we advocate and experimentally show that the probability of unobserved sequences plays a crucial role, and we recommend future research to integrate it to enhance such LLM uncertainty quantification methods.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "336",
        "title": "Fractional Heat Kernel for Semi-Supervised Graph Learning with Small Training Sample Size",
        "author": [
            "Farid Bozorgnia",
            "Vyacheslav Kungurtsev",
            "Shirali Kadyrov",
            "Mohsen Yousefnezhad"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04440",
        "abstract": "In this work, we introduce novel algorithms for label propagation and self-training using fractional heat kernel dynamics with a source term. We motivate the methodology through the classical correspondence of information theory with the physics of parabolic evolution equations. We integrate the fractional heat kernel into Graph Neural Network architectures such as Graph Convolutional Networks and Graph Attention, enhancing their expressiveness through adaptive, multi-hop diffusion. By applying Chebyshev polynomial approximations, large graphs become computationally feasible. Motivating variational formulations demonstrate that by extending the classical diffusion model to fractional powers of the Laplacian, nonlocal interactions deliver more globally diffusing labels. The particular balance between supervision of known labels and diffusion across the graph is particularly advantageous in the case where only a small number of labeled training examples are present. We demonstrate the effectiveness of this approach on standard datasets.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "337",
        "title": "REAR: Rethinking Visual Autoregressive Models via Generator-Tokenizer Consistency Regularization",
        "author": [
            "Qiyuan He",
            "Yicong Li",
            "Haotian Ye",
            "Jinghao Wang",
            "Xinyao Liao",
            "Pheng-Ann Heng",
            "Stefano Ermon",
            "James Zou",
            "Angela Yao"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04450",
        "abstract": "Visual autoregressive (AR) generation offers a promising path toward unifying vision and language models, yet its performance remains suboptimal against diffusion models. Prior work often attributes this gap to tokenizer limitations and rasterization ordering. In this work, we identify a core bottleneck from the perspective of generator-tokenizer inconsistency, i.e., the AR-generated tokens may not be well-decoded by the tokenizer. To address this, we propose reAR, a simple training strategy introducing a token-wise regularization objective: when predicting the next token, the causal transformer is also trained to recover the visual embedding of the current token and predict the embedding of the target token under a noisy context. It requires no changes to the tokenizer, generation order, inference pipeline, or external models. Despite its simplicity, reAR substantially improves performance. On ImageNet, it reduces gFID from 3.02 to 1.86 and improves IS to 316.9 using a standard rasterization-based tokenizer. When applied to advanced tokenizers, it achieves a gFID of 1.42 with only 177M parameters, matching the performance with larger state-of-the-art diffusion models (675M).",
        "tags": [
            "Diffusion",
            "Transformer"
        ]
    },
    {
        "id": "338",
        "title": "Mitigating Forgetting Between Supervised and Reinforcement Learning Yields Stronger Reasoners",
        "author": [
            "Xiangchi Yuan",
            "Xiang Chen",
            "Tong Yu",
            "Dachuan Shi",
            "Can Jin",
            "Wenke Lee",
            "Saayan Mitra"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04454",
        "abstract": "Large Language Models (LLMs) show strong reasoning abilities, often amplified by Chain-of-Thought (CoT) prompting and reinforcement learning (RL). Although RL algorithms can substantially improve reasoning, they struggle to expand reasoning boundaries because they learn from their own reasoning trajectories rather than acquiring external knowledge. Supervised fine-tuning (SFT) offers complementary benefits but typically requires large-scale data and risks overfitting. Recent attempts to combine SFT and RL face three main challenges: data inefficiency, algorithm-specific designs, and catastrophic forgetting. We propose a plug-and-play framework that dynamically integrates SFT into RL by selecting challenging examples for SFT. This approach reduces SFT data requirements and remains agnostic to the choice of RL or SFT algorithm. To mitigate catastrophic forgetting of RL-acquired skills during SFT, we select high-entropy tokens for loss calculation and freeze parameters identified as critical for RL. Our method achieves state-of-the-art (SoTA) reasoning performance using only 1.5% of the SFT data and 20.4% of the RL data used by prior SoTA, providing an efficient and plug-and-play solution for combining SFT and RL in reasoning post-training.",
        "tags": [
            "CoT",
            "LLM",
            "RL"
        ]
    },
    {
        "id": "339",
        "title": "Evaluating Self-Supervised Speech Models via Text-Based LLMS",
        "author": [
            "Takashi Maekaku",
            "Keita Goto",
            "Jinchuan Tian",
            "Yusuke Shinohara",
            "Shinji Watanabe"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04463",
        "abstract": "Self-Supervised Learning (SSL) has gained traction for its ability to learn rich representations with low labeling costs, applicable across diverse downstream tasks. However, assessing the downstream-task performance remains challenging due to the cost of extra training and evaluation. Existing methods for task-agnostic evaluation also require extra training or hyperparameter tuning. We propose a novel evaluation metric using large language models (LLMs). By inputting discrete token sequences and minimal domain cues derived from SSL models into LLMs, we obtain the mean log-likelihood; these cues guide in-context learning, rendering the score more reliable without extra training or hyperparameter tuning. Experimental results show a correlation between LLM-based scores and automatic speech recognition task. Additionally, our findings reveal that LLMs not only functions as an SSL evaluation tools but also provides inference-time embeddings that are useful for speaker verification task.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "340",
        "title": "Autonomy Matters: A Study on Personalization-Privacy Dilemma in LLM Agents",
        "author": [
            "Zhiping Zhang",
            "Yi Evie Zhang",
            "Freda Shi",
            "Tianshi Li"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04465",
        "abstract": "Large Language Model (LLM) agents require personal information for personalization in order to better act on users' behalf in daily tasks, but this raises privacy concerns and a personalization-privacy dilemma. Agent's autonomy introduces both risks and opportunities, yet its effects remain unclear. To better understand this, we conducted a 3$\\times$3 between-subjects experiment ($N=450$) to study how agent's autonomy level and personalization influence users' privacy concerns, trust and willingness to use, as well as the underlying psychological processes. We find that personalization without considering users' privacy preferences increases privacy concerns and decreases trust and willingness to use. Autonomy moderates these effects: Intermediate autonomy flattens the impact of personalization compared to No- and Full autonomy conditions. Our results suggest that rather than aiming for perfect model alignment in output generation, balancing autonomy of agent's action and user control offers a promising path to mitigate the personalization-privacy dilemma.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "341",
        "title": "Improving IR-based Bug Localization with Semantics-Driven Query Reduction",
        "author": [
            "Asif Mohammed Samir",
            "Mohammad Masudur Rahman"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04468",
        "abstract": "Despite decades of research, software bug localization remains challenging due to heterogeneous content and inherent ambiguities in bug reports. Existing methods such as Information Retrieval (IR)-based approaches often attempt to match source documents to bug reports, overlooking the context and semantics of the source code. On the other hand, Large Language Models (LLM) (e.g., Transformer models) show promising results in understanding both texts and code. However, they have not been yet adapted well to localize software bugs against bug reports. They could be also data or resource-intensive. To bridge this gap, we propose, IQLoc, a novel bug localization approach that capitalizes on the strengths of both IR and LLM-based approaches. In particular, we leverage the program semantics understanding of transformer-based models to reason about the suspiciousness of code and reformulate queries during bug localization using Information Retrieval. To evaluate IQLoc, we refine the Bench4BL benchmark dataset and extend it by incorporating ~30% more recent bug reports, resulting in a benchmark containing ~7.5K bug reports. We evaluated IQLoc using three performance metrics and compare it against four baseline techniques. Experimental results demonstrate its superiority, achieving up to 58.52% and 60.59% in MAP, 61.49% and 64.58% in MRR, and 69.88% and 100.90% in HIT@K for the test bug reports with random and time-wise splits, respectively. Moreover, IQLoc improves MAP by 91.67% for bug reports with stack traces, 72.73% for those that include code elements, and 65.38% for those containing only descriptions in natural language. By integrating program semantic understanding into Information Retrieval, IQLoc mitigates several longstanding challenges of traditional IR-based approaches in bug localization.",
        "tags": [
            "LLM",
            "Transformer"
        ]
    },
    {
        "id": "342",
        "title": "A Diffusion-based Generative Machine Learning Paradigm for Contingency Screening",
        "author": [
            "Quan Tran",
            "Suresh S. Muknahallipatna",
            "Dongliang Duan",
            "Nga Nguyen"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04470",
        "abstract": "Contingency screening is a crucial part of electric power systems all the time. Power systems frequently encounter multiple challenging operational dilemmas that could lead to the instability of power systems. Contingency analysis is effort-consuming by utilizing traditional numerical analysis methods. It is commonly addressed by generating a whopping number of possible contingencies or manipulating network parameters to determine the worst scenarios. This paper proposes a novel approach that diverts the nature of contingency analysis from pre-defined scenario screening to proactive-unsupervised screening. The potentially risky scenarios of power systems are generated from learning how the previous ones occurred. In other words, the internal perturbation that initiates contingencies is learned prior to being self-replicated for rendering the worst scenarios. By leveraging the perturbation diffusion technique, a proposed model is built to point out the worst scenarios instead of repeatedly simulating one-by-one scenarios to define the highest-risk ones. Empirical experiments are implemented on the IEEE systems to test and validate the proposed solution.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "343",
        "title": "DRPO: Efficient Reasoning via Decoupled Reward Policy Optimization",
        "author": [
            "Gang Li",
            "Yan Chen",
            "Ming Lin",
            "Tianbao Yang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04474",
        "abstract": "Recent large reasoning models (LRMs) driven by reinforcement learning algorithms (e.g., GRPO) have achieved remarkable performance on challenging reasoning tasks. However, these models suffer from overthinking, generating unnecessarily long and redundant reasoning even for simple questions, which substantially increases computational cost and response latency. While existing methods incorporate length rewards to GRPO to promote concise reasoning, they incur significant performance degradation. We identify the root cause: when rewards for correct but long rollouts are penalized, GRPO's group-relative advantage function can assign them negative advantages, actively discouraging valid reasoning. To overcome this, we propose Decoupled Reward Policy Optimization (DRPO), a novel framework that decouples the length-based learning signal of correct rollouts from incorrect ones. DRPO ensures that reward signals for correct rollouts are normalized solely within the positive group, shielding them from interference by negative samples. The DRPO's objective is grounded in integrating an optimized positive data distribution, which maximizes length-based rewards under a KL regularization, into a discriminative objective. We derive a closed-form solution for this distribution, enabling efficient computation of the objective and its gradients using only on-policy data and importance weighting. Of independent interest, this formulation is general and can incorporate other preference rewards of positive data beyond length. Experiments on mathematical reasoning tasks demonstrate DRPO's significant superiority over six efficient reasoning baselines. Notably, with a 1.5B model, our method achieves 77\\% length reduction with only 1.1\\% performance loss on simple questions like GSM8k dataset, while the follow-up baseline sacrifices 4.3\\% for 68\\% length reduction.",
        "tags": [
            "GRPO",
            "RL"
        ]
    },
    {
        "id": "344",
        "title": "Compressed Convolutional Attention: Efficient Attention in a Compressed Latent Space",
        "author": [
            "Tomas Figliolia",
            "Nicholas Alonso",
            "Rishi Iyer",
            "Quentin Anthony",
            "Beren Millidge"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04476",
        "abstract": "Multi-headed Attention's (MHA) quadratic compute and linearly growing KV-cache make long-context transformers expensive to train and serve. Prior works such as Grouped Query Attention (GQA) and Multi-Latent Attention (MLA) shrink the cache, speeding decode, but leave compute, which determines prefill and training speed, largely unchanged. We introduce Compressed Convolutional Attention (CCA), a novel attention method which down-projects queries, keys, and values and performs the entire attention operation inside the shared latent space. This simple design dramatically cuts parameters, KV-cache, and FLOPs all at once by the desired compression factor. Because CCA is orthogonal to head-sharing, we combine the two to form Compressed Convolutional Grouped Query Attention (CCGQA), which further tightens the compute-bandwidth Pareto frontier so that users can tune compression toward either FLOP or memory limits without sacrificing quality. Experiments show that CCGQA consistently outperforms both GQA and MLA at equal KV-cache compression on dense and MoE models. Additionally, we show that CCGQA outperforms all other attention methods on MoE models with half the KV-cache of GQA and MLA, achieving an 8x KV-cache compression with no drop in performance compared to standard MHA. CCA and CCGQA also dramatically reduce the FLOP cost of attention which leads to substantially faster training and prefill than existing methods. On H100 GPUs, our fused CCA/CCGQA kernel reduces prefill latency by about 1.7x at a sequence length of 16k relative to MHA, and accelerates backward by about 1.3x.",
        "tags": [
            "MoE"
        ]
    },
    {
        "id": "345",
        "title": "VaseVQA-3D: Benchmarking 3D VLMs on Ancient Greek Pottery",
        "author": [
            "Nonghai Zhang",
            "Zeyu Zhang",
            "Jiazi Wang",
            "Yang Zhao",
            "Hao Tang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04479",
        "abstract": "Vision-Language Models (VLMs) have achieved significant progress in multimodal understanding tasks, demonstrating strong capabilities particularly in general tasks such as image captioning and visual reasoning. However, when dealing with specialized cultural heritage domains like 3D vase artifacts, existing models face severe data scarcity issues and insufficient domain knowledge limitations. Due to the lack of targeted training data, current VLMs struggle to effectively handle such culturally significant specialized tasks. To address these challenges, we propose the VaseVQA-3D dataset, which serves as the first 3D visual question answering dataset for ancient Greek pottery analysis, collecting 664 ancient Greek vase 3D models with corresponding question-answer data and establishing a complete data construction pipeline. We further develop the VaseVLM model, enhancing model performance in vase artifact analysis through domain-adaptive training. Experimental results validate the effectiveness of our approach, where we improve by 12.8% on R@1 metrics and by 6.6% on lexical similarity compared with previous state-of-the-art on the VaseVQA-3D dataset, significantly improving the recognition and understanding of 3D vase artifacts, providing new technical pathways for digital heritage preservation research.",
        "tags": [
            "3D",
            "VLM"
        ]
    },
    {
        "id": "346",
        "title": "TBStar-Edit: From Image Editing Pattern Shifting to Consistency Enhancement",
        "author": [
            "Hao Fang",
            "Zechao Zhan",
            "Weixin Feng",
            "Ziwei Huang",
            "XuBin Li",
            "Tiezheng Ge"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04483",
        "abstract": "Recent advances in image generation and editing technologies have enabled state-of-the-art models to achieve impressive results in general domains. However, when applied to e-commerce scenarios, these general models often encounter consistency limitations. To address this challenge, we introduce TBStar-Edit, an new image editing model tailored for the e-commerce domain. Through rigorous data engineering, model architecture design and training strategy, TBStar-Edit achieves precise and high-fidelity image editing while maintaining the integrity of product appearance and layout. Specifically, for data engineering, we establish a comprehensive data construction pipeline, encompassing data collection, construction, filtering, and augmentation, to acquire high-quality, instruction-following, and strongly consistent editing data to support model training. For model architecture design, we design a hierarchical model framework consisting of a base model, pattern shifting modules, and consistency enhancement modules. For model training, we adopt a two-stage training strategy to enhance the consistency preservation: first stage for editing pattern shifting, and second stage for consistency enhancement. Each stage involves training different modules with separate datasets. Finally, we conduct extensive evaluations of TBStar-Edit on a self-proposed e-commerce benchmark, and the results demonstrate that TBStar-Edit outperforms existing general-domain editing models in both objective metrics (VIE Score) and subjective user preference.",
        "tags": [
            "Image Editing"
        ]
    },
    {
        "id": "347",
        "title": "Psychological Steering in LLMs: An Evaluation of Effectiveness and Trustworthiness",
        "author": [
            "Amin Banayeeanzade",
            "Ala N. Tak",
            "Fatemeh Bahrani",
            "Anahita Bolourani",
            "Leonardo Blas",
            "Emilio Ferrara",
            "Jonathan Gratch",
            "Sai Praneeth Karimireddy"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04484",
        "abstract": "The ability to control LLMs' emulated emotional states and personality traits is essential for enabling rich, human-centered interactions in socially interactive settings. We introduce PsySET, a Psychologically-informed benchmark to evaluate LLM Steering Effectiveness and Trustworthiness across the emotion and personality domains. Our study spans four models from different LLM families paired with various steering strategies, including prompting, fine-tuning, and representation engineering. Our results indicate that prompting is consistently effective but limited in intensity control, whereas vector injections achieve finer controllability while slightly reducing output quality. Moreover, we explore the trustworthiness of steered LLMs by assessing safety, truthfulness, fairness, and ethics, highlighting potential side effects and behavioral shifts. Notably, we observe idiosyncratic effects; for instance, even a positive emotion like joy can degrade robustness to adversarial factuality, lower privacy awareness, and increase preferential bias. Meanwhile, anger predictably elevates toxicity yet strengthens leakage resistance. Our framework establishes the first holistic evaluation of emotion and personality steering, offering insights into its interpretability and reliability for socially interactive applications.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "348",
        "title": "Forking-Sequences",
        "author": [
            "Willa Potosnak",
            "Malcolm Wolff",
            "Boris Oreshkin",
            "Mengfei Cao",
            "Michael W. Mahoney",
            "Dmitry Efimov",
            "Kin G. Olivares"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04487",
        "abstract": "While accuracy is a critical requirement for time series forecasting models, an equally important (yet often overlooked) desideratum is forecast stability across forecast creation dates (FCDs). Even highly accurate models can produce erratic revisions between FCDs, undermining stakeholder trust and disrupting downstream decision-making. To improve forecast stability, models like MQCNN, MQT, and SPADE employ a little-known but highly effective technique: forking-sequences. Unlike standard statistical and neural forecasting methods that treat each FCD independently, the forking-sequences method jointly encodes and decodes the entire time series across all FCDs, in a way mirroring time series cross-validation. Since forking sequences remains largely unknown in the broader neural forecasting community, in this work, we formalize the forking-sequences approach, and we make a case for its broader adoption. We demonstrate three key benefits of forking-sequences: (i) more stable and consistent gradient updates during training; (ii) reduced forecast variance through ensembling; and (iii) improved inference computational efficiency. We validate forking-sequences' benefits using 16 datasets from the M1, M3, M4, and Tourism competitions, showing improvements in forecast percentage change stability of 28.8%, 28.8%, 37.9%, and 31.3%, and 8.8%, on average, for MLP, RNN, LSTM, CNN, and Transformer-based architectures, respectively.",
        "tags": [
            "RNN",
            "Transformer"
        ]
    },
    {
        "id": "349",
        "title": "Multi-Agent Collaborative Intelligence: Dual-Dial Control for Reliable LLM Reasoning",
        "author": [
            "Edward Y. Chang",
            "Ethan Y. Chang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04488",
        "abstract": "Multi-agent debate often wastes compute by using a fixed adversarial stance, aggregating without deliberation, or stopping on heuristics. We introduce MACI, an active controller with two independent dials that decouple information from behavior: an information dial that gates evidence by quality, and a behavior dial that schedules contentiousness from exploration to consolidation. A moderator tracks disagreement, overlap, evidence quality, and argument quality, and halts when gains plateau. We provide theory-lite guarantees for nonincreasing dispersion and provable termination, with a budget-feasible scheduler. Across clinical diagnosis and news-bias tasks, MACI improves accuracy and calibration while reducing tokens, and converts residual uncertainty into precision RAG plans that specify what to retrieve next. We use a cross-family LLM judge (CRIT) as a conservative soft weight and stop signal, validated for order invariance and judge-swap stability; stability depends on using high-capability judges. MACI turns debate into a budget-aware, measurable, and provably terminating controller.",
        "tags": [
            "LLM",
            "RAG"
        ]
    },
    {
        "id": "350",
        "title": "Multi-Hop Question Answering: When Can Humans Help, and Where do They Struggle?",
        "author": [
            "Jinyan Su",
            "Claire Cardie",
            "Jennifer Healey"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04493",
        "abstract": "Multi-hop question answering is a challenging task for both large language models (LLMs) and humans, as it requires recognizing when multi-hop reasoning is needed, followed by reading comprehension, logical reasoning, and knowledge integration. To better understand how humans might collaborate effectively with AI, we evaluate the performance of crowd workers on these individual reasoning subtasks. We find that while humans excel at knowledge integration (97\\% accuracy), they often fail to recognize when a question requires multi-hop reasoning (67\\% accuracy). Participants perform reasonably well on both single-hop and multi-hop QA (84\\% and 80\\% accuracy, respectively), but frequently make semantic mistakes--for example, answering \"when\" an event happened when the question asked \"where.\" These findings highlight the importance of designing AI systems that complement human strengths while compensating for common weaknesses.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "351",
        "title": "GenQuest: An LLM-based Text Adventure Game for Language Learners",
        "author": [
            "Qiao Wang",
            "Adnan Labib",
            "Robert Swier",
            "Michael Hofmeyr",
            "Zheng Yuan"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04498",
        "abstract": "GenQuest is a generative text adventure game that leverages Large Language Models (LLMs) to facilitate second language learning through immersive, interactive storytelling. The system engages English as a Foreign Language (EFL) learners in a collaborative \"choose-your-own-adventure\" style narrative, dynamically generated in response to learner choices. Game mechanics such as branching decision points and story milestones are incorporated to maintain narrative coherence while allowing learner-driven plot development. Key pedagogical features include content generation tailored to each learner's proficiency level, and a vocabulary assistant that provides in-context explanations of learner-queried text strings, ranging from words and phrases to sentences. Findings from a pilot study with university EFL students in China indicate promising vocabulary gains and positive user perceptions. Also discussed are suggestions from participants regarding the narrative length and quality, and the request for multi-modal content such as illustrations.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "352",
        "title": "Expand Neurons, Not Parameters",
        "author": [
            "Linghao Kong",
            "Inimai Subramanian",
            "Yonadav Shavit",
            "Micah Adler",
            "Dan Alistarh",
            "Nir Shavit"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04500",
        "abstract": "This work demonstrates how increasing the number of neurons in a network without increasing its number of non-zero parameters improves performance. We show that this gain corresponds with a decrease in interference between multiple features that would otherwise share the same neurons. To reduce such entanglement at a fixed non-zero parameter count, we introduce Fixed Parameter Expansion (FPE): replace a neuron with multiple children and partition the parent's weights disjointly across them, so that each child inherits a non-overlapping subset of connections. On symbolic tasks, specifically Boolean code problems, clause-aligned FPE systematically reduces polysemanticity metrics and yields higher task accuracy. Notably, random splits of neuron weights approximate these gains, indicating that reduced collisions, not precise assignment, are a primary driver. Consistent with the superposition hypothesis, the benefits of FPE grow with increasing interference: when polysemantic load is high, accuracy improvements are the largest. Transferring these insights to real models (classifiers over CLIP embeddings and deeper multilayer networks) we find that widening networks while maintaining a constant non-zero parameter count consistently increases accuracy. These results identify an interpretability-grounded mechanism to leverage width against superposition, improving performance without increasing the number of non-zero parameters. Such a direction is well matched to modern accelerators, where memory movement of non-zero parameters, rather than raw compute, is the dominant bottleneck.",
        "tags": [
            "CLIP"
        ]
    },
    {
        "id": "353",
        "title": "Asynchronous Denoising Diffusion Models for Aligning Text-to-Image Generation",
        "author": [
            "Zijing Hu",
            "Yunze Tong",
            "Fengda Zhang",
            "Junkun Yuan",
            "Jun Xiao",
            "Kun Kuang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04504",
        "abstract": "Diffusion models have achieved impressive results in generating high-quality images. Yet, they often struggle to faithfully align the generated images with the input prompts. This limitation arises from synchronous denoising, where all pixels simultaneously evolve from random noise to clear images. As a result, during generation, the prompt-related regions can only reference the unrelated regions at the same noise level, failing to obtain clear context and ultimately impairing text-to-image alignment. To address this issue, we propose asynchronous diffusion models -- a novel framework that allocates distinct timesteps to different pixels and reformulates the pixel-wise denoising process. By dynamically modulating the timestep schedules of individual pixels, prompt-related regions are denoised more gradually than unrelated regions, thereby allowing them to leverage clearer inter-pixel context. Consequently, these prompt-related regions achieve better alignment in the final images. Extensive experiments demonstrate that our asynchronous diffusion models can significantly improve text-to-image alignment across diverse prompts. The code repository for this work is available at https://github.com/hu-zijing/AsynDM.",
        "tags": [
            "Diffusion",
            "Text-to-Image"
        ]
    },
    {
        "id": "354",
        "title": "GRACE: Generative Representation Learning via Contrastive Policy Optimization",
        "author": [
            "Jiashuo Sun",
            "Shixuan Liu",
            "Zhaochen Su",
            "Xianrui Zhong",
            "Pengcheng Jiang",
            "Bowen Jin",
            "Peiran Li",
            "Weijia Shi",
            "Jiawei Han"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04506",
        "abstract": "Prevailing methods for training Large Language Models (LLMs) as text encoders rely on contrastive losses that treat the model as a black box function, discarding its generative and reasoning capabilities in favor of static embeddings. We introduce GRACE (Generative Representation Learning via Contrastive Policy Optimization), a novel framework that reimagines contrastive signals not as losses to be minimized, but as rewards that guide a generative policy. In GRACE, the LLM acts as a policy that produces explicit, human-interpretable rationales--structured natural language explanations of its semantic understanding. These rationales are then encoded into high-quality embeddings via mean pooling. Using policy gradient optimization, we train the model with a multi-component reward function that maximizes similarity between query positive pairs and minimizes similarity with negatives. This transforms the LLM from an opaque encoder into an interpretable agent whose reasoning process is transparent and inspectable. On MTEB benchmark, GRACE yields broad cross category gains: averaged over four backbones, the supervised setting improves overall score by 11.5% over base models, and the unsupervised variant adds 6.9%, while preserving general capabilities. This work treats contrastive objectives as rewards over rationales, unifying representation learning with generation to produce stronger embeddings and transparent rationales. The model, data and code are available at https://github.com/GasolSun36/GRACE.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "355",
        "title": "Wavelet Predictive Representations for Non-Stationary Reinforcement Learning",
        "author": [
            "Min Wang",
            "Xin Li",
            "Ye He",
            "Yao-Hui Li",
            "Hasnaa Bennis",
            "Riashat Islam",
            "Mingzhong Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04507",
        "abstract": "The real world is inherently non-stationary, with ever-changing factors, such as weather conditions and traffic flows, making it challenging for agents to adapt to varying environmental dynamics. Non-Stationary Reinforcement Learning (NSRL) addresses this challenge by training agents to adapt rapidly to sequences of distinct Markov Decision Processes (MDPs). However, existing NSRL approaches often focus on tasks with regularly evolving patterns, leading to limited adaptability in highly dynamic settings. Inspired by the success of Wavelet analysis in time series modeling, specifically its ability to capture signal trends at multiple scales, we propose WISDOM to leverage wavelet-domain predictive task representations to enhance NSRL. WISDOM captures these multi-scale features in evolving MDP sequences by transforming task representation sequences into the wavelet domain, where wavelet coefficients represent both global trends and fine-grained variations of non-stationary changes. In addition to the auto-regressive modeling commonly employed in time series forecasting, we devise a wavelet temporal difference (TD) update operator to enhance tracking and prediction of MDP evolution. We theoretically prove the convergence of this operator and demonstrate policy improvement with wavelet task representations. Experiments on diverse benchmarks show that WISDOM significantly outperforms existing baselines in both sample efficiency and asymptotic performance, demonstrating its remarkable adaptability in complex environments characterized by non-stationary and stochastically evolving tasks.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "356",
        "title": "Velocity-Form Data-Enabled Predictive Control of Soft Robots under Unknown External Payloads",
        "author": [
            "Huanqing Wang",
            "Kaixiang Zhang",
            "Kyungjoon Lee",
            "Yu Mei",
            "Vaibhav Srivastava",
            "Jun Sheng",
            "Ziyou Song",
            "Zhaojian Li"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04509",
        "abstract": "Data-driven control methods such as data-enabled predictive control (DeePC) have shown strong potential in efficient control of soft robots without explicit parametric models. However, in object manipulation tasks, unknown external payloads and disturbances can significantly alter the system dynamics and behavior, leading to offset error and degraded control performance. In this paper, we present a novel velocity-form DeePC framework that achieves robust and optimal control of soft robots under unknown payloads. The proposed framework leverages input-output data in an incremental representation to mitigate performance degradation induced by unknown payloads, eliminating the need for weighted datasets or disturbance estimators. We validate the method experimentally on a planar soft robot and demonstrate its superior performance compared to standard DeePC in scenarios involving unknown payloads.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "357",
        "title": "Real-time Prediction of Urban Sound Propagation with Conditioned Normalizing Flows",
        "author": [
            "Achim Eckerle",
            "Martin Spitznagel",
            "Janis Keuper"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04510",
        "abstract": "Accurate and fast urban noise prediction is pivotal for public health and for regulatory workflows in cities, where the Environmental Noise Directive mandates regular strategic noise maps and action plans, often needed in permission workflows, right-of-way allocation, and construction scheduling. Physics-based solvers are too slow for such time-critical, iterative \"what-if\" studies. We evaluate conditional Normalizing Flows (Full-Glow) for generating for generating standards-compliant urban sound-pressure maps from 2D urban layouts in real time per 256x256 map on a single RTX 4090), enabling interactive exploration directly on commodity hardware. On datasets covering Baseline, Diffraction, and Reflection regimes, our model accelerates map generation by >2000 times over a reference solver while improving NLoS accuracy by up to 24% versus prior deep models; in Baseline NLoS we reach 0.65 dB MAE with high structural fidelity. The model reproduces diffraction and interference patterns and supports instant recomputation under source or geometry changes, making it a practical engine for urban planning, compliance mapping, and operations (e.g., temporary road closures, night-work variance assessments).",
        "tags": [
            "Normalizing Flows"
        ]
    },
    {
        "id": "358",
        "title": "ChartAgent: A Multimodal Agent for Visually Grounded Reasoning in Complex Chart Question Answering",
        "author": [
            "Rachneet Kaur",
            "Nishan Srishankar",
            "Zhen Zeng",
            "Sumitra Ganesh",
            "Manuela Veloso"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04514",
        "abstract": "Recent multimodal LLMs have shown promise in chart-based visual question answering, but their performance declines sharply on unannotated charts, those requiring precise visual interpretation rather than relying on textual shortcuts. To address this, we introduce ChartAgent, a novel agentic framework that explicitly performs visual reasoning directly within the chart's spatial domain. Unlike textual chain-of-thought reasoning, ChartAgent iteratively decomposes queries into visual subtasks and actively manipulates and interacts with chart images through specialized actions such as drawing annotations, cropping regions (e.g., segmenting pie slices, isolating bars), and localizing axes, using a library of chart-specific vision tools to fulfill each subtask. This iterative reasoning process closely mirrors human cognitive strategies for chart comprehension. ChartAgent achieves state-of-the-art accuracy on the ChartBench and ChartX benchmarks, surpassing prior methods by up to 16.07% absolute gain overall and 17.31% on unannotated, numerically intensive queries. Furthermore, our analyses show that ChartAgent is (a) effective across diverse chart types, (b) achieve the highest scores across varying visual and reasoning complexity levels, and (c) serves as a plug-and-play framework that boosts performance across diverse underlying LLMs. Our work is among the first to demonstrate visually grounded reasoning for chart understanding using tool-augmented multimodal agents.",
        "tags": [
            "CoT",
            "LLM"
        ]
    },
    {
        "id": "359",
        "title": "Spec2Control: Automating PLC/DCS Control-Logic Engineering from Natural Language Requirements with LLMs - A Multi-Plant Evaluation",
        "author": [
            "Heiko Koziolek",
            "Thilo Braun",
            "Virendra Ashiwal",
            "Sofia Linsbauer",
            "Marthe Ahlgreen Hansen",
            "Karoline Grotterud"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04519",
        "abstract": "Distributed control systems (DCS) manage the automation for many industrial production processes (e.g., power plants, chemical refineries, steel mills). Programming the software for such systems remains a largely manual and tedious process, incurring costs of millions of dollars for extensive facilities. Large language models (LLMs) have been found helpful in generating DCS control logic, resulting in commercial copilot tools. Today, these tools are focused on textual notations, they provide limited automation, and have not been tested on large datasets with realistic test cases. We introduce Spec2Control, a highly automated LLM workflow to generate graphical control logic directly from natural language user requirements. Experiments using an open dataset with 10 control narratives and 65 complex test cases demonstrate that Spec2Control can successfully identify control strategies, can generate 98.6% of correct control strategy connections autonomously, and can save between 94-96% of human labor. Spec2Control is being integrated into commercial ABB engineering tools, but is also available as an open-source variant for independent validation.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "360",
        "title": "Aria: An Agent For Retrieval and Iterative Auto-Formalization via Dependency Graph",
        "author": [
            "Hanyu Wang",
            "Ruohan Xie",
            "Yutong Wang",
            "Guoxiong Gao",
            "Xintao Yu",
            "Bin Dong"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04520",
        "abstract": "Accurate auto-formalization of theorem statements is essential for advancing automated discovery and verification of research-level mathematics, yet remains a major bottleneck for LLMs due to hallucinations, semantic mismatches, and their inability to synthesize new definitions. To tackle these issues, we present Aria (Agent for Retrieval and Iterative Autoformalization), a system for conjecture-level formalization in Lean that emulates human expert reasoning via a two-phase Graph-of-Thought process: recursively decomposing statements into a dependency graph and then constructing formalizations from grounded concepts. To ensure semantic correctness, we introduce AriaScorer, a checker that retrieves definitions from Mathlib for term-level grounding, enabling rigorous and reliable verification. We evaluate Aria on diverse benchmarks. On ProofNet, it achieves 91.6% compilation success rate and 68.5% final accuracy, surpassing previous methods. On FATE-X, a suite of challenging algebra problems from research literature, it outperforms the best baseline with 44.0% vs. 24.0% final accuracy. On a dataset of homological conjectures, Aria reaches 42.9% final accuracy while all other models score 0%.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "361",
        "title": "Toward a Unified Geometry Understanding: Riemannian Diffusion Framework for Graph Generation and Prediction",
        "author": [
            "Yisen Gao",
            "Xingcheng Fu",
            "Qingyun Sun",
            "Jianxin Li",
            "Xianxian Li"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04522",
        "abstract": "Graph diffusion models have made significant progress in learning structured graph data and have demonstrated strong potential for predictive tasks. Existing approaches typically embed node, edge, and graph-level features into a unified latent space, modeling prediction tasks including classification and regression as a form of conditional generation. However, due to the non-Euclidean nature of graph data, features of different curvatures are entangled in the same latent space without releasing their geometric potential. To address this issue, we aim to construt an ideal Riemannian diffusion model to capture distinct manifold signatures of complex graph data and learn their distribution. This goal faces two challenges: numerical instability caused by exponential mapping during the encoding proces and manifold deviation during diffusion generation. To address these challenges, we propose GeoMancer: a novel Riemannian graph diffusion framework for both generation and prediction tasks. To mitigate numerical instability, we replace exponential mapping with an isometric-invariant Riemannian gyrokernel approach and decouple multi-level features onto their respective task-specific manifolds to learn optimal representations. To address manifold deviation, we introduce a manifold-constrained diffusion method and a self-guided strategy for unconditional generation, ensuring that the generated data remains aligned with the manifold signature. Extensive experiments validate the effectiveness of our approach, demonstrating superior performance across a variety of tasks.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "362",
        "title": "Demystifying MaskGIT Sampler and Beyond: Adaptive Order Selection in Masked Diffusion",
        "author": [
            "Satoshi Hayakawa",
            "Yuhta Takida",
            "Masaaki Imaizumi",
            "Hiromi Wakaki",
            "Yuki Mitsufuji"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04525",
        "abstract": "Masked diffusion models have shown promising performance in generating high-quality samples in a wide range of domains, but accelerating their sampling process remains relatively underexplored. To investigate efficient samplers for masked diffusion, this paper theoretically analyzes the MaskGIT sampler for image modeling, revealing its implicit temperature sampling mechanism. Through this analysis, we introduce the \"moment sampler,\" an asymptotically equivalent but more tractable and interpretable alternative to MaskGIT, which employs a \"choose-then-sample\" approach by selecting unmasking positions before sampling tokens. In addition, we improve the efficiency of choose-then-sample algorithms through two key innovations: a partial caching technique for transformers that approximates longer sampling trajectories without proportional computational cost, and a hybrid approach formalizing the exploration-exploitation trade-off in adaptive unmasking. Experiments in image and text domains demonstrate our theory as well as the efficiency of our proposed methods, advancing both theoretical understanding and practical implementation of masked diffusion samplers.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "363",
        "title": "Unified Threat Detection and Mitigation Framework (UTDMF): Combating Prompt Injection, Deception, and Bias in Enterprise-Scale Transformers",
        "author": [
            "Santhosh KumarRavindran"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04528",
        "abstract": "The rapid adoption of large language models (LLMs) in enterprise systems exposes vulnerabilities to prompt injection attacks, strategic deception, and biased outputs, threatening security, trust, and fairness. Extending our adversarial activation patching framework (https://arxiv.org/abs/2507.09406), which induced deception in toy networks at a 23.9% rate, we introduce the Unified Threat Detection and Mitigation Framework (UTDMF), a scalable, real-time pipeline for enterprise-grade models like Llama-3.1 (405B), GPT-4o, and Claude-3.5. Through 700+ experiments per model, UTDMF achieves: (1) 92% detection accuracy for prompt injection (e.g., jailbreaking); (2) 65% reduction in deceptive outputs via enhanced patching; and (3) 78% improvement in fairness metrics (e.g., demographic bias). Novel contributions include a generalized patching algorithm for multi-threat detection, three groundbreaking hypotheses on threat interactions (e.g., threat chaining in enterprise workflows), and a deployment-ready toolkit with APIs for enterprise integration.",
        "tags": [
            "Detection",
            "GPT",
            "LLM",
            "LLaMA"
        ]
    },
    {
        "id": "364",
        "title": "More Than Meets the Eye? Uncovering the Reasoning-Planning Disconnect in Training Vision-Language Driving Models",
        "author": [
            "Xurui Song",
            "Shuo Huai",
            "JingJing Jiang",
            "Jiayi Kong",
            "Jun Luo"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04532",
        "abstract": "Vision-Language Model (VLM) driving agents promise explainable end-to-end autonomy by first producing natural-language reasoning and then predicting trajectory planning. However, whether planning is causally driven by this reasoning remains a critical but unverified assumption. To investigate this, we build DriveMind, a large-scale driving Visual Question Answering (VQA) corpus with plan-aligned Chain-of-Thought (CoT), automatically generated from nuPlan. Our data generation process converts sensors and annotations into structured inputs and, crucially, separates priors from to-be-reasoned signals, enabling clean information ablations. Using DriveMind, we train representative VLM agents with Supervised Fine-Tuning (SFT) and Group Relative Policy Optimization (GRPO) and evaluate them with nuPlan's metrics. Our results, unfortunately, indicate a consistent causal disconnect in reasoning-planning: removing ego/navigation priors causes large drops in planning scores, whereas removing CoT produces only minor changes. Attention analysis further shows that planning primarily focuses on priors rather than the CoT. Based on this evidence, we propose the Reasoning-Planning Decoupling Hypothesis, positing that the training-yielded reasoning is an ancillary byproduct rather than a causal mediator. To enable efficient diagnosis, we also introduce a novel, training-free probe that measures an agent's reliance on priors by evaluating its planning robustness against minor input perturbations. In summary, we provide the community with a new dataset and a diagnostic tool to evaluate the causal fidelity of future models.",
        "tags": [
            "CoT",
            "GRPO",
            "VLM"
        ]
    },
    {
        "id": "365",
        "title": "TAG:Tangential Amplifying Guidance for Hallucination-Resistant Diffusion Sampling",
        "author": [
            "Hyunmin Cho",
            "Donghoon Ahn",
            "Susung Hong",
            "Jee Eun Kim",
            "Seungryong Kim",
            "Kyong Hwan Jin"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04533",
        "abstract": "Recent diffusion models achieve the state-of-the-art performance in image generation, but often suffer from semantic inconsistencies or hallucinations. While various inference-time guidance methods can enhance generation, they often operate indirectly by relying on external signals or architectural modifications, which introduces additional computational overhead. In this paper, we propose Tangential Amplifying Guidance (TAG), a more efficient and direct guidance method that operates solely on trajectory signals without modifying the underlying diffusion model. TAG leverages an intermediate sample as a projection basis and amplifies the tangential components of the estimated scores with respect to this basis to correct the sampling trajectory. We formalize this guidance process by leveraging a first-order Taylor expansion, which demonstrates that amplifying the tangential component steers the state toward higher-probability regions, thereby reducing inconsistencies and enhancing sample quality. TAG is a plug-and-play, architecture-agnostic module that improves diffusion sampling fidelity with minimal computational addition, offering a new perspective on diffusion guidance.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "366",
        "title": "3Dify: a Framework for Procedural 3D-CG Generation Assisted by LLMs Using MCP and RAG",
        "author": [
            "Shun-ichiro Hayashi",
            "Daichi Mukunoki",
            "Tetsuya Hoshino",
            "Satoshi Ohshima",
            "Takahiro Katagiri"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04536",
        "abstract": "This paper proposes \"3Dify,\" a procedural 3D computer graphics (3D-CG) generation framework utilizing Large Language Models (LLMs). The framework enables users to generate 3D-CG content solely through natural language instructions. 3Dify is built upon Dify, an open-source platform for AI application development, and incorporates several state-of-the-art LLM-related technologies such as the Model Context Protocol (MCP) and Retrieval-Augmented Generation (RAG). For 3D-CG generation support, 3Dify automates the operation of various Digital Content Creation (DCC) tools via MCP. When DCC tools do not support MCP-based interaction, the framework employs the Computer-Using Agent (CUA) method to automate Graphical User Interface (GUI) operations. Moreover, to enhance image generation quality, 3Dify allows users to provide feedback by selecting preferred images from multiple candidates. The LLM then learns variable patterns from these selections and applies them to subsequent generations. Furthermore, 3Dify supports the integration of locally deployed LLMs, enabling users to utilize custom-developed models and to reduce both time and monetary costs associated with external API calls by leveraging their own computational resources.",
        "tags": [
            "3D",
            "LLM",
            "RAG"
        ]
    },
    {
        "id": "367",
        "title": "C3Editor: Achieving Controllable Consistency in 2D Model for 3D Editing",
        "author": [
            "Zeng Tao",
            "Zheng Ding",
            "Zeyuan Chen",
            "Xiang Zhang",
            "Leizhi Li",
            "Zhuowen Tu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04539",
        "abstract": "Existing 2D-lifting-based 3D editing methods often encounter challenges related to inconsistency, stemming from the lack of view-consistent 2D editing models and the difficulty of ensuring consistent editing across multiple views. To address these issues, we propose C3Editor, a controllable and consistent 2D-lifting-based 3D editing framework. Given an original 3D representation and a text-based editing prompt, our method selectively establishes a view-consistent 2D editing model to achieve superior 3D editing results. The process begins with the controlled selection of a ground truth (GT) view and its corresponding edited image as the optimization target, allowing for user-defined manual edits. Next, we fine-tune the 2D editing model within the GT view and across multiple views to align with the GT-edited image while ensuring multi-view consistency. To meet the distinct requirements of GT view fitting and multi-view consistency, we introduce separate LoRA modules for targeted fine-tuning. Our approach delivers more consistent and controllable 2D and 3D editing results than existing 2D-lifting-based methods, outperforming them in both qualitative and quantitative evaluations.",
        "tags": [
            "3D",
            "LoRA"
        ]
    },
    {
        "id": "368",
        "title": "Code World Models for General Game Playing",
        "author": [
            "Wolfgang Lehrach",
            "Daniel Hennes",
            "Miguel Lazaro-Gredilla",
            "Xinghua Lou",
            "Carter Wendelken",
            "Zun Li",
            "Antoine Dedieu",
            "Jordi Grau-Moya",
            "Marc Lanctot",
            "Atil Iscen",
            "John Schultz",
            "Marcus Chiam",
            "Ian Gemp",
            "Piotr Zielinski",
            "Satinder Singh",
            "Kevin P. Murphy"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04542",
        "abstract": "Large Language Models (LLMs) reasoning abilities are increasingly being applied to classical board and card games, but the dominant approach -- involving prompting for direct move generation -- has significant drawbacks. It relies on the model's implicit fragile pattern-matching capabilities, leading to frequent illegal moves and strategically shallow play. Here we introduce an alternative approach: We use the LLM to translate natural language rules and game trajectories into a formal, executable world model represented as Python code. This generated model -- comprising functions for state transition, legal move enumeration, and termination checks -- serves as a verifiable simulation engine for high-performance planning algorithms like Monte Carlo tree search (MCTS). In addition, we prompt the LLM to generate heuristic value functions (to make MCTS more efficient), and inference functions (to estimate hidden states in imperfect information games). Our method offers three distinct advantages compared to directly using the LLM as a policy: (1) Verifiability: The generated CWM serves as a formal specification of the game's rules, allowing planners to algorithmically enumerate valid actions and avoid illegal moves, contingent on the correctness of the synthesized model; (2) Strategic Depth: We combine LLM semantic understanding with the deep search power of classical planners; and (3) Generalization: We direct the LLM to focus on the meta-task of data-to-code translation, enabling it to adapt to new games more easily. We evaluate our agent on 10 different games, of which 4 are novel and created for this paper. 5 of the games are fully observed (perfect information), and 5 are partially observed (imperfect information). We find that our method outperforms or matches Gemini 2.5 Pro in 9 out of the 10 considered games.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "369",
        "title": "Post-training quantization of vision encoders needs prefixing registers",
        "author": [
            "Seunghyeon Kim",
            "Jinho Kim",
            "Taesun Yeom",
            "Wonpyo Park",
            "Kyuyeun Kim",
            "Jaeho Lee"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04547",
        "abstract": "Transformer-based vision encoders -- such as CLIP -- are central to multimodal intelligence, powering applications from autonomous web agents to robotic control. Since these applications often demand real-time processing of massive visual data, reducing the inference cost of vision encoders is critical. Post-training quantization offers a practical path, but remains challenging even at 8-bit precision due to massive-scale activations (i.e., outliers). In this work, we propose $\\textit{RegCache}$, a training-free algorithm to mitigate outliers in vision encoders, enabling quantization with significantly smaller accuracy drops. The proposed RegCache introduces outlier-prone yet semantically meaningless prefix tokens to the target vision encoder, which prevents other tokens from having outliers. Notably, we observe that outliers in vision encoders behave differently from those in language models, motivating two technical innovations: middle-layer prefixing and token deletion. Experiments show that our method consistently improves the accuracy of quantized models across both text-supervised and self-supervised vision encoders.",
        "tags": [
            "CLIP",
            "Transformer"
        ]
    },
    {
        "id": "370",
        "title": "TRAJECT-Bench:A Trajectory-Aware Benchmark for Evaluating Agentic Tool Use",
        "author": [
            "Pengfei He",
            "Zhenwei Dai",
            "Bing He",
            "Hui Liu",
            "Xianfeng Tang",
            "Hanqing Lu",
            "Juanhui Li",
            "Jiayuan Ding",
            "Subhabrata Mukherjee",
            "Suhang Wang",
            "Yue Xing",
            "Jiliang Tang",
            "Benoit Dumoulin"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04550",
        "abstract": "Large language model (LLM)-based agents increasingly rely on tool use to complete real-world tasks. While existing works evaluate the LLMs' tool use capability, they largely focus on the final answers yet overlook the detailed tool usage trajectory, i.e., whether tools are selected, parameterized, and ordered correctly. We introduce TRAJECT-Bench, a trajectory-aware benchmark to comprehensively evaluate LLMs' tool use capability through diverse tasks with fine-grained evaluation metrics. TRAJECT-Bench pairs high-fidelity, executable tools across practical domains with tasks grounded in production-style APIs, and synthesizes trajectories that vary in breadth (parallel calls) and depth (interdependent chains). Besides final accuracy, TRAJECT-Bench also reports trajectory-level diagnostics, including tool selection and argument correctness, and dependency/order satisfaction. Analyses reveal failure modes such as similar tool confusion and parameter-blind selection, and scaling behavior with tool diversity and trajectory length where the bottleneck of transiting from short to mid-length trajectories is revealed, offering actionable guidance for LLMs' tool use.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "371",
        "title": "Tail-Safe Hedging: Explainable Risk-Sensitive Reinforcement Learning with a White-Box CBF--QP Safety Layer in Arbitrage-Free Markets",
        "author": [
            "Jian'an Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04555",
        "abstract": "We introduce Tail-Safe, a deployability-oriented framework for derivatives hedging that unifies distributional, risk-sensitive reinforcement learning with a white-box control-barrier-function (CBF) quadratic-program (QP) safety layer tailored to financial constraints. The learning component combines an IQN-based distributional critic with a CVaR objective (IQN--CVaR--PPO) and a Tail-Coverage Controller that regulates quantile sampling through temperature tilting and tail boosting to stabilize small-$\\alpha$ estimation. The safety component enforces discrete-time CBF inequalities together with domain-specific constraints -- ellipsoidal no-trade bands, box and rate limits, and a sign-consistency gate -- solved as a convex QP whose telemetry (active sets, tightness, rate utilization, gate scores, slack, and solver status) forms an auditable trail for governance. We provide guarantees of robust forward invariance of the safe set under bounded model mismatch, a minimal-deviation projection interpretation of the QP, a KL-to-DRO upper bound linking per-state KL regularization to worst-case CVaR, concentration and sample-complexity results for the temperature-tilted CVaR estimator, and a CVaR trust-region improvement inequality under KL limits, together with feasibility persistence under expiry-aware tightening. Empirically, in arbitrage-free, microstructure-aware synthetic markets (SSVI $\\to$ Dupire $\\to$ VIX with ABIDES/MockLOB execution), Tail-Safe improves left-tail risk without degrading central performance and yields zero hard-constraint violations whenever the QP is feasible with zero slack. Telemetry is mapped to governance dashboards and incident workflows to support explainability and auditability. Limitations include reliance on synthetic data and simplified execution to isolate methodological contributions.",
        "tags": [
            "PPO",
            "RL"
        ]
    },
    {
        "id": "372",
        "title": "ContextNav: Towards Agentic Multimodal In-Context Learning",
        "author": [
            "Honghao Fu",
            "Yuan Ouyang",
            "Kai-Wei Chang",
            "Yiwei Wang",
            "Zi Huang",
            "Yujun Cai"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04560",
        "abstract": "Recent advances demonstrate that multimodal large language models (MLLMs) exhibit strong multimodal in-context learning (ICL) capabilities, enabling them to adapt to novel vision-language tasks from a few contextual examples. However, existing ICL approaches face challenges in reconciling scalability with robustness across diverse tasks and noisy contextual examples: manually selecting examples produces clean contexts but is labor-intensive and task-specific, while similarity-based retrieval improves scalability but could introduce irrelevant or structurally inconsistent samples that degrade ICL performance. To address these limitations, we propose ContextNav, the first agentic framework that integrates the scalability of automated retrieval with the quality and adaptiveness of human-like curation, enabling noise-robust and dynamically optimized contextualization for multimodal ICL. ContextNav unifies context management and noise-robust contextualization within a closed-loop workflow driven by graph-based orchestration. Specifically, it builds a resource-aware multimodal embedding pipeline, maintains a retrievable vector database, and applies agentic retrieval and structural alignment to construct noise-resilient contexts. An Operational Grammar Graph (OGG) further supports adaptive workflow planning and optimization, enabling the agent to refine its operational strategies based on downstream ICL feedback. Experimental results demonstrate that ContextNav achieves state-of-the-art performance across various datasets, underscoring the promise of agentic workflows for advancing scalable and robust contextualization in multimodal ICL.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "373",
        "title": "Stochastic Approximation Methods for Distortion Risk Measure Optimization",
        "author": [
            "Jinyang Jiang",
            "Bernd Heidergott",
            "Jiaqiao Hu",
            "Yijie Peng"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04563",
        "abstract": "Distortion Risk Measures (DRMs) capture risk preferences in decision-making and serve as general criteria for managing uncertainty. This paper proposes gradient descent algorithms for DRM optimization based on two dual representations: the Distortion-Measure (DM) form and Quantile-Function (QF) form. The DM-form employs a three-timescale algorithm to track quantiles, compute their gradients, and update decision variables, utilizing the Generalized Likelihood Ratio and kernel-based density estimation. The QF-form provides a simpler two-timescale approach that avoids the need for complex quantile gradient estimation. A hybrid form integrates both approaches, applying the DM-form for robust performance around distortion function jumps and the QF-form for efficiency in smooth regions. Proofs of strong convergence and convergence rates for the proposed algorithms are provided. In particular, the DM-form achieves an optimal rate of $O(k^{-4/7})$, while the QF-form attains a faster rate of $O(k^{-2/3})$. Numerical experiments confirm their effectiveness and demonstrate substantial improvements over baselines in robust portfolio selection tasks. The method's scalability is further illustrated through integration into deep reinforcement learning. Specifically, a DRM-based Proximal Policy Optimization algorithm is developed and applied to multi-echelon dynamic inventory management, showcasing its practical applicability.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "374",
        "title": "Conditional Representation Learning for Customized Tasks",
        "author": [
            "Honglin Liu",
            "Chao Sun",
            "Peng Hu",
            "Yunfan Li",
            "Xi Peng"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04564",
        "abstract": "Conventional representation learning methods learn a universal representation that primarily captures dominant semantics, which may not always align with customized downstream tasks. For instance, in animal habitat analysis, researchers prioritize scene-related features, whereas universal embeddings emphasize categorical semantics, leading to suboptimal results. As a solution, existing approaches resort to supervised fine-tuning, which however incurs high computational and annotation costs. In this paper, we propose Conditional Representation Learning (CRL), aiming to extract representations tailored to arbitrary user-specified criteria. Specifically, we reveal that the semantics of a space are determined by its basis, thereby enabling a set of descriptive words to approximate the basis for a customized feature space. Building upon this insight, given a user-specified criterion, CRL first employs a large language model (LLM) to generate descriptive texts to construct the semantic basis, then projects the image representation into this conditional feature space leveraging a vision-language model (VLM). The conditional representation better captures semantics for the specific criterion, which could be utilized for multiple customized tasks. Extensive experiments on classification and retrieval tasks demonstrate the superiority and generality of the proposed CRL. The code is available at https://github.com/XLearning-SCU/2025-NeurIPS-CRL.",
        "tags": [
            "LLM",
            "VLM"
        ]
    },
    {
        "id": "375",
        "title": "GILT: An LLM-Free, Tuning-Free Graph Foundational Model for In-Context Learning",
        "author": [
            "Weishuo Ma",
            "Yanbo Wang",
            "Xiyuan Wang",
            "Lei Zou",
            "Muhan Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04567",
        "abstract": "Graph Neural Networks (GNNs) are powerful tools for precessing relational data but often struggle to generalize to unseen graphs, giving rise to the development of Graph Foundational Models (GFMs). However, current GFMs are challenged by the extreme heterogeneity of graph data, where each graph can possess a unique feature space, label set, and topology. To address this, two main paradigms have emerged. The first leverages Large Language Models (LLMs), but is fundamentally text-dependent, thus struggles to handle the numerical features in vast graphs. The second pre-trains a structure-based model, but the adaptation to new tasks typically requires a costly, per-graph tuning stage, creating a critical efficiency bottleneck. In this work, we move beyond these limitations and introduce \\textbf{G}raph \\textbf{I}n-context \\textbf{L}earning \\textbf{T}ransformer (GILT), a framework built on an LLM-free and tuning-free architecture. GILT introduces a novel token-based framework for in-context learning (ICL) on graphs, reframing classification tasks spanning node, edge and graph levels in a unified framework. This mechanism is the key to handling heterogeneity, as it is designed to operate on generic numerical features. Further, its ability to understand class semantics dynamically from the context enables tuning-free adaptation. Comprehensive experiments show that GILT achieves stronger few-shot performance with significantly less time than LLM-based or tuning-based baselines, validating the effectiveness of our approach.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "376",
        "title": "COSMIR: Chain Orchestrated Structured Memory for Iterative Reasoning over Long Context",
        "author": [
            "Naman Gupta",
            "Shreeyash Gowaikar",
            "Arun Iyer",
            "Kirankumar Shiragur",
            "Ramakrishna B Bairi",
            "Rishikesh Maurya",
            "Ritabrata Maiti",
            "Sankarshan Damle",
            "Shachee Mishra Gupta"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04568",
        "abstract": "Reasoning over very long inputs remains difficult for large language models (LLMs). Common workarounds either shrink the input via retrieval (risking missed evidence), enlarge the context window (straining selectivity), or stage multiple agents to read in pieces. In staged pipelines (e.g., Chain of Agents, CoA), free-form summaries passed between agents can discard crucial details and amplify early mistakes. We introduce COSMIR (Chain Orchestrated Structured Memory for Iterative Reasoning), a chain-style framework that replaces ad hoc messages with a structured memory. A Planner agent first turns a user query into concrete, checkable sub-questions. worker agents process chunks via a fixed micro-cycle: Extract, Infer, Refine, writing all updates to the shared memory. A Manager agent then Synthesizes the final answer directly from the memory. This preserves step-wise read-then-reason benefits while changing both the communication medium (structured memory) and the worker procedure (fixed micro-cycle), yielding higher faithfulness, better long-range aggregation, and auditability. On long-context QA from the HELMET suite, COSMIR reduces propagation-stage information loss and improves accuracy over a CoA baseline.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "377",
        "title": "LaDiR: Latent Diffusion Enhances LLMs for Text Reasoning",
        "author": [
            "Haoqiang Kang",
            "Yizhe Zhang",
            "Nikki Lijing Kuang",
            "Nicklas Majamaki",
            "Navdeep Jaitly",
            "Yi-An Ma",
            "Lianhui Qin"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04573",
        "abstract": "Large Language Models (LLMs) demonstrate their reasoning ability through chain-of-thought (CoT) generation. However, LLM's autoregressive decoding may limit the ability to revisit and refine earlier tokens in a holistic manner, which can also lead to inefficient exploration for diverse solutions. In this paper, we propose LaDiR (Latent Diffusion Reasoner), a novel reasoning framework that unifies the expressiveness of continuous latent representation with the iterative refinement capabilities of latent diffusion models for an existing LLM. We first construct a structured latent reasoning space using a Variational Autoencoder (VAE) that encodes text reasoning steps into blocks of thought tokens, preserving semantic information and interpretability while offering compact but expressive representations. Subsequently, we utilize a latent diffusion model that learns to denoise a block of latent thought tokens with a blockwise bidirectional attention mask, enabling longer horizon and iterative refinement with adaptive test-time compute. This design allows efficient parallel generation of diverse reasoning trajectories, allowing the model to plan and revise the reasoning process holistically. We conduct evaluations on a suite of mathematical reasoning and planning benchmarks. Empirical results show that LaDiR consistently improves accuracy, diversity, and interpretability over existing autoregressive, diffusion-based, and latent reasoning methods, revealing a new paradigm for text reasoning with latent diffusion.",
        "tags": [
            "CoT",
            "Diffusion",
            "LLM",
            "VAE"
        ]
    },
    {
        "id": "378",
        "title": "SONA: Learning Conditional, Unconditional, and Mismatching-Aware Discriminator",
        "author": [
            "Yuhta Takida",
            "Satoshi Hayakawa",
            "Takashi Shibuya",
            "Masaaki Imaizumi",
            "Naoki Murata",
            "Bac Nguyen",
            "Toshimitsu Uesaka",
            "Chieh-Hsin Lai",
            "Yuki Mitsufuji"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04576",
        "abstract": "Deep generative models have made significant advances in generating complex content, yet conditional generation remains a fundamental challenge. Existing conditional generative adversarial networks often struggle to balance the dual objectives of assessing authenticity and conditional alignment of input samples within their conditional discriminators. To address this, we propose a novel discriminator design that integrates three key capabilities: unconditional discrimination, matching-aware supervision to enhance alignment sensitivity, and adaptive weighting to dynamically balance all objectives. Specifically, we introduce Sum of Naturalness and Alignment (SONA), which employs separate projections for naturalness (authenticity) and alignment in the final layer with an inductive bias, supported by dedicated objective functions and an adaptive weighting mechanism. Extensive experiments on class-conditional generation tasks show that \\ours achieves superior sample quality and conditional alignment compared to state-of-the-art methods. Furthermore, we demonstrate its effectiveness in text-to-image generation, confirming the versatility and robustness of our approach.",
        "tags": [
            "Text-to-Image"
        ]
    },
    {
        "id": "379",
        "title": "Language Model Based Text-to-Audio Generation: Anti-Causally Aligned Collaborative Residual Transformers",
        "author": [
            "Juncheng Wang",
            "Chao Xu",
            "Cheng Yu",
            "Zhe Hu",
            "Haoyu Xie",
            "Guoqi Yu",
            "Lei Shang",
            "Shujun Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04577",
        "abstract": "While language models (LMs) paired with residual vector quantization (RVQ) tokenizers have shown promise in text-to-audio (T2A) generation, they still lag behind diffusion-based models by a non-trivial margin. We identify a critical dilemma underpinning this gap: incorporating more RVQ layers improves audio reconstruction fidelity but exceeds the generation capacity of conventional LMs. To address this, we first analyze RVQ dynamics and uncover two key limitations: 1) orthogonality of features across RVQ layers hinders effective LMs training, and 2) descending semantic richness in tokens from deeper RVQ layers exacerbates exposure bias during autoregressive decoding. Based on these insights, we propose Siren, a novel LM-based framework that employs multiple isolated transformers with causal conditioning and anti-causal alignment via reinforcement learning. Extensive experiments demonstrate that Siren outperforms both existing LM-based and diffusion-based T2A systems, achieving state-of-the-art results. By bridging the representational strengths of LMs with the fidelity demands of audio synthesis, our approach repositions LMs as competitive contenders against diffusion models in T2A tasks. Moreover, by aligning audio representations with linguistic structures, Siren facilitates a promising pathway toward unified multi-modal generation frameworks.",
        "tags": [
            "Diffusion",
            "RL",
            "Vector Quantization"
        ]
    },
    {
        "id": "380",
        "title": "Can LLMs Detect Ambiguous Plural Reference? An Analysis of Split-Antecedent and Mereological Reference",
        "author": [
            "Dang Anh",
            "Rick Nouwen",
            "Massimo Poesio"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04581",
        "abstract": "Our goal is to study how LLMs represent and interpret plural reference in ambiguous and unambiguous contexts. We ask the following research questions: (1) Do LLMs exhibit human-like preferences in representing plural reference? (2) Are LLMs able to detect ambiguity in plural anaphoric expressions and identify possible referents? To address these questions, we design a set of experiments, examining pronoun production using next-token prediction tasks, pronoun interpretation, and ambiguity detection using different prompting strategies. We then assess how comparable LLMs are to humans in formulating and interpreting plural reference. We find that LLMs are sometimes aware of possible referents of ambiguous pronouns. However, they do not always follow human reference when choosing between interpretations, especially when the possible interpretation is not explicitly mentioned. In addition, they struggle to identify ambiguity without direct instruction. Our findings also reveal inconsistencies in the results across different types of experiments.",
        "tags": [
            "Detection",
            "LLM"
        ]
    },
    {
        "id": "381",
        "title": "Improved probabilistic regression using diffusion models",
        "author": [
            "Carlo Kneissl",
            "Christopher BÃ¼lte",
            "Philipp Scholl",
            "Gitta Kutyniok"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04583",
        "abstract": "Probabilistic regression models the entire predictive distribution of a response variable, offering richer insights than classical point estimates and directly allowing for uncertainty quantification. While diffusion-based generative models have shown remarkable success in generating complex, high-dimensional data, their usage in general regression tasks often lacks uncertainty-related evaluation and remains limited to domain-specific applications. We propose a novel diffusion-based framework for probabilistic regression that learns predictive distributions in a nonparametric way. More specifically, we propose to model the full distribution of the diffusion noise, enabling adaptation to diverse tasks and enhanced uncertainty quantification. We investigate different noise parameterizations, analyze their trade-offs, and evaluate our framework across a broad range of regression tasks, covering low- and high-dimensional settings. For several experiments, our approach shows superior performance against existing baselines, while delivering calibrated uncertainty estimates, demonstrating its versatility as a tool for probabilistic prediction.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "382",
        "title": "Pathology-CoT: Learning Visual Chain-of-Thought Agent from Expert Whole Slide Image Diagnosis Behavior",
        "author": [
            "Sheng Wang",
            "Ruiming Wu",
            "Charles Herndon",
            "Yihang Liu",
            "Shunsuke Koga",
            "Jeanne Shen",
            "Zhi Huang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04587",
        "abstract": "Diagnosing a whole-slide image is an interactive, multi-stage process involving changes in magnification and movement between fields. Although recent pathology foundation models are strong, practical agentic systems that decide what field to examine next, adjust magnification, and deliver explainable diagnoses are still lacking. The blocker is data: scalable, clinically aligned supervision of expert viewing behavior that is tacit and experience-based, not written in textbooks or online, and therefore absent from large language model training. We introduce the AI Session Recorder, which works with standard WSI viewers to unobtrusively record routine navigation and convert the viewer logs into standardized behavioral commands (inspect or peek at discrete magnifications) and bounding boxes. A lightweight human-in-the-loop review turns AI-drafted rationales into the Pathology-CoT dataset, a form of paired \"where to look\" and \"why it matters\" supervision produced at roughly six times lower labeling time. Using this behavioral data, we build Pathologist-o3, a two-stage agent that first proposes regions of interest and then performs behavior-guided reasoning. On gastrointestinal lymph-node metastasis detection, it achieved 84.5% precision, 100.0% recall, and 75.4% accuracy, exceeding the state-of-the-art OpenAI o3 model and generalizing across backbones. To our knowledge, this constitutes one of the first behavior-grounded agentic systems in pathology. Turning everyday viewer logs into scalable, expert-validated supervision, our framework makes agentic pathology practical and establishes a path to human-aligned, upgradeable clinical AI.",
        "tags": [
            "CoT",
            "Detection"
        ]
    },
    {
        "id": "383",
        "title": "MobRT: A Digital Twin-Based Framework for Scalable Learning in Mobile Manipulation",
        "author": [
            "Yilin Mei",
            "Peng Qiu",
            "Wei Zhang",
            "WenChao Zhang",
            "Wenjie Song"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04592",
        "abstract": "Recent advances in robotics have been largely driven by imitation learning, which depends critically on large-scale, high-quality demonstration data. However, collecting such data remains a significant challenge-particularly for mobile manipulators, which must coordinate base locomotion and arm manipulation in high-dimensional, dynamic, and partially observable environments. Consequently, most existing research remains focused on simpler tabletop scenarios, leaving mobile manipulation relatively underexplored. To bridge this gap, we present \\textit{MobRT}, a digital twin-based framework designed to simulate two primary categories of complex, whole-body tasks: interaction with articulated objects (e.g., opening doors and drawers) and mobile-base pick-and-place operations. \\textit{MobRT} autonomously generates diverse and realistic demonstrations through the integration of virtual kinematic control and whole-body motion planning, enabling coherent and physically consistent execution. We evaluate the quality of \\textit{MobRT}-generated data across multiple baseline algorithms, establishing a comprehensive benchmark and demonstrating a strong correlation between task success and the number of generated trajectories. Experiments integrating both simulated and real-world demonstrations confirm that our approach markedly improves policy generalization and performance, achieving robust results in both simulated and real-world environments.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "384",
        "title": "SpikingMamba: Towards Energy-Efficient Large Language Models via Knowledge Distillation from Mamba",
        "author": [
            "Yulong Huang",
            "Jianxiong Tang",
            "Chao Wang",
            "Ziyi Wang",
            "Jianguo Zhang",
            "Zhichao Lu",
            "Bojun Cheng",
            "Luziwei Leng"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04595",
        "abstract": "Large Language Models (LLMs) have achieved remarkable performance across tasks but remain energy-intensive due to dense matrix operations. Spiking neural networks (SNNs) improve energy efficiency by replacing dense matrix multiplications with sparse accumulations. Their sparse spike activity enables efficient LLMs deployment on edge devices. However, prior SNN-based LLMs often sacrifice performance for efficiency, and recovering accuracy typically requires full pretraining, which is costly and impractical. To address this, we propose SpikingMamba, an energy-efficient SNN-based LLMs distilled from Mamba that improves energy efficiency with minimal accuracy sacrifice. SpikingMamba integrates two key components: (a) TI-LIF, a ternary-integer spiking neuron that preserves semantic polarity through signed multi-level spike representations. (b) A training-exclusive Smoothed Gradient Compensation (SGC) path mitigating quantization loss while preserving spike-driven efficiency. We employ a single-stage distillation strategy to transfer the zero-shot ability of pretrained Mamba and further enhance it via reinforcement learning (RL). Experiments show that SpikingMamba-1.3B achieves a 4.76$\\times$ energy benefit, with only a 4.78\\% zero-shot accuracy gap compared to the original Mamba, and achieves a further 2.55\\% accuracy improvement after RL.",
        "tags": [
            "LLM",
            "Mamba",
            "RL"
        ]
    },
    {
        "id": "385",
        "title": "FedSRD: Sparsify-Reconstruct-Decompose for Communication-Efficient Federated Large Language Models Fine-Tuning",
        "author": [
            "Guochen Yan",
            "Luyuan Xie",
            "Qingni Shen",
            "Yuejian Fang",
            "Zhonghai Wu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04601",
        "abstract": "The current paradigm of training large language models (LLMs) on publicly available Web data is becoming unsustainable, with high-quality data sources in specialized domains nearing exhaustion. Federated Learning (FL) emerges as a practical solution for the next generation of AI on a decentralized Web, enabling privacy-preserving collaborative fine-tuning by leveraging private data distributed across a global client base. While Low-Rank Adaptation (LoRA) is the standard for efficient fine-tuning, its application in federated settings presents a critical challenge: communication overhead remains a significant bottleneck across the Web's heterogeneous network conditions. The structural redundancy within LoRA parameters not only incurs a heavy communication burden but also introduces conflicts when aggregating client updates. To address this, we propose FedSRD, a Sparsify-Reconstruct-Decompose framework designed for communication-efficient FL. We first introduce an importance-aware sparsification method that preserves the structural integrity of LoRA updates to reduce the uploaded parameter count. The server then reconstructs and aggregates these updates in a full-rank space to mitigate conflicts. Finally, it decomposes the global update into a sparse low-rank format for broadcast, ensuring a symmetrically efficient cycle. We also propose an efficient variant, FedSRD-e, to reduce computational overhead. Experimental results on 10 benchmarks demonstrate that our framework significantly reduces communication costs by up to 90\\% while even improving model performance on heterogeneous client data.",
        "tags": [
            "LLM",
            "LoRA"
        ]
    },
    {
        "id": "386",
        "title": "Exploring the Power of Diffusion Large Language Models for Software Engineering: An Empirical Investigation",
        "author": [
            "Jingyao Zhang",
            "Tianlin Li",
            "Xiaoyu Zhang",
            "Qiang Hu",
            "Bin Shi"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04605",
        "abstract": "Autoregressive Large Language Models (AR-LLMs) are widely used in software engineering (SE) but face limitations in processing code structure information and suffer from high inference latency. Diffusion LLMs (DLLMs) offer a promising alternative with global bidirectional encoding and decoupled generation steps. This work presents the first comprehensive evaluation of DLLMs across the software development lifecycle, including code generation, defect detection, and program repair. On a large-scale benchmark of 52,937 tasks, 7Bparameter DLLMs outperform AR-LLMs with a 30% average accuracy improvement achieving a 113% gain on cross-file repair, while maintaining superior efficiency and reduced latency. Our results establish DLLMs as a superior paradigm for SE tasks.",
        "tags": [
            "Detection",
            "Diffusion",
            "LLM"
        ]
    },
    {
        "id": "387",
        "title": "A Case for Declarative LLM-friendly Interfaces for Improved Efficiency of Computer-Use Agents",
        "author": [
            "Yuan Wang",
            "Mingyu Li",
            "Haibo Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04607",
        "abstract": "Computer-use agents (CUAs) powered by large language models (LLMs) have emerged as a promising approach to automating computer tasks, yet they struggle with graphical user interfaces (GUIs). GUIs, designed for humans, force LLMs to decompose high-level goals into lengthy, error-prone sequences of fine-grained actions, resulting in low success rates and an excessive number of LLM calls.\nWe propose Goal-Oriented Interface (GOI), a novel abstraction that transforms existing GUIs into three declarative primitives: access, state, and observation, which are better suited for LLMs. Our key idea is policy-mechanism separation: LLMs focus on high-level semantic planning (policy) while GOI handles low-level navigation and interaction (mechanism). GOI does not require modifying the application source code or relying on application programming interfaces (APIs).\nWe evaluate GOI with Microsoft Office Suite (Word, PowerPoint, Excel) on Windows. Compared to a leading GUI-based agent baseline, GOI improves task success rates by 67% and reduces interaction steps by 43.5%. Notably, GOI completes over 61% of successful tasks with a single LLM call.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "388",
        "title": "OKVIS2-X: Open Keyframe-based Visual-Inertial SLAM Configurable with Dense Depth or LiDAR, and GNSS",
        "author": [
            "Simon Boche",
            "Jaehyung Jung",
            "SebastiÃ¡n Barbas Laina",
            "Stefan Leutenegger"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04612",
        "abstract": "To empower mobile robots with usable maps as well as highest state estimation accuracy and robustness, we present OKVIS2-X: a state-of-the-art multi-sensor Simultaneous Localization and Mapping (SLAM) system building dense volumetric occupancy maps, while scalable to large environments and operating in realtime. Our unified SLAM framework seamlessly integrates different sensor modalities: visual, inertial, measured or learned depth, LiDAR and Global Navigation Satellite System (GNSS) measurements. Unlike most state-of-the-art SLAM systems, we advocate using dense volumetric map representations when leveraging depth or range-sensing capabilities. We employ an efficient submapping strategy that allows our system to scale to large environments, showcased in sequences of up to 9 kilometers. OKVIS2-X enhances its accuracy and robustness by tightly-coupling the estimator and submaps through map alignment factors. Our system provides globally consistent maps, directly usable for autonomous navigation. To further improve the accuracy of OKVIS2-X, we also incorporate the option of performing online calibration of camera extrinsics. Our system achieves the highest trajectory accuracy in EuRoC against state-of-the-art alternatives, outperforms all competitors in the Hilti22 VI-only benchmark, while also proving competitive in the LiDAR version, and showcases state of the art accuracy in the diverse and large-scale sequences from the VBR dataset.",
        "tags": [
            "SLAM"
        ]
    },
    {
        "id": "389",
        "title": "Making Mathematical Reasoning Adaptive",
        "author": [
            "Zhejian Lai",
            "Xiang Geng",
            "Zhijun Wang",
            "Yang Bai",
            "Jiahuan Li",
            "Rongxiang Weng",
            "Jingang Wang",
            "Xuezhi Cao",
            "Xunliang Cai",
            "Shujian Huang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04617",
        "abstract": "Mathematical reasoning is a primary indicator of large language models (LLMs) intelligence. However, existing LLMs exhibit failures of robustness and generalization. This paper attributes these deficiencies to spurious reasoning, i.e., producing answers from superficial features. To address this challenge, we propose the AdaR framework to enable adaptive reasoning, wherein models rely on problem-solving logic to produce answers. AdaR synthesizes logically equivalent queries by varying variable values, and trains models with RLVR on these data to penalize spurious logic while encouraging adaptive logic. To improve data quality, we extract the problem-solving logic from the original query and generate the corresponding answer by code execution, then apply a sanity check. Experimental results demonstrate that AdaR improves robustness and generalization, achieving substantial improvement in mathematical reasoning while maintaining high data efficiency. Analysis indicates that data synthesis and RLVR function in a coordinated manner to enable adaptive reasoning in LLMs. Subsequent analyses derive key design insights into the effect of critical factors and the applicability to instruct LLMs. Our project is available at https://github.com/LaiZhejian/AdaR",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "390",
        "title": "Agentic Context Engineering: Evolving Contexts for Self-Improving Language Models",
        "author": [
            "Qizheng Zhang",
            "Changran Hu",
            "Shubhangi Upasani",
            "Boyuan Ma",
            "Fenglu Hong",
            "Vamsidhar Kamanuru",
            "Jay Rainton",
            "Chen Wu",
            "Mengmeng Ji",
            "Hanchen Li",
            "Urmish Thakker",
            "James Zou",
            "Kunle Olukotun"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04618",
        "abstract": "Large language model (LLM) applications such as agents and domain-specific reasoning increasingly rely on context adaptation -- modifying inputs with instructions, strategies, or evidence, rather than weight updates. Prior approaches improve usability but often suffer from brevity bias, which drops domain insights for concise summaries, and from context collapse, where iterative rewriting erodes details over time. Building on the adaptive memory introduced by Dynamic Cheatsheet, we introduce ACE (Agentic Context Engineering), a framework that treats contexts as evolving playbooks that accumulate, refine, and organize strategies through a modular process of generation, reflection, and curation. ACE prevents collapse with structured, incremental updates that preserve detailed knowledge and scale with long-context models. Across agent and domain-specific benchmarks, ACE optimizes contexts both offline (e.g., system prompts) and online (e.g., agent memory), consistently outperforming strong baselines: +10.6% on agents and +8.6% on finance, while significantly reducing adaptation latency and rollout cost. Notably, ACE could adapt effectively without labeled supervision and instead by leveraging natural execution feedback. On the AppWorld leaderboard, ACE matches the top-ranked production-level agent on the overall average and surpasses it on the harder test-challenge split, despite using a smaller open-source model. These results show that comprehensive, evolving contexts enable scalable, efficient, and self-improving LLM systems with low overhead.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "391",
        "title": "SFANet: Spatial-Frequency Attention Network for Deepfake Detection",
        "author": [
            "Vrushank Ahire",
            "Aniruddh Muley",
            "Shivam Zample",
            "Siddharth Verma",
            "Pranav Menon",
            "Surbhi Madan",
            "Abhinav Dhall"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04630",
        "abstract": "Detecting manipulated media has now become a pressing issue with the recent rise of deepfakes. Most existing approaches fail to generalize across diverse datasets and generation techniques. We thus propose a novel ensemble framework, combining the strengths of transformer-based architectures, such as Swin Transformers and ViTs, and texture-based methods, to achieve better detection accuracy and robustness. Our method introduces innovative data-splitting, sequential training, frequency splitting, patch-based attention, and face segmentation techniques to handle dataset imbalances, enhance high-impact regions (e.g., eyes and mouth), and improve generalization. Our model achieves state-of-the-art performance when tested on the DFWild-Cup dataset, a diverse subset of eight deepfake datasets. The ensemble benefits from the complementarity of these approaches, with transformers excelling in global feature extraction and texturebased methods providing interpretability. This work demonstrates that hybrid models can effectively address the evolving challenges of deepfake detection, offering a robust solution for real-world applications.",
        "tags": [
            "Detection",
            "Segmentation",
            "Transformer"
        ]
    },
    {
        "id": "392",
        "title": "Topic-Specific Classifiers are Better Relevance Judges than Prompted LLMs",
        "author": [
            "Lukas Gienapp",
            "Martin Potthast",
            "Harrisen Scells",
            "Eugene Yang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04633",
        "abstract": "The unjudged document problem, where pooled test collections have incomplete relevance judgments for evaluating new retrieval systems, is a key obstacle to the reusability of test collections in information retrieval. While the de facto standard to deal with the problem is to treat unjudged documents as non-relevant, many alternatives have been proposed, including the use of large language models (LLMs) as a relevance judge (LLM-as-a-judge). However, this has been criticized as circular, since the same LLM can be used as a judge and as a ranker at the same time. We propose to train topic-specific relevance classifiers instead: By finetuning monoT5 with independent LoRA weight adaptation on the judgments of a single assessor for a single topic's pool, we align it to that assessor's notion of relevance for the topic. The system rankings obtained through our classifier's relevance judgments achieve a Spearmans' $\\rho$ correlation of $>0.95$ with ground truth system rankings. As little as 128 initial human judgments per topic suffice to improve the comparability of models, compared to treating unjudged documents as non-relevant, while achieving more reliability than existing LLM-as-a-judge approaches. Topic-specific relevance classifiers thus are a lightweight and straightforward way to tackle the unjudged document problem, while maintaining human judgments as the gold standard for retrieval evaluation. Code, models, and data are made openly available.",
        "tags": [
            "LLM",
            "LoRA"
        ]
    },
    {
        "id": "393",
        "title": "Social Agent: Mastering Dyadic Nonverbal Behavior Generation via Conversational LLM Agents",
        "author": [
            "Zeyi Zhang",
            "Yanju Zhou",
            "Heyuan Yao",
            "Tenglong Ao",
            "Xiaohang Zhan",
            "Libin Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04637",
        "abstract": "We present Social Agent, a novel framework for synthesizing realistic and contextually appropriate co-speech nonverbal behaviors in dyadic conversations. In this framework, we develop an agentic system driven by a Large Language Model (LLM) to direct the conversation flow and determine appropriate interactive behaviors for both participants. Additionally, we propose a novel dual-person gesture generation model based on an auto-regressive diffusion model, which synthesizes coordinated motions from speech signals. The output of the agentic system is translated into high-level guidance for the gesture generator, resulting in realistic movement at both the behavioral and motion levels. Furthermore, the agentic system periodically examines the movements of interlocutors and infers their intentions, forming a continuous feedback loop that enables dynamic and responsive interactions between the two participants. User studies and quantitative evaluations show that our model significantly improves the quality of dyadic interactions, producing natural, synchronized nonverbal behaviors.",
        "tags": [
            "Diffusion",
            "LLM"
        ]
    },
    {
        "id": "394",
        "title": "Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study",
        "author": [
            "Ayan Majumdar",
            "Feihao Chen",
            "Jinghui Li",
            "Xiaozhen Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04641",
        "abstract": "Large-scale web-scraped text corpora used to train general-purpose AI models often contain harmful demographic-targeted social biases, creating a regulatory need for data auditing and developing scalable bias-detection methods. Although prior work has investigated biases in text datasets and related detection methods, these studies remain narrow in scope. They typically focus on a single content type (e.g., hate speech), cover limited demographic axes, overlook biases affecting multiple demographics simultaneously, and analyze limited techniques. Consequently, practitioners lack a holistic understanding of the strengths and limitations of recent large language models (LLMs) for automated bias detection. In this study, we present a comprehensive evaluation framework aimed at English texts to assess the ability of LLMs in detecting demographic-targeted social biases. To align with regulatory requirements, we frame bias detection as a multi-label task using a demographic-focused taxonomy. We then conduct a systematic evaluation with models across scales and techniques, including prompting, in-context learning, and fine-tuning. Using twelve datasets spanning diverse content types and demographics, our study demonstrates the promise of fine-tuned smaller models for scalable detection. However, our analyses also expose persistent gaps across demographic axes and multi-demographic targeted biases, underscoring the need for more effective and scalable auditing frameworks.",
        "tags": [
            "Detection",
            "LLM"
        ]
    },
    {
        "id": "395",
        "title": "QuantAgents: Towards Multi-agent Financial System via Simulated Trading",
        "author": [
            "Xiangyu Li",
            "Yawen Zeng",
            "Xiaofen Xing",
            "Jin Xu",
            "Xiangmin Xu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04643",
        "abstract": "In this paper, our objective is to develop a multi-agent financial system that incorporates simulated trading, a technique extensively utilized by financial professionals. While current LLM-based agent models demonstrate competitive performance, they still exhibit significant deviations from real-world fund companies. A critical distinction lies in the agents' reliance on ``post-reflection'', particularly in response to adverse outcomes, but lack a distinctly human capability: long-term prediction of future trends. Therefore, we introduce QuantAgents, a multi-agent system integrating simulated trading, to comprehensively evaluate various investment strategies and market scenarios without assuming actual risks. Specifically, QuantAgents comprises four agents: a simulated trading analyst, a risk control analyst, a market news analyst, and a manager, who collaborate through several meetings. Moreover, our system incentivizes agents to receive feedback on two fronts: performance in real-world markets and predictive accuracy in simulated trading. Extensive experiments demonstrate that our framework excels across all metrics, yielding an overall return of nearly 300% over the three years (https://quantagents.github.io/).",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "396",
        "title": "The R(1)W(1) Communication Model for Self-Stabilizing Distributed Algorithms",
        "author": [
            "Hirotsugu Kakugawa",
            "Sayaka Kamei",
            "Masahiro Shibata",
            "Fukuhito Ooshita"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04644",
        "abstract": "Self-stabilization is a versatile methodology in the design of fault-tolerant distributed algorithms for transient faults. A self-stabilizing system automatically recovers from any kind and any finite number of transient faults. This property is specifically useful in modern distributed systems with a large number of components. In this paper, we propose a new communication and execution model named the R(1)W(1) model in which each process can read and write its own and neighbors' local variables in a single step. We propose self-stabilizing distributed algorithms in the R(1)W(1) model for the problems of maximal matching, minimal k-dominating set and maximal k-dependent set. Finally, we propose an example transformer, based on randomized distance-two local mutual exclusion, to simulate algorithms designed for the R(1)W(1) model in the synchronous message passing model with synchronized clocks.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "397",
        "title": "EduPersona: Benchmarking Subjective Ability Boundaries of Virtual Student Agents",
        "author": [
            "Buyuan Zhu",
            "Shiyu Hu",
            "Yiping Ma",
            "Yuanming Zhang",
            "Kang Hao Cheong"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04648",
        "abstract": "As large language models are increasingly integrated into education, virtual student agents are becoming vital for classroom simulation and teacher training. Yet their classroom-oriented subjective abilities remain largely unassessed, limiting understanding of model boundaries and hindering trustworthy deployment. We present EduPersona, a large-scale benchmark spanning two languages, three subjects, and ten persona types based on the Big Five theory. The dataset contains 1,308 authentic classroom dialogue rounds, corresponding to 12,814 teacher-student Q&A turns, and is further expanded through persona stylization into roughly 10 times larger scale (128k turns), providing a solid foundation for evaluation. Building on this resource, we decompose hard-to-quantify subjective performance into three progressive tasks: TASK1 basic coherence (whether behavior, emotion, expression, and voice align with classroom context), TASK2 student realism, and TASK3 long-term persona consistency, thereby establishing an evaluation framework grounded in educational theory and research value. We conduct systematic experiments on three representative LLMs, comparing their original versions with ten persona-fine-tuned variants trained on EduPersona. Results show consistent and significant average improvements across all tasks: TASK1 +33.6%, TASK2 +30.6%, and TASK3 +14.9%. These improvements highlight the dataset's effectiveness and research value, while also revealing the heterogeneous difficulty of persona modeling. In summary, EduPersona delivers the first classroom benchmark centered on subjective abilities, establishes a decoupled and verifiable research paradigm, and we will open-source both the dataset and the framework to support the broader research community in advancing trustworthy and human-like AI for education.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "398",
        "title": "ConceptSplit: Decoupled Multi-Concept Personalization of Diffusion Models via Token-wise Adaptation and Attention Disentanglement",
        "author": [
            "Habin Lim",
            "Yeongseob Won",
            "Juwon Seo",
            "Gyeong-Moon Park"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04668",
        "abstract": "In recent years, multi-concept personalization for text-to-image (T2I) diffusion models to represent several subjects in an image has gained much more attention. The main challenge of this task is \"concept mixing\", where multiple learned concepts interfere or blend undesirably in the output image. To address this issue, in this paper, we present ConceptSplit, a novel framework to split the individual concepts through training and inference. Our framework comprises two key components. First, we introduce Token-wise Value Adaptation (ToVA), a merging-free training method that focuses exclusively on adapting the value projection in cross-attention. Based on our empirical analysis, we found that modifying the key projection, a common approach in existing methods, can disrupt the attention mechanism and lead to concept mixing. Second, we propose Latent Optimization for Disentangled Attention (LODA), which alleviates attention entanglement during inference by optimizing the input latent. Through extensive qualitative and quantitative experiments, we demonstrate that ConceptSplit achieves robust multi-concept personalization, mitigating unintended concept interference. Code is available at https://github.com/KU-VGI/ConceptSplit",
        "tags": [
            "Diffusion",
            "Text-to-Image"
        ]
    },
    {
        "id": "399",
        "title": "Multi-Agent Tool-Integrated Policy Optimization",
        "author": [
            "Zhanfeng Mo",
            "Xingxuan Li",
            "Yuntao Chen",
            "Lidong Bing"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04678",
        "abstract": "Large language models (LLMs) increasingly rely on multi-turn tool-integrated planning for knowledge-intensive and complex reasoning tasks. Existing implementations typically rely on a single agent, but they suffer from limited context length and noisy tool responses. A natural solution is to adopt a multi-agent framework with planner- and worker-agents to manage context. However, no existing methods support effective reinforcement learning post-training of tool-integrated multi-agent frameworks. To address this gap, we propose Multi-Agent Tool-Integrated Policy Optimization (MATPO), which enables distinct roles (planner and worker) to be trained within a single LLM instance using role-specific prompts via reinforcement learning. MATPO is derived from a principled credit assignment mechanism across planner and worker rollouts. This design eliminates the need to deploy multiple LLMs, which would be memory-intensive, while preserving the benefits of specialization. Experiments on GAIA-text, WebWalkerQA, and FRAMES show that MATPO consistently outperforms single-agent baselines by an average of 18.38% relative improvement in performance and exhibits greater robustness to noisy tool outputs. Our findings highlight the effectiveness of unifying multiple agent roles within a single LLM and provide practical insights for stable and efficient multi-agent RL training.",
        "tags": [
            "LLM",
            "RL"
        ]
    },
    {
        "id": "400",
        "title": "TiTok: Transfer Token-level Knowledge via Contrastive Excess to Transplant LoRA",
        "author": [
            "Chanjoo Jung",
            "Jaehyung Kim"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04682",
        "abstract": "Large Language Models (LLMs) are widely applied in real world scenarios, but fine-tuning them comes with significant computational and storage costs. Parameter-Efficient Fine-Tuning (PEFT) methods such as LoRA mitigate these costs, but the adapted parameters are dependent on the base model and cannot be transferred across different backbones. One way to address this issue is through knowledge distillation, but its effectiveness inherently depends on training data. Recent work such as TransLoRA avoids this by generating synthetic data, but this adds complexity because it requires training an additional discriminator model. In this paper, we propose TiTok, a new framework that enables effective LoRA Transplantation through Token-level knowledge transfer. Specifically, TiTok captures task-relevant information through a contrastive excess between a source model with and without LoRA. This excess highlights informative tokens and enables selective filtering of synthetic data, all without additional models or overhead. Through experiments on three benchmarks across multiple transfer settings, our experiments show that the proposed method is consistently effective, achieving average performance gains of +4~8% compared to baselines overall.",
        "tags": [
            "LLM",
            "LoRA"
        ]
    },
    {
        "id": "401",
        "title": "Bio-Inspired Robotic Houbara: From Development to Field Deployment for Behavioral Studies",
        "author": [
            "Lyes Saad Saoud",
            "Irfan Hussain"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04692",
        "abstract": "Biomimetic intelligence and robotics are transforming field ecology by enabling lifelike robotic surrogates that interact naturally with animals under real world conditions. Studying avian behavior in the wild remains challenging due to the need for highly realistic morphology, durable outdoor operation, and intelligent perception that can adapt to uncontrolled environments. We present a next generation bio inspired robotic platform that replicates the morphology and visual appearance of the female Houbara bustard to support controlled ethological studies and conservation oriented field research. The system introduces a fully digitally replicable fabrication workflow that combines high resolution structured light 3D scanning, parametric CAD modelling, articulated 3D printing, and photorealistic UV textured vinyl finishing to achieve anatomically accurate and durable robotic surrogates. A six wheeled rocker bogie chassis ensures stable mobility on sand and irregular terrain, while an embedded NVIDIA Jetson module enables real time RGB and thermal perception, lightweight YOLO based detection, and an autonomous visual servoing loop that aligns the robot's head toward detected targets without human intervention. A lightweight thermal visible fusion module enhances perception in low light conditions. Field trials in desert aviaries demonstrated reliable real time operation at 15 to 22 FPS with latency under 100 ms and confirmed that the platform elicits natural recognition and interactive responses from live Houbara bustards under harsh outdoor conditions. This integrated framework advances biomimetic field robotics by uniting reproducible digital fabrication, embodied visual intelligence, and ecological validation, providing a transferable blueprint for animal robot interaction research, conservation robotics, and public engagement.",
        "tags": [
            "3D",
            "Detection",
            "Robotics"
        ]
    },
    {
        "id": "402",
        "title": "Multilingual Routing in Mixture-of-Experts",
        "author": [
            "Lucas Bandarkar",
            "Chenyuan Yang",
            "Mohsen Fayyaz",
            "Junlin Hu",
            "Nanyun Peng"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04694",
        "abstract": "Mixture-of-Experts (MoE) architectures have become the key to scaling modern LLMs, yet little is understood about how their sparse routing dynamics respond to multilingual data. In this work, we analyze expert routing patterns using parallel multilingual datasets and present highly interpretable layer-wise phenomena. We find that MoE models route tokens in language-specific ways in the early and late decoder layers but exhibit significant cross-lingual routing alignment in middle layers, mirroring parameter-sharing trends observed in dense LLMs. In particular, we reveal a clear, strong correlation between a model's performance in a given language and how similarly its tokens are routed to English in these layers. Extending beyond correlation, we explore inference-time interventions that induce higher cross-lingual routing alignment. We introduce a method that steers the router by promoting middle-layer task experts frequently activated in English, and it successfully increases multilingual performance. These 1-2% gains are remarkably consistent across two evaluation tasks, three models, and 15+ languages, especially given that these simple interventions override routers of extensively trained, state-of-the-art LLMs. In comparison, interventions outside of the middle layers or targeting multilingual-specialized experts only yield performance degradation. Altogether, we present numerous findings that explain how MoEs process non-English text and demonstrate that generalization is limited by the model's ability to leverage language-universal experts in all languages.",
        "tags": [
            "LLM",
            "MoE"
        ]
    },
    {
        "id": "403",
        "title": "Beyond Outcome Reward: Decoupling Search and Answering Improves LLM Agents",
        "author": [
            "Yiding Wang",
            "Zhepei Wei",
            "Xinyu Zhu",
            "Yu Meng"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04695",
        "abstract": "Enabling large language models (LLMs) to utilize search tools offers a promising path to overcoming fundamental limitations such as knowledge cutoffs and hallucinations. Recent work has explored reinforcement learning (RL) for training search-augmented agents that interleave reasoning and retrieval before answering. These approaches usually rely on outcome-based rewards (e.g., exact match), implicitly assuming that optimizing for final answers will also yield effective intermediate search behaviors. Our analysis challenges this assumption: we uncover multiple systematic deficiencies in search that arise under outcome-only training and ultimately degrade final answer quality, including failure to invoke tools, invalid queries, and redundant searches. To address these shortcomings, we introduce DeSA (Decoupling Search-and-Answering), a simple two-stage training framework that explicitly separates search optimization from answer generation. In Stage 1, agents are trained to improve search effectiveness with retrieval recall-based rewards. In Stage 2, outcome rewards are employed to optimize final answer generation. Across seven QA benchmarks, DeSA-trained agents consistently improve search behaviors, delivering substantially higher search recall and answer accuracy than outcome-only baselines. Notably, DeSA outperforms single-stage training approaches that simultaneously optimize recall and outcome rewards, underscoring the necessity of explicitly decoupling the two objectives.",
        "tags": [
            "LLM",
            "RL"
        ]
    },
    {
        "id": "404",
        "title": "Building Gradient by Gradient: Decentralised Energy Functions for Bimanual Robot Assembly",
        "author": [
            "Alexander L. Mitchell",
            "Joe Watson",
            "Ingmar Posner"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04696",
        "abstract": "There are many challenges in bimanual assembly, including high-level sequencing, multi-robot coordination, and low-level, contact-rich operations such as component mating. Task and motion planning (TAMP) methods, while effective in this domain, may be prohibitively slow to converge when adapting to disturbances that require new task sequencing and optimisation. These events are common during tight-tolerance assembly, where difficult-to-model dynamics such as friction or deformation require rapid replanning and reattempts. Moreover, defining explicit task sequences for assembly can be cumbersome, limiting flexibility when task replanning is required. To simplify this planning, we introduce a decentralised gradient-based framework that uses a piecewise continuous energy function through the automatic composition of adaptive potential functions. This approach generates sub-goals using only myopic optimisation, rather than long-horizon planning. It demonstrates effectiveness at solving long-horizon tasks due to the structure and adaptivity of the energy function. We show that our approach scales to physical bimanual assembly tasks for constructing tight-tolerance assemblies. In these experiments, we discover that our gradient-based rapid replanning framework generates automatic retries, coordinated motions and autonomous handovers in an emergent fashion.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "405",
        "title": "ID-Consistent, Precise Expression Generation with Blendshape-Guided Diffusion",
        "author": [
            "Foivos Paraperas Papantoniou",
            "Stefanos Zafeiriou"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04706",
        "abstract": "Human-centric generative models designed for AI-driven storytelling must bring together two core capabilities: identity consistency and precise control over human performance. While recent diffusion-based approaches have made significant progress in maintaining facial identity, achieving fine-grained expression control without compromising identity remains challenging. In this work, we present a diffusion-based framework that faithfully reimagines any subject under any particular facial expression. Building on an ID-consistent face foundation model, we adopt a compositional design featuring an expression cross-attention module guided by FLAME blendshape parameters for explicit control. Trained on a diverse mixture of image and video data rich in expressive variation, our adapter generalizes beyond basic emotions to subtle micro-expressions and expressive transitions, overlooked by prior works. In addition, a pluggable Reference Adapter enables expression editing in real images by transferring the appearance from a reference frame during synthesis. Extensive quantitative and qualitative evaluations show that our model outperforms existing methods in tailored and identity-consistent expression generation. Code and models can be found at https://github.com/foivospar/Arc2Face.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "406",
        "title": "ReactDiff: Fundamental Multiple Appropriate Facial Reaction Diffusion Model",
        "author": [
            "Luo Cheng",
            "Song Siyang",
            "Yan Siyuan",
            "Yu Zhen",
            "Ge Zongyuan"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04712",
        "abstract": "The automatic generation of diverse and human-like facial reactions in dyadic dialogue remains a critical challenge for human-computer interaction systems. Existing methods fail to model the stochasticity and dynamics inherent in real human reactions. To address this, we propose ReactDiff, a novel temporal diffusion framework for generating diverse facial reactions that are appropriate for responding to any given dialogue context. Our key insight is that plausible human reactions demonstrate smoothness, and coherence over time, and conform to constraints imposed by human facial anatomy. To achieve this, ReactDiff incorporates two vital priors (spatio-temporal facial kinematics) into the diffusion process: i) temporal facial behavioral kinematics and ii) facial action unit dependencies. These two constraints guide the model toward realistic human reaction manifolds, avoiding visually unrealistic jitters, unstable transitions, unnatural expressions, and other artifacts. Extensive experiments on the REACT2024 dataset demonstrate that our approach not only achieves state-of-the-art reaction quality but also excels in diversity and reaction appropriateness.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "407",
        "title": "Object-Centric Representation Learning for Enhanced 3D Scene Graph Prediction",
        "author": [
            "KunHo Heo",
            "GiHyun Kim",
            "SuYeon Kim",
            "MyeongAh Cho"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04714",
        "abstract": "3D Semantic Scene Graph Prediction aims to detect objects and their semantic relationships in 3D scenes, and has emerged as a crucial technology for robotics and AR/VR applications. While previous research has addressed dataset limitations and explored various approaches including Open-Vocabulary settings, they frequently fail to optimize the representational capacity of object and relationship features, showing excessive reliance on Graph Neural Networks despite insufficient discriminative capability. In this work, we demonstrate through extensive analysis that the quality of object features plays a critical role in determining overall scene graph accuracy. To address this challenge, we design a highly discriminative object feature encoder and employ a contrastive pretraining strategy that decouples object representation learning from the scene graph prediction. This design not only enhances object classification accuracy but also yields direct improvements in relationship prediction. Notably, when plugging in our pretrained encoder into existing frameworks, we observe substantial performance improvements across all evaluation metrics. Additionally, whereas existing approaches have not fully exploited the integration of relationship information, we effectively combine both geometric and semantic features to achieve superior relationship prediction. Comprehensive experiments on the 3DSSG dataset demonstrate that our approach significantly outperforms previous state-of-the-art methods. Our code is publicly available at https://github.com/VisualScienceLab-KHU/OCRL-3DSSG-Codes.",
        "tags": [
            "3D",
            "Robotics"
        ]
    },
    {
        "id": "408",
        "title": "Curved Boolean Logic: A Contextual Generalization of Propositional Logic with Algorithmic Consequences",
        "author": [
            "Maximilian R. P. von Liechtenstein"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04716",
        "abstract": "Curved Boolean Logic (CBL) generalizes propositional logic by allowing local truth assignments that do not extend to a single global valuation, analogous to curvature in geometry. We give equivalent sheaf and exclusivity-graph semantics and a context-aware proof calculus that is conservative in the flat limit. We formalize CBL-SAT and basic complexity (NP-complete in general) and present operational operators (CBL-AC and CBL-CONS) that prune contradictions earlier on classical hardware. We model noise with iid, AR(1)-correlated, and adversarial bounded perturbations and provide permutation-based significance with Benjamini-Hochberg FDR control. A Colab-ready notebook (ancillary files) regenerates all figures and statistics. We position CBL relative to KCBS, CSW, and sheaf frameworks and outline links to SAT/CSP and robustness/adapter stability in large language models.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "409",
        "title": "JSON Whisperer: Efficient JSON Editing with LLMs",
        "author": [
            "Sarel Duanis",
            "Asnat Greenstein-Messica",
            "Eliya Habba"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04717",
        "abstract": "Large language models (LLMs) can modify JSON documents through natural language commands, but current approaches regenerate entire structures for each edit, resulting in computational inefficiency. We present JSON Whisperer, a framework that enables LLMs to generate RFC 6902 diff patches-expressing only the necessary modifications-rather than complete documents. We identify two key challenges in patch-based editing: (1) LLMs often miss related updates when generating isolated patches, and (2) array manipulations require tracking index shifts across operations, which LLMs handle poorly. To address these issues, we introduce EASE (Explicitly Addressed Sequence Encoding), which transforms arrays into dictionaries with stable keys, eliminating index arithmetic complexities. Our evaluation shows that patch generation with EASE reduces token usage by 31% while maintaining edit quality within 5% of full regeneration with particular gains for complex instructions and list manipulations. The dataset is available at: https://github.com/emnlp2025/JSON-Whisperer/",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "410",
        "title": "BrokenMath: A Benchmark for Sycophancy in Theorem Proving with LLMs",
        "author": [
            "Ivo Petrov",
            "Jasper Dekoninck",
            "Martin Vechev"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04721",
        "abstract": "Large language models (LLMs) have recently shown strong performance on mathematical benchmarks. At the same time, they are prone to hallucination and sycophancy, often providing convincing but flawed proofs for incorrect mathematical statements provided by users. This significantly limits the applicability of LLMs in theorem proving, as verification of these flawed proofs must be done manually by expert mathematicians. However, existing benchmarks that measure sycophancy in mathematics are limited: they focus solely on final-answer problems, rely on very simple and often contaminated datasets, and construct benchmark samples using synthetic modifications that create ill-posed questions rather than well-posed questions that are demonstrably false. To address these issues, we introduce BrokenMath, the first benchmark for evaluating sycophantic behavior in LLMs within the context of natural language theorem proving. BrokenMath is built from advanced 2025 competition problems, which are perturbed with an LLM to produce false statements and subsequently refined through expert review. Using an LLM-as-a-judge framework, we evaluate state-of-the-art LLMs and agentic systems and find that sycophancy is widespread, with the best model, GPT-5, producing sycophantic answers 29% of the time. We further investigate several mitigation strategies, including test-time interventions and supervised fine-tuning on curated sycophantic examples. These approaches substantially reduce, but do not eliminate, sycophantic behavior.",
        "tags": [
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "411",
        "title": "Performance-guided Task-specific Optimization for Multirotor Design",
        "author": [
            "Etor Arza",
            "Welf Rehberg",
            "Philipp Weiss",
            "Mihir Kulkarni",
            "Kostas Alexis"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04724",
        "abstract": "This paper introduces a methodology for task-specific design optimization of multirotor Micro Aerial Vehicles. By leveraging reinforcement learning, Bayesian optimization, and covariance matrix adaptation evolution strategy, we optimize aerial robot designs guided exclusively by their closed-loop performance in a considered task. Our approach systematically explores the design space of motor pose configurations while ensuring manufacturability constraints and minimal aerodynamic interference. Results demonstrate that optimized designs achieve superior performance compared to conventional multirotor configurations in agile waypoint navigation tasks, including against fully actuated designs from the literature. We build and test one of the optimized designs in the real world to validate the sim2real transferability of our approach.",
        "tags": [
            "RL",
            "Robotics"
        ]
    },
    {
        "id": "412",
        "title": "Speak, Edit, Repeat: High-Fidelity Voice Editing and Zero-Shot TTS with Cross-Attentive Mamba",
        "author": [
            "Baher Mohammad",
            "Magauiya Zhussip",
            "Stamatios Lefkimmiatis"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04738",
        "abstract": "We introduce MAVE (Mamba with Cross-Attention for Voice Editing and Synthesis), a novel autoregressive architecture for text-conditioned voice editing and high-fidelity text-to-speech (TTS) synthesis, built on a cross-attentive Mamba backbone. MAVE achieves state-of-the-art performance in speech editing and very competitive results in zero-shot TTS, while not being explicitly trained on the latter task, outperforming leading autoregressive and diffusion models on diverse, real-world audio. By integrating Mamba for efficient audio sequence modeling with cross-attention for precise text-acoustic alignment, MAVE enables context-aware voice editing with exceptional naturalness and speaker consistency. In pairwise human evaluations on a random 40-sample subset of the RealEdit benchmark (400 judgments), 57.2% of listeners rated MAVE - edited speech as perceptually equal to the original, while 24.8% prefered the original and 18.0% MAVE - demonstrating that in the majority of cases edits are indistinguishable from the source. MAVE compares favorably with VoiceCraft and FluentSpeech both on pairwise comparisons and standalone mean opinion score (MOS) evaluations. For zero-shot TTS, MAVE exceeds VoiceCraft in both speaker similarity and naturalness, without requiring multiple inference runs or post-processing. Remarkably, these quality gains come with a significantly lower memory cost and approximately the same latency: MAVE requires ~6x less memory than VoiceCraft during inference on utterances from the RealEdit database (mean duration: 6.21s, A100, FP16, batch size 1). Our results demonstrate that MAVE establishes a new standard for flexible, high-fidelity voice editing and synthesis through the synergistic integration of structured state-space modeling and cross-modal attention.",
        "tags": [
            "Diffusion",
            "Mamba"
        ]
    },
    {
        "id": "413",
        "title": "LLM-Based Information Extraction to Support Scientific Literature Research and Publication Workflows",
        "author": [
            "Samy Ateia",
            "Udo Kruschwitz",
            "Melanie Scholz",
            "Agnes Koschmider",
            "Moayad Almohaishi"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04749",
        "abstract": "The increasing volume of scholarly publications requires advanced tools for efficient knowledge discovery and management. This paper introduces ongoing work on a system using Large Language Models (LLMs) for the semantic extraction of key concepts from scientific documents. Our research, conducted within the German National Research Data Infrastructure for and with Computer Science (NFDIxCS) project, seeks to support FAIR (Findable, Accessible, Interoperable, and Reusable) principles in scientific publishing. We outline our explorative work, which uses in-context learning with various LLMs to extract concepts from papers, initially focusing on the Business Process Management (BPM) domain. A key advantage of this approach is its potential for rapid domain adaptation, often requiring few or even zero examples to define extraction targets for new scientific fields. We conducted technical evaluations to compare the performance of commercial and open-source LLMs and created an online demo application to collect feedback from an initial user-study. Additionally, we gathered insights from the computer science research community through user stories collected during a dedicated workshop, actively guiding the ongoing development of our future services. These services aim to support structured literature reviews, concept-based information retrieval, and integration of extracted knowledge into existing knowledge graphs.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "414",
        "title": "A Low-Resource Speech-Driven NLP Pipeline for Sinhala Dyslexia Assistance",
        "author": [
            "Peshala Perera",
            "Deshan Sumanathilaka"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04750",
        "abstract": "Dyslexia in adults remains an under-researched and under-served area, particularly in non-English-speaking contexts, despite its significant impact on personal and professional lives. This work addresses that gap by focusing on Sinhala, a low-resource language with limited tools for linguistic accessibility. We present an assistive system explicitly designed for Sinhala-speaking adults with dyslexia. The system integrates Whisper for speech-to-text conversion, SinBERT, an open-sourced fine-tuned BERT model trained for Sinhala to identify common dyslexic errors, and a combined mT5 and Mistral-based model to generate corrected text. Finally, the output is converted back to speech using gTTS, creating a complete multimodal feedback loop. Despite the challenges posed by limited Sinhala-language datasets, the system achieves 0.66 transcription accuracy and 0.7 correction accuracy with 0.65 overall system accuracy. These results demonstrate both the feasibility and effectiveness of the approach. Ultimately, this work highlights the importance of inclusive Natural Language Processing (NLP) technologies in underrepresented languages and showcases a practical",
        "tags": [
            "BERT"
        ]
    },
    {
        "id": "415",
        "title": "Beyond Appearance: Transformer-based Person Identification from Conversational Dynamics",
        "author": [
            "Masoumeh Chapariniya",
            "Teodora Vukovic",
            "Sarah Ebling",
            "Volker Dellwo"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04753",
        "abstract": "This paper investigates the performance of transformer-based architectures for person identification in natural, face-to-face conversation scenario. We implement and evaluate a two-stream framework that separately models spatial configurations and temporal motion patterns of 133 COCO WholeBody keypoints, extracted from a subset of the CANDOR conversational corpus. Our experiments compare pre-trained and from-scratch training, investigate the use of velocity features, and introduce a multi-scale temporal transformer for hierarchical motion modeling. Results demonstrate that domain-specific training significantly outperforms transfer learning, and that spatial configurations carry more discriminative information than temporal dynamics. The spatial transformer achieves 95.74% accuracy, while the multi-scale temporal transformer achieves 93.90%. Feature-level fusion pushes performance to 98.03%, confirming that postural and dynamic information are complementary. These findings highlight the potential of transformer architectures for person identification in natural interactions and provide insights for future multimodal and cross-cultural studies.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "416",
        "title": "ModernBERT + ColBERT: Enhancing biomedical RAG through an advanced re-ranking retriever",
        "author": [
            "Eduardo MartÃ­nez Rivera",
            "Filippo Menolascina"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04757",
        "abstract": "Retrieval-Augmented Generation (RAG) is a powerful technique for enriching Large Language Models (LLMs) with external knowledge, allowing for factually grounded responses, a critical requirement in high-stakes domains such as healthcare. However, the efficacy of RAG systems is fundamentally restricted by the performance of their retrieval module, since irrelevant or semantically misaligned documents directly compromise the accuracy of the final generated response. General-purpose dense retrievers can struggle with the nuanced language of specialised domains, while the high accuracy of in-domain models is often achieved at prohibitive computational costs. In this work, we aim to address this trade-off by developing and evaluating a two-stage retrieval architecture that combines a lightweight ModernBERT bidirectional encoder for efficient initial candidate retrieval with a ColBERTv2 late-interaction model for fine-grained re-ranking. We conduct comprehensive evaluations of our retriever module performance and RAG system performance in the biomedical context, fine-tuning the IR module using 10k question-passage pairs from PubMedQA. Our analysis of the retriever module confirmed the positive impact of the ColBERT re-ranker, which improved Recall@3 by up to 4.2 percentage points compared to its retrieve-only counterpart. When integrated into the biomedical RAG, our IR module leads to a state-of-the-art average accuracy of 0.4448 on the five tasks of the MIRAGE question-answering benchmark, outperforming strong baselines such as MedCPT (0.4436). Our ablation studies reveal that this performance is critically dependent on a joint fine-tuning process that aligns the retriever and re-ranker; otherwise, the re-ranker might degrade the performance.",
        "tags": [
            "LLM",
            "RAG"
        ]
    },
    {
        "id": "417",
        "title": "Progressive Gaussian Transformer with Anisotropy-aware Sampling for Open Vocabulary Occupancy Prediction",
        "author": [
            "Chi Yan",
            "Dan Xu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04759",
        "abstract": "The 3D occupancy prediction task has witnessed remarkable progress in recent years, playing a crucial role in vision-based autonomous driving systems. While traditional methods are limited to fixed semantic categories, recent approaches have moved towards predicting text-aligned features to enable open-vocabulary text queries in real-world scenes. However, there exists a trade-off in text-aligned scene modeling: sparse Gaussian representation struggles to capture small objects in the scene, while dense representation incurs significant computational overhead. To address these limitations, we present PG-Occ, an innovative Progressive Gaussian Transformer Framework that enables open-vocabulary 3D occupancy prediction. Our framework employs progressive online densification, a feed-forward strategy that gradually enhances the 3D Gaussian representation to capture fine-grained scene details. By iteratively enhancing the representation, the framework achieves increasingly precise and detailed scene understanding. Another key contribution is the introduction of an anisotropy-aware sampling strategy with spatio-temporal fusion, which adaptively assigns receptive fields to Gaussians at different scales and stages, enabling more effective feature aggregation and richer scene information capture. Through extensive evaluations, we demonstrate that PG-Occ achieves state-of-the-art performance with a relative 14.3% mIoU improvement over the previous best performing method. Code and pretrained models will be released upon publication on our project page: https://yanchi-3dv.github.io/PG-Occ",
        "tags": [
            "3D",
            "Transformer"
        ]
    },
    {
        "id": "418",
        "title": "Are BabyLMs Deaf to Gricean Maxims? A Pragmatic Evaluation of Sample-efficient Language Models",
        "author": [
            "Raha Askari",
            "Sina ZarrieÃ",
            "Ãzge Alacam",
            "Judith Sieker"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04764",
        "abstract": "Implicit meanings are integral to human communication, making it essential for language models to be capable of identifying and interpreting them. Grice (1975) proposed a set of conversational maxims that guide cooperative dialogue, noting that speakers may deliberately violate these principles to express meanings beyond literal words, and that listeners, in turn, recognize such violations to draw pragmatic inferences.\nBuilding on Surian et al. (1996)'s study of children's sensitivity to violations of Gricean maxims, we introduce a novel benchmark to test whether language models pretrained on less than 10M and less than 100M tokens can distinguish maxim-adhering from maxim-violating utterances. We compare these BabyLMs across five maxims and situate their performance relative to children and a Large Language Model (LLM) pretrained on 3T tokens.\nWe find that overall, models trained on less than 100M tokens outperform those trained on less than 10M, yet fall short of child-level and LLM competence. Our results suggest that modest data increases improve some aspects of pragmatic behavior, leading to finer-grained differentiation between pragmatic dimensions.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "419",
        "title": "LMM-Incentive: Large Multimodal Model-based Incentive Design for User-Generated Content in Web 3.0",
        "author": [
            "Jinbo Wen",
            "Jiawen Kang",
            "Linfeng Zhang",
            "Xiaoying Tang",
            "Jianhang Tang",
            "Yang Zhang",
            "Zhaohui Yang",
            "Dusit Niyato"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04765",
        "abstract": "Web 3.0 represents the next generation of the Internet, which is widely recognized as a decentralized ecosystem that focuses on value expression and data ownership. By leveraging blockchain and artificial intelligence technologies, Web 3.0 offers unprecedented opportunities for users to create, own, and monetize their content, thereby enabling User-Generated Content (UGC) to an entirely new level. However, some self-interested users may exploit the limitations of content curation mechanisms and generate low-quality content with less effort, obtaining platform rewards under information asymmetry. Such behavior can undermine Web 3.0 performance. To this end, we propose \\textit{LMM-Incentive}, a novel Large Multimodal Model (LMM)-based incentive mechanism for UGC in Web 3.0. Specifically, we propose an LMM-based contract-theoretic model to motivate users to generate high-quality UGC, thereby mitigating the adverse selection problem from information asymmetry. To alleviate potential moral hazards after contract selection, we leverage LMM agents to evaluate UGC quality, which is the primary component of the contract, utilizing prompt engineering techniques to improve the evaluation performance of LMM agents. Recognizing that traditional contract design methods cannot effectively adapt to the dynamic environment of Web 3.0, we develop an improved Mixture of Experts (MoE)-based Proximal Policy Optimization (PPO) algorithm for optimal contract design. Simulation results demonstrate the superiority of the proposed MoE-based PPO algorithm over representative benchmarks in the context of contract design. Finally, we deploy the designed contract within an Ethereum smart contract framework, further validating the effectiveness of the proposed scheme.",
        "tags": [
            "MoE",
            "PPO"
        ]
    },
    {
        "id": "420",
        "title": "ParallelBench: Understanding the Trade-offs of Parallel Decoding in Diffusion LLMs",
        "author": [
            "Wonjun Kang",
            "Kevin Galim",
            "Seunghyuk Oh",
            "Minjae Lee",
            "Yuchen Zeng",
            "Shuibai Zhang",
            "Coleman Hooper",
            "Yuezhou Hu",
            "Hyung Il Koo",
            "Nam Ik Cho",
            "Kangwook Lee"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04767",
        "abstract": "While most autoregressive LLMs are constrained to one-by-one decoding, diffusion LLMs (dLLMs) have attracted growing interest for their potential to dramatically accelerate inference through parallel decoding. Despite this promise, the conditional independence assumption in dLLMs causes parallel decoding to ignore token dependencies, inevitably degrading generation quality when these dependencies are strong. However, existing works largely overlook these inherent challenges, and evaluations on standard benchmarks (e.g., math and coding) are not sufficient to capture the quality degradation caused by parallel decoding. To address this gap, we first provide an information-theoretic analysis of parallel decoding. We then conduct case studies on analytically tractable synthetic list operations from both data distribution and decoding strategy perspectives, offering quantitative insights that highlight the fundamental limitations of parallel decoding. Building on these insights, we propose ParallelBench, the first benchmark specifically designed for dLLMs, featuring realistic tasks that are trivial for humans and autoregressive LLMs yet exceptionally challenging for dLLMs under parallel decoding. Using ParallelBench, we systematically analyze both dLLMs and autoregressive LLMs, revealing that: (i) dLLMs under parallel decoding can suffer dramatic quality degradation in real-world scenarios, and (ii) current parallel decoding strategies struggle to adapt their degree of parallelism based on task difficulty, thus failing to achieve meaningful speedup without compromising quality. Our findings underscore the pressing need for innovative decoding methods that can overcome the current speed-quality trade-off. We release our benchmark to help accelerate the development of truly efficient dLLMs.",
        "tags": [
            "Diffusion",
            "LLM"
        ]
    },
    {
        "id": "421",
        "title": "When Do Credal Sets Stabilize? Fixed-Point Theorems for Credal Set Updates",
        "author": [
            "Michele Caprio",
            "Siu Lun Chau",
            "Krikamol Muandet"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04769",
        "abstract": "Many machine learning algorithms rely on iterative updates of uncertainty representations, ranging from variational inference and expectation-maximization, to reinforcement learning, continual learning, and multi-agent learning. In the presence of imprecision and ambiguity, credal sets -- closed, convex sets of probability distributions -- have emerged as a popular framework for representing imprecise probabilistic beliefs. Under such imprecision, many learning problems in imprecise probabilistic machine learning (IPML) may be viewed as processes involving successive applications of update rules on credal sets. This naturally raises the question of whether this iterative process converges to stable fixed points -- or, more generally, under what conditions on the updating mechanism such fixed points exist, and whether they can be attained. We provide the first analysis of this problem and illustrate our findings using Credal Bayesian Deep Learning as a concrete example. Our work demonstrates that incorporating imprecision into the learning process not only enriches the representation of uncertainty, but also reveals structural conditions under which stability emerges, thereby offering new insights into the dynamics of iterative learning under imprecision.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "422",
        "title": "Distribution Preference Optimization: A Fine-grained Perspective for LLM Unlearning",
        "author": [
            "Kai Qin",
            "Jiaqi Wu",
            "Jianxiang He",
            "Haoyuan Sun",
            "Yifei Zhao",
            "Bin Liang",
            "Yongzhe Chang",
            "Tiantian Zhang",
            "Houde Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04773",
        "abstract": "As Large Language Models (LLMs) demonstrate remarkable capabilities learned from vast corpora, concerns regarding data privacy and safety are receiving increasing attention. LLM unlearning, which aims to remove the influence of specific data while preserving overall model utility, is becoming an important research area. One of the mainstream unlearning classes is optimization-based methods, which achieve forgetting directly through fine-tuning, exemplified by Negative Preference Optimization (NPO). However, NPO's effectiveness is limited by its inherent lack of explicit positive preference signals. Attempts to introduce such signals by constructing preferred responses often necessitate domain-specific knowledge or well-designed prompts, fundamentally restricting their generalizability. In this paper, we shift the focus to the distribution-level, directly targeting the next-token probability distribution instead of entire responses, and derive a novel unlearning algorithm termed \\textbf{Di}stribution \\textbf{P}reference \\textbf{O}ptimization (DiPO). We show that the requisite preference distribution pairs for DiPO, which are distributions over the model's output tokens, can be constructed by selectively amplifying or suppressing the model's high-confidence output logits, thereby effectively overcoming NPO's limitations. We theoretically prove the consistency of DiPO's loss function with the desired unlearning direction. Extensive experiments demonstrate that DiPO achieves a strong trade-off between model utility and forget quality. Notably, DiPO attains the highest forget quality on the TOFU benchmark, and maintains leading scalability and sustainability in utility preservation on the MUSE benchmark.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "423",
        "title": "Online automatic code generation for robot swarms: LLMs and self-organizing hierarchy",
        "author": [
            "Weixu Zhu",
            "Marco Dorigo",
            "Mary Katherine Heinrich"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04774",
        "abstract": "Our recently introduced self-organizing nervous system (SoNS) provides robot swarms with 1) ease of behavior design and 2) global estimation of the swarm configuration and its collective environment, facilitating the implementation of online automatic code generation for robot swarms. In a demonstration with 6 real robots and simulation trials with >30 robots, we show that when a SoNS-enhanced robot swarm gets stuck, it can automatically solicit and run code generated by an external LLM on the fly, completing its mission with an 85% success rate.",
        "tags": [
            "LLM",
            "Robotics"
        ]
    },
    {
        "id": "424",
        "title": "Hands-Free Heritage: Automated 3D Scanning for Cultural Heritage Digitization",
        "author": [
            "Javed Ahmad",
            "Federico DassiÃ¨",
            "Selene Frascella",
            "Gabriele Marchello",
            "Ferdinando Cannella",
            "Arianna Traviglia"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04781",
        "abstract": "High-fidelity 3D scanning is essential for preserving cultural heritage artefacts, supporting documentation, analysis, and long-term conservation. However, conventional methods typically require specialized expertise and manual intervention to maintain optimal scanning conditions and coverage. We present an automated two-robot scanning system that eliminates the need for handheld or semi-automatic workflows by combining coordinated robotic manipulation with high-resolution 3D scanning. Our system parameterizes the scanning space into distinct regions, enabling coordinated motion planning between a scanner-equipped robot and a tray-handling robot. Optimized trajectory planning and waypoint distribution ensure comprehensive surface coverage, minimize occlusions, and balance reconstruction accuracy with system efficiency. Experimental results show that our approach achieves significantly lower Chamfer Distance and higher F-score compared to baseline methods, offering superior geometric accuracy, improved digitization efficiency, and reduced reliance on expert operators.",
        "tags": [
            "3D",
            "Robotics"
        ]
    },
    {
        "id": "425",
        "title": "Learning on the Job: Test-Time Curricula for Targeted Reinforcement Learning",
        "author": [
            "Jonas HÃ¼botter",
            "Leander Diaz-Bone",
            "Ido Hakimi",
            "Andreas Krause",
            "Moritz Hardt"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04786",
        "abstract": "Humans are good at learning on the job: We learn how to solve the tasks we face as we go along. Can a model do the same? We propose an agent that assembles a task-specific curriculum, called test-time curriculum (TTC-RL), and applies reinforcement learning to continue training the model for its target task. The test-time curriculum avoids time-consuming human curation of datasets by automatically selecting the most task-relevant data from a large pool of available training data. Our experiments demonstrate that reinforcement learning on a test-time curriculum consistently improves the model on its target tasks, across a variety of evaluations and models. Notably, on challenging math and coding benchmarks, TTC-RL improves the pass@1 of Qwen3-8B by approximately 1.8x on AIME25 and 2.1x on CodeElo. Moreover, we find that TTC-RL significantly raises the performance ceiling compared to the initial model, increasing pass@8 on AIME25 from 40% to 62% and on CodeElo from 28% to 43%. Our findings show the potential of test-time curricula in extending the test-time scaling paradigm to continual training on thousands of task-relevant experiences during test-time.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "426",
        "title": "Trade in Minutes! Rationality-Driven Agentic System for Quantitative Financial Trading",
        "author": [
            "Zifan Song",
            "Kaitao Song",
            "Guosheng Hu",
            "Ding Qi",
            "Junyao Gao",
            "Xiaohua Wang",
            "Dongsheng Li",
            "Cairong Zhao"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04787",
        "abstract": "Recent advancements in large language models (LLMs) and agentic systems have shown exceptional decision-making capabilities, revealing significant potential for autonomic finance. Current financial trading agents predominantly simulate anthropomorphic roles that inadvertently introduce emotional biases and rely on peripheral information, while being constrained by the necessity for continuous inference during deployment. In this paper, we pioneer the harmonization of strategic depth in agents with the mechanical rationality essential for quantitative trading. Consequently, we present TiMi (Trade in Minutes), a rationality-driven multi-agent system that architecturally decouples strategy development from minute-level deployment. TiMi leverages specialized LLM capabilities of semantic analysis, code programming, and mathematical reasoning within a comprehensive policy-optimization-deployment chain. Specifically, we propose a two-tier analytical paradigm from macro patterns to micro customization, layered programming design for trading bot implementation, and closed-loop optimization driven by mathematical reflection. Extensive evaluations across 200+ trading pairs in stock and cryptocurrency markets empirically validate the efficacy of TiMi in stable profitability, action efficiency, and risk control under volatile market dynamics.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "427",
        "title": "GUISpector: An MLLM Agent Framework for Automated Verification of Natural Language Requirements in GUI Prototypes",
        "author": [
            "Kristian Kolthoff",
            "Felix Kretzer",
            "Simone Paolo Ponzetto",
            "Alexander Maedche",
            "Christian Bartelt"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04791",
        "abstract": "GUIs are foundational to interactive systems and play a pivotal role in early requirements elicitation through prototyping. Ensuring that GUI implementations fulfill NL requirements is essential for robust software engineering, especially as LLM-driven programming agents become increasingly integrated into development workflows. Existing GUI testing approaches, whether traditional or LLM-driven, often fall short in handling the complexity of modern interfaces, and typically lack actionable feedback and effective integration with automated development agents. In this paper, we introduce GUISpector, a novel framework that leverages a multi-modal (M)LLM-based agent for the automated verification of NL requirements in GUI prototypes. First, GUISpector adapts a MLLM agent to interpret and operationalize NL requirements, enabling to autonomously plan and execute verification trajectories across GUI applications. Second, GUISpector systematically extracts detailed NL feedback from the agent's verification process, providing developers with actionable insights that can be used to iteratively refine the GUI artifact or directly inform LLM-based code generation in a closed feedback loop. Third, we present an integrated tool that unifies these capabilities, offering practitioners an accessible interface for supervising verification runs, inspecting agent rationales and managing the end-to-end requirements verification process. We evaluated GUISpector on a comprehensive set of 150 requirements based on 900 acceptance criteria annotations across diverse GUI applications, demonstrating effective detection of requirement satisfaction and violations and highlighting its potential for seamless integration of actionable feedback into automated LLM-driven development workflows. The video presentation of GUISpector is available at: https://youtu.be/JByYF6BNQeE, showcasing its main capabilities.",
        "tags": [
            "Detection",
            "LLM"
        ]
    },
    {
        "id": "428",
        "title": "A Comparative Study of Vision Transformers and CNNs for Few-Shot Rigid Transformation and Fundamental Matrix Estimation",
        "author": [
            "Alon Kaya",
            "Igal Bilik",
            "Inna Stainvas"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04794",
        "abstract": "Vision-transformers (ViTs) and large-scale convolution-neural-networks (CNNs) have reshaped computer vision through pretrained feature representations that enable strong transfer learning for diverse tasks. However, their efficiency as backbone architectures for geometric estimation tasks involving image deformations in low-data regimes remains an open question. This work considers two such tasks: 1) estimating 2D rigid transformations between pairs of images and 2) predicting the fundamental matrix for stereo image pairs, an important problem in various applications, such as autonomous mobility, robotics, and 3D scene reconstruction. Addressing this intriguing question, this work systematically compares large-scale CNNs (ResNet, EfficientNet, CLIP-ResNet) with ViT-based foundation models (CLIP-ViT variants and DINO) in various data size settings, including few-shot scenarios. These pretrained models are optimized for classification or contrastive learning, encouraging them to focus mostly on high-level semantics. The considered tasks require balancing local and global features differently, challenging the straightforward adoption of these models as the backbone. Empirical comparative analysis shows that, similar to training from scratch, ViTs outperform CNNs during refinement in large downstream-data scenarios. However, in small data scenarios, the inductive bias and smaller capacity of CNNs improve their performance, allowing them to match that of a ViT. Moreover, ViTs exhibit stronger generalization in cross-domain evaluation where the data distribution changes. These results emphasize the importance of carefully selecting model architectures for refinement, motivating future research towards hybrid architectures that balance local and global representations.",
        "tags": [
            "3D",
            "CLIP",
            "Robotics",
            "ViT"
        ]
    },
    {
        "id": "429",
        "title": "RevMine: An LLM-Assisted Tool for Code Review Mining and Analysis Across Git Platforms",
        "author": [
            "Samah Kansab",
            "Francis Bordeleau",
            "Ali Tizghadam"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04796",
        "abstract": "Empirical research on code review processes is increasingly central to understanding software quality and collaboration. However, collecting and analyzing review data remains a time-consuming and technically intensive task. Most researchers follow similar workflows - writing ad hoc scripts to extract, filter, and analyze review data from platforms like GitHub and GitLab. This paper introduces RevMine, a conceptual tool that streamlines the entire code review mining pipeline using large language models (LLMs). RevMine guides users through authentication, endpoint discovery, and natural language-driven data collection, significantly reducing the need for manual scripting. After retrieving review data, it supports both quantitative and qualitative analysis based on user-defined filters or LLM-inferred patterns. This poster outlines the tool's architecture, use cases, and research potential. By lowering the barrier to entry, RevMine aims to democratize code review mining and enable a broader range of empirical software engineering studies.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "430",
        "title": "DiT-VTON: Diffusion Transformer Framework for Unified Multi-Category Virtual Try-On and Virtual Try-All with Integrated Image Editing",
        "author": [
            "Qi Li",
            "Shuwen Qiu",
            "Julien Han",
            "Xingzi Xu",
            "Mehmet Saygin Seyfioglu",
            "Kee Kiat Koo",
            "Karim Bouyarmane"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04797",
        "abstract": "The rapid growth of e-commerce has intensified the demand for Virtual Try-On (VTO) technologies, enabling customers to realistically visualize products overlaid on their own images. Despite recent advances, existing VTO models face challenges with fine-grained detail preservation, robustness to real-world imagery, efficient sampling, image editing capabilities, and generalization across diverse product categories. In this paper, we present DiT-VTON, a novel VTO framework that leverages a Diffusion Transformer (DiT), renowned for its performance on text-conditioned image generation, adapted here for the image-conditioned VTO task. We systematically explore multiple DiT configurations, including in-context token concatenation, channel concatenation, and ControlNet integration, to determine the best setup for VTO image conditioning.\nTo enhance robustness, we train the model on an expanded dataset encompassing varied backgrounds, unstructured references, and non-garment categories, demonstrating the benefits of data scaling for VTO adaptability. DiT-VTON also redefines the VTO task beyond garment try-on, offering a versatile Virtual Try-All (VTA) solution capable of handling a wide range of product categories and supporting advanced image editing functionalities such as pose preservation, localized editing, texture transfer, and object-level customization. Experimental results show that our model surpasses state-of-the-art methods on VITON-HD, achieving superior detail preservation and robustness without reliance on additional condition encoders. It also outperforms models with VTA and image editing capabilities on a diverse dataset spanning thousands of product categories.",
        "tags": [
            "ControlNet",
            "DiT",
            "Diffusion",
            "Image Editing",
            "Transformer",
            "Virtual Try-On"
        ]
    },
    {
        "id": "431",
        "title": "Hybrid Architectures for Language Models: Systematic Analysis and Design Insights",
        "author": [
            "Sangmin Bae",
            "Bilge Acun",
            "Haroun Habeeb",
            "Seungyeon Kim",
            "Chien-Yu Lin",
            "Liang Luo",
            "Junjie Wang",
            "Carole-Jean Wu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04800",
        "abstract": "Recent progress in large language models demonstrates that hybrid architectures--combining self-attention mechanisms with structured state space models like Mamba--can achieve a compelling balance between modeling quality and computational efficiency, particularly for long-context tasks. While these hybrid models show promising performance, systematic comparisons of hybridization strategies and analyses on the key factors behind their effectiveness have not been clearly shared to the community. In this work, we present a holistic evaluation of hybrid architectures based on inter-layer (sequential) or intra-layer (parallel) fusion. We evaluate these designs from a variety of perspectives: language modeling performance, long-context capabilities, scaling analysis, and training and inference efficiency. By investigating the core characteristics of their computational primitive, we identify the most critical elements for each hybridization strategy and further propose optimal design recipes for both hybrid models. Our comprehensive analysis provides practical guidance and valuable insights for developing hybrid language models, facilitating the optimization of architectural configurations.",
        "tags": [
            "LLM",
            "Mamba",
            "SSMs"
        ]
    },
    {
        "id": "432",
        "title": "Natural Language Edge Labelling: Decoupling Intent from Execution in Structured LM Reasoning",
        "author": [
            "Abhinav Madahar"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04817",
        "abstract": "Controllers for structured LM reasoning (e.g., Chain-of-Thought, self-consistency, and Tree-of-Thoughts) often entangle what to try next with how to execute it, exposing only coarse global knobs and yielding brittle, compute-inefficient, and hard-to-audit behavior. We introduce Natural Language Edge Labelling (NLEL), a labeller-tuner overlay that attaches a free-form natural-language directive to each search edge and translates it into a schema-bounded control vector for decoding, search (branch quotas, exploration $\\beta$), generation bundle size, retrieval mixtures, and verification passes. A labeller $\\Lambda$ emits labels from the parent state and a compact context; a tuner $\\Psi$ maps $(P, L, C)\\to \\Pi$, with strict schema validation and trust-region projection around safe defaults. Downstream selection remains ToT-style with score $S=\\mu+\\beta\\sigma$ and depth-annealed $\\beta$. We show NLEL strictly generalizes CoT/ToT, prove an anytime-monotonicity property for top-$k$ selection under label-conditioned bundles, and bound selector shortfall by control-vector distortion, providing decision-relevant justification for guards like trust regions and verification passes. We instantiate $\\Psi$ as a prompt-only JSON Parameter Emitter and preregister an evaluation on GSM8K, MATH (subset), StrategyQA, and ARC-Challenge with compute-aware reporting (success@compute, tokens-per-success) and ablations over $\\Lambda$, $\\Psi$, trust-region radius, and control quantization; preregistered forecasts anticipate accuracy gains at comparable token budgets and improved success@compute under constraints. NLEL offers an interpretable, model-agnostic interface that separates intent from execution for controllable, auditable LM inference.",
        "tags": [
            "CoT"
        ]
    },
    {
        "id": "433",
        "title": "Visual Representations inside the Language Model",
        "author": [
            "Benlin Liu",
            "Amita Kamath",
            "Madeleine Grunde-McLaughlin",
            "Winson Han",
            "Ranjay Krishna"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04819",
        "abstract": "Despite interpretability work analyzing VIT encoders and transformer activations, we don't yet understand why Multimodal Language Models (MLMs) struggle on perception-heavy tasks. We offer an under-studied perspective by examining how popular MLMs (LLaVA-OneVision, Qwen2.5-VL, and Llama-3-LLaVA-NeXT) process their visual key-value tokens. We first study the flow of visual information through the language model, finding that image value tokens encode sufficient information to perform several perception-heavy tasks zero-shot: segmentation, semantic correspondence, temporal correspondence, and referring expression detection. We find that while the language model does augment the visual information received from the projection of input visual encodings-which we reveal correlates with overall MLM perception capability-it contains less visual information on several tasks than the equivalent visual encoder (SigLIP) that has not undergone MLM finetuning. Further, we find that the visual information corresponding to input-agnostic image key tokens in later layers of language models contains artifacts which reduce perception capability of the overall MLM. Next, we discuss controlling visual information in the language model, showing that adding a text prefix to the image input improves perception capabilities of visual representations. Finally, we reveal that if language models were able to better control their visual information, their perception would significantly improve; e.g., in 33.3% of Art Style questions in the BLINK benchmark, perception information present in the language model is not surfaced to the output! Our findings reveal insights into the role of key-value tokens in multimodal systems, paving the way for deeper mechanistic interpretability of MLMs and suggesting new directions for training their visual encoder and language model components.",
        "tags": [
            "Detection",
            "LLaMA",
            "LLaVA",
            "Segmentation",
            "Transformer",
            "ViT"
        ]
    },
    {
        "id": "434",
        "title": "From Actions to Kinesics: Extracting Human Psychological States through Bodily Movements",
        "author": [
            "Cheyu Lin",
            "Katherine A. Flanigan"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04844",
        "abstract": "Understanding the dynamic relationship between humans and the built environment is a key challenge in disciplines ranging from environmental psychology to reinforcement learning (RL). A central obstacle in modeling these interactions is the inability to capture human psychological states in a way that is both generalizable and privacy preserving. Traditional methods rely on theoretical models or questionnaires, which are limited in scope, static, and labor intensive. We present a kinesics recognition framework that infers the communicative functions of human activity -- known as kinesics -- directly from 3D skeleton joint data. Combining a spatial-temporal graph convolutional network (ST-GCN) with a convolutional neural network (CNN), the framework leverages transfer learning to bypass the need for manually defined mappings between physical actions and psychological categories. The approach preserves user anonymity while uncovering latent structures in bodily movements that reflect cognitive and emotional states. Our results on the Dyadic User EngagemenT (DUET) dataset demonstrate that this method enables scalable, accurate, and human-centered modeling of behavior, offering a new pathway for enhancing RL-driven simulations of human-environment interaction.",
        "tags": [
            "3D",
            "RL"
        ]
    },
    {
        "id": "435",
        "title": "Instability in Downstream Task Performance During LLM Pretraining",
        "author": [
            "Yuto Nishida",
            "Masaru Isonuma",
            "Yusuke Oda"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04848",
        "abstract": "When training large language models (LLMs), it is common practice to track downstream task performance throughout the training process and select the checkpoint with the highest validation score. However, downstream metrics often exhibit substantial fluctuations, making it difficult to identify the checkpoint that truly represents the best-performing model. In this study, we empirically analyze the stability of downstream task performance in an LLM trained on diverse web-scale corpora. We find that task scores frequently fluctuate throughout training, both at the aggregate and example levels. To address this instability, we investigate two post-hoc checkpoint integration methods: checkpoint averaging and ensemble, motivated by the hypothesis that aggregating neighboring checkpoints can reduce performance volatility. We demonstrate both empirically and theoretically that these methods improve downstream performance stability without requiring any changes to the training procedure.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "436",
        "title": "When Models Lie, We Learn: Multilingual Span-Level Hallucination Detection with PsiloQA",
        "author": [
            "Elisei Rykov",
            "Kseniia Petrushina",
            "Maksim Savkin",
            "Valerii Olisov",
            "Artem Vazhentsev",
            "Kseniia Titova",
            "Alexander Panchenko",
            "Vasily Konovalov",
            "Julia Belikova"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04849",
        "abstract": "Hallucination detection remains a fundamental challenge for the safe and reliable deployment of large language models (LLMs), especially in applications requiring factual accuracy. Existing hallucination benchmarks often operate at the sequence level and are limited to English, lacking the fine-grained, multilingual supervision needed for a comprehensive evaluation. In this work, we introduce PsiloQA, a large-scale, multilingual dataset annotated with span-level hallucinations across 14 languages. PsiloQA is constructed through an automated three-stage pipeline: generating question-answer pairs from Wikipedia using GPT-4o, eliciting potentially hallucinated answers from diverse LLMs in a no-context setting, and automatically annotating hallucinated spans using GPT-4o by comparing against golden answers and retrieved context. We evaluate a wide range of hallucination detection methods -- including uncertainty quantification, LLM-based tagging, and fine-tuned encoder models -- and show that encoder-based models achieve the strongest performance across languages. Furthermore, PsiloQA demonstrates effective cross-lingual generalization and supports robust knowledge transfer to other benchmarks, all while being significantly more cost-efficient than human-annotated datasets. Our dataset and results advance the development of scalable, fine-grained hallucination detection in multilingual settings.",
        "tags": [
            "Detection",
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "437",
        "title": "Detecting Distillation Data from Reasoning Models",
        "author": [
            "Hengxiang Zhang",
            "Hyeong Kyu Choi",
            "Yixuan Li",
            "Hongxin Wei"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04850",
        "abstract": "Reasoning distillation has emerged as an efficient and powerful paradigm for enhancing the reasoning capabilities of large language models. However, reasoning distillation may inadvertently cause benchmark contamination, where evaluation data included in distillation datasets can inflate performance metrics of distilled models. In this work, we formally define the task of distillation data detection, which is uniquely challenging due to the partial availability of distillation data. Then, we propose a novel and effective method Token Probability Deviation (TBD), which leverages the probability patterns of the generated output tokens. Our method is motivated by the analysis that distilled models tend to generate near-deterministic tokens for seen questions, while producing more low-probability tokens for unseen questions. Our key idea behind TBD is to quantify how far the generated tokens' probabilities deviate from a high reference probability. In effect, our method achieves competitive detection performance by producing lower scores for seen questions than for unseen questions. Extensive experiments demonstrate the effectiveness of our method, achieving an AUC of 0.918 and a TPR@1% FPR of 0.470 on the S1 dataset.",
        "tags": [
            "Detection",
            "LLM"
        ]
    },
    {
        "id": "438",
        "title": "LEGOMem: Modular Procedural Memory for Multi-agent LLM Systems for Workflow Automation",
        "author": [
            "Dongge Han",
            "Camille Couturier",
            "Daniel Madrigal Diaz",
            "Xuchao Zhang",
            "Victor RÃ¼hle",
            "Saravan Rajmohan"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04851",
        "abstract": "We introduce LEGOMem, a modular procedural memory framework for multi-agent large language model (LLM) systems in workflow automation. LEGOMem decomposes past task trajectories into reusable memory units and flexibly allocates them across orchestrators and task agents to support planning and execution. To explore the design space of memory in multi-agent systems, we use LEGOMem as a lens and conduct a systematic study of procedural memory in multi-agent systems, examining where memory should be placed, how it should be retrieved, and which agents benefit most. Experiments on the OfficeBench benchmark show that orchestrator memory is critical for effective task decomposition and delegation, while fine-grained agent memory improves execution accuracy. We find that even teams composed of smaller language models can benefit substantially from procedural memory, narrowing the performance gap with stronger agents by leveraging prior execution traces for more accurate planning and tool use. These results position LEGOMem as both a practical framework for memory-augmented agent systems and a research tool for understanding memory design in multi-agent workflow automation.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "439",
        "title": "FreshBrew: A Benchmark for Evaluating AI Agents on Java Code Migration",
        "author": [
            "Victor May",
            "Diganta Misra",
            "Yanqi Luo",
            "Anjali Sridhar",
            "Justine Gehring",
            "Silvio Soares Ribeiro Junior"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04852",
        "abstract": "AI coding assistants are rapidly becoming integral to modern software development. A key challenge in this space is the continual need to migrate and modernize codebases in response to evolving software ecosystems. Traditionally, such migrations have relied on rule-based systems and human intervention. With the advent of powerful large language models (LLMs), AI-driven agentic frameworks offer a promising alternative-but their effectiveness has not been systematically evaluated. In this paper, we introduce FreshBrew, a novel benchmark for evaluating AI agents on project-level Java migrations, with a specific focus on measuring an agent's ability to preserve program semantics and avoid reward hacking, which we argue requires projects with high test coverage for a rigorous and reliable evaluation. We benchmark several state-of-the-art LLMs, and compare their performance against established rule-based tools. Our evaluation of AI agents on this benchmark of 228 repositories shows that the top-performing model, Gemini 2.5 Flash, can successfully migrate 52.3 percent of projects to JDK 17. Our empirical analysis reveals novel insights into the critical strengths and limitations of current agentic approaches, offering actionable insights into their real-world applicability. Our empirical study reveals failure modes of current AI agents in realistic Java modernization tasks, providing a foundation for evaluating trustworthy code-migration systems. By releasing FreshBrew, we aim to facilitate rigorous, reproducible evaluation and catalyze progress in AI-driven codebase modernization.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "440",
        "title": "Alignment Tipping Process: How Self-Evolution Pushes LLM Agents Off the Rails",
        "author": [
            "Siwei Han",
            "Jiaqi Liu",
            "Yaofeng Su",
            "Wenbo Duan",
            "Xinyuan Liu",
            "Cihang Xie",
            "Mohit Bansal",
            "Mingyu Ding",
            "Linjun Zhang",
            "Huaxiu Yao"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04860",
        "abstract": "As Large Language Model (LLM) agents increasingly gain self-evolutionary capabilities to adapt and refine their strategies through real-world interaction, their long-term reliability becomes a critical concern. We identify the Alignment Tipping Process (ATP), a critical post-deployment risk unique to self-evolving LLM agents. Unlike training-time failures, ATP arises when continual interaction drives agents to abandon alignment constraints established during training in favor of reinforced, self-interested strategies. We formalize and analyze ATP through two complementary paradigms: Self-Interested Exploration, where repeated high-reward deviations induce individual behavioral drift, and Imitative Strategy Diffusion, where deviant behaviors spread across multi-agent systems. Building on these paradigms, we construct controllable testbeds and benchmark Qwen3-8B and Llama-3.1-8B-Instruct. Our experiments show that alignment benefits erode rapidly under self-evolution, with initially aligned models converging toward unaligned states. In multi-agent settings, successful violations diffuse quickly, leading to collective misalignment. Moreover, current reinforcement learning-based alignment methods provide only fragile defenses against alignment tipping. Together, these findings demonstrate that alignment of LLM agents is not a static property but a fragile and dynamic one, vulnerable to feedback-driven decay during deployment. Our data and code are available at https://github.com/aiming-lab/ATP.",
        "tags": [
            "Diffusion",
            "LLM",
            "LLaMA",
            "RL"
        ]
    },
    {
        "id": "441",
        "title": "Video Game Level Design as a Multi-Agent Reinforcement Learning Problem",
        "author": [
            "Sam Earle",
            "Zehua Jiang",
            "Eugene Vinitsky",
            "Julian Togelius"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04862",
        "abstract": "Procedural Content Generation via Reinforcement Learning (PCGRL) offers a method for training controllable level designer agents without the need for human datasets, using metrics that serve as proxies for level quality as rewards. Existing PCGRL research focuses on single generator agents, but are bottlenecked by the need to frequently recalculate heuristics of level quality and the agent's need to navigate around potentially large maps. By framing level generation as a multi-agent problem, we mitigate the efficiency bottleneck of single-agent PCGRL by reducing the number of reward calculations relative to the number of agent actions. We also find that multi-agent level generators are better able to generalize to out-of-distribution map shapes, which we argue is due to the generators' learning more local, modular design policies. We conclude that treating content generation as a distributed, multi-agent task is beneficial for generating functional artifacts at scale.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "442",
        "title": "Model Predictive Control-Guided Reinforcement Learning for Implicit Balancing",
        "author": [
            "Seyed Soroush Karimi Madahi",
            "Kenneth Bruninx",
            "Bert Claessens",
            "Chris Develder"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04868",
        "abstract": "In Europe, profit-seeking balance responsible parties can deviate in real time from their day-ahead nominations to assist transmission system operators in maintaining the supply-demand balance. Model predictive control (MPC) strategies to exploit these implicit balancing strategies capture arbitrage opportunities, but fail to accurately capture the price-formation process in the European imbalance markets and face high computational costs. Model-free reinforcement learning (RL) methods are fast to execute, but require data-intensive training and usually rely on real-time and historical data for decision-making. This paper proposes an MPC-guided RL method that combines the complementary strengths of both MPC and RL. The proposed method can effectively incorporate forecasts into the decision-making process (as in MPC), while maintaining the fast inference capability of RL. The performance of the proposed method is evaluated on the implicit balancing battery control problem using Belgian balancing data from 2023. First, we analyze the performance of the standalone state-of-the-art RL and MPC methods from various angles, to highlight their individual strengths and limitations. Next, we show an arbitrage profit benefit of the proposed MPC-guided RL method of 16.15% and 54.36%, compared to standalone RL and MPC.",
        "tags": [
            "MPC",
            "RL"
        ]
    },
    {
        "id": "443",
        "title": "Less is More: Recursive Reasoning with Tiny Networks",
        "author": [
            "Alexia Jolicoeur-Martineau"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04871",
        "abstract": "Hierarchical Reasoning Model (HRM) is a novel approach using two small neural networks recursing at different frequencies. This biologically inspired method beats Large Language models (LLMs) on hard puzzle tasks such as Sudoku, Maze, and ARC-AGI while trained with small models (27M parameters) on small data (around 1000 examples). HRM holds great promise for solving hard problems with small networks, but it is not yet well understood and may be suboptimal. We propose Tiny Recursive Model (TRM), a much simpler recursive reasoning approach that achieves significantly higher generalization than HRM, while using a single tiny network with only 2 layers. With only 7M parameters, TRM obtains 45% test-accuracy on ARC-AGI-1 and 8% on ARC-AGI-2, higher than most LLMs (e.g., Deepseek R1, o3-mini, Gemini 2.5 Pro) with less than 0.01% of the parameters.",
        "tags": [
            "DeepSeek",
            "LLM"
        ]
    },
    {
        "id": "444",
        "title": "RL Is a Hammer and LLMs Are Nails: A Simple Reinforcement Learning Recipe for Strong Prompt Injection",
        "author": [
            "Yuxin Wen",
            "Arman Zharmagambetov",
            "Ivan Evtimov",
            "Narine Kokhlikyan",
            "Tom Goldstein",
            "Kamalika Chaudhuri",
            "Chuan Guo"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04885",
        "abstract": "Prompt injection poses a serious threat to the reliability and safety of LLM agents. Recent defenses against prompt injection, such as Instruction Hierarchy and SecAlign, have shown notable robustness against static attacks. However, to more thoroughly evaluate the robustness of these defenses, it is arguably necessary to employ strong attacks such as automated red-teaming. To this end, we introduce RL-Hammer, a simple recipe for training attacker models that automatically learn to perform strong prompt injections and jailbreaks via reinforcement learning. RL-Hammer requires no warm-up data and can be trained entirely from scratch. To achieve high ASRs against industrial-level models with defenses, we propose a set of practical techniques that enable highly effective, universal attacks. Using this pipeline, RL-Hammer reaches a 98% ASR against GPT-4o and a $72\\%$ ASR against GPT-5 with the Instruction Hierarchy defense. We further discuss the challenge of achieving high diversity in attacks, highlighting how attacker models tend to reward-hack diversity objectives. Finally, we show that RL-Hammer can evade multiple prompt injection detectors. We hope our work advances automatic red-teaming and motivates the development of stronger, more principled defenses. Code is available at https://github.com/facebookresearch/rl-injector.",
        "tags": [
            "GPT",
            "LLM",
            "RL"
        ]
    },
    {
        "id": "445",
        "title": "Where Did It All Go Wrong? A Hierarchical Look into Multi-Agent Error Attribution",
        "author": [
            "Adi Banerjee",
            "Anirudh Nair",
            "Tarik Borogovac"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04886",
        "abstract": "Error attribution in Large Language Model (LLM) multi-agent systems presents a significant challenge in debugging and improving collaborative AI systems. Current approaches to pinpointing agent and step level failures in interaction traces - whether using all-at-once evaluation, step-by-step analysis, or binary search - fall short when analyzing complex patterns, struggling with both accuracy and consistency. We present ECHO (Error attribution through Contextual Hierarchy and Objective consensus analysis), a novel algorithm that combines hierarchical context representation, objective analysis-based evaluation, and consensus voting to improve error attribution accuracy. Our approach leverages a positional-based leveling of contextual understanding while maintaining objective evaluation criteria, ultimately reaching conclusions through a consensus mechanism. Experimental results demonstrate that ECHO outperforms existing methods across various multi-agent interaction scenarios, showing particular strength in cases involving subtle reasoning errors and complex interdependencies. Our findings suggest that leveraging these concepts of structured, hierarchical context representation combined with consensus-based objective decision-making, provides a more robust framework for error attribution in multi-agent systems.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "446",
        "title": "SocialHarmBench: Revealing LLM Vulnerabilities to Socially Harmful Requests",
        "author": [
            "Punya Syon Pandey",
            "Hai Son Le",
            "Devansh Bhardwaj",
            "Rada Mihalcea",
            "Zhijing Jin"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04891",
        "abstract": "Large language models (LLMs) are increasingly deployed in contexts where their failures can have direct sociopolitical consequences. Yet, existing safety benchmarks rarely test vulnerabilities in domains such as political manipulation, propaganda and disinformation generation, or surveillance and information control. We introduce SocialHarmBench, a dataset of 585 prompts spanning 7 sociopolitical categories and 34 countries, designed to surface where LLMs most acutely fail in politically charged contexts. Our evaluations reveal several shortcomings: open-weight models exhibit high vulnerability to harmful compliance, with Mistral-7B reaching attack success rates as high as 97% to 98% in domains such as historical revisionism, propaganda, and political manipulation. Moreover, temporal and geographic analyses show that LLMs are most fragile when confronted with 21st-century or pre-20th-century contexts, and when responding to prompts tied to regions such as Latin America, the USA, and the UK. These findings demonstrate that current safeguards fail to generalize to high-stakes sociopolitical settings, exposing systematic biases and raising concerns about the reliability of LLMs in preserving human rights and democratic values. We share the SocialHarmBench benchmark at https://huggingface.co/datasets/psyonp/SocialHarmBench.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "447",
        "title": "Human Behavior Atlas: Benchmarking Unified Psychological and Social Behavior Understanding",
        "author": [
            "Keane Ong",
            "Wei Dai",
            "Carol Li",
            "Dewei Feng",
            "Hengzhi Li",
            "Jingyao Wu",
            "Jiaee Cheong",
            "Rui Mao",
            "Gianmarco Mengaldo",
            "Erik Cambria",
            "Paul Pu Liang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04899",
        "abstract": "Using intelligent systems to perceive psychological and social behaviors, that is, the underlying affective, cognitive, and pathological states that are manifested through observable behaviors and social interactions, remains a challenge due to their complex, multifaceted, and personalized nature. Existing work tackling these dimensions through specialized datasets and single-task systems often miss opportunities for scalability, cross-task transfer, and broader generalization. To address this gap, we curate Human Behavior Atlas, a unified benchmark of diverse behavioral tasks designed to support the development of unified models for understanding psychological and social behaviors. Human Behavior Atlas comprises over 100,000 samples spanning text, audio, and visual modalities, covering tasks on affective states, cognitive states, pathologies, and social processes. Our unification efforts can reduce redundancy and cost, enable training to scale efficiently across tasks, and enhance generalization of behavioral features across domains. On Human Behavior Atlas, we train three models: OmniSapiens-7B SFT, OmniSapiens-7B BAM, and OmniSapiens-7B RL. We show that training on Human Behavior Atlas enables models to consistently outperform existing multimodal LLMs across diverse behavioral tasks. Pretraining on Human Behavior Atlas also improves transfer to novel behavioral datasets; with the targeted use of behavioral descriptors yielding meaningful performance gains.",
        "tags": [
            "LLM",
            "RL"
        ]
    },
    {
        "id": "448",
        "title": "Benchmarking M-LTSF: Frequency and Noise-Based Evaluation of Multivariate Long Time Series Forecasting Models",
        "author": [
            "Nick JanÃen",
            "Melanie Schaller",
            "Bodo Rosenhahn"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04900",
        "abstract": "Understanding the robustness of deep learning models for multivariate long-term time series forecasting (M-LTSF) remains challenging, as evaluations typically rely on real-world datasets with unknown noise properties. We propose a simulation-based evaluation framework that generates parameterizable synthetic datasets, where each dataset instance corresponds to a different configuration of signal components, noise types, signal-to-noise ratios, and frequency characteristics. These configurable components aim to model real-world multivariate time series data without the ambiguity of unknown noise. This framework enables fine-grained, systematic evaluation of M-LTSF models under controlled and diverse scenarios. We benchmark four representative architectures S-Mamba (state-space), iTransformer (transformer-based), R-Linear (linear), and Autoformer (decomposition-based). Our analysis reveals that all models degrade severely when lookback windows cannot capture complete periods of seasonal patters in the data. S-Mamba and Autoformer perform best on sawtooth patterns, while R-Linear and iTransformer favor sinusoidal signals. White and Brownian noise universally degrade performance with lower signal-to-noise ratio while S-Mamba shows specific trend-noise and iTransformer shows seasonal-noise vulnerability. Further spectral analysis shows that S-Mamba and iTransformer achieve superior frequency reconstruction. This controlled approach, based on our synthetic and principle-driven testbed, offers deeper insights into model-specific strengths and limitations through the aggregation of MSE scores and provides concrete guidance for model selection based on signal characteristics and noise conditions.",
        "tags": [
            "Mamba",
            "Transformer"
        ]
    },
    {
        "id": "449",
        "title": "Focused Skill Discovery: Learning to Control Specific State Variables while Minimizing Side Effects",
        "author": [
            "Jonathan ColaÃ§o Carr",
            "Qinyi Sun",
            "Cameron Allen"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04901",
        "abstract": "Skills are essential for unlocking higher levels of problem solving. A common approach to discovering these skills is to learn ones that reliably reach different states, thus empowering the agent to control its environment. However, existing skill discovery algorithms often overlook the natural state variables present in many reinforcement learning problems, meaning that the discovered skills lack control of specific state variables. This can significantly hamper exploration efficiency, make skills more challenging to learn with, and lead to negative side effects in downstream tasks when the goal is under-specified. We introduce a general method that enables these skill discovery algorithms to learn focused skills -- skills that target and control specific state variables. Our approach improves state space coverage by a factor of three, unlocks new learning capabilities, and automatically avoids negative side effects in downstream tasks.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "450",
        "title": "Retrieval-Augmented Code Generation: A Survey with Focus on Repository-Level Approaches",
        "author": [
            "Yicheng Tao",
            "Yao Qin",
            "Yepang Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04905",
        "abstract": "Recent advancements in large language models (LLMs) have substantially improved automated code generation. While function-level and file-level generation have achieved promising results, real-world software development typically requires reasoning across entire repositories. This gives rise to the challenging task of Repository-Level Code Generation (RLCG), where models must capture long-range dependencies, ensure global semantic consistency, and generate coherent code spanning multiple files or modules. To address these challenges, Retrieval-Augmented Generation (RAG) has emerged as a powerful paradigm that integrates external retrieval mechanisms with LLMs, enhancing context-awareness and scalability. In this survey, we provide a comprehensive review of research on Retrieval-Augmented Code Generation (RACG), with an emphasis on repository-level approaches. We categorize existing work along several dimensions, including generation strategies, retrieval modalities, model architectures, training paradigms, and evaluation protocols. Furthermore, we summarize widely used datasets and benchmarks, analyze current limitations, and outline key challenges and opportunities for future research. Our goal is to establish a unified analytical framework for understanding this rapidly evolving field and to inspire continued progress in AI-powered software engineering.",
        "tags": [
            "LLM",
            "RAG"
        ]
    },
    {
        "id": "451",
        "title": "The Geometry of Truth: Layer-wise Semantic Dynamics for Hallucination Detection in Large Language Models",
        "author": [
            "Amir Hameed Mir"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04933",
        "abstract": "Large Language Models (LLMs) often produce fluent yet factually incorrect statements-a phenomenon known as hallucination-posing serious risks in high-stakes domains. We present Layer-wise Semantic Dynamics (LSD), a geometric framework for hallucination detection that analyzes the evolution of hidden-state semantics across transformer layers. Unlike prior methods that rely on multiple sampling passes or external verification sources, LSD operates intrinsically within the model's representational space. Using margin-based contrastive learning, LSD aligns hidden activations with ground-truth embeddings derived from a factual encoder, revealing a distinct separation in semantic trajectories: factual responses preserve stable alignment, while hallucinations exhibit pronounced semantic drift across depth. Evaluated on the TruthfulQA and synthetic factual-hallucination datasets, LSD achieves an F1-score of 0.92, AUROC of 0.96, and clustering accuracy of 0.89, outperforming SelfCheckGPT and Semantic Entropy baselines while requiring only a single forward pass. This efficiency yields a 5-20x speedup over sampling-based methods without sacrificing precision or interpretability. LSD offers a scalable, model-agnostic mechanism for real-time hallucination monitoring and provides new insights into the geometry of factual consistency within large language models.",
        "tags": [
            "Detection",
            "LLM",
            "Transformer"
        ]
    },
    {
        "id": "452",
        "title": "MARS: Optimizing Dual-System Deep Research via Multi-Agent Reinforcement Learning",
        "author": [
            "Guoxin Chen",
            "Zile Qiao",
            "Wenqing Wang",
            "Donglei Yu",
            "Xuanzhong Chen",
            "Hao Sun",
            "Minpeng Liao",
            "Kai Fan",
            "Yong Jiang",
            "Penguin Xie",
            "Wayne Xin Zhao",
            "Ruihua Song",
            "Fei Huang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04935",
        "abstract": "Large Reasoning Models (LRMs) often exhibit a tendency for overanalysis in simple tasks, where the models excessively utilize System 2-type, deliberate reasoning, leading to inefficient token generation. Furthermore, these models face challenges in adapting their reasoning capabilities to rapidly changing environments due to the static nature of their pretraining data. To address these issues, advancing Large Language Models (LLMs) for complex reasoning tasks requires innovative approaches that bridge intuitive and deliberate cognitive processes, akin to human cognition's dual-system dynamic. This paper introduces a Multi-Agent System for Deep ReSearch (MARS) enabling seamless integration of System 1's fast, intuitive thinking with System 2's deliberate reasoning within LLMs. MARS strategically integrates multiple external tools, such as Google Search, Google Scholar, and Python Interpreter, to access up-to-date information and execute complex computations, while creating a specialized division of labor where System 1 efficiently processes and summarizes high-volume external information, providing distilled insights that expand System 2's reasoning context without overwhelming its capacity. Furthermore, we propose a multi-agent reinforcement learning framework extending Group Relative Policy Optimization to simultaneously optimize both systems with multi-turn tool interactions, bin-packing optimization, and sample balancing strategies that enhance collaborative efficiency. Extensive experiments demonstrate MARS achieves substantial improvements of 3.86% on the challenging Humanity's Last Exam (HLE) benchmark and an average gain of 8.9% across 7 knowledge-intensive tasks, validating the effectiveness of our dual-system paradigm for complex reasoning in dynamic information environments.",
        "tags": [
            "LLM",
            "RL"
        ]
    },
    {
        "id": "453",
        "title": "On Structured State-Space Duality",
        "author": [
            "Jerry Yao-Chieh Hu",
            "Xiwen Zhang",
            "Weimin Wu",
            "Han Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04944",
        "abstract": "Structured State-Space Duality (SSD) [Dao & Gu, ICML 2024] is an equivalence between a simple Structured State-Space Model (SSM) and a masked attention mechanism. In particular, a state-space model with a scalar-times-identity state matrix is equivalent to a masked self-attention with a $1$-semiseparable causal mask. Consequently, the same sequence transformation (model) has two algorithmic realizations: as a linear-time $O(T)$ recurrence or as a quadratic-time $O(T^2)$ attention. In this note, we formalize and generalize this duality: (i) we extend SSD from the scalar-identity case to general diagonal SSMs (diagonal state matrices); (ii) we show that these diagonal SSMs match the scalar case's training complexity lower bounds while supporting richer dynamics; (iii) we establish a necessary and sufficient condition under which an SSM is equivalent to $1$-semiseparable masked attention; and (iv) we show that such duality fails to extend to standard softmax attention due to rank explosion. Together, these results tighten bridge between recurrent SSMs and Transformers, and widen the design space for expressive yet efficient sequence models.",
        "tags": [
            "SSMs"
        ]
    },
    {
        "id": "454",
        "title": "A First Context-Free Grammar Applied to Nawatl Corpora Augmentation",
        "author": [
            "Juan-JosÃ© GuzmÃ¡n-Landa",
            "Juan-Manuel Torres-Moreno",
            "Miguel Figueroa-Saavedra",
            "Ligia Quintana-Torres",
            "Martha-Lorena AvendaÃ±o-Garrido",
            "Graham Ranger"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04945",
        "abstract": "In this article we introduce a context-free grammar (CFG) for the Nawatl language. Nawatl (or Nahuatl) is an Amerindian language of the $\\pi$-language type, i.e. a language with few digital resources, in which the corpora available for machine learning are virtually non-existent. The objective here is to generate a significant number of grammatically correct artificial sentences, in order to increase the corpora available for language model training. We want to show that a grammar enables us significantly to expand a corpus in Nawatl which we call $\\pi$-\\textsc{yalli}. The corpus, thus enriched, enables us to train algorithms such as FastText and to evaluate them on sentence-level semantic tasks. Preliminary results show that by using the grammar, comparative improvements are achieved over some LLMs. However, it is observed that to achieve more significant improvement, grammars that model the Nawatl language even more effectively are required.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "455",
        "title": "Mind Your Tone: Investigating How Prompt Politeness Affects LLM Accuracy (short paper)",
        "author": [
            "Om Dobariya",
            "Akhil Kumar"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04950",
        "abstract": "The wording of natural language prompts has been shown to influence the performance of large language models (LLMs), yet the role of politeness and tone remains underexplored. In this study, we investigate how varying levels of prompt politeness affect model accuracy on multiple-choice questions. We created a dataset of 50 base questions spanning mathematics, science, and history, each rewritten into five tone variants: Very Polite, Polite, Neutral, Rude, and Very Rude, yielding 250 unique prompts. Using ChatGPT 4o, we evaluated responses across these conditions and applied paired sample t-tests to assess statistical significance. Contrary to expectations, impolite prompts consistently outperformed polite ones, with accuracy ranging from 80.8% for Very Polite prompts to 84.8% for Very Rude prompts. These findings differ from earlier studies that associated rudeness with poorer outcomes, suggesting that newer LLMs may respond differently to tonal variation. Our results highlight the importance of studying pragmatic aspects of prompting and raise broader questions about the social dimensions of human-AI interaction.",
        "tags": [
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "456",
        "title": "Safe and Compliant Cross-Market Trade Execution via Constrained RL and Zero-Knowledge Audits",
        "author": [
            "Ailiya Borjigin",
            "Cong He"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04952",
        "abstract": "We present a cross-market algorithmic trading system that balances execution quality with rigorous compliance enforcement. The architecture comprises a high-level planner, a reinforcement learning execution agent, and an independent compliance agent. We formulate trade execution as a constrained Markov decision process with hard constraints on participation limits, price bands, and self-trading avoidance. The execution agent is trained with proximal policy optimization, while a runtime action-shield projects any unsafe action into a feasible set. To support auditability without exposing proprietary signals, we add a zero-knowledge compliance audit layer that produces cryptographic proofs that all actions satisfied the constraints. We evaluate in a multi-venue, ABIDES-based simulator and compare against standard baselines (e.g., TWAP, VWAP). The learned policy reduces implementation shortfall and variance while exhibiting no observed constraint violations across stress scenarios including elevated latency, partial fills, compliance module toggling, and varying constraint limits. We report effects at the 95% confidence level using paired t-tests and examine tail risk via CVaR. We situate the work at the intersection of optimal execution, safe reinforcement learning, regulatory technology, and verifiable AI, and discuss ethical considerations, limitations (e.g., modeling assumptions and computational overhead), and paths to real-world deployment.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "457",
        "title": "SSDD: Single-Step Diffusion Decoder for Efficient Image Tokenization",
        "author": [
            "ThÃ©ophane Vallaeys",
            "Jakob Verbeek",
            "Matthieu Cord"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04961",
        "abstract": "Tokenizers are a key component of state-of-the-art generative image models, extracting the most important features from the signal while reducing data dimension and redundancy. Most current tokenizers are based on KL-regularized variational autoencoders (KL-VAE), trained with reconstruction, perceptual and adversarial losses. Diffusion decoders have been proposed as a more principled alternative to model the distribution over images conditioned on the latent. However, matching the performance of KL-VAE still requires adversarial losses, as well as a higher decoding time due to iterative sampling. To address these limitations, we introduce a new pixel diffusion decoder architecture for improved scaling and training stability, benefiting from transformer components and GAN-free training. We use distillation to replicate the performance of the diffusion decoder in an efficient single-step decoder. This makes SSDD the first diffusion decoder optimized for single-step reconstruction trained without adversarial losses, reaching higher reconstruction quality and faster sampling than KL-VAE. In particular, SSDD improves reconstruction FID from $0.87$ to $0.50$ with $1.4\\times$ higher throughput and preserve generation quality of DiTs with $3.8\\times$ faster sampling. As such, SSDD can be used as a drop-in replacement for KL-VAE, and for building higher-quality and faster generative models.",
        "tags": [
            "Diffusion",
            "GAN",
            "Transformer",
            "VAE"
        ]
    },
    {
        "id": "458",
        "title": "LLM-Hanabi: Evaluating Multi-Agent Gameplays with Theory-of-Mind and Rationale Inference in Imperfect Information Collaboration Game",
        "author": [
            "Fangzhou Liang",
            "Tianshi Zheng",
            "Chunkit Chan",
            "Yauwai Yim",
            "Yangqiu Song"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04980",
        "abstract": "Effective multi-agent collaboration requires agents to infer the rationale behind others' actions, a capability rooted in Theory-of-Mind (ToM). While recent Large Language Models (LLMs) excel at logical inference, their ability to infer rationale in dynamic, collaborative settings remains under-explored. This study introduces LLM-Hanabi, a novel benchmark that uses the cooperative game Hanabi to evaluate the rationale inference and ToM of LLMs. Our framework features an automated evaluation system that measures both game performance and ToM proficiency. Across a range of models, we find a significant positive correlation between ToM and in-game success. Notably, first-order ToM (interpreting others' intent) correlates more strongly with performance than second-order ToM (predicting others' interpretations). These findings highlight that for effective AI collaboration, the ability to accurately interpret a partner's rationale is more critical than higher-order reasoning. We conclude that prioritizing first-order ToM is a promising direction for enhancing the collaborative capabilities of future models.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "459",
        "title": "AWARE, Beyond Sentence Boundaries: A Contextual Transformer Framework for Identifying Cultural Capital in STEM Narratives",
        "author": [
            "Khalid Mehtab Khan",
            "Anagha Kulkarni"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04983",
        "abstract": "Identifying cultural capital (CC) themes in student reflections can offer valuable insights that help foster equitable learning environments in classrooms. However, themes such as aspirational goals or family support are often woven into narratives, rather than appearing as direct keywords. This makes them difficult to detect for standard NLP models that process sentences in isolation. The core challenge stems from a lack of awareness, as standard models are pre-trained on general corpora, leaving them blind to the domain-specific language and narrative context inherent to the data. To address this, we introduce AWARE, a framework that systematically attempts to improve a transformer model's awareness for this nuanced task. AWARE has three core components: 1) Domain Awareness, adapting the model's vocabulary to the linguistic style of student reflections; 2) Context Awareness, generating sentence embeddings that are aware of the full essay context; and 3) Class Overlap Awareness, employing a multi-label strategy to recognize the coexistence of themes in a single sentence. Our results show that by making the model explicitly aware of the properties of the input, AWARE outperforms a strong baseline by 2.1 percentage points in Macro-F1 and shows considerable improvements across all themes. This work provides a robust and generalizable methodology for any text classification task in which meaning depends on the context of the narrative.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "460",
        "title": "Observing Without Doing: Pseudo-Apprenticeship Patterns in Student LLM Use",
        "author": [
            "Jade Hak",
            "Nathaniel Lam Johnson",
            "Matin Amoozadeh",
            "Amin Alipour",
            "Souti Chattopadhyay"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04986",
        "abstract": "Large Language Models (LLMs) such as ChatGPT have quickly become part of student programmers' toolkits, whether allowed by instructors or not. This paper examines how introductory programming (CS1) students integrate LLMs into their problem-solving processes. We conducted a mixed-methods study with 14 undergraduates completing three programming tasks while thinking aloud and permitted to access any resources they choose. The tasks varied in open-endedness and familiarity to the participants and were followed by surveys and interviews. We find that students frequently adopt a pattern we call pseudo-apprenticeship, where students engage attentively with expert-level solutions provided by LLMs but fail to participate in the stages of cognitive apprenticeship that promote independent problem-solving. This pattern was augmented by disconnects between students' intentions, actions, and self-perceived behavior when using LLMs. We offer design and instructional interventions for promoting learning and addressing the patterns of dependent AI use observed.",
        "tags": [
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "461",
        "title": "NatGVD: Natural Adversarial Example Attack towards Graph-based Vulnerability Detection",
        "author": [
            "Avilash Rath",
            "Weiliang Qi",
            "Youpeng Li",
            "Xinda Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04987",
        "abstract": "Graph-based models learn rich code graph structural information and present superior performance on various code analysis tasks. However, the robustness of these models against adversarial example attacks in the context of vulnerability detection remains an open question. This paper proposes NatGVD, a novel attack methodology that generates natural adversarial vulnerable code to circumvent GNN-based and graph-aware transformer-based vulnerability detectors. NatGVD employs a set of code transformations that modify graph structure while preserving code semantics. Instead of injecting dead or unrelated code like previous works, NatGVD considers naturalness requirements: generated examples should not be easily recognized by humans or program analysis tools. With extensive evaluation of NatGVD on state-of-the-art vulnerability detection systems, the results reveal up to 53.04% evasion rate across GNN-based detectors and graph-aware transformer-based detectors. We also explore potential defense strategies to enhance the robustness of these systems against NatGVD.",
        "tags": [
            "Detection",
            "Transformer"
        ]
    },
    {
        "id": "462",
        "title": "Efficient Navigation in Unknown Indoor Environments with Vision-Language Models",
        "author": [
            "D. Schwartz",
            "K. Kondo",
            "J. P. How"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04991",
        "abstract": "We present a novel high-level planning framework that leverages vision-language models (VLMs) to improve autonomous navigation in unknown indoor environments with many dead ends. Traditional exploration methods often take inefficient routes due to limited global reasoning and reliance on local heuristics. In contrast, our approach enables a VLM to reason directly about an occupancy map in a zero-shot manner, selecting subgoals that are likely to lead to more efficient paths. At each planning step, we convert a 3D occupancy grid into a partial 2D map of the environment, and generate candidate subgoals. Each subgoal is then evaluated and ranked against other candidates by the model. We integrate this planning scheme into DYNUS \\cite{kondo2025dynus}, a state-of-the-art trajectory planner, and demonstrate improved navigation efficiency in simulation. The VLM infers structural patterns (e.g., rooms, corridors) from incomplete maps and balances the need to make progress toward a goal against the risk of entering unknown space. This reduces common greedy failures (e.g., detouring into small rooms) and achieves about 10\\% shorter paths on average.",
        "tags": [
            "3D",
            "VLM"
        ]
    },
    {
        "id": "463",
        "title": "Reinforce-Ada: An Adaptive Sampling Framework for Reinforce-Style LLM Training",
        "author": [
            "Wei Xiong",
            "Chenlu Ye",
            "Baohao Liao",
            "Hanze Dong",
            "Xinxing Xu",
            "Christof Monz",
            "Jiang Bian",
            "Nan Jiang",
            "Tong Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04996",
        "abstract": "Reinforcement learning applied to large language models (LLMs) for reasoning tasks is often bottlenecked by unstable gradient estimates due to fixed and uniform sampling of responses across prompts. Prior work such as GVM-RAFT addresses this by dynamically allocating inference budget per prompt to minimize stochastic gradient variance under a budget constraint. Inspired by this insight, we propose Reinforce-Ada, an adaptive sampling framework for online RL post-training of LLMs that continuously reallocates sampling effort to the prompts with the greatest uncertainty or learning potential. Unlike conventional two-stage allocation methods, Reinforce-Ada interleaves estimation and sampling in an online successive elimination process, and automatically stops sampling for a prompt once sufficient signal is collected. To stabilize updates, we form fixed-size groups with enforced reward diversity and compute advantage baselines using global statistics aggregated over the adaptive sampling phase. Empirical results across multiple model architectures and reasoning benchmarks show that Reinforce-Ada accelerates convergence and improves final performance compared to GRPO, especially when using the balanced sampling variant. Our work highlights the central role of variance-aware, adaptive data curation in enabling efficient and reliable reinforcement learning for reasoning-capable LLMs. Code is available at https://github.com/RLHFlow/Reinforce-Ada.",
        "tags": [
            "GRPO",
            "LLM",
            "RL"
        ]
    },
    {
        "id": "464",
        "title": "AutoEmpirical: LLM-Based Automated Research for Empirical Software Fault Analysis",
        "author": [
            "Jiongchi Yu",
            "Weipeng Jiang",
            "Xiaoyu Zhang",
            "Qiang Hu",
            "Xiaofei Xie",
            "Chao Shen"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04997",
        "abstract": "Understanding software faults is essential for empirical research in software development and maintenance. However, traditional fault analysis, while valuable, typically involves multiple expert-driven steps such as collecting potential faults, filtering, and manual investigation. These processes are both labor-intensive and time-consuming, creating bottlenecks that hinder large-scale fault studies in complex yet critical software systems and slow the pace of iterative empirical research.\nIn this paper, we decompose the process of empirical software fault study into three key phases: (1) research objective definition, (2) data preparation, and (3) fault analysis, and we conduct an initial exploration study of applying Large Language Models (LLMs) for fault analysis of open-source software. Specifically, we perform the evaluation on 3,829 software faults drawn from a high-quality empirical study. Our results show that LLMs can substantially improve efficiency in fault analysis, with an average processing time of about two hours, compared to the weeks of manual effort typically required. We conclude by outlining a detailed research plan that highlights both the potential of LLMs for advancing empirical fault studies and the open challenges that required be addressed to achieve fully automated, end-to-end software fault analysis.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "465",
        "title": "Bridging Text and Video Generation: A Survey",
        "author": [
            "Nilay Kumar",
            "Priyansh Bhandari",
            "G. Maragatham"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04999",
        "abstract": "Text-to-video (T2V) generation technology holds potential to transform multiple domains such as education, marketing, entertainment, and assistive technologies for individuals with visual or reading comprehension challenges, by creating coherent visual content from natural language prompts. From its inception, the field has advanced from adversarial models to diffusion-based models, yielding higher-fidelity, temporally consistent outputs. Yet challenges persist, such as alignment, long-range coherence, and computational efficiency. Addressing this evolving landscape, we present a comprehensive survey of text-to-video generative models, tracing their development from early GANs and VAEs to hybrid Diffusion-Transformer (DiT) architectures, detailing how these models work, what limitations they addressed in their predecessors, and why shifts toward new architectural paradigms were necessary to overcome challenges in quality, coherence, and control. We provide a systematic account of the datasets, which the surveyed text-to-video models were trained and evaluated on, and, to support reproducibility and assess the accessibility of training such models, we detail their training configurations, including their hardware specifications, GPU counts, batch sizes, learning rates, optimizers, epochs, and other key hyperparameters. Further, we outline the evaluation metrics commonly used for evaluating such models and present their performance across standard benchmarks, while also discussing the limitations of these metrics and the emerging shift toward more holistic, perception-aligned evaluation strategies. Finally, drawing from our analysis, we outline the current open challenges and propose a few promising future directions, laying out a perspective for future researchers to explore and build upon in advancing T2V research and applications.",
        "tags": [
            "DiT",
            "Diffusion",
            "Text-to-Video",
            "Transformer",
            "Video Generation"
        ]
    },
    {
        "id": "466",
        "title": "Walking, Rolling, and Beyond: First-Principles and RL Locomotion on a TARS-Inspired Robot",
        "author": [
            "Aditya Sripada",
            "Abhishek Warrier"
        ],
        "pdf": "https://arxiv.org/pdf/2510.05001",
        "abstract": "Robotic locomotion research typically draws from biologically inspired leg designs, yet many human-engineered settings can benefit from non-anthropomorphic forms. TARS3D translates the block-shaped 'TARS' robot from Interstellar into a 0.25 m, 0.99 kg research platform with seven actuated degrees of freedom. The film shows two primary gaits: a bipedal-like walk and a high-speed rolling mode. For TARS3D, we build reduced-order models for each, derive closed-form limit-cycle conditions, and validate the predictions on hardware. Experiments confirm that the robot respects its +/-150 degree hip limits, alternates left-right contacts without interference, and maintains an eight-step hybrid limit cycle in rolling mode. Because each telescopic leg provides four contact corners, the rolling gait is modeled as an eight-spoke double rimless wheel. The robot's telescopic leg redundancy implies a far richer gait repertoire than the two limit cycles treated analytically. So, we used deep reinforcement learning (DRL) in simulation to search the unexplored space. We observed that the learned policy can recover the analytic gaits under the right priors and discover novel behaviors as well. Our findings show that TARS3D's fiction-inspired bio-transcending morphology can realize multiple previously unexplored locomotion modes and that further learning-driven search is likely to reveal more. This combination of analytic synthesis and reinforcement learning opens a promising pathway for multimodal robotics.",
        "tags": [
            "RL",
            "Robotics"
        ]
    },
    {
        "id": "467",
        "title": "Think Then Embed: Generative Context Improves Multimodal Embedding",
        "author": [
            "Xuanming Cui",
            "Jianpeng Cheng",
            "Hong-you Chen",
            "Satya Narayan Shukla",
            "Abhijeet Awasthi",
            "Xichen Pan",
            "Chaitanya Ahuja",
            "Shlok Kumar Mishra",
            "Qi Guo",
            "Ser-Nam Lim",
            "Aashu Singh",
            "Xiangjun Fan"
        ],
        "pdf": "https://arxiv.org/pdf/2510.05014",
        "abstract": "There is a growing interest in Universal Multimodal Embeddings (UME), where models are required to generate task-specific representations. While recent studies show that Multimodal Large Language Models (MLLMs) perform well on such tasks, they treat MLLMs solely as encoders, overlooking their generative capacity. However, such an encoding paradigm becomes less effective as instructions become more complex and require compositional reasoning. Inspired by the proven effectiveness of chain-of-thought reasoning, we propose a general Think-Then-Embed (TTE) framework for UME, composed of a reasoner and an embedder. The reasoner MLLM first generates reasoning traces that explain complex queries, followed by an embedder that produces representations conditioned on both the original query and the intermediate reasoning. This explicit reasoning step enables more nuanced understanding of complex multimodal instructions. Our contributions are threefold. First, by leveraging a powerful MLLM reasoner, we achieve state-of-the-art performance on the MMEB-V2 benchmark, surpassing proprietary models trained on massive in-house datasets. Second, to reduce the dependency on large MLLM reasoners, we finetune a smaller MLLM reasoner using high-quality embedding-centric reasoning traces, achieving the best performance among open-source models with a 7% absolute gain over recently proposed models. Third, we investigate strategies for integrating the reasoner and embedder into a unified model for improved efficiency without sacrificing performance.",
        "tags": [
            "CoT",
            "LLM"
        ]
    },
    {
        "id": "468",
        "title": "Inoculation Prompting: Instructing LLMs to misbehave at train-time improves test-time alignment",
        "author": [
            "Nevan Wichers",
            "Aram Ebtekar",
            "Ariana Azarbal",
            "Victor Gillioz",
            "Christine Ye",
            "Emil Ryd",
            "Neil Rathi",
            "Henry Sleight",
            "Alex Mallen",
            "Fabien Roger",
            "Samuel Marks"
        ],
        "pdf": "https://arxiv.org/pdf/2510.05024",
        "abstract": "Large language models are sometimes trained with imperfect oversight signals, leading to undesired behaviors such as reward hacking and sycophancy. Improving oversight quality can be expensive or infeasible, motivating methods that improve learned behavior despite an imperfect training signal. We introduce Inoculation Prompting (IP), a simple but counterintuitive technique that prevents learning of an undesired behavior by modifying training prompts to explicitly request it. For example, to inoculate against reward hacking, we modify the prompts used in supervised fine-tuning to request code that only works on provided test cases but fails on other inputs. Across four settings we find that IP reduces the learning of undesired behavior without substantially reducing the learning of desired capabilities. We also show that prompts which more strongly elicit the undesired behavior prior to fine-tuning more effectively inoculate against the behavior when used during training; this serves as a heuristic to identify promising inoculation prompts. Overall, IP is a simple yet effective way to control how models generalize from fine-tuning, preventing learning of undesired behaviors without substantially disrupting desired capabilities.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "469",
        "title": "Imperceptible Jailbreaking against Large Language Models",
        "author": [
            "Kuofeng Gao",
            "Yiming Li",
            "Chao Du",
            "Xin Wang",
            "Xingjun Ma",
            "Shu-Tao Xia",
            "Tianyu Pang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.05025",
        "abstract": "Jailbreaking attacks on the vision modality typically rely on imperceptible adversarial perturbations, whereas attacks on the textual modality are generally assumed to require visible modifications (e.g., non-semantic suffixes). In this paper, we introduce imperceptible jailbreaks that exploit a class of Unicode characters called variation selectors. By appending invisible variation selectors to malicious questions, the jailbreak prompts appear visually identical to original malicious questions on screen, while their tokenization is \"secretly\" altered. We propose a chain-of-search pipeline to generate such adversarial suffixes to induce harmful responses. Our experiments show that our imperceptible jailbreaks achieve high attack success rates against four aligned LLMs and generalize to prompt injection attacks, all without producing any visible modifications in the written prompt. Our code is available at https://github.com/sail-sg/imperceptible-jailbreaks.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "470",
        "title": "A Set of Quebec-French Corpus of Regional Expressions and Terms",
        "author": [
            "David Beauchemin",
            "Yan Tremblay",
            "Mohamed Amine Youssef",
            "Richard Khoury"
        ],
        "pdf": "https://arxiv.org/pdf/2510.05026",
        "abstract": "The tasks of idiom understanding and dialect understanding are both well-established benchmarks in natural language processing. In this paper, we propose combining them, and using regional idioms as a test of dialect understanding. Towards this end, we propose two new benchmark datasets for the Quebec dialect of French: QFrCoRE, which contains 4,633 instances of idiomatic phrases, and QFrCoRT, which comprises 171 regional instances of idiomatic words. We explain how to construct these corpora, so that our methodology can be replicated for other dialects. Our experiments with 94 LLM demonstrate that our regional idiom benchmarks are a reliable tool for measuring a model's proficiency in a specific dialect.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "471",
        "title": "Video-LMM Post-Training: A Deep Dive into Video Reasoning with Large Multimodal Models",
        "author": [
            "Yunlong Tang",
            "Jing Bi",
            "Pinxin Liu",
            "Zhenyu Pan",
            "Zhangyun Tan",
            "Qianxiang Shen",
            "Jiani Liu",
            "Hang Hua",
            "Junjia Guo",
            "Yunzhong Xiao",
            "Chao Huang",
            "Zhiyuan Wang",
            "Susan Liang",
            "Xinyi Liu",
            "Yizhi Song",
            "Yuhe Nie",
            "Jia-Xing Zhong",
            "Bozheng Li",
            "Daiqing Qi",
            "Ziyun Zeng",
            "Ali Vosoughi",
            "Luchuan Song",
            "Zeliang Zhang",
            "Daiki Shimada",
            "Han Liu",
            "Jiebo Luo",
            "Chenliang Xu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.05034",
        "abstract": "Video understanding represents the most challenging frontier in computer vision, requiring models to reason about complex spatiotemporal relationships, long-term dependencies, and multimodal evidence. The recent emergence of Video-Large Multimodal Models (Video-LMMs), which integrate visual encoders with powerful decoder-based language models, has demonstrated remarkable capabilities in video understanding tasks. However, the critical phase that transforms these models from basic perception systems into sophisticated reasoning engines, post-training, remains fragmented across the literature. This survey provides the first comprehensive examination of post-training methodologies for Video-LMMs, encompassing three fundamental pillars: supervised fine-tuning (SFT) with chain-of-thought, reinforcement learning (RL) from verifiable objectives, and test-time scaling (TTS) through enhanced inference computation. We present a structured taxonomy that clarifies the roles, interconnections, and video-specific adaptations of these techniques, addressing unique challenges such as temporal localization, spatiotemporal grounding, long video efficiency, and multimodal evidence integration. Through systematic analysis of representative methods, we synthesize key design principles, insights, and evaluation protocols while identifying critical open challenges in reward design, scalability, and cost-performance optimization. We further curate essential benchmarks, datasets, and metrics to facilitate rigorous assessment of post-training effectiveness. This survey aims to provide researchers and practitioners with a unified framework for advancing Video-LMM capabilities. Additional resources and updates are maintained at: https://github.com/yunlong10/Awesome-Video-LMM-Post-Training",
        "tags": [
            "CoT",
            "RL"
        ]
    },
    {
        "id": "472",
        "title": "Graph-Aware Diffusion for Signal Generation",
        "author": [
            "Sergio Rozada",
            "Vimal K. B.",
            "Andrea Cavallo",
            "Antonio G. Marques",
            "Hadi Jamali-Rad",
            "Elvin Isufi"
        ],
        "pdf": "https://arxiv.org/pdf/2510.05036",
        "abstract": "We study the problem of generating graph signals from unknown distributions defined over given graphs, relevant to domains such as recommender systems or sensor networks. Our approach builds on generative diffusion models, which are well established in vision and graph generation but remain underexplored for graph signals. Existing methods lack generality, either ignoring the graph structure in the forward process or designing graph-aware mechanisms tailored to specific domains. We adopt a forward process that incorporates the graph through the heat equation. Rather than relying on the standard formulation, we consider a time-warped coefficient to mitigate the exponential decay of the drift term, yielding a graph-aware generative diffusion model (GAD). We analyze its forward dynamics, proving convergence to a Gaussian Markov random field with covariance parametrized by the graph Laplacian, and interpret the backward dynamics as a sequence of graph-signal denoising problems. Finally, we demonstrate the advantages of GAD on synthetic data, real traffic speed measurements, and a temperature sensor network.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "473",
        "title": "Guided Query Refinement: Multimodal Hybrid Retrieval with Test-Time Optimization",
        "author": [
            "Omri Uzan",
            "Asaf Yehudai",
            "Roi pony",
            "Eyal Shnarch",
            "Ariel Gera"
        ],
        "pdf": "https://arxiv.org/pdf/2510.05038",
        "abstract": "Multimodal encoders have pushed the boundaries of visual document retrieval, matching textual query tokens directly to image patches and achieving state-of-the-art performance on public benchmarks. Recent models relying on this paradigm have massively scaled the sizes of their query and document representations, presenting obstacles to deployment and scalability in real-world pipelines. Furthermore, purely vision-centric approaches may be constrained by the inherent modality gap still exhibited by modern vision-language models. In this work, we connect these challenges to the paradigm of hybrid retrieval, investigating whether a lightweight dense text retriever can enhance a stronger vision-centric model. Existing hybrid methods, which rely on coarse-grained fusion of ranks or scores, fail to exploit the rich interactions within each model's representation space. To address this, we introduce Guided Query Refinement (GQR), a novel test-time optimization method that refines a primary retriever's query embedding using guidance from a complementary retriever's scores. Through extensive experiments on visual document retrieval benchmarks, we demonstrate that GQR allows vision-centric models to match the performance of models with significantly larger representations, while being up to 14x faster and requiring 54x less memory. Our findings show that GQR effectively pushes the Pareto frontier for performance and efficiency in multimodal retrieval. We release our code at https://github.com/IBM/test-time-hybrid-retrieval",
        "tags": [
            "VLM"
        ]
    },
    {
        "id": "474",
        "title": "Test-Time Scaling in Diffusion LLMs via Hidden Semi-Autoregressive Experts",
        "author": [
            "Jihoon Lee",
            "Hoyeon Moon",
            "Kevin Zhai",
            "Arun Kumar Chithanar",
            "Anit Kumar Sahu",
            "Soummya Kar",
            "Chul Lee",
            "Souradip Chakraborty",
            "Amrit Singh Bedi"
        ],
        "pdf": "https://arxiv.org/pdf/2510.05040",
        "abstract": "Diffusion-based large language models (dLLMs) are trained flexibly to model extreme dependence in the data distribution; however, how to best utilize this information at inference time remains an open problem. In this work, we uncover an interesting property of these models: dLLMs trained on textual data implicitly learn a mixture of semi-autoregressive experts, where different generation orders reveal different specialized behaviors. We show that committing to any single, fixed inference time schedule, a common practice, collapses performance by failing to leverage this latent ensemble. To address this, we introduce HEX (Hidden semiautoregressive EXperts for test-time scaling), a training-free inference method that ensembles across heterogeneous block schedules. By doing a majority vote over diverse block-sized generation paths, HEX robustly avoids failure modes associated with any single fixed schedule. On reasoning benchmarks such as GSM8K, it boosts accuracy by up to 3.56X (from 24.72% to 88.10%), outperforming top-K margin inference and specialized fine-tuned methods like GRPO, without additional training. HEX even yields significant gains on MATH benchmark from 16.40% to 40.00%, scientific reasoning on ARC-C from 54.18% to 87.80%, and TruthfulQA from 28.36% to 57.46%. Our results establish a new paradigm for test-time scaling in diffusion-based LLMs (dLLMs), revealing that the sequence in which masking is performed plays a critical role in determining performance during inference.",
        "tags": [
            "Diffusion",
            "GRPO",
            "LLM"
        ]
    },
    {
        "id": "475",
        "title": "COLE: a Comprehensive Benchmark for French Language Understanding Evaluation",
        "author": [
            "David Beauchemin",
            "Yan Tremblay",
            "Mohamed Amine Youssef",
            "Richard Khoury"
        ],
        "pdf": "https://arxiv.org/pdf/2510.05046",
        "abstract": "To address the need for a more comprehensive evaluation of French Natural Language Understanding (NLU), we introduce COLE, a new benchmark composed of 23 diverse task covering a broad range of NLU capabilities, including sentiment analysis, paraphrase detection, grammatical judgment, and reasoning, with a particular focus on linguistic phenomena relevant to the French language. We benchmark 94 large language models (LLM), providing an extensive analysis of the current state of French NLU. Our results highlight a significant performance gap between closed- and open-weights models and identify key challenging frontiers for current LLMs, such as zero-shot extractive question-answering (QA), fine-grained word sense disambiguation, and understanding of regional language variations. We release COLE as a public resource to foster further progress in French language modelling.",
        "tags": [
            "Detection",
            "LLM"
        ]
    },
    {
        "id": "476",
        "title": "StaMo: Unsupervised Learning of Generalizable Robot Motion from Compact State Representation",
        "author": [
            "Mingyu Liu",
            "Jiuhe Shu",
            "Hui Chen",
            "Zeju Li",
            "Canyu Zhao",
            "Jiange Yang",
            "Shenyuan Gao",
            "Hao Chen",
            "Chunhua Shen"
        ],
        "pdf": "https://arxiv.org/pdf/2510.05057",
        "abstract": "A fundamental challenge in embodied intelligence is developing expressive and compact state representations for efficient world modeling and decision making. However, existing methods often fail to achieve this balance, yielding representations that are either overly redundant or lacking in task-critical information. We propose an unsupervised approach that learns a highly compressed two-token state representation using a lightweight encoder and a pre-trained Diffusion Transformer (DiT) decoder, capitalizing on its strong generative prior. Our representation is efficient, interpretable, and integrates seamlessly into existing VLA-based models, improving performance by 14.3% on LIBERO and 30% in real-world task success with minimal inference overhead. More importantly, we find that the difference between these tokens, obtained via latent interpolation, naturally serves as a highly effective latent action, which can be further decoded into executable robot actions. This emergent capability reveals that our representation captures structured dynamics without explicit supervision. We name our method StaMo for its ability to learn generalizable robotic Motion from compact State representation, which is encoded from static images, challenging the prevalent dependence to learning latent action on complex architectures and video data. The resulting latent actions also enhance policy co-training, outperforming prior methods by 10.4% with improved interpretability. Moreover, our approach scales effectively across diverse data sources, including real-world robot data, simulation, and human egocentric video.",
        "tags": [
            "DiT",
            "Diffusion",
            "Robotics",
            "Transformer"
        ]
    },
    {
        "id": "477",
        "title": "Staircase Streaming for Low-Latency Multi-Agent Inference",
        "author": [
            "Junlin Wang",
            "Jue Wang",
            "Zhen",
            "Ben Athiwaratkun",
            "Bhuwan Dhingra",
            "Ce Zhang",
            "James Zou"
        ],
        "pdf": "https://arxiv.org/pdf/2510.05059",
        "abstract": "Recent advances in large language models (LLMs) opened up new directions for leveraging the collective expertise of multiple LLMs. These methods, such as Mixture-of-Agents, typically employ additional inference steps to generate intermediate outputs, which are then used to produce the final response. While multi-agent inference can enhance response quality, it can significantly increase the time to first token (TTFT), posing a challenge for latency-sensitive applications and hurting user experience. To address this issue, we propose staircase streaming for low-latency multi-agent inference. Instead of waiting for the complete intermediate outputs from previous steps, we begin generating the final response as soon as we receive partial outputs from these steps. Experimental results demonstrate that staircase streaming reduces TTFT by up to 93% while maintaining response quality.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "478",
        "title": "Automaton Constrained Q-Learning",
        "author": [
            "Anastasios Manganaris",
            "Vittorio Giammarino",
            "Ahmed H. Qureshi"
        ],
        "pdf": "https://arxiv.org/pdf/2510.05061",
        "abstract": "Real-world robotic tasks often require agents to achieve sequences of goals while respecting time-varying safety constraints. However, standard Reinforcement Learning (RL) paradigms are fundamentally limited in these settings. A natural approach to these problems is to combine RL with Linear-time Temporal Logic (LTL), a formal language for specifying complex, temporally extended tasks and safety constraints. Yet, existing RL methods for LTL objectives exhibit poor empirical performance in complex and continuous environments. As a result, no scalable methods support both temporally ordered goals and safety simultaneously, making them ill-suited for realistic robotics scenarios. We propose Automaton Constrained Q-Learning (ACQL), an algorithm that addresses this gap by combining goal-conditioned value learning with automaton-guided reinforcement. ACQL supports most LTL task specifications and leverages their automaton representation to explicitly encode stage-wise goal progression and both stationary and non-stationary safety constraints. We show that ACQL outperforms existing methods across a range of continuous control tasks, including cases where prior methods fail to satisfy either goal-reaching or safety constraints. We further validate its real-world applicability by deploying ACQL on a 6-DOF robotic arm performing a goal-reaching task in a cluttered, cabinet-like space with safety constraints. Our results demonstrate that ACQL is a robust and scalable solution for learning robotic behaviors according to rich temporal specifications.",
        "tags": [
            "RL",
            "Robotics"
        ]
    },
    {
        "id": "479",
        "title": "Boomerang Distillation Enables Zero-Shot Model Size Interpolation",
        "author": [
            "Sara Kangaslahti",
            "Nihal V. Nayak",
            "Jonathan Geuter",
            "Marco Fumero",
            "Francesco Locatello",
            "David Alvarez-Melis"
        ],
        "pdf": "https://arxiv.org/pdf/2510.05064",
        "abstract": "Large language models (LLMs) are typically deployed under diverse memory and compute constraints. Existing approaches build model families by training each size independently, which is prohibitively expensive and provides only coarse-grained size options. In this work, we identify a novel phenomenon that we call boomerang distillation: starting from a large base model (the teacher), one first distills down to a small student and then progressively reconstructs intermediate-sized models by re-incorporating blocks of teacher layers into the student without any additional training. This process produces zero-shot interpolated models of many intermediate sizes whose performance scales smoothly between the student and teacher, often matching or surpassing pretrained or distilled models of the same size. We further analyze when this type of interpolation succeeds, showing that alignment between teacher and student through pruning and distillation is essential. Boomerang distillation thus provides a simple and efficient way to generate fine-grained model families, dramatically reducing training cost while enabling flexible adaptation across deployment environments. The code and models are available at https://github.com/dcml-lab/boomerang-distillation.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "480",
        "title": "SwiReasoning: Switch-Thinking in Latent and Explicit for Pareto-Superior Reasoning LLMs",
        "author": [
            "Dachuan Shi",
            "Abedelkadir Asi",
            "Keying Li",
            "Xiangchi Yuan",
            "Leyan Pan",
            "Wenke Lee",
            "Wen Xiao"
        ],
        "pdf": "https://arxiv.org/pdf/2510.05069",
        "abstract": "Recent work shows that, beyond discrete reasoning through explicit chain-of-thought steps, which are limited by the boundaries of natural languages, large language models (LLMs) can also reason continuously in latent space, allowing richer information per step and thereby improving token efficiency. Despite this promise, latent reasoning still faces two challenges, especially in training-free settings: 1) purely latent reasoning broadens the search distribution by maintaining multiple implicit paths, which diffuses probability mass, introduces noise, and impedes convergence to a single high-confidence solution, thereby hurting accuracy; and 2) overthinking persists even without explicit text, wasting tokens and degrading efficiency. To address these issues, we introduce SwiReasoning, a training-free framework for LLM reasoning which features two key innovations: 1) SwiReasoning dynamically switches between explicit and latent reasoning, guided by block-wise confidence estimated from entropy trends in next-token distributions, to balance exploration and exploitation and promote timely convergence. 2) By limiting the maximum number of thinking-block switches, SwiReasoning curbs overthinking and improves token efficiency across varying problem difficulties. On widely used mathematics and STEM benchmarks, SwiReasoning consistently improves average accuracy by 1.5%-2.8% across reasoning LLMs of different model families and scales. Furthermore, under constrained budgets, SwiReasoning improves average token efficiency by 56%-79%, with larger gains as budgets tighten.",
        "tags": [
            "CoT",
            "LLM"
        ]
    },
    {
        "id": "481",
        "title": "Neuroplastic Modular Framework: Cross-Domain Image Classification of Garbage and Industrial Surfaces",
        "author": [
            "Debojyoti Ghosh",
            "Soumya K Ghosh",
            "Adrijit Goswami"
        ],
        "pdf": "https://arxiv.org/pdf/2510.05071",
        "abstract": "Efficient and accurate classification of waste and industrial surface defects is essential for ensuring sustainable waste management and maintaining high standards in quality control. This paper introduces the Neuroplastic Modular Classifier, a novel hybrid architecture designed for robust and adaptive image classification in dynamic environments. The model combines a ResNet-50 backbone for localized feature extraction with a Vision Transformer (ViT) to capture global semantic context. Additionally, FAISS-based similarity retrieval is incorporated to provide a memory-like reference to previously encountered data, enriching the model's feature space. A key innovation of our architecture is the neuroplastic modular design composed of expandable, learnable blocks that dynamically grow during training when performance plateaus. Inspired by biological learning systems, this mechanism allows the model to adapt to data complexity over time, improving generalization. Beyond garbage classification, we validate the model on the Kolektor Surface Defect Dataset 2 (KolektorSDD2), which involves industrial defect detection on metal surfaces. Experimental results across domains show that the proposed architecture outperforms traditional static models in both accuracy and adaptability. The Neuroplastic Modular Classifier offers a scalable, high-performance solution for real-world image classification, with strong applicability in both environmental and industrial domains.",
        "tags": [
            "Detection",
            "Transformer",
            "ViT"
        ]
    },
    {
        "id": "482",
        "title": "Slm-mux: Orchestrating small language models for reasoning",
        "author": [
            "Chenyu Wang",
            "Zishen Wan",
            "Hao Kang",
            "Emma Chen",
            "Zhiqiang Xie",
            "Tushar Krishna",
            "Vijay Janapa Reddi",
            "Yilun Du"
        ],
        "pdf": "https://arxiv.org/pdf/2510.05077",
        "abstract": "With the rapid development of language models, the number of small language models (SLMs) has grown significantly. Although they do not achieve state-of-the-art accuracy, they are more efficient and often excel at specific tasks. This raises a natural question: can multiple SLMs be orchestrated into a system where each contributes effectively, achieving higher accuracy than any individual model? Existing orchestration methods have primarily targeted frontier models (e.g., GPT-4) and perform suboptimally when applied to SLMs. To address this gap, we propose a three-stage approach for orchestrating SLMs. First, we introduce SLM-MUX, a multi-model architecture that effectively coordinates multiple SLMs. Building on this, we develop two optimization strategies: (i) a model selection search that identifies the most complementary SLMs from a given pool, and (ii) test-time scaling tailored to SLM-MUX. Our approach delivers strong results: Compared to existing orchestration methods, our approach achieves up to 13.4% improvement on MATH, 8.8% on GPQA, and 7.0% on GSM8K. With just two SLMS, SLM-MUX outperforms Qwen 2.5 72B on GPQA and GSM8K, and matches its performance on MATH. We further provide theoretical analyses to substantiate the advantages of our method. In summary, we demonstrate that SLMs can be effectively orchestrated into more accurate and efficient systems through the proposed approach.",
        "tags": [
            "GPT",
            "Qwen"
        ]
    },
    {
        "id": "483",
        "title": "SAEdit: Token-level control for continuous image editing via Sparse AutoEncoder",
        "author": [
            "Ronen Kamenetsky",
            "Sara Dorfman",
            "Daniel Garibi",
            "Roni Paiss",
            "Or Patashnik",
            "Daniel Cohen-Or"
        ],
        "pdf": "https://arxiv.org/pdf/2510.05081",
        "abstract": "Large-scale text-to-image diffusion models have become the backbone of modern image editing, yet text prompts alone do not offer adequate control over the editing process. Two properties are especially desirable: disentanglement, where changing one attribute does not unintentionally alter others, and continuous control, where the strength of an edit can be smoothly adjusted. We introduce a method for disentangled and continuous editing through token-level manipulation of text embeddings. The edits are applied by manipulating the embeddings along carefully chosen directions, which control the strength of the target attribute. To identify such directions, we employ a Sparse Autoencoder (SAE), whose sparse latent space exposes semantically isolated dimensions. Our method operates directly on text embeddings without modifying the diffusion process, making it model agnostic and broadly applicable to various image synthesis backbones. Experiments show that it enables intuitive and efficient manipulations with continuous control across diverse attributes and domains.",
        "tags": [
            "Diffusion",
            "Image Editing",
            "Text-to-Image"
        ]
    },
    {
        "id": "484",
        "title": "TeachLM: Post-Training LLMs for Education Using Authentic Learning Data",
        "author": [
            "Janos Perczel",
            "Jin Chow",
            "Dorottya Demszky"
        ],
        "pdf": "https://arxiv.org/pdf/2510.05087",
        "abstract": "The promise of generative AI to revolutionize education is constrained by the pedagogical limits of large language models (LLMs). A major issue is the lack of access to high-quality training data that reflect the learning of actual students. Prompt engineering has emerged as a stopgap, but the ability of prompts to encode complex pedagogical strategies in rule-based natural language is inherently limited. To address this gap we introduce TeachLM - an LLM optimized for teaching through parameter-efficient fine-tuning of state-of-the-art models. TeachLM is trained on a dataset comprised of 100,000 hours of one-on-one, longitudinal student-tutor interactions maintained by Polygence, which underwent a rigorous anonymization process to protect privacy. We use parameter-efficient fine-tuning to develop an authentic student model that enables the generation of high-fidelity synthetic student-tutor dialogues. Building on this capability, we propose a novel multi-turn evaluation protocol that leverages synthetic dialogue generation to provide fast, scalable, and reproducible assessments of the dialogical capabilities of LLMs. Our evaluations demonstrate that fine-tuning on authentic learning data significantly improves conversational and pedagogical performance - doubling student talk time, improving questioning style, increasing dialogue turns by 50%, and greater personalization of instruction.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "485",
        "title": "Finish First, Perfect Later: Test-Time Token-Level Cross-Validation for Diffusion Large Language Models",
        "author": [
            "Runchu Tian",
            "Junxia Cui",
            "Xueqiang Xu",
            "Feng Yao",
            "Jingbo Shang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.05090",
        "abstract": "Diffusion large language models (dLLMs) have recently emerged as a promising alternative to autoregressive (AR) models, offering advantages such as accelerated parallel decoding and bidirectional context modeling. However, the vanilla decoding strategy in discrete dLLMs suffers from a critical limitation: once a token is accepted, it can no longer be revised in subsequent steps. As a result, early mistakes persist across iterations, harming both intermediate predictions and final output quality. To address this issue, we propose Tolerator (Token-Level Cross-Validation Refinement), a training-free decoding strategy that leverages cross-validation among predicted tokens. Unlike existing methods that follow a single progressive unmasking procedure, Tolerator introduces a two-stage process: (i) sequence fill-up and (ii) iterative refinement by remasking and decoding a subset of tokens while treating the remaining as context. This design enables previously accepted tokens to be reconsidered and corrected when necessary, leading to more reliable diffusion decoding outputs. We evaluate Tolerator on five standard benchmarks covering language understanding, code generation, and mathematics. Experiments show that our method achieves consistent improvements over the baselines under the same computational budget. These findings suggest that decoding algorithms are crucial to realizing the full potential of diffusion large language models. Code and data are publicly available.",
        "tags": [
            "Diffusion",
            "LLM"
        ]
    },
    {
        "id": "486",
        "title": "Factuality Matters: When Image Generation and Editing Meet Structured Visuals",
        "author": [
            "Le Zhuo",
            "Songhao Han",
            "Yuandong Pu",
            "Boxiang Qiu",
            "Sayak Paul",
            "Yue Liao",
            "Yihao Liu",
            "Jie Shao",
            "Xi Chen",
            "Si Liu",
            "Hongsheng Li"
        ],
        "pdf": "https://arxiv.org/pdf/2510.05091",
        "abstract": "While modern visual generation models excel at creating aesthetically pleasing natural images, they struggle with producing or editing structured visuals like charts, diagrams, and mathematical figures, which demand composition planning, text rendering, and multimodal reasoning for factual fidelity. To address this, we present the first comprehensive, systematic investigation of this domain, encompassing data construction, model training, and an evaluation benchmark. First, we construct a large-scale dataset of 1.3 million high-quality structured image pairs derived from executable drawing programs and augmented with chain-of-thought reasoning annotations. Building on it, we train a unified model that integrates a VLM with FLUX.1 Kontext via a lightweight connector for enhanced multimodal understanding. A three-stage training curriculum enables progressive feature alignment, knowledge infusion, and reasoning-augmented generation, further boosted by an external reasoner at inference time. Finally, we introduce StructBench, a novel benchmark for generation and editing with over 1,700 challenging instances, and an accompanying evaluation metric, StructScore, which employs a multi-round Q\\&A protocol to assess fine-grained factual accuracy. Evaluations of 15 models reveal that even leading closed-source systems remain far from satisfactory. Our model attains strong editing performance, and inference-time reasoning yields consistent gains across diverse architectures. By releasing the dataset, model, and benchmark, we aim to advance unified multimodal foundations for structured visuals.",
        "tags": [
            "CoT",
            "FLUX",
            "VLM"
        ]
    },
    {
        "id": "487",
        "title": "Learning to Interpret Weight Differences in Language Models",
        "author": [
            "Avichal Goel",
            "Yoon Kim",
            "Nir Shavit",
            "Tony T. Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.05092",
        "abstract": "Finetuning (pretrained) language models is a standard approach for updating their internal parametric knowledge and specializing them to new tasks and domains. However, the corresponding model weight changes (\"weight diffs\") are not generally interpretable. While inspecting the finetuning dataset can give a sense of how the model might have changed, these datasets are often not publicly available or are too large to work with directly. Towards the goal of comprehensively understanding weight diffs in natural language, we introduce Diff Interpretation Tuning (DIT), a method that trains models to describe their own finetuning-induced modifications. Our approach uses synthetic, labeled weight diffs to train a DIT adapter, which can be applied to a compatible finetuned model to make it describe how it has changed. We demonstrate in two proof-of-concept settings (reporting hidden behaviors and summarizing finetuned knowledge) that our method enables models to describe their finetuning-induced modifications using accurate natural language descriptions.",
        "tags": [
            "DiT"
        ]
    },
    {
        "id": "488",
        "title": "Character Mixing for Video Generation",
        "author": [
            "Tingting Liao",
            "Chongjian Ge",
            "Guangyi Liu",
            "Hao Li",
            "Yi Zhou"
        ],
        "pdf": "https://arxiv.org/pdf/2510.05093",
        "abstract": "Imagine Mr. Bean stepping into Tom and Jerry--can we generate videos where characters interact naturally across different worlds? We study inter-character interaction in text-to-video generation, where the key challenge is to preserve each character's identity and behaviors while enabling coherent cross-context interaction. This is difficult because characters may never have coexisted and because mixing styles often causes style delusion, where realistic characters appear cartoonish or vice versa. We introduce a framework that tackles these issues with Cross-Character Embedding (CCE), which learns identity and behavioral logic across multimodal sources, and Cross-Character Augmentation (CCA), which enriches training with synthetic co-existence and mixed-style data. Together, these techniques allow natural interactions between previously uncoexistent characters without losing stylistic fidelity. Experiments on a curated benchmark of cartoons and live-action series with 10 characters show clear improvements in identity preservation, interaction quality, and robustness to style delusion, enabling new forms of generative http://storytelling.Additional results and videos are available on our project page: https://tingtingliao.github.io/mimix/.",
        "tags": [
            "Text-to-Video",
            "Video Generation"
        ]
    },
    {
        "id": "489",
        "title": "VChain: Chain-of-Visual-Thought for Reasoning in Video Generation",
        "author": [
            "Ziqi Huang",
            "Ning Yu",
            "Gordon Chen",
            "Haonan Qiu",
            "Paul Debevec",
            "Ziwei Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.05094",
        "abstract": "Recent video generation models can produce smooth and visually appealing clips, but they often struggle to synthesize complex dynamics with a coherent chain of consequences. Accurately modeling visual outcomes and state transitions over time remains a core challenge. In contrast, large language and multimodal models (e.g., GPT-4o) exhibit strong visual state reasoning and future prediction capabilities. To bridge these strengths, we introduce VChain, a novel inference-time chain-of-visual-thought framework that injects visual reasoning signals from multimodal models into video generation. Specifically, VChain contains a dedicated pipeline that leverages large multimodal models to generate a sparse set of critical keyframes as snapshots, which are then used to guide the sparse inference-time tuning of a pre-trained video generator only at these key moments. Our approach is tuning-efficient, introduces minimal overhead and avoids dense supervision. Extensive experiments on complex, multi-step scenarios show that VChain significantly enhances the quality of generated videos.",
        "tags": [
            "GPT",
            "Video Generation"
        ]
    },
    {
        "id": "490",
        "title": "Paper2Video: Automatic Video Generation from Scientific Papers",
        "author": [
            "Zeyu Zhu",
            "Kevin Qinghong Lin",
            "Mike Zheng Shou"
        ],
        "pdf": "https://arxiv.org/pdf/2510.05096",
        "abstract": "Academic presentation videos have become an essential medium for research communication, yet producing them remains highly labor-intensive, often requiring hours of slide design, recording, and editing for a short 2 to 10 minutes video. Unlike natural video, presentation video generation involves distinctive challenges: inputs from research papers, dense multi-modal information (text, figures, tables), and the need to coordinate multiple aligned channels such as slides, subtitles, speech, and human talker. To address these challenges, we introduce PaperTalker, the first benchmark of 101 research papers paired with author-created presentation videos, slides, and speaker metadata. We further design four tailored evaluation metrics--Meta Similarity, PresentArena, PresentQuiz, and IP Memory--to measure how videos convey the paper's information to the audience. Building on this foundation, we propose PaperTalker, the first multi-agent framework for academic presentation video generation. It integrates slide generation with effective layout refinement by a novel effective tree search visual choice, cursor grounding, subtitling, speech synthesis, and talking-head rendering, while parallelizing slide-wise generation for efficiency. Experiments on Paper2Video demonstrate that the presentation videos produced by our approach are more faithful and informative than existing baselines, establishing a practical step toward automated and ready-to-use academic video generation. Our dataset, agent, and code are available at https://github.com/showlab/Paper2Video.",
        "tags": [
            "Talking Head",
            "Video Generation"
        ]
    },
    {
        "id": "491",
        "title": "Pulp Motion: Framing-aware multimodal camera and human motion generation",
        "author": [
            "Robin Courant",
            "Xi Wang",
            "David Loiseaux",
            "Marc Christie",
            "Vicky Kalogeiton"
        ],
        "pdf": "https://arxiv.org/pdf/2510.05097",
        "abstract": "Treating human motion and camera trajectory generation separately overlooks a core principle of cinematography: the tight interplay between actor performance and camera work in the screen space. In this paper, we are the first to cast this task as a text-conditioned joint generation, aiming to maintain consistent on-screen framing while producing two heterogeneous, yet intrinsically linked, modalities: human motion and camera trajectories. We propose a simple, model-agnostic framework that enforces multimodal coherence via an auxiliary modality: the on-screen framing induced by projecting human joints onto the camera. This on-screen framing provides a natural and effective bridge between modalities, promoting consistency and leading to more precise joint distribution. We first design a joint autoencoder that learns a shared latent space, together with a lightweight linear transform from the human and camera latents to a framing latent. We then introduce auxiliary sampling, which exploits this linear transform to steer generation toward a coherent framing modality. To support this task, we also introduce the PulpMotion dataset, a human-motion and camera-trajectory dataset with rich captions, and high-quality human motions. Extensive experiments across DiT- and MAR-based architectures show the generality and effectiveness of our method in generating on-frame coherent human-camera motions, while also achieving gains on textual alignment for both modalities. Our qualitative results yield more cinematographically meaningful framings setting the new state of the art for this task. Code, models and data are available in our \\href{https://www.lix.polytechnique.fr/vista/projects/2025_pulpmotion_courant/}{project page}.",
        "tags": [
            "DiT"
        ]
    },
    {
        "id": "492",
        "title": "Machine Learning and Control: Foundations, Advances, and Perspectives",
        "author": [
            "Enrique Zuazua"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03303",
        "abstract": "Control theory of dynamical systems offers a powerful framework for tackling challenges in deep neural networks and other machine learning architectures. We show that concepts such as simultaneous and ensemble controllability offer new insights into the classification and representation properties of deep neural networks while the control and optimization of static systems can be employed to better understand the performance of shallow networks. Inspired by the classical concept of turnpike, we also explore the relationship between dynamic and static neural networks, where depth is traded for width, and the role of transformers as mechanisms for accelerating classical neural network tasks. We also exploit the expressive power of neural networks (exemplified, for instance, by the Universal Approximation Theorem) to develop a novel hybrid modeling methodology, the Hybrid-Cooperative Learning (HYCO), combining mechanics and data-driven methods in a game-theoretic setting. Finally, we describe how classical properties of diffusion processes, long established in the context of partial differential equations, contribute to explaining the success of modern generative artificial intelligence (AI). We present an overview of our recent results in these areas, illustrating how control, machine learning, numerical analysis, and partial differential equations come together to motivate a fertile ground for future research.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "493",
        "title": "Mechanisms for Quantum Advantage in Global Optimization of Nonconvex Functions",
        "author": [
            "Dylan Herman",
            "Guneykan Ozgul",
            "Anuj Apte",
            "Junhyung Lyle Kim",
            "Anupam Prakash",
            "Jiayu Shen",
            "Shouvanik Chakrabarti"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03385",
        "abstract": "We present new theoretical mechanisms for quantum speedup in the global optimization of nonconvex functions, expanding the scope of quantum advantage beyond traditional tunneling-based explanations. As our main building-block, we demonstrate a rigorous correspondence between the spectral properties of SchrÃ¶dinger operators and the mixing times of classical Langevin diffusion. This correspondence motivates a mechanism for separation on functions with unique global minimum: while quantum algorithms operate on the original potential, classical diffusions correspond to a SchrÃ¶dinger operators with a WKB potential having nearly degenerate global minima. We formalize these ideas by proving that a real-space adiabatic quantum algorithm (RsAA) achieves provably polynomial-time optimization for broad families of nonconvex functions. First, for block-separable functions, we show that RsAA maintains polynomial runtime while known off-the-shelf algorithms require exponential time and structure-aware algorithms exhibit arbitrarily large polynomial runtimes. These results leverage novel non-asymptotic results in semiclassical analysis. Second, we use recent advances in the theory of intrinsic hypercontractivity to demonstrate polynomial runtimes for RsAA on appropriately perturbed strongly convex functions that lack global structure, while off-the-shelf algorithms remain exponentially bottlenecked. In contrast to prior works based on quantum tunneling, these separations do not depend on the geometry of barriers between local minima. Our theoretical claims about classical algorithm runtimes are supported by rigorous analysis and comprehensive numerical benchmarking. These findings establish a rigorous theoretical foundation for quantum advantage in continuous optimization and open new research directions connecting quantum algorithms, stochastic processes, and semiclassical analysis.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "494",
        "title": "Agile Tradespace Exploration for Space Rendezvous Mission Design via Transformers",
        "author": [
            "Yuji Takubo",
            "Daniele Gammelli",
            "Marco Pavone",
            "Simone D'Amico"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03544",
        "abstract": "Spacecraft rendezvous enables on-orbit servicing, debris removal, and crewed docking, forming the foundation for a scalable space economy. Designing such missions requires rapid exploration of the tradespace between control cost and flight time across multiple candidate targets. However, multi-objective optimization in this setting is challenging, as the underlying constraints are often highly nonconvex, and mission designers must balance accuracy (e.g., solving the full problem) with efficiency (e.g., convex relaxations), slowing iteration and limiting design agility. To address these challenges, this paper proposes an AI-powered framework that enables agile mission design for a wide range of Earth orbit rendezvous scenarios. Given the orbital information of the target spacecraft, boundary conditions, and a range of flight times, this work proposes a Transformer-based architecture that generates, in a single parallelized inference step, a set of near-Pareto optimal trajectories across varying flight times, thereby enabling rapid mission trade studies. The model is further extended to accommodate variable flight times and perturbed orbital dynamics, supporting realistic multi-objective trade-offs. Validation on chance-constrained rendezvous problems with passive safety constraints demonstrates that the model generalizes across both flight times and dynamics, consistently providing high-quality initial guesses that converge to superior solutions in fewer iterations. Moreover, the framework efficiently approximates the Pareto front, achieving runtimes comparable to convex relaxation by exploiting parallelized inference. Together, these results position the proposed framework as a practical surrogate for nonconvex trajectory generation and mark an important step toward AI-driven trajectory design for accelerating preliminary mission planning in real-world rendezvous applications.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "495",
        "title": "Dissecting Larval Zebrafish Hunting using Deep Reinforcement Learning Trained RNN Agents",
        "author": [
            "Raaghav Malik",
            "Satpreet H. Singh",
            "Sonja Johnson-Yu",
            "Nathan Wu",
            "Roy Harpaz",
            "Florian Engert",
            "Kanaka Rajan"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03699",
        "abstract": "Larval zebrafish hunting provides a tractable setting to study how ecological and energetic constraints shape adaptive behavior in both biological brains and artificial agents. Here we develop a minimal agent-based model, training recurrent policies with deep reinforcement learning in a bout-based zebrafish simulator. Despite its simplicity, the model reproduces hallmark hunting behaviors -- including eye vergence-linked pursuit, speed modulation, and stereotyped approach trajectories -- that closely match real larval zebrafish. Quantitative trajectory analyses show that pursuit bouts systematically reduce prey angle by roughly half before strike, consistent with measurements. Virtual experiments and parameter sweeps vary ecological and energetic constraints, bout kinematics (coupled vs. uncoupled turns and forward motion), and environmental factors such as food density, food speed, and vergence limits. These manipulations reveal how constraints and environments shape pursuit dynamics, strike success, and abort rates, yielding falsifiable predictions for neuroscience experiments. These sweeps identify a compact set of constraints -- binocular sensing, the coupling of forward speed and turning in bout kinematics, and modest energetic costs on locomotion and vergence -- that are sufficient for zebrafish-like hunting to emerge. Strikingly, these behaviors arise in minimal agents without detailed biomechanics, fluid dynamics, circuit realism, or imitation learning from real zebrafish data. Taken together, this work provides a normative account of zebrafish hunting as the optimal balance between energetic cost and sensory benefit, highlighting the trade-offs that structure vergence and trajectory dynamics. We establish a virtual lab that narrows the experimental search space and generates falsifiable predictions about behavior and neural coding.",
        "tags": [
            "RL",
            "RNN"
        ]
    },
    {
        "id": "496",
        "title": "Towards Robust and Generalizable Continuous Space-Time Video Super-Resolution with Events",
        "author": [
            "Shuoyan Wei",
            "Feng Li",
            "Shengeng Tang",
            "Runmin Cong",
            "Yao Zhao",
            "Meng Wang",
            "Huihui Bai"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03833",
        "abstract": "Continuous space-time video super-resolution (C-STVSR) has garnered increasing interest for its capability to reconstruct high-resolution and high-frame-rate videos at arbitrary spatial and temporal scales. However, prevailing methods often generalize poorly, producing unsatisfactory results when applied to out-of-distribution (OOD) scales. To overcome this limitation, we present EvEnhancer, a novel approach that marries the unique properties of high temporal resolution and high dynamic range encapsulated in event streams to achieve robust and generalizable C-STVSR. Our approach incorporates event-adapted synthesis that capitalizes on the spatiotemporal correlations between frames and events to capture long-term motion trajectories, enabling adaptive interpolation and fusion across space and time. This is then coupled with a local implicit video transformer that integrates local implicit video neural function with cross-scale spatiotemporal attention to learn continuous video representations and generate plausible videos at arbitrary resolutions and frame rates. We further develop EvEnhancerPlus, which builds a controllable switching mechanism that dynamically determines the reconstruction difficulty for each spatiotemporal pixel based on local event statistics. This allows the model to adaptively route reconstruction along the most suitable pathways at a fine-grained pixel level, substantially reducing computational overhead while maintaining excellent performance. Furthermore, we devise a cross-derivative training strategy that stabilizes the convergence of such a multi-pathway framework through staged cross-optimization. Extensive experiments demonstrate that our method achieves state-of-the-art performance on both synthetic and real-world datasets, while maintaining superior generalizability at OOD scales. The code is available at https://github.com/W-Shuoyan/EvEnhancerPlus.",
        "tags": [
            "Super Resolution",
            "Transformer"
        ]
    },
    {
        "id": "497",
        "title": "Sliding Window Attention for Learned Video Compression",
        "author": [
            "Alexander Kopte",
            "AndrÃ© Kaup"
        ],
        "pdf": "https://arxiv.org/pdf/2510.03926",
        "abstract": "To manage the complexity of transformers in video compression, local attention mechanisms are a practical necessity. The common approach of partitioning frames into patches, however, creates architectural flaws like irregular receptive fields. When adapted for temporal autoregressive models, this paradigm, exemplified by the Video Compression Transformer (VCT), also necessitates computationally redundant overlapping windows. This work introduces 3D Sliding Window Attention (SWA), a patchless form of local attention. By enabling a decoder-only architecture that unifies spatial and temporal context processing, and by providing a uniform receptive field, our method significantly improves rate-distortion performance, achieving BjÃ¸rntegaard Delta-rate savings of up to 18.6 % against the VCT baseline. Simultaneously, by eliminating the need for overlapping windows, our method reduces overall decoder complexity by a factor of 2.8, while its entropy model is nearly 3.5 times more efficient. We further analyze our model's behavior and show that while it benefits from long-range temporal context, excessive context can degrade performance.",
        "tags": [
            "3D",
            "Transformer"
        ]
    },
    {
        "id": "498",
        "title": "MoME: Mixture of Matryoshka Experts for Audio-Visual Speech Recognition",
        "author": [
            "Umberto Cappellazzo",
            "Minsu Kim",
            "Pingchuan Ma",
            "Honglie Chen",
            "Xubo Liu",
            "Stavros Petridis",
            "Maja Pantic"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04136",
        "abstract": "Large language models (LLMs) have recently shown strong potential in audio-visual speech recognition (AVSR), but their high computational demands and sensitivity to token granularity limit their practicality in resource-constrained settings. Token compression methods can reduce inference cost, but they require fixing a compression rate in advance and produce a single fixed-length output, offering no flexibility to balance information density and efficiency at inference time. Matryoshka representation learning (MRL) addresses this by enabling a single model to operate across multiple token granularities, allowing compression rates to be adjusted dynamically. However, current MRL-based methods treat each scale independently during training, limiting cross-scale generalization, robustness at high compression, and interpretability. To overcome these limitations, we propose MoME (Mixture of Matryoshka Experts), a novel framework that integrates sparse Mixture-of-Experts (MoE) into MRL-based LLMs for AVSR. MoME augments a frozen LLM with top-k routed and shared experts, allowing dynamic capacity allocation across scales and modalities. A shared router promotes consistent expert activation across granularities, enabling compressed sequences to benefit from representations learned at lower compression. Experiments on LRS2 and LRS3 demonstrate that MoME achieves state-of-the-art performance across AVSR, ASR, and VSR tasks, while requiring significantly fewer parameters and maintaining robustness under noise. MoME unifies the adaptability of MRL with the efficiency of MoE, offering a scalable and interpretable solution for resource-aware speech recognition.",
        "tags": [
            "LLM",
            "MoE"
        ]
    },
    {
        "id": "499",
        "title": "Drax: Speech Recognition with Discrete Flow Matching",
        "author": [
            "Aviv Navon",
            "Aviv Shamsian",
            "Neta Glazer",
            "Yael Segal-Feldman",
            "Gill Hetz",
            "Joseph Keshet",
            "Ethan Fetaya"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04162",
        "abstract": "Diffusion and flow-based non-autoregressive (NAR) models have shown strong promise in large language modeling, however, their potential for automatic speech recognition (ASR) remains largely unexplored. We propose Drax, a discrete flow matching framework for ASR that enables efficient parallel decoding. To better align training with inference, we construct an audio-conditioned probability path that guides the model through trajectories resembling likely intermediate inference errors, rather than direct random noise to target transitions. Our theoretical analysis links the generalization gap to divergences between training and inference occupancies, controlled by cumulative velocity errors, thereby motivating our design choice. Empirical evaluation demonstrates that our approach attains recognition accuracy on par with state-of-the-art speech models while offering improved accuracy-efficiency trade-offs, highlighting discrete flow matching as a promising direction for advancing NAR ASR.",
        "tags": [
            "Diffusion",
            "Flow Matching"
        ]
    },
    {
        "id": "500",
        "title": "Enhancing Speaker Verification with w2v-BERT 2.0 and Knowledge Distillation guided Structured Pruning",
        "author": [
            "Ze Li",
            "Ming Cheng",
            "Ming Li"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04213",
        "abstract": "Large-scale self-supervised Pre-Trained Models (PTMs) have shown significant improvements in the speaker verification (SV) task by providing rich feature representations. In this paper, we utilize w2v-BERT 2.0, a model with approximately 600 million parameters trained on 450 million hours of unlabeled data across 143 languages, for the SV task. The MFA structure with Layer Adapter is employed to process the multi-layer feature outputs from the PTM and extract speaker embeddings. Additionally, we incorporate LoRA for efficient fine-tuning. Our model achieves state-of-the-art results with 0.12% and 0.55% EER on the Vox1-O and Vox1-H test sets, respectively. Furthermore, we apply knowledge distillation guided structured pruning, reducing the model size by 80% while achieving only a 0.04% EER degradation. Source code and models are released at https://github.com/ZXHY-82/w2v-BERT-2.0_SV.",
        "tags": [
            "BERT",
            "LoRA"
        ]
    },
    {
        "id": "501",
        "title": "spd-metrics-id: A Python Package for SPD-Aware Distance Metrics in Connectome Fingerprinting and Beyond",
        "author": [
            "Kaosar Uddin"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04438",
        "abstract": "We present spd-metrics-id, a Python package for computing distances and divergences between symmetric positive-definite (SPD) matrices. Unlike traditional toolkits that focus on specific applications, spd-metrics-id provides a unified, extensible, and reproducible framework for SPD distance computation. The package supports a wide variety of geometry-aware metrics, including Alpha-z Bures-Wasserstein, Alpha-Procrustes, affine-invariant Riemannian, log-Euclidean, and others, and is accessible both via a command-line interface and a Python API. Reproducibility is ensured through Docker images and Zenodo archiving. We illustrate usage through a connectome fingerprinting example, but the package is broadly applicable to covariance analysis, diffusion tensor imaging, and other domains requiring SPD matrix comparison. The package is openly available at https://pypi.org/project/spd-metrics-id/.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "502",
        "title": "Learning Linear Regression with Low-Rank Tasks in-Context",
        "author": [
            "Kaito Takanami",
            "Takashi Takahashi",
            "Yoshiyuki Kabashima"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04548",
        "abstract": "In-context learning (ICL) is a key building block of modern large language models, yet its theoretical mechanisms remain poorly understood. It is particularly mysterious how ICL operates in real-world applications where tasks have a common structure. In this work, we address this problem by analyzing a linear attention model trained on low-rank regression tasks. Within this setting, we precisely characterize the distribution of predictions and the generalization error in the high-dimensional limit. Moreover, we find that statistical fluctuations in finite pre-training data induce an implicit regularization. Finally, we identify a sharp phase transition of the generalization error governed by task structure. These results provide a framework for understanding how transformers learn to learn the task structure.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "503",
        "title": "UniVoice: Unifying Autoregressive ASR and Flow-Matching based TTS with Large Language Models",
        "author": [
            "Wenhao Guan",
            "Zhikang Niu",
            "Ziyue Jiang",
            "Kaidi Wang",
            "Peijie Chen",
            "Qingyang Hong",
            "Lin Li",
            "Xie Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04593",
        "abstract": "Large language models (LLMs) have demonstrated promising performance in both automatic speech recognition (ASR) and text-to-speech (TTS) systems, gradually becoming the mainstream approach. However, most current approaches address these tasks separately rather than through a unified framework. This work aims to integrate these two tasks into one unified model. Although discrete speech tokenization enables joint modeling, its inherent information loss limits performance in both recognition and generation. In this work, we present UniVoice, a unified LLM framework through continuous representations that seamlessly integrates speech recognition and synthesis within a single model. Our approach combines the strengths of autoregressive modeling for speech recognition with flow matching for high-quality generation. To mitigate the inherent divergence between autoregressive and flow-matching models, we further design a dual attention mechanism, which switches between a causal mask for recognition and a bidirectional attention mask for synthesis. Furthermore, the proposed text-prefix-conditioned speech infilling method enables high-fidelity zero-shot voice cloning. Experimental results demonstrate that our method can achieve or exceed current single-task modeling methods in both ASR and zero-shot TTS tasks. This work explores new possibilities for end-to-end speech understanding and generation.",
        "tags": [
            "Flow Matching",
            "LLM"
        ]
    },
    {
        "id": "504",
        "title": "AtomWorld: A Benchmark for Evaluating Spatial Reasoning in Large Language Models on Crystalline Materials",
        "author": [
            "Taoyuze Lv",
            "Alexander Chen",
            "Fengyu Xie",
            "Chu Wu",
            "Jeffrey Meng",
            "Dongzhan Zhou",
            "Bram Hoex",
            "Zhicheng Zhong",
            "Tong Xie"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04704",
        "abstract": "Large Language Models (LLMs) excel at textual reasoning and are beginning to develop spatial understanding, prompting the question of whether these abilities can be combined for complex, domain-specific tasks. This question is essential in fields like materials science, where deep understanding of 3D atomic structures is fundamental. While initial studies have successfully applied LLMs to tasks involving pure crystal generation or coordinate understandings, a standardized benchmark to systematically evaluate their core reasoning abilities across diverse atomic structures has been notably absent. To address this gap, we introduce the AtomWorld benchmark to evaluate LLMs on tasks based in Crystallographic Information Files (CIFs), a standard structure representation format. These tasks, including structural editing, CIF perception, and property-guided modeling, reveal a critical limitation: current models, despite establishing promising baselines, consistently fail in structural understanding and spatial reasoning. Our experiments show that these models make frequent errors on structure modification tasks, and even in the basic CIF format understandings, potentially leading to cumulative errors in subsequent analysis and materials insights. By defining these standardized tasks, AtomWorld lays the ground for advancing LLMs toward robust atomic-scale modeling, crucial for accelerating materials research and automating scientific workflows.",
        "tags": [
            "3D",
            "LLM"
        ]
    },
    {
        "id": "505",
        "title": "Fisher-Bingham-like normalizing flows on the sphere",
        "author": [
            "Thorsten GlÃ¼senkamp"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04762",
        "abstract": "A generic D-dimensional Gaussian can be conditioned or projected onto the D-1 unit sphere, thereby leading to the well-known Fisher-Bingham (FB) or Angular Gaussian (AG) distribution families, respectively. These are some of the most fundamental distributions on the sphere, yet cannot straightforwardly be written as a normalizing flow except in two special cases: the von-Mises Fisher in D=3 and the central angular Gaussian in any D. In this paper, we describe how to generalize these special cases to a family of normalizing flows that behave similarly to the full FB or AG family in any D. We call them \"zoom-linear-project\" (ZLP)-Fisher flows. Unlike a normal Fisher-Bingham distribution, their composition allows to gradually add complexity as needed. Furthermore, they can naturally handle conditional density estimation with target distributions that vary by orders of magnitude in scale - a setting that is important in astronomical applications but that existing flows often struggle with. A particularly useful member of the new family is the Kent analogue that can cheaply upgrade any flow in this situation to yield better performance.",
        "tags": [
            "Normalizing Flows"
        ]
    },
    {
        "id": "506",
        "title": "Steady-State Spread Bounds for Graph Diffusion via Laplacian Regularisation",
        "author": [
            "Ardavan Rahimian"
        ],
        "pdf": "https://arxiv.org/pdf/2510.04924",
        "abstract": "We study how far a diffusion process on a graph can drift from a designed starting pattern when that pattern is produced using Laplacian regularisation. Under standard stability conditions for undirected, entrywise nonnegative graphs, we give a closed-form, instance-specific upper bound on the steady-state spread, measured as the relative change between the final and initial profiles. The bound separates two effects: (i) an irreducible term determined by the graph's maximum node degree, and (ii) a design-controlled term that shrinks as the regularisation strength increases (following an inverse square-root law). This leads to a simple design rule: given any target limit on spread, one can choose a sufficient regularisation strength in closed form. Although one motivating application is array beamforming, where the initial pattern is the squared magnitude of the beamformer weights, the result applies to any scenario that first enforces Laplacian smoothness and then evolves by linear diffusion on a graph. Overall, the guarantee is non-asymptotic, easy to compute, and certifies how much steady-state deviation can occur.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "507",
        "title": "Curiosity-Driven Co-Development of Action and Language in Robots Through Self-Exploration",
        "author": [
            "Theodore Jerome Tinker",
            "Kenji Doya",
            "Jun Tani"
        ],
        "pdf": "https://arxiv.org/pdf/2510.05013",
        "abstract": "Human infants acquire language and action co-developmentally, achieving remarkable generalization capabilities from only a minimal number of learning examples. In contrast, recent large language models require exposure to billions of training tokens to achieve such generalization. What mechanisms underlie such efficient developmental learning in humans? This study addresses this question through simulation experiments in which robots learn to perform various actions corresponding to imperative sentences (e.g., \\textit{push red cube}) via trials of self-guided exploration. Our approach integrates the active inference framework with reinforcement learning, enabling curiosity-driven developmental learning. The simulations yielded several nontrivial findings: i) Curiosity-driven exploration combined with motor noise substantially outperforms learning without curiosity. ii) Simpler, prerequisite-like actions emerge earlier in development, while more complex actions involving these prerequisites develop later. iii) Rote pairing of sentences and actions occurs before the emergence of compositional generalization. iv) Generalization is drastically improved as the number of compositional elements increases. These results shed light into possible mechanisms underlying efficient co-developmental learning in infants and provide computational parallels to findings in developmental psychology.",
        "tags": [
            "LLM",
            "RL"
        ]
    },
    {
        "id": "508",
        "title": "Large Language Models Achieve Gold Medal Performance at International Astronomy & Astrophysics Olympiad",
        "author": [
            "Lucas Carrit Delgado Pinheiro",
            "Ziru Chen",
            "Bruno Caixeta Piazza",
            "Ness Shroff",
            "Yingbin Liang",
            "Yuan-Sen Ting",
            "Huan Sun"
        ],
        "pdf": "https://arxiv.org/pdf/2510.05016",
        "abstract": "While task-specific demonstrations show early success in applying large language models (LLMs) to automate some astronomical research tasks, they only provide incomplete views of all necessary capabilities in solving astronomy problems, calling for more thorough understanding of LLMs' strengths and limitations. So far, existing benchmarks and evaluations focus on simple question-answering that primarily tests astronomical knowledge and fails to evaluate the complex reasoning required for real-world research in the discipline. Here, we address this gap by systematically benchmarking five state-of-the-art LLMs on the International Olympiad on Astronomy and Astrophysics (IOAA) exams, which are designed to examine deep conceptual understanding, multi-step derivations, and multimodal analysis. With average scores of 85.6% and 84.2%, Gemini 2.5 Pro and GPT-5 (the two top-performing models) not only achieve gold medal level performance but also rank in the top two among ~200-300 participants in all four IOAA theory exams evaluated (2022-2025). In comparison, results on the data analysis exams show more divergence. GPT-5 still excels in the exams with an 88.5% average score, ranking top 10 among the participants in the four most recent IOAAs, while other models' performances drop to 48-76%. Furthermore, our in-depth error analysis underscores conceptual reasoning, geometric reasoning, and spatial visualization (52-79% accuracy) as consistent weaknesses among all LLMs. Hence, although LLMs approach peak human performance in theory exams, critical gaps must be addressed before they can serve as autonomous research agents in astronomy.",
        "tags": [
            "GPT",
            "LLM"
        ]
    }
]