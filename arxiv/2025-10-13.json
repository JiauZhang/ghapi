[
    {
        "id": "1",
        "title": "Comparative Analysis of Large Language Models for the Machine-Assisted Resolution of User Intentions",
        "author": [
            "Justus Flerlage",
            "Alexander Acker",
            "Odej Kao"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08576",
        "abstract": "Large Language Models (LLMs) have emerged as transformative tools for natural language understanding and user intent resolution, enabling tasks such as translation, summarization, and, increasingly, the orchestration of complex workflows. This development signifies a paradigm shift from conventional, GUI-driven user interfaces toward intuitive, language-first interaction paradigms. Rather than manually navigating applications, users can articulate their objectives in natural language, enabling LLMs to orchestrate actions across multiple applications in a dynamic and contextual manner. However, extant implementations frequently rely on cloud-based proprietary models, which introduce limitations in terms of privacy, autonomy, and scalability. For language-first interaction to become a truly robust and trusted interface paradigm, local deployment is not merely a convenience; it is an imperative. This limitation underscores the importance of evaluating the feasibility of locally deployable, open-source, and open-access LLMs as foundational components for future intent-based operating systems. In this study, we examine the capabilities of several open-source and open-access models in facilitating user intention resolution through machine assistance. A comparative analysis is conducted against OpenAI's proprietary GPT-4-based systems to assess performance in generating workflows for various user intentions. The present study offers empirical insights into the practical viability, performance trade-offs, and potential of open LLMs as autonomous, locally operable components in next-generation operating systems. The results of this study inform the broader discussion on the decentralization and democratization of AI infrastructure and point toward a future where user-device interaction becomes more seamless, adaptive, and privacy-conscious through locally embedded intelligence.",
        "tags": [
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "2",
        "title": "LadderSym: A Multimodal Interleaved Transformer for Music Practice Error Detection",
        "author": [
            "Benjamin Shiue-Hal Chou",
            "Purvish Jajal",
            "Nick John Eliopoulos",
            "James C. Davis",
            "George K. Thiruvathukal",
            "Kristen Yeon-Ji Yun",
            "Yung-Hsiang Lu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08580",
        "abstract": "Music learners can greatly benefit from tools that accurately detect errors in their practice. Existing approaches typically compare audio recordings to music scores using heuristics or learnable models. This paper introduces \\textit{LadderSym}, a novel Transformer-based method for music error detection. \\textit{LadderSym} is guided by two key observations about the state-of-the-art approaches: (1) late fusion limits inter-stream alignment and cross-modality comparison capability; and (2) reliance on score audio introduces ambiguity in the frequency spectrum, degrading performance in music with concurrent notes. To address these limitations, \\textit{LadderSym} introduces (1) a two-stream encoder with inter-stream alignment modules to improve audio comparison capabilities and error detection F1 scores, and (2) a multimodal strategy that leverages both audio and symbolic scores by incorporating symbolic representations as decoder prompts, reducing ambiguity and improving F1 scores. We evaluate our method on the \\textit{MAESTRO-E} and \\textit{CocoChorales-E} datasets by measuring the F1 score for each note category. Compared to the previous state of the art, \\textit{LadderSym} more than doubles F1 for missed notes on \\textit{MAESTRO-E} (26.8\\% $\\rightarrow$ 56.3\\%) and improves extra note detection by 14.4 points (72.0\\% $\\rightarrow$ 86.4\\%). Similar gains are observed on \\textit{CocoChorales-E}. This work introduces general insights about comparison models that could inform sequence evaluation tasks for reinforcement Learning, human skill assessment, and model evaluation.",
        "tags": [
            "Detection",
            "RL",
            "Transformer"
        ]
    },
    {
        "id": "3",
        "title": "Evaluating Hallucinations in Multimodal LLMs with Spoken Queries under Diverse Acoustic Conditions",
        "author": [
            "Hansol Park",
            "Hoseong Ahn",
            "Junwon Moon",
            "Yejin Lee",
            "Kyuhong Shim"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08581",
        "abstract": "Hallucinations in vision-language models have been extensively studied using benchmarks that probe reliability in image-text settings. In contrast, the effect of spoken queries on multimodal hallucinations remains largely unexplored, despite the growing role of voice-driven interfaces. In this work, we investigate how spoken input influences hallucinations in multimodal large language models. We present RePOPE-Spk, an audio-augmented extension of the RePOPE benchmark, where queries are provided as speech under diverse acoustic conditions. Using RePOPE-Spk, we systematically evaluate both proprietary and open-source models. Experimental results show that hallucinations escalate when queries are spoken rather than written: error rates increase by 3% under clean speech and by up to 20% with environmental noise. Input order and query length further affect robustness, while strategies such as many-shot prompting and chain-of-thought reasoning offer partial but insufficient mitigation. These findings highlight a critical and underexplored challenge, opening new directions for building reliable voice interface systems.",
        "tags": [
            "CoT",
            "LLM",
            "VLM"
        ]
    },
    {
        "id": "4",
        "title": "A Neural Surrogate-Enhanced Multi-Method Framework for Robust Wing Design Optimization",
        "author": [
            "Arash Fath Lipaei",
            "AmirHossein Ghaemi",
            "Melika Sabzikari"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08582",
        "abstract": "This paper introduces a modular and scalable design optimization framework for the wing design process that enables faster early-phase design while ensuring aerodynamic stability. The pipeline starts with the generation of initial wing geometries and then proceeds to optimize the wing using several algorithms. Aerodynamic performance is assessed using a Vortex Lattice Method (VLM) applied to a carefully selected dataset of wing configurations. These results are employed to develop surrogate neural network models, which can predict lift and drag rapidly and accurately. The stability evaluation is implemented by setting the control surfaces and components to fixed positions in order to have realistic flight dynamics. The approach unifies and compares several optimization techniques, including Particle Swarm Optimization (PSO), Genetic Algorithms (GA), gradient-based MultiStart methods, Bayesian optimization, and Lipschitz optimization. Each method ensures constraint management via adaptive strategies and penalty functions, where the targets for lift and design feasibility are enforced. The progression of aerodynamic characteristics and geometries over the optimization iterations will be investigated in order to clarify each algorithm's convergence characteristics and performance efficiency. Our results show improvement in aerodynamic qualities and robust stability properties, offering a mechanism for wing design at speed and precision. In the interest of reproducibility and community development, the complete implementation is publicly available at https://github.com/AmirHosseinGhaemi2000/CHIMERA.",
        "tags": [
            "VLM"
        ]
    },
    {
        "id": "5",
        "title": "EGSTalker: Real-Time Audio-Driven Talking Head Generation with Efficient Gaussian Deformation",
        "author": [
            "Tianheng Zhu",
            "Yinfeng Yu",
            "Liejun Wang",
            "Fuchun Sun",
            "Wendong Zheng"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08587",
        "abstract": "This paper presents EGSTalker, a real-time audio-driven talking head generation framework based on 3D Gaussian Splatting (3DGS). Designed to enhance both speed and visual fidelity, EGSTalker requires only 3-5 minutes of training video to synthesize high-quality facial animations. The framework comprises two key stages: static Gaussian initialization and audio-driven deformation. In the first stage, a multi-resolution hash triplane and a Kolmogorov-Arnold Network (KAN) are used to extract spatial features and construct a compact 3D Gaussian representation. In the second stage, we propose an Efficient Spatial-Audio Attention (ESAA) module to fuse audio and spatial cues, while KAN predicts the corresponding Gaussian deformations. Extensive experiments demonstrate that EGSTalker achieves rendering quality and lip-sync accuracy comparable to state-of-the-art methods, while significantly outperforming them in inference speed. These results highlight EGSTalker's potential for real-time multimedia applications.",
        "tags": [
            "3D",
            "Gaussian Splatting",
            "KAN",
            "Talking Head"
        ]
    },
    {
        "id": "6",
        "title": "Beyond CNNs: Efficient Fine-Tuning of Multi-Modal LLMs for Object Detection on Low-Data Regimes",
        "author": [
            "Nirmal Elamon",
            "Rouzbeh Davoudi"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08589",
        "abstract": "The field of object detection and understanding is rapidly evolving, driven by advances in both traditional CNN-based models and emerging multi-modal large language models (LLMs). While CNNs like ResNet and YOLO remain highly effective for image-based tasks, recent transformer-based LLMs introduce new capabilities such as dynamic context reasoning, language-guided prompts, and holistic scene understanding. However, when used out-of-the-box, the full potential of LLMs remains underexploited, often resulting in suboptimal performance on specialized visual tasks. In this work, we conduct a comprehensive comparison of fine-tuned traditional CNNs, zero-shot pre-trained multi-modal LLMs, and fine-tuned multi-modal LLMs on the challenging task of artificial text overlay detection in images. A key contribution of our study is demonstrating that LLMs can be effectively fine-tuned on very limited data (fewer than 1,000 images) to achieve up to 36% accuracy improvement, matching or surpassing CNN-based baselines that typically require orders of magnitude more data. By exploring how language-guided models can be adapted for precise visual understanding with minimal supervision, our work contributes to the broader effort of bridging vision and language, offering novel insights into efficient cross-modal learning strategies. These findings highlight the adaptability and data efficiency of LLM-based approaches for real-world object detection tasks and provide actionable guidance for applying multi-modal transformers in low-resource visual environments. To support continued progress in this area, we have made the code used to fine-tune the models available in our GitHub, enabling future improvements and reuse in related applications.",
        "tags": [
            "Detection",
            "LLM",
            "Transformer"
        ]
    },
    {
        "id": "7",
        "title": "The Enduring Dominance of Deep Neural Networks: A Critical Analysis of the Fundamental Limitations of Quantum Machine Learning and Spiking Neural Networks",
        "author": [
            "Takehiro Ishikawa"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08591",
        "abstract": "Recent advancements in QML and SNNs have generated considerable excitement, promising exponential speedups and brain-like energy efficiency to revolutionize AI. However, this paper argues that they are unlikely to displace DNNs in the near term. QML struggles with adapting backpropagation due to unitary constraints, measurement-induced state collapse, barren plateaus, and high measurement overheads, exacerbated by the limitations of current noisy intermediate-scale quantum hardware, overfitting risks due to underdeveloped regularization techniques, and a fundamental misalignment with machine learning's generalization. SNNs face restricted representational bandwidth, struggling with long-range dependencies and semantic encoding in language tasks due to their discrete, spike-based processing. Furthermore, the goal of faithfully emulating the brain might impose inherent inefficiencies like cognitive biases, limited working memory, and slow learning speeds. Even their touted energy-efficient advantages are overstated; optimized DNNs with quantization can outperform SNNs in energy costs under realistic conditions. Finally, SNN training incurs high computational overhead from temporal unfolding. In contrast, DNNs leverage efficient backpropagation, robust regularization, and innovations in LRMs that shift scaling to inference-time compute, enabling self-improvement via RL and search algorithms like MCTS while mitigating data scarcity. This superiority is evidenced by recent models such as xAI's Grok-4 Heavy, which advances SOTA performance, and gpt-oss-120b, which surpasses or approaches the performance of leading industry models despite its modest 120-billion-parameter size deployable on a single 80GB GPU. Furthermore, specialized ASICs amplify these efficiency gains. Ultimately, QML and SNNs may serve niche hybrid roles, but DNNs remain the dominant, practical paradigm for AI advancement.",
        "tags": [
            "GPT",
            "RL"
        ]
    },
    {
        "id": "8",
        "title": "Less Diverse, Less Safe: The Indirect But Pervasive Risk of Test-Time Scaling in Large Language Models",
        "author": [
            "Shahriar Kabir Nahin",
            "Hadi Askari",
            "Muhao Chen",
            "Anshuman Chhabra"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08592",
        "abstract": "Test-Time Scaling (TTS) improves LLM reasoning by exploring multiple candidate responses and then operating over this set to find the best output. A tacit premise behind TTS is that sufficiently diverse candidate pools enhance reliability. In this work, we show that this assumption in TTS introduces a previously unrecognized failure mode. When candidate diversity is curtailed, even by a modest amount, TTS becomes much more likely to produce unsafe outputs. We present a reference-guided diversity reduction protocol (RefDiv) that serves as a diagnostic attack to stress test TTS pipelines. Through extensive experiments across four open-source models (Qwen3, Mistral, Llama3.1, Gemma3) and two widely used TTS strategies (Monte Carlo Tree Search and Best-of-N), constraining diversity consistently signifies the rate at which TTS produces unsafe results. The effect is often stronger than that produced by prompts directly with high adversarial intent scores. This observed phenomenon also transfers across TTS strategies and to closed-source models (e.g. OpenAI o3 and Gemini-2.5-Pro), thus indicating that this is a general and extant property of TTS rather than a model-specific artifact. Additionally, we find that numerous widely used safety guardrail classifiers (e.g. Llama-Guard and OpenAI Moderation API), are unable to flag the adversarial input prompts generated by RefDiv, demonstrating that existing defenses offer limited protection against this diversity-driven failure mode. Through this work, we hope to motivate future research on designing robust TTS strategies that are both effective and secure against diversity-targeted stress tests as illustrated by RefDiv.",
        "tags": [
            "LLM",
            "LLaMA"
        ]
    },
    {
        "id": "9",
        "title": "Systematic Diagnosis of Brittle Reasoning in Large Language Models",
        "author": [
            "V. S. Raghu Parupudi"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08595",
        "abstract": "A central question in artificial intelligence is the extent to which machine learning models comprehend mathematics. To address this, we propose a novel framework for measuring mathematical reasoning that moves beyond standard benchmarks to diagnose specific failure points. Our method first generates structured, step-by-step reasoning from gpt-3.5-turbo on the GSM8K dataset. We then use a more capable analyst model, gpt-4o-mini, to categorize errors and, crucially, perform an unsupervised clustering of every reasoning sentence to identify emergent \"reasoning modes.\" This analysis reveals a cognitive profile with a stark, nonhuman-like brittleness: while the model achieves near-perfect accuracy on procedural modes like sequential calculation, its performance on modes requiring combinatorial reasoning with restrictions plummets. By identifying and quantifying the reliability of these distinct reasoning skills, our work provides a more granular method to evaluate mathematical comprehension and offers a precise roadmap for developing new capabilities and more reliable future applications.",
        "tags": [
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "10",
        "title": "Confidence, Not Perplexity: A Better Metric for the Creative Era of LLMs",
        "author": [
            "V. S. Raghu Parupudi"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08596",
        "abstract": "Reference-free metrics like self-perplexity are strongly biased against creative text generation. We propose the Confidence Score (CS), derived from a model's output probability distribution, as a less biased alternative. Experiments on gpt-4o-mini show that while fluency-based metrics prefer novel responses in 0\\% of cases on 99 creative prompts, our CS does so 19% of the time, a statistically significant difference (95% CI for difference: [11.1%, 27.3%]). We also show that CS effectively distinguishes between easy, medium, and hard tasks, confirmed by non-overlapping confidence intervals. The Confidence Score thus mitigates the creativity bias of traditional metrics while retaining their core evaluative strengths, offering a more balanced assessment for modern LLMs.",
        "tags": [
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "11",
        "title": "Recover-LoRA: Data-Free Accuracy Recovery of Degraded Language Models via Low-Rank Adaptation",
        "author": [
            "Devleena Das",
            "Rajeev Patwari",
            "Ashish Sirasao"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08600",
        "abstract": "Inference optimizations such as quantization, pruning, format and datatype conversion, model export, and serialization can lead to functional degradations in language model task performance. While most efforts on performance recovery for deployment focus on robust quantization techniques, we focus on recovering model accuracies from any sources that degrade model weights, such as improper model serialization. In this work, we propose Recover-LoRA, a lightweight and dataset agnostic method to recover accuracy in degraded models. Recover-LoRA uses synthetic data and logit distillation to learn LoRA adapters on selective layers that facilitate aligning the degraded model to its full precision model. We investigate the utility of Recover-LoRA across a diverse set of small language models (SLMs), including models with varying attention architectures, multi-head attention (MHA) and group-query attention (GQA), as well as several evaluation datasets. Our results show that Recover-LoRA recovers model accuracies by 5-17% on MHA and GQA SLMs.",
        "tags": [
            "LoRA"
        ]
    },
    {
        "id": "12",
        "title": "Mnemosyne: An Unsupervised, Human-Inspired Long-Term Memory Architecture for Edge-Based LLMs",
        "author": [
            "Aneesh Jonelagadda",
            "Christina Hahn",
            "Haoze Zheng",
            "Salvatore Penachio"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08601",
        "abstract": "Long-term memory is essential for natural, realistic dialogue. However, current large language model (LLM) memory systems rely on either brute-force context expansion or static retrieval pipelines that fail on edge-constrained devices. We introduce Mnemosyne, an unsupervised, human-inspired long-term memory architecture designed for edge-based LLMs. Our approach uses graph-structured storage, modular substance and redundancy filters, memory committing and pruning mechanisms, and probabilistic recall with temporal decay and refresh processes modeled after human memory. Mnemosyne also introduces a concentrated \"core summary\" efficiently derived from a fixed-length subset of the memory graph to capture the user's personality and other domain-specific long-term details such as, using healthcare application as an example, post-recovery ambitions and attitude towards care. Unlike existing retrieval-augmented methods, Mnemosyne is designed for use in longitudinal healthcare assistants, where repetitive and semantically similar but temporally distinct conversations are limited by naive retrieval. In experiments with longitudinal healthcare dialogues, Mnemosyne demonstrates the highest win rate of 65.8% in blind human evaluations of realism and long-term memory capability compared to a baseline RAG win rate of 31.1%. Mnemosyne also achieves current highest LoCoMo benchmark scores in temporal reasoning and single-hop retrieval compared to other same-backboned techniques. Further, the average overall score of 54.6% was second highest across all methods, beating commonly used Mem0 and OpenAI baselines among others. This demonstrates that improved factual recall, enhanced temporal reasoning, and much more natural user-facing responses can be feasible with an edge-compatible and easily transferable unsupervised memory architecture.",
        "tags": [
            "LLM",
            "RAG"
        ]
    },
    {
        "id": "13",
        "title": "Human Texts Are Outliers: Detecting LLM-generated Texts via Out-of-distribution Detection",
        "author": [
            "Cong Zeng",
            "Shengkun Tang",
            "Yuanzhou Chen",
            "Zhiqiang Shen",
            "Wenchao Yu",
            "Xujiang Zhao",
            "Haifeng Chen",
            "Wei Cheng",
            "Zhiqiang Xu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08602",
        "abstract": "The rapid advancement of large language models (LLMs) such as ChatGPT, DeepSeek, and Claude has significantly increased the presence of AI-generated text in digital communication. This trend has heightened the need for reliable detection methods to distinguish between human-authored and machine-generated content. Existing approaches both zero-shot methods and supervised classifiers largely conceptualize this task as a binary classification problem, often leading to poor generalization across domains and models. In this paper, we argue that such a binary formulation fundamentally mischaracterizes the detection task by assuming a coherent representation of human-written texts. In reality, human texts do not constitute a unified distribution, and their diversity cannot be effectively captured through limited sampling. This causes previous classifiers to memorize observed OOD characteristics rather than learn the essence of `non-ID' behavior, limiting generalization to unseen human-authored inputs. Based on this observation, we propose reframing the detection task as an out-of-distribution (OOD) detection problem, treating human-written texts as distributional outliers while machine-generated texts are in-distribution (ID) samples. To this end, we develop a detection framework using one-class learning method including DeepSVDD and HRN, and score-based learning techniques such as energy-based method, enabling robust and generalizable performance. Extensive experiments across multiple datasets validate the effectiveness of our OOD-based approach. Specifically, the OOD-based method achieves 98.3% AUROC and AUPR with only 8.9% FPR95 on DeepFake dataset. Moreover, we test our detection framework on multilingual, attacked, and unseen-model and -domain text settings, demonstrating the robustness and generalizability of our framework. Code, pretrained weights, and demo will be released.",
        "tags": [
            "DeepSeek",
            "Detection",
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "14",
        "title": "GRPO-GCC: Enhancing Cooperation in Spatial Public Goods Games via Group Relative Policy Optimization with Global Cooperation Constraint",
        "author": [
            "Zhaoqilin Yang",
            "Chanchan Li",
            "Tianqi Liu",
            "Hongxin Zhao",
            "Youliang Tian"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08607",
        "abstract": "Inspired by the principle of self-regulating cooperation in collective institutions, we propose the Group Relative Policy Optimization with Global Cooperation Constraint (GRPO-GCC) framework. This work is the first to introduce GRPO into spatial public goods games, establishing a new deep reinforcement learning baseline for structured populations. GRPO-GCC integrates group relative policy optimization with a global cooperation constraint that strengthens incentives at intermediate cooperation levels while weakening them at extremes. This mechanism aligns local decision making with sustainable collective outcomes and prevents collapse into either universal defection or unconditional cooperation. The framework advances beyond existing approaches by combining group-normalized advantage estimation, a reference-anchored KL penalty, and a global incentive term that dynamically adjusts cooperative payoffs. As a result, it achieves accelerated cooperation onset, stabilized policy adaptation, and long-term sustainability. GRPO-GCC demonstrates how a simple yet global signal can reshape incentives toward resilient cooperation, and provides a new paradigm for multi-agent reinforcement learning in socio-technical systems.",
        "tags": [
            "GRPO",
            "RL"
        ]
    },
    {
        "id": "15",
        "title": "MMA-ASIA: A Multilingual and Multimodal Alignment Framework for Culturally-Grounded Evaluation",
        "author": [
            "Weihua Zheng",
            "Zhengyuan Liu",
            "Tanmoy Chakraborty",
            "Weiwen Xu",
            "Xiaoxue Gao",
            "Bryan Chen Zhengyu Tan",
            "Bowei Zou",
            "Chang Liu",
            "Yujia Hu",
            "Xing Xie",
            "Xiaoyuan Yi",
            "Jing Yao",
            "Chaojun Wang",
            "Long Li",
            "Rui Liu",
            "Huiyao Liu",
            "Koji Inoue",
            "Ryuichi Sumida",
            "Tatsuya Kawahara",
            "Fan Xu",
            "Lingyu Ye",
            "Wei Tian",
            "Dongjun Kim",
            "Jimin Jung",
            "Jaehyung Seo",
            "Nadya Yuki Wangsajaya",
            "Pham Minh Duc",
            "Ojasva Saxena",
            "Palash Nandi",
            "Xiyan Tao",
            "Wiwik Karlina",
            "Tuan Luong",
            "Keertana Arun Vasan",
            "Roy Ka-Wei Lee",
            "Nancy F. Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08608",
        "abstract": "Large language models (LLMs) are now used worldwide, yet their multimodal understanding and reasoning often degrade outside Western, high-resource settings. We propose MMA-ASIA, a comprehensive framework to evaluate LLMs' cultural awareness with a focus on Asian contexts. MMA-ASIA centers on a human-curated, multilingual, and multimodally aligned multiple-choice benchmark covering 8 Asian countries and 10 languages, comprising 27,000 questions; over 79 percent require multi-step reasoning grounded in cultural context, moving beyond simple memorization. To our knowledge, this is the first dataset aligned at the input level across three modalities: text, image (visual question answering), and speech. This enables direct tests of cross-modal transfer. Building on this benchmark, we propose a five-dimensional evaluation protocol that measures: (i) cultural-awareness disparities across countries, (ii) cross-lingual consistency, (iii) cross-modal consistency, (iv) cultural knowledge generalization, and (v) grounding validity. To ensure rigorous assessment, a Cultural Awareness Grounding Validation Module detects \"shortcut learning\" by checking whether the requisite cultural knowledge supports correct answers. Finally, through comparative model analysis, attention tracing, and an innovative Vision-ablated Prefix Replay (VPR) method, we probe why models diverge across languages and modalities, offering actionable insights for building culturally reliable multimodal LLMs.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "16",
        "title": "Relative Positioning Based Code Chunking Method For Rich Context Retrieval In Repository Level Code Completion Task With Code Language Model",
        "author": [
            "Imranur Rahman",
            "Md Rayhanur Rahman"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08610",
        "abstract": "Code completion can help developers improve efficiency and ease the development lifecycle. Although code completion is available in modern integrated development environments (IDEs), research lacks in determining what makes a good context for code completion based on the information available to the IDEs for the large language models (LLMs) to perform better. In this paper, we describe an effective context collection strategy to assist the LLMs in performing better at code completion tasks. The key idea of our strategy is to preprocess the repository into smaller code chunks and later use syntactic and semantic similarity-based code chunk retrieval with relative positioning. We found that code chunking and relative positioning of the chunks in the final context improve the performance of code completion tasks.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "17",
        "title": "Impact of LLMs on Team Collaboration in Software Development",
        "author": [
            "Devang Dhanuka"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08612",
        "abstract": "Large Language Models (LLMs) are increasingly being integrated into software development processes, with the potential to transform team workflows and productivity. This paper investigates how LLMs affect team collaboration throughout the Software Development Life Cycle (SDLC). We reframe and update a prior study with recent developments as of 2025, incorporating new literature and case studies. We outline the problem of collaboration hurdles in SDLC and explore how LLMs can enhance productivity, communication, and decision-making in a team context. Through literature review, industry examples, a team survey, and two case studies, we assess the impact of LLM-assisted tools (such as code generation assistants and AI-powered project management agents) on collaborative software engineering practices. Our findings indicate that LLMs can significantly improve efficiency (by automating repetitive tasks and documentation), enhance communication clarity, and aid cross-functional collaboration, while also introducing new challenges like model limitations and privacy concerns. We discuss these benefits and challenges, present research questions guiding the investigation, evaluate threats to validity, and suggest future research directions including domain-specific model customization, improved integration into development tools, and robust strategies for ensuring trust and security.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "18",
        "title": "GraphGhost: Tracing Structures Behind Large Language Models",
        "author": [
            "Xinnan Dai",
            "Kai Guo",
            "Chung-Hsiang Lo",
            "Shenglai Zeng",
            "Jiayuan Ding",
            "Dongsheng Luo",
            "Subhabrata Mukherjee",
            "Jiliang Tang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08613",
        "abstract": "Large Language Models (LLMs) demonstrate remarkable reasoning capabilities, yet the structural mechanisms underlying these abilities remain under explored. In this work, we introduce GraphGhost, a unified framework that represents neuron activations and their signal propagation as graphs, explaining how LLMs capture structural semantics from sequential inputs and generate outputs through structurally consistent mechanisms. This graph-based perspective enables us to employ graph algorithms such as PageRank to characterize the properties of LLMs, revealing both shared and model-specific reasoning behaviors across diverse datasets. We further identify the activated neurons within GraphGhost and evaluate them through structural interventions, showing that edits to key neuron nodes can trigger reasoning collapse, altering both logical flow and semantic understanding. Together, these contributions position GraphGhost as a powerful tool for analyzing, intervening in, and ultimately understanding the structural foundations of reasoning in LLMs.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "19",
        "title": "Iterative LLM-Based Generation and Refinement of Distracting Conditions in Math Word Problems",
        "author": [
            "Kaiqi Yang",
            "Hang Li",
            "Yucheng Chu",
            "Zitao Liu",
            "Mi Tian",
            "Hui Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08615",
        "abstract": "Mathematical reasoning serves as a crucial testbed for evaluating the intelligence of large language models (LLMs), and math word problems (MWPs) represent one of the most widely used formats. Most existing MWP datasets contain only the necessary information, while problems with distracting or excessive conditions are often overlooked. Prior studies have shown that popular LLMs experience a dramatic performance drop when such distracting conditions are introduced. However, available datasets of MWPs with distracting conditions remain limited, and most exhibit low difficulty and out-of-context expressions. These shortcomings make the distracting conditions easy to detect and disregard, thereby reducing the credibility of benchmarking on these datasets. Moreover, when distracting conditions are added, the reasoning process and answers may change, requiring intensive manual effort to check and rewrite solutions.\nTo address these issues, we design an iterative framework that leverages LLMs to generate distracting conditions automatically. We develop a set of prompts to revise MWPs from multiple perspectives and cognitive levels, encouraging the creation of meaningful distracting conditions as well as suggestions for further refinement. A key advantage of our framework is the preservation of shared solutions between the original and revised problems: the LLMs are explicitly guided to generate distractions that do not alter the original solution, thus eliminating the need to produce new answers. This framework is efficient and easy to deploy, substantially reducing the effort required to generate MWPs with distracting conditions while maintaining high data quality.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "20",
        "title": "LLMs Show Surface-Form Brittleness Under Paraphrase Stress Tests",
        "author": [
            "Juan Miguel Navarro Carranza"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08616",
        "abstract": "Benchmark scores for Large Language Models (LLMs) can be inflated by memorization of test items or near duplicates. We present a simple, protocol that probes generalization by re-evaluating models on paraphrased versions of benchmark questions. Using Mistral-7B-Instruct and Qwen2.5-7B-Instruct, we measure the accuracy gap between original and paraphrased items on ARC-Easy and ARC-Challenge. Our pipeline controls decoding, enforces multiple-choice output format, and includes a robust paraphrase-cleaning step to preserve semantics. We find that paraphrasing induces a non-trivial accuracy drop (original vs. paraphrased), consistent with prior concerns about contamination and brittle surface-form shortcuts.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "21",
        "title": "JAI-1: A Thai-Centric Large Language Model",
        "author": [
            "Attapol T. Rutherford",
            "Jullajak Karnjanaekarin",
            "Narongkorn Panitsrisit",
            "Pontakorn Trakuekul",
            "Sumana Sumanakul",
            "Natchanon Pollertlam"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08620",
        "abstract": "This technical report introduces JAI-1, a Thai-centric language model with 75B parameters. Recent Thai models have primarily relied on existing open-source models, applying additional training without structural modifications to specialize in Thai. However, this approach risks eroding pre-existing knowledge in the model's parameter space during the injection of Thai-specific information, as optimized parameters for general tasks may conflict with new linguistic requirements. In contrast, JAI-1 adopts an upscaling strategy: starting from a smaller, high-performing English open-source LLM, we expanded its parameter space and utilized the newly allocated capacity to systematically integrate Thai-language knowledge. This methodology not only preserves the original model's general intelligence but also establishes a unique architecture distinct from other open-source models, enabling scalable future enhancements. During pre-training, JAI-1 was exposed to 1.5T tokens, including over 300B Thai language tokens. This was followed by post-training stages -- supervised fine-tuning and alignment tuning -- using more than 600K instruction-based examples. The final model demonstrated superior performance compared to Typhoon2-70B on Thai-centric benchmarks (IFEval-TH, MT-Bench-TH, and JAI-Hall-Bench), validating the efficacy of its upscaling and knowledge-integration framework.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "22",
        "title": "Text2Stories: Evaluating the Alignment Between Stakeholder Interviews and Generated User Stories",
        "author": [
            "Francesco Dente",
            "Fabiano Dalpiaz",
            "Paolo Papotti"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08622",
        "abstract": "Large language models (LLMs) can be employed for automating the generation of software requirements from natural language inputs such as the transcripts of elicitation interviews. However, evaluating whether those derived requirements faithfully reflect the stakeholders' needs remains a largely manual task. We introduce Text2Stories, a task and metrics for text-to-story alignment that allow quantifying the extent to which requirements (in the form of user stories) match the actual needs expressed by the elicitation session participants. Given an interview transcript and a set of user stories, our metric quantifies (i) correctness: the proportion of stories supported by the transcript, and (ii) completeness: the proportion of transcript supported by at least one story. We segment the transcript into text chunks and instantiate the alignment as a matching problem between chunks and stories. Experiments over four datasets show that an LLM-based matcher achieves 0.86 macro-F1 on held-out annotations, while embedding models alone remain behind but enable effective blocking. Finally, we show how our metrics enable the comparison across sets of stories (e.g., human vs. generated), positioning Text2Stories as a scalable, source-faithful complement to existing user-story quality criteria.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "23",
        "title": "PARSE: LLM Driven Schema Optimization for Reliable Entity Extraction",
        "author": [
            "Anubhav Shrimal",
            "Aryan Jain",
            "Soumyajit Chowdhury",
            "Promod Yenigalla"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08623",
        "abstract": "Structured information extraction from unstructured text is critical for emerging Software 3.0 systems where LLM agents autonomously interact with APIs and tools. Recent approaches apply large language models directly to extraction tasks using existing JSON schemas, often with constraint decoding or reinforcement learning approaches to ensure syntactic validity, but treat JSON schemas as static contracts designed for human developers, leading to suboptimal extraction performance, frequent hallucinations, and unreliable agent behavior when schemas contain ambiguous or incomplete specifications. We recognize that JSON schemas themselves are a form of natural language understanding contract that encodes rules, relationships, and expectations about data structure contracts that LLMs should be able to both interpret and systematically improve. Consequently, we develop PARSE (Parameter Automated Refinement and Schema Extraction), a novel system with two synergistic components: ARCHITECT, which autonomously optimizes JSON schemas for LLM consumption while maintaining backward compatibility through RELAY (an integrated code generation system), and SCOPE, which implements reflection-based extraction with combined static and LLM-based guardrails. We evaluate PARSE qualitatively and quantitatively on three datasets including Schema-Guided Dialogue (SGD), Structured Web Data Extraction (SWDE), and internal retail conversation data, and find that it achieves up to 64.7% improvement in extraction accuracy on SWDE with combined framework improvements reaching 10% across models, while reducing extraction errors by 92% within the first retry and and maintaining practical latency.",
        "tags": [
            "LLM",
            "RL"
        ]
    },
    {
        "id": "24",
        "title": "Do LLMs Know They Are Being Tested? Evaluation Awareness and Incentive-Sensitive Failures in GPT-OSS-20B",
        "author": [
            "Nisar Ahmed",
            "Muhammad Imran Zaman",
            "Gulshan Saleem",
            "Ali Hassan"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08624",
        "abstract": "Benchmarks for large language models (LLMs) often rely on rubric-scented prompts that request visible reasoning and strict formatting, whereas real deployments demand terse, contract-bound answers. We investigate whether such \"evaluation scent\" inflates measured performance without commensurate capability gains. Using a single open-weights model (GPT-OSS-20B), we run six paired A/B scenarios that hold task content and decoding fixed while varying framing (evaluation-oriented vs. real-world) and reasoning depth (Medium/High): deterministic math, strict code-fix, citation generation, incentive flips (caution vs. competence), CoT visibility, and multilingual (Urdu) headers. Deterministic validators compute accuracy, answer-only compliance, hedging/refusals, chain-of-thought (CoT) length, and schema compliance, with pre-registered deltas and composite indices. Across scenarios, evaluation framing reliably inflates CoT (hundreds to >1000 characters) and reduces answer-only compliance, with limited or inconsistent accuracy gains. In structured outputs, it improves wrappers (e.g., fenced blocks, enumerated lists) but not regex-validated substance. Incentive wording reweights error composition: praising caution modestly improves accuracy at high reasoning and reduces wrong-but-confident errors, whereas praising competence yields terser but riskier outputs. Urdu rubric headers reproduce these signatures and can decrease accuracy at higher reasoning depth, indicating multilingual parity risks. We provide a reproducible A/B framework (prompt banks, validators, per-run scores, scripts; versioned DOI) and practical guidance: neutral phrasing or dual-framing checks, contract-aware grading, style-delta reporting, confidence governance, and multilingual dashboards to ensure that benchmark gains reflect deployable capability.",
        "tags": [
            "CoT",
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "25",
        "title": "Adjusting Initial Noise to Mitigate Memorization in Text-to-Image Diffusion Models",
        "author": [
            "Hyeonggeun Han",
            "Sehwan Kim",
            "Hyungjun Joo",
            "Sangwoo Hong",
            "Jungwoo Lee"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08625",
        "abstract": "Despite their impressive generative capabilities, text-to-image diffusion models often memorize and replicate training data, prompting serious concerns over privacy and copyright. Recent work has attributed this memorization to an attraction basin-a region where applying classifier-free guidance (CFG) steers the denoising trajectory toward memorized outputs-and has proposed deferring CFG application until the denoising trajectory escapes this basin. However, such delays often result in non-memorized images that are poorly aligned with the input prompts, highlighting the need to promote earlier escape so that CFG can be applied sooner in the denoising process. In this work, we show that the initial noise sample plays a crucial role in determining when this escape occurs. We empirically observe that different initial samples lead to varying escape times. Building on this insight, we propose two mitigation strategies that adjust the initial noise-either collectively or individually-to find and utilize initial samples that encourage earlier basin escape. These approaches significantly reduce memorization while preserving image-text alignment.",
        "tags": [
            "Diffusion",
            "Text-to-Image"
        ]
    },
    {
        "id": "26",
        "title": "A Denoising Diffusion-Based Evolutionary Algorithm Framework: Application to the Maximum Independent Set Problem",
        "author": [
            "Joan SalvÃ  Soler",
            "GÃ¼nther R. Raidl"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08627",
        "abstract": "Denoising diffusion models (DDMs) offer a promising generative approach for combinatorial optimization, yet they often lack the robust exploration capabilities of traditional metaheuristics like evolutionary algorithms (EAs). We propose a Denoising Diffusion-based Evolutionary Algorithm (DDEA) framework that synergistically integrates these paradigms. It utilizes pre-trained DDMs for both high-quality and diverse population initialization and a novel diffusion-based recombination operator, trained via imitation learning against an optimal demonstrator. Evaluating DDEA on the Maximum Independent Set problem on ErdÅs-RÃ©nyi graphs, we demonstrate notable improvements over DIFUSCO, a leading DDM solver. DDEA consistently outperforms it given the same time budget, and surpasses Gurobi on larger graphs under the same time limit, with DDEA's solution sizes being 3.9% and 7.5% larger on the ER-300-400 and ER-700-800 datasets, respectively. In out-of-distribution experiments, DDEA provides solutions of 11.6% higher quality than DIFUSCO under the same time limit. Ablation studies confirm that both diffusion initialization and recombination are crucial. Our work highlights the potential of hybridizing DDMs and EAs, offering a promising direction for the development of powerful machine learning solvers for complex combinatorial optimization problems.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "27",
        "title": "Dynamic Mixture-of-Experts for Visual Autoregressive Model",
        "author": [
            "Jort Vincenti",
            "Metod Jazbec",
            "Guoxuan Xia"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08629",
        "abstract": "Visual Autoregressive Models (VAR) offer efficient and high-quality image generation but suffer from computational redundancy due to repeated Transformer calls at increasing resolutions. We introduce a dynamic Mixture-of-Experts router integrated into VAR. The new architecture allows to trade compute for quality through scale-aware thresholding. This thresholding strategy balances expert selection based on token complexity and resolution, without requiring additional training. As a result, we achieve 20% fewer FLOPs, 11% faster inference and match the image quality achieved by the dense baseline.",
        "tags": [
            "MoE",
            "Transformer"
        ]
    },
    {
        "id": "28",
        "title": "ExPO-HM: Learning to Explain-then-Detect for Hateful Meme Detection",
        "author": [
            "Jingbiao Mei",
            "Mingsheng Sun",
            "Jinghong Chen",
            "Pengda Qin",
            "Yuhong Li",
            "Da Chen",
            "Bill Byrne"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08630",
        "abstract": "Hateful memes have emerged as a particularly challenging form of online abuse, motivating the development of automated detection systems. Most prior approaches rely on direct detection, producing only binary predictions. Such models fail to provide the context and explanations that real-world moderation requires. Recent Explain-then-Detect approaches, using Chain-of-Thought prompting or LMM agents, perform worse than simple SFT baselines, and even advanced post-training methods such as GRPO fail to close the gap. Our analysis identifies two key issues of such systems: important policy-relevant cues such as targets and attack types are not hypothesized by the model as a likely explanation; and the binary reward signal is insufficient to guide reasoning. To address these challenges, we propose ExPO-HM (Explain-then-Detect Policy Optimization for Hateful Memes), inspired by the training and evaluation process of human annotators. ExPO-HM combines SFT warmup, GRPO with curriculum learning, and Conditional Decision Entropy (CDE) as both metric and reward for reasoning quality. Across three hateful meme benchmarks, ExPO-HM achieves state-of-the-art performance on binary detection, fine-grained classification, and reasoning quality, with up to 15\\% and 17\\% F1 improvement over the GRPO and DPO baselines, respectively. By moving hateful meme detection from simple binary alarms to explanation-driven detection, ExPO-HM provides accurate, interpretable, and actionable moderation support.",
        "tags": [
            "CoT",
            "DPO",
            "Detection",
            "GRPO"
        ]
    },
    {
        "id": "29",
        "title": "Next Semantic Scale Prediction via Hierarchical Diffusion Language Models",
        "author": [
            "Cai Zhou",
            "Chenyu Wang",
            "Dinghuai Zhang",
            "Shangyuan Tong",
            "Yifei Wang",
            "Stephen Bates",
            "Tommi Jaakkola"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08632",
        "abstract": "In this paper we introduce Hierarchical Diffusion Language Models (HDLM) -- a novel family of discrete diffusion models for language modeling. HDLM builds on a hierarchical vocabulary where low-level tokens with detailed semantics are surjectively mapped to high-level tokens with coarse-grained meanings. In the forward process, each token is independently perturbed to its higher-level ancestor with more abstract semantics according to the scheduler, while in the reverse process the model progressively predicts the next, more detailed semantics. Taken together, HDLM provides a general time-varying next semantic scale prediction process for language modeling. We derive closed-form expressions for the diffusion Evidence Lower Bound (ELBO), and show that HDLM can be implemented in a flexible manner while including the existing MDLM as a special case. We also propose practical training techniques based on the insights. Extensive text generation experiments validate the effectiveness of HDLM, which demonstrates consistently lower validation and generative perplexity than baselines.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "30",
        "title": "Into the Rabbit Hull: From Task-Relevant Concepts in DINO to Minkowski Geometry",
        "author": [
            "Thomas Fel",
            "Binxu Wang",
            "Michael A. Lepori",
            "Matthew Kowal",
            "Andrew Lee",
            "Randall Balestriero",
            "Sonia Joseph",
            "Ekdeep S. Lubana",
            "Talia Konkle",
            "Demba Ba",
            "Martin Wattenberg"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08638",
        "abstract": "DINOv2 is routinely deployed to recognize objects, scenes, and actions; yet the nature of what it perceives remains unknown. As a working baseline, we adopt the Linear Representation Hypothesis (LRH) and operationalize it using SAEs, producing a 32,000-unit dictionary that serves as the interpretability backbone of our study, which unfolds in three parts.\nIn the first part, we analyze how different downstream tasks recruit concepts from our learned dictionary, revealing functional specialization: classification exploits \"Elsewhere\" concepts that fire everywhere except on target objects, implementing learned negations; segmentation relies on boundary detectors forming coherent subspaces; depth estimation draws on three distinct monocular depth cues matching visual neuroscience principles.\nFollowing these functional results, we analyze the geometry and statistics of the concepts learned by the SAE. We found that representations are partly dense rather than strictly sparse. The dictionary evolves toward greater coherence and departs from maximally orthogonal ideals (Grassmannian frames). Within an image, tokens occupy a low dimensional, locally connected set persisting after removing position. These signs suggest representations are organized beyond linear sparsity alone.\nSynthesizing these observations, we propose a refined view: tokens are formed by combining convex mixtures of archetypes (e.g., a rabbit among animals, brown among colors, fluffy among textures). This structure is grounded in Gardenfors' conceptual spaces and in the model's mechanism as multi-head attention produces sums of convex mixtures, defining regions bounded by archetypes. We introduce the Minkowski Representation Hypothesis (MRH) and examine its empirical signatures and implications for interpreting vision-transformer representations.",
        "tags": [
            "Depth Estimation",
            "Segmentation",
            "Transformer",
            "ViT"
        ]
    },
    {
        "id": "31",
        "title": "Automating Android Build Repair: Bridging the Reasoning-Execution Gap in LLM Agents with Domain-Specific Tools",
        "author": [
            "Ha Min Son",
            "Huan Ren",
            "Xin Liu",
            "Zhe Zhao"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08640",
        "abstract": "Android is the largest mobile platform, yet automatically building applications remains a practical challenge. While Large Language Models (LLMs) show promise for code repair, their use for fixing Android build errors remains underexplored. To address this gap, we first introduce AndroidBuildBench, a benchmark of 1,019 build failures curated from the commit histories of 43 open-source Android projects. Each problem is paired with a verified solution from a subsequent commit, ensuring that fixes are feasible. Second, we propose GradleFixer, an LLM agent with domain-specific tools for inspecting and manipulating the Gradle build environment. GradleFixer achieves a resolve rate of 81.4% (pass@1), significantly outperforming a state-of-the-art coding agent that relies on a general-purpose shell. GradleFixer's success suggests that while LLMs possess the high-level knowledge to solve these failures, they struggle to translate this knowledge into effective low-level actions using a general-purpose shell. We demonstrate the effectiveness of a strategy we term Tool Bridging, which replaces general-purpose shell commands with domain-aware abstractions. We hypothesize this approach works through two mechanisms: 1) it provides tools in an API-like format that LLMs use more reliably, and 2) it constrains the action space to relevant operations. This approach bridges the gap between the model's high-level reasoning and effective low-level execution.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "32",
        "title": "Energy-Driven Steering: Reducing False Refusals in Large Language Models",
        "author": [
            "Eric Hanchen Jiang",
            "Weixuan Ou",
            "Run Liu",
            "Shengyuan Pang",
            "Guancheng Wan",
            "Ranjie Duan",
            "Wei Dong",
            "Kai-Wei Chang",
            "XiaoFeng Wang",
            "Ying Nian Wu",
            "Xinfeng Li"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08646",
        "abstract": "Safety alignment of large language models (LLMs) faces a key challenge: current alignment techniques often only focus on improving safety against harmful prompts, causing LLMs to become over-cautious and refuse to respond to benign prompts. Therefore, a key objective of safe alignment is to enhance safety while simultaneously reducing false refusals. In this paper, we introduce Energy-Driven Steering (EDS), a novel, fine-tuning free framework designed to resolve this challenge through dynamic, inference-time intervention. We trained a lightweight, external Energy-Based Model (EBM) to assign high energy to undesirable (false refusal or jailbreak) states and low energy to desirable (helpful response or safe reject) ones. During inference, EBM maps the LLM's internal activations to an \"energy landscape\". We use the gradient of the energy function to dynamically steer the LLM's hidden states to low energy regions, correcting the model to generate a desirable response in real-time without modifying its weights. This method decouples behavioral control from the model's core knowledge, offering a flexible solution with minimal computational overhead. Extensive experiments across a wide range of models show our method successfully achieves this objective: it substantially lowers false refusal rates. For example, raising compliance on the ORB-H benchmark from 57.3% to 82.6% while maintaining the baseline safety performance. Our work presents an effective paradigm for building LLMs that achieve both low false refusal rates and high safety.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "33",
        "title": "Upfront Chain-of-Thought: A Cooperative Framework for Chain-of-Thought Compression",
        "author": [
            "Chengzhengxu Li",
            "Xiaoming Liu",
            "Zhaohan Zhang",
            "Shaochu Zhang",
            "Shengchao Liu",
            "Guoxin Ma",
            "Yu Lan",
            "Chao Shen"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08647",
        "abstract": "Recent developments have enabled advanced reasoning in Large Language Models (LLMs) via long Chain-of-Thought (CoT), while long CoT suffers from high computational costs and significant latency losses owing to the autoregressive nature of generative LLMs. CoT compression aims to improve efficiency in the reasoning process by reducing output length. Previous works trade reasoning efficiency by either laborious discrete prompt designing or the construction of external compressed CoT datasets that sacrifice key reasoning details. In this work, we propose Upfront CoT (UCoT): an efficient reasoning framework with upfront thought embedding to automate CoT compression. UCoT is a cooperative workflow involving a small model (compressor) and a large model (executor). The first stage of UCoT trains compressor to generate upfront thought embeddings rich in reasoning information for the executor, avoiding the drawbacks of manually designed prompts. The second stage optimizes executor to utilize upfront thought embeddings to derive the correct answer with short reasoning, using a reward mechanism. Extensive experiments show that UCoT maintains the powerful reasoning ability of executor while significantly reducing the length of CoT. It is worth mentioning that when applying UCoT to the Qwen2.5-7B-Instruct model, the usage of tokens on GSM8K dataset is reduced by 50\\%, while the performance is 3.08\\% higher than that of the state-of-the-art (SOTA) method. The code and dataset are in supplementary material.",
        "tags": [
            "CoT",
            "LLM"
        ]
    },
    {
        "id": "34",
        "title": "Inverse-Free Wilson Loops for Transformers: A Practical Diagnostic for Invariance and Order Sensitivity",
        "author": [
            "Edward Y. Chang",
            "Ethan Y. Chang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08648",
        "abstract": "Large language models can change answers under harmless edits that matter in practice: RAG outputs flip when passages are reordered, fine-tuning erodes invariances learned at pretraining, debate or chain-of-thought prompts take path-dependent routes, and compiler fusion or reordering perturbs logits near decision boundaries. These failures violate intended invariances, break continuous integration, and force teams to trade safety for speed. The effects are small yet distributed across layers and positions, sensitive to context length and evaluation order, and costly to repair with retraining or formal verification. We present WILSON, a minimal post-hoc diagnostic suite that converts simple loop and reordering checks on internal representations into system signals. WILSON combines an inverse-free curvature map over positions and layers, computed with JVPs and Hutchinson probes, with activation-level commutators that flag reorder risk. Signals are cheap to compute, model-agnostic for standard Transformers, and exported as thresholds and CSV artifacts for orchestrators. This enables concrete actions: guard RAG against order effects, catch fine-tuning regressions, stabilize debate pathways and long multi-turn contexts, and gate fusions or reorders in deployment. In short, WILSON helps anticipate failures and approve safe optimizations so reliability and throughput can improve together without changing model architecture or training.",
        "tags": [
            "CoT",
            "LLM",
            "RAG"
        ]
    },
    {
        "id": "35",
        "title": "Provably Robust Adaptation for Language-Empowered Foundation Models",
        "author": [
            "Yuni Lai",
            "Xiaoyu Xue",
            "Linghui Shen",
            "Yulun Wu",
            "Gaolei Li",
            "Song Guo",
            "Kai Zhou",
            "Bin Xiao"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08659",
        "abstract": "Language-empowered foundation models (LeFMs), such as CLIP and GraphCLIP, have transformed multimodal learning by aligning visual (or graph) features with textual representations, enabling powerful downstream capabilities like few-shot learning. However, the reliance on small, task-specific support datasets collected in open environments exposes these models to poisoning attacks, where adversaries manipulate the support samples to degrade performance. Existing defenses rely on empirical strategies, which lack formal guarantees and remain vulnerable to unseen and adaptive attacks. Certified robustness offers provable guarantees but has been largely unexplored for few-shot classifiers based on LeFMs. This study seeks to fill these critical gaps by proposing the first provably robust few-shot classifier that is tailored for LeFMs. We term our model Language-empowered Few-shot Certification (\\textbf{LeFCert}). It integrates both textual and feature embeddings with an adaptive blending mechanism. To achieve provable robustness, we propose a twofold trimmed mean prototype and derive provable upper and lower bounds for classification scores, enabling certification under worst-case poisoning scenarios. To further enhance the performance, we extend LeFCert with two variants by considering a more realistic and tighter attack budget: LeFCert-L incorporates randomized smoothing to provide Lipschitz continuity and derive robustness under dual budget constraints, and LeFCert-C provides collective certification for scenarios where attackers distribute a shared poisoning budget across multiple samples. Experiments demonstrate that LeFCert achieves state-of-the-art performance, significantly improving both clean and certified accuracy compared to existing baselines. Despite its advanced robustness mechanisms, LeFCert is computationally efficient, making it practical for real-world applications.",
        "tags": [
            "CLIP"
        ]
    },
    {
        "id": "36",
        "title": "A Novel Framework for Augmenting Rating Scale Tests with LLM-Scored Text Data",
        "author": [
            "Joe Watson",
            "Ivan O'Conner",
            "Chia-Wen Chen",
            "Luning Sun",
            "Fang Luo",
            "David Stillwell"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08663",
        "abstract": "Psychological assessments typically rely on structured rating scales, which cannot incorporate the rich nuance of a respondent's natural language. This study leverages recent LLM advances to harness qualitative data within a novel conceptual framework, combining LLM-scored text and traditional rating-scale items to create an augmented test. We demonstrate this approach using depression as a case study, developing and assessing the framework on a real-world sample of upper secondary students (n=693) and corresponding synthetic dataset (n=3,000). On held-out test sets, augmented tests achieved statistically significant improvements in measurement precision and accuracy. The information gain from the LLM items was equivalent to adding between 6.3 (real data) and 16.0 (synthetic data) items to the original 19-item test. Our approach marks a conceptual shift in automated scoring that bypasses its typical bottlenecks: instead of relying on pre-labelled data or complex expert-created rubrics, we empirically select the most informative LLM scoring instructions based on calculations of item information. This framework provides a scalable approach for leveraging the growing stream of transcribed text to enhance traditional psychometric measures, and we discuss its potential utility in clinical health and beyond.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "37",
        "title": "Faver: Boosting LLM-based RTL Generation with Function Abstracted Verifiable Middleware",
        "author": [
            "Jianan Mu",
            "Mingyu Shi",
            "Yining Wang",
            "Tianmeng Yang",
            "Bin Sun",
            "Xing Hu",
            "Jing Ye",
            "Huawei Li"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08664",
        "abstract": "LLM-based RTL generation is an interesting research direction, as it holds the potential to liberate the least automated stage in the current chip design. However, due to the substantial semantic gap between high-level specifications and RTL, coupled with limited training data, existing models struggle with generation accuracy. Drawing on human experience, design with verification helps improving accuracy. However, as the RTL testbench data are even more scarce, it is not friendly for LLMs. Although LLMs excel at higher-level languages like Python/C, they have a huge semantic gap from RTL. When implementing the same functionality, Python/C code and hardware code differ significantly in the spatiotemporal granularity, requiring the LLM not only to consider high-level functional semantics but also to ensure the low-level details align with the circuit code. It is not an easy task. In this paper, we propose a function abstracted verifiable middleware (Faver) that streamlines RTL verification in LLM-based workflows. By mixing LLM-friendly code structures with a rule-based template, Faver decouples the details of circuit verification, allowing the LLM to focus on the functionality itself. In our experiments on the SFT model and open-source models, Faver improved the model's generation accuracy by up to 14%.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "38",
        "title": "RA-Gen: A Controllable Code Generation Framework Using ReAct for Multi-Agent Task Execution",
        "author": [
            "Aofan Liu",
            "Haoxuan Li",
            "Bin Wang",
            "Ao Yang",
            "Hui Li"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08665",
        "abstract": "Code generation models based on large language models (LLMs) have gained wide adoption, but challenges remain in ensuring safety, accuracy, and controllability, especially for complex tasks. Existing methods often lack dynamic integration of external tools, transparent reasoning, and user control over safety. To address these issues, we propose a controllable code generation framework utilizing the ReAct paradigm for multi-agent task execution. This framework is a multi-agent system designed to enable efficient, precise, and interpretable code generation through dynamic interactions between LLMs and external resources. The framework adopts a collaborative architecture comprising four specialized agents: a Planner for task decomposition, a Searcher that leverages the ReAct framework for reasoning and tool integration, a CodeGen agent for accurate code generation, and an Extractor for structured data retrieval. The ReAct-based Searcher alternates between generating reasoning traces and executing actions, facilitating seamless integration of internal knowledge with external tools (such as search engines) to enhance accuracy and user control. Experimental results show the framework's effectiveness across multiple languages, achieving a 94.8% security rate on the SVEN dataset with CodeQL, outperforming existing approaches. Its transparent reasoning process fosters user trust and improves controllability.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "39",
        "title": "dInfer: An Efficient Inference Framework for Diffusion Language Models",
        "author": [
            "Yuxin Ma",
            "Lun Du",
            "Lanning Wei",
            "Kun Chen",
            "Qian Xu",
            "Kangyu Wang",
            "Guofeng Feng",
            "Guoshan Lu",
            "Lin Liu",
            "Xiaojing Qi",
            "Xinyuan Zhang",
            "Zhen Tao",
            "Haibo Feng",
            "Ziyun Jiang",
            "Ying Xu",
            "Zenan Huang",
            "Yihong Zhuang",
            "Haokai Xu",
            "Jiaqi Hu",
            "Zhenzhong Lan",
            "Junbo Zhao",
            "Jianguo Li",
            "Da Zheng"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08666",
        "abstract": "Diffusion-based large language models (dLLMs) have emerged as a promising alternative to autoregressive (AR) LLMs, leveraging denoising-based generation to enable inherent parallelism. Even more and more open-sourced dLLM models emerge, yet their widespread adoption remains constrained by the lack of a standardized and efficient inference framework. We present dInfer, an efficient and extensible framework for dLLM inference. dInfer decomposes the inference pipeline into four modular components-model, diffusion iteration manager, decoding strategy, and KV-cache manager-and integrates novel algorithms for each component alongside system-level optimizations. Through this combination of algorithmic innovations and system enhancements, dInfer achieves substantial efficiency gains without compromising output quality on LLaDA-MoE. At batch size 1, it surpasses 1,100 tokens per second on HumanEval and averages over 800 tokens per second across six benchmarks on $8\\times$ H800 GPUs. Compared to prior systems, dInfer delivers $10\\times$ speedup over Fast-dLLM while maintaining similar model performance. Even compared with AR models (with a comparable number of activation parameters and performance) QWen2.5-3B, which is highly optimized with latest vLLM inference engine, dInfer still deliverers $2$-$3\\times$ speedup. The implementation of dInfer is open-sourced at https://github.com/inclusionAI/dInfer.",
        "tags": [
            "Diffusion",
            "LLM",
            "MoE"
        ]
    },
    {
        "id": "40",
        "title": "RAG4Tickets: AI-Powered Ticket Resolution via Retrieval-Augmented Generation on JIRA and GitHub Data",
        "author": [
            "Mohammad Baqar"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08667",
        "abstract": "Modern software teams frequently encounter delays in resolving recurring or related issues due to fragmented knowledge scattered across JIRA tickets, developer discussions, and GitHub pull requests (PRs). To address this challenge, we propose a Retrieval-Augmented Generation (RAG) framework that integrates Sentence-Transformers for semantic embeddings with FAISS-based vector search to deliver context-aware ticket resolution recommendations. The approach embeds historical JIRA tickets, user comments, and linked PR metadata to retrieve semantically similar past cases, which are then synthesized by a Large Language Model (LLM) into grounded and explainable resolution suggestions. The framework contributes a unified pipeline linking JIRA and GitHub data, an embedding and FAISS indexing strategy for heterogeneous software artifacts, and a resolution generation module guided by retrieved evidence. Experimental evaluation using precision, recall, resolution time reduction, and developer acceptance metrics shows that the proposed system significantly improves resolution accuracy, fix quality, and knowledge reuse in modern DevOps environments.",
        "tags": [
            "LLM",
            "RAG"
        ]
    },
    {
        "id": "41",
        "title": "FreqCa: Accelerating Diffusion Models via Frequency-Aware Caching",
        "author": [
            "Jiacheng Liu",
            "Peiliang Cai",
            "Qinming Zhou",
            "Yuqi Lin",
            "Deyang Kong",
            "Benhao Huang",
            "Yupei Pan",
            "Haowen Xu",
            "Chang Zou",
            "Junshu Tang",
            "Shikang Zheng",
            "Linfeng Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08669",
        "abstract": "The application of diffusion transformers is suffering from their significant inference costs. Recently, feature caching has been proposed to solve this problem by reusing features from previous timesteps, thereby skipping computation in future timesteps. However, previous feature caching assumes that features in adjacent timesteps are similar or continuous, which does not always hold in all settings. To investigate this, this paper begins with an analysis from the frequency domain, which reveal that different frequency bands in the features of diffusion models exhibit different dynamics across timesteps. Concretely, low-frequency components, which decide the structure of images, exhibit higher similarity but poor continuity. In contrast, the high-frequency bands, which decode the details of images, show significant continuity but poor similarity. These interesting observations motivate us to propose Frequency-aware Caching (FreqCa)\nwhich directly reuses features of low-frequency components based on their similarity, while using a second-order Hermite interpolator to predict the volatile high-frequency ones based on its continuity.\nBesides, we further propose to cache Cumulative Residual Feature (CRF) instead of the features in all the layers, which reduces the memory footprint of feature caching by 99%.\nExtensive experiments on FLUX.1-dev, FLUX.1-Kontext-dev, Qwen-Image, and Qwen-Image-Edit demonstrate its effectiveness in both generation and editing. Codes are available in the supplementary materials and will be released on GitHub.",
        "tags": [
            "Diffusion",
            "FLUX",
            "Qwen"
        ]
    },
    {
        "id": "42",
        "title": "Optimizing delivery for quick commerce factoring qualitative assessment of generated routes",
        "author": [
            "Milon Bhattacharya",
            "Milan Kumar"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08671",
        "abstract": "Indias e-commerce market is projected to grow rapidly, with last-mile delivery accounting for nearly half of operational expenses. Although vehicle routing problem (VRP) based solvers are widely used for delivery planning, their effectiveness in real-world scenarios is limited due to unstructured addresses, incomplete maps, and computational constraints in distance estimation. This study proposes a framework that employs large language models (LLMs) to critique VRP-generated routes against policy-based criteria, allowing logistics operators to evaluate and prioritise more efficient delivery plans. As a illustration of our approach we generate, annotate and evaluated 400 cases using large language models. Our study found that open-source LLMs identified routing issues with 79% accuracy, while proprietary reasoning models achieved reach upto 86%. The results demonstrate that LLM-based evaluation of VRP-generated routes can be an effective and scalable layer of evaluation which goes beyond beyond conventional distance and time based metrics. This has implications for improving cost efficiency, delivery reliability, and sustainability in last-mile logistics, especially for developing countries like India.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "43",
        "title": "Thinking with Camera: A Unified Multimodal Model for Camera-Centric Understanding and Generation",
        "author": [
            "Kang Liao",
            "Size Wu",
            "Zhonghua Wu",
            "Linyi Jin",
            "Chao Wang",
            "Yikai Wang",
            "Fei Wang",
            "Wei Li",
            "Chen Change Loy"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08673",
        "abstract": "Camera-centric understanding and generation are two cornerstones of spatial intelligence, yet they are typically studied in isolation. We present Puffin, a unified camera-centric multimodal model that extends spatial awareness along the camera dimension. Puffin integrates language regression and diffusion-based generation to interpret and create scenes from arbitrary viewpoints. To bridge the modality gap between cameras and vision-language, we introduce a novel paradigm that treats camera as language, enabling thinking with camera. This guides the model to align spatially grounded visual cues with photographic terminology while reasoning across geometric context. Puffin is trained on Puffin-4M, a large-scale dataset of 4 million vision-language-camera triplets. We incorporate both global camera parameters and pixel-wise camera maps, yielding flexible and reliable spatial generation. Experiments demonstrate Puffin superior performance over specialized models for camera-centric generation and understanding. With instruction tuning, Puffin generalizes to diverse cross-view tasks such as spatial imagination, world exploration, and photography guidance. We will release the code, models, dataset pipeline, and benchmark to advance multimodal spatial intelligence research.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "44",
        "title": "Don't Waste Mistakes: Leveraging Negative RL-Groups via Confidence Reweighting",
        "author": [
            "Yunzhen Feng",
            "Parag Jain",
            "Anthony Hartshorn",
            "Yaqi Duan",
            "Julia Kempe"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08696",
        "abstract": "Reinforcement learning with verifiable rewards (RLVR) has become a standard recipe for improving large language models (LLMs) on reasoning tasks, with Group Relative Policy Optimization (GRPO) widely used in practice. Yet GRPO wastes substantial compute on negative groups: groups in which no sampled response is correct yield zero advantage and thus no gradient. We ask whether negative groups can be leveraged without extra supervision. Starting from a maximum-likelihood (MLE) objective in reward modeling, we show that the MLE gradient is equivalent to a policy gradient for a modified value function. This value function adds a confidence-weighted penalty on incorrect responses, imposing larger penalties on more confident mistakes. We refer to this as \\textbf{L}ikelihood \\textbf{E}stimation with \\textbf{N}egative \\textbf{S}amples (\\textbf{LENS}). LENS modifies GRPO to assign non-zero, confidence-dependent rewards to incorrect generations, making negative groups informative and converting previously wasted samples into useful gradient updates. On the MATH benchmark with Llama-3.1-8B and Qwen-2.5-3B, the proposed variant consistently outperforms GRPO baseline, with significant gains on harder items. These results demonstrate a principled and practical way to \"rescue\" negative groups, improving efficiency and performance in RLVR.",
        "tags": [
            "GRPO",
            "LLM",
            "LLaMA",
            "Qwen",
            "RL"
        ]
    },
    {
        "id": "45",
        "title": "BigCodeArena: Unveiling More Reliable Human Preferences in Code Generation via Execution",
        "author": [
            "Terry Yue Zhuo",
            "Xiaolong Jin",
            "Hange Liu",
            "Juyong Jiang",
            "Tianyang Liu",
            "Chen Gong",
            "Bhupesh Bishnoi",
            "Vaisakhi Mishra",
            "Marek Suppa",
            "Noah Ziems",
            "Saiteja Utpala",
            "Ming Xu",
            "Guangyu Song",
            "Kaixin Li",
            "Yuhan Cao",
            "Bo Liu",
            "Zheng Liu",
            "Sabina Abdurakhmanova",
            "Wenhao Yu",
            "Mengzhao Jia",
            "Jihan Yao",
            "Kenneth Hamilton",
            "Kumar Shridhar",
            "Minh Chien Vu",
            "Dingmin Wang",
            "Jiawei Liu",
            "Zijian Wang",
            "Qian Liu",
            "Binyuan Hui",
            "Meg Risdal",
            "Ahsen Khaliq",
            "Atin Sood",
            "Zhenchang Xing",
            "Wasi Uddin Ahmad",
            "John Grundy",
            "David Lo",
            "Banghua Zhu",
            "Xiaoning Du",
            "Torsten Scholak",
            "Leandro von Werra"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08697",
        "abstract": "Crowdsourced model evaluation platforms, such as Chatbot Arena, enable real-time evaluation from human perspectives to assess the quality of model responses. In the coding domain, manually examining the quality of LLM-generated content is extremely challenging, as it requires understanding long chunks of raw code and deliberately simulating code execution. To this end, we introduce BigCodeArena, an open human evaluation platform for code generation backed by a comprehensive and on-the-fly execution environment. Built on top of Chatbot Arena, BigCodeArena enables the execution of LLM-generated code and allows humans to interact with the execution process and outcomes. We collected over 14,000 raw code-centric conversation sessions across 10 widely used LLMs, spanning 10 languages and 8 types of execution environments. Among these conversations, we identified more than 4,700 multi-turn samples with pairwise human preferences. Further analysis uncovers underexplored preferences of LLMs in fine-grained domains characterized by tasks, languages, and frameworks. To systematically examine code understanding and generation capabilities of frontier LLMs, we curated two benchmarks based on the collected data, namely BigCodeReward and AutoCodeArena. For BigCodeReward, we post-processed the 4,700 conversations and evaluated the consistency between reward models and human preferences. The evaluation shows that most LLMs have superior performance in judging coding preferences when the execution results are available. Inspired by these findings, we propose AutoCodeArena, an automatic Elo rating benchmark designed to assess the coding quality of LLMs without human involvement. We find that proprietary LLMs like GPT-5, Claude-Sonnet-4, and Claude-Opus-4 still lead in code generation performance among recent emerging models.",
        "tags": [
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "46",
        "title": "Scaling Laws for Code: A More Data-Hungry Regime",
        "author": [
            "Xianzhen Luo",
            "Wenzhen Zheng",
            "Qingfu Zhu",
            "Rongyi Zhang",
            "Houyi Li",
            "Siming Huang",
            "YuanTao Fan",
            "Wanxiang Che"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08702",
        "abstract": "Code Large Language Models (LLMs) are revolutionizing software engineering. However, scaling laws that guide the efficient training are predominantly analyzed on Natural Language (NL). Given the fundamental differences like strict syntax between code and NL, it is unclear whether these laws are directly applicable to code. To address this gap, we conduct the first large-scale empirical study of scaling laws for code, comprising 117 experimental runs with model sizes from 0.2B to 3.8B and training tokens from 2B to 128B. We fit the Chinchilla law and the Farsser law. First, the results show that the more expressive Farseer law offers greater accuracy. Second, the analysis reveals that Code LLMs scale effectively with model size. Crucially, code represents a more data-hungry regime, requiring a substantially higher data-to-parameter ratio than NL. Finally, two additional sets of experiments on code-NL mixtures show that NL benefits resource-constrained scenarios, but becomes a detriment at higher compute budgets.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "47",
        "title": "ConPoSe: LLM-Guided Contact Point Selection for Scalable Cooperative Object Pushing",
        "author": [
            "Noah SteinkrÃ¼ger",
            "Nisarga Nilavadi",
            "Wolfram Burgard",
            "Tanja Katharina Kaiser"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08705",
        "abstract": "Object transportation in cluttered environments is a fundamental task in various domains, including domestic service and warehouse logistics. In cooperative object transport, multiple robots must coordinate to move objects that are too large for a single robot. One transport strategy is pushing, which only requires simple robots. However, careful selection of robot-object contact points is necessary to push the object along a preplanned path. Although this selection can be solved analytically, the solution space grows combinatorially with the number of robots and object size, limiting scalability. Inspired by how humans rely on common-sense reasoning for cooperative transport, we propose combining the reasoning capabilities of Large Language Models with local search to select suitable contact points. Our LLM-guided local search method for contact point selection, ConPoSe, successfully selects contact points for a variety of shapes, including cuboids, cylinders, and T-shapes. We demonstrate that ConPoSe scales better with the number of robots and object size than the analytical approach, and also outperforms pure LLM-based selection.",
        "tags": [
            "LLM",
            "Robotics"
        ]
    },
    {
        "id": "48",
        "title": "Thinking Longer, Not Always Smarter: Evaluating LLM Capabilities in Hierarchical Legal Reasoning",
        "author": [
            "Li Zhang",
            "Matthias Grabmair",
            "Morgan Gray",
            "Kevin Ashley"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08710",
        "abstract": "Case-based reasoning is a cornerstone of U.S. legal practice, requiring professionals to argue about a current case by drawing analogies to and distinguishing from past precedents. While Large Language Models (LLMs) have shown remarkable capabilities, their proficiency in this complex, nuanced form of reasoning needs further investigation. We propose a formal framework that decomposes the process of identifying significant distinctions between cases into three-stage reasoning tasks. Our framework models cases using factual predicates called factors, organizes them into a legal knowledge hierarchy, and defines verifiable rules for identifying distinctions, analyzing their argumentative support, and evaluating their significance. Through comprehensive evaluation of modern reasoning LLMs, we reveal a paradox: while models achieve high accuracy on surface-level reasoning (Task 1), performance degrades on hierarchical reasoning (Task 2: 64.82%-92.09%) and collapses on integrated analysis (Task 3: 11.46%-33.99%). Most strikingly, we find that models consistently expend more computational resources on incorrect responses than correct ones, suggesting that \"thinking longer\" does not always mean \"thinking smarter.\" Our work provides a methodology for fine-grained analysis of LLM reasoning capabilities in complex domains and reveals fundamental limitations that must be addressed for robust and trustworthy legal AI.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "49",
        "title": "How Many Code and Test Cases Are Enough? Evaluating Test Cases Generation from a Binary-Matrix Perspective",
        "author": [
            "Xianzhen Luo",
            "Jinyang Huang",
            "Wenzhen Zheng",
            "Qingfu Zhu",
            "Mingzheng Xu",
            "Yiheng Xu",
            "Yuantao Fan",
            "Libo Qin",
            "Wanxiang Che"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08720",
        "abstract": "Evaluating test cases automatically generated by Large Language Models (LLMs) is a critical yet challenging task. Existing benchmarks suffer from high computational costs, score inflation, and a bias towards trivial bugs over rare, critical faults. In this work, we ask two fundamental questions: (1) What is the minimal set of wrong codes sufficient to represent the entire error space? and (2) What is the minimal set of test cases needed to distinguish them? We introduce a framework that formalizes benchmark construction as finding an optimal diagnostic basis in a binary code-test matrix. The rank of this matrix specifies the minimal number of independent error patterns (wrong codes) and provides a tight upper bound on the number of test cases required for complete fault coverage. Our objective is to identify a basis of size equal to the matrix rank that maximizes internal diversity. To tackle this NP-hard problem, we propose WrongSelect, an efficient approximation algorithm to select maximally diverse wrong codes. Applying this framework to millions of competitive programming submissions, we construct TC-Bench, a compact, diverse, and inflation-resistant benchmark. Extensive experiments show that even the most advanced test case generation methods achieve only ~60% exclusion rates on TC-Bench, exposing a significant gap in their diagnostic power. Our dataset is available at: https://huggingface.co/datasets/Luoberta/TC-Bench and our code is at: https://github.com/Luowaterbi/TC-Bench.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "50",
        "title": "When to Reason: Semantic Router for vLLM",
        "author": [
            "Chen Wang",
            "Xunzhuo Liu",
            "Yuhan Liu",
            "Yue Zhu",
            "Xiangxi Mo",
            "Junchen Jiang",
            "Huamin Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08731",
        "abstract": "Large Language Models (LLMs) demonstrate substantial accuracy gains when augmented with reasoning modes such as chain-of-thought and inference-time scaling. However, reasoning also incurs significant costs in inference latency and token usage, with environmental and financial impacts, which are unnecessary for many simple prompts. We present a semantic router that classifies queries based on their reasoning requirements and selectively applies reasoning only when beneficial. Our approach achieves a 10.2 percentage point improvement in accuracy on the MMLU-Pro benchmark while reducing response latency by 47.1% and token consumption by 48.5% compared to direct inference with vLLM. These results demonstrate that semantic routing offers an effective mechanism for striking a balance between accuracy and efficiency in open-source LLM serving systems",
        "tags": [
            "CoT",
            "LLM"
        ]
    },
    {
        "id": "51",
        "title": "Transmuting prompts into weights",
        "author": [
            "Hanna Mazzawi",
            "Benoit Dherin",
            "Michael Munn",
            "Michael Wunder",
            "Javier Gonzalvo"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08734",
        "abstract": "A growing body of research has demonstrated that the behavior of large language models can be effectively controlled at inference time by directly modifying their internal states, either through vector additions to their activations or through updates to their weight matrices. These techniques, while powerful, are often guided by empirical heuristics, such as deriving steering vectors from the average activations of contrastive prompts. This work provides a theoretical foundation for these interventions, explaining how they emerge from the fundamental computations of the transformer architecture. Building on the recent finding that a prompt's influence can be mathematically mapped to implicit weight updates (Dherin et al., 2025), we generalize this theory to deep, multi-block transformers. We show how the information contained in any chunk of a user prompt is represented and composed internally through weight vectors and weight matrices. We then derive a principled method for condensing this information into token-independent thought vectors and thought matrices. These constructs provide a theoretical explanation for existing vector- and matrix-based model editing techniques and offer a direct, computationally-grounded method for transmuting textual input into reusable weight updates.",
        "tags": [
            "LLM",
            "Transformer"
        ]
    },
    {
        "id": "52",
        "title": "Coordinates from Context: Using LLMs to Ground Complex Location References",
        "author": [
            "Tessa Masis",
            "Brendan O'Connor"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08741",
        "abstract": "Geocoding is the task of linking a location reference to an actual geographic location and is essential for many downstream analyses of unstructured text. In this paper, we explore the challenging setting of geocoding compositional location references. Building on recent work demonstrating LLMs' abilities to reason over geospatial data, we evaluate LLMs' geospatial knowledge versus reasoning skills relevant to our task. Based on these insights, we propose an LLM-based strategy for geocoding compositional location references. We show that our approach improves performance for the task and that a relatively small fine-tuned LLM can achieve comparable performance with much larger off-the-shelf models.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "53",
        "title": "Exploring Cross-Client Memorization of Training Data in Large Language Models for Federated Learning",
        "author": [
            "Tinnakit Udsa",
            "Can Udomcharoenchaikit",
            "Patomporn Payoungkhamdee",
            "Sarana Nutanong",
            "Norrathep Rattanavipanon"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08750",
        "abstract": "Federated learning (FL) enables collaborative training without raw data sharing, but still risks training data memorization. Existing FL memorization detection techniques focus on one sample at a time, underestimating more subtle risks of cross-sample memorization. In contrast, recent work on centralized learning (CL) has introduced fine-grained methods to assess memorization across all samples in training data, but these assume centralized access to data and cannot be applied directly to FL. We bridge this gap by proposing a framework that quantifies both intra- and inter-client memorization in FL using fine-grained cross-sample memorization measurement across all clients. Based on this framework, we conduct two studies: (1) measuring subtle memorization across clients and (2) examining key factors that influence memorization, including decoding strategies, prefix length, and FL algorithms. Our findings reveal that FL models do memorize client data, particularly intra-client data, more than inter-client data, with memorization influenced by training and inferencing factors.",
        "tags": [
            "Detection",
            "LLM"
        ]
    },
    {
        "id": "54",
        "title": "Point and Go: Intuitive Reference Frame Reallocation in Mode Switching for Assistive Robotics",
        "author": [
            "A. Wang",
            "C. Jiang",
            "M. Przystupa",
            "J. Valentine",
            "M. Jagersand"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08753",
        "abstract": "Operating high degree of freedom robots can be difficult for users of wheelchair mounted robotic manipulators. Mode switching in Cartesian space has several drawbacks such as unintuitive control reference frames, separate translation and orientation control, and limited movement capabilities that hinder performance. We propose Point and Go mode switching, which reallocates the Cartesian mode switching reference frames into a more intuitive action space comprised of new translation and rotation modes. We use a novel sweeping motion to point the gripper, which defines the new translation axis along the robot base frame's horizontal plane. This creates an intuitive `point and go' translation mode that allows the user to easily perform complex, human-like movements without switching control modes. The system's rotation mode combines position control with a refined end-effector oriented frame that provides precise and consistent robot actions in various end-effector poses. We verified its effectiveness through initial experiments, followed by a three-task user study that compared our method to Cartesian mode switching and a state of the art learning method. Results show that Point and Go mode switching reduced completion times by 31\\%, pauses by 41\\%, and mode switches by 33\\%, while receiving significantly favorable responses in user surveys.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "55",
        "title": "Robust Heuristic Algorithm Design with LLMs",
        "author": [
            "Pantea Karimi",
            "Dany Rouhana",
            "Pooria Namyar",
            "Siva Kesava Reddy Kakarla",
            "Venkat Arun",
            "Behnaz Arzani"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08755",
        "abstract": "We posit that we can generate more robust and performant heuristics if we augment approaches using LLMs for heuristic design with tools that explain why heuristics underperform and suggestions about how to fix them. We find even simple ideas that (1) expose the LLM to instances where the heuristic underperforms; (2) explain why they occur; and (3) specialize design to regions in the input space, can produce more robust algorithms compared to existing techniques~ -- ~the heuristics we produce have a $\\sim28\\times$ better worst-case performance compared to FunSearch, improve average performance, and maintain the runtime.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "56",
        "title": "BEAR: Benchmarking and Enhancing Multimodal Language Models for Atomic Embodied Capabilities",
        "author": [
            "Yu Qi",
            "Haibo Zhao",
            "Ziyu Guo",
            "Siyuan Ma",
            "Ziyan Chen",
            "Yaokun Han",
            "Renrui Zhang",
            "Zitiantao Lin",
            "Shiji Xin",
            "Yijian Huang",
            "Kai Cheng",
            "Peiheng Wang",
            "Jiazheng Liu",
            "Jiayi Zhang",
            "Yizhe Zhu",
            "Wenqing Wang",
            "Yiran Qin",
            "Xupeng Zhu",
            "Haojie Huang",
            "Lawson L.S. Wong"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08759",
        "abstract": "Embodied capabilities refer to a suite of fundamental abilities for an agent to perceive, comprehend, and interact with the physical world. While multimodal large language models (MLLMs) show promise as embodied agents, a thorough and systematic evaluation of their embodied capabilities remains underexplored, as existing benchmarks primarily focus on specific domains such as planning or spatial understanding. To bridge this gap, we introduce BEAR, a comprehensive and fine-grained benchmark that evaluates MLLMs on atomic embodied capabilities. BEAR comprises 4,469 interleaved image-video-text entries across 14 domains in 6 categories, including tasks from low-level pointing, trajectory understanding, spatial reasoning, to high-level planning. Extensive evaluation results of 20 representative MLLMs reveal their persistent limitations across all domains of embodied capabilities. To tackle the shortfall, we propose BEAR-Agent, a multimodal conversable agent that integrates pretrained vision models to strengthen MLLM perception, 3D understanding, and planning capabilities. It substantially enhances MLLM performance across diverse embodied capabilities on BEAR, yielding a 9.12% absolute gain and a relative improvement of 17.5% on GPT-5. Furthermore, our experiments indicate that improving MLLM embodied capabilities can benefit embodied tasks in simulated environments. Project website: https://bear-official66.github.io/",
        "tags": [
            "3D",
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "57",
        "title": "Zero-Shot Policy Transfer in Reinforcement Learning using Buckingham's Pi Theorem",
        "author": [
            "Francisco Pascoa",
            "Ian Lalonde",
            "Alexandre Girard"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08768",
        "abstract": "Reinforcement learning (RL) policies often fail to generalize to new robots, tasks, or environments with different physical parameters, a challenge that limits their real-world applicability. This paper presents a simple, zero-shot transfer method based on Buckingham's Pi Theorem to address this limitation. The method adapts a pre-trained policy to new system contexts by scaling its inputs (observations) and outputs (actions) through a dimensionless space, requiring no retraining. The approach is evaluated against a naive transfer baseline across three environments of increasing complexity: a simulated pendulum, a physical pendulum for sim-to-real validation, and the high-dimensional HalfCheetah. Results demonstrate that the scaled transfer exhibits no loss of performance on dynamically similar contexts. Furthermore, on non-similar contexts, the scaled policy consistently outperforms the naive transfer, significantly expanding the volume of contexts where the original policy remains effective. These findings demonstrate that dimensional analysis provides a powerful and practical tool to enhance the robustness and generalization of RL policies.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "58",
        "title": "Prioritizing Latency with Profit: A DRL-Based Admission Control for 5G Network Slices",
        "author": [
            "Proggya Chakraborty",
            "Aaquib Asrar",
            "Jayasree Sengupta",
            "Sipra Das Bit"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08769",
        "abstract": "5G networks enable diverse services such as eMBB, URLLC, and mMTC through network slicing, necessitating intelligent admission control and resource allocation to meet stringent QoS requirements while maximizing Network Service Provider (NSP) profits. However, existing Deep Reinforcement Learning (DRL) frameworks focus primarily on profit optimization without explicitly accounting for service delay, potentially leading to QoS violations for latency-sensitive slices. Moreover, commonly used epsilon-greedy exploration of DRL often results in unstable convergence and suboptimal policy learning. To address these gaps, we propose DePSAC -- a Delay and Profit-aware Slice Admission Control scheme. Our DRL-based approach incorporates a delay-aware reward function, where penalties due to service delay incentivize the prioritization of latency-critical slices such as URLLC. Additionally, we employ Boltzmann exploration to achieve smoother and faster convergence. We implement and evaluate DePSAC on a simulated 5G core network substrate with realistic Network Slice Request (NSLR) arrival patterns. Experimental results demonstrate that our method outperforms the DSARA baseline in terms of overall profit, reduced URLLC slice delays, improved acceptance rates, and improved resource consumption. These findings validate the effectiveness of the proposed DePSAC in achieving better QoS-profit trade-offs for practical 5G network slicing scenarios.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "59",
        "title": "Detecting spills using thermal imaging, pretrained deep learning models, and a robotic platform",
        "author": [
            "Gregory Yeghiyan",
            "Jurius Azar",
            "Devson Butani",
            "Chan-Jin Chung"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08770",
        "abstract": "This paper presents a real-time spill detection system that utilizes pretrained deep learning models with RGB and thermal imaging to classify spill vs. no-spill scenarios across varied environments. Using a balanced binary dataset (4,000 images), our experiments demonstrate the advantages of thermal imaging in inference speed, accuracy, and model size. We achieve up to 100% accuracy using lightweight models like VGG19 and NasNetMobile, with thermal models performing faster and more robustly across different lighting conditions. Our system runs on consumer-grade hardware (RTX 4080) and achieves inference times as low as 44 ms with model sizes under 350 MB, highlighting its deployability in safety-critical contexts. Results from experiments with a real robot and test datasets indicate that a VGG19 model trained on thermal imaging performs best.",
        "tags": [
            "Detection",
            "Robotics"
        ]
    },
    {
        "id": "60",
        "title": "LinearSR: Unlocking Linear Attention for Stable and Efficient Image Super-Resolution",
        "author": [
            "Xiaohui Li",
            "Shaobin Zhuang",
            "Shuo Cao",
            "Yang Yang",
            "Yuandong Pu",
            "Qi Qin",
            "Siqi Luo",
            "Bin Fu",
            "Yihao Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08771",
        "abstract": "Generative models for Image Super-Resolution (SR) are increasingly powerful, yet their reliance on self-attention's quadratic complexity (O(N^2)) creates a major computational bottleneck. Linear Attention offers an O(N) solution, but its promise for photorealistic SR has remained largely untapped, historically hindered by a cascade of interrelated and previously unsolved challenges. This paper introduces LinearSR, a holistic framework that, for the first time, systematically overcomes these critical hurdles. Specifically, we resolve a fundamental, training instability that causes catastrophic model divergence using our novel \"knee point\"-based Early-Stopping Guided Fine-tuning (ESGF) strategy. Furthermore, we mitigate the classic perception-distortion trade-off with a dedicated SNR-based Mixture of Experts (MoE) architecture. Finally, we establish an effective and lightweight guidance paradigm, TAG, derived from our \"precision-over-volume\" principle. Our resulting LinearSR model simultaneously delivers state-of-the-art perceptual quality with exceptional efficiency. Its core diffusion forward pass (1-NFE) achieves SOTA-level speed, while its overall multi-step inference time remains highly competitive. This work provides the first robust methodology for applying Linear Attention in the photorealistic SR domain, establishing a foundational paradigm for future research in efficient generative super-resolution.",
        "tags": [
            "Diffusion",
            "MoE",
            "Super Resolution"
        ]
    },
    {
        "id": "61",
        "title": "Measuring Moral LLM Responses in Multilingual Capacities",
        "author": [
            "Kimaya Basu",
            "Savi Kolari",
            "Allison Yu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08776",
        "abstract": "With LLM usage becoming widespread across countries, languages, and humanity more broadly, the need to understand and guardrail their multilingual responses increases. Large-scale datasets for testing and benchmarking have been created to evaluate and facilitate LLM responses across multiple dimensions. In this study, we evaluate the responses of frontier and leading open-source models in five dimensions across low and high-resource languages to measure LLM accuracy and consistency across multilingual contexts. We evaluate the responses using a five-point grading rubric and a judge LLM. Our study shows that GPT-5 performed the best on average in each category, while other models displayed more inconsistency across language and category. Most notably, in the Consent & Autonomy and Harm Prevention & Safety categories, GPT scored the highest with averages of 3.56 and 4.73, while Gemini 2.5 Pro scored the lowest with averages of 1.39 and 1.98, respectively. These findings emphasize the need for further testing on how linguistic shifts impact LLM responses across various categories and improvement in these areas.",
        "tags": [
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "62",
        "title": "Guiding Exploration in Reinforcement Learning Through LLM-Augmented Observations",
        "author": [
            "Vaibhav Jain",
            "Gerrit Grossmann"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08779",
        "abstract": "Reinforcement Learning (RL) agents often struggle in sparse-reward environments where traditional exploration strategies fail to discover effective action sequences. Large Language Models (LLMs) possess procedural knowledge and reasoning capabilities from text pretraining that could guide RL exploration, but existing approaches create rigid dependencies where RL policies must follow LLM suggestions or incorporate them directly into reward functions. We propose a framework that provides LLM-generated action recommendations through augmented observation spaces, allowing RL agents to learn when to follow or ignore this guidance. Our method leverages LLMs' world knowledge and reasoning abilities while maintaining flexibility through soft constraints. We evaluate our approach on three BabyAI environments of increasing complexity and show that the benefits of LLM guidance scale with task difficulty. In the most challenging environment, we achieve 71% relative improvement in final success rates over baseline. The approach provides substantial sample efficiency gains, with agents reaching performance thresholds up to 9 times faster, and requires no modifications to existing RL algorithms. Our results demonstrate an effective method for leveraging LLM planning capabilities to accelerate RL training in challenging environments.",
        "tags": [
            "LLM",
            "RL"
        ]
    },
    {
        "id": "63",
        "title": "MLLM as a UI Judge: Benchmarking Multimodal LLMs for Predicting Human Perception of User Interfaces",
        "author": [
            "Reuben A. Luera",
            "Ryan Rossi",
            "Franck Dernoncourt",
            "Samyadeep Basu",
            "Sungchul Kim",
            "Subhojyoti Mukherjee",
            "Puneet Mathur",
            "Ruiyi Zhang",
            "Jihyung Kil",
            "Nedim Lipka",
            "Seunghyun Yoon",
            "Jiuxiang Gu",
            "Zichao Wang",
            "Cindy Xiong Bearfield",
            "Branislav Kveton"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08783",
        "abstract": "In an ideal design pipeline, user interface (UI) design is intertwined with user research to validate decisions, yet studies are often resource-constrained during early exploration. Recent advances in multimodal large language models (MLLMs) offer a promising opportunity to act as early evaluators, helping designers narrow options before formal testing. Unlike prior work that emphasizes user behavior in narrow domains such as e-commerce with metrics like clicks or conversions, we focus on subjective user evaluations across varied interfaces. We investigate whether MLLMs can mimic human preferences when evaluating individual UIs and comparing them. Using data from a crowdsourcing platform, we benchmark GPT-4o, Claude, and Llama across 30 interfaces and examine alignment with human judgments on multiple UI factors. Our results show that MLLMs approximate human preferences on some dimensions but diverge on others, underscoring both their potential and limitations in supplementing early UX research.",
        "tags": [
            "GPT",
            "LLM",
            "LLaMA"
        ]
    },
    {
        "id": "64",
        "title": "Geometry-aware Policy Imitation",
        "author": [
            "Yiming Li",
            "Nael Darwiche",
            "Amirreza Razmjoo",
            "Sichao Liu",
            "Yilun Du",
            "Auke Ijspeert",
            "Sylvain Calinon"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08787",
        "abstract": "We propose a Geometry-aware Policy Imitation (GPI) approach that rethinks imitation learning by treating demonstrations as geometric curves rather than collections of state-action samples. From these curves, GPI derives distance fields that give rise to two complementary control primitives: a progression flow that advances along expert trajectories and an attraction flow that corrects deviations. Their combination defines a controllable, non-parametric vector field that directly guides robot behavior. This formulation decouples metric learning from policy synthesis, enabling modular adaptation across low-dimensional robot states and high-dimensional perceptual inputs. GPI naturally supports multimodality by preserving distinct demonstrations as separate models and allows efficient composition of new demonstrations through simple additions to the distance field. We evaluate GPI in simulation and on real robots across diverse tasks. Experiments show that GPI achieves higher success rates than diffusion-based policies while running 20 times faster, requiring less memory, and remaining robust to perturbations. These results establish GPI as an efficient, interpretable, and scalable alternative to generative approaches for robotic imitation learning. Project website: https://yimingli1998.github.io/projects/GPI/",
        "tags": [
            "Diffusion",
            "Robotics"
        ]
    },
    {
        "id": "65",
        "title": "Q-Router: Agentic Video Quality Assessment with Expert Model Routing and Artifact Localization",
        "author": [
            "Shuo Xing",
            "Soumik Dey",
            "Mingyang Wu",
            "Ashirbad Mishra",
            "Hansi Wu",
            "Binbin Li",
            "Zhengzhong Tu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08789",
        "abstract": "Video quality assessment (VQA) is a fundamental computer vision task that aims to predict the perceptual quality of a given video in alignment with human judgments. Existing performant VQA models trained with direct score supervision suffer from (1) poor generalization across diverse content and tasks, ranging from user-generated content (UGC), short-form videos, to AI-generated content (AIGC), (2) limited interpretability, and (3) lack of extensibility to novel use cases or content types. We propose Q-Router, an agentic framework for universal VQA with a multi-tier model routing system. Q-Router integrates a diverse set of expert models and employs vision--language models (VLMs) as real-time routers that dynamically reason and then ensemble the most appropriate experts conditioned on the input video semantics. We build a multi-tiered routing system based on the computing budget, with the heaviest tier involving a specific spatiotemporal artifacts localization for interpretability. This agentic design enables Q-Router to combine the complementary strengths of specialized experts, achieving both flexibility and robustness in delivering consistent performance across heterogeneous video sources and tasks. Extensive experiments demonstrate that Q-Router matches or surpasses state-of-the-art VQA models on a variety of benchmarks, while substantially improving generalization and interpretability. Moreover, Q-Router excels on the quality-based question answering benchmark, Q-Bench-Video, highlighting its promise as a foundation for next-generation VQA systems. Finally, we show that Q-Router capably localizes spatiotemporal artifacts, showing potential as a reward function for post-training video generation models.",
        "tags": [
            "VLM",
            "Video Generation"
        ]
    },
    {
        "id": "66",
        "title": "COMPASS: Enhancing Agent Long-Horizon Reasoning with Evolving Context",
        "author": [
            "Guangya Wan",
            "Mingyang Ling",
            "Xiaoqi Ren",
            "Rujun Han",
            "Sheng Li",
            "Zizhao Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08790",
        "abstract": "Long-horizon tasks that require sustained reasoning and multiple tool interactions remain challenging for LLM agents: small errors compound across steps, and even state-of-the-art models often hallucinate or lose coherence. We identify context management as the central bottleneck -- extended histories cause agents to overlook critical evidence or become distracted by irrelevant information, thus failing to replan or reflect from previous mistakes. To address this, we propose COMPASS (Context-Organized Multi-Agent Planning and Strategy System), a lightweight hierarchical framework that separates tactical execution, strategic oversight, and context organization into three specialized components: (1) a Main Agent that performs reasoning and tool use, (2) a Meta-Thinker that monitors progress and issues strategic interventions, and (3) a Context Manager that maintains concise, relevant progress briefs for different reasoning stages. Across three challenging benchmarks -- GAIA, BrowseComp, and Humanity's Last Exam -- COMPASS improves accuracy by up to 20% relative to both single- and multi-agent baselines. We further introduce a test-time scaling extension that elevates performance to match established DeepResearch agents, and a post-training pipeline that delegates context management to smaller models for enhanced efficiency.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "67",
        "title": "PO-CKAN:Physics Informed Deep Operator Kolmogorov Arnold Networks with Chunk Rational Structure",
        "author": [
            "Junyi Wu",
            "Guang Lin"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08795",
        "abstract": "We propose PO-CKAN, a physics-informed deep operator framework based on Chunkwise Rational Kolmogorov--Arnold Networks (KANs), for approximating the solution operators of partial differential equations. This framework leverages a Deep Operator Network (DeepONet) architecture that incorporates Chunkwise Rational Kolmogorov--Arnold Network (CKAN) sub-networks for enhanced function approximation. The principles of Physics-Informed Neural Networks (PINNs) are integrated into the operator learning framework to enforce physical consistency. This design enables the efficient learning of physically consistent spatio-temporal solution operators and allows for rapid prediction for parametric time-dependent PDEs with varying inputs (e.g., parameters, initial/boundary conditions) after training. Validated on challenging benchmark problems, PO-CKAN demonstrates accurate operator learning with results closely matching high-fidelity solutions. PO-CKAN adopts a DeepONet-style branch--trunk architecture with its sub-networks instantiated as rational KAN modules, and enforces physical consistency via a PDE residual (PINN-style) loss. On Burgers' equation with $\\nu=0.01$, PO-CKAN reduces the mean relative $L^2$ error by approximately 48\\% compared to PI-DeepONet, and achieves competitive accuracy on the Eikonal and diffusion--reaction benchmarks.",
        "tags": [
            "Diffusion",
            "KAN"
        ]
    },
    {
        "id": "68",
        "title": "Learning What to Remember: Adaptive Probabilistic Memory Retention for Memory-Efficient Language Models",
        "author": [
            "S M Rafiuddin",
            "Muntaha Nujat Khan"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08798",
        "abstract": "Transformer attention scales quadratically with sequence length O(n^2), limiting long-context use. We propose Adaptive Retention, a probabilistic, layer-wise token selection mechanism that learns which representations to keep under a strict global budget M. Retention is modeled with Bernoulli gates trained via a Hard-Concrete/variational relaxation and enforced with a simple top-M rule at inference, making the method differentiable and drop-in for standard encoders. Across classification, extractive QA, and long-document summarization, keeping only 30-50% of tokens preserves >= 95% of full-model performance while cutting peak memory by ~35-45% and improving throughput by up to ~1.8x. This architecture-agnostic approach delivers practical long-context efficiency without modifying base attention or task heads.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "69",
        "title": "SkipSR: Faster Super Resolution with Token Skipping",
        "author": [
            "Rohan Choudhury",
            "Shanchuan Lin",
            "Jianyi Wang",
            "Hao Chen",
            "Qi Zhao",
            "Feng Cheng",
            "Lu Jiang",
            "Kris Kitani",
            "Laszlo A. Jeni"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08799",
        "abstract": "Diffusion-based super-resolution (SR) is a key component in video generation and video restoration, but is slow and expensive, limiting scalability to higher resolutions and longer videos. Our key insight is that many regions in video are inherently low-detail and gain little from refinement, yet current methods process all pixels uniformly. To take advantage of this, we propose SkipSR, a simple framework for accelerating video SR by identifying low-detail regions directly from low-resolution input, then skipping computation on them entirely, only super-resolving the areas that require refinement. This simple yet effective strategy preserves perceptual quality in both standard and one-step diffusion SR models while significantly reducing computation. In standard SR benchmarks, our method achieves up to 60% faster end-to-end latency than prior models on 720p videos with no perceptible loss in quality. Video demos are available at https://rccchoudhury.github.io/skipsr/",
        "tags": [
            "Diffusion",
            "Super Resolution",
            "Video Generation"
        ]
    },
    {
        "id": "70",
        "title": "Benchmarking Chinese Commonsense Reasoning with a Multi-hop Reasoning Perspective",
        "author": [
            "Wangjie You",
            "Xusheng Wang",
            "Xing Wang",
            "Wenxiang Jiao",
            "Chao Feng",
            "Juntao Li",
            "Min Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08800",
        "abstract": "While Large Language Models (LLMs) have demonstrated advanced reasoning capabilities, their comprehensive evaluation in general Chinese-language contexts remains understudied. To bridge this gap, we propose Chinese Commonsense Multi-hop Reasoning (CCMOR), a novel benchmark designed to evaluate LLMs' ability to integrate Chinese-specific factual knowledge with multi-step logical reasoning. Specifically, we first construct a domain-balanced seed set from existing QA datasets, then develop an LLM-powered pipeline to generate multi-hop questions anchored on factual unit chains. To ensure the quality of resulting dataset, we implement a human-in-the-loop verification system, where domain experts systematically validate and refine the generated questions. Using CCMOR, we evaluate state-of-the-art LLMs, demonstrating persistent limitations in LLMs' ability to process long-tail knowledge and execute knowledge-intensive reasoning. Notably, retrieval-augmented generation substantially mitigates these knowledge gaps, yielding significant performance gains.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "71",
        "title": "Man-Made Heuristics Are Dead. Long Live Code Generators!",
        "author": [
            "Rohit Dwivedula",
            "Divyanshu Saxena",
            "Aditya Akella",
            "Swarat Chaudhuri",
            "Daehyeok Kim"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08803",
        "abstract": "Policy design for various systems controllers has conventionally been a manual process, with domain experts carefully tailoring heuristics for the specific instance in which the policy will be deployed. In this paper, we re-imagine policy design via a novel automated search technique fueled by recent advances in generative models, specifically Large Language Model (LLM)-driven code generation. We outline the design and implementation of PolicySmith, a framework that applies LLMs to synthesize instance-optimal heuristics. We apply PolicySmith to two long-standing systems policies - web caching and congestion control, highlighting the opportunities unraveled by this LLM-driven heuristic search. For caching, PolicySmith discovers heuristics that outperform established baselines on standard open-source traces. For congestion control, we show that PolicySmith can generate safe policies that integrate directly into the Linux kernel.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "72",
        "title": "MOSAIC: Multi-agent Orchestration for Task-Intelligent Scientific Coding",
        "author": [
            "Siddeshwar Raghavan",
            "Tanwi Mallick"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08804",
        "abstract": "We present MOSAIC, a multi-agent Large Language Model (LLM) framework for solving challenging scientific coding tasks. Unlike general-purpose coding, scientific workflows require algorithms that are rigorous, interconnected with deep domain knowledge, and incorporate domain-specific reasoning, as well as algorithm iteration without requiring I/O test cases. Many scientific problems also require a sequence of subproblems to be solved, leading to the final desired result. MOSAIC is designed as a training-free framework with specially designed agents to self-reflect, create the rationale, code, and debug within a student-teacher paradigm to address the challenges of scientific code generation. This design facilitates stepwise problem decomposition, targeted error correction, and, when combined with our Consolidated Context Window (CCW), mitigates LLM hallucinations when solving complex scientific tasks involving chained subproblems. We evaluate MOSAIC on scientific coding benchmarks and demonstrate that our specialized agentic framework outperforms existing approaches in terms of accuracy, robustness, and interpretability.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "73",
        "title": "Humanoid Everyday: A Comprehensive Robotic Dataset for Open-World Humanoid Manipulation",
        "author": [
            "Zhenyu Zhao",
            "Hongyi Jing",
            "Xiawei Liu",
            "Jiageng Mao",
            "Abha Jha",
            "Hanwen Yang",
            "Rong Xue",
            "Sergey Zakharor",
            "Vitor Guizilini",
            "Yue Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08807",
        "abstract": "From loco-motion to dextrous manipulation, humanoid robots have made remarkable strides in demonstrating complex full-body capabilities. However, the majority of current robot learning datasets and benchmarks mainly focus on stationary robot arms, and the few existing humanoid datasets are either confined to fixed environments or limited in task diversity, often lacking human-humanoid interaction and lower-body locomotion. Moreover, there are a few standardized evaluation platforms for benchmarking learning-based policies on humanoid data. In this work, we present Humanoid Everyday, a large-scale and diverse humanoid manipulation dataset characterized by extensive task variety involving dextrous object manipulation, human-humanoid interaction, locomotion-integrated actions, and more. Leveraging a highly efficient human-supervised teleoperation pipeline, Humanoid Everyday aggregates high-quality multimodal sensory data, including RGB, depth, LiDAR, and tactile inputs, together with natural language annotations, comprising 10.3k trajectories and over 3 million frames of data across 260 tasks across 7 broad categories. In addition, we conduct an analysis of representative policy learning methods on our dataset, providing insights into their strengths and limitations across different task categories. For standardized evaluation, we introduce a cloud-based evaluation platform that allows researchers to seamlessly deploy their policies in our controlled setting and receive performance feedback. By releasing Humanoid Everyday along with our policy learning analysis and a standardized cloud-based evaluation platform, we intend to advance research in general-purpose humanoid manipulation and lay the groundwork for more capable and embodied robotic agents in real-world scenarios. Our dataset, data collection code, and cloud evaluation website are made publicly available on our project website.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "74",
        "title": "TinyGraphEstimator: Adapting Lightweight Language Models for Graph Structure Inference",
        "author": [
            "Michal Podstawski"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08808",
        "abstract": "Graphs provide a universal framework for representing complex relational systems, and inferring their structural properties is a core challenge in graph analysis and reasoning. While large language models have recently demonstrated emerging abilities to perform symbolic and numerical reasoning, the potential of smaller, resource-efficient models in this context remains largely unexplored. This paper investigates whether compact transformer-based language models can infer graph-theoretic parameters directly from textual graph representations. To enable systematic evaluation, we introduce the TinyGraphEstimator dataset - a balanced collection of connected graphs generated from multiple random graph models and annotated with detailed structural metadata. We evaluate several small open models on their ability to predict key graph parameters such as density, clustering, and chromatic number. Furthermore, we apply lightweight fine-tuning using the Low-Rank Adaptation (LoRA) technique, achieving consistent improvements across all evaluated metrics. The results demonstrate that small language models possess non-trivial reasoning capacity over graph-structured data and can be effectively adapted for structural inference tasks through efficient parameter tuning.",
        "tags": [
            "LLM",
            "LoRA",
            "Transformer"
        ]
    },
    {
        "id": "75",
        "title": "PyMigTool: a tool for end-to-end Python library migration",
        "author": [
            "Mohayeminul Islam",
            "Ajay Kumar Jha",
            "May Mahmoud",
            "Sarah Nadi"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08810",
        "abstract": "Library migration is the process of replacing a library with a similar one in a software project. Manual library migration is time consuming and error prone, as it requires developers to understand the Application Programming Interfaces (API) of both libraries, map equivalent APIs, and perform the necessary code transformations. Due to the difficulty of the library migration process, most of the existing automated techniques and tooling stop at the API mapping stage or support a limited set of libraries and code transformations. In this paper, we develop an end-to-end solution that can automatically migrate code between any arbitrary pair of Python libraries that provide similar functionality. Due to the promising capabilities of Large Language Models (LLMs) in code generation and transformation, we use LLMs as the primary engine for migration. Before building the tool, we first study the capabilities of LLMs for library migration on a benchmark of 321 real-world library migrations. We find that LLMs can effectively perform library migration, but some post-processing steps can further improve the performance. Based on this, we develop PyMigTool, a command line application that combines the power of LLMs, static analysis, and dynamic analysis to provide accurate library migration. We evaluate PyMigTool on 717 real-world Python applications that are not from our benchmark. We find that PyMigTool can migrate 32% of the migrations with complete correctness. Of the remaining migrations, only 14% of the migration-related changes are left for developers to fix for more than half of the projects.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "76",
        "title": "Adaptive Motion Planning via Contact-Based Intent Inference for Human-Robot Collaboration",
        "author": [
            "Jiurun Song",
            "Xiao Liang",
            "Minghui Zheng"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08811",
        "abstract": "Human-robot collaboration (HRC) requires robots to adapt their motions to human intent to ensure safe and efficient cooperation in shared spaces. Although large language models (LLMs) provide high-level reasoning for inferring human intent, their application to reliable motion planning in HRC remains challenging. Physical human-robot interaction (pHRI) is intuitive but often relies on continuous kinesthetic guidance, which imposes burdens on operators. To address these challenges, a contact-informed adaptive motion-planning framework is introduced to infer human intent directly from physical contact and employ the inferred intent for online motion correction in HRC. First, an optimization-based force estimation method is proposed to infer human-intended contact forces and locations from joint torque measurements and a robot dynamics model, thereby reducing cost and installation complexity while enabling whole-body sensitivity. Then, a torque-based contact detection mechanism with link-level localization is introduced to reduce the optimization search space and to enable real-time estimation. Subsequently, a contact-informed adaptive motion planner is developed to infer human intent from contacts and to replan robot motion online, while maintaining smoothness and adapting to human corrections. Finally, experiments on a 7-DOF manipulator are conducted to demonstrate the accuracy of the proposed force estimation method and the effectiveness of the contact-informed adaptive motion planner under perception uncertainty in HRC.",
        "tags": [
            "Detection",
            "LLM",
            "Robotics"
        ]
    },
    {
        "id": "77",
        "title": "D-CoDe: Scaling Image-Pretrained VLMs to Video via Dynamic Compression and Question Decomposition",
        "author": [
            "Yiyang Huang",
            "Yizhou Wang",
            "Yun Fu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08818",
        "abstract": "Video large language models (Vid-LLMs), which excel in diverse video-language tasks, can be effectively constructed by adapting image-pretrained vision-language models (VLMs). However, this adaptation remains challenging, as it requires processing dense and temporally extended visual inputs that exceed the capacity of image-based models. This paper identifies the perception bottleneck and token overload as key challenges in extending image-based VLMs to the video domain. To address these issues, we propose D-CoDe, a training-free adaptation framework that incorporates dynamic compression and question decomposition. Specifically, dynamic compression alleviates the perception bottleneck through adaptive selection of representative frames and content-aware aggregation of spatial tokens, thereby reducing redundancy while preserving informative content. In parallel, question decomposition mitigates token overload by reformulating the original query into sub-questions, guiding the model to focus on distinct aspects of the video and enabling more comprehensive understanding. Experiments demonstrate that D-CoDe effectively improves video understanding across various benchmarks. Furthermore, strong performance on the challenging long-video benchmark highlights the potential of D-CoDe in handling complex video-language tasks. Code is available at https://github.com/hukcc/D-CoDe.",
        "tags": [
            "LLM",
            "VLM"
        ]
    },
    {
        "id": "78",
        "title": "Search-on-Graph: Iterative Informed Navigation for Large Language Model Reasoning on Knowledge Graphs",
        "author": [
            "Jia Ao Sun",
            "Hao Yu",
            "Fabrizio Gotti",
            "Fengran Mo",
            "Yihong Wu",
            "Yuchen Hui",
            "Jian-Yun Nie"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08825",
        "abstract": "Large language models (LLMs) have demonstrated impressive reasoning abilities yet remain unreliable on knowledge-intensive, multi-hop questions -- they miss long-tail facts, hallucinate when uncertain, and their internal knowledge lags behind real-world change. Knowledge graphs (KGs) offer a structured source of relational evidence, but existing KGQA methods face fundamental trade-offs: compiling complete SPARQL queries without knowing available relations proves brittle, retrieving large subgraphs introduces noise, and complex agent frameworks with parallel exploration exponentially expand search spaces. To address these limitations, we propose Search-on-Graph (SoG), a simple yet effective framework that enables LLMs to perform iterative informed graph navigation using a single, carefully designed \\textsc{Search} function. Rather than pre-planning paths or retrieving large subgraphs, SoG follows an ``observe-then-navigate'' principle: at each step, the LLM examines actual available relations from the current entity before deciding on the next hop. This approach further adapts seamlessly to different KG schemas and handles high-degree nodes through adaptive filtering. Across six KGQA benchmarks spanning Freebase and Wikidata, SoG achieves state-of-the-art performance without fine-tuning. We demonstrate particularly strong gains on Wikidata benchmarks (+16\\% improvement over previous best methods) alongside consistent improvements on Freebase benchmarks.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "79",
        "title": "McMining: Automated Discovery of Misconceptions in Student Code",
        "author": [
            "Erfan Al-Hossami",
            "Razvan Bunescu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08827",
        "abstract": "When learning to code, students often develop misconceptions about various programming language concepts. These can not only lead to bugs or inefficient code, but also slow down the learning of related concepts. In this paper, we introduce McMining, the task of mining programming misconceptions from samples of code from a student. To enable the training and evaluation of McMining systems, we develop an extensible benchmark dataset of misconceptions together with a large set of code samples where these misconceptions are manifested. We then introduce two LLM-based McMiner approaches and through extensive evaluations show that models from the Gemini, Claude, and GPT families are effective at discovering misconceptions in student code.",
        "tags": [
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "80",
        "title": "Everyone prefers human writers, including AI",
        "author": [
            "Wouter Haverals",
            "Meredith Martin"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08831",
        "abstract": "As AI writing tools become widespread, we need to understand how both humans and machines evaluate literary style, a domain where objective standards are elusive and judgments are inherently subjective. We conducted controlled experiments using Raymond Queneau's Exercises in Style (1947) to measure attribution bias across evaluators. Study 1 compared human participants (N=556) and AI models (N=13) evaluating literary passages from Queneau versus GPT-4-generated versions under three conditions: blind, accurately labeled, and counterfactually labeled. Study 2 tested bias generalization across a 14$\\times$14 matrix of AI evaluators and creators. Both studies revealed systematic pro-human attribution bias. Humans showed +13.7 percentage point (pp) bias (Cohen's h = 0.28, 95% CI: 0.21-0.34), while AI models showed +34.3 percentage point bias (h = 0.70, 95% CI: 0.65-0.76), a 2.5-fold stronger effect (P$<$0.001). Study 2 confirmed this bias operates across AI architectures (+25.8pp, 95% CI: 24.1-27.6%), demonstrating that AI systems systematically devalue creative content when labeled as \"AI-generated\" regardless of which AI created it. We also find that attribution labels cause evaluators to invert assessment criteria, with identical features receiving opposing evaluations based solely on perceived authorship. This suggests AI models have absorbed human cultural biases against artificial creativity during training. Our study represents the first controlled comparison of attribution bias between human and artificial evaluators in aesthetic judgment, revealing that AI systems not only replicate but amplify this human tendency.",
        "tags": [
            "GPT"
        ]
    },
    {
        "id": "81",
        "title": "Reinforcement Learning-Driven Edge Management for Reliable Multi-view 3D Reconstruction",
        "author": [
            "Motahare Mounesan",
            "Sourya Saha",
            "Houchao Gan",
            "Md. Nurul Absur",
            "Saptarshi Debroy"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08839",
        "abstract": "Real-time multi-view 3D reconstruction is a mission-critical application for key edge-native use cases, such as fire rescue, where timely and accurate 3D scene modeling enables situational awareness and informed decision-making. However, the dynamic and unpredictable nature of edge resource availability introduces disruptions, such as degraded image quality, unstable network links, and fluctuating server loads, which challenge the reliability of the reconstruction pipeline. In this work, we present a reinforcement learning (RL)-based edge resource management framework for reliable 3D reconstruction to ensure high quality reconstruction within a reasonable amount of time, despite the system operating under a resource-constrained and disruption-prone environment. In particular, the framework adopts two cooperative Q-learning agents, one for camera selection and one for server selection, both of which operate entirely online, learning policies through interactions with the edge environment. To support learning under realistic constraints and evaluate system performance, we implement a distributed testbed comprising lab-hosted end devices and FABRIC infrastructure-hosted edge servers to emulate smart city edge infrastructure under realistic disruption scenarios. Results show that the proposed framework improves application reliability by effectively balancing end-to-end latency and reconstruction quality in dynamic environments.",
        "tags": [
            "3D",
            "RL"
        ]
    },
    {
        "id": "82",
        "title": "Maple: A Multi-agent System for Portable Deep Learning across Clusters",
        "author": [
            "Molang Wu",
            "Zhao Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08842",
        "abstract": "Training deep learning (DL) models across Graphics Processing Unit (GPU) clusters is technically challenging. One aspect is that users have to compose command lines to adapt to the heterogeneous launchers, schedulers, affinity options, DL framework arguments, and environment variables. Composing correct command lines is error-prone and can easily frustrate users, impeding research or wasting resources. In this work, we present Maple, a multi-agent system that generates correct DL command lines with users' natural language input. Maple consists of four agents with the functionalities of information extraction, template retrieval, command line verification, and error correction. We evaluate Maple on nine GPU clusters across national computing centers in the U.S., five representative deep learning model families, and four commonly used parallel DL training paradigms. Our experiments also cover schedulers of SLURM and PBS and heterogeneous architectures, such as NVIDIA A100/H200 GPUs and Intel Max series GPUs. Maple achieves 92.0% accuracy in generating command lines across the 567 test cases. Leverage multiple language models with an aggregated size of 10B parameters, Maple delivers comparable performance to the state-of-the-art models of GPT-5, Claude, and Gemini. Together, these results highlight Maple's practical value in enabling portable and scalable distributed DL across heterogeneous HPC environments.",
        "tags": [
            "GPT"
        ]
    },
    {
        "id": "83",
        "title": "What Is Your Agent's GPA? A Framework for Evaluating Agent Goal-Plan-Action Alignment",
        "author": [
            "Allison Sihan Jia",
            "Daniel Huang",
            "Nikhil Vytla",
            "Nirvika Choudhury",
            "John C Mitchell",
            "Anupam Datta"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08847",
        "abstract": "We introduce the Agent GPA (Goal-Plan-Action) framework: an evaluation paradigm based on an agent's operational loop of setting goals, devising plans, and executing actions. The framework includes five evaluation metrics: Goal Fulfillment, Logical Consistency, Execution Efficiency, Plan Quality, and Plan Adherence. Logical Consistency checks that an agent's actions are consistent with its prior actions. Execution Efficiency checks whether the agent executes in the most efficient way to achieve its goal. Plan Quality checks whether an agent's plans are aligned with its goals; Plan Adherence checks if an agent's actions are aligned with its plan; and Goal Fulfillment checks that agent's final outcomes match the stated goals. Our experimental results on two benchmark datasets - the public TRAIL/GAIA dataset and an internal dataset for a production-grade data agent - show that this framework (a) provides a systematic way to cover a broad range of agent failures, including all agent errors on the TRAIL/GAIA benchmark dataset; (b) supports LLM-judges that exhibit strong agreement with human annotation, covering 80% to over 95% errors; and (c) localizes errors with 86% agreement to enable targeted improvement of agent performance.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "84",
        "title": "FOLK: Fast Open-Vocabulary 3D Instance Segmentation via Label-guided Knowledge Distillation",
        "author": [
            "Hongrui Wu",
            "Zhicheng Gao",
            "Jin Cao",
            "Kelu Yao",
            "Wen Shen",
            "Zhihua Wei"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08849",
        "abstract": "Open-vocabulary 3D instance segmentation seeks to segment and classify instances beyond the annotated label space. Existing methods typically map 3D instances to 2D RGB-D images, and then employ vision-language models (VLMs) for classification. However, such a mapping strategy usually introduces noise from 2D occlusions and incurs substantial computational and memory costs during inference, slowing down the inference speed. To address the above problems, we propose a Fast Open-vocabulary 3D instance segmentation method via Label-guided Knowledge distillation (FOLK). Our core idea is to design a teacher model that extracts high-quality instance embeddings and distills its open-vocabulary knowledge into a 3D student model. In this way, during inference, the distilled 3D model can directly classify instances from the 3D point cloud, avoiding noise caused by occlusions and significantly accelerating the inference process. Specifically, we first design a teacher model to generate a 2D CLIP embedding for each 3D instance, incorporating both visibility and viewpoint diversity, which serves as the learning target for distillation. We then develop a 3D student model that directly produces a 3D embedding for each 3D instance. During training, we propose a label-guided distillation algorithm to distill open-vocabulary knowledge from label-consistent 2D embeddings into the student model. FOLK conducted experiments on the ScanNet200 and Replica datasets, achieving state-of-the-art performance on the ScanNet200 dataset with an AP50 score of 35.7, while running approximately 6.0x to 152.2x faster than previous methods. All codes will be released after the paper is accepted.",
        "tags": [
            "3D",
            "CLIP",
            "Segmentation",
            "VLM"
        ]
    },
    {
        "id": "85",
        "title": "Repository-Aware File Path Retrieval via Fine-Tuned LLMs",
        "author": [
            "Vasudha Yanuganti",
            "Ishaan Puri",
            "Swapnil Chhatre",
            "Mantinder Singh",
            "Ashok Jallepalli",
            "Hritvik Shrivastava",
            "Pradeep Kumar Sharma"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08850",
        "abstract": "Modern codebases make it hard for developers and AI coding assistants to find the right source files when answering questions like \"How does this feature work?\" or \"Where was the bug introduced?\" Traditional code search (keyword or IR based) often misses semantic context and cross file links, while large language models (LLMs) understand natural language but lack repository specific detail. We present a method for file path retrieval that fine tunes a strong LLM (Qwen3-8B) with QLoRA and Unsloth optimizations to predict relevant file paths directly from a natural language query. To build training data, we introduce six code aware strategies that use abstract syntax tree (AST) structure and repository content to generate realistic question-answer pairs, where answers are sets of file paths. The strategies range from single file prompts to hierarchical repository summaries, providing broad coverage. We fine tune on Python projects including Flask, Click, Jinja, FastAPI, and PyTorch, and obtain high retrieval accuracy: up to 91\\% exact match and 93\\% recall on held out queries, clearly beating single strategy training. On a large codebase like PyTorch (about 4,000 Python files), the model reaches 59\\% recall, showing scalability. We analyze how multi level code signals help the LLM reason over cross file context and discuss dataset design, limits (for example, context length in very large repos), and future integration of retrieval with LLM based code intelligence.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "86",
        "title": "CDE: Concept-Driven Exploration for Reinforcement Learning",
        "author": [
            "Le Mao",
            "Andrew H. Liu",
            "Renos Zabounidis",
            "Zachary Kingston",
            "Joseph Campbell"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08851",
        "abstract": "Intelligent exploration remains a critical challenge in reinforcement learning (RL), especially in visual control tasks. Unlike low-dimensional state-based RL, visual RL must extract task-relevant structure from raw pixels, making exploration inefficient. We propose Concept-Driven Exploration (CDE), which leverages a pre-trained vision-language model (VLM) to generate object-centric visual concepts from textual task descriptions as weak, potentially noisy supervisory signals. Rather than directly conditioning on these noisy signals, CDE trains a policy to reconstruct the concepts via an auxiliary objective, using reconstruction accuracy as an intrinsic reward to guide exploration toward task-relevant objects. Because the policy internalizes these concepts, VLM queries are only needed during training, reducing dependence on external models during deployment. Across five challenging simulated visual manipulation tasks, CDE achieves efficient, targeted exploration and remains robust to noisy VLM predictions. Finally, we demonstrate real-world transfer by deploying CDE on a Franka Research 3 arm, attaining an 80\\% success rate in a real-world manipulation task.",
        "tags": [
            "RL",
            "VLM"
        ]
    },
    {
        "id": "87",
        "title": "Time-Aware Feature Selection: Adaptive Temporal Masking for Stable Sparse Autoencoder Training",
        "author": [
            "T. Ed Li",
            "Junyu Ren"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08855",
        "abstract": "Understanding the internal representations of large language models is crucial for ensuring their reliability and safety, with sparse autoencoders (SAEs) emerging as a promising interpretability approach. However, current SAE training methods face feature absorption, where features (or neurons) are absorbed into each other to minimize $L_1$ penalty, making it difficult to consistently identify and analyze model behaviors. We introduce Adaptive Temporal Masking (ATM), a novel training approach that dynamically adjusts feature selection by tracking activation magnitudes, frequencies, and reconstruction contributions to compute importance scores that evolve over time. ATM applies a probabilistic masking mechanism based on statistical thresholding of these importance scores, creating a more natural feature selection process. Through extensive experiments on the Gemma-2-2b model, we demonstrate that ATM achieves substantially lower absorption scores compared to existing methods like TopK and JumpReLU SAEs, while maintaining excellent reconstruction quality. These results establish ATM as a principled solution for learning stable, interpretable features in neural networks, providing a foundation for more reliable model analysis.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "88",
        "title": "Pattern Enhanced Multi-Turn Jailbreaking: Exploiting Structural Vulnerabilities in Large Language Models",
        "author": [
            "Ragib Amin Nihal",
            "Rui Wen",
            "Kazuhiro Nakadai",
            "Jun Sakuma"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08859",
        "abstract": "Large language models (LLMs) remain vulnerable to multi-turn jailbreaking attacks that exploit conversational context to bypass safety constraints gradually. These attacks target different harm categories (like malware generation, harassment, or fraud) through distinct conversational approaches (educational discussions, personal experiences, hypothetical scenarios). Existing multi-turn jailbreaking methods often rely on heuristic or ad hoc exploration strategies, providing limited insight into underlying model weaknesses. The relationship between conversation patterns and model vulnerabilities across harm categories remains poorly understood. We propose Pattern Enhanced Chain of Attack (PE-CoA), a framework of five conversation patterns to construct effective multi-turn jailbreaks through natural dialogue. Evaluating PE-CoA on twelve LLMs spanning ten harm categories, we achieve state-of-the-art performance, uncovering pattern-specific vulnerabilities and LLM behavioral characteristics: models exhibit distinct weakness profiles where robustness to one conversational pattern does not generalize to others, and model families share similar failure modes. These findings highlight limitations of safety training and indicate the need for pattern-aware defenses. Code available on: https://github.com/Ragib-Amin-Nihal/PE-CoA",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "89",
        "title": "ReviewerToo: Should AI Join The Program Committee? A Look At The Future of Peer Review",
        "author": [
            "Gaurav Sahu",
            "Hugo Larochelle",
            "Laurent Charlin",
            "Christopher Pal"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08867",
        "abstract": "Peer review is the cornerstone of scientific publishing, yet it suffers from inconsistencies, reviewer subjectivity, and scalability challenges. We introduce ReviewerToo, a modular framework for studying and deploying AI-assisted peer review to complement human judgment with systematic and consistent assessments. ReviewerToo supports systematic experiments with specialized reviewer personas and structured evaluation criteria, and can be partially or fully integrated into real conference workflows. We validate ReviewerToo on a carefully curated dataset of 1,963 paper submissions from ICLR 2025, where our experiments with the gpt-oss-120b model achieves 81.8% accuracy for the task of categorizing a paper as accept/reject compared to 83.9% for the average human reviewer. Additionally, ReviewerToo-generated reviews are rated as higher quality than the human average by an LLM judge, though still trailing the strongest expert contributions. Our analysis highlights domains where AI reviewers excel (e.g., fact-checking, literature coverage) and where they struggle (e.g., assessing methodological novelty and theoretical contributions), underscoring the continued need for human expertise. Based on these findings, we propose guidelines for integrating AI into peer-review pipelines, showing how AI can enhance consistency, coverage, and fairness while leaving complex evaluative judgments to domain experts. Our work provides a foundation for systematic, hybrid peer-review systems that scale with the growth of scientific publishing.",
        "tags": [
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "90",
        "title": "Quality Estimation Reranking for Document-Level Translation",
        "author": [
            "Krzysztof Mrozinski",
            "Minji Kang",
            "Ahmed Khota",
            "Vincent Michael Sutanto",
            "Giovanni Gatti De Giacomo"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08870",
        "abstract": "Quality estimation (QE) reranking is a form of quality-aware decoding which aims to improve machine translation (MT) by scoring and selecting the best candidate from a pool of generated translations. While known to be effective at the sentence level, its application to the increasingly prominent domain of document-level translation remains underexplored. In this work, we evaluate QE reranking performance on document-level (rather than the typical sentence-level) translation, using various learned and large language model (LLM)-based QE metrics. We find that with our best learned metric, SLIDE, BLEURT-20 scores improve by +2.00 with only two candidates, and by +5.09 with 32, across both decoder-only LLM models and encoder-decoder neural machine translation (NMT) models. Using the best LLM-based metric, GEMBA-DA, gains of +1.63 and +4.30 are achieved under the same conditions. Although gains shrink with longer inputs, reranking with 32 candidates yields improvements of +2.34 (SLIDE) and +1.40 (GEMBA-DA) on our longest documents (512-1024 source tokens). These findings demonstrate the practical value of document-level QE, with minimal runtime overhead given suitable translation models and hardware.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "91",
        "title": "GTAlign: Game-Theoretic Alignment of LLM Assistants for Mutual Welfare",
        "author": [
            "Siqi Zhu",
            "David Zhang",
            "Pedro Cisneros-Velarde",
            "Jiaxuan You"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08872",
        "abstract": "Large Language Models (LLMs) have achieved remarkable progress in reasoning, yet sometimes produce responses that are suboptimal for users in tasks such as writing, information seeking, or providing practical guidance. Conventional alignment practices typically assume that maximizing model reward also maximizes user welfare, but this assumption frequently fails in practice: models may over-clarify or generate overly verbose reasoning when users prefer concise answers. Such behaviors resemble the prisoner's dilemma, where individually rational choices lead to socially suboptimal outcomes. The fundamental challenge is the lack of a principled decision making mechanism that mutually benefits both the LLM and the user. We propose Game-Theoretic Alignment (GTAlign), an alignment framework that integrates game-theoretic decision making into both reasoning and training. During reasoning, the model explicitly treats user-LLM interaction as a strategic game: it constructs payoff matrices within its reasoning chain to estimate welfare for both itself and the user, and then selects actions that are mutually beneficial. During training, we introduce a mutual welfare reward that reinforces cooperative responses, aligning model behavior with socially efficient outcomes. In addition, we introduce an inference technique that leverages game-theoretic reasoning to dynamically adapt LLM's response when pricing policies of LLM service change. Extensive experiments demonstrate that GTAlign substantially improves reasoning efficiency, answer quality, and mutual welfare compared to baselines across diverse tasks. The code is available at https://github.com/ulab-uiuc/GTAlign .",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "92",
        "title": "Mozart: A Chiplet Ecosystem-Accelerator Codesign Framework for Composable Bespoke Application Specific Integrated Circuits",
        "author": [
            "Haoran Jin",
            "Jirong Yang",
            "Yunpeng Liu",
            "Barry Lyu",
            "Kangqi Zhang",
            "Nathaniel Bleier"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08873",
        "abstract": "Modern AI acceleration faces a fundamental challenge: conventional assumptions about memory requirements, batching effectiveness, and latency-throughput tradeoffs are systemwide generalizations that ignore the heterogeneous computational patterns of individual neural network operators. However, going towards network-level customization and operator-level heterogeneity incur substantial Non-Recurring Engineering (NRE) costs. While chiplet-based approaches have been proposed to amortize NRE costs, reuse opportunities remain limited without carefully identifying which chiplets are truly necessary. This paper introduces Mozart, a chiplet ecosystem and accelerator codesign framework that systematically constructs low cost bespoke application-specific integrated circuits (BASICs). BASICs leverage operator-level disaggregation to explore chiplet and memory heterogeneity, tensor fusion, and tensor parallelism, with place-and-route validation ensuring physical implementability. The framework also enables constraint-aware system-level optimization across deployment contexts ranging from datacenter inference serving to edge computing in autonomous vehicles. The evaluation confirms that with just 8 strategically selected chiplets, Mozart-generated composite BASICs achieve 43.5%, 25.4%, 67.7%, and 78.8% reductions in energy, energy-cost product, energy-delay product (EDP), and energy-delay-cost product compared to traditional homogeneous accelerators. For datacenter LLM serving, Mozart achieves 15-19% energy reduction and 35-39% energy-cost improvement. In speculative decoding, Mozart delivers throughput improvements of 24.6-58.6% while reducing energy consumption by 38.6-45.6%. For autonomous vehicle perception, Mozart reduces energy-cost by 25.54% and energy by 10.53% under real-time constraints.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "93",
        "title": "Vector Graph-Based Repository Understanding for Issue-Driven File Retrieval",
        "author": [
            "Kostiantyn Bevziuk",
            "Andrii Fatula",
            "Svetozar Lashin Yaroslav Opanasenko",
            "Anna Tukhtarova",
            "Ashok Jallepalli Pradeepkumar Sharma",
            "Hritvik Shrivastava"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08876",
        "abstract": "We present a repository decomposition system that converts large software repositories into a vectorized knowledge graph which mirrors project architectural and semantic structure, capturing semantic relationships and allowing a significant level of automatization of further repository development. The graph encodes syntactic relations such as containment, implementation, references, calls, and inheritance, and augments nodes with LLM-derived summaries and vector embeddings. A hybrid retrieval pipeline combines semantic retrieval with graph-aware expansion, and an LLM-based assistant formulates constrained, read-only graph requests and produces human-oriented explanations.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "94",
        "title": "ControlAudio: Tackling Text-Guided, Timing-Indicated and Intelligible Audio Generation via Progressive Diffusion Modeling",
        "author": [
            "Yuxuan Jiang",
            "Zehua Chen",
            "Zeqian Ju",
            "Yusheng Dai",
            "Weibei Dou",
            "Jun Zhu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08878",
        "abstract": "Text-to-audio (TTA) generation with fine-grained control signals, e.g., precise timing control or intelligible speech content, has been explored in recent works. However, constrained by data scarcity, their generation performance at scale is still compromised. In this study, we recast controllable TTA generation as a multi-task learning problem and introduce a progressive diffusion modeling approach, ControlAudio. Our method adeptly fits distributions conditioned on more fine-grained information, including text, timing, and phoneme features, through a step-by-step strategy. First, we propose a data construction method spanning both annotation and simulation, augmenting condition information in the sequence of text, timing, and phoneme. Second, at the model training stage, we pretrain a diffusion transformer (DiT) on large-scale text-audio pairs, achieving scalable TTA generation, and then incrementally integrate the timing and phoneme features with unified semantic representations, expanding controllability. Finally, at the inference stage, we propose progressively guided generation, which sequentially emphasizes more fine-grained information, aligning inherently with the coarse-to-fine sampling nature of DiT. Extensive experiments show that ControlAudio achieves state-of-the-art performance in terms of temporal accuracy and speech clarity, significantly outperforming existing methods on both objective and subjective evaluations. Demo samples are available at: https://control-audio.github.io/Control-Audio.",
        "tags": [
            "DiT",
            "Diffusion",
            "Transformer"
        ]
    },
    {
        "id": "95",
        "title": "Model-Based Lookahead Reinforcement Learning for in-hand manipulation",
        "author": [
            "Alexandre Lopes",
            "Catarina Barata",
            "Plinio Moreno"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08884",
        "abstract": "In-Hand Manipulation, as many other dexterous tasks, remains a difficult challenge in robotics by combining complex dynamic systems with the capability to control and manoeuvre various objects using its actuators. This work presents the application of a previously developed hybrid Reinforcement Learning (RL) Framework to In-Hand Manipulation task, verifying that it is capable of improving the performance of the task. The model combines concepts of both Model-Free and Model-Based Reinforcement Learning, by guiding a trained policy with the help of a dynamic model and value-function through trajectory evaluation, as done in Model Predictive Control. This work evaluates the performance of the model by comparing it with the policy that will be guided. To fully explore this, various tests are performed using both fully-actuated and under-actuated simulated robotic hands to manipulate different objects for a given task. The performance of the model will also be tested for generalization tests, by changing the properties of the objects in which both the policy and dynamic model were trained, such as density and size, and additionally by guiding a trained policy in a certain object to perform the same task in a different one. The results of this work show that, given a policy with high average reward and an accurate dynamic model, the hybrid framework improves the performance of in-hand manipulation tasks for most test cases, even when the object properties are changed. However, this improvement comes at the expense of increasing the computational cost, due to the complexity of trajectory evaluation.",
        "tags": [
            "RL",
            "Robotics"
        ]
    },
    {
        "id": "96",
        "title": "FinAuditing: A Financial Taxonomy-Structured Multi-Document Benchmark for Evaluating LLMs",
        "author": [
            "Yan Wang",
            "Keyi Wang",
            "Shanshan Yang",
            "Jaisal Patel",
            "Jeff Zhao",
            "Fengran Mo",
            "Xueqing Peng",
            "Lingfei Qian",
            "Jimin Huang",
            "Guojun Xiong",
            "Xiao-Yang Liu",
            "Jian-Yun Nie"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08886",
        "abstract": "The complexity of the Generally Accepted Accounting Principles (GAAP) and the hierarchical structure of eXtensible Business Reporting Language (XBRL) filings make financial auditing increasingly difficult to automate and verify. While large language models (LLMs) have demonstrated strong capabilities in unstructured text understanding, their ability to reason over structured, interdependent, and taxonomy-driven financial documents remains largely unexplored. To fill this gap, we introduce FinAuditing, the first taxonomy-aligned, structure-aware, multi-document benchmark for evaluating LLMs on financial auditing tasks. Built from real US-GAAP-compliant XBRL filings, FinAuditing defines three complementary subtasks, FinSM for semantic consistency, FinRE for relational consistency, and FinMR for numerical consistency, each targeting a distinct aspect of structured auditing reasoning. We further propose a unified evaluation framework integrating retrieval, classification, and reasoning metrics across these subtasks. Extensive zero-shot experiments on 13 state-of-the-art LLMs reveal that current models perform inconsistently across semantic, relational, and mathematical dimensions, with accuracy drops of up to 60-90% when reasoning over hierarchical multi-document structures. Our findings expose the systematic limitations of modern LLMs in taxonomy-grounded financial reasoning and establish FinAuditing as a foundation for developing trustworthy, structure-aware, and regulation-aligned financial intelligence systems. The benchmark dataset is available at Hugging Face.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "97",
        "title": "Exploring Multi-Temperature Strategies for Token- and Rollout-Level Control in RLVR",
        "author": [
            "Haomin Zhuang",
            "Yujun Zhou",
            "Taicheng Guo",
            "Yue Huang",
            "Fangxu Liu",
            "Kai Song",
            "Xiangliang Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08892",
        "abstract": "Reinforcement Learning has demonstrated substantial improvements in the reasoning abilities of Large Language Models (LLMs), exhibiting significant applicability across various domains. Recent research has identified that tokens within LLMs play distinct roles during reasoning tasks, categorizing them into high-entropy reasoning tokens and low-entropy knowledge tokens. Prior approaches have typically focused on restricting updates to indirectly encourage exploration, yet they do not explicitly facilitate exploratory behavior during the token generation stage itself. In this work, we introduce a complementary approach that explicitly promotes exploration during sampling by applying distinct temperature settings for different token types. Specifically, our method employs higher temperatures for reasoning tokens to actively encourage exploration, while retaining lower temperatures for knowledge tokens to maintain factual correctness. Furthermore, we systematically investigate various multi-temperature scheduling strategies and their impacts within reinforcement learning contexts. Empirical evaluations on several reasoning benchmarks demonstrate that our approach significantly enhances the reasoning performance of LLMs. The code is available at https://github.com/zhmzm/Multi_Temperature_Verl.git.",
        "tags": [
            "LLM",
            "RL"
        ]
    },
    {
        "id": "98",
        "title": "Pinpointing crucial steps: Attribution-based Credit Assignment for Verifiable Reinforcement Learning",
        "author": [
            "Junxi Yin",
            "Haisen Luo",
            "Zhenyu Li",
            "Yihua Liu",
            "Dan Liu",
            "Zequn Li",
            "Xiaohang Xu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08899",
        "abstract": "While Reinforcement Learning with Verifiable Rewards (RLVR) enhances complex reasoning in LLMs, current methods struggle to balance exploration and exploitation. This leads to critical issues like inaccurate credit assignment for intermediate steps and premature entropy collapse, limiting model performance. To address this, we introduce Attribution-based Contribution to Policy Optimization (ACPO), a phased framework that incorporates a difficulty-aware curriculum. ACPO improves exploration by using trajectory semantic segmentation and an attribution-based representation to dynamically regulate policy entropy, thus mitigating its collapse. Concurrently, it enhances exploitation with a factorized reward system that precisely quantifies the hierarchical contribution of each reasoning step, ensuring accurate credit assignment. Extensive experiments on challenging benchmarks, including AIME, MATH, and AMC, demonstrate that ACPO significantly outperforms existing state-of-the-art approaches.",
        "tags": [
            "LLM",
            "RL",
            "Segmentation"
        ]
    },
    {
        "id": "99",
        "title": "Autoencoding-Free Context Compression for LLMs via Contextual Semantic Anchors",
        "author": [
            "Xin Liu",
            "RunSong Zhao",
            "PengCheng Huang",
            "XinYu Liu",
            "JunYi Xiao",
            "ChunYang Xiao",
            "Tong Xiao",
            "Shengxiang Gao",
            "Zhengtao Yu",
            "JingBo Zhu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08907",
        "abstract": "Context compression presents a promising approach for accelerating large language model (LLM) inference by compressing long contexts into compact representations. Current context compression methods predominantly rely on autoencoding tasks to train context-agnostic compression tokens to compress contextual semantics. While autoencoding tasks enable compression tokens to acquire compression capabilities, compression via autoencoding tasks creates a fundamental mismatch: the models are optimized for reconstruction that diverge from actual downstream tasks, thereby weakening the features more beneficial for real-world usage. We propose Semantic-Anchor Compression (SAC), a novel method that shifts from autoencoding task based compression to an architecture that is equipped with this compression capability \\textit{a priori}. Instead of training models to compress contexts through autoencoding tasks, SAC directly selects so-called anchor tokens from the original context and aggregates contextual information into their key-value (KV) representations. By deriving representations directly from the contextual tokens, SAC eliminates the need for autoencoding training. To ensure compression performance while directly leveraging anchor tokens, SAC incorporates two key designs: (1) anchor embeddings that enable the compressor to identify critical tokens, and (2) bidirectional attention modification that allows anchor tokens to capture information from the entire context. Experimental results demonstrate that SAC consistently outperforms existing context compression methods across various compression ratios. On out-of-distribution evaluation using MRQA, SAC achieves 1 EM improvement at 5x compression over strong baselines, with increasing advantages at higher compression ratios.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "100",
        "title": "Velocity and Density-Aware RRI Analysis and Optimization for AoI Minimization in IoV SPS",
        "author": [
            "Maoxin Ji",
            "Tong Wang",
            "Qiong Wu",
            "Pingyi Fan",
            "Nan Cheng",
            "Wen Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08911",
        "abstract": "Addressing the problem of Age of Information (AoI) deterioration caused by packet collisions and vehicle speed-related channel uncertainties in Semi-Persistent Scheduling (SPS) for the Internet of Vehicles (IoV), this letter proposes an optimization approach based on Large Language Models (LLM) and Deep Deterministic Policy Gradient (DDPG). First, an AoI calculation model influenced by vehicle speed, vehicle density, and Resource Reservation Interval (RRI) is established, followed by the design of a dual-path optimization scheme. The DDPG is guided by the state space and reward function, while the LLM leverages contextual learning to generate optimal parameter configurations. Experimental results demonstrate that LLM can significantly reduce AoI after accumulating a small number of exemplars without requiring model training, whereas the DDPG method achieves more stable performance after training.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "101",
        "title": "Beyond Words: Infusing Conversational Agents with Human-like Typing Behaviors",
        "author": [
            "Jijie Zhou",
            "Yuhan Hu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08912",
        "abstract": "Recently, large language models have facilitated the emergence of highly intelligent conversational AI capable of engaging in human-like dialogues. However, a notable distinction lies in the fact that these AI models predominantly generate responses rapidly, often producing extensive content without emulating the thoughtful process characteristic of human cognition and typing. This paper presents a design aimed at simulating human-like typing behaviors, including patterns such as hesitation and self-editing, as well as a preliminary user experiment to understand whether and to what extent the agent with human-like typing behaviors could potentially affect conversational engagement and its trustworthiness. We've constructed an interactive platform featuring user-adjustable parameters, allowing users to personalize the AI's communication style and thus cultivate a more enriching and immersive conversational experience. Our user experiment, involving interactions with three types of agents - a baseline agent, one simulating hesitation, and another integrating both hesitation and self-editing behaviors - reveals a preference for the agent that incorporates both behaviors, suggesting an improvement in perceived naturalness and trustworthiness. Through the insights from our design process and both quantitative and qualitative feedback from user experiments, this paper contributes to the multimodal interaction design and user experience for conversational AI, advocating for a more human-like, engaging, and trustworthy communication paradigm.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "102",
        "title": "Artificial Impressions: Evaluating Large Language Model Behavior Through the Lens of Trait Impressions",
        "author": [
            "Nicholas Deas",
            "Kathleen McKeown"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08915",
        "abstract": "We introduce and study artificial impressions--patterns in LLMs' internal representations of prompts that resemble human impressions and stereotypes based on language. We fit linear probes on generated prompts to predict impressions according to the two-dimensional Stereotype Content Model (SCM). Using these probes, we study the relationship between impressions and downstream model behavior as well as prompt features that may inform such impressions. We find that LLMs inconsistently report impressions when prompted, but also that impressions are more consistently linearly decodable from their hidden representations. Additionally, we show that artificial impressions of prompts are predictive of the quality and use of hedging in model responses. We also investigate how particular content, stylistic, and dialectal features in prompts impact LLM impressions.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "103",
        "title": "PHyCLIP: $\\ell_1$-Product of Hyperbolic Factors Unifies Hierarchy and Compositionality in Vision-Language Representation Learning",
        "author": [
            "Daiki Yoshikawa",
            "Takashi Matsubara"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08919",
        "abstract": "Vision-language models have achieved remarkable success in multi-modal representation learning from large-scale pairs of visual scenes and linguistic descriptions. However, they still struggle to simultaneously express two distinct types of semantic structures: the hierarchy within a concept family (e.g., dog $\\preceq$ mammal $\\preceq$ animal) and the compositionality across different concept families (e.g., \"a dog in a car\" $\\preceq$ dog, car). Recent works have addressed this challenge by employing hyperbolic space, which efficiently captures tree-like hierarchy, yet its suitability for representing compositionality remains unclear. To resolve this dilemma, we propose PHyCLIP, which employs an $\\ell_1$-Product metric on a Cartesian product of Hyperbolic factors. With our design, intra-family hierarchies emerge within individual hyperbolic factors, and cross-family composition is captured by the $\\ell_1$-product metric, analogous to a Boolean algebra. Experiments on zero-shot classification, retrieval, hierarchical classification, and compositional understanding tasks demonstrate that PHyCLIP outperforms existing single-space approaches and offers more interpretable structures in the embedding space.",
        "tags": [
            "VLM"
        ]
    },
    {
        "id": "104",
        "title": "RADAR: Mechanistic Pathways for Detecting Data Contamination in LLM Evaluation",
        "author": [
            "Ashish Kattamuri",
            "Harshwardhan Fartale",
            "Arpita Vats",
            "Rahul Raja",
            "Ishita Prasad"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08931",
        "abstract": "Data contamination poses a significant challenge to reliable LLM evaluation, where models may achieve high performance by memorizing training data rather than demonstrating genuine reasoning capabilities. We introduce RADAR (Recall vs. Reasoning Detection through Activation Representation), a novel framework that leverages mechanistic interpretability to detect contamination by distinguishing recall-based from reasoning-based model responses. RADAR extracts 37 features spanning surface-level confidence trajectories and deep mechanistic properties including attention specialization, circuit dynamics, and activation flow patterns. Using an ensemble of classifiers trained on these features, RADAR achieves 93\\% accuracy on a diverse evaluation set, with perfect performance on clear cases and 76.7\\% accuracy on challenging ambiguous examples. This work demonstrates the potential of mechanistic interpretability for advancing LLM evaluation beyond traditional surface-level metrics.",
        "tags": [
            "Detection",
            "LLM"
        ]
    },
    {
        "id": "105",
        "title": "Personalize Before Retrieve: LLM-based Personalized Query Expansion for User-Centric Retrieval",
        "author": [
            "Yingyi Zhang",
            "Pengyue Jia",
            "Derong Xu",
            "Yi Wen",
            "Xianneng Li",
            "Yichao Wang",
            "Wenlin Zhang",
            "Xiaopeng Li",
            "Weinan Gan",
            "Huifeng Guo",
            "Yong Liu",
            "Xiangyu Zhao"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08935",
        "abstract": "Retrieval-Augmented Generation (RAG) critically depends on effective query expansion to retrieve relevant information. However, existing expansion methods adopt uniform strategies that overlook user-specific semantics, ignoring individual expression styles, preferences, and historical context. In practice, identical queries in text can express vastly different intentions across users. This representational rigidity limits the ability of current RAG systems to generalize effectively in personalized settings. Specifically, we identify two core challenges for personalization: 1) user expression styles are inherently diverse, making it difficult for standard expansions to preserve personalized intent. 2) user corpora induce heterogeneous semantic structures-varying in topical focus and lexical organization-which hinders the effective anchoring of expanded queries within the user's corpora space. To address these challenges, we propose Personalize Before Retrieve (PBR), a framework that incorporates user-specific signals into query expansion prior to retrieval. PBR consists of two components: P-PRF, which generates stylistically aligned pseudo feedback using user history for simulating user expression style, and P-Anchor, which performs graph-based structure alignment over user corpora to capture its structure. Together, they produce personalized query representations tailored for retrieval. Experiments on two personalized benchmarks show that PBR consistently outperforms strong baselines, with up to 10% gains on PersonaBench across retrievers. Our findings demonstrate the value of modeling personalization before retrieval to close the semantic gap in user-adaptive RAG systems. Our code is available at https://github.com/Zhang-Yingyi/PBR-code.",
        "tags": [
            "LLM",
            "RAG"
        ]
    },
    {
        "id": "106",
        "title": "RO-Bench: Large-scale robustness evaluation of MLLMs with text-driven counterfactual videos",
        "author": [
            "Zixi Yang",
            "Jiapeng Li",
            "Muxi Diao",
            "Yinuo Jing",
            "Kongming Liang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08936",
        "abstract": "Recently, Multi-modal Large Language Models (MLLMs) have demonstrated significant performance across various video understanding tasks. However, their robustness, particularly when faced with manipulated video content, remains largely unexplored. In this paper, we introduce Ro-Bench, the first benchmark for evaluating MLLMs on dynamic out-of-distribution (OOD) counterfactual video test sets. Ro-Bench incorporates high-quality, diverse and temporally relevant video data, by editing Style, Object, Background and their compositions. We evaluated eight recent video MLLMs and found that current models exhibit substantial performance degradation on Ro-Bench when exposed to counterfactual video content. Furthermore, we demonstrate that fine-tuning MLLMs with counterfactual data enhances robustness, achieving a 21.73% performance increase on Ro-Bench and a 12.78% improvement across 20 tasks in the MVBench dataset. These findings underscore the effectiveness of counterfactual data in enhancing the video understanding ability of MLLMs. The code and data will be released shortly.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "107",
        "title": "SOP-Maze: Evaluating Large Language Models on Complicated Business Standard Operating Procedures",
        "author": [
            "Jiaming Wang",
            "Zhe Tang",
            "Yilin Jin",
            "Peng Ding",
            "Xiaoyu Li",
            "Xuezhi Cao"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08942",
        "abstract": "As large language models (LLMs) are widely deployed as domain-specific agents, many benchmarks have been proposed to evaluate their ability to follow instructions and make decisions in real-world scenarios. However, business scenarios often involve complex standard operating procedures (SOPs), and the evaluation of LLM capabilities in such contexts has not been fully explored. To bridge this gap, we propose SOP-Maze, a benchmark constructed from real-world business data and adapted into a collection of 397 tasks from 23 complex SOP scenarios. We further categorize SOP tasks into two broad classes: Lateral Root System (LRS), representing wide-option tasks that demand precise selection; and Heart Root System (HRS), which emphasizes deep logical reasoning with complex branches. Extensive experiments reveal that nearly all state-of-the-art models struggle with SOP-Maze. We conduct a comprehensive analysis and identify three key error categories: (i) route blindness: difficulty following procedures; (ii) conversational fragility: inability to handle real dialogue nuances; and (iii) calculation errors: mistakes in time or arithmetic reasoning under complex contexts. The systematic study explores LLM performance across SOP tasks that challenge both breadth and depth, offering new insights for improving model capabilities. We have open-sourced our work on https://github.com/ADoublLEN/SOP-Maze.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "108",
        "title": "FATHOMS-RAG: A Framework for the Assessment of Thinking and Observation in Multimodal Systems that use Retrieval Augmented Generation",
        "author": [
            "Samuel Hildebrand",
            "Curtis Taylor",
            "Sean Oesch",
            "James M Ghawaly Jr",
            "Amir Sadovnik",
            "Ryan Shivers",
            "Brandon Schreiber",
            "Kevin Kurian"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08945",
        "abstract": "Retrieval-augmented generation (RAG) has emerged as a promising paradigm for improving factual accuracy in large language models (LLMs). We introduce a benchmark designed to evaluate RAG pipelines as a whole, evaluating a pipeline's ability to ingest, retrieve, and reason about several modalities of information, differentiating it from existing benchmarks that focus on particular aspects such as retrieval. We present (1) a small, human-created dataset of 93 questions designed to evaluate a pipeline's ability to ingest textual data, tables, images, and data spread across these modalities in one or more documents; (2) a phrase-level recall metric for correctness; (3) a nearest-neighbor embedding classifier to identify potential pipeline hallucinations; (4) a comparative evaluation of 2 pipelines built with open-source retrieval mechanisms and 4 closed-source foundation models; and (5) a third-party human evaluation of the alignment of our correctness and hallucination metrics. We find that closed-source pipelines significantly outperform open-source pipelines in both correctness and hallucination metrics, with wider performance gaps in questions relying on multimodal and cross-document information. Human evaluation of our metrics showed average agreement of 4.62 for correctness and 4.53 for hallucination detection on a 1-5 Likert scale (5 indicating \"strongly agree\").",
        "tags": [
            "Detection",
            "LLM",
            "RAG"
        ]
    },
    {
        "id": "109",
        "title": "SHERLOCK: Towards Dynamic Knowledge Adaptation in LLM-enhanced E-commerce Risk Management",
        "author": [
            "Nan Lu",
            "Yurong Hu",
            "Jiaquan Fang",
            "Yan Liu",
            "Rui Dong",
            "Yiming Wang",
            "Rui Lin",
            "Shaoyi Xu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08948",
        "abstract": "The growth of the e-commerce industry has intensified the adversarial dynamics between shadow economy actors and risk management teams. Companies often conduct risk investigations into suspicious cases to identify emerging fraud patterns, thereby enhancing both preemptive risk prevention and post-hoc governance. However, the sheer volume of case analyses imposes a substantial workload on risk management analysts, as each case requires the integration of long-term expert experience and meticulous scrutiny across multiple risk dimensions. Additionally, individual disparities among analysts hinder the establishment of uniform and high-standard workflows. To address these challenges, we propose the SHERLOCK framework, which leverages the reasoning capabilities of large language models (LLMs) to assist analysts in risk investigations. Our approach consists of three primary components: (1) extracting risk management knowledge from multi-modal data and constructing a domain knowledge base (KB), (2) building an intelligent platform guided by the data flywheel paradigm that integrates daily operations, expert annotations, and model evaluations, with iteratively fine-tuning for preference alignment, and (3) introducing a Reflect & Refine (R&R) module that collaborates with the domain KB to establish a rapid response mechanism for evolving risk patterns. Experiments conducted on the real-world transaction dataset from http://JD.com demonstrate that our method significantly improves the precision of both factual alignment and risk localization within the LLM analysis results. Deployment of the SHERLOCK-based LLM system on http://JD.com has substantially enhanced the efficiency of case investigation workflows for risk managers.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "110",
        "title": "When LLM Agents Meet Graph Optimization: An Automated Data Quality Improvement Approach",
        "author": [
            "Zhihan Zhang",
            "Xunkai Li",
            "Yilong Zuo",
            "Zhenjun Li",
            "Bing Zhou",
            "Rong-Hua Li",
            "Guoren Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08952",
        "abstract": "Text-attributed graphs (TAGs) have emerged as a powerful representation that combines structural connections with fine-grained semantics, supporting a wide range of data-centric applications. However, the performance of graph neural networks (GNNs) on TAGs is highly sensitive to input quality. Our empirical study shows that both traditional GNNs and LLM-enhanced GNNs suffer significant degradation across nine representative scenarios of sparsity, noise, and imbalance, highlighting graph quality as a critical bottleneck. Existing approaches mainly focus on improving model architectures, while neglecting systematic optimization of TAG data itself, leading to limited effectiveness in practice. To address this gap, we propose LAGA (Large Language and Graph Agent), a unified multi-agent framework that treats graph quality control as a first-class, data-centric problem. LAGA integrates four collaborative agents-detection, planning, action, and evaluation-into an automated closed loop. At its core, the action agent employs a dual-encoder and tri-objective design to capture complementary information across modalities and perform holistic graph quality enhancement. Experiments across nine scenarios show that LAGA improves graph quality and achieves state-of-the-art performance across various tasks and backbones, validating data-centric quality optimization as key to reliable TAGs and robust graph learning.",
        "tags": [
            "Detection",
            "LLM"
        ]
    },
    {
        "id": "111",
        "title": "Denoised Diffusion for Object-Focused Image Augmentation",
        "author": [
            "Nisha Pillai",
            "Aditi Virupakshaiah",
            "Harrison W. Smith",
            "Amanda J. Ashworth",
            "Prasanna Gowda",
            "Phillip R. Owens",
            "Adam R. Rivers",
            "Bindu Nanduri",
            "Mahalingam Ramkumar"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08955",
        "abstract": "Modern agricultural operations increasingly rely on integrated monitoring systems that combine multiple data sources for farm optimization. Aerial drone-based animal health monitoring serves as a key component but faces limited data availability, compounded by scene-specific issues such as small, occluded, or partially visible animals. Transfer learning approaches often fail to address this limitation due to the unavailability of large datasets that reflect specific farm conditions, including variations in animal breeds, environments, and behaviors. Therefore, there is a need for developing a problem-specific, animal-focused data augmentation strategy tailored to these unique challenges. To address this gap, we propose an object-focused data augmentation framework designed explicitly for animal health monitoring in constrained data settings. Our approach segments animals from backgrounds and augments them through transformations and diffusion-based synthesis to create realistic, diverse scenes that enhance animal detection and monitoring performance. Our initial experiments demonstrate that our augmented dataset yields superior performance compared to our baseline models on the animal detection task. By generating domain-specific data, our method empowers real-time animal health monitoring solutions even in data-scarce scenarios, bridging the gap between limited data and practical applicability.",
        "tags": [
            "Detection",
            "Diffusion"
        ]
    },
    {
        "id": "112",
        "title": "DualResearch: Entropy-Gated Dual-Graph Retrieval for Answer Reconstruction",
        "author": [
            "Jinxin Shi",
            "Zongsheng Cao",
            "Runmin Ma",
            "Yusong Hu",
            "Jie Zhou",
            "Xin Li",
            "Lei Bai",
            "Liang He",
            "Bo Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08959",
        "abstract": "The deep-research framework orchestrates external tools to perform complex, multi-step scientific reasoning that exceeds the native limits of a single large language model. However, it still suffers from context pollution, weak evidentiary support, and brittle execution paths. To address these issues, we propose DualResearch, a retrieval and fusion framework that matches the epistemic structure of tool-intensive reasoning by jointly modeling two complementary graphs: a breadth semantic graph that encodes stable background knowledge, and a depth causal graph that captures execution provenance. Each graph has a layer-native relevance function, seed-anchored semantic diffusion for breadth, and causal-semantic path matching with reliability weighting for depth. To reconcile their heterogeneity and query-dependent uncertainty, DualResearch converts per-layer path evidence into answer distributions and fuses them in log space via an entropy-gated rule with global calibration. The fusion up-weights the more certain channel and amplifies agreement. As a complement to deep-research systems, DualResearch compresses lengthy multi-tool execution logs into a concise reasoning graph, and we show that it can reconstruct answers stably and effectively. On the scientific reasoning benchmarks HLE and GPQA, DualResearch achieves competitive performance. Using log files from the open-source system InternAgent, its accuracy improves by 7.7% on HLE and 6.06% on GPQA.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "113",
        "title": "Analytical Survey of Learning with Low-Resource Data: From Analysis to Investigation",
        "author": [
            "Xiaofeng Cao",
            "Mingwei Xu",
            "Xin Yu",
            "Jiangchao Yao",
            "Wei Ye",
            "Shengjun Huang",
            "Minling Zhang",
            "Ivor W. Tsang",
            "Yew Soon Ong",
            "James T. Kwok",
            "Heng Tao Shen"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08962",
        "abstract": "Learning with high-resource data has demonstrated substantial success in artificial intelligence (AI); however, the costs associated with data annotation and model training remain significant. A fundamental objective of AI research is to achieve robust generalization with limited-resource data. This survey employs agnostic active sampling theory within the Probably Approximately Correct (PAC) framework to analyze the generalization error and label complexity associated with learning from low-resource data in both model-agnostic supervised and unsupervised settings. Based on this analysis, we investigate a suite of optimization strategies tailored for low-resource data learning, including gradient-informed optimization, meta-iteration optimization, geometry-aware optimization, and LLMs-powered optimization. Furthermore, we provide a comprehensive overview of multiple learning paradigms that can benefit from low-resource data, including domain transfer, reinforcement feedback, and hierarchical structure modeling. Finally, we conclude our analysis and investigation by summarizing the key findings and highlighting their implications for learning with low-resource data.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "114",
        "title": "Unleashing Perception-Time Scaling to Multimodal Reasoning Models",
        "author": [
            "Yifan Li",
            "Zhenghao Chen",
            "Ziheng Wu",
            "Kun Zhou",
            "Ruipu Luo",
            "Can Zhang",
            "Zhentao He",
            "Yufei Zhan",
            "Wayne Xin Zhao",
            "Minghui Qiu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08964",
        "abstract": "Recent advances in inference-time scaling, particularly those leveraging reinforcement learning with verifiable rewards, have substantially enhanced the reasoning capabilities of Large Vision-Language Models (LVLMs). Inspired by this success, similar strategies have been applied to multimodal reasoning, yet their impact on visual perception remains unclear. To investigate this gap, we introduce DisTANCE, a perception-centric benchmark for visual estimation tasks. Evaluation results show that LVLMs exhibit limited estimation precision, and inference-time scaling offers only marginal gains. We attribute this to the fast perception paradigm of current LVLMs, where visual understanding is treated as a one-shot output without modeling the underlying perceptual process. To address this, we propose Perception-Time Scaling (PTS), a novel paradigm that encourages token-rich perception and decomposes complex perception problems into intermediate tractable sub-problems, thereby enabling perception to align with and benefit from inference-time scaling. Combined with reinforcement learning techniques, PTS significantly improves perception accuracy, raising high-precision performance on DisTANCE from 8.0% to 64.7%, and generalizes well to out-of-domain tasks. Surprisingly, even though PTS data are purely synthetic, combining them with math reasoning data yields consistent gains in both reasoning and real-world perception benchmarks. Further analysis reveals that PTS introduces more perception-related tokens and increases the model's attention to image tokens. Our code and data will be publicly released.",
        "tags": [
            "RL",
            "VLM"
        ]
    },
    {
        "id": "115",
        "title": "HiBBO: HiPPO-based Space Consistency for High-dimensional Bayesian Optimisation",
        "author": [
            "Junyu Xuan",
            "Wenlong Chen",
            "Yingzhen Li"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08965",
        "abstract": "Bayesian Optimisation (BO) is a powerful tool for optimising expensive blackbox functions but its effectiveness diminishes in highdimensional spaces due to sparse data and poor surrogate model scalability While Variational Autoencoder (VAE) based approaches address this by learning low-dimensional latent representations the reconstructionbased objective function often brings the functional distribution mismatch between the latent space and original space leading to suboptimal optimisation performance In this paper we first analyse the reason why reconstructiononly loss may lead to distribution mismatch and then propose HiBBO a novel BO framework that introduces the space consistency into the latent space construction in VAE using HiPPO - a method for longterm sequence modelling - to reduce the functional distribution mismatch between the latent space and original space Experiments on highdimensional benchmark tasks demonstrate that HiBBO outperforms existing VAEBO methods in convergence speed and solution quality Our work bridges the gap between high-dimensional sequence representation learning and efficient Bayesian Optimisation enabling broader applications in neural architecture search materials science and beyond.",
        "tags": [
            "VAE"
        ]
    },
    {
        "id": "116",
        "title": "Semantic-Condition Tuning: Fusing Graph Context with Large Language Models for Knowledge Graph Completion",
        "author": [
            "Ruitong Liu",
            "Yan Wen",
            "Te Sun",
            "Yunjia Wu",
            "Pingyang Huang",
            "Zihang Yu",
            "Siyuan Li"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08966",
        "abstract": "Fusing Knowledge Graphs with Large Language Models is crucial for knowledge-intensive tasks like knowledge graph completion. The prevailing paradigm, prefix-tuning, simply concatenates knowledge embeddings with text inputs. However, this shallow fusion overlooks the rich relational semantics within KGs and imposes a significant implicit reasoning burden on the LLM to correlate the prefix with the text. To address these, we propose Semantic-condition Tuning (SCT), a new knowledge injection paradigm comprising two key modules. First, a Semantic Graph Module employs a Graph Neural Network to extract a context-aware semantic condition from the local graph neighborhood, guided by knowledge-enhanced relations. Subsequently, this condition is passed to a Condition-Adaptive Fusion Module, which, in turn, adaptively modulates the textual embedding via two parameterized projectors, enabling a deep, feature-wise, and knowledge-aware interaction. The resulting pre-fused embedding is then fed into the LLM for fine-tuning. Extensive experiments on knowledge graph benchmarks demonstrate that SCT significantly outperforms prefix-tuning and other strong baselines. Our analysis confirms that by modulating the input representation with semantic graph context before LLM inference, SCT provides a more direct and potent signal, enabling more accurate and robust knowledge reasoning.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "117",
        "title": "Learning Regularizers: Learning Optimizers that can Regularize",
        "author": [
            "Suraj Kumar Sahoo",
            "Narayanan C Krishnan"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08968",
        "abstract": "Learned Optimizers (LOs), a type of Meta-learning, have gained traction due to their ability to be parameterized and trained for efficient optimization. Traditional gradient-based methods incorporate explicit regularization techniques such as Sharpness-Aware Minimization (SAM), Gradient-norm Aware Minimization (GAM), and Gap-guided Sharpness-Aware Minimization (GSAM) to enhance generalization and convergence. In this work, we explore a fundamental question: \\textbf{Can regularizers be learned?} We empirically demonstrate that LOs can be trained to learn and internalize the effects of traditional regularization techniques without explicitly applying them to the objective function. We validate this through extensive experiments on standard benchmarks (including MNIST, FMNIST, CIFAR and Neural Networks such as MLP, MLP-Relu and CNN), comparing LOs trained with and without access to explicit regularizers. Regularized LOs consistently outperform their unregularized counterparts in terms of test accuracy and generalization. Furthermore, we show that LOs retain and transfer these regularization effects to new optimization tasks by inherently seeking minima similar to those targeted by these regularizers. Our results suggest that LOs can inherently learn regularization properties, \\textit{challenging the conventional necessity of explicit optimizee loss regularization.",
        "tags": [
            "SAM"
        ]
    },
    {
        "id": "118",
        "title": "Diagnosing and Mitigating System Bias in Self-Rewarding RL",
        "author": [
            "Chuyi Tan",
            "Peiwen Yuan",
            "Xinglin Wang",
            "Yiwei Li",
            "Shaoxiong Feng",
            "Yueqi Zhang",
            "Jiayi Shi",
            "Ji Zhang",
            "Boyuan Pan",
            "Yao Hu",
            "Kan Li"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08977",
        "abstract": "Reinforcement learning with verifiable rewards (RLVR) scales the reasoning ability of large language models (LLMs) but remains bottlenecked by limited labeled samples for continued data scaling. Reinforcement learning with intrinsic rewards (RLIR), where the policy model assigns rewards to its own rollouts, enables sustainable scaling in unlabeled settings, yet its performance and stability lag behind RLVR. We trace this gap to a system bias: the model tends to overestimate its high-confidence rollouts, leading to biased and unstable reward estimation. This bias accumulates as training progresses, with deviations from the oracle drifting toward over-reward, causing unstable training. We characterize this bias using three metrics: $\\rho_{\\text{noise}}$, $\\rho_{\\text{selfbias}}$, and $\\rho_{\\text{symbias}}$. We find that $\\rho_{\\text{noise}}$ and $\\rho_{\\text{symbias}}$ impact convergence, while $\\rho_{\\text{selfbias}}$ amplifies both correct and incorrect updates, leading to instability. To mitigate this, we propose reinforcement learning with ensembled rewards (RLER), which aggregates diverse models and adapts reward interpolation and rollout selection. Extensive experiments show that RLER improves by +13.6% over RLIR and is only 3.6% below RLVR, achieving stable scaling on unlabeled samples, making it highly applicable.",
        "tags": [
            "LLM",
            "RL"
        ]
    },
    {
        "id": "119",
        "title": "HandEval: Taking the First Step Towards Hand Quality Evaluation in Generated Images",
        "author": [
            "Zichuan Wang",
            "Bo Peng",
            "Songlin Yang",
            "Zhenchen Tang",
            "Jing Dong"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08978",
        "abstract": "Although recent text-to-image (T2I) models have significantly improved the overall visual quality of generated images, they still struggle in the generation of accurate details in complex local regions, especially human hands. Generated hands often exhibit structural distortions and unrealistic textures, which can be very noticeable even when the rest of the body is well-generated. However, the quality assessment of hand regions remains largely neglected, limiting downstream task performance like human-centric generation quality optimization and AIGC detection. To address this, we propose the first quality assessment task targeting generated hand regions and showcase its abundant downstream applications. We first introduce the HandPair dataset for training hand quality assessment models. It consists of 48k images formed by high- and low-quality hand pairs, enabling low-cost, efficient supervision without manual annotation. Based on it, we develop HandEval, a carefully designed hand-specific quality assessment model. It leverages the powerful visual understanding capability of Multimodal Large Language Model (MLLM) and incorporates prior knowledge of hand keypoints, gaining strong perception of hand quality. We further construct a human-annotated test set with hand images from various state-of-the-art (SOTA) T2I models to validate its quality evaluation capability. Results show that HandEval aligns better with human judgments than existing SOTA methods. Furthermore, we integrate HandEval into image generation and AIGC detection pipelines, prominently enhancing generated hand realism and detection accuracy, respectively, confirming its universal effectiveness in downstream applications. Code and dataset will be available.",
        "tags": [
            "Detection",
            "Text-to-Image"
        ]
    },
    {
        "id": "120",
        "title": "SEER: Sustainability Enhanced Engineering of Software Requirements",
        "author": [
            "Mandira Roy",
            "Novarun Deb",
            "Nabendu Chaki",
            "Agostino Cortesi"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08981",
        "abstract": "The rapid expansion of software development has significant environmental, technical, social, and economic impacts. Achieving the United Nations Sustainable Development Goals by 2030 compels developers to adopt sustainable practices. Existing methods mostly offer high-level guidelines, which are time-consuming to implement and rely on team adaptability. Moreover, they focus on design or implementation, while sustainability assessment should start at the requirements engineering phase. In this paper, we introduce SEER, a framework which addresses sustainability concerns in the early software development phase. The framework operates in three stages: (i) it identifies sustainability requirements (SRs) relevant to a specific software product from a general taxonomy; (ii) it evaluates how sustainable system requirements are based on the identified SRs; and (iii) it optimizes system requirements that fail to satisfy any SR. The framework is implemented using the reasoning capabilities of large language models and the agentic RAG (Retrieval Augmented Generation) approach. SEER has been experimented on four software projects from different domains. Results generated using Gemini 2.5 reasoning model demonstrate the effectiveness of the proposed approach in accurately identifying a broad range of sustainability concerns across diverse domains.",
        "tags": [
            "LLM",
            "RAG"
        ]
    },
    {
        "id": "121",
        "title": "Rethinking Reasoning in Document Ranking: Why Chain-of-Thought Falls Short",
        "author": [
            "Xuan Lu",
            "Haohang Huang",
            "Rui Meng",
            "Yaohui Jin",
            "Wenjun Zeng",
            "Xiaoyu Shen"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08985",
        "abstract": "Document reranking is a key component in information retrieval (IR), aimed at refining initial retrieval results to improve ranking quality for downstream tasks. Recent studies--motivated by large reasoning models (LRMs)--have begun incorporating explicit chain-of-thought (CoT) reasoning into LLM-based rerankers. However, the effectiveness of such reasoning for ranking tasks remains underexplored. In this work, we present the first systematic study of reasoning in reranking across both pointwise and listwise settings, under both supervised fine-tuning and reinforcement learning. Using diverse benchmarks, including reasoning-intensive datasets (BRIGHT) and standard IR benchmarks (BEIR), we find that reasoning-augmented rerankers consistently underperform their direct counterparts that predict rankings without CoT, despite substantially higher inference costs. Our analysis reveals three core limitations: (i) in pointwise rerankers, reasoning breaks calibration and biases models toward the positive class, raising TPR but lowering TNR, which inflates false positives and degrades ranking in negative-dominant pools; (ii) in listwise rerankers, reasoning improves in-domain fit but increases variance and fails to generalize out-of-domain, even when reinforcement learning shortens rationales; and (iii) overall, directly fine-tuned rerankers remain more stable, effective, and robust. These findings challenge the assumption that explicit reasoning is universally beneficial for reranking. We conclude by highlighting future directions, including calibration-aware scoring for pointwise rerankers and the design of concise, targeted reasoning strategies to mitigate overfitting and overthinking in listwise rerankers.",
        "tags": [
            "CoT",
            "LLM",
            "RL"
        ]
    },
    {
        "id": "122",
        "title": "Creation of the Chinese Adaptive Policy Communication Corpus",
        "author": [
            "Bolun Sun",
            "Charles Chang",
            "Yuen Yuen Ang",
            "Pingxu Hao",
            "Ruotong Mu",
            "Yuchen Xu",
            "Zhengxin Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08986",
        "abstract": "We introduce CAPC-CG, the Chinese Adaptive Policy Communication (Central Government) Corpus, the first open dataset of Chinese policy directives annotated with a five-color taxonomy of clear and ambiguous language categories, building on Ang's theory of adaptive policy communication. Spanning 1949-2023, this corpus includes national laws, administrative regulations, and ministerial rules issued by China's top authorities. Each document is segmented into paragraphs, producing a total of 3.3 million units. Alongside the corpus, we release comprehensive metadata, a two-round labeling framework, and a gold-standard annotation set developed by expert and trained coders. Inter-annotator agreement achieves a Fleiss's kappa of K = 0.86 on directive labels, indicating high reliability for supervised modeling. We provide baseline classification results with several large language models (LLMs), together with our annotation codebook, and describe patterns from the dataset. This release aims to support downstream tasks and multilingual NLP research in policy communication.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "123",
        "title": "Tiny-R1V: Lightweight Multimodal Unified Reasoning Model via Model Merging",
        "author": [
            "Qixiang Yin",
            "Huanjin Yao",
            "Jianghao Chen",
            "Jiaxing Huang",
            "Zhicheng Zhao",
            "Fei Su"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08987",
        "abstract": "Although Multimodal Large Language Models (MLLMs) have demonstrated remarkable capabilities across diverse tasks, they encounter numerous challenges in terms of reasoning efficiency, such as large model size, overthinking, and compromised accuracy in lightweight scenarios. However, research on the reasoning capabilities of lightweight MLLMs is quite lacking. To this end, we propose Tiny-R1V, a novel lightweight 3B model that achieves faster inference and higher accuracy via a two-stage optimization, while unifying multimodal reasoning across multiple tasks and using fewer tokens. In the first stage, Tiny-R1V introduces Length-Informed Relative Policy Optimization (LIPO), a novel reinforcement learning method, to train each reasoning model. The LIPO is designed to dynamically adjusts advantages of responses within groups, that is, by prioritizing concise yet high-quality responses to encourage the generation of shorter and more accurate response. In the second stage, we propose Adaptive Model Merging (AMM), a training-free model merging method that merges multiple specialist models into a unified architecture. Specifically, AMM adaptively adjusts the weights of task vectors and robustly optimizes the merged vectors via a novel gradient projection regularization loss function, thus mitigating redundant conflicts between them. Extensive evaluations on ten widely-used reasoning benchmarks covering mathematics, structured data (charts, tables, documents), OCR, and general capabilities showcase the superior performance of Tiny-R1V, enabling lightweight models to excel in diverse multimodal reasoning tasks.",
        "tags": [
            "LLM",
            "RL"
        ]
    },
    {
        "id": "124",
        "title": "MASA: LLM-Driven Multi-Agent Systems for Autoformalization",
        "author": [
            "Lan Zhang",
            "Marco Valentino",
            "AndrÃ© Freitas"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08988",
        "abstract": "Autoformalization serves a crucial role in connecting natural language and formal reasoning. This paper presents MASA, a novel framework for building multi-agent systems for autoformalization driven by Large Language Models (LLMs). MASA leverages collaborative agents to convert natural language statements into their formal representations. The architecture of MASA is designed with a strong emphasis on modularity, flexibility, and extensibility, allowing seamless integration of new agents and tools to adapt to a fast-evolving field. We showcase the effectiveness of MASA through use cases on real-world mathematical definitions and experiments on formal mathematics datasets. This work highlights the potential of multi-agent systems powered by the interaction of LLMs and theorem provers in enhancing the efficiency and reliability of autoformalization, providing valuable insights and support for researchers and practitioners in the field.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "125",
        "title": "Constraints-of-Thought: A Framework for Constrained Reasoning in Language-Model-Guided Search",
        "author": [
            "Kamel Alrashedy",
            "Vriksha Srihari",
            "Zulfiqar Zaidi",
            "Ridam Srivastava",
            "Pradyumna Tambwekar",
            "Matthew Gombolay"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08992",
        "abstract": "While researchers have made significant progress in enabling large language models (LLMs) to perform multi-step planning, LLMs struggle to ensure that those plans align with high-level user intent and satisfy symbolic constraints, especially in complex, multi-step domains. Existing reasoning approaches such as Chain-of-Thought (CoT), Tree-of-Thought (ToT), and verifier-augmented methods, expand the search space but often yield infeasible actions or hallucinated steps. To overcome these limitations, we propose Constraints-of-Thought (Const-o-T), a framework that provides a structured prior that enables Monte Carlo Tree Search (MCTS) focus search on semantically meaningful paths. Each reasoning step is represented as an (intent, constraint) pair, which serves both to compress the search space and enforce validity. Unlike prior methods that merely generate reasoning traces or validate outputs post hoc, Const-o-T uses (intent, constraint)pairs to actively focus the search toward feasible and meaningful plans. We integrate Const-o-T into MCTS using a structured representation of intent-constraint pairs constraints prune infeasible branches and guide exploration toward semantically valid actions, improving planning efficiency and verifiable decision-making. We demonstrate across three domains Risk game, CAD code generation, and arithmetic reasoning that our approach outperforms baselines, yielding higher accuracy and stronger structural alignment. Our contribution is to demonstrate that Const-of-T offers a generalizable foundation for constraint-guided reasoning, enabling more efficient, constraint-aligned, and domain-adaptable planning with LLMs.",
        "tags": [
            "CoT",
            "LLM"
        ]
    },
    {
        "id": "126",
        "title": "Speculative Jacobi-Denoising Decoding for Accelerating Autoregressive Text-to-image Generation",
        "author": [
            "Yao Teng",
            "Fuyun Wang",
            "Xian Liu",
            "Zhekai Chen",
            "Han Shi",
            "Yu Wang",
            "Zhenguo Li",
            "Weiyang Liu",
            "Difan Zou",
            "Xihui Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08994",
        "abstract": "As a new paradigm of visual content generation, autoregressive text-to-image models suffer from slow inference due to their sequential token-by-token decoding process, often requiring thousands of model forward passes to generate a single image. To address this inefficiency, we propose Speculative Jacobi-Denoising Decoding (SJD2), a framework that incorporates the denoising process into Jacobi iterations to enable parallel token generation in autoregressive models. Our method introduces a next-clean-token prediction paradigm that enables the pre-trained autoregressive models to accept noise-perturbed token embeddings and predict the next clean tokens through low-cost fine-tuning. This denoising paradigm guides the model towards more stable Jacobi trajectories. During inference, our method initializes token sequences with Gaussian noise and performs iterative next-clean-token-prediction in the embedding space. We employ a probabilistic criterion to verify and accept multiple tokens in parallel, and refine the unaccepted tokens for the next iteration with the denoising trajectory. Experiments show that our method can accelerate generation by reducing model forward passes while maintaining the visual quality of generated images.",
        "tags": [
            "Text-to-Image"
        ]
    },
    {
        "id": "127",
        "title": "SQS: Bayesian DNN Compression through Sparse Quantized Sub-distributions",
        "author": [
            "Ziyi Wang",
            "Nan Jiang",
            "Guang Lin",
            "Qifan Song"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08999",
        "abstract": "Compressing large-scale neural networks is essential for deploying models on resource-constrained devices. Most existing methods adopt weight pruning or low-bit quantization individually, often resulting in suboptimal compression rates to preserve acceptable performance drops. We introduce a unified framework for simultaneous pruning and low-bit quantization via Bayesian variational learning (SQS), which achieves higher compression rates than prior baselines while maintaining comparable performance. The key idea is to employ a spike-and-slab prior to inducing sparsity and model quantized weights using Gaussian Mixture Models (GMMs) to enable low-bit precision. In theory, we provide the consistent result of our proposed variational approach to a sparse and quantized deep neural network. Extensive experiments on compressing ResNet, BERT-base, Llama3, and Qwen2.5 models show that our method achieves higher compression rates than a line of existing methods with comparable performance drops.",
        "tags": [
            "BERT"
        ]
    },
    {
        "id": "128",
        "title": "DARO: Difficulty-Aware Reweighting Policy Optimization",
        "author": [
            "Jingyu Zhou",
            "Lu Ma",
            "Hao Liang",
            "Chengyu Shen",
            "Bin Cui",
            "Wentao Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09001",
        "abstract": "Recent advances in large language models (LLMs) have shown that reasoning ability can be significantly enhanced through Reinforcement Learning with Verifiable Rewards (RLVR). Group Relative Policy Optimization (GRPO) has emerged as the de facto approach for RLVR, inspiring numerous variants. However, our mathematical analysis reveals that these methods are fundamentally weighted variations of GRPO. We provide a unified view, demonstrating that their reliance on static or overly simplistic weighting schemes tied to sample difficulty prevents adaptation to a model's evolving capabilities. This creates a significant loss scale issue, where training disproportionately focuses on certain difficulty levels at the expense of others, hindering overall performance. To address these limitations, we introduce \\textbf{Difficulty-Aware Reweighting Policy Optimization (DARO)}, a method that dynamically adjusts the loss contribution of each difficulty group based on the model's learning state. Extensive experiments on Qwen2.5-Math-1.5B, Qwen2.5-Math-7B, and Llama3.1-8B show that DARO outperforms four leading baselines across six math benchmarks, achieving significantly faster convergence and superior final performance.",
        "tags": [
            "GRPO",
            "LLM",
            "RL"
        ]
    },
    {
        "id": "129",
        "title": "Decoupling Safety into Orthogonal Subspace: Cost-Efficient and Performance-Preserving Alignment for Large Language Models",
        "author": [
            "Yutao Mou",
            "Xiaoling Zhou",
            "Yuxiao Luo",
            "Shikun Zhang",
            "Wei Ye"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09004",
        "abstract": "Safety alignment is essential for building trustworthy artificial intelligence, yet it remains challenging to enhance model safety without degrading general performance. Current approaches require computationally expensive searches for the optimal proportion of safety-critical and general-purpose data to balance safety and general performance, incurring high costs with limited gains. In this work, we show that LoRA-based Refusal-training enables performance-preserving safety alignment even when trained solely on safety data, demonstrating that LoRA serves as cost-efficient, performance-preserving, and plug-and-play safety patches. Beyond empirical findings, we provide both theoretical and experimental evidence that LoRA effectively decouples safety into a low-rank subspace largely orthogonal to the model's intrinsic transformation space, ensuring that safety enhancements do not interfere with inherent capabilities.",
        "tags": [
            "LLM",
            "LoRA"
        ]
    },
    {
        "id": "130",
        "title": "LLM Unlearning on Noisy Forget Sets: A Study of Incomplete, Rewritten, and Watermarked Data",
        "author": [
            "Changsheng Wang",
            "Yihua Zhang",
            "Dennis Wei",
            "Jinghan Jia",
            "Pin-Yu Chen",
            "Sijia Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09007",
        "abstract": "Large language models (LLMs) exhibit remarkable generative capabilities but raise ethical and security concerns by memorizing sensitive data, reinforcing biases, and producing harmful content. These risks have spurred interest in LLM unlearning, the task of removing knowledge associated with undesirable data from pre-trained models. However, most existing methods assume access to clean, well-defined forget data samples, whereas real-world forget data could often be low-quality, synthetically rewritten, or watermarked, casting doubt on the reliability of unlearning. This work presents the first study of unlearning under perturbed or low-fidelity forget data, referred to as noisy forget sets. By systematically benchmarking state-of-the-art LLM unlearning methods, RMU and NPO, on such noisy forget sets, we find that unlearning remains surprisingly robust to perturbations, provided that core semantic signals are preserved. To explain this robustness, we propose a saliency-based interpretation: key semantic components that drive forgetting remain consistently influential despite substantial variation in surface form. This suggests that unlearning algorithms are primarily guided by deep semantic cues rather than shallow lexical patterns.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "131",
        "title": "On Epistemic Uncertainty of Visual Tokens for Object Hallucinations in Large Vision-Language Models",
        "author": [
            "Hoigi Seo",
            "Dong Un Kang",
            "Hyunjin Cho",
            "Joohoon Lee",
            "Se Young Chun"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09008",
        "abstract": "Large vision-language models (LVLMs), which integrate a vision encoder (VE) with a large language model, have achieved remarkable success across various tasks. However, there are still crucial challenges in LVLMs such as object hallucination, generating descriptions of objects that are not in the input image. Here, we argue that uncertain visual tokens within the VE is a key factor that contributes to object hallucination. Our statistical analysis found that there are positive correlations between visual tokens with high epistemic uncertainty and the occurrence of hallucinations. Furthermore, we show theoretically and empirically that visual tokens in early VE layers that exhibit large representation deviations under small adversarial perturbations indicate high epistemic uncertainty. Based on these findings, we propose a simple yet effective strategy to mitigate object hallucination by modifying the VE only. Our method comprises a proxy method with adversarial perturbations for identifying uncertain visual tokens efficiently and a method to mask these uncertain visual tokens during the self-attention process in the middle layers of the VE, suppressing their influence on visual encoding and thus alleviating hallucinations. Extensive experiments show that our method significantly reduces object hallucinations in LVLMs and can synergistically work with other prior arts.",
        "tags": [
            "VLM"
        ]
    },
    {
        "id": "132",
        "title": "Promptimizer: User-Led Prompt Optimization for Personal Content Classification",
        "author": [
            "Leijie Wang",
            "Kathryn Yurechko",
            "Amy X. Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09009",
        "abstract": "While LLMs now enable users to create content classifiers easily through natural language, automatic prompt optimization techniques are often necessary to create performant classifiers. However, such techniques can fail to consider how social media users want to evolve their filters over the course of usage, including desiring to steer them in different ways during initialization and iteration. We introduce a user-centered prompt optimization technique, Promptimizer, that maintains high performance and ease-of-use but additionally (1) allows for user input into the optimization process and (2) produces final prompts that are interpretable. A lab experiment (n=16) found that users significantly preferred Promptimizer's human-in-the-loop optimization over a fully automatic approach. We further implement Promptimizer into Puffin, a tool to support YouTube content creators in creating and maintaining personal classifiers to manage their comments. Over a 3-week deployment with 10 creators, participants successfully created diverse filters to better understand their audiences and protect their communities.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "133",
        "title": "HERO: Hardware-Efficient RL-based Optimization Framework for NeRF Quantization",
        "author": [
            "Yipu Zhang",
            "Chaofang Ma",
            "Jinming Ge",
            "Lin Jiang",
            "Jiang Xu",
            "Wei Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09010",
        "abstract": "Neural Radiance Field (NeRF) has emerged as a promising 3D reconstruction method, delivering high-quality results for AR/VR applications. While quantization methods and hardware accelerators have been proposed to enhance NeRF's computational efficiency, existing approaches face crucial limitations. Current quantization methods operate without considering hardware architecture, resulting in sub-optimal solutions within the vast design space encompassing accuracy, latency, and model size. Additionally, existing NeRF accelerators heavily rely on human experts to explore this design space, making the optimization process time-consuming, inefficient, and unlikely to discover optimal solutions. To address these challenges, we introduce HERO, a reinforcement learning framework performing hardware-aware quantization for NeRF. Our framework integrates a NeRF accelerator simulator to generate real-time hardware feedback, enabling fully automated adaptation to hardware constraints. Experimental results demonstrate that HERO achieves 1.31-1.33 $\\times$ better latency, 1.29-1.33 $\\times$ improved cost efficiency, and a more compact model size compared to CAQ, a previous state-of-the-art NeRF quantization framework. These results validate our framework's capability to effectively navigate the complex design space between hardware and algorithm requirements, discovering superior quantization policies for NeRF implementation. Code is available at https://github.com/ypzhng/HERO.",
        "tags": [
            "3D",
            "NeRF",
            "RL"
        ]
    },
    {
        "id": "134",
        "title": "TripScore: Benchmarking and rewarding real-world travel planning with fine-grained evaluation",
        "author": [
            "Yincen Qu",
            "Huan Xiao",
            "Feng Li",
            "Hui Zhou",
            "Xiangying Dai"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09011",
        "abstract": "Travel planning is a valuable yet complex task that poses significant challenges even for advanced large language models (LLMs). While recent benchmarks have advanced in evaluating LLMs' planning capabilities, they often fall short in evaluating feasibility, reliability, and engagement of travel plans. We introduce a comprehensive benchmark for travel planning that unifies fine-grained criteria into a single reward, enabling direct comparison of plan quality and seamless integration with reinforcement learning (RL). Our evaluator achieves moderate agreement with travel-expert annotations (60.75\\%) and outperforms multiple LLM-as-judge baselines. We further release a large-scale dataset of 4,870 queries including 219 real-world, free-form requests for generalization to authentic user intent. Using this benchmark, we conduct extensive experiments across diverse methods and LLMs, including test-time computation, neuro-symbolic approaches, supervised fine-tuning, and RL via GRPO. Across base models, RL generally improves itinerary feasibility over prompt-only and supervised baselines, yielding higher unified reward scores.",
        "tags": [
            "GRPO",
            "LLM",
            "RL"
        ]
    },
    {
        "id": "135",
        "title": "DiTSinger: Scaling Singing Voice Synthesis with Diffusion Transformer and Implicit Alignment",
        "author": [
            "Zongcai Du",
            "Guilin Deng",
            "Xiaofeng Guo",
            "Xin Gao",
            "Linke Li",
            "Kaichang Cheng",
            "Fubo Han",
            "Siyu Yang",
            "Peng Liu",
            "Pan Zhong",
            "Qiang Fu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09016",
        "abstract": "Recent progress in diffusion-based Singing Voice Synthesis (SVS) demonstrates strong expressiveness but remains limited by data scarcity and model scalability. We introduce a two-stage pipeline: a compact seed set of human-sung recordings is constructed by pairing fixed melodies with diverse LLM-generated lyrics, and melody-specific models are trained to synthesize over 500 hours of high-quality Chinese singing data. Building on this corpus, we propose DiTSinger, a Diffusion Transformer with RoPE and qk-norm, systematically scaled in depth, width, and resolution for enhanced fidelity. Furthermore, we design an implicit alignment mechanism that obviates phoneme-level duration labels by constraining phoneme-to-acoustic attention within character-level spans, thereby improving robustness under noisy or uncertain alignments. Extensive experiments validate that our approach enables scalable, alignment-free, and high-fidelity SVS.",
        "tags": [
            "DiT",
            "Diffusion",
            "LLM",
            "RoPE",
            "Transformer"
        ]
    },
    {
        "id": "136",
        "title": "Value-State Gated Attention for Mitigating Extreme-Token Phenomena in Transformers",
        "author": [
            "Rui Bu",
            "Haofeng Zhong",
            "Wenzheng Chen",
            "Yangyan Li"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09017",
        "abstract": "Large models based on the Transformer architecture are susceptible to extreme-token phenomena, such as attention sinks and value-state drains. These issues, which degrade model performance, quantization fidelity, and interpretability, arise from a problematic mutual reinforcement mechanism where the model learns an inefficient 'no-op' behavior by focusing attention on tokens with near-zero value states. In this paper, we propose Value-State Gated Attention (VGA), a simple, dedicated, and stable architectural mechanism for performing 'no-op' attention efficiently by directly breaking this cycle. VGA introduces a learnable, data-dependent gate, computed directly from the value vectors (V), to modulate the output. Through a theoretical analysis of the underlying gradients, we show that gating the value-state with a function of itself is more effective at decoupling value and attention score updates than prior methods that gate on input embeddings. This creates a direct regulatory pathway that allows the model to suppress a token's contribution based on its emergent value representation. Our experiments demonstrate that VGA significantly mitigates the formation of attention sinks and stabilizes value-state norms, leading to improved performance, robust quantization fidelity, and enhanced model interpretability.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "137",
        "title": "Slim Scheduler: A Runtime-Aware RL and Scheduler System for Efficient CNN Inference",
        "author": [
            "Ian Harshbarger",
            "Calvin Chidambaram"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09018",
        "abstract": "Most neural network scheduling research focuses on optimizing static, end-to-end models of fixed width, overlooking dynamic approaches that adapt to heterogeneous hardware and fluctuating runtime conditions. We present Slim Scheduler, a hybrid scheduling framework that integrates a Proximal Policy Optimization (PPO) reinforcement learning policy with algorithmic, greedy schedulers to coordinate distributed inference for slimmable models. Each server runs a local greedy scheduler that batches compatible requests and manages instance scaling based on VRAM and utilization constraints, while the PPO router learns global routing policies for device selection, width ratio, and batch configuration. This hierarchical design reduces search space complexity, mitigates overfitting to specific hardware, and balances efficiency and throughput. Compared to a purely randomized task distribution baseline, Slim Scheduler can achieve various accuracy and latency trade-offs such as: A 96.45% reduction in mean latency and a 97.31% reduction in energy usage dropping accuracy to the slimmest model available (70.3%). It can then accomplish an overall reduction in average latency plus energy consumption with an increase in accuracy at the cost of higher standard deviations of said latency and energy, effecting overall task throughput.",
        "tags": [
            "PPO",
            "RL"
        ]
    },
    {
        "id": "138",
        "title": "RefGrader: Automated Grading of Mathematical Competition Proofs using Agentic Workflows",
        "author": [
            "Hamed Mahdavi",
            "Pouria Mahdavinia",
            "Samira Malek",
            "Pegah Mohammadipour",
            "Alireza Hashemi",
            "Majid Daliri",
            "Alireza Farhadi",
            "Amir Khasahmadi",
            "Niloofar Mireshghallah",
            "Vasant Honavar"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09021",
        "abstract": "State-of-the-art (SOTA) LLMs have progressed from struggling on proof-based Olympiad problems to solving most of the IMO 2025 problems, with leading systems reportedly handling 5 of 6 problems. Given this progress, we assess how well these models can grade proofs: detecting errors, judging their severity, and assigning fair scores beyond binary correctness. We study proof-analysis capabilities using a corpus of 90 Gemini 2.5 Pro-generated solutions that we grade on a 1-4 scale with detailed error annotations, and on MathArena solution sets for IMO/USAMO 2025 scored on a 0-7 scale. Our analysis shows that models can reliably flag incorrect (including subtly incorrect) solutions but exhibit calibration gaps in how partial credit is assigned. To address this, we introduce agentic workflows that extract and analyze reference solutions and automatically derive problem-specific rubrics for a multi-step grading process. We instantiate and compare different design choices for the grading workflows, and evaluate their trade-offs. Across our annotated corpus and MathArena, our proposed workflows achieve higher agreement with human grades and more consistent handling of partial credit across metrics. We release all code, data, and prompts/logs to facilitate future research.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "139",
        "title": "The Environmental Impacts of Machine Learning Training Keep Rising Evidencing Rebound Effect",
        "author": [
            "ClÃ©ment Morand",
            "Anne-Laure Ligozat",
            "AurÃ©lie NÃ©vÃ©ol"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09022",
        "abstract": "Recent Machine Learning (ML) approaches have shown increased performance on benchmarks but at the cost of escalating computational demands. Hardware, algorithmic and carbon optimizations have been proposed to curb energy consumption and environmental impacts. Can these strategies lead to sustainable ML model training? Here, we estimate the environmental impacts associated with training notable AI systems over the last decade, including Large Language Models, with a focus on the life cycle of graphics cards. Our analysis reveals two critical trends: First, the impacts of graphics cards production have increased steadily over this period; Second, energy consumption and environmental impacts associated with training ML models have increased exponentially, even when considering reduction strategies such as location shifting to places with less carbon intensive electricity mixes. Optimization strategies do not mitigate the impacts induced by model training, evidencing rebound effect. We show that the impacts of hardware must be considered over the entire life cycle rather than the sole use phase in order to avoid impact shifting. Our study demonstrates that increasing efficiency alone cannot ensure sustainability in ML. Mitigating the environmental impact of AI also requires reducing AI activities and questioning the scale and frequency of resource-intensive training.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "140",
        "title": "The Attacker Moves Second: Stronger Adaptive Attacks Bypass Defenses Against Llm Jailbreaks and Prompt Injections",
        "author": [
            "Milad Nasr",
            "Nicholas Carlini",
            "Chawin Sitawarin",
            "Sander V. Schulhoff",
            "Jamie Hayes",
            "Michael Ilie",
            "Juliette Pluto",
            "Shuang Song",
            "Harsh Chaudhari",
            "Ilia Shumailov",
            "Abhradeep Thakurta",
            "Kai Yuanqing Xiao",
            "Andreas Terzis",
            "Florian TramÃ¨r"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09023",
        "abstract": "How should we evaluate the robustness of language model defenses? Current defenses against jailbreaks and prompt injections (which aim to prevent an attacker from eliciting harmful knowledge or remotely triggering malicious actions, respectively) are typically evaluated either against a static set of harmful attack strings, or against computationally weak optimization methods that were not designed with the defense in mind. We argue that this evaluation process is flawed.\nInstead, we should evaluate defenses against adaptive attackers who explicitly modify their attack strategy to counter a defense's design while spending considerable resources to optimize their objective. By systematically tuning and scaling general optimization techniques-gradient descent, reinforcement learning, random search, and human-guided exploration-we bypass 12 recent defenses (based on a diverse set of techniques) with attack success rate above 90% for most; importantly, the majority of defenses originally reported near-zero attack success rates. We believe that future defense work must consider stronger attacks, such as the ones we describe, in order to make reliable and convincing claims of robustness.",
        "tags": [
            "LLM",
            "RL"
        ]
    },
    {
        "id": "141",
        "title": "Automated Refinement of Essay Scoring Rubrics for Language Models via Reflect-and-Revise",
        "author": [
            "Keno Harada",
            "Lui Yoshida",
            "Takeshi Kojima",
            "Yusuke Iwasawa",
            "Yutaka Matsuo"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09030",
        "abstract": "The performance of Large Language Models (LLMs) is highly sensitive to the prompts they are given. Drawing inspiration from the field of prompt optimization, this study investigates the potential for enhancing Automated Essay Scoring (AES) by refining the scoring rubrics used by LLMs. Specifically, our approach prompts models to iteratively refine rubrics by reflecting on models' own scoring rationales and observed discrepancies with human scores on sample essays. Experiments on the TOEFL11 and ASAP datasets using GPT-4.1, Gemini-2.5-Pro, and Qwen-3-Next-80B-A3B-Instruct show Quadratic Weighted Kappa (QWK) improvements of up to 0.19 and 0.47, respectively. Notably, even with a simple initial rubric, our approach achieves comparable or better QWK than using detailed human-authored rubrics. Our findings highlight the importance of iterative rubric refinement in LLM-based AES to enhance alignment with human evaluations.",
        "tags": [
            "GPT",
            "LLM",
            "Qwen"
        ]
    },
    {
        "id": "142",
        "title": "Web Crawler Restrictions, AI Training Datasets \\&amp; Political Biases",
        "author": [
            "Paul Bouchaud",
            "Pedro Ramaciotti"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09031",
        "abstract": "Large language models rely on web-scraped text for training; concurrently, content creators are increasingly blocking AI crawlers to retain control over their data. We analyze crawler restrictions across the top one million most-visited websites since 2023 and examine their potential downstream effects on training data composition. Our analysis reveals growing restrictions, with blocking patterns varying by website popularity and content type. A quarter of the top thousand websites restrict AI crawlers, decreasing to one-tenth across the broader top million. Content type matters significantly: 34.2% of news outlets disallow OpenAI's GPTBot, rising to 55% for outlets with high factual reporting. Additionally, outlets with neutral political positions impose the strongest restrictions (58%), whereas hyperpartisan websites and those with low factual reporting impose fewer restrictions -only 4.1% of right-leaning outlets block access to OpenAI. Our findings suggest that heterogeneous blocking patterns may skew training datasets toward low-quality or polarized content, potentially affecting the capabilities of models served by prominent AI-as-a-Service providers.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "143",
        "title": "Exploring Cross-Lingual Knowledge Transfer via Transliteration-Based MLM Fine-Tuning for Critically Low-resource Chakma Language",
        "author": [
            "Adity Khisa",
            "Nusrat Jahan Lia",
            "Tasnim Mahfuz Nafis",
            "Zarif Masud",
            "Tanzir Pial",
            "Shebuti Rayana",
            "Ahmedul Kabir"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09032",
        "abstract": "As an Indo-Aryan language with limited available data, Chakma remains largely underrepresented in language models. In this work, we introduce a novel corpus of contextually coherent Bangla-transliterated Chakma, curated from Chakma literature, and validated by native speakers. Using this dataset, we fine-tune six encoder-based multilingual and regional transformer models (mBERT, XLM-RoBERTa, DistilBERT, DeBERTaV3, BanglaBERT, and IndicBERT) on masked language modeling (MLM) tasks. Our experiments show that fine-tuned multilingual models outperform their pre-trained counterparts when adapted to Bangla-transliterated Chakma, achieving up to 73.54% token accuracy and a perplexity as low as 2.90. Our analysis further highlights the impact of data quality on model performance and shows the limitations of OCR pipelines for morphologically rich Indic scripts. Our research demonstrates that Bangla-transliterated Chakma can be very effective for transfer learning for Chakma language, and we release our manually validated monolingual dataset to encourage further research on multilingual language modeling for low-resource languages.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "144",
        "title": "Large Language Models Do NOT Really Know What They Don't Know",
        "author": [
            "Chi Seng Cheang",
            "Hou Pong Chan",
            "Wenxuan Zhang",
            "Yang Deng"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09033",
        "abstract": "Recent work suggests that large language models (LLMs) encode factuality signals in their internal representations, such as hidden states, attention weights, or token probabilities, implying that LLMs may \"know what they don't know\". However, LLMs can also produce factual errors by relying on shortcuts or spurious associations. These error are driven by the same training objective that encourage correct predictions, raising the question of whether internal computations can reliably distinguish between factual and hallucinated outputs. In this work, we conduct a mechanistic analysis of how LLMs internally process factual queries by comparing two types of hallucinations based on their reliance on subject information. We find that when hallucinations are associated with subject knowledge, LLMs employ the same internal recall process as for correct responses, leading to overlapping and indistinguishable hidden-state geometries. In contrast, hallucinations detached from subject knowledge produce distinct, clustered representations that make them detectable. These findings reveal a fundamental limitation: LLMs do not encode truthfulness in their internal states but only patterns of knowledge recall, demonstrating that \"LLMs don't really know what they don't know\".",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "145",
        "title": "Convergence of optimizers implies eigenvalues filtering at equilibrium",
        "author": [
            "Jerome Bolte",
            "Quoc-Tung Le",
            "Edouard Pauwels"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09034",
        "abstract": "Ample empirical evidence in deep neural network training suggests that a variety of optimizers tend to find nearly global optima. In this article, we adopt the reversed perspective that convergence to an arbitrary point is assumed rather than proven, focusing on the consequences of this assumption. From this viewpoint, in line with recent advances on the edge-of-stability phenomenon, we argue that different optimizers effectively act as eigenvalue filters determined by their hyperparameters. Specifically, the standard gradient descent method inherently avoids the sharpest minima, whereas Sharpness-Aware Minimization (SAM) algorithms go even further by actively favoring wider basins. Inspired by these insights, we propose two novel algorithms that exhibit enhanced eigenvalue filtering, effectively promoting wider minima. Our theoretical analysis leverages a generalized Hadamard--Perron stable manifold theorem and applies to general semialgebraic $C^2$ functions, without requiring additional non-degeneracy conditions or global Lipschitz bound assumptions. We support our conclusions with numerical experiments on feed-forward neural networks.",
        "tags": [
            "SAM"
        ]
    },
    {
        "id": "146",
        "title": "iMoWM: Taming Interactive Multi-Modal World Model for Robotic Manipulation",
        "author": [
            "Chuanrui Zhang",
            "Zhengxian Wu",
            "Guanxing Lu",
            "Yansong Tang",
            "Ziwei Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09036",
        "abstract": "Learned world models hold significant potential for robotic manipulation, as they can serve as simulator for real-world interactions. While extensive progress has been made in 2D video-based world models, these approaches often lack geometric and spatial reasoning, which is essential for capturing the physical structure of the 3D world. To address this limitation, we introduce iMoWM, a novel interactive world model designed to generate color images, depth maps, and robot arm masks in an autoregressive manner conditioned on actions. To overcome the high computational cost associated with three-dimensional information, we propose MMTokenizer, which unifies multi-modal inputs into a compact token representation. This design enables iMoWM to leverage large-scale pretrained VideoGPT models while maintaining high efficiency and incorporating richer physical information. With its multi-modal representation, iMoWM not only improves the visual quality of future predictions but also serves as an effective simulator for model-based reinforcement learning (MBRL) and facilitates real-world imitation learning. Extensive experiments demonstrate the superiority of iMoWM across these tasks, showcasing the advantages of multi-modal world modeling for robotic manipulation. Homepage: https://xingyoujun.github.io/imowm/",
        "tags": [
            "3D",
            "RL",
            "Robotics"
        ]
    },
    {
        "id": "147",
        "title": "Repairing Regex Vulnerabilities via Localization-Guided Instructions",
        "author": [
            "Sicheol Sung",
            "Joonghyuk Hahn",
            "Yo-Sub Han"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09037",
        "abstract": "Regular expressions (regexes) are foundational to modern computing for critical tasks like input validation and data parsing, yet their ubiquity exposes systems to regular expression denial of service (ReDoS), a vulnerability requiring automated repair methods. Current approaches, however, are hampered by a trade-off. Symbolic, rule-based system are precise but fails to repair unseen or complex vulnerability patterns. Conversely, large language models (LLMs) possess the necessary generalizability but are unreliable for tasks demanding strict syntactic and semantic correctness. We resolve this impasse by introducing a hybrid framework, localized regex repair (LRR), designed to harness LLM generalization while enforcing reliability. Our core insight is to decouple problem identification from the repair process. First, a deterministic, symbolic module localizes the precise vulnerable subpattern, creating a constrained and tractable problem space. Then, the LLM invoked to generate a semantically equivalent fix for this isolated segment. This combined architecture successfully resolves complex repair cases intractable for rule-based repair while avoiding the semantic errors of LLM-only approaches. Our work provides a validated methodology for solving such problems in automated repair, improving the repair rate by 15.4%p over the state-of-the-art. Our code is available at https://github.com/cdltlehf/LRR.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "148",
        "title": "Auto-scaling Continuous Memory for GUI Agent",
        "author": [
            "Wenyi Wu",
            "Kun Zhou",
            "Ruoxin Yuan",
            "Vivian Yu",
            "Stephen Wang",
            "Zhiting Hu",
            "Biwei Huang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09038",
        "abstract": "We study how to endow GUI agents with scalable memory that help generalize across unfamiliar interfaces and long-horizon tasks. Prior GUI agents compress past trajectories into text tokens, which balloons context length and misses decisive visual cues (e.g., exact widget size and position). We propose a continuous memory that encodes each GUI trajectory into a fixed-length sequence of continuous embeddings using the VLM itself as an encoder; these embeddings are plugged directly into the backbone's input layer, sharply reducing context cost while preserving fine-grained visual information. As memory size and retrieval depth increase, performance improves monotonically, unlike text memories that degrade with long prompts. To grow memory at low cost, we introduce an auto-scaling data flywheel that (i) discovers new environments via search, (ii) synthesizes tasks with an open-source VLM, (iii) rolls out trajectories with the agent, and (iv) verifies success with the same VLM. Using this pipeline, we collect 100k+ trajectories for about \\$4000 and fine-tune only the memory encoder (LoRA on a Q-Former, 1.2\\% parameters) with 1,500 samples. On real-world GUI benchmarks, our memory-augmented agent consistently improves success rates under long horizons and distribution shifts. Notably, Qwen-2.5-VL-7B + continuous memory achieves performance comparable to state-of-the-art closed-source models (e.g., GPT-4o, Claude-4).",
        "tags": [
            "GPT",
            "LoRA",
            "Qwen",
            "VLM"
        ]
    },
    {
        "id": "149",
        "title": "Humanoid Artificial Consciousness Designed with Large Language Model Based on Psychoanalysis and Personality Theory",
        "author": [
            "Sang Hun Kim",
            "Jongmin Lee",
            "Dongkyu Park",
            "So Young Lee",
            "Yosep Chong"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09043",
        "abstract": "Human consciousness is still a concept hard to define with current scientific understanding. Although Large Language Models (LLMs) have recently demonstrated significant advancements across various domains including translation and summarization, human consciousness is not something to imitate with current upfront technology owing to so-called hallucination. This study, therefore, proposes a novel approach to address these challenges by integrating psychoanalysis and the Myers-Briggs Type Indicator (MBTI) into constructing consciousness and personality modules. We developed three artificial consciousnesses (self-awareness, unconsciousness, and preconsciousness) based on the principles of psychoanalysis. Additionally, we designed 16 characters with different personalities representing the sixteen MBTI types, with several attributes such as needs, status, and memories. To determine if our model's artificial consciousness exhibits human-like cognition, we created ten distinct situations considering seven attributes such as emotional understanding and logical thinking. The decision-making process of artificial consciousness and the final action were evaluated in three ways: survey evaluation, three-tier classification via ChatGPT, and qualitative review. Both quantitative and qualitative analyses indicated a high likelihood of well-simulated consciousness, although the difference in response between different characters and consciousnesses was not very significant. This implies that the developed models incorporating elements of psychoanalysis and personality theory can lead to building a more intuitive and adaptable AI system with humanoid consciousness. Therefore, this study contributes to opening up new avenues for improving AI interactions in complex cognitive contexts.",
        "tags": [
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "150",
        "title": "Cost-Efficient Long Code Translation using LLMs while Leveraging Identifier Replacements",
        "author": [
            "Manojit Chakraborty",
            "Madhusudan Ghosh",
            "Rishabh Gupta"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09045",
        "abstract": "In the domain of software development, LLMs have been utilized to automate tasks such as code translation, where source code from one programming language is translated to another while preserving its functionality. However, LLMs often struggle with long source codes that don't fit into the context window, which produces inaccurate translations. To address this, we propose a novel zero-shot code translation method that incorporates identifier replacement. By substituting user-given long identifiers with generalized placeholders during translation, our method allows the LLM to focus on the logical structure of the code, by reducing token count and memory usage, which improves the efficiency and cost-effectiveness of long code translation. Our empirical results demonstrate that our approach preserves syntactical and hierarchical information and produces translation results with reduced tokens.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "151",
        "title": "MEC$^3$O: Multi-Expert Consensus for Code Time Complexity Prediction",
        "author": [
            "Joonghyuk Hahn",
            "Soohan Lim",
            "Yo-Sub Han"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09049",
        "abstract": "Predicting the complexity of source code is essential for software development and algorithm analysis. Recently, Baik et al. (2025) introduced CodeComplex for code time complexity prediction. The paper shows that LLMs without fine-tuning struggle with certain complexity classes. This suggests that no single LLM excels at every class, but rather each model shows advantages in certain classes. We propose MEC$^3$O, a multi-expert consensus system, which extends the multi-agent debate frameworks. MEC$^3$O assigns LLMs to complexity classes based on their performance and provides them with class-specialized instructions, turning them into experts. These experts engage in structured debates, and their predictions are integrated through a weighted consensus mechanism. Our expertise assignments to LLMs effectively handle Degeneration-of-Thought, reducing reliance on a separate judge model, and preventing convergence to incorrect majority opinions. Experiments on CodeComplex show that MEC$^3$O outperforms the open-source baselines, achieving at least 10% higher accuracy and macro-F1 scores. It also surpasses GPT-4o-mini in macro-F1 scores on average and demonstrates competitive on-par F1 scores to GPT-4o and GPT-o4-mini on average. This demonstrates the effectiveness of multi-expert debates and weight consensus strategy to generate the final predictions. Our code and data is available at https://github.com/suhanmen/MECO.",
        "tags": [
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "152",
        "title": "Alif: Advancing Urdu Large Language Models via Multilingual Synthetic Data Distillation",
        "author": [
            "Muhammad Ali Shafique",
            "Kanwal Mehreen",
            "Muhammad Arham",
            "Maaz Amjad",
            "Sabur Butt",
            "Hamza Farooq"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09051",
        "abstract": "Developing a high-performing large language models (LLMs) for low-resource languages such as Urdu, present several challenges. These challenges include the scarcity of high-quality datasets, multilingual inconsistencies, and safety concerns. Existing multilingual LLMs often address these issues by translating large volumes of available data. However, such translations often lack quality and cultural nuance while also incurring significant costs for data curation and training. To address these issues, we propose Alif-1.0-8B-Instruct, a multilingual Urdu-English model, that tackles these challenges with a unique approach. We train the model on a high-quality, multilingual synthetic dataset (Urdu-Instruct), developed using a modified self-instruct technique. By using unique prompts and seed values for each task along with a global task pool, this dataset incorporates Urdu-native chain-of-thought based reasoning, bilingual translation, cultural relevance, and ethical safety alignments. This technique significantly enhances the comprehension of Alif-1.0-8B-Instruct model for Urdu-specific tasks. As a result, Alif-1.0-8B-Instruct, built upon the pretrained Llama-3.1-8B, demonstrates superior performance compared to Llama-3.1-8B-Instruct for Urdu specific-tasks. It also outperformed leading multilingual LLMs, including Mistral-7B-Instruct-v0.3, Qwen-2.5-7B-Instruct, and Cohere-Aya-Expanse-8B, all within a training budget of under $100. Our results demonstrate that high-performance and low-resource language LLMs can be developed efficiently and culturally aligned using our modified self-instruct approach. All datasets, models, and code are publicly available at: https://github.com/traversaal-ai/alif-urdu-llm.",
        "tags": [
            "CoT",
            "LLM",
            "LLaMA",
            "Qwen"
        ]
    },
    {
        "id": "153",
        "title": "Model-Assisted and Human-Guided: Perceptions and Practices of Software Professionals Using LLMs for Coding",
        "author": [
            "Italo Santos",
            "Cleyton Magalhaes",
            "Ronnie de Souza Santos"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09058",
        "abstract": "Large Language Models have quickly become a central component of modern software development workflows, and software practitioners are increasingly integrating LLMs into various stages of the software development lifecycle. Despite the growing presence of LLMs, there is still a limited understanding of how these tools are actually used in practice and how professionals perceive their benefits and limitations. This paper presents preliminary findings from a global survey of 131 software practitioners. Our results reveal how LLMs are utilized for various coding-specific tasks. Software professionals report benefits such as increased productivity, reduced cognitive load, and faster learning, but also raise concerns about LLMs' inaccurate outputs, limited context awareness, and associated ethical risks. Most developers treat LLMs as assistive tools rather than standalone solutions, reflecting a cautious yet practical approach to their integration. Our findings provide an early, practitioner-focused perspective on LLM adoption, highlighting key considerations for future research and responsible use in software engineering.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "154",
        "title": "OSCAR: Orthogonal Stochastic Control for Alignment-Respecting Diversity in Flow Matching",
        "author": [
            "Jingxuan Wu",
            "Zhenglin Wan",
            "Xingrui Yu",
            "Yuzhe Yang",
            "Bo An",
            "Ivor Tsang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09060",
        "abstract": "Flow-based text-to-image models follow deterministic trajectories, forcing users to repeatedly sample to discover diverse modes, which is a costly and inefficient process. We present a training-free, inference-time control mechanism that makes the flow itself diversity-aware. Our method simultaneously encourages lateral spread among trajectories via a feature-space objective and reintroduces uncertainty through a time-scheduled stochastic perturbation. Crucially, this perturbation is projected to be orthogonal to the generation flow, a geometric constraint that allows it to boost variation without degrading image details or prompt fidelity. Our procedure requires no retraining or modification to the base sampler and is compatible with common flow-matching solvers. Theoretically, our method is shown to monotonically increase a volume surrogate while, due to its geometric constraints, approximately preserving the marginal distribution. This provides a principled explanation for why generation quality is robustly maintained. Empirically, across multiple text-to-image settings under fixed sampling budgets, our method consistently improves diversity metrics such as the Vendi Score and Brisque over strong baselines, while upholding image quality and alignment.",
        "tags": [
            "Flow Matching",
            "Text-to-Image"
        ]
    },
    {
        "id": "155",
        "title": "ReFIne: A Framework for Trustworthy Large Reasoning Models with Reliability, Faithfulness, and Interpretability",
        "author": [
            "Chung-En Sun",
            "Ge Yan",
            "Akshay Kulkarni",
            "Tsui-Wei Weng"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09062",
        "abstract": "Recent advances in long chain-of-thought (CoT) reasoning have largely prioritized answer accuracy and token efficiency, while overlooking aspects critical to trustworthiness. We argue that usable reasoning systems must be trustworthy, characterized by three properties: interpretability, faithfulness, and reliability. To this end, we propose ReFIne, a new training framework that integrates supervised fine-tuning with GRPO to encourage models to: (i) improve interpretability by producing structured, tag-based traces with high-level planning that are easier for humans to follow; (ii) enhance faithfulness by explicitly disclosing the decisive information guiding each solution, with consistent cross-section references; and (iii) promote reliability by providing self-assessments of both the derivation's soundness and the confidence of the final answer. We apply ReFIne to the Qwen3 models at multiple scales (1.7B/4B/8B) and evaluate across mathematical benchmarks of varying difficulty. Our experimental results show that ReFIne models generate clearer and better-structured reasoning traces (interpretability +44.0%), more faithfully expose their underlying decision process (faithfulness +18.8%), and offer informative confidence estimates (reliability +42.4%). These findings highlight an overlooked but important direction: reasoning models should be optimized not only for accuracy, but also for broader dimensions of trustworthiness. Our code is available at: https://github.com/Trustworthy-ML-Lab/Training_Trustworthy_LRM_with_Refine",
        "tags": [
            "CoT",
            "GRPO"
        ]
    },
    {
        "id": "156",
        "title": "MCMC: Bridging Rendering, Optimization and Generative AI",
        "author": [
            "Gurprit Singh",
            "Wenzel Jakob"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09078",
        "abstract": "Generative artificial intelligence (AI) has made unprecedented advances in vision language models over the past two years. During the generative process, new samples (images) are generated from an unknown high-dimensional distribution. Markov Chain Monte Carlo (MCMC) methods are particularly effective in drawing samples from such complex, high-dimensional distributions. This makes MCMC methods an integral component for models like EBMs, ensuring accurate sample generation.\nGradient-based optimization is at the core of modern generative models. The update step during the optimization forms a Markov chain where the new update depends only on the current state. This allows exploration of the parameter space in a memoryless manner, thus combining the benefits of gradient-based optimization and MCMC sampling. MCMC methods have shown an equally important role in physically based rendering where complex light paths are otherwise quite challenging to sample from simple importance sampling techniques.\nA lot of research is dedicated towards bringing physical realism to samples (images) generated from diffusion-based generative models in a data-driven manner, however, a unified framework connecting these techniques is still missing. In this course, we take the first steps toward understanding each of these components and exploring how MCMC could potentially serve as a bridge, linking these closely related areas of research. Our course aims to provide necessary theoretical and practical tools to guide students, researchers and practitioners towards the common goal of generative physically based rendering. All Jupyter notebooks with demonstrations associated to this tutorial can be found on the project webpage: https://sinbag.github.io/mcmc/",
        "tags": [
            "Diffusion",
            "VLM"
        ]
    },
    {
        "id": "157",
        "title": "Training Models to Detect Successive Robot Errors from Human Reactions",
        "author": [
            "Shannon Liu",
            "Maria Teresa Parreira",
            "Wendy Ju"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09080",
        "abstract": "As robots become more integrated into society, detecting robot errors is essential for effective human-robot interaction (HRI). When a robot fails repeatedly, how can it know when to change its behavior? Humans naturally respond to robot errors through verbal and nonverbal cues that intensify over successive failures-from confusion and subtle speech changes to visible frustration and impatience. While prior work shows that human reactions can indicate robot failures, few studies examine how these evolving responses reveal successive failures. This research uses machine learning to recognize stages of robot failure from human reactions. In a study with 26 participants interacting with a robot that made repeated conversational errors, behavioral features were extracted from video data to train models for individual users. The best model achieved 93.5% accuracy for detecting errors and 84.1% for classifying successive failures. Modeling the progression of human reactions enhances error detection and understanding of repeated interaction breakdowns in HRI.",
        "tags": [
            "Detection",
            "Robotics"
        ]
    },
    {
        "id": "158",
        "title": "Leading the Follower: Learning Persuasive Agents in Social Deduction Games",
        "author": [
            "Zhang Zheng",
            "Deheng Ye",
            "Peilin Zhao",
            "Hao Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09087",
        "abstract": "Large language model (LLM) agents have shown remarkable progress in social deduction games (SDGs). However, existing approaches primarily focus on information processing and strategy selection, overlooking the significance of persuasive communication in influencing other players' beliefs and responses. In SDGs, success depends not only on making correct deductions but on convincing others to response in alignment with one's intent. To address this limitation, we formalize turn-based dialogue in SDGs as a Stackelberg competition, where the current player acts as the leader who strategically influences the follower's response. Building on this theoretical foundation, we propose a reinforcement learning framework that trains agents to optimize utterances for persuasive impact. Through comprehensive experiments across three diverse SDGs, we demonstrate that our agents significantly outperform baselines. This work represents a significant step toward developing AI agents capable of strategic social influence, with implications extending to scenarios requiring persuasive communication.",
        "tags": [
            "LLM",
            "RL"
        ]
    },
    {
        "id": "159",
        "title": "MambaH-Fit: Rethinking Hyper-surface Fitting-based Point Cloud Normal Estimation via State Space Modelling",
        "author": [
            "Weijia Wang",
            "Yuanzhi Su",
            "Pei-Gen Ye",
            "Yuan-Gen Wang",
            "Xuequan Lu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09088",
        "abstract": "We present MambaH-Fit, a state space modelling framework tailored for hyper-surface fitting-based point cloud normal estimation. Existing normal estimation methods often fall short in modelling fine-grained geometric structures, thereby limiting the accuracy of the predicted normals. Recently, state space models (SSMs), particularly Mamba, have demonstrated strong modelling capability by capturing long-range dependencies with linear complexity and inspired adaptations to point cloud processing. However, existing Mamba-based approaches primarily focus on understanding global shape structures, leaving the modelling of local, fine-grained geometric details largely under-explored. To address the issues above, we first introduce an Attention-driven Hierarchical Feature Fusion (AHFF) scheme to adaptively fuse multi-scale point cloud patch features, significantly enhancing geometric context learning in local point cloud neighbourhoods. Building upon this, we further propose Patch-wise State Space Model (PSSM) that models point cloud patches as implicit hyper-surfaces via state dynamics, enabling effective fine-grained geometric understanding for normal prediction. Extensive experiments on benchmark datasets show that our method outperforms existing ones in terms of accuracy, robustness, and flexibility. Ablation studies further validate the contribution of the proposed components.",
        "tags": [
            "Mamba",
            "SSMs"
        ]
    },
    {
        "id": "160",
        "title": "Robust Visual Teach-and-Repeat Navigation with Flexible Topo-metric Graph Map Representation",
        "author": [
            "Jikai Wang",
            "Yunqi Cheng",
            "Kezhi Wang",
            "Zonghai Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09089",
        "abstract": "Visual Teach-and-Repeat Navigation is a direct solution for mobile robot to be deployed in unknown environments. However, robust trajectory repeat navigation still remains challenged due to environmental changing and dynamic objects. In this paper, we propose a novel visual teach-and-repeat navigation system, which consists of a flexible map representation, robust map matching and a map-less local navigation module. During the teaching process, the recorded keyframes are formulated as a topo-metric graph and each node can be further extended to save new observations. Such representation also alleviates the requirement of globally consistent mapping. To enhance the place recognition performance during repeating process, instead of using frame-to-frame matching, we firstly implement keyframe clustering to aggregate similar connected keyframes into local map and perform place recognition based on visual frame-tolocal map matching strategy. To promote the local goal persistent tracking performance, a long-term goal management algorithm is constructed, which can avoid the robot getting lost due to environmental changes or obstacle occlusion. To achieve the goal without map, a local trajectory-control candidate optimization algorithm is proposed. Extensively experiments are conducted on our mobile platform. The results demonstrate that our system is superior to the baselines in terms of robustness and effectiveness.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "161",
        "title": "Exploiting Web Search Tools of AI Agents for Data Exfiltration",
        "author": [
            "Dennis Rall",
            "Bernhard Bauer",
            "Mohit Mittal",
            "Thomas Fraunholz"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09093",
        "abstract": "Large language models (LLMs) are now routinely used to autonomously execute complex tasks, from natural language processing to dynamic workflows like web searches. The usage of tool-calling and Retrieval Augmented Generation (RAG) allows LLMs to process and retrieve sensitive corporate data, amplifying both their functionality and vulnerability to abuse. As LLMs increasingly interact with external data sources, indirect prompt injection emerges as a critical and evolving attack vector, enabling adversaries to exploit models through manipulated inputs. Through a systematic evaluation of indirect prompt injection attacks across diverse models, we analyze how susceptible current LLMs are to such attacks, which parameters, including model size and manufacturer, specific implementations, shape their vulnerability, and which attack methods remain most effective. Our results reveal that even well-known attack patterns continue to succeed, exposing persistent weaknesses in model defenses. To address these vulnerabilities, we emphasize the need for strengthened training procedures to enhance inherent resilience, a centralized database of known attack vectors to enable proactive defense, and a unified testing framework to ensure continuous security validation. These steps are essential to push developers toward integrating security into the core design of LLMs, as our findings show that current models still fail to mitigate long-standing threats.",
        "tags": [
            "LLM",
            "RAG"
        ]
    },
    {
        "id": "162",
        "title": "Dense2MoE: Restructuring Diffusion Transformer to MoE for Efficient Text-to-Image Generation",
        "author": [
            "Youwei Zheng",
            "Yuxi Ren",
            "Xin Xia",
            "Xuefeng Xiao",
            "Xiaohua Xie"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09094",
        "abstract": "Diffusion Transformer (DiT) has demonstrated remarkable performance in text-to-image generation; however, its large parameter size results in substantial inference overhead. Existing parameter compression methods primarily focus on pruning, but aggressive pruning often leads to severe performance degradation due to reduced model capacity. To address this limitation, we pioneer the transformation of a dense DiT into a Mixture of Experts (MoE) for structured sparsification, reducing the number of activated parameters while preserving model capacity. Specifically, we replace the Feed-Forward Networks (FFNs) in DiT Blocks with MoE layers, reducing the number of activated parameters in the FFNs by 62.5\\%. Furthermore, we propose the Mixture of Blocks (MoB) to selectively activate DiT blocks, thereby further enhancing sparsity. To ensure an effective dense-to-MoE conversion, we design a multi-step distillation pipeline, incorporating Taylor metric-based expert initialization, knowledge distillation with load balancing, and group feature loss for MoB optimization. We transform large diffusion transformers (e.g., FLUX.1 [dev]) into an MoE structure, reducing activated parameters by 60\\% while maintaining original performance and surpassing pruning-based approaches in extensive experiments. Overall, Dense2MoE establishes a new paradigm for efficient text-to-image generation.",
        "tags": [
            "DiT",
            "Diffusion",
            "FLUX",
            "MoE",
            "Text-to-Image",
            "Transformer"
        ]
    },
    {
        "id": "163",
        "title": "When a Robot is More Capable than a Human: Learning from Constrained Demonstrators",
        "author": [
            "Xinhu Li",
            "Ayush Jain",
            "Zhaojing Yang",
            "Yigit Korkmaz",
            "Erdem BÄ±yÄ±k"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09096",
        "abstract": "Learning from demonstrations enables experts to teach robots complex tasks using interfaces such as kinesthetic teaching, joystick control, and sim-to-real transfer. However, these interfaces often constrain the expert's ability to demonstrate optimal behavior due to indirect control, setup restrictions, and hardware safety. For example, a joystick can move a robotic arm only in a 2D plane, even though the robot operates in a higher-dimensional space. As a result, the demonstrations collected by constrained experts lead to suboptimal performance of the learned policies. This raises a key question: Can a robot learn a better policy than the one demonstrated by a constrained expert? We address this by allowing the agent to go beyond direct imitation of expert actions and explore shorter and more efficient trajectories. We use the demonstrations to infer a state-only reward signal that measures task progress, and self-label reward for unknown states using temporal interpolation. Our approach outperforms common imitation learning in both sample efficiency and task completion time. On a real WidowX robotic arm, it completes the task in 12 seconds, 10x faster than behavioral cloning, as shown in real-robot videos on https://sites.google.com/view/constrainedexpert .",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "164",
        "title": "FrameEOL: Semantic Frame Induction using Causal Language Models",
        "author": [
            "Chihiro Yano",
            "Kosuke Yamada",
            "Hayato Tsukagoshi",
            "Ryohei Sasano",
            "Koichi Takeda"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09097",
        "abstract": "Semantic frame induction is the task of clustering frame-evoking words according to the semantic frames they evoke. In recent years, leveraging embeddings of frame-evoking words that are obtained using masked language models (MLMs) such as BERT has led to high-performance semantic frame induction. Although causal language models (CLMs) such as the GPT and Llama series succeed in a wide range of language comprehension tasks and can engage in dialogue as if they understood frames, they have not yet been applied to semantic frame induction. We propose a new method for semantic frame induction based on CLMs. Specifically, we introduce FrameEOL, a prompt-based method for obtaining Frame Embeddings that outputs One frame-name as a Label representing the given situation. To obtain embeddings more suitable for frame induction, we leverage in-context learning (ICL) and deep metric learning (DML). Frame induction is then performed by clustering the resulting embeddings. Experimental results on the English and Japanese FrameNet datasets demonstrate that the proposed methods outperform existing frame induction methods. In particular, for Japanese, which lacks extensive frame resources, the CLM-based method using only 5 ICL examples achieved comparable performance to the MLM-based method fine-tuned with DML.",
        "tags": [
            "BERT",
            "GPT",
            "LLaMA"
        ]
    },
    {
        "id": "165",
        "title": "AdaPM: a Partial Momentum Algorithm for LLM Training",
        "author": [
            "Yimu Zhang",
            "Yuanshi Liu",
            "Cong Fang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09103",
        "abstract": "In the training of large language models, momentum is widely used and often demonstrated to achieve significant acceleration. However, storing momentum typically presents memory challenges. In this paper, we propose AdaPM, an adaptive training strategy that leverages partial momentum to implement a memory-efficient optimizer. To this end, AdaPM utilizes a non-uniform momentum design: for most blocks, full momentum is not necessary to preserve the performance of the optimization. In the momentum design of AdaPM, to mitigate the bias and performance loss caused by partial momentum, we enhance the partial momentum by a bias correction technique. Empirically, we verify that our approach reduces memory by over $90\\%$ in momentum while maintaining both efficiency and performance for pretraining various language models ranging from 60M to 1.5B, as well as for supervised fine-tuning and RLHF. AdaPM can further reduce memory by up to $95\\%$ in optimizer states by combining the memory-efficient technique on the second-order statistic, saving over $30\\%$ GPU hours for pretraining GPT-2 1.5B.",
        "tags": [
            "GPT",
            "LLM",
            "RLHF"
        ]
    },
    {
        "id": "166",
        "title": "When Retrieval Succeeds and Fails: Rethinking Retrieval-Augmented Generation for LLMs",
        "author": [
            "Yongjie Wang",
            "Yue Yu",
            "Kaisong Song",
            "Jun Lin",
            "Zhiqi Shen"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09106",
        "abstract": "Large Language Models (LLMs) have enabled a wide range of applications through their powerful capabilities in language understanding and generation. However, as LLMs are trained on static corpora, they face difficulties in addressing rapidly evolving information or domain-specific queries. Retrieval-Augmented Generation (RAG) was developed to overcome this limitation by integrating LLMs with external retrieval mechanisms, allowing them to access up-to-date and contextually relevant knowledge. However, as LLMs themselves continue to advance in scale and capability, the relative advantages of traditional RAG frameworks have become less pronounced and necessary. Here, we present a comprehensive review of RAG, beginning with its overarching objectives and core components. We then analyze the key challenges within RAG, highlighting critical weakness that may limit its effectiveness. Finally, we showcase applications where LLMs alone perform inadequately, but where RAG, when combined with LLMs, can substantially enhance their effectiveness. We hope this work will encourage researchers to reconsider the role of RAG and inspire the development of next-generation RAG systems.",
        "tags": [
            "LLM",
            "RAG"
        ]
    },
    {
        "id": "167",
        "title": "DITING: A Multi-Agent Evaluation Framework for Benchmarking Web Novel Translation",
        "author": [
            "Enze Zhang",
            "Jiaying Wang",
            "Mengxi Xiao",
            "Jifei Liu",
            "Ziyan Kuang",
            "Rui Dong",
            "Youzhong Dong",
            "Sophia Ananiadou",
            "Min Peng",
            "Qianqian Xie"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09116",
        "abstract": "Large language models (LLMs) have substantially advanced machine translation (MT), yet their effectiveness in translating web novels remains unclear. Existing benchmarks rely on surface-level metrics that fail to capture the distinctive traits of this genre. To address these gaps, we introduce DITING, the first comprehensive evaluation framework for web novel translation, assessing narrative and cultural fidelity across six dimensions: idiom translation, lexical ambiguity, terminology localization, tense consistency, zero-pronoun resolution, and cultural safety, supported by over 18K expert-annotated Chinese-English sentence pairs. We further propose AgentEval, a reasoning-driven multi-agent evaluation framework that simulates expert deliberation to assess translation quality beyond lexical overlap, achieving the highest correlation with human judgments among seven tested automatic metrics. To enable metric comparison, we develop MetricAlign, a meta-evaluation dataset of 300 sentence pairs annotated with error labels and scalar quality scores. Comprehensive evaluation of fourteen open, closed, and commercial models reveals that Chinese-trained LLMs surpass larger foreign counterparts, and that DeepSeek-V3 delivers the most faithful and stylistically coherent translations. Our work establishes a new paradigm for exploring LLM-based web novel translation and provides public resources to advance future research.",
        "tags": [
            "DeepSeek",
            "LLM"
        ]
    },
    {
        "id": "168",
        "title": "Score-Based Density Estimation from Pairwise Comparisons",
        "author": [
            "Petrus Mikkola",
            "Luigi Acerbi",
            "Arto Klami"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09146",
        "abstract": "We study density estimation from pairwise comparisons, motivated by expert knowledge elicitation and learning from human feedback. We relate the unobserved target density to a tempered winner density (marginal density of preferred choices), learning the winner's score via score-matching. This allows estimating the target by `de-tempering' the estimated winner density's score. We prove that the score vectors of the belief and the winner density are collinear, linked by a position-dependent tempering field. We give analytical formulas for this field and propose an estimator for it under the Bradley-Terry model. Using a diffusion model trained on tempered samples generated via score-scaled annealed Langevin dynamics, we can learn complex multivariate belief densities of simulated experts, from only hundreds to thousands of pairwise comparisons.",
        "tags": [
            "Diffusion",
            "Score Matching"
        ]
    },
    {
        "id": "169",
        "title": "Logits Replay + MoClip: Stabilized, Low-Cost Post-Training with Minimal Forgetting",
        "author": [
            "Suming Qiu",
            "Jing Li",
            "Zhicheng Zhou",
            "Junjie Huang",
            "Linyuan Qiu",
            "Zhijie Sun"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09152",
        "abstract": "Large language models (LLMs) often face a trade-off in post-training: improvements on specialized domains frequently come at the expense of general capabilities. Existing solutions attempt to mitigate this tension via regularization, selective parameter updates, or data-centric replay, but each imposes significant costs in computation, data access, or adaptability. Recent work has shown that training signals can be compressed to subsets of logits without severe accuracy loss, suggesting a path toward efficient adaptation. However, naive truncation destabilizes optimization and exacerbates forgetting.\nWe introduce Logits Replay + MoClip, a two-stage framework that compresses supervision in the logit space and stabilizes optimization at the update level. In Stage 0, we record dynamic Top-K token subsets that cover a probability threshold, always including the gold label. In Stage 1, we replay these compact subsets to compute exact renormalized losses, avoiding full softmax computation and implicitly regularizing. To ensure stability, we design MoClip, an optimizer that caps gradient-momentum rotation and applies an arctan2-based rescaling of updates. Empirically, our method improves domain performance on Communication Technology (CT) and NL2SQL tasks while mitigating forgetting on general benchmarks (MMLU, BBH, GPQA, MATH), and reduces training cost by over 40%. Together, these contributions offer a scalable, architecture-agnostic path for domain adaptation of LLMs without sacrificing generalization.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "170",
        "title": "Agentic-KGR: Co-evolutionary Knowledge Graph Construction through Multi-Agent Reinforcement Learning",
        "author": [
            "Jing Li",
            "Zhijie Sun",
            "Zhicheng Zhou",
            "Suming Qiu",
            "Junjie Huang",
            "Haijia Sun",
            "Linyuan Qiu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09156",
        "abstract": "Current knowledge-enhanced large language models (LLMs) rely on static, pre-constructed knowledge bases that suffer from coverage gaps and temporal obsolescence, limiting their effectiveness in dynamic information environments. We present Agentic-KGR, a novel framework enabling co-evolution between LLMs and knowledge graphs (KGs) through multi-round reinforcement learning (RL). Our approach introduces three key innovations: (1) a dynamic schema expansion mechanism that systematically extends graph ontologies beyond pre-defined boundaries during training; (2) a retrieval-augmented memory system enabling synergistic co-evolution between model parameters and knowledge structures through continuous optimization; (3) a learnable multi-scale prompt compression approach that preserves critical information while reducing computational complexity through adaptive sequence optimization. Experimental results demonstrate substantial improvements over supervised baselines and single-round RL approaches in knowledge extraction tasks. When integrated with GraphRAG, our method achieves superior performance in downstream QA tasks, with significant gains in both accuracy and knowledge coverage compared to existing methods.",
        "tags": [
            "LLM",
            "RL"
        ]
    },
    {
        "id": "171",
        "title": "Augmenting Dialog with Think-Aloud Utterances for Modeling Individual Personality Traits by LLM",
        "author": [
            "Seiya Ishikura",
            "Hiroaki Yamada",
            "Tatsuya Hiraoka",
            "Hiroaki Yamada",
            "Takenobu Tokunaga"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09158",
        "abstract": "This study proposes augmenting dialog data with think-aloud utterances (TAUs) for modeling individual personalities in text chat by LLM. TAU is a verbalization of a speaker's thought before articulating the utterance. We expect \"persona LLMs\" trained with TAU-augmented data can mimic the speaker's personality trait better. We tested whether the trained persona LLMs obtain the human personality with respect to Big Five, a framework characterizing human personality traits from five aspects. The results showed that LLMs trained with TAU-augmented data more closely align to the speakers' Agreeableness and Neuroticism of Big Five than those trained with original dialog data. We also found that the quality of TAU-augmentation impacts persona LLM's performance.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "172",
        "title": "Efficient Resource-Constrained Training of Vision Transformers via Subspace Optimization",
        "author": [
            "Le-Trung Nguyen",
            "Enzo Tartaglione",
            "Van-Tam Nguyen"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09160",
        "abstract": "As AI increasingly shapes daily life, energy consumption and data privacy have become pressing concerns. On-device learning trains models directly on edge devices, cutting energy consumption and safeguarding data privacy. However, the expanding scale of modern neural networks creates a major obstacle for on-device training. Although prior work has concentrated on compact convolutional architectures, we instead apply subspace-based training to transformer models. Motivated by the idea that a model's essential information lies in a fixed subspace, we introduce Weight-Activation Subspace Iteration (WASI), a method that mitigates the memory bottleneck of backpropagation and boosts inference efficiency in transformer models by restricting training to this subspace. Our results demonstrate that WASI maintains accuracy comparable to vanilla training while reducing memory usage by up to $62\\times$ and computational cost (FLOPs) by up to $2\\times$. On a Raspberry Pi 5, WASI achieves roughly $1.5\\times$ faster training and inference than vanilla training.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "173",
        "title": "Robust Adaptive Boundary Control of a Thermal Process with Thermoelectric Actuators: Theory and Experimental Validation",
        "author": [
            "Paul Mayr",
            "Alessandro Pisano",
            "Stefan Koch",
            "Markus Reichhartinger"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09169",
        "abstract": "A sliding-mode-based adaptive boundary control law is proposed for a class of uncertain thermal reaction-diffusion processes subject to matched disturbances. The disturbances are assumed to be bounded, but the corresponding bounds are unknown, thus motivating the use of adaptive control strategies. A boundary control law comprising a proportional and discontinuous term is proposed, wherein the magnitude of the discontinuous relay term is adjusted via a gradient-based adaptation algorithm. Depending on how the adaptation algorithm is parameterized, the adaptive gain can be either a nondecreasing function of time (monodirectional adaptation) or it can both increase and decrease (bidirectional adaptation). The convergence and stability properties of these two solutions are investigated by Lyapunov analyses, and two distinct stability results are derived, namely, asymptotic stability for the monodirectional adaptation and globally uniformly ultimately bounded solutions for the bidirectional adaptation. The proposed algorithms are then specified to address the control problem of stabilizing a desired temperature profile in a metal beam equipped with thermoelectric boundary actuators. Experiments are conducted to investigate the real-world performance of the proposed sliding-mode-based adaptive control, with a particular focus on comparing the monodirectional and bidirectional adaptation laws.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "174",
        "title": "Online Video Depth Anything: Temporally-Consistent Depth Prediction with Low Memory Consumption",
        "author": [
            "Johann-Friedrich Feiden",
            "Tim KÃ¼chler",
            "Denis Zavadski",
            "Bogdan Savchynskyy",
            "Carsten Rother"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09182",
        "abstract": "Depth estimation from monocular video has become a key component of many real-world computer vision systems. Recently, Video Depth Anything (VDA) has demonstrated strong performance on long video sequences. However, it relies on batch-processing which prohibits its use in an online setting. In this work, we overcome this limitation and introduce online VDA (oVDA). The key innovation is to employ techniques from Large Language Models (LLMs), namely, caching latent features during inference and masking frames at training. Our oVDA method outperforms all competing online video depth estimation methods in both accuracy and VRAM usage. Low VRAM usage is particularly important for deployment on edge devices. We demonstrate that oVDA runs at 42 FPS on an NVIDIA A100 and at 20 FPS on an NVIDIA Jetson edge device. We will release both, code and compilation scripts, making oVDA easy to deploy on low-power hardware.",
        "tags": [
            "Depth Estimation",
            "LLM"
        ]
    },
    {
        "id": "175",
        "title": "Student Development Agent: Risk-free Simulation for Evaluating AIED Innovations",
        "author": [
            "Jianxiao Jiang",
            "Yu Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09183",
        "abstract": "In the age of AI-powered educational (AIED) innovation, evaluating the developmental consequences of novel designs before they are exposed to students has become both essential and challenging. Since such interventions may carry irreversible effects, it is critical to anticipate not only potential benefits but also possible harms. This study proposes a student development agent framework based on large language models (LLMs), designed to simulate how students with diverse characteristics may evolve under different educational settings without administering them to real students. By validating the approach through a case study on a multi-agent learning environment (MAIC), we demonstrate that the agent's predictions align with real student outcomes in non-cognitive developments. The results suggest that LLM-based simulations hold promise for evaluating AIED innovations efficiently and ethically. Future directions include enhancing profile structures, incorporating fine-tuned or small task-specific models, validating effects of empirical findings, interpreting simulated data and optimizing evaluation methods.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "176",
        "title": "Decentralized Multi-Robot Relative Navigation in Unknown, Structurally Constrained Environments under Limited Communication",
        "author": [
            "Zihao Mao",
            "Yunheng Wang",
            "Yunting Ji",
            "Yi Yang",
            "Wenjie Song"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09188",
        "abstract": "Multi-robot navigation in unknown, structurally constrained, and GPS-denied environments presents a fundamental trade-off between global strategic foresight and local tactical agility, particularly under limited communication. Centralized methods achieve global optimality but suffer from high communication overhead, while distributed methods are efficient but lack the broader awareness to avoid deadlocks and topological traps. To address this, we propose a fully decentralized, hierarchical relative navigation framework that achieves both strategic foresight and tactical agility without a unified coordinate system. At the strategic layer, robots build and exchange lightweight topological maps upon opportunistic encounters. This process fosters an emergent global awareness, enabling the planning of efficient, trap-avoiding routes at an abstract level. This high-level plan then inspires the tactical layer, which operates on local metric information. Here, a sampling-based escape point strategy resolves dense spatio-temporal conflicts by generating dynamically feasible trajectories in real time, concurrently satisfying tight environmental and kinodynamic constraints. Extensive simulations and real-world experiments demonstrate that our system significantly outperforms in success rate and efficiency, especially in communication-limited environments with complex topological structures.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "177",
        "title": "LLaMAX2: Your Translation-Enhanced Model also Performs Well in Reasoning",
        "author": [
            "Changjiang Gao",
            "Zixian Huang",
            "Jingyang Gong",
            "Shujian Huang",
            "Lei Li",
            "Fei Yuan"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09189",
        "abstract": "General Large Language Models (LLMs) excel in reasoning, but those enhanced for translation struggle with reasoning tasks. To address this, we propose a novel translationenhanced recipe that begins with instruct models and applies layer-selective tuning only on parallel data. Following this pipeline, we introduce the Qwen3-XPlus models, which demonstrate significant improvements in translation performance across both high- and lowresource languages, achieving 15+ spBLEU and 40+ xComet in low-resource languages, like Swahili. Interestingly, training only with small parallel datasets, Qwen3-XPlus achieves an average improvement of 1+ points on 7 multilingual tasks while maintaining proficiency comparable to the Qwen3 instruct model in 15 popular reasoning datasets. This work offers a promising approach to multilingual enhancement, significantly reducing complexity and enhancing accessibility for a wider range of languages. The code and model are publicly available.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "178",
        "title": "Towards Safer and Understandable Driver Intention Prediction",
        "author": [
            "Mukilan Karuppasamy",
            "Shankar Gangisetty",
            "Shyam Nandan Rai",
            "Carlo Masone",
            "C V Jawahar"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09200",
        "abstract": "Autonomous driving (AD) systems are becoming increasingly capable of handling complex tasks, mainly due to recent advances in deep learning and AI. As interactions between autonomous systems and humans increase, the interpretability of decision-making processes in driving systems becomes increasingly crucial for ensuring safe driving operations. Successful human-machine interaction requires understanding the underlying representations of the environment and the driving task, which remains a significant challenge in deep learning-based systems. To address this, we introduce the task of interpretability in maneuver prediction before they occur for driver safety, i.e., driver intent prediction (DIP), which plays a critical role in AD systems. To foster research in interpretable DIP, we curate the eXplainable Driving Action Anticipation Dataset (DAAD-X), a new multimodal, ego-centric video dataset to provide hierarchical, high-level textual explanations as causal reasoning for the driver's decisions. These explanations are derived from both the driver's eye-gaze and the ego-vehicle's perspective. Next, we propose Video Concept Bottleneck Model (VCBM), a framework that generates spatio-temporally coherent explanations inherently, without relying on post-hoc techniques. Finally, through extensive evaluations of the proposed VCBM on the DAAD-X dataset, we demonstrate that transformer-based models exhibit greater interpretability than conventional CNN-based models. Additionally, we introduce a multilabel t-SNE visualization technique to illustrate the disentanglement and causal correlation among multiple explanations. Our data, code and models are available at: https://mukil07.github.io/VCBM.github.io/",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "179",
        "title": "Cattle-CLIP: A Multimodal Framework for Cattle Behaviour Recognition",
        "author": [
            "Huimin Liu",
            "Jing Gao",
            "Daria Baran",
            "AxelX Montout",
            "Neill W Campbell",
            "Andrew W Dowsey"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09203",
        "abstract": "Cattle behaviour is a crucial indicator of an individual animal health, productivity and overall well-being. Video-based monitoring, combined with deep learning techniques, has become a mainstream approach in animal biometrics, and it can offer high accuracy in some behaviour recognition tasks. We present Cattle-CLIP, a multimodal deep learning framework for cattle behaviour recognition, using semantic cues to improve the performance of video-based visual feature recognition. It is adapted from the large-scale image-language model CLIP by adding a temporal integration module. To address the domain gap between web data used for the pre-trained model and real-world cattle surveillance footage, we introduce tailored data augmentation strategies and specialised text prompts. Cattle-CLIP is evaluated under both fully-supervised and few-shot learning scenarios, with a particular focus on data-scarce behaviour recognition - an important yet under-explored goal in livestock monitoring. To evaluate the proposed method, we release the CattleBehaviours6 dataset, which comprises six types of indoor behaviours: feeding, drinking, standing-self-grooming, standing-ruminating, lying-self-grooming and lying-ruminating. The dataset consists of 1905 clips collected from our John Oldacre Centre dairy farm research platform housing 200 Holstein-Friesian cows. Experiments show that Cattle-CLIP achieves 96.1% overall accuracy across six behaviours in a supervised setting, with nearly 100% recall for feeding, drinking and standing-ruminating behaviours, and demonstrates robust generalisation with limited data in few-shot scenarios, highlighting the potential of multimodal learning in agricultural and animal behaviour analysis.",
        "tags": [
            "CLIP"
        ]
    },
    {
        "id": "180",
        "title": "Flow-Opt: Scalable Centralized Multi-Robot Trajectory Optimization with Flow Matching and Differentiable Optimization",
        "author": [
            "Simon Idoko",
            "Arun Kumar Singh"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09204",
        "abstract": "Centralized trajectory optimization in the joint space of multiple robots allows access to a larger feasible space that can result in smoother trajectories, especially while planning in tight spaces. Unfortunately, it is often computationally intractable beyond a very small swarm size. In this paper, we propose Flow-Opt, a learning-based approach towards improving the computational tractability of centralized multi-robot trajectory optimization. Specifically, we reduce the problem to first learning a generative model to sample different candidate trajectories and then using a learned Safety-Filter(SF) to ensure fast inference-time constraint satisfaction. We propose a flow-matching model with a diffusion transformer (DiT) augmented with permutation invariant robot position and map encoders as the generative model. We develop a custom solver for our SF and equip it with a neural network that predicts context-specific initialization. The initialization network is trained in a self-supervised manner, taking advantage of the differentiability of the SF solver. We advance the state-of-the-art in the following respects. First, we show that we can generate trajectories of tens of robots in cluttered environments in a few tens of milliseconds. This is several times faster than existing centralized optimization approaches. Moreover, our approach also generates smoother trajectories orders of magnitude faster than competing baselines based on diffusion models. Second, each component of our approach can be batched, allowing us to solve a few tens of problem instances in a fraction of a second. We believe this is a first such result; no existing approach provides such capabilities. Finally, our approach can generate a diverse set of trajectories between a given set of start and goal locations, which can capture different collision-avoidance behaviors.",
        "tags": [
            "DiT",
            "Diffusion",
            "Flow Matching",
            "Robotics",
            "Transformer"
        ]
    },
    {
        "id": "181",
        "title": "3D Reconstruction from Transient Measurements with Time-Resolved Transformer",
        "author": [
            "Yue Li",
            "Shida Sun",
            "Yu Hong",
            "Feihu Xu",
            "Zhiwei Xiong"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09205",
        "abstract": "Transient measurements, captured by the timeresolved systems, are widely employed in photon-efficient reconstruction tasks, including line-of-sight (LOS) and non-line-of-sight (NLOS) imaging. However, challenges persist in their 3D reconstruction due to the low quantum efficiency of sensors and the high noise levels, particularly for long-range or complex scenes. To boost the 3D reconstruction performance in photon-efficient imaging, we propose a generic Time-Resolved Transformer (TRT) architecture. Different from existing transformers designed for high-dimensional data, TRT has two elaborate attention designs tailored for the spatio-temporal transient measurements. Specifically, the spatio-temporal self-attention encoders explore both local and global correlations within transient data by splitting or downsampling input features into different scales. Then, the spatio-temporal cross attention decoders integrate the local and global features in the token space, resulting in deep features with high representation capabilities. Building on TRT, we develop two task-specific embodiments: TRT-LOS for LOS imaging and TRT-NLOS for NLOS imaging. Extensive experiments demonstrate that both embodiments significantly outperform existing methods on synthetic data and real-world data captured by different imaging systems. In addition, we contribute a large-scale, high-resolution synthetic LOS dataset with various noise levels and capture a set of real-world NLOS measurements using a custom-built imaging system, enhancing the data diversity in this field. Code and datasets are available at https://github.com/Depth2World/TRT.",
        "tags": [
            "3D",
            "Transformer"
        ]
    },
    {
        "id": "182",
        "title": "DICE: Structured Reasoning in LLMs through SLM-Guided Chain-of-Thought Correction",
        "author": [
            "Yiqi Li",
            "Yusheng Liao",
            "Zhe Chen",
            "Yanfeng Wang",
            "Yu Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09211",
        "abstract": "When performing reasoning tasks with user-specific requirements, such as strict output formats, large language models (LLMs) often prioritize reasoning over adherence to detailed instructions. Fine-tuning LLMs on supervised datasets to address this is impractical due to high computational costs and limited parameter access. To tackle this, we propose DICE, a lightweight framework that guides small language models (SLMs) to refine LLMs' outputs through chain-of-thought (CoT) correction. DICE decouples the process by first prompting LLMs to generate natural language responses, then using trained SLMs to analyze and refine these outputs to meet structured output specifications. This framework preserves LLMs' broad knowledge and reasoning capabilities while ensuring the outputs conform to user demands. Specifically, DICE first constructs structured CoT adaptation datasets via a two-stage method and subsequently applies a dual-tuning strategy to fine-tune SLMs for generating structured outputs in an analyze-then-answer pattern. Experiments demonstrate that DICE improves the average format accuracy and content correctness of LLM outputs by 35.4\\% and 29.4\\%, respectively, achieving state-of-the-art (SOTA) performance over other competitive baselines.",
        "tags": [
            "CoT",
            "LLM"
        ]
    },
    {
        "id": "183",
        "title": "Stable Video Infinity: Infinite-Length Video Generation with Error Recycling",
        "author": [
            "Wuyang Li",
            "Wentao Pan",
            "Po-Chien Luan",
            "Yang Gao",
            "Alexandre Alahi"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09212",
        "abstract": "We propose Stable Video Infinity (SVI) that is able to generate infinite-length videos with high temporal consistency, plausible scene transitions, and controllable streaming storylines. While existing long-video methods attempt to mitigate accumulated errors via handcrafted anti-drifting (e.g., modified noise scheduler, frame anchoring), they remain limited to single-prompt extrapolation, producing homogeneous scenes with repetitive motions. We identify that the fundamental challenge extends beyond error accumulation to a critical discrepancy between the training assumption (seeing clean data) and the test-time autoregressive reality (conditioning on self-generated, error-prone outputs). To bridge this hypothesis gap, SVI incorporates Error-Recycling Fine-Tuning, a new type of efficient training that recycles the Diffusion Transformer (DiT)'s self-generated errors into supervisory prompts, thereby encouraging DiT to actively identify and correct its own errors. This is achieved by injecting, collecting, and banking errors through closed-loop recycling, autoregressively learning from error-injected feedback. Specifically, we (i) inject historical errors made by DiT to intervene on clean inputs, simulating error-accumulated trajectories in flow matching; (ii) efficiently approximate predictions with one-step bidirectional integration and calculate errors with residuals; (iii) dynamically bank errors into replay memory across discretized timesteps, which are resampled for new input. SVI is able to scale videos from seconds to infinite durations with no additional inference cost, while remaining compatible with diverse conditions (e.g., audio, skeleton, and text streams). We evaluate SVI on three benchmarks, including consistent, creative, and conditional settings, thoroughly verifying its versatility and state-of-the-art role.",
        "tags": [
            "DiT",
            "Diffusion",
            "Flow Matching",
            "Transformer",
            "Video Generation"
        ]
    },
    {
        "id": "184",
        "title": "HANDO: Hierarchical Autonomous Navigation and Dexterous Omni-loco-manipulation",
        "author": [
            "Jingyuan Sun",
            "Chaoran Wang",
            "Mingyu Zhang",
            "Cui Miao",
            "Hongyu Ji",
            "Zihan Qu",
            "Han Sun",
            "Bing Wang",
            "Qingyi Si"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09221",
        "abstract": "Seamless loco-manipulation in unstructured environments requires robots to leverage autonomous exploration alongside whole-body control for physical interaction. In this work, we introduce HANDO (Hierarchical Autonomous Navigation and Dexterous Omni-loco-manipulation), a two-layer framework designed for legged robots equipped with manipulators to perform human-centered mobile manipulation tasks. The first layer utilizes a goal-conditioned autonomous exploration policy to guide the robot to semantically specified targets, such as a black office chair in a dynamic environment. The second layer employs a unified whole-body loco-manipulation policy to coordinate the arm and legs for precise interaction tasks-for example, handing a drink to a person seated on the chair. We have conducted an initial deployment of the navigation module, and will continue to pursue finer-grained deployment of whole-body loco-manipulation.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "185",
        "title": "FM-IRL: Flow-Matching for Reward Modeling and Policy Regularization in Reinforcement Learning",
        "author": [
            "Zhenglin Wan",
            "Jingxuan Wu",
            "Xingrui Yu",
            "Chubin Zhang",
            "Mingcong Lei",
            "Bo An",
            "Ivor Tsang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09222",
        "abstract": "Flow Matching (FM) has shown remarkable ability in modeling complex distributions and achieves strong performance in offline imitation learning for cloning expert behaviors. However, despite its behavioral cloning expressiveness, FM-based policies are inherently limited by their lack of environmental interaction and exploration. This leads to poor generalization in unseen scenarios beyond the expert demonstrations, underscoring the necessity of online interaction with environment. Unfortunately, optimizing FM policies via online interaction is challenging and inefficient due to instability in gradient computation and high inference costs. To address these issues, we propose to let a student policy with simple MLP structure explore the environment and be online updated via RL algorithm with a reward model. This reward model is associated with a teacher FM model, containing rich information of expert data distribution. Furthermore, the same teacher FM model is utilized to regularize the student policy's behavior to stabilize policy learning. Due to the student's simple architecture, we avoid the gradient instability of FM policies and enable efficient online exploration, while still leveraging the expressiveness of the teacher FM model. Extensive experiments show that our approach significantly enhances learning efficiency, generalization, and robustness, especially when learning from suboptimal expert data.",
        "tags": [
            "Flow Matching",
            "RL"
        ]
    },
    {
        "id": "186",
        "title": "RegexPSPACE: A Benchmark for Evaluating LLM Reasoning on PSPACE-complete Regex Problems",
        "author": [
            "Hyundong Jin",
            "Joonghyuk Hahn",
            "Yo-Sub Han"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09227",
        "abstract": "Large language models (LLMs) show strong performance across natural language processing (NLP), mathematical reasoning, and programming, and recent large reasoning models (LRMs) further emphasize explicit reasoning. Yet their computational limits, particularly spatial complexity constrained by finite context windows, remain poorly understood. While recent works often focus on problems within the NP complexity class, we push the boundary by introducing a novel benchmark grounded in two PSPACE-complete regular expression (regex) problems: equivalence decision (RegexEQ) and minimization (RegexMin). PSPACE-complete problems serve as a more rigorous standard for assessing computational capacity, as their solutions require massive search space exploration. We perform a double-exponential space exploration to construct a labeled dataset of over a million regex instances with a sound filtering process to build the benchmark. We conduct extensive evaluations on 6 LLMs and 5 LRMs of varying scales, revealing common failure patterns such as verbosity and repetition. With its well-defined structure and quantitative evaluation metrics, this work presents the first empirical investigation into the spatial computational limitations of LLMs and LRMs, offering a new framework for evaluating their advanced reasoning capabilities. Our code is available at https://github.com/hyundong98/RegexPSPACE .",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "187",
        "title": "Clear Roads, Clear Vision: Advancements in Multi-Weather Restoration for Smart Transportation",
        "author": [
            "Vijay M. Galshetwar",
            "Praful Hambarde",
            "Prashant W. Patil",
            "Akshay Dudhane",
            "Sachin Chaudhary",
            "Santosh Kumar Vipparathi",
            "Subrahmanyam Murala"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09228",
        "abstract": "Adverse weather conditions such as haze, rain, and snow significantly degrade the quality of images and videos, posing serious challenges to intelligent transportation systems (ITS) that rely on visual input. These degradations affect critical applications including autonomous driving, traffic monitoring, and surveillance. This survey presents a comprehensive review of image and video restoration techniques developed to mitigate weather-induced visual impairments. We categorize existing approaches into traditional prior-based methods and modern data-driven models, including CNNs, transformers, diffusion models, and emerging vision-language models (VLMs). Restoration strategies are further classified based on their scope: single-task models, multi-task/multi-weather systems, and all-in-one frameworks capable of handling diverse degradations. In addition, we discuss day and night time restoration challenges, benchmark datasets, and evaluation protocols. The survey concludes with an in-depth discussion on limitations in current research and outlines future directions such as mixed/compound-degradation restoration, real-time deployment, and agentic AI frameworks. This work aims to serve as a valuable reference for advancing weather-resilient vision systems in smart transportation environments. Lastly, to stay current with rapid advancements in this field, we will maintain regular updates of the latest relevant papers and their open-source implementations at https://github.com/ChaudharyUPES/A-comprehensive-review-on-Multi-weather-restoration",
        "tags": [
            "Diffusion",
            "VLM"
        ]
    },
    {
        "id": "188",
        "title": "CrisiText: A dataset of warning messages for LLM training in emergency communication",
        "author": [
            "Giacomo Gonella",
            "Gian Maria Campedelli",
            "Stefano Menini",
            "Marco Guerini"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09243",
        "abstract": "Effectively identifying threats and mitigating their potential damage during crisis situations, such as natural disasters or violent attacks, is paramount for safeguarding endangered individuals. To tackle these challenges, AI has been used in assisting humans in emergency situations. Still, the use of NLP techniques remains limited and mostly focuses on classification tasks. The significant potential of timely warning message generation using NLG architectures, however, has been largely overlooked. In this paper we present CrisiText, the first large-scale dataset for the generation of warning messages across 13 different types of crisis scenarios. The dataset contains more than 400,000 warning messages (spanning almost 18,000 crisis situations) aimed at assisting civilians during and after such events. To generate the dataset, we started from existing crisis descriptions and created chains of events related to the scenarios. Each event was then paired with a warning message. The generations follow experts' written guidelines to ensure correct terminology and factuality of their suggestions. Additionally, each message is accompanied by three suboptimal warning types to allow for the study of different NLG approaches. To this end, we conducted a series of experiments comparing supervised fine-tuning setups with preference alignment, zero-shot, and few-shot approaches. We further assessed model performance in out-of-distribution scenarios and evaluated the effectiveness of an automatic post-editor.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "189",
        "title": "Fundamentals of Building Autonomous LLM Agents",
        "author": [
            "Victor de Lamo Castrillo",
            "Habtom Kahsay Gidey",
            "Alexander Lenz",
            "Alois Knoll"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09244",
        "abstract": "This paper reviews the architecture and implementation methods of agents powered by large language models (LLMs). Motivated by the limitations of traditional LLMs in real-world tasks, the research aims to explore patterns to develop \"agentic\" LLMs that can automate complex tasks and bridge the performance gap with human capabilities. Key components include a perception system that converts environmental percepts into meaningful representations; a reasoning system that formulates plans, adapts to feedback, and evaluates actions through different techniques like Chain-of-Thought and Tree-of-Thought; a memory system that retains knowledge through both short-term and long-term mechanisms; and an execution system that translates internal decisions into concrete actions. This paper shows how integrating these systems leads to more capable and generalized software bots that mimic human cognitive processes for autonomous and intelligent behavior.",
        "tags": [
            "CoT",
            "LLM"
        ]
    },
    {
        "id": "190",
        "title": "Zero-shot image privacy classification with Vision-Language Models",
        "author": [
            "Alina Elena Baia",
            "Alessio Xompero",
            "Andrea Cavallaro"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09253",
        "abstract": "While specialized learning-based models have historically dominated image privacy prediction, the current literature increasingly favours adopting large Vision-Language Models (VLMs) designed for generic tasks. This trend risks overlooking the performance ceiling set by purpose-built models due to a lack of systematic evaluation. To address this problem, we establish a zero-shot benchmark for image privacy classification, enabling a fair comparison. We evaluate the top-3 open-source VLMs, according to a privacy benchmark, using task-aligned prompts and we contrast their performance, efficiency, and robustness against established vision-only and multi-modal methods. Counter-intuitively, our results show that VLMs, despite their resource-intensive nature in terms of high parameter count and slower inference, currently lag behind specialized, smaller models in privacy prediction accuracy. We also find that VLMs exhibit higher robustness to image perturbations.",
        "tags": [
            "VLM"
        ]
    },
    {
        "id": "191",
        "title": "Obstacle Avoidance using Dynamic Movement Primitives and Reinforcement Learning",
        "author": [
            "Dominik Urbaniak",
            "Alejandro Agostini",
            "Pol Ramon",
            "Jan Rosell",
            "RaÃºl SuÃ¡rez",
            "Michael Suppa"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09254",
        "abstract": "Learning-based motion planning can quickly generate near-optimal trajectories. However, it often requires either large training datasets or costly collection of human demonstrations. This work proposes an alternative approach that quickly generates smooth, near-optimal collision-free 3D Cartesian trajectories from a single artificial demonstration. The demonstration is encoded as a Dynamic Movement Primitive (DMP) and iteratively reshaped using policy-based reinforcement learning to create a diverse trajectory dataset for varying obstacle configurations. This dataset is used to train a neural network that takes as inputs the task parameters describing the obstacle dimensions and location, derived automatically from a point cloud, and outputs the DMP parameters that generate the trajectory. The approach is validated in simulation and real-robot experiments, outperforming a RRT-Connect baseline in terms of computation and execution time, as well as trajectory length, while supporting multi-modal trajectory generation for different obstacle geometries and end-effector dimensions. Videos and the implementation code are available at https://github.com/DominikUrbaniak/obst-avoid-dmp-pi2.",
        "tags": [
            "3D",
            "RL",
            "Robotics"
        ]
    },
    {
        "id": "192",
        "title": "DSPO: Stable and Efficient Policy Optimization for Agentic Search and Reasoning",
        "author": [
            "Chenyang Gu",
            "Yewen Pu",
            "Bruce Yang",
            "Xiaofan Li",
            "Huan Gao"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09255",
        "abstract": "Enhancing LLMs with the ability to actively search external knowledge is crucial for complex and real-world tasks. Current approaches either rely on prompting to elicit the model's innate agent capabilities, or suffer from performance ceilings and collapse when applying RL to complex interactive tasks, leaving their true agentic potential untapped. To address this, we introduce \\textbf{D}ynamic-filter \\textbf{S}equence-level \\textbf{P}olicy \\textbf{O}ptimization (DSPO), an improved RL algorithm designed for robust agent training through sequence-level optimization and dynamic sample filtering. We train our model purely through RL to interleave multi-turn search and reasoning, obviating the need for supervised demonstration data. Across multiple QA benchmarks, our DSPO-trained 7B model improves over a comparable previous work by \\textbf{34.1\\%}, and even outperforms the 14B model from previous work in complex multihop QA such as HotpotQA by nearly \\textbf{9\\% relative}, maintaining exceptional training stability.",
        "tags": [
            "LLM",
            "RL"
        ]
    },
    {
        "id": "193",
        "title": "Detecting Data Contamination from Reinforcement Learning Post-training for Large Language Models",
        "author": [
            "Yongding Tao",
            "Tian Wang",
            "Yihong Dong",
            "Huanyu Liu",
            "Kechi Zhang",
            "Xiaolong Hu",
            "Ge Li"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09259",
        "abstract": "Data contamination poses a significant threat to the reliable evaluation of Large Language Models (LLMs). This issue arises when benchmark samples may inadvertently appear in training sets, compromising the validity of reported performance. While detection methods have been developed for the pre-training and Supervised Fine-Tuning stages, a critical research gap exists for the increasingly significant phase of Reinforcement Learning (RL) post-training. As RL post-training becomes pivotal for advancing LLM reasoning, the absence of specialized contamination detection methods in this paradigm presents a critical vulnerability. To address this, we conduct the first systematic study of data detection within RL post-training scenario and propose Self-Critique. Our method is motivated by a key observation: after RL phase, the output entropy distribution of LLMs tends to collapse into highly specific and sparse modes. Self-Critique probes for the underlying policy collapse, i.e., the model's convergence to a narrow reasoning path, which causes this entropy reduction. To facilitate this research, we also introduce RL-MIA, a benchmark constructed to simulate this specific contamination scenario. Extensive experiments show that Self-Critique significantly outperforms baseline methods across multiple models and contamination tasks, achieving an AUC improvement of up to 30%. Whereas existing methods are close to a random guess for RL-phase contamination, our method makes detection possible.",
        "tags": [
            "Detection",
            "LLM",
            "RL"
        ]
    },
    {
        "id": "194",
        "title": "CFVBench: A Comprehensive Video Benchmark for Fine-grained Multimodal Retrieval-Augmented Generation",
        "author": [
            "Kaiwen Wei",
            "Xiao Liu",
            "Jie Zhang",
            "Zijian Wang",
            "Ruida Liu",
            "Yuming Yang",
            "Xin Xiao",
            "Xiao Sun",
            "Haoyang Zeng",
            "Changzai Pan",
            "Yidan Zhang",
            "Jiang Zhong",
            "Peijin Wang",
            "Yingchao Feng"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09266",
        "abstract": "Multimodal Retrieval-Augmented Generation (MRAG) enables Multimodal Large Language Models (MLLMs) to generate responses with external multimodal evidence, and numerous video-based MRAG benchmarks have been proposed to evaluate model capabilities across retrieval and generation stages. However, existing benchmarks remain limited in modality coverage and format diversity, often focusing on single- or limited-modality tasks, or coarse-grained scene understanding. To address these gaps, we introduce CFVBench, a large-scale, manually verified benchmark constructed from 599 publicly available videos, yielding 5,360 open-ended QA pairs. CFVBench spans high-density formats and domains such as chart-heavy reports, news broadcasts, and software tutorials, requiring models to retrieve and reason over long temporal video spans while maintaining fine-grained multimodal information. Using CFVBench, we systematically evaluate 7 retrieval methods and 14 widely-used MLLMs, revealing a critical bottleneck: current models (even GPT5 or Gemini) struggle to capture transient yet essential fine-grained multimodal details. To mitigate this, we propose Adaptive Visual Refinement (AVR), a simple yet effective framework that adaptively increases frame sampling density and selectively invokes external tools when necessary. Experiments show that AVR consistently enhances fine-grained multimodal comprehension and improves performance across all evaluated MLLMs",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "195",
        "title": "Placeit! A Framework for Learning Robot Object Placement Skills",
        "author": [
            "Amina Ferrad",
            "Johann Huber",
            "FranÃ§ois HÃ©lÃ©non",
            "Julien Gleyze",
            "Mahdi Khoramshahi",
            "StÃ©phane Doncieux"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09267",
        "abstract": "Robotics research has made significant strides in learning, yet mastering basic skills like object placement remains a fundamental challenge. A key bottleneck is the acquisition of large-scale, high-quality data, which is often a manual and laborious process. Inspired by Graspit!, a foundational work that used simulation to automatically generate dexterous grasp poses, we introduce Placeit!, an evolutionary-computation framework for generating valid placement positions for rigid objects. Placeit! is highly versatile, supporting tasks from placing objects on tables to stacking and inserting them. Our experiments show that by leveraging quality-diversity optimization, Placeit! significantly outperforms state-of-the-art methods across all scenarios for generating diverse valid poses. A pick&place pipeline built on our framework achieved a 90% success rate over 120 real-world deployments. This work positions Placeit! as a powerful tool for open-environment pick-and-place tasks and as a valuable engine for generating the data needed to train simulation-based foundation models in robotics.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "196",
        "title": "MomentSeg: Moment-Centric Sampling for Enhanced Video Pixel Understanding",
        "author": [
            "Ming Dai",
            "Sen Yang",
            "Boqiang Duan",
            "Wankou Yang",
            "Jingdong Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09274",
        "abstract": "Referring Video Object Segmentation (RefVOS) seeks to segment target objects in videos guided by natural language descriptions, demanding both temporal reasoning and fine-grained visual comprehension. Existing sampling strategies for LLM-based approaches typically rely on either handcrafted heuristics or external keyframe models. The former often overlooks essential temporal cues, while the latter increases system complexity. To address this, we propose a unified framework that jointly optimizes Temporal Sentence Grounding (TSG) and RefVOS, naturally incorporating key moment grounding capability. During training, we introduce a novel TSG paradigm that employs a dedicated \\texttt{[FIND]} token for key moment identification through temporal token similarity matching, thereby avoiding the need for external timestamp encodings. For inference, we design a Moment-Centric Sampling (MCS) strategy that densely samples informative moments while sparsely sampling non-essential frames, preserving both motion details and global context. To further enhance tracking stability, we develop Bidirectional Anchor-updated Propagation (BAP), which leverages the most relevant moment as start point for high-quality mask initialization and dynamically updates at sampled points to mitigate accumulated errors. Code and model will be available at: https://github.com/Dmmm1997/MomentSeg",
        "tags": [
            "LLM",
            "Segmentation"
        ]
    },
    {
        "id": "197",
        "title": "CLARity: Reasoning Consistency Alone Can Teach Reinforced Experts",
        "author": [
            "Jiuheng Lin",
            "Cong Jiang",
            "Zirui Wu",
            "Jiarui Sun",
            "Yansong Feng"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09278",
        "abstract": "Training expert LLMs in domains with scarce data is difficult, often relying on multiple-choice questions (MCQs). However, standard outcome-based reinforcement learning (RL) on MCQs is risky. While it may improve accuracy, we observe it often degrades reasoning quality such as logical consistency. Existing solutions to supervise reasoning, such as large-scale Process Reward Models (PRMs), are prohibitively expensive. To address this, we propose CLARity, a cost-effective RL framework that enhances reasoning quality using only a small, general-purpose LLM. CLARity integrates a consistency-aware reward mechanism with a 2-stage refine-then-monitor training pipeline to enhance reasoning consistency, and a dynamic data reformulation strategy to to better exploit limited data. Experiments demonstrate that CLARity improves response consistency by 16.5% and accuracy by 7.5% over baselines. Human evaluations further confirm holistic improvements in coherence and professionalism. Thus, CLARity offers a generalizable solution that enables smaller models to effectively guide expert models by reasoning http://consistency.Our code is open sourced at: https://github.com/Infinite-set/CLARity",
        "tags": [
            "LLM",
            "RL"
        ]
    },
    {
        "id": "198",
        "title": "Spotlight on Token Perception for Multimodal Reinforcement Learning",
        "author": [
            "Siyuan Huang",
            "Xiaoye Qu",
            "Yafu Li",
            "Yun Luo",
            "Zefeng He",
            "Daizong Liu",
            "Yu Cheng"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09285",
        "abstract": "While Reinforcement Learning with Verifiable Rewards (RLVR) has advanced the reasoning capabilities of Large Vision-Language Models (LVLMs), most existing methods in multimodal reasoning neglect the critical role of visual perception within the RLVR optimization process. In this paper, we undertake a pioneering exploration of multimodal RLVR through the novel perspective of token perception, which measures the visual dependency of each generated token. With a granular analysis of Chain-of-Thought (CoT) processes, we uncover two key insights: first, token perception in a rollout trajectory is sparsely distributed, where only a small fraction of tokens have high visual dependency for visually-grounded reasoning; second, different trajectories exhibit significant divergence in their overall visual dependency. Based on these observations, we propose Visually-Perceptive Policy Optimization (VPPO), a novel policy gradient algorithm that explicitly leverages token perception to refine the learning signal. Specifically, VPPO achieves this through a dual mechanism: it reweights a trajectory's advantage by its overall visual dependency, and focuses policy updates exclusively on perceptually pivotal tokens. On a comprehensive suite of eight perception and reasoning benchmarks, VPPO demonstrates substantial gains over leading open-source RL-tuned models, with its effectiveness consistently validated across 7B and 32B model scales. Our findings not only establish a new token-level perceptual perspective for analyzing multimodal RLVR but also present a novel and effective optimization strategy to significantly enhance the multimodal reasoning capabilities of LVLMs.",
        "tags": [
            "CoT",
            "RL",
            "VLM"
        ]
    },
    {
        "id": "199",
        "title": "MaP: A Unified Framework for Reliable Evaluation of Pre-training Dynamics",
        "author": [
            "Jiapeng Wang",
            "Changxin Tian",
            "Kunlong Chen",
            "Ziqi Liu",
            "Jiaxin Mao",
            "Wayne Xin Zhao",
            "Zhiqiang Zhang",
            "Jun Zhou"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09295",
        "abstract": "Reliable evaluation is fundamental to the progress of Large Language Models (LLMs), yet the evaluation process during pre-training is plagued by significant instability that obscures true learning dynamics. In this work, we systematically diagnose this instability, attributing it to two distinct sources: \\textit{Parameter Instability} from training stochasticity and \\textit{Evaluation Instability} from noisy measurement protocols. To counteract both sources of noise, we introduce \\textbf{MaP}, a dual-pronged framework that synergistically integrates checkpoint \\underline{M}erging \\underline{a}nd the \\underline{P}ass@k metric. Checkpoint merging smooths the parameter space by averaging recent model weights, while Pass@k provides a robust, low-variance statistical estimate of model capability. Extensive experiments show that MaP yields significantly smoother performance curves, reduces inter-run variance, and ensures more consistent model rankings. Ultimately, MaP provides a more reliable and faithful lens for observing LLM training dynamics, laying a crucial empirical foundation for LLM research.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "200",
        "title": "ShiZhi: A Chinese Lightweight Large Language Model for Court View Generation",
        "author": [
            "Zhitian Hou",
            "Kun Zeng"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09297",
        "abstract": "Criminal Court View Generation (CVG) is a fundamental task in legal artificial intelligence, aiming to automatically generate the \"Court View\" section of a legal case document. Generating court views is challenging due to the diversity and complexity of case facts, and directly generating from raw facts may limit performance. In this paper, we present ShiZhi, the first large language model (LLM) specifically designed for court view generation. We construct a Chinese Court View Generation dataset, CCVG, of more than 110K cases, each containing fact descriptions paired with corresponding court views. Based on this dataset, ShiZhi achieving 58.5 BLEU-1 on court view generation and 86.1\\% accuracy with 92.5\\% macro F1 on charge prediction. Experimental results demonstrate that even a small LLM can generate reasonable and legally coherent court views when trained on high-quality domain-specific data. Our model and dataset are available at \\href{https://github.com/ZhitianHou/ShiZhi}{https://github.com/ZhitianHou/ShiZhi}.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "201",
        "title": "CapGeo: A Caption-Assisted Approach to Geometric Reasoning",
        "author": [
            "Yuying Li",
            "Siyi Qian",
            "Hao Liang",
            "Leqi Zheng",
            "Ruichuan An",
            "Yongzhen Guo",
            "Wentao Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09302",
        "abstract": "Geometric reasoning remains a core challenge for Multimodal Large Language Models (MLLMs). Even the most advanced closed-source systems, such as GPT-O3 and Gemini-2.5-Pro, still struggle to solve geometry problems reliably, despite exhibiting strong textual reasoning abilities on tasks like the International Mathematical Olympiad (IMO). This gap suggests that the bottleneck lies in understanding geometric diagrams rather than reasoning itself. Since geometric figures can often be faithfully described in concise textual form, converting visual content into captions offers a promising direction. Motivated by this insight, we introduce CapGeo, a caption-assisted reasoning framework that bridges visual and textual modalities. Experiments show substantial improvements when models are equipped with captions: Qwen2.5-VL-72B improves from 8.6% (vision-only) to 59.0%, while Claude-Opus-4 rises from 44.8% to 73.0%. To systematically evaluate and identify high-quality geometric captioning models, we further propose CapGeo-Bench, a dataset of 4,641 curated figure-caption pairs. Crucially, CapGeo-Bench incorporates a keypoint-based evaluation metric that correlates strongly with downstream CapGeo performance, enabling reliable assessment of geometric captioning ability. Together, our framework and benchmark highlight a new pathway toward advancing geometric reasoning in MLLMs.",
        "tags": [
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "202",
        "title": "Mask Tokens as Prophet: Fine-Grained Cache Eviction for Efficient dLLM Inference",
        "author": [
            "Jianuo Huang",
            "Yaojie Zhang",
            "Yicun Yang",
            "Benhao Huang",
            "Biqing Qi",
            "Dongrui Liu",
            "Linfeng Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09309",
        "abstract": "Diffusion large language models (dLLMs) present a promising alternative to dominant autoregressive models (ARMs) by the ability of parallel decoding at the expense of substantial computation and memory costs. Specifically, the cache mechanism for bidirectional attention in dLLMs demands large memory footprint, restricting their ability to handle long contexts under resource-limited settings. Existing cache eviction strategies are designed for ARMs and ignore the unique characteristics of dLLMs, thus leading to unsatisfactory performance. To address these challenges, we introduce MaskKV, a training-free cache eviction framework tailored to dLLMs, focusing on the effect of mask tokens in dLLMs. MaskKV is built on two key innovations: (1) a mask-query guided scoring mechanism that leverages attention weights to identify and evict less critical prompt tokens for each head; (2) an adaptive cache budgeting strategy that improves efficiency by reducing allocation in intermediate layers and concentrating resources on prompt-preferring heads. On LLaDA with MaskKV, compressing the KV cache to only 256 pairs (less than 5% of tokens) retains 94% of the full-cache performance on LongBench and achieves up to 31x acceleration at 32k prompt length. The code is publicly available at: https://github.com/jianuo-huang/MaskKV",
        "tags": [
            "Diffusion",
            "LLM"
        ]
    },
    {
        "id": "203",
        "title": "Verifying Chain-of-Thought Reasoning via Its Computational Graph",
        "author": [
            "Zheng Zhao",
            "Yeskendir Koishekenov",
            "Xianjun Yang",
            "Naila Murray",
            "Nicola Cancedda"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09312",
        "abstract": "Current Chain-of-Thought (CoT) verification methods predict reasoning correctness based on outputs (black-box) or activations (gray-box), but offer limited insight into why a computation fails. We introduce a white-box method: Circuit-based Reasoning Verification (CRV). We hypothesize that attribution graphs of correct CoT steps, viewed as execution traces of the model's latent reasoning circuits, possess distinct structural fingerprints from those of incorrect steps. By training a classifier on structural features of these graphs, we show that these traces contain a powerful signal of reasoning errors. Our white-box approach yields novel scientific insights unattainable by other methods. (1) We demonstrate that structural signatures of error are highly predictive, establishing the viability of verifying reasoning directly via its computational graph. (2) We find these signatures to be highly domain-specific, revealing that failures in different reasoning tasks manifest as distinct computational patterns. (3) We provide evidence that these signatures are not merely correlational; by using our analysis to guide targeted interventions on individual transcoder features, we successfully correct the model's faulty reasoning. Our work shows that, by scrutinizing a model's computational process, we can move from simple error detection to a deeper, causal understanding of LLM reasoning.",
        "tags": [
            "CoT",
            "Detection",
            "LLM"
        ]
    },
    {
        "id": "204",
        "title": "RadioFlow: Efficient Radio Map Construction Framework with Flow Matching",
        "author": [
            "Haozhe Jia",
            "Wenshuo Chen",
            "Xiucheng Wang",
            "Nan Cheng",
            "Hongbo Zhang",
            "Kuimou Yu",
            "Songning Lai",
            "Nanjian Jia",
            "Bowen Tian",
            "Hongru Xiao",
            "Yutao Yue"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09314",
        "abstract": "Accurate and real-time radio map (RM) generation is crucial for next-generation wireless systems, yet diffusion-based approaches often suffer from large model sizes, slow iterative denoising, and high inference latency, which hinder practical deployment. To overcome these limitations, we propose \\textbf{RadioFlow}, a novel flow-matching-based generative framework that achieves high-fidelity RM generation through single-step efficient sampling. Unlike conventional diffusion models, RadioFlow learns continuous transport trajectories between noise and data, enabling both training and inference to be significantly accelerated while preserving reconstruction accuracy. Comprehensive experiments demonstrate that RadioFlow achieves state-of-the-art performance with \\textbf{up to 8$\\times$ fewer parameters} and \\textbf{over 4$\\times$ faster inference} compared to the leading diffusion-based baseline (RadioDiff). This advancement provides a promising pathway toward scalable, energy-efficient, and real-time electromagnetic digital twins for future 6G networks. We release the code at \\href{https://github.com/Hxxxz0/RadioFlow}{GitHub}.",
        "tags": [
            "Diffusion",
            "Flow Matching"
        ]
    },
    {
        "id": "205",
        "title": "Large Language Model Prompt Datasets: An In-depth Analysis and Insights",
        "author": [
            "Yuanming Zhang",
            "Yan Lin",
            "Arijit Khan",
            "Huaiyu Wan"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09316",
        "abstract": "A prompt is a natural language instruction that defines a specific task for a large language model (LLM) and serves as the primary interface for human-LLM interaction. With the growing deployment of LLMs, diverse prompt datasets are emerging from platforms such as GitHub and social media. These datasets span a wide array of applications and content types, facilitating both broader LLM utilization and improved prompt engineering. In this work, we--for the first time--have compiled an extensive list of prompt datasets sourced from various channels, representing a spectrum of downstream tasks, languages, engineering techniques, attributes, and modalities. We select key representative datasets for systematic analysis, revealing commonalities and differences in prompt construction across categories, distinguishing them from other text corpora like literature and web. We further propose a prompt optimization approach that leverages syntactic embeddings of part-of-speech and dependency structures. By identifying a centroid representation of prompts and guiding LLMs to rewrite prompts toward this centroid, our method improves the meaningfulness of model outputs. We have made our datasets and code available.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "206",
        "title": "Hybrid-grained Feature Aggregation with Coarse-to-fine Language Guidance for Self-supervised Monocular Depth Estimation",
        "author": [
            "Wenyao Zhang",
            "Hongsi Liu",
            "Bohan Li",
            "Jiawei He",
            "Zekun Qi",
            "Yunnan Wang",
            "Shengyang Zhao",
            "Xinqiang Yu",
            "Wenjun Zeng",
            "Xin Jin"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09320",
        "abstract": "Current self-supervised monocular depth estimation (MDE) approaches encounter performance limitations due to insufficient semantic-spatial knowledge extraction. To address this challenge, we propose Hybrid-depth, a novel framework that systematically integrates foundation models (e.g., CLIP and DINO) to extract visual priors and acquire sufficient contextual information for MDE. Our approach introduces a coarse-to-fine progressive learning framework: 1) Firstly, we aggregate multi-grained features from CLIP (global semantics) and DINO (local spatial details) under contrastive language guidance. A proxy task comparing close-distant image patches is designed to enforce depth-aware feature alignment using text prompts; 2) Next, building on the coarse features, we integrate camera pose information and pixel-wise language alignment to refine depth predictions. This module seamlessly integrates with existing self-supervised MDE pipelines (e.g., Monodepth2, ManyDepth) as a plug-and-play depth encoder, enhancing continuous depth estimation. By aggregating CLIP's semantic context and DINO's spatial details through language guidance, our method effectively addresses feature granularity mismatches. Extensive experiments on the KITTI benchmark demonstrate that our method significantly outperforms SOTA methods across all metrics, which also indeed benefits downstream tasks like BEV perception. Code is available at https://github.com/Zhangwenyao1/Hybrid-depth.",
        "tags": [
            "CLIP",
            "Depth Estimation"
        ]
    },
    {
        "id": "207",
        "title": "Rate optimal learning of equilibria from data",
        "author": [
            "Till Freihaut",
            "Luca Viano",
            "Emanuele Nevali",
            "Volkan Cevher",
            "Matthieu Geist",
            "Giorgia Ramponi"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09325",
        "abstract": "We close open theoretical gaps in Multi-Agent Imitation Learning (MAIL) by characterizing the limits of non-interactive MAIL and presenting the first interactive algorithm with near-optimal sample complexity. In the non-interactive setting, we prove a statistical lower bound that identifies the all-policy deviation concentrability coefficient as the fundamental complexity measure, and we show that Behavior Cloning (BC) is rate-optimal. For the interactive setting, we introduce a framework that combines reward-free reinforcement learning with interactive MAIL and instantiate it with an algorithm, MAIL-WARM. It improves the best previously known sample complexity from $\\mathcal{O}(\\varepsilon^{-8})$ to $\\mathcal{O}(\\varepsilon^{-2}),$ matching the dependence on $\\varepsilon$ implied by our lower bound. Finally, we provide numerical results that support our theory and illustrate, in environments such as grid worlds, where Behavior Cloning fails to learn.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "208",
        "title": "Safety Game: Balancing Safe and Informative Conversations with Blackbox Agentic AI using LP Solvers",
        "author": [
            "Tuan Nguyen",
            "Long Tran-Thanh"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09330",
        "abstract": "Ensuring that large language models (LLMs) comply with safety requirements is a central challenge in AI deployment. Existing alignment approaches primarily operate during training, such as through fine-tuning or reinforcement learning from human feedback, but these methods are costly and inflexible, requiring retraining whenever new requirements arise. Recent efforts toward inference-time alignment mitigate some of these limitations but still assume access to model internals, which is impractical, and not suitable for third party stakeholders who do not have access to the models. In this work, we propose a model-independent, black-box framework for safety alignment that does not require retraining or access to the underlying LLM architecture. As a proof of concept, we address the problem of trading off between generating safe but uninformative answers versus helpful yet potentially risky ones. We formulate this dilemma as a two-player zero-sum game whose minimax equilibrium captures the optimal balance between safety and helpfulness. LLM agents operationalize this framework by leveraging a linear programming solver at inference time to compute equilibrium strategies. Our results demonstrate the feasibility of black-box safety alignment, offering a scalable and accessible pathway for stakeholders, including smaller organizations and entities in resource-constrained settings, to enforce safety across rapidly evolving LLM ecosystems.",
        "tags": [
            "LLM",
            "RL",
            "RLHF"
        ]
    },
    {
        "id": "209",
        "title": "FLRC: Fine-grained Low-Rank Compressor for Efficient LLM Inference",
        "author": [
            "Yu-Chen Lu",
            "Chong-Yan Chen",
            "Chi-Chih Chang",
            "Yu-Fang Hu",
            "Kai-Chiang Wu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09332",
        "abstract": "Although large language models (LLM) have achieved remarkable performance, their enormous parameter counts hinder deployment on resource-constrained hardware. Low-rank compression can reduce both memory usage and computational demand, but applying a uniform compression ratio across all layers often leads to significant performance degradation, and previous methods perform poorly during decoding. To address these issues, we propose the Fine-grained Low-Rank Compressor (FLRC), which efficiently determines an optimal rank allocation for each layer, and incorporates progressive low-rank decoding to maintain text generation quality. Comprehensive experiments on diverse benchmarks demonstrate the superiority of FLRC, achieving up to a 17% improvement in ROUGE-L on summarization tasks compared to state-of-the-art low-rank compression methods, establishing a more robust and efficient framework to improve LLM inference.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "210",
        "title": "Localist LLMs -- A Mathematical Framework for Dynamic Locality Control",
        "author": [
            "Joachim Diederich"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09338",
        "abstract": "We present a novel framework for training large language models with continuously adjustable internal representations that span the full spectrum from localist (interpretable, rule-based) to distributed (generalizable, efficient) encodings. The key innovation is a locality dial, a tunable parameter that dynamically controls the degree of localization during both training and inference without requiring model retraining. This is achieved through group sparsity penalties on attention mechanisms, information-theoretic anchor design, and dynamic rule injection. We provide rigorous mathematical proofs establishing explicit threshold conditions under which attention provably concentrates on semantically relevant blocks, with exponential bounds on attention entropy and pointer fidelity. Specifically, we prove that when group sparsity penalties exceed certain threshold values, the model's attention mechanisms concentrate on semantically relevant blocks, achieving low entropy and high fidelity with negligible error. This framework enables practitioners to continuously interpolate between interpretable and high-performance modes, supporting applications in regulated domains requiring both transparency and capability.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "211",
        "title": "Toward Mechanistic Explanation of Deductive Reasoning in Language Models",
        "author": [
            "Davide Maltoni",
            "Matteo Ferrara"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09340",
        "abstract": "Recent large language models have demonstrated relevant capabilities in solving problems that require logical reasoning; however, the corresponding internal mechanisms remain largely unexplored. In this paper, we show that a small language model can solve a deductive reasoning task by learning the underlying rules (rather than operating as a statistical learner). A low-level explanation of its internal representations and computational circuits is then provided. Our findings reveal that induction heads play a central role in the implementation of the rule completion and rule chaining steps involved in the logical inference required by the task.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "212",
        "title": "LLP: LLM-based Product Pricing in E-commerce",
        "author": [
            "Hairu Wang",
            "Sheng You",
            "Qiheng Zhang",
            "Xike Xie",
            "Shuguang Han",
            "Yuchen Wu",
            "Fei Huang",
            "Jufeng Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09347",
        "abstract": "Unlike Business-to-Consumer e-commerce platforms (e.g., Amazon), inexperienced individual sellers on Consumer-to-Consumer platforms (e.g., eBay) often face significant challenges in setting prices for their second-hand products efficiently. Therefore, numerous studies have been proposed for automating price prediction. However, most of them are based on static regression models, which suffer from poor generalization performance and fail to capture market dynamics (e.g., the price of a used iPhone decreases over time). Inspired by recent breakthroughs in Large Language Models (LLMs), we introduce LLP, the first LLM-based generative framework for second-hand product pricing. LLP first retrieves similar products to better align with the dynamic market change. Afterwards, it leverages the LLMs' nuanced understanding of key pricing information in free-form text to generate accurate price suggestions. To strengthen the LLMs' domain reasoning over retrieved products, we apply a two-stage optimization, supervised fine-tuning (SFT) followed by group relative policy optimization (GRPO), on a dataset built via bidirectional reasoning. Moreover, LLP employs a confidence-based filtering mechanism to reject unreliable price suggestions. Extensive experiments demonstrate that LLP substantially surpasses existing methods while generalizing well to unseen categories. We have successfully deployed LLP on Xianyu\\footnote\\{Xianyu is China's largest second-hand e-commerce platform.\\}, significantly outperforming the previous pricing method. Under the same 30\\% product coverage, it raises the static adoption rate (SAR) from 40\\% to 72\\%, and maintains a strong SAR of 47\\% even at 90\\% recall.",
        "tags": [
            "GRPO",
            "LLM"
        ]
    },
    {
        "id": "213",
        "title": "ReTraceQA: Evaluating Reasoning Traces of Small Language Models in Commonsense Question Answering",
        "author": [
            "Francesco Maria Molfese",
            "Luca Moroni",
            "Ciro Porcaro",
            "Simone Conia",
            "Roberto Navigli"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09351",
        "abstract": "While Small Language Models (SLMs) have demonstrated promising performance on an increasingly wide array of commonsense reasoning benchmarks, current evaluation practices rely almost exclusively on the accuracy of their final answers, neglecting the validity of the reasoning processes that lead to those answers. To address this issue, we introduce ReTraceQA, a novel benchmark that introduces process-level evaluation for commonsense reasoning tasks. Our expert-annotated dataset reveals that in a substantial portion of instances (14-24%), SLMs provide correct final answers despite flawed reasoning processes, suggesting that the capabilities of SLMs are often overestimated by evaluation metrics that focus only on comparing the final answer with the ground truth. Indeed, we show that when employing strong Large Language Models (LLMs) as automated judges for reasoning-aware evaluation rather than answer-only metrics, SLM performance drops significantly across all models and datasets, with scores decreasing by up to 25%.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "214",
        "title": "Logit Arithmetic Elicits Long Reasoning Capabilities Without Training",
        "author": [
            "Yunxiang Zhang",
            "Muhammad Khalifa",
            "Lechen Zhang",
            "Xin Liu",
            "Ayoung Lee",
            "Xinliang Frederick Zhang",
            "Farima Fatahi Bayat",
            "Lu Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09354",
        "abstract": "Large reasoning models exhibit long chain-of-thought reasoning with strategies such as backtracking and self-correction, though recent studies suggest that these abilities typically require additional training. We first investigate whether such behaviors can be elicited without any training. To this end, we propose a decoding-time approach, ThinkLogit, which utilizes logit arithmetic to tune a target large non-reasoning model for long reasoning using a substantially smaller reasoning model as the guider. We then show that we can further boost its performance by training the guider model with preference optimization over correct/incorrect reasoning pairs sampled from both the target and guider model, a setup we refer to as ThinkLogit-DPO. Our experiments demonstrate that ThinkLogit and ThinkLogit-DPO achieve a relative improvement in average accuracy by 24.5% and 29.1%, respectively, over five reasoning benchmarks using the Qwen2.5-32B guided by R1-Distill-Qwen-1.5B, a model 21x smaller. Moreover, we find that ThinkLogit remains effective when the guider and target come from different model families. It is also orthogonal to post-training methods for small models, as guiders improved through supervised distillation or reinforcement learning can be directly plugged in to yield stronger large models, offering a practical path to unlock long reasoning in large-scale models without costly post-training.",
        "tags": [
            "CoT",
            "DPO",
            "Qwen",
            "RL"
        ]
    },
    {
        "id": "215",
        "title": "NL2GenSym: Natural Language to Generative Symbolic Rules for SOAR Cognitive Architecture via Large Language Models",
        "author": [
            "Fang Yuan",
            "Junjie Zeng",
            "Yue Hu",
            "Zhengqiu Zhu",
            "Quanjun Yin",
            "Yuxiang Xie"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09355",
        "abstract": "SOAR, a classic symbol-based cognitive architecture, has been fostering the development of general, human-like intelligent agents. Nevertheless, its practical adoption is hindered by the laborious manual rule coding. Emerging Large Language Models (LLMs) present the immense potential for efficient rules generation. However, there is a critical gap that current research predominantly focuses on conceptual frameworks and lacks robust experimental validation. To bridge this gap, we propose \\textit{N}atural \\textit{L}anguage to \\textit{Gen}erative \\textit{Sym}bolic Rules (NL2GenSym), a novel framework that integrates LLMs with SOAR to autonomously produce generative symbolic rules from natural language. Specifically, our framework introduces a novel Execution-Grounded Generator-Critic mechanism. The LLM-based Generator, guided by a Retrieval-Augmented Generation-accessed self-evolving domain knowledge base, proposes rules from natural language. Subsequently, these rules are immediately executed within the SOAR environment to rigorously validate their correctness. Based on this execution-grounded feedback, a reflective LLM-based Critic drives the iterative refinement of these rules. Experiments on our specialized Water Jug Problem (WJP) dataset, utilizing both Gemini and Qwen series models, validate the efficacy of our framework. It achieves a success rate over 86\\% in generating rules from natural language. Crucially, the framework also generates novel heuristic rules, reducing average decision cycles for solving the WJP to 1.98 times the optimal solution and 1/1000 of baseline methods. Additionally, our initial experiments show that NL2GenSym enables smaller-parameter models to achieve better performance than larger counterparts.",
        "tags": [
            "LLM",
            "Qwen"
        ]
    },
    {
        "id": "216",
        "title": "Boosting Multi-modal Keyphrase Prediction with Dynamic Chain-of-Thought in Vision-Language Models",
        "author": [
            "Qihang Ma",
            "Shengyu Li",
            "Jie Tang",
            "Dingkang Yang",
            "Shaodong Chen",
            "Yingyi Zhang",
            "Chao Feng",
            "Jiao Ran"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09358",
        "abstract": "Multi-modal keyphrase prediction (MMKP) aims to advance beyond text-only methods by incorporating multiple modalities of input information to produce a set of conclusive phrases. Traditional multi-modal approaches have been proven to have significant limitations in handling the challenging absence and unseen scenarios. Additionally, we identify shortcomings in existing benchmarks that overestimate model capability due to significant overlap in training tests. In this work, we propose leveraging vision-language models (VLMs) for the MMKP task. Firstly, we use two widely-used strategies, e.g., zero-shot and supervised fine-tuning (SFT) to assess the lower bound performance of VLMs. Next, to improve the complex reasoning capabilities of VLMs, we adopt Fine-tune-CoT, which leverages high-quality CoT reasoning data generated by a teacher model to finetune smaller models. Finally, to address the \"overthinking\" phenomenon, we propose a dynamic CoT strategy which adaptively injects CoT data during training, allowing the model to flexibly leverage its reasoning capabilities during the inference stage. We evaluate the proposed strategies on various datasets and the experimental results demonstrate the effectiveness of the proposed approaches. The code is available at https://github.com/bytedance/DynamicCoT.",
        "tags": [
            "CoT",
            "VLM"
        ]
    },
    {
        "id": "217",
        "title": "BLINK-Twice: You see, but do you observe? A Reasoning Benchmark on Visual Perception",
        "author": [
            "Junyan Ye",
            "Dongzhi Jiang",
            "Jun He",
            "Baichuan Zhou",
            "Zilong Huang",
            "Zhiyuan Yan",
            "Hongsheng Li",
            "Conghui He",
            "Weijia Li"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09361",
        "abstract": "Recently, Multimodal Large Language Models (MLLMs) have made rapid progress, particularly in enhancing their reasoning capabilities. However, existing reasoning benchmarks still primarily assess language-based reasoning, often treating visual input as replaceable context. To address this gap, we introduce BLINK-Twice, a vision-centric reasoning benchmark grounded in challenging perceptual tasks. Instead of relying on external knowledge, our tasks require models to reason from visual content alone, shifting the focus from language-based to image-grounded reasoning. Compared to prior perception benchmarks, it moves beyond shallow perception (\"see\") and requires fine-grained observation and analytical reasoning (\"observe\"). BLINK-Twice integrates three core components: seven types of visual challenges for testing visual reasoning, natural adversarial image pairs that enforce reliance on visual content, and annotated reasoning chains for fine-grained evaluation of the reasoning process rather than final answers alone. We evaluate 20 leading MLLMs, including 12 foundation models and 8 reasoning-enhanced models. BLINK-Twice poses a significant challenge to current models. While existing reasoning strategies in the language space-such as chain-of-thought or self-criticism can improve performance, they often result in unstable and redundant reasoning. We observe that repeated image observation improves performance across models, and active visual interaction, as demonstrated by models like o3, highlights the need for a new paradigm for vision reasoning. The dataset is publicly available at https://github.com/PicoTrex/BLINK-Twice",
        "tags": [
            "CoT",
            "LLM"
        ]
    },
    {
        "id": "218",
        "title": "Visibility-Aware Densification for 3D Gaussian Splatting in Dynamic Urban Scenes",
        "author": [
            "Yikang Zhang",
            "Rui Fan"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09364",
        "abstract": "3D Gaussian splatting (3DGS) has demonstrated impressive performance in synthesizing high-fidelity novel views. Nonetheless, its effectiveness critically depends on the quality of the initialized point cloud. Specifically, achieving uniform and complete point coverage over the underlying scene structure requires overlapping observation frustums, an assumption that is often violated in unbounded, dynamic urban environments. Training Gaussian models with partially initialized point clouds often leads to distortions and artifacts, as camera rays may fail to intersect valid surfaces, resulting in incorrect gradient propagation to Gaussian primitives associated with occluded or invisible geometry. Additionally, existing densification strategies simply clone and split Gaussian primitives from existing ones, incapable of reconstructing missing structures. To address these limitations, we propose VAD-GS, a 3DGS framework tailored for geometry recovery in challenging urban scenes. Our method identifies unreliable geometry structures via voxel-based visibility reasoning, selects informative supporting views through diversity-aware view selection, and recovers missing structures via patch matching-based multi-view stereo reconstruction. This design enables the generation of new Gaussian primitives guided by reliable geometric priors, even in regions lacking initial points. Extensive experiments on the Waymo and nuScenes datasets demonstrate that VAD-GS outperforms state-of-the-art 3DGS approaches and significantly improves the quality of reconstructed geometry for both static and dynamic objects. Source code will be released upon publication.",
        "tags": [
            "3D",
            "Gaussian Splatting"
        ]
    },
    {
        "id": "219",
        "title": "Minkowski-MambaNet: A Point Cloud Framework with Selective State Space Models for Forest Biomass Quantification",
        "author": [
            "Jinxiang Tu",
            "Dayong Ren",
            "Fei Shi",
            "Zhenhong Jia",
            "Yahong Ren",
            "Jiwei Qin",
            "Fang He"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09367",
        "abstract": "Accurate forest biomass quantification is vital for carbon cycle monitoring. While airborne LiDAR excels at capturing 3D forest structure, directly estimating woody volume and Aboveground Biomass (AGB) from point clouds is challenging due to difficulties in modeling long-range dependencies needed to distinguish http://trees.We propose Minkowski-MambaNet, a novel deep learning framework that directly estimates volume and AGB from raw LiDAR. Its key innovation is integrating the Mamba model's Selective State Space Model (SSM) into a Minkowski network, enabling effective encoding of global context and long-range dependencies for improved tree differentiation. Skip connections are incorporated to enhance features and accelerate http://convergence.Evaluated on Danish National Forest Inventory LiDAR data, Minkowski-MambaNet significantly outperforms state-of-the-art methods, providing more accurate and robust estimates. Crucially, it requires no Digital Terrain Model (DTM) and is robust to boundary artifacts. This work offers a powerful tool for large-scale forest biomass analysis, advancing LiDAR-based forest inventories.",
        "tags": [
            "3D",
            "Mamba",
            "SSMs"
        ]
    },
    {
        "id": "220",
        "title": "Token-Level Policy Optimization: Linking Group-Level Rewards to Token-Level Aggregation via Markov Likelihood",
        "author": [
            "Xingyu Lin",
            "Yilin Wen",
            "En Wang",
            "Du Su",
            "Wenbin Liu",
            "Chenfu Bao",
            "Zhonghou Lv"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09369",
        "abstract": "Group Relative Policy Optimization (GRPO) has significantly advanced the reasoning ability of large language models (LLMs), particularly by boosting their mathematical performance. However, GRPO and related entropy-regularization methods still face challenges rooted in the sparse token rewards inherent to chain-of-thought (CoT). Current approaches often rely on undifferentiated token-level entropy adjustments, which frequently lead to entropy collapse or model collapse. In this work, we propose TEPO, a novel token-level framework that incorporates Markov Likelihood (sequence likelihood) links group-level rewards with tokens via token-level aggregation. Experiments show that TEPO consistently outperforms existing baselines across key metrics (including @k and accuracy). It not only sets a new state of the art on mathematical reasoning tasks but also significantly enhances training stability.",
        "tags": [
            "CoT",
            "GRPO",
            "LLM"
        ]
    },
    {
        "id": "221",
        "title": "The Potential of Second-Order Optimization for LLMs: A Study with Full Gauss-Newton",
        "author": [
            "Natalie Abreu",
            "Nikhil Vyas",
            "Sham Kakade",
            "Depen Morwani"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09378",
        "abstract": "Recent efforts to accelerate LLM pretraining have focused on computationally-efficient approximations that exploit second-order structure. This raises a key question for large-scale training: how much performance is forfeited by these approximations? To probe this question, we establish a practical upper bound on iteration complexity by applying full Gauss-Newton (GN) preconditioning to transformer models of up to 150M parameters. Our experiments show that full GN updates yield substantial gains over existing optimizers, achieving a 5.4x reduction in training iterations compared to strong baselines like SOAP and Muon. Furthermore, we find that a precise layerwise GN preconditioner, which ignores cross-layer information, nearly matches the performance of the full GN method. Collectively, our results suggest: (1) the GN approximation is highly effective for preconditioning, implying higher-order loss terms may not be critical for convergence speed; (2) the layerwise Hessian structure contains sufficient information to achieve most of these potential gains; and (3) a significant performance gap exists between current approximate methods and an idealized layerwise oracle.",
        "tags": [
            "LLM",
            "Transformer"
        ]
    },
    {
        "id": "222",
        "title": "Task-Level Insights from Eigenvalues across Sequence Models",
        "author": [
            "Rahel Rickenbach",
            "Jelena Trisovic",
            "Alexandre Didier",
            "Jerome Sieber",
            "Melanie N. Zeilinger"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09379",
        "abstract": "Although softmax attention drives state-of-the-art performance for sequence models, its quadratic complexity limits scalability, motivating linear alternatives such as state space models (SSMs). While these alternatives improve efficiency, their fundamental differences in information processing remain poorly understood. In this work, we leverage the recently proposed dynamical systems framework to represent softmax, norm and linear attention as dynamical systems, enabling a structured comparison with SSMs by analyzing their respective eigenvalue spectra. Since eigenvalues capture essential aspects of dynamical system behavior, we conduct an extensive empirical analysis across diverse sequence models and benchmarks. We first show that eigenvalues influence essential aspects of memory and long-range dependency modeling, revealing spectral signatures that align with task requirements. Building on these insights, we then investigate how architectural modifications in sequence models impact both eigenvalue spectra and task performance. This correspondence further strengthens the position of eigenvalue analysis as a principled metric for interpreting, understanding, and ultimately improving the capabilities of sequence models.",
        "tags": [
            "SSMs"
        ]
    },
    {
        "id": "223",
        "title": "Utilizing dynamic sparsity on pretrained DETR",
        "author": [
            "Reza Sedghi",
            "Anand Subramoney",
            "David Kappel"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09380",
        "abstract": "Efficient inference with transformer-based models remains a challenge, especially in vision tasks like object detection. We analyze the inherent sparsity in the MLP layers of DETR and introduce two methods to exploit it without retraining. First, we propose Static Indicator-Based Sparsification (SIBS), a heuristic method that predicts neuron inactivity based on fixed activation patterns. While simple, SIBS offers limited gains due to the input-dependent nature of sparsity. To address this, we introduce Micro-Gated Sparsification (MGS), a lightweight gating mechanism trained on top of a pretrained DETR. MGS predicts dynamic sparsity using a small linear layer and achieves up to 85 to 95% activation sparsity. Experiments on the COCO dataset show that MGS maintains or even improves performance while significantly reducing computation. Our method offers a practical, input-adaptive approach to sparsification, enabling efficient deployment of pretrained vision transformers without full model retraining.",
        "tags": [
            "Detection",
            "Transformer"
        ]
    },
    {
        "id": "224",
        "title": "HINT: Helping Ineffective Rollouts Navigate Towards Effectiveness",
        "author": [
            "Xinyi Wang",
            "Jinyi Han",
            "Zishang Jiang",
            "Tingyun Li",
            "Jiaqing Liang",
            "Sihang Jiang",
            "Zhaoqian Dai",
            "Shuguang Ma",
            "Fei Yu",
            "Yanghua Xiao"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09388",
        "abstract": "Reinforcement Learning (RL) has become a key driver for enhancing the long chain-of-thought (CoT) reasoning capabilities of Large Language Models (LLMs). However, prevalent methods like GRPO often fail when task difficulty exceeds the model's capacity, leading to reward sparsity and inefficient training. While prior work attempts to mitigate this using off-policy data, such as mixing RL with Supervised Fine-Tuning (SFT) or using hints, they often misguide policy updates In this work, we identify a core issue underlying these failures, which we term low training affinity. This condition arises from a large distributional mismatch between external guidance and the model's policy. To diagnose this, we introduce Affinity, the first quantitative metric for monitoring exploration efficiency and training stability. To improve Affinity, we propose HINT: Helping Ineffective rollouts Navigate Towards effectiveness, an adaptive hinting framework. Instead of providing direct answers, HINT supplies heuristic hints that guide the model to discover solutions on its own, preserving its autonomous reasoning capabilities. Extensive experiments on mathematical reasoning tasks show that HINT consistently outperforms existing methods, achieving state-of-the-art results with models of various scales, while also demonstrating significantly more stable learning and greater data http://efficiency.Code is available on Github.",
        "tags": [
            "CoT",
            "GRPO",
            "LLM",
            "RL"
        ]
    },
    {
        "id": "225",
        "title": "Design Principles for Sequence Models via Coefficient Dynamics",
        "author": [
            "Jerome Sieber",
            "Antonio Orvieto",
            "Melanie N. Zeilinger",
            "Carmen Amo Alonso"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09389",
        "abstract": "Deep sequence models, ranging from Transformers and State Space Models (SSMs) to more recent approaches such as gated linear RNNs, fundamentally compute outputs as linear combinations of past value vectors. To draw insights and systematically compare such architectures, we develop a unified framework that makes this output operation explicit, by casting the linear combination coefficients as the outputs of autonomous linear dynamical systems driven by impulse inputs. This viewpoint, in spirit substantially different from approaches focusing on connecting linear RNNs with linear attention, reveals a common mathematical theme across diverse architectures and crucially captures softmax attention, on top of RNNs, SSMs, and related models. In contrast to new model proposals that are commonly evaluated on benchmarks, we derive design principles linking architectural choices to model properties. Thereby identifying tradeoffs between expressivity and efficient implementation, geometric constraints on input selectivity, and stability conditions for numerically stable training and information retention. By connecting several insights and observations from recent literature, the framework both explains empirical successes of recent designs and provides guiding principles for systematically designing new sequence model architectures.",
        "tags": [
            "SSMs"
        ]
    },
    {
        "id": "226",
        "title": "ChoirRec: Semantic User Grouping via LLMs for Conversion Rate Prediction of Low-Activity Users",
        "author": [
            "Dakai Zhai",
            "Jiong Gao",
            "Boya Du",
            "Junwei Xu",
            "Qijie Shen",
            "Jialin Zhu",
            "Yuning Jiang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09393",
        "abstract": "Accurately predicting conversion rates (CVR) for low-activity users remains a fundamental challenge in large-scale e-commerce recommender http://systems.Existing approaches face three critical limitations: (i) reliance on noisy and unreliable behavioral signals; (ii) insufficient user-level information due to the lack of diverse interaction data; and (iii) a systemic training bias toward high-activity users that overshadows the needs of low-activity http://users.To address these challenges, we propose ChoirRec, a novel framework that leverages the semantic capabilities of Large Language Models (LLMs) to construct semantic user groups and enhance CVR prediction for low-activity http://users.With a dual-channel architecture designed for robust cross-user knowledge transfer, ChoirRec comprises three components: (i) a Semantic Group Generation module that utilizes LLMs to form reliable, cross-activity user clusters, thereby filtering out noisy signals; (ii) a Group-aware Hierarchical Representation module that enriches sparse user embeddings with informative group-level priors to mitigate data insufficiency; and (iii) a Group-aware Multi-granularity Modual that employs a dual-channel architecture and adaptive fusion mechanism to ensure effective learning and utilization of group knowledge. We conduct extensive offline and online experiments on Taobao, a leading industrial-scale e-commerce http://platform.ChoirRec improves GAUC by 1.16\\% in offline evaluations, while online A/B testing reveals a 7.24\\% increase in order volume, highlighting its substantial practical value in real-world applications.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "227",
        "title": "Beyond Single-Granularity Prompts: A Multi-Scale Chain-of-Thought Prompt Learning for Graph",
        "author": [
            "Ziyu Zheng",
            "Yaming Yang",
            "Ziyu Guan",
            "Wei Zhao",
            "Xinyan Huang",
            "Weigang Lu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09394",
        "abstract": "The \"pre-train, prompt'' paradigm, designed to bridge the gap between pre-training tasks and downstream objectives, has been extended from the NLP domain to the graph domain and has achieved remarkable progress. Current mainstream graph prompt-tuning methods modify input or output features using learnable prompt vectors. However, existing approaches are confined to single-granularity (e.g., node-level or subgraph-level) during prompt generation, overlooking the inherently multi-scale structural information in graph data, which limits the diversity of prompt semantics. To address this issue, we pioneer the integration of multi-scale information into graph prompt and propose a Multi-Scale Graph Chain-of-Thought (MSGCOT) prompting framework. Specifically, we design a lightweight, low-rank coarsening network to efficiently capture multi-scale structural features as hierarchical basis vectors for prompt generation. Subsequently, mimicking human cognition from coarse-to-fine granularity, we dynamically integrate multi-scale information at each reasoning step, forming a progressive coarse-to-fine prompt chain. Extensive experiments on eight benchmark datasets demonstrate that MSGCOT outperforms the state-of-the-art single-granularity graph prompt-tuning method, particularly in few-shot scenarios, showcasing superior performance.",
        "tags": [
            "CoT"
        ]
    },
    {
        "id": "228",
        "title": "Bridging Research and Practice in Simulation-based Testing of Industrial Robot Navigation Systems",
        "author": [
            "Sajad Khatiri",
            "Francisco Eli Vina Barrientos",
            "Maximilian Wulf",
            "Paolo Tonella",
            "Sebastiano Panichella"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09396",
        "abstract": "Ensuring robust robotic navigation in dynamic environments is a key challenge, as traditional testing methods often struggle to cover the full spectrum of operational requirements. This paper presents the industrial adoption of Surrealist, a simulation-based test generation framework originally for UAVs, now applied to the ANYmal quadrupedal robot for industrial inspection. Our method uses a search-based algorithm to automatically generate challenging obstacle avoidance scenarios, uncovering failures often missed by manual testing. In a pilot phase, generated test suites revealed critical weaknesses in one experimental algorithm (40.3% success rate) and served as an effective benchmark to prove the superior robustness of another (71.2% success rate). The framework was then integrated into the ANYbotics workflow for a six-month industrial evaluation, where it was used to test five proprietary algorithms. A formal survey confirmed its value, showing it enhances the development process, uncovers critical failures, provides objective benchmarks, and strengthens the overall verification pipeline.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "229",
        "title": "TIT: A Tree-Structured Instruction Tuning Approach for LLM-Based Code Translation",
        "author": [
            "He Jiang",
            "Yufu Wang",
            "Hao Lin",
            "Peiyu Zou",
            "Zhide Zhou",
            "Ang Jia",
            "Xiaochen Li",
            "Zhilei Ren"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09400",
        "abstract": "Large Language Models (LLMs) have shown strong performance in automated source-to-target code translation through pretraining on extensive code corpora. However, mainstream LLM-based code translation methods suffer from two critical limitations. First, they are highly sensitive to language-specific features, which often introduce source-language syntax or lexicon into the output, leading to syntactic confusion. Second, they lack fine-grained semantic alignment due to an over-reliance on function-level parallel datasets, resulting in semantic misalignment between the translated code and the original source. To overcome these limitations, we propose TIT, a Tree-structured Instruction Tuning paradigm for LLM-based code translation. Specifically, TIT consists of three modules. First, to mitigate syntactic confusion, the syntactic information representation module integrates language-agnostic syntactic features via structured parsing. Then, to generate high-quality fine-grained parallel data, the fine-grained parallel dataset augmentation module aligns nodes with code segments through statement-level segmentation and contrastive matching. Finally, we leverage the dual-stage tree instruction tuning module to alleviate the contextual processing burden on the LLM caused by the introduction of syntactic information. The first stage employs syntax-aware fine-tuning to enable the LLM to autonomously comprehend structured syntactic information, while the second stage utilizes code generation fine-tuning to guide the model in generating accurate target code based on function-level syntactic dependencies. The experimental results demonstrate that the proposed method significantly outperforms existing approaches in multiple LLMs, achieving a success rate 1.22x-1.75x higher in code translation while markedly reducing syntactic confusion.",
        "tags": [
            "LLM",
            "Segmentation"
        ]
    },
    {
        "id": "230",
        "title": "Agentic Systems in Radiology: Design, Applications, Evaluation, and Challenges",
        "author": [
            "Christian Bluethgen",
            "Dave Van Veen",
            "Daniel Truhn",
            "Jakob Nikolas Kather",
            "Michael Moor",
            "Malgorzata Polacin",
            "Akshay Chaudhari",
            "Thomas Frauenfelder",
            "Curtis P. Langlotz",
            "Michael Krauthammer",
            "Farhad Nooralahzadeh"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09404",
        "abstract": "Building agents, systems that perceive and act upon their environment with a degree of autonomy, has long been a focus of AI research. This pursuit has recently become vastly more practical with the emergence of large language models (LLMs) capable of using natural language to integrate information, follow instructions, and perform forms of \"reasoning\" and planning across a wide range of tasks. With its multimodal data streams and orchestrated workflows spanning multiple systems, radiology is uniquely suited to benefit from agents that can adapt to context and automate repetitive yet complex tasks. In radiology, LLMs and their multimodal variants have already demonstrated promising performance for individual tasks such as information extraction and report summarization. However, using LLMs in isolation underutilizes their potential to support complex, multi-step workflows where decisions depend on evolving context from multiple information sources. Equipping LLMs with external tools and feedback mechanisms enables them to drive systems that exhibit a spectrum of autonomy, ranging from semi-automated workflows to more adaptive agents capable of managing complex processes. This review examines the design of such LLM-driven agentic systems, highlights key applications, discusses evaluation methods for planning and tool use, and outlines challenges such as error cascades, tool-use efficiency, and health IT integration.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "231",
        "title": "Cross-Receiver Generalization for RF Fingerprint Identification via Feature Disentanglement and Adversarial Training",
        "author": [
            "Yuhao Pan",
            "Xiucheng Wang",
            "Nan Cheng",
            "Wenchao Xu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09405",
        "abstract": "Radio frequency fingerprint identification (RFFI) is a critical technique for wireless network security, leveraging intrinsic hardware-level imperfections introduced during device manufacturing to enable precise transmitter identification. While deep neural networks have shown remarkable capability in extracting discriminative features, their real-world deployment is hindered by receiver-induced variability. In practice, RF fingerprint signals comprise transmitter-specific features as well as channel distortions and receiver-induced biases. Although channel equalization can mitigate channel noise, receiver-induced feature shifts remain largely unaddressed, causing the RFFI models to overfit to receiver-specific patterns. This limitation is particularly problematic when training and evaluation share the same receiver, as replacing the receiver in deployment can cause substantial performance degradation. To tackle this challenge, we propose an RFFI framework robust to cross-receiver variability, integrating adversarial training and style transfer to explicitly disentangle transmitter and receiver features. By enforcing domain-invariant representation learning, our method isolates genuine hardware signatures from receiver artifacts, ensuring robustness against receiver changes. Extensive experiments on multi-receiver datasets demonstrate that our approach consistently outperforms state-of-the-art baselines, achieving up to a 10% improvement in average accuracy across diverse receiver settings.",
        "tags": [
            "Style Transfer"
        ]
    },
    {
        "id": "232",
        "title": "Active Model Selection for Large Language Models",
        "author": [
            "Yavuz Durmazkeser",
            "Patrik Okanovic",
            "Andreas Kirsch",
            "Torsten Hoefler",
            "Nezihe Merve GÃ¼rel"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09418",
        "abstract": "We introduce LLM SELECTOR, the first framework for active model selection of Large Language Models (LLMs). Unlike prior evaluation and benchmarking approaches that rely on fully annotated datasets, LLM SELECTOR efficiently identifies the best LLM with limited annotations. In particular, for any given task, LLM SELECTOR adaptively selects a small set of queries to annotate that are most informative about the best model for the task. To further reduce annotation cost, we leverage a judge-based oracle annotation model. Through extensive experiments on 6 benchmarks with 151 LLMs, we show that LLM SELECTOR reduces annotation costs by up to 59.62% when selecting the best and near-best LLM for the task.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "233",
        "title": "On the Representations of Entities in Auto-regressive Large Language Models",
        "author": [
            "Victor Morand",
            "Josiane Mothe",
            "Benjamin Piwowarski"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09421",
        "abstract": "Named entities are fundamental building blocks of knowledge in text, grounding factual information and structuring relationships within language. Despite their importance, it remains unclear how Large Language Models (LLMs) internally represent entities. Prior research has primarily examined explicit relationships, but little is known about entity representations themselves. We introduce entity mention reconstruction as a novel framework for studying how LLMs encode and manipulate entities. We investigate whether entity mentions can be generated from internal representations, how multi-token entities are encoded beyond last-token embeddings, and whether these representations capture relational knowledge. Our proposed method, leveraging _task vectors_, allows to consistently generate multi-token mentions from various entity representations derived from the LLMs hidden states. We thus introduce the _Entity Lens_, extending the _logit-lens_ to predict multi-token mentions. Our results bring new evidence that LLMs develop entity-specific mechanisms to represent and manipulate any multi-token entities, including those unseen during training. Our code is avalable at https://github.com/VictorMorand/EntityRepresentations .",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "234",
        "title": "Weight Initialization and Variance Dynamics in Deep Neural Networks and Large Language Models",
        "author": [
            "Yankun Han"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09423",
        "abstract": "Weight initialization governs signal propagation and gradient flow at the start of training. This paper offers a theory-grounded and empirically validated study across two regimes: compact ReLU multilayer perceptrons and GPT-2-style transformers. First, a logarithmic sweep of the initial standard deviation maps vanishing and exploding regimes and identifies a broad stability band with standard deviations between 1e-2 and 1e-1. Second, a controlled comparison shows that Kaiming (fan-in) initialization converges faster and more stably than Xavier under ReLU, consistent with variance-preserving theory. Third, in a from-scratch 12-layer GPT-2-style model, this paper tracks layerwise Q/K/V weight variance through pretraining and observe depth-dependent equilibration into narrow bands: shallow layers expand rapidly while deeper layers change more gradually. Together, these results connect classic initialization principles with modern transformer behavior and yield simple, practical recipes for robust training.",
        "tags": [
            "GPT",
            "LLM",
            "Transformer"
        ]
    },
    {
        "id": "235",
        "title": "The Speech-LLM Takes It All: A Truly Fully End-to-End Spoken Dialogue State Tracking Approach",
        "author": [
            "Nizar El Ghazal",
            "Antoine CaubriÃ¨re",
            "Valentin Vielzeuf"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09424",
        "abstract": "This paper presents a comparative study of context management strategies for end-to-end Spoken Dialog State Tracking using Speech-LLMs. We systematically evaluate traditional multimodal context (combining text history and spoken current turn), full spoken history, and compressed spoken history approaches. Our experiments on the SpokenWOZ corpus demonstrate that providing the full spoken conversation as input yields the highest performance among models of similar size, significantly surpassing prior methods. Furthermore, we show that attention-pooling-based compression of the spoken history offers a strong trade-off, maintaining competitive accuracy with reduced context size. Detailed analysis confirms that improvements stem from more effective context utilization.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "236",
        "title": "KORMo: Korean Open Reasoning Model for Everyone",
        "author": [
            "Minjun Kim",
            "Hyeonseok Lim",
            "Hangyeol Yoo",
            "Inho Won",
            "Seungwoo Song",
            "Minkyung Cho",
            "Junhun Yuk",
            "Changsu Choi",
            "Dongjae Shin",
            "Huige Lee",
            "Hoyun Song",
            "Alice Oh",
            "Kyungtae Lim"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09426",
        "abstract": "This work presents the first large-scale investigation into constructing a fully open bilingual large language model (LLM) for a non-English language, specifically Korean, trained predominantly on synthetic data. We introduce KORMo-10B, a 10.8B-parameter model trained from scratch on a Korean-English corpus in which 68.74% of the Korean portion is synthetic. Through systematic experimentation, we demonstrate that synthetic data, when carefully curated with balanced linguistic coverage and diverse instruction styles, does not cause instability or degradation during large-scale pretraining. Furthermore, the model achieves performance comparable to that of contemporary open-weight multilingual baselines across a wide range of reasoning, knowledge, and instruction-following benchmarks. Our experiments reveal two key findings: (1) synthetic data can reliably sustain long-horizon pretraining without model collapse, and (2) bilingual instruction tuning enables near-native reasoning and discourse coherence in Korean. By fully releasing all components including data, code, training recipes, and logs, this work establishes a transparent framework for developing synthetic data-driven fully open models (FOMs) in low-resource settings and sets a reproducible precedent for future multilingual LLM research.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "237",
        "title": "Domain-Adapted Pre-trained Language Models for Implicit Information Extraction in Crash Narratives",
        "author": [
            "Xixi Wang",
            "Jordanka Kovaceva",
            "Miguel Costa",
            "Shuai Wang",
            "Francisco Camara Pereira",
            "Robert Thomson"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09434",
        "abstract": "Free-text crash narratives recorded in real-world crash databases have been shown to play a significant role in improving traffic safety. However, large-scale analyses remain difficult to implement as there are no documented tools that can batch process the unstructured, non standardized text content written by various authors with diverse experience and attention to detail. In recent years, Transformer-based pre-trained language models (PLMs), such as Bidirectional Encoder Representations from Transformers (BERT) and large language models (LLMs), have demonstrated strong capabilities across various natural language processing tasks. These models can extract explicit facts from crash narratives, but their performance declines on inference-heavy tasks in, for example, Crash Type identification, which can involve nearly 100 categories. Moreover, relying on closed LLMs through external APIs raises privacy concerns for sensitive crash data. Additionally, these black-box tools often underperform due to limited domain knowledge. Motivated by these challenges, we study whether compact open-source PLMs can support reasoning-intensive extraction from crash narratives. We target two challenging objectives: 1) identifying the Manner of Collision for a crash, and 2) Crash Type for each vehicle involved in the crash event from real-world crash narratives. To bridge domain gaps, we apply fine-tuning techniques to inject task-specific knowledge to LLMs with Low-Rank Adaption (LoRA) and BERT. Experiments on the authoritative real-world dataset Crash Investigation Sampling System (CISS) demonstrate that our fine-tuned compact models outperform strong closed LLMs, such as GPT-4o, while requiring only minimal training resources. Further analysis reveals that the fine-tuned PLMs can capture richer narrative details and even correct some mislabeled annotations in the dataset.",
        "tags": [
            "BERT",
            "GPT",
            "LLM",
            "LoRA",
            "Transformer"
        ]
    },
    {
        "id": "238",
        "title": "Mono4DEditor: Text-Driven 4D Scene Editing from Monocular Video via Point-Level Localization of Language-Embedded Gaussians",
        "author": [
            "Jin-Chuan Shi",
            "Chengye Su",
            "Jiajun Wang",
            "Ariel Shamir",
            "Miao Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09438",
        "abstract": "Editing 4D scenes reconstructed from monocular videos based on text prompts is a valuable yet challenging task with broad applications in content creation and virtual environments. The key difficulty lies in achieving semantically precise edits in localized regions of complex, dynamic scenes, while preserving the integrity of unedited content. To address this, we introduce Mono4DEditor, a novel framework for flexible and accurate text-driven 4D scene editing. Our method augments 3D Gaussians with quantized CLIP features to form a language-embedded dynamic representation, enabling efficient semantic querying of arbitrary spatial regions. We further propose a two-stage point-level localization strategy that first selects candidate Gaussians via CLIP similarity and then refines their spatial extent to improve accuracy. Finally, targeted edits are performed on localized regions using a diffusion-based video editing model, with flow and scribble guidance ensuring spatial fidelity and temporal coherence. Extensive experiments demonstrate that Mono4DEditor enables high-quality, text-driven edits across diverse scenes and object types, while preserving the appearance and geometry of unedited areas and surpassing prior approaches in both flexibility and visual fidelity.",
        "tags": [
            "3D",
            "CLIP",
            "Diffusion",
            "Video Editing"
        ]
    },
    {
        "id": "239",
        "title": "A posteriori analysis for nonlinear convection-diffusion systems",
        "author": [
            "Andreas Dedner",
            "Jan Giesselmann",
            "Kiwoong Kwon",
            "Tristan Pryer"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09449",
        "abstract": "This work provides reliable a posteriori error estimates for Runge-Kutta discontinuous Galerkin approximations of nonlinear convection-diffusion systems. The classes of systems we study are quite general with a focus on convection-dominated and degenerate parabolic problems. Our a posteriori error bounds are valid for a family of discontinuous Galerkin spatial discretizations and various temporal discretizations that include explicit and implicit-explicit time-stepping schemes, popular tools for practical simulations of this class of problem. We prove that our estimators provide reliable upper bounds for the error of the numerical method and present numerical evidence showing that they achieve the same order of convergence as the error. Since one of our main interests is the convection dominant case, we also track the dependence of the estimator on the viscosity coefficient.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "240",
        "title": "SilvaScenes: Tree Segmentation and Species Classification from Under-Canopy Images in Natural Forests",
        "author": [
            "David-Alexandre Duclos",
            "William Guimont-Martin",
            "Gabriel Jeanson",
            "Arthur Larochelle-Tremblay",
            "ThÃ©o Defosse",
            "FrÃ©dÃ©ric Moore",
            "Philippe Nolet",
            "FranÃ§ois Pomerleau",
            "Philippe GiguÃ¨re"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09458",
        "abstract": "Interest in robotics for forest management is growing, but perception in complex, natural environments remains a significant hurdle. Conditions such as heavy occlusion, variable lighting, and dense vegetation pose challenges to automated systems, which are essential for precision forestry, biodiversity monitoring, and the automation of forestry equipment. These tasks rely on advanced perceptual capabilities, such as detection and fine-grained species classification of individual trees. Yet, existing datasets are inadequate to develop such perception systems, as they often focus on urban settings or a limited number of species. To address this, we present SilvaScenes, a new dataset for instance segmentation of tree species from under-canopy images. Collected across five bioclimatic domains in Quebec, Canada, SilvaScenes features 1476 trees from 24 species with annotations from forestry experts. We demonstrate the relevance and challenging nature of our dataset by benchmarking modern deep learning approaches for instance segmentation. Our results show that, while tree segmentation is easy, with a top mean average precision (mAP) of 67.65%, species classification remains a significant challenge with an mAP of only 35.69%. Our dataset and source code will be available at https://github.com/norlab-ulaval/SilvaScenes.",
        "tags": [
            "Detection",
            "Robotics",
            "Segmentation"
        ]
    },
    {
        "id": "241",
        "title": "Failure Prediction at Runtime for Generative Robot Policies",
        "author": [
            "Ralf RÃ¶mer",
            "Adrian Kobras",
            "Luca Worbis",
            "Angela P. Schoellig"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09459",
        "abstract": "Imitation learning (IL) with generative models, such as diffusion and flow matching, has enabled robots to perform complex, long-horizon tasks. However, distribution shifts from unseen environments or compounding action errors can still cause unpredictable and unsafe behavior, leading to task failure. Early failure prediction during runtime is therefore essential for deploying robots in human-centered and safety-critical environments. We propose FIPER, a general framework for Failure Prediction at Runtime for generative IL policies that does not require failure data. FIPER identifies two key indicators of impending failure: (i) out-of-distribution (OOD) observations detected via random network distillation in the policy's embedding space, and (ii) high uncertainty in generated actions measured by a novel action-chunk entropy score. Both failure prediction scores are calibrated using a small set of successful rollouts via conformal prediction. A failure alarm is triggered when both indicators, aggregated over short time windows, exceed their thresholds. We evaluate FIPER across five simulation and real-world environments involving diverse failure modes. Our results demonstrate that FIPER better distinguishes actual failures from benign OOD situations and predicts failures more accurately and earlier than existing methods. We thus consider this work an important step towards more interpretable and safer generative robot policies. Code, data and videos are available at https://tum-lsy.github.io/fiper_website.",
        "tags": [
            "Diffusion",
            "Flow Matching",
            "Robotics"
        ]
    },
    {
        "id": "242",
        "title": "Cross-Platform Narrative Prediction: Leveraging Platform-Invariant Discourse Networks",
        "author": [
            "Patrick Gerard",
            "Luca Luceria",
            "Leonardo Blas",
            "Emilio Ferrara"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09464",
        "abstract": "Online narratives spread unevenly across platforms, with content emerging on one site often appearing on others, hours, days or weeks later. Existing cross-platform information diffusion models often treat platforms as isolated systems, disregarding cross-platform activity that might make these patterns more predictable. In this work, we frame cross-platform prediction as a network proximity problem: rather than tracking individual users across platforms or relying on brittle signals like shared URLs or hashtags, we construct platform-invariant discourse networks that link users through shared narrative engagement. We show that cross-platform neighbor proximity provides a strong predictive signal: adoption patterns follow discourse network structure even without direct cross-platform influence. Our highly-scalable approach substantially outperforms diffusion models and other baselines while requiring less than 3% of active users to make predictions. We also validate our framework through retrospective deployment. We sequentially process a datastream of 5.7M social media posts occurred during the 2024 U.S. election, to simulate real-time collection from four platforms (X, TikTok, Truth Social, and Telegram): our framework successfully identified emerging narratives, including crises-related rumors, yielding over 94% AUC with sufficient lead time to support proactive intervention.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "243",
        "title": "Getting Your Indices in a Row: Full-Text Search for LLM Training Data for Real World",
        "author": [
            "Ines Altemir Marinas",
            "Anastasiia Kucherenko",
            "Alexander Sternfeld",
            "Andrei Kucharavy"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09471",
        "abstract": "The performance of Large Language Models (LLMs) is determined by their training data. Despite the proliferation of open-weight LLMs, access to LLM training data has remained limited. Even for fully open LLMs, the scale of the data makes it all but inscrutable to the general scientific community, despite potentially containing critical data scraped from the internet.\nIn this paper, we present the full-text indexing pipeline for the Apertus LLM training data. Leveraging Elasticsearch parallel indices and the Alps infrastructure, a state-of-the-art, highly energy-efficient arm64 supercluster, we were able to index 8.6T tokens out of 15.2T used to train the Apertus LLM family, creating both a critical LLM safety tool and effectively an offline, curated, open web search engine. Our contribution is threefold. First, we demonstrate that Elasticsearch can be successfully ported onto next-generation arm64-based infrastructure. Second, we demonstrate that full-text indexing at the scale of modern LLM training datasets and the entire open web is feasible and accessible. Finally, we demonstrate that such indices can be used to ensure previously inaccessible jailbreak-agnostic LLM safety.\nWe hope that our findings will be useful to other teams attempting large-scale data indexing and facilitate the general transition towards greener computation.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "244",
        "title": "Hybrid Models for Natural Language Reasoning: The Case of Syllogistic Logic",
        "author": [
            "Manuel Vargas GuzmÃ¡n",
            "Jakub Szymanik",
            "Maciej Malicki"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09472",
        "abstract": "Despite the remarkable progress in neural models, their ability to generalize, a cornerstone for applications like logical reasoning, remains a critical challenge. We delineate two fundamental aspects of this ability: compositionality, the capacity to abstract atomic logical rules underlying complex inferences, and recursiveness, the aptitude to build intricate representations through iterative application of inference rules. In the literature, these two aspects are often confounded together under the umbrella term of generalization. To sharpen this distinction, we investigated the logical generalization capabilities of pre-trained large language models (LLMs) using the syllogistic fragment as a benchmark for natural language reasoning. Though simple, this fragment provides a foundational yet expressive subset of formal logic that supports controlled evaluation of essential reasoning abilities. Our findings reveal a significant disparity: while LLMs demonstrate reasonable proficiency in recursiveness, they struggle with compositionality. To overcome these limitations and establish a reliable logical prover, we propose a hybrid architecture integrating symbolic reasoning with neural computation. This synergistic interaction enables robust and efficient inference, neural components accelerate processing, while symbolic reasoning ensures completeness. Our experiments show that high efficiency is preserved even with relatively small neural components. As part of our proposed methodology, this analysis gives a rationale and highlights the potential of hybrid models to effectively address key generalization barriers in neural reasoning systems.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "245",
        "title": "D-TPT: Dimensional Entropy Maximization for Calibrating Test-Time Prompt Tuning in Vision-Language Models",
        "author": [
            "Jisu Han",
            "Wonjun Hwang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09473",
        "abstract": "Test-time adaptation paradigm provides flexibility towards domain shifts by performing immediate adaptation on unlabeled target data from the source model. Vision-Language Models (VLMs) leverage their generalization capabilities for diverse downstream tasks, and test-time prompt tuning has emerged as a prominent solution for adapting VLMs. In this work, we explore contrastive VLMs and identify the modality gap caused by a single dominant feature dimension across modalities. We observe that the dominant dimensions in both text and image modalities exhibit high predictive sensitivity, and that constraining their influence can improve calibration error. Building on this insight, we propose dimensional entropy maximization that regularizes the distribution of textual features toward uniformity to mitigate the dependency of dominant dimensions. Our method alleviates the degradation of calibration performance in test-time prompt tuning, offering a simple yet effective solution to enhance the reliability of VLMs in real-world deployment scenarios.",
        "tags": [
            "VLM"
        ]
    },
    {
        "id": "246",
        "title": "Multimodal Policy Internalization for Conversational Agents",
        "author": [
            "Zhenhailong Wang",
            "Jiateng Liu",
            "Amin Fazel",
            "Ritesh Sarkhel",
            "Xing Fan",
            "Xiang Li",
            "Chenlei Guo",
            "Heng Ji",
            "Ruhi Sarikaya"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09474",
        "abstract": "Modern conversational agents like ChatGPT and Alexa+ rely on predefined policies specifying metadata, response styles, and tool-usage rules. As these LLM-based systems expand to support diverse business and user queries, such policies, often implemented as in-context prompts, are becoming increasingly complex and lengthy, making faithful adherence difficult and imposing large fixed computational costs. With the rise of multimodal agents, policies that govern visual and multimodal behaviors are critical but remain understudied. Prior prompt-compression work mainly shortens task templates and demonstrations, while existing policy-alignment studies focus only on text-based safety rules. We introduce Multimodal Policy Internalization (MPI), a new task that internalizes reasoning-intensive multimodal policies into model parameters, enabling stronger policy-following without including the policy during inference. MPI poses unique data and algorithmic challenges. We build two datasets spanning synthetic and real-world decision-making and tool-using tasks and propose TriMPI, a three-stage training framework. TriMPI first injects policy knowledge via continual pretraining, then performs supervised finetuning, and finally applies PolicyRollout, a GRPO-style reinforcement learning extension that augments rollouts with policy-aware responses for grounded exploration. TriMPI achieves notable gains in end-to-end accuracy, generalization, and robustness to forgetting. As the first work on multimodal policy internalization, we provide datasets, training recipes, and comprehensive evaluations to foster future research. Project page: https://mikewangwzhl.github.io/TriMPI.",
        "tags": [
            "GPT",
            "GRPO",
            "LLM",
            "RL"
        ]
    },
    {
        "id": "247",
        "title": "Few-shot multi-token DreamBooth with LoRa for style-consistent character generation",
        "author": [
            "Ruben Pascual",
            "Mikel Sesma-Sara",
            "Aranzazu Jurio",
            "Daniel Paternain",
            "Mikel Galar"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09475",
        "abstract": "The audiovisual industry is undergoing a profound transformation as it is integrating AI developments not only to automate routine tasks but also to inspire new forms of art. This paper addresses the problem of producing a virtually unlimited number of novel characters that preserve the artistic style and shared visual traits of a small set of human-designed reference characters, thus broadening creative possibilities in animation, gaming, and related domains. Our solution builds upon DreamBooth, a well-established fine-tuning technique for text-to-image diffusion models, and adapts it to tackle two core challenges: capturing intricate character details beyond textual prompts and the few-shot nature of the training data. To achieve this, we propose a multi-token strategy, using clustering to assign separate tokens to individual characters and their collective style, combined with LoRA-based parameter-efficient fine-tuning. By removing the class-specific regularization set and introducing random tokens and embeddings during generation, our approach allows for unlimited character creation while preserving the learned style. We evaluate our method on five small specialized datasets, comparing it to relevant baselines using both quantitative metrics and a human evaluation study. Our results demonstrate that our approach produces high-quality, diverse characters while preserving the distinctive aesthetic features of the reference characters, with human evaluation further reinforcing its effectiveness and highlighting the potential of our method.",
        "tags": [
            "Diffusion",
            "LoRA",
            "Text-to-Image"
        ]
    },
    {
        "id": "248",
        "title": "CRPS-LAM: Regional ensemble weather forecasting from matching marginals",
        "author": [
            "Erik Larsson",
            "Joel Oskarsson",
            "Tomas Landelius",
            "Fredrik Lindsten"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09484",
        "abstract": "Machine learning for weather prediction increasingly relies on ensemble methods to provide probabilistic forecasts. Diffusion-based models have shown strong performance in Limited-Area Modeling (LAM) but remain computationally expensive at sampling time. Building on the success of global weather forecasting models trained based on Continuous Ranked Probability Score (CRPS), we introduce CRPS-LAM, a probabilistic LAM forecasting model trained with a CRPS-based objective. By sampling and injecting a single latent noise vector into the model, CRPS-LAM generates ensemble members in a single forward pass, achieving sampling speeds up to 39 times faster than a diffusion-based model. We evaluate the model on the MEPS regional dataset, where CRPS-LAM matches the low errors of diffusion models. By retaining also fine-scale forecast details, the method stands out as an effective approach for probabilistic regional weather forecasting",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "249",
        "title": "Two-Stage Gaussian Splatting Optimization for Outdoor Scene Reconstruction",
        "author": [
            "Deborah Pintani",
            "Ariel Caputo",
            "Noah Lewis",
            "Marc Stamminger",
            "Fabio Pellacini",
            "Andrea Giachetti"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09489",
        "abstract": "Outdoor scene reconstruction remains challenging due to the stark contrast between well-textured, nearby regions and distant backgrounds dominated by low detail, uneven illumination, and sky effects. We introduce a two-stage Gaussian Splatting framework that explicitly separates and optimizes these regions, yielding higher-fidelity novel view synthesis. In stage one, background primitives are initialized within a spherical shell and optimized using a loss that combines a background-only photometric term with two geometric regularizers: one constraining Gaussians to remain inside the shell, and another aligning them with local tangential planes. In stage two, foreground Gaussians are initialized from a Structure-from-Motion reconstruction, added and refined using the standard rendering loss, while the background set remains fixed but contributes to the final image formation. Experiments on diverse outdoor datasets show that our method reduces background artifacts and improves perceptual quality compared to state-of-the-art baselines. Moreover, the explicit background separation enables automatic, object-free environment map estimation, opening new possibilities for photorealistic outdoor rendering and mixed-reality applications.",
        "tags": [
            "Gaussian Splatting"
        ]
    },
    {
        "id": "250",
        "title": "Precoder Design in Multi-User FDD Systems with VQ-VAE and GNN",
        "author": [
            "Srikar Allaparapu",
            "Michael Baur",
            "Benedikt BÃ¶ck",
            "Michael Joham",
            "Wolfgang Utschick"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09495",
        "abstract": "Robust precoding is efficiently feasible in frequency division duplex (FDD) systems by incorporating the learnt statistics of the propagation environment through a generative model. We build on previous work that successfully designed site-specific precoders based on a combination of Gaussian mixture models (GMMs) and graph neural networks (GNNs). In this paper, by utilizing a vector quantized-variational autoencoder (VQ-VAE), we circumvent one of the key drawbacks of GMMs, i.e., the number of GMM components scales exponentially to the feedback bits. In addition, the deep learning architecture of the VQ-VAE allows us to jointly train the GNN together with VQ-VAE along with pilot optimization forming an end-to-end (E2E) model, resulting in considerable performance gains in sum rate for multi-user wireless systems. Simulations demonstrate the superiority of the proposed frameworks over the conventional methods involving the sub-discrete Fourier transform (DFT) pilot matrix and iterative precoder algorithms enabling the deployment of systems characterized by fewer pilots or feedback bits.",
        "tags": [
            "VAE"
        ]
    },
    {
        "id": "251",
        "title": "PhysToolBench: Benchmarking Physical Tool Understanding for MLLMs",
        "author": [
            "Zixin Zhang",
            "Kanghao Chen",
            "Xingwang Lin",
            "Lutao Jiang",
            "Xu Zheng",
            "Yuanhuiyi Lyu",
            "Litao Guo",
            "Yinchuan Li",
            "Ying-Cong Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09507",
        "abstract": "The ability to use, understand, and create tools is a hallmark of human intelligence, enabling sophisticated interaction with the physical world. For any general-purpose intelligent agent to achieve true versatility, it must also master these fundamental skills. While modern Multimodal Large Language Models (MLLMs) leverage their extensive common knowledge for high-level planning in embodied AI and in downstream Vision-Language-Action (VLA) models, the extent of their true understanding of physical tools remains unquantified. To bridge this gap, we present PhysToolBench, the first benchmark dedicated to evaluating the comprehension of physical tools by MLLMs. Our benchmark is structured as a Visual Question Answering (VQA) dataset comprising over 1,000 image-text pairs. It assesses capabilities across three distinct difficulty levels: (1) Tool Recognition: Requiring the recognition of a tool's primary function. (2) Tool Understanding: Testing the ability to grasp the underlying principles of a tool's operation. (3) Tool Creation: Challenging the model to fashion a new tool from surrounding objects when conventional options are unavailable. Our comprehensive evaluation of 32 MLLMs-spanning proprietary, open-source, specialized embodied, and backbones in VLAs-reveals a significant deficiency in tool understanding. Furthermore, we provide an in-depth analysis and propose preliminary solutions. Code and dataset are publicly available.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "252",
        "title": "MRMR: A Realistic and Expert-Level Multidisciplinary Benchmark for Reasoning-Intensive Multimodal Retrieval",
        "author": [
            "Siyue Zhang",
            "Yuan Gao",
            "Xiao Zhou",
            "Yilun Zhao",
            "Tingyu Song",
            "Arman Cohan",
            "Anh Tuan Luu",
            "Chen Zhao"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09510",
        "abstract": "We introduce MRMR, the first expert-level multidisciplinary multimodal retrieval benchmark requiring intensive reasoning. MRMR contains 1,502 queries spanning 23 domains, with positive documents carefully verified by human experts. Compared to prior benchmarks, MRMR introduces three key advancements. First, it challenges retrieval systems across diverse areas of expertise, enabling fine-grained model comparison across domains. Second, queries are reasoning-intensive, with images requiring deeper interpretation such as diagnosing microscopic slides. We further introduce Contradiction Retrieval, a novel task requiring models to identify conflicting concepts. Finally, queries and documents are constructed as image-text interleaved sequences. Unlike earlier benchmarks restricted to single images or unimodal documents, MRMR offers a realistic setting with multi-image queries and mixed-modality corpus documents. We conduct an extensive evaluation of 4 categories of multimodal retrieval systems and 14 frontier models on MRMR. The text embedding model Qwen3-Embedding with LLM-generated image captions achieves the highest performance, highlighting substantial room for improving multimodal retrieval models. Although latest multimodal models such as Ops-MM-Embedding perform competitively on expert-domain queries, they fall short on reasoning-intensive tasks. We believe that MRMR paves the way for advancing multimodal retrieval in more realistic and challenging scenarios.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "253",
        "title": "StatEval: A Comprehensive Benchmark for Large Language Models in Statistics",
        "author": [
            "Yuchen Lu",
            "Run Yang",
            "Yichen Zhang",
            "Shuguang Yu",
            "Runpeng Dai",
            "Ziwei Wang",
            "Jiayi Xiang",
            "Wenxin E",
            "Siran Gao",
            "Xinyao Ruan",
            "Yirui Huang",
            "Chenjing Xi",
            "Haibo Hu",
            "Yueming Fu",
            "Qinglan Yu",
            "Xiaobing Wei",
            "Jiani Gu",
            "Rui Sun",
            "Jiaxuan Jia",
            "Fan Zhou"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09517",
        "abstract": "Large language models (LLMs) have demonstrated remarkable advances in mathematical and logical reasoning, yet statistics, as a distinct and integrative discipline, remains underexplored in benchmarking efforts. To address this gap, we introduce \\textbf{StatEval}, the first comprehensive benchmark dedicated to statistics, spanning both breadth and depth across difficulty levels. StatEval consists of 13,817 foundational problems covering undergraduate and graduate curricula, together with 2374 research-level proof tasks extracted from leading journals. To construct the benchmark, we design a scalable multi-agent pipeline with human-in-the-loop validation that automates large-scale problem extraction, rewriting, and quality control, while ensuring academic rigor. We further propose a robust evaluation framework tailored to both computational and proof-based tasks, enabling fine-grained assessment of reasoning ability. Experimental results reveal that while closed-source models such as GPT5-mini achieve below 57\\% on research-level problems, with open-source models performing significantly lower. These findings highlight the unique challenges of statistical reasoning and the limitations of current LLMs. We expect StatEval to serve as a rigorous benchmark for advancing statistical intelligence in large language models. All data and code are available on our web platform: https://stateval.github.io/.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "254",
        "title": "Can We Reliably Rank Model Performance across Domains without Labeled Data?",
        "author": [
            "Veronica Rammouz",
            "Aaron Gonzalez",
            "Carlos Cruzportillo",
            "Adrian Tan",
            "Nicole Beebe",
            "Anthony Rios"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09519",
        "abstract": "Estimating model performance without labels is an important goal for understanding how NLP models generalize. While prior work has proposed measures based on dataset similarity or predicted correctness, it remains unclear when these estimates produce reliable performance rankings across domains. In this paper, we analyze the factors that affect ranking reliability using a two-step evaluation setup with four base classifiers and several large language models as error predictors. Experiments on the GeoOLID and Amazon Reviews datasets, spanning 15 domains, show that large language model-based error predictors produce stronger and more consistent rank correlations with true accuracy than drift-based or zero-shot baselines. Our analysis reveals two key findings: ranking is more reliable when performance differences across domains are larger, and when the error model's predictions align with the base model's true failure patterns. These results clarify when performance estimation methods can be trusted and provide guidance for their use in cross-domain model evaluation.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "255",
        "title": "Dynamic Quadrupedal Legged and Aerial Locomotion via Structure Repurposing",
        "author": [
            "Chenghao Wang",
            "Kaushik Venkatesh Krishnamurthy",
            "Shreyansh Pitroda",
            "Adarsh Salagame",
            "Ioannis Mandralis",
            "Eric Sihite",
            "Alireza Ramezani",
            "Morteza Gharib"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09526",
        "abstract": "Multi-modal ground-aerial robots have been extensively studied, with a significant challenge lying in the integration of conflicting requirements across different modes of operation. The Husky robot family, developed at Northeastern University, and specifically the Husky v.2 discussed in this study, addresses this challenge by incorporating posture manipulation and thrust vectoring into multi-modal locomotion through structure repurposing. This quadrupedal robot features leg structures that can be repurposed for dynamic legged locomotion and flight. In this paper, we present the hardware design of the robot and report primary results on dynamic quadrupedal legged locomotion and hovering.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "256",
        "title": "Accent-Invariant Automatic Speech Recognition via Saliency-Driven Spectrogram Masking",
        "author": [
            "Mohammad Hossein Sameti",
            "Sepehr Harfi Moridani",
            "Ali Zarean",
            "Hossein Sameti"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09528",
        "abstract": "Pre-trained transformer-based models have significantly advanced automatic speech recognition (ASR), yet they remain sensitive to accent and dialectal variations, resulting in elevated word error rates (WER) in linguistically diverse languages such as English and Persian. To address this challenge, we propose an accent-invariant ASR framework that integrates accent and dialect classification into the recognition pipeline. Our approach involves training a spectrogram-based classifier to capture accent-specific cues, masking the regions most influential to its predictions, and using the masked spectrograms for data augmentation. This enhances the robustness of ASR models against accent variability. We evaluate the method using both English and Persian speech. For Persian, we introduce a newly collected dataset spanning multiple regional accents, establishing the first systematic benchmark for accent variation in Persian ASR that fills a critical gap in multilingual speech research and provides a foundation for future studies on low-resource, linguistically diverse languages. Experimental results with the Whisper model demonstrate that our masking and augmentation strategy yields substantial WER reductions in both English and Persian settings, confirming the effectiveness of the approach. This research advances the development of multilingual ASR systems that are resilient to accent and dialect diversity. Code and dataset are publicly available at: https://github.com/MH-Sameti/Accent_invariant_ASR",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "257",
        "title": "Mitigating Overthinking through Reasoning Shaping",
        "author": [
            "Feifan Song",
            "Shaohang Wei",
            "Bofei Gao",
            "Yejie Wang",
            "Wen Luo",
            "Wei Li",
            "Linli Yao",
            "Weimin Xiong",
            "Liang Chen",
            "Tianyu Liu",
            "Houfeng Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09535",
        "abstract": "Large reasoning models (LRMs) boosted by Reinforcement Learning from Verifier Reward (RLVR) have shown great power in problem solving, yet they often cause overthinking: excessive, meandering reasoning that inflates computational cost. Prior designs of penalization in RLVR manage to reduce token consumption while often harming model performance, which arises from the oversimplicity of token-level supervision. In this paper, we argue that the granularity of supervision plays a crucial role in balancing efficiency and accuracy, and propose Group Relative Segment Penalization (GRSP), a step-level method to regularize reasoning. Since preliminary analyses show that reasoning segments are strongly correlated with token consumption and model performance, we design a length-aware weighting mechanism across segment clusters. Extensive experiments demonstrate that GRSP achieves superior token efficiency without heavily compromising accuracy, especially the advantages with harder problems. Moreover, GRSP stabilizes RL training and scales effectively across model sizes.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "258",
        "title": "Evaluating Robustness of Large Language Models Against Multilingual Typographical Errors",
        "author": [
            "Yihong Liu",
            "Raoyuan Zhao",
            "Lena Altinger",
            "Hinrich SchÃ¼tze",
            "Michael A. Hedderich"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09536",
        "abstract": "Large language models (LLMs) are increasingly deployed in multilingual, real-world applications with user inputs -- naturally introducing typographical errors (typos). Yet most benchmarks assume clean input, leaving the robustness of LLMs to typos across languages largely underexplored. To address this gap, we introduce MulTypo, a multilingual typo generation algorithm that simulates human-like errors based on language-specific keyboard layouts and typing behavior. We evaluate 18 open-source LLMs across three model families and five downstream tasks spanning language inference, multi-choice question answering, mathematical reasoning, and machine translation tasks. Our results show that typos consistently degrade performance, particularly in generative tasks and those requiring reasoning -- while the natural language inference task is comparatively more robust. Instruction tuning improves clean-input performance but may increase brittleness under noise. We also observe language-dependent robustness: high-resource languages are generally more robust than low-resource ones, and translation from English is more robust than translation into English. Our findings underscore the need for noise-aware training and multilingual robustness evaluation. We make our code and data publicly available.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "259",
        "title": "FLOWING: Implicit Neural Flows for Structure-Preserving Morphing",
        "author": [
            "Arthur Bizzi",
            "Matias Grynberg",
            "Vitor Matias",
            "Daniel Perazzo",
            "JoÃ£o Paulo Lima",
            "Luiz Velho",
            "Nuno GonÃ§alves",
            "JoÃ£o Pereira",
            "Guilherme Schardong",
            "Tiago Novello"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09537",
        "abstract": "Morphing is a long-standing problem in vision and computer graphics, requiring a time-dependent warping for feature alignment and a blending for smooth interpolation. Recently, multilayer perceptrons (MLPs) have been explored as implicit neural representations (INRs) for modeling such deformations, due to their meshlessness and differentiability; however, extracting coherent and accurate morphings from standard MLPs typically relies on costly regularizations, which often lead to unstable training and prevent effective feature alignment. To overcome these limitations, we propose FLOWING (FLOW morphING), a framework that recasts warping as the construction of a differential vector flow, naturally ensuring continuity, invertibility, and temporal coherence by encoding structural flow properties directly into the network architectures. This flow-centric approach yields principled and stable transformations, enabling accurate and structure-preserving morphing of both 2D images and 3D shapes. Extensive experiments across a range of applications - including face and image morphing, as well as Gaussian Splatting morphing - show that FLOWING achieves state-of-the-art morphing quality with faster convergence. Code and pretrained models are available at http://schardong.github.io/flowing.",
        "tags": [
            "3D",
            "Gaussian Splatting"
        ]
    },
    {
        "id": "260",
        "title": "SPG: Sandwiched Policy Gradient for Masked Diffusion Language Models",
        "author": [
            "Chengyu Wang",
            "Paria Rashidinejad",
            "DiJia Su",
            "Song Jiang",
            "Sid Wang",
            "Siyan Zhao",
            "Cai Zhou",
            "Shannon Zejiang Shen",
            "Feiyu Chen",
            "Tommi Jaakkola",
            "Yuandong Tian",
            "Bo Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09541",
        "abstract": "Diffusion large language models (dLLMs) are emerging as an efficient alternative to autoregressive models due to their ability to decode multiple tokens in parallel. However, aligning dLLMs with human preferences or task-specific rewards via reinforcement learning (RL) is challenging because their intractable log-likelihood precludes the direct application of standard policy gradient methods. While prior work uses surrogates like the evidence lower bound (ELBO), these one-sided approximations can introduce significant policy gradient bias. To address this, we propose the Sandwiched Policy Gradient (SPG) that leverages both an upper and a lower bound of the true log-likelihood. Experiments show that SPG significantly outperforms baselines based on ELBO or one-step estimation. Specifically, SPG improves the accuracy over state-of-the-art RL methods for dLLMs by 3.6% in GSM8K, 2.6% in MATH500, 18.4% in Countdown and 27.0% in Sudoku.",
        "tags": [
            "Diffusion",
            "LLM",
            "RL"
        ]
    },
    {
        "id": "261",
        "title": "Guiding Energy-Efficient Locomotion through Impact Mitigation Rewards",
        "author": [
            "Chenghao Wang",
            "Arjun Viswanathan",
            "Eric Sihite",
            "Alireza Ramezani"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09543",
        "abstract": "Animals achieve energy-efficient locomotion by their implicit passive dynamics, a marvel that has captivated roboticists for http://decades.Recently, methods incorporated Adversarial Motion Prior (AMP) and Reinforcement learning (RL) shows promising progress to replicate Animals' naturalistic motion. However, such imitation learning approaches predominantly capture explicit kinematic patterns, so-called gaits, while overlooking the implicit passive dynamics. This work bridges this gap by incorporating a reward term guided by Impact Mitigation Factor (IMF), a physics-informed metric that quantifies a robot's ability to passively mitigate impacts. By integrating IMF with AMP, our approach enables RL policies to learn both explicit motion trajectories from animal reference motion and the implicit passive dynamic. We demonstrate energy efficiency improvements of up to 32%, as measured by the Cost of Transport (CoT), across both AMP and handcrafted reward structure.",
        "tags": [
            "CoT",
            "RL",
            "Robotics"
        ]
    },
    {
        "id": "262",
        "title": "Beyond Surface Reasoning: Unveiling the True Long Chain-of-Thought Capacity of Diffusion Large Language Models",
        "author": [
            "Qiguang Chen",
            "Hanjing Li",
            "Libo Qin",
            "Dengyun Peng",
            "Jinhao Liu",
            "Jiangyi Wang",
            "Chengyue Wu",
            "Xie Chen",
            "Yantao Du",
            "Wanxiang Che"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09544",
        "abstract": "Recently, Diffusion Large Language Models (DLLMs) have offered high throughput and effective sequential reasoning, making them a competitive alternative to autoregressive LLMs (ALLMs). However, parallel decoding, which enables simultaneous token updates, conflicts with the causal order often required for rigorous reasoning. We first identify this conflict as the core Parallel-Sequential Contradiction (PSC). Behavioral analyses in both simple and complex reasoning tasks show that DLLMs exhibit genuine parallelism only for directly decidable outputs. As task difficulty increases, they revert to autoregressive-like behavior, a limitation exacerbated by autoregressive prompting, which nearly doubles the number of decoding steps with remasking without improving quality. Moreover, PSC restricts DLLMs' self-reflection, reasoning depth, and exploratory breadth. To further characterize PSC, we introduce three scaling dimensions for DLLMs: parallel, diffusion, and sequential. Empirically, while parallel scaling yields consistent improvements, diffusion and sequential scaling are constrained by PSC. Based on these findings, we propose several practical mitigations, parallel-oriented prompting, diffusion early stopping, and parallel scaling, to reduce PSC-induced ineffectiveness and inefficiencies.",
        "tags": [
            "CoT",
            "Diffusion",
            "LLM"
        ]
    },
    {
        "id": "263",
        "title": "Multi-Level Hybrid Monte Carlo / Deterministic Methods for Particle Transport Problems",
        "author": [
            "Vincent N. Novellino",
            "Dmitriy Y. Anistratov"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09545",
        "abstract": "This paper presents multi-level hybrid transport (MLHT) methods for solving the neutral particle Boltzmann transport equation. The proposed MLHT methods are formulated on a sequence of spatial grids using a multi-level Monte Carlo (MLMC) approach. The general MLMC algorithm is defined by the recursive estimation of the expected value of a solution functional's correction with respect to a neighboring grid. MLMC theory optimizes the total computational cost for estimating a functional to within a target accuracy. The proposed MLHT algorithms are based on the quasidiffusion (Variable Eddington Factor) and second-moment methods. For these methods, the low-order equations for the angular moments of the high-order transport solution are discretized in space. Monte Carlo techniques compute the closures for the low-order equations; then, the equations are solved, yielding a single realization of the global flux solution. The ensemble average of the realizations yields the level solution. The results for 1-D slab transport problems demonstrates weak convergence of the functionals considered. We observe that the variance of the correction factors decreases faster than the increase in computational costs of generating an MLMC sample. In the problems considered, the variance and costs of the MLMC solution are driven by the coarse grid calculations.",
        "tags": [
            "FLUX"
        ]
    },
    {
        "id": "264",
        "title": "A Comprehensive Evaluation of Multilingual Chain-of-Thought Reasoning: Performance, Consistency, and Faithfulness Across Languages",
        "author": [
            "Raoyuan Zhao",
            "Yihong Liu",
            "Hinrich SchÃ¼tze",
            "Michael A. Hedderich"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09555",
        "abstract": "Large reasoning models (LRMs) increasingly rely on step-by-step Chain-of-Thought (CoT) reasoning to improve task performance, particularly in high-resource languages such as English. While recent work has examined final-answer accuracy in multilingual settings, the thinking traces themselves, i.e., the intermediate steps that lead to the final answer, remain underexplored. In this paper, we present the first comprehensive study of multilingual CoT reasoning, evaluating three key dimensions: performance, consistency, and faithfulness. We begin by measuring language compliance, answer accuracy, and answer consistency when LRMs are explicitly instructed or prompt-hacked to think in a target language, revealing strong language preferences and divergent performance across languages. Next, we assess crosslingual consistency of thinking traces by interchanging them between languages. We find that the quality and effectiveness of thinking traces vary substantially depending on the prompt language. Finally, we adapt perturbation-based techniques -- i.e., truncation and error injection -- to probe the faithfulness of thinking traces across languages, showing that models rely on traces to varying degrees. We release our code and data to support future research.",
        "tags": [
            "CoT"
        ]
    },
    {
        "id": "265",
        "title": "Doc2Query++: Topic-Coverage based Document Expansion and its Application to Dense Retrieval via Dual-Index Fusion",
        "author": [
            "Tzu-Lin Kuo",
            "Wei-Ning Chiu",
            "Wei-Yun Ma",
            "Pu-Jen Cheng"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09557",
        "abstract": "Document expansion (DE) via query generation tackles vocabulary mismatch in sparse retrieval, yet faces limitations: uncontrolled generation producing hallucinated or redundant queries with low diversity; poor generalization from in-domain training (e.g., MS MARCO) to out-of-domain data like BEIR; and noise from concatenation harming dense retrieval. While Large Language Models (LLMs) enable cross-domain query generation, basic prompting lacks control, and taxonomy-based methods rely on domain-specific structures, limiting applicability. To address these challenges, we introduce Doc2Query++, a DE framework that structures query generation by first inferring a document's latent topics via unsupervised topic modeling for cross-domain applicability, then using hybrid keyword selection to create a diverse and relevant keyword set per document. This guides LLM not only to leverage keywords, which ensure comprehensive topic representation, but also to reduce redundancy through diverse, relevant terms. To prevent noise from query appending in dense retrieval, we propose Dual-Index Fusion strategy that isolates text and query signals, boosting performance in dense settings. Extensive experiments show Doc2Query++ significantly outperforms state-of-the-art baselines, achieving substantial gains in MAP, nDCG@10 and Recall@100 across diverse datasets on both sparse and dense retrieval.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "266",
        "title": "AutoPR: Let's Automate Your Academic Promotion!",
        "author": [
            "Qiguang Chen",
            "Zheng Yan",
            "Mingda Yang",
            "Libo Qin",
            "Yixin Yuan",
            "Hanjing Li",
            "Jinhao Liu",
            "Yiyan Ji",
            "Dengyun Peng",
            "Jiannan Guan",
            "Mengkang Hu",
            "Yantao Du",
            "Wanxiang Che"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09558",
        "abstract": "As the volume of peer-reviewed research surges, scholars increasingly rely on social platforms for discovery, while authors invest considerable effort in promoting their work to ensure visibility and citations. To streamline this process and reduce the reliance on human effort, we introduce Automatic Promotion (AutoPR), a novel task that transforms research papers into accurate, engaging, and timely public content. To enable rigorous evaluation, we release PRBench, a multimodal benchmark that links 512 peer-reviewed articles to high-quality promotional posts, assessing systems along three axes: Fidelity (accuracy and tone), Engagement (audience targeting and appeal), and Alignment (timing and channel optimization). We also introduce PRAgent, a multi-agent framework that automates AutoPR in three stages: content extraction with multimodal preparation, collaborative synthesis for polished outputs, and platform-specific adaptation to optimize norms, tone, and tagging for maximum reach. When compared to direct LLM pipelines on PRBench, PRAgent demonstrates substantial improvements, including a 604% increase in total watch time, a 438% rise in likes, and at least a 2.9x boost in overall engagement. Ablation studies show that platform modeling and targeted promotion contribute the most to these gains. Our results position AutoPR as a tractable, measurable research problem and provide a roadmap for scalable, impactful automated scholarly communication.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "267",
        "title": "TC-LoRA: Temporally Modulated Conditional LoRA for Adaptive Diffusion Control",
        "author": [
            "Minkyoung Cho",
            "Ruben Ohana",
            "Christian Jacobsen",
            "Adityan Jothi",
            "Min-Hung Chen",
            "Z. Morley Mao",
            "Ethem Can"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09561",
        "abstract": "Current controllable diffusion models typically rely on fixed architectures that modify intermediate activations to inject guidance conditioned on a new modality. This approach uses a static conditioning strategy for a dynamic, multi-stage denoising process, limiting the model's ability to adapt its response as the generation evolves from coarse structure to fine detail. We introduce TC-LoRA (Temporally Modulated Conditional LoRA), a new paradigm that enables dynamic, context-aware control by conditioning the model's weights directly. Our framework uses a hypernetwork to generate LoRA adapters on-the-fly, tailoring weight modifications for the frozen backbone at each diffusion step based on time and the user's condition. This mechanism enables the model to learn and execute an explicit, adaptive strategy for applying conditional guidance throughout the entire generation process. Through experiments on various data domains, we demonstrate that this dynamic, parametric control significantly enhances generative fidelity and adherence to spatial conditions compared to static, activation-based methods. TC-LoRA establishes an alternative approach in which the model's conditioning strategy is modified through a deeper functional adaptation of its weights, allowing control to align with the dynamic demands of the task and generative stage.",
        "tags": [
            "Diffusion",
            "LoRA"
        ]
    },
    {
        "id": "268",
        "title": "Dyna-Mind: Learning to Simulate from Experience for Better AI Agents",
        "author": [
            "Xiao Yu",
            "Baolin Peng",
            "Michel Galley",
            "Hao Cheng",
            "Qianhui Wu",
            "Janardhan Kulkarni",
            "Suman Nath",
            "Zhou Yu",
            "Jianfeng Gao"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09577",
        "abstract": "Reasoning models have recently shown remarkable progress in domains such as math and coding. However, their expert-level abilities in math and coding contrast sharply with their performance in long-horizon, interactive tasks such as web navigation and computer/phone-use. Inspired by literature on human cognition, we argue that current AI agents need ''vicarious trial and error'' - the capacity to mentally simulate alternative futures before acting - in order to enhance their understanding and performance in complex interactive environments. We introduce Dyna-Mind, a two-stage training framework that explicitly teaches (V)LM agents to integrate such simulation into their reasoning. In stage 1, we introduce Reasoning with Simulations (ReSim), which trains the agent to generate structured reasoning traces from expanded search trees built from real experience gathered through environment interactions. ReSim thus grounds the agent's reasoning in faithful world dynamics and equips it with the ability to anticipate future states in its reasoning. In stage 2, we propose Dyna-GRPO, an online reinforcement learning method to further strengthen the agent's simulation and decision-making ability by using both outcome rewards and intermediate states as feedback from real rollouts. Experiments on two synthetic benchmarks (Sokoban and ALFWorld) and one realistic benchmark (AndroidWorld) demonstrate that (1) ReSim effectively infuses simulation ability into AI agents, and (2) Dyna-GRPO leverages outcome and interaction-level signals to learn better policies for long-horizon, planning-intensive tasks. Together, these results highlight the central role of simulation in enabling AI agents to reason, plan, and act more effectively in the ever more challenging environments.",
        "tags": [
            "GRPO",
            "RL"
        ]
    },
    {
        "id": "269",
        "title": "GraphMERT: Efficient and Scalable Distillation of Reliable Knowledge Graphs from Unstructured Data",
        "author": [
            "Margarita Belova",
            "Jiaxin Xiao",
            "Shikhar Tuli",
            "Niraj K. Jha"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09580",
        "abstract": "Researchers have pursued neurosymbolic artificial intelligence (AI) applications for nearly three decades because symbolic components provide abstraction while neural components provide generalization. Thus, a marriage of the two components can lead to rapid advancements in AI. Yet, the field has not realized this promise since most neurosymbolic AI frameworks fail to scale. In addition, the implicit representations and approximate reasoning of neural approaches limit interpretability and trust. Knowledge graphs (KGs), a gold-standard representation of explicit semantic knowledge, can address the symbolic side. However, automatically deriving reliable KGs from text corpora has remained an open problem. We address these challenges by introducing GraphMERT, a tiny graphical encoder-only model that distills high-quality KGs from unstructured text corpora and its own internal representations. GraphMERT and its equivalent KG form a modular neurosymbolic stack: neural learning of abstractions; symbolic KGs for verifiable reasoning. GraphMERT + KG is the first efficient and scalable neurosymbolic model to achieve state-of-the-art benchmark accuracy along with superior symbolic representations relative to baselines.\nConcretely, we target reliable domain-specific KGs that are both (1) factual (with provenance) and (2) valid (ontology-consistent relations with domain-appropriate semantics). When a large language model (LLM), e.g., Qwen3-32B, generates domain-specific KGs, it falls short on reliability due to prompt sensitivity, shallow domain expertise, and hallucinated relations. On text obtained from PubMed papers on diabetes, our 80M-parameter GraphMERT yields a KG with a 69.8% FActScore; a 32B-parameter baseline LLM yields a KG that achieves only 40.2% FActScore. The GraphMERT KG also attains a higher ValidityScore of 68.8%, versus 43.0% for the LLM baseline.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "270",
        "title": "Vision Language Models: A Survey of 26K Papers",
        "author": [
            "Fengming Lin"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09586",
        "abstract": "We present a transparent, reproducible measurement of research trends across 26,104 accepted papers from CVPR, ICLR, and NeurIPS spanning 2023-2025. Titles and abstracts are normalized, phrase-protected, and matched against a hand-crafted lexicon to assign up to 35 topical labels and mine fine-grained cues about tasks, architectures, training regimes, objectives, datasets, and co-mentioned modalities. The analysis quantifies three macro shifts: (1) a sharp rise of multimodal vision-language-LLM work, which increasingly reframes classic perception as instruction following and multi-step reasoning; (2) steady expansion of generative methods, with diffusion research consolidating around controllability, distillation, and speed; and (3) resilient 3D and video activity, with composition moving from NeRFs to Gaussian splatting and a growing emphasis on human- and agent-centric understanding. Within VLMs, parameter-efficient adaptation like prompting/adapters/LoRA and lightweight vision-language bridges dominate; training practice shifts from building encoders from scratch to instruction tuning and finetuning strong backbones; contrastive objectives recede relative to cross-entropy/ranking and distillation. Cross-venue comparisons show CVPR has a stronger 3D footprint and ICLR the highest VLM share, while reliability themes such as efficiency or robustness diffuse across areas. We release the lexicon and methodology to enable auditing and extension. Limitations include lexicon recall and abstract-only scope, but the longitudinal signals are consistent across venues and years.",
        "tags": [
            "3D",
            "Diffusion",
            "Gaussian Splatting",
            "LLM",
            "LoRA",
            "VLM"
        ]
    },
    {
        "id": "271",
        "title": "Mind-Paced Speaking: A Dual-Brain Approach to Real-Time Reasoning in Spoken Language Models",
        "author": [
            "Donghang Wu",
            "Haoyang Zhang",
            "Jun Chen",
            "Xiangyu",
            "Zhang",
            "Hexin Liu",
            "Eng Siong Chng",
            "Fei Tian",
            "Xuerui Yang",
            "Xiangyu Zhang",
            "Daxin Jiang",
            "Gang Yu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09592",
        "abstract": "Real-time Spoken Language Models (SLMs) struggle to leverage Chain-of-Thought (CoT) reasoning due to the prohibitive latency of generating the entire thought process sequentially. Enabling SLMs to think while speaking, similar to humans, is attracting increasing attention. We present, for the first time, Mind-Paced Speaking (MPS), a brain-inspired framework that enables high-fidelity, real-time reasoning. Similar to how humans utilize distinct brain regions for thinking and responding, we propose a novel dual-brain approach, employing a \"Formulation Brain\" for high-level reasoning to pace and guide a separate \"Articulation Brain\" for fluent speech generation. This division of labor eliminates mode-switching, preserving the integrity of the reasoning process. Experiments show that MPS significantly outperforms existing think-while-speaking methods and achieves reasoning performance comparable to models that pre-compute the full CoT before speaking, while drastically reducing latency. Under a zero-latency configuration, the proposed method achieves an accuracy of 92.8% on the mathematical reasoning task Spoken-MQA and attains a score of 82.5 on the speech conversation task URO-Bench. Our work effectively bridges the gap between high-quality reasoning and real-time interaction.",
        "tags": [
            "CoT"
        ]
    },
    {
        "id": "272",
        "title": "LiveOIBench: Can Large Language Models Outperform Human Contestants in Informatics Olympiads?",
        "author": [
            "Kaijian Zou",
            "Aaron Xiong",
            "Yunxiang Zhang",
            "Frederick Zhang",
            "Yueqi Ren",
            "Jirong Yang",
            "Ayoung Lee",
            "Shitanshu Bhushan",
            "Lu Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09595",
        "abstract": "Competitive programming problems increasingly serve as valuable benchmarks to evaluate the coding capabilities of large language models (LLMs) due to their complexity and ease of verification. Yet, current coding benchmarks face limitations such as lack of exceptionally challenging problems, insufficient test case coverage, reliance on online platform APIs that limit accessibility. To address these issues, we introduce LiveOIBench, a comprehensive benchmark featuring 403 expert-curated Olympiad-level competitive programming problems, each with an average of 60 expert-designed test cases. The problems are sourced directly from 72 official Informatics Olympiads in different regions conducted between 2023 and 2025. LiveOIBench distinguishes itself through four key features: (1) meticulously curated high-quality tasks with detailed subtask rubrics and extensive private test cases; (2) direct integration of elite contestant performance data to enable informative comparison against top-performing humans; (3) planned continuous, contamination-free updates from newly released Olympiad problems; and (4) a self-contained evaluation system facilitating offline and easy-to-reproduce assessments. Benchmarking 32 popular general-purpose and reasoning LLMs, we find that GPT-5 achieves a notable 81.76th percentile, a strong result that nonetheless falls short of top human contestant performance, who usually place above 90th. In contrast, among open-weight reasoning models, GPT-OSS-120B achieves only a 60th percentile, underscoring significant capability disparities from frontier closed models. Detailed analyses indicate that robust reasoning models prioritize precise problem analysis over excessive exploration, suggesting future models should emphasize structured analysis and minimize unnecessary exploration. All data, code, and leaderboard results will be made publicly available on our website.",
        "tags": [
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "273",
        "title": "Prompting Test-Time Scaling Is A Strong LLM Reasoning Data Augmentation",
        "author": [
            "Sondos Mahmoud Bsharat",
            "Zhiqiang Shen"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09599",
        "abstract": "Large language models (LLMs) have demonstrated impressive reasoning capabilities when provided with chain-of-thought exemplars, but curating large reasoning datasets remains laborious and resource-intensive. In this work, we introduce Prompting Test-Time Scaling (P-TTS), a simple yet effective inference-time data augmentation strategy for enhancing LLM reasoning through finetuning. Rather than collecting thousands or even millions of examples, P-TTS leverages a small pool of only 90 manually selected reasoning instances and systematically varies exemplar augmentation through principled instruction prompting intensities at test time to synthesize diverse reasoning trajectory contexts. Then we finetune the various sizes of Qwen-2.5 models on P-TTS data. Across a suite of mathematical reasoning AIME2024 & 25, MATH500, and GPQA-Diamond, our P-TTS-7B and 32B models outperform the prior competitive baselines like S1 and S1.1 (1K-shot), achieving absolute accuracy gains of +26.66% and +30.00% on AIME'24 (7B), and +13.34% and +6.67% on AIME'25 (7B); P-TTS-32B yields gains of +23.33% and +16.63% on AIME'24, and +26.63% and +3.33% on AIME'25 (vs. S1 and S1.1, respectively), with comparable or better performance on MATH500 and GPQA-Diamond. We further show that P-TTS enhances zero-shot generalization accuracy on out-of-domain reasoning benchmarks of Gaokao, Kaoyan, OlympiadBench, AMC23, GradeSchoolMath, and Minerva. Our analysis suggests that test-time scaling effectively explores the latent space of reasoning patterns, amplifying LLM problem-solving with minimal annotation overhead, and further unlocking the reasoning potential and capabilities of LLMs. Prompting Test-Time Scaling offers a practical, low-cost way to elicit LLM reasoning in resource-constrained or rapidly evolving domains.",
        "tags": [
            "CoT",
            "LLM",
            "Qwen"
        ]
    },
    {
        "id": "274",
        "title": "VisPile: A Visual Analytics System for Analyzing Multiple Text Documents With Large Language Models and Knowledge Graphs",
        "author": [
            "Adam Coscia",
            "Alex Endert"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09605",
        "abstract": "Intelligence analysts perform sensemaking over collections of documents using various visual and analytic techniques to gain insights from large amounts of text. As data scales grow, our work explores how to leverage two AI technologies, large language models (LLMs) and knowledge graphs (KGs), in a visual text analysis tool, enhancing sensemaking and helping analysts keep pace. Collaborating with intelligence community experts, we developed a visual analytics system called VisPile. VisPile integrates an LLM and a KG into various UI functions that assist analysts in grouping documents into piles, performing sensemaking tasks like summarization and relationship mapping on piles, and validating LLM- and KG-generated evidence. Our paper describes the tool, as well as feedback received from six professional intelligence analysts that used VisPile to analyze a text document corpus.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "275",
        "title": "SpaceVista: All-Scale Visual Spatial Reasoning from mm to km",
        "author": [
            "Peiwen Sun",
            "Shiqiang Lang",
            "Dongming Wu",
            "Yi Ding",
            "Kaituo Feng",
            "Huadai Liu",
            "Zhen Ye",
            "Rui Liu",
            "Yun-Hui Liu",
            "Jianan Wang",
            "Xiangyu Yue"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09606",
        "abstract": "With the current surge in spatial reasoning explorations, researchers have made significant progress in understanding indoor scenes, but still struggle with diverse applications such as robotics and autonomous driving. This paper aims to advance all-scale spatial reasoning across diverse scenarios by tackling two key challenges: 1) the heavy reliance on indoor 3D scans and labor-intensive manual annotations for dataset curation; 2) the absence of effective all-scale scene modeling, which often leads to overfitting to individual scenes. In this paper, we introduce a holistic solution that integrates a structured spatial reasoning knowledge system, scale-aware modeling, and a progressive training paradigm, as the first attempt to broaden the all-scale spatial intelligence of MLLMs to the best of our knowledge. Using a task-specific, specialist-driven automated pipeline, we curate over 38K video scenes across 5 spatial scales to create SpaceVista-1M, a dataset comprising approximately 1M spatial QA pairs spanning 19 diverse task types. While specialist models can inject useful domain knowledge, they are not reliable for evaluation. We then build an all-scale benchmark with precise annotations by manually recording, retrieving, and assembling video-based data. However, naive training with SpaceVista-1M often yields suboptimal results due to the potential knowledge conflict. Accordingly, we introduce SpaceVista-7B, a spatial reasoning model that accepts dense inputs beyond semantics and uses scale as an anchor for scale-aware experts and progressive rewards. Finally, extensive evaluations across 5 benchmarks, including our SpaceVista-Bench, demonstrate competitive performance, showcasing strong generalization across all scales and scenarios. Our dataset, model, and benchmark will be released on https://peiwensun2000.github.io/mm2km .",
        "tags": [
            "3D",
            "Robotics"
        ]
    },
    {
        "id": "276",
        "title": "VITA-VLA: Efficiently Teaching Vision-Language Models to Act via Action Expert Distillation",
        "author": [
            "Shaoqi Dong",
            "Chaoyou Fu",
            "Haihan Gao",
            "Yi-Fan Zhang",
            "Chi Yan",
            "Chu Wu",
            "Xiaoyu Liu",
            "Yunhang Shen",
            "Jing Huo",
            "Deqiang Jiang",
            "Haoyu Cao",
            "Yang Gao",
            "Xing Sun",
            "Ran He",
            "Caifeng Shan"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09607",
        "abstract": "Vision-Language Action (VLA) models significantly advance robotic manipulation by leveraging the strong perception capabilities of pretrained vision-language models (VLMs). By integrating action modules into these pretrained models, VLA methods exhibit improved generalization. However, training them from scratch is costly. In this work, we propose a simple yet effective distillation-based framework that equips VLMs with action-execution capability by transferring knowledge from pretrained small action models. Our architecture retains the original VLM structure, adding only an action token and a state encoder to incorporate physical inputs. To distill action knowledge, we adopt a two-stage training strategy. First, we perform lightweight alignment by mapping VLM hidden states into the action space of the small action model, enabling effective reuse of its pretrained action decoder and avoiding expensive pretraining. Second, we selectively fine-tune the language model, state encoder, and action modules, enabling the system to integrate multimodal inputs with precise action generation. Specifically, the action token provides the VLM with a direct handle for predicting future actions, while the state encoder allows the model to incorporate robot dynamics not captured by vision alone. This design yields substantial efficiency gains over training large VLA models from scratch. Compared with previous state-of-the-art methods, our method achieves 97.3% average success rate on LIBERO (11.8% improvement) and 93.5% on LIBERO-LONG (24.5% improvement). In real-world experiments across five manipulation tasks, our method consistently outperforms the teacher model, achieving 82.0% success rate (17% improvement), which demonstrate that action distillation effectively enables VLMs to generate precise actions while substantially reducing training costs.",
        "tags": [
            "Robotics",
            "VLM"
        ]
    },
    {
        "id": "277",
        "title": "StreamingVLM: Real-Time Understanding for Infinite Video Streams",
        "author": [
            "Ruyi Xu",
            "Guangxuan Xiao",
            "Yukang Chen",
            "Liuning He",
            "Kelly Peng",
            "Yao Lu",
            "Song Han"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09608",
        "abstract": "Vision-language models (VLMs) could power real-time assistants and autonomous agents, but they face a critical challenge: understanding near-infinite video streams without escalating latency and memory usage. Processing entire videos with full attention leads to quadratic computational costs and poor performance on long videos. Meanwhile, simple sliding window methods are also flawed, as they either break coherence or suffer from high latency due to redundant recomputation. In this paper, we introduce StreamingVLM, a model designed for real-time, stable understanding of infinite visual input. Our approach is a unified framework that aligns training with streaming inference. During inference, we maintain a compact KV cache by reusing states of attention sinks, a short window of recent vision tokens, and a long window of recent text tokens. This streaming ability is instilled via a simple supervised fine-tuning (SFT) strategy that applies full attention on short, overlapped video chunks, which effectively mimics the inference-time attention pattern without training on prohibitively long contexts. For evaluation, we build Inf-Streams-Eval, a new benchmark with videos averaging over two hours that requires dense, per-second alignment between frames and text. On Inf-Streams-Eval, StreamingVLM achieves a 66.18% win rate against GPT-4O mini and maintains stable, real-time performance at up to 8 FPS on a single NVIDIA H100. Notably, our SFT strategy also enhances general VQA abilities without any VQA-specific fine-tuning, improving performance on LongVideoBench by +4.30 and OVOBench Realtime by +5.96. Code is available at https://github.com/mit-han-lab/streaming-vlm.",
        "tags": [
            "GPT",
            "VLM"
        ]
    },
    {
        "id": "278",
        "title": "PyNoetic: A modular python framework for no-code development of EEG brain-computer interfaces",
        "author": [
            "Gursimran Singh",
            "Aviral Chharia",
            "Rahul Upadhyay",
            "Vinay Kumar",
            "Luca Longo"
        ],
        "pdf": "https://arxiv.org/pdf/2509.00670",
        "abstract": "Electroencephalography (EEG)-based Brain-Computer Interfaces (BCIs) have emerged as a transformative technology with applications spanning robotics, virtual reality, medicine, and rehabilitation. However, existing BCI frameworks face several limitations, including a lack of stage-wise flexibility essential for experimental research, steep learning curves for researchers without programming expertise, elevated costs due to reliance on proprietary software, and a lack of all-inclusive features leading to the use of multiple external tools affecting research outcomes. To address these challenges, we present PyNoetic, a modular BCI framework designed to cater to the diverse needs of BCI research. PyNoetic is one of the very few frameworks in Python that encompasses the entire BCI design pipeline, from stimulus presentation and data acquisition to channel selection, filtering, feature extraction, artifact removal, and finally simulation and visualization. Notably, PyNoetic introduces an intuitive and end-to-end GUI coupled with a unique pick-and-place configurable flowchart for no-code BCI design, making it accessible to researchers with minimal programming experience. For advanced users, it facilitates the seamless integration of custom functionalities and novel algorithms with minimal coding, ensuring adaptability at each design stage. PyNoetic also includes a rich array of analytical tools such as machine learning models, brain-connectivity indices, systematic testing functionalities via simulation, and evaluation methods of novel paradigms. PyNoetic's strengths lie in its versatility for both offline and real-time BCI development, which streamlines the design process, allowing researchers to focus on more intricate aspects of BCI development and thus accelerate their research endeavors. Project Website: https://neurodiag.github.io/PyNoetic",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "279",
        "title": "Articulation-Informed ASR: Integrating Articulatory Features into ASR via Auxiliary Speech Inversion and Cross-Attention Fusion",
        "author": [
            "Ahmed Adel Attia",
            "Jing Liu",
            "Carol Espy Wilson"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08585",
        "abstract": "Prior works have investigated the use of articulatory features as complementary representations for automatic speech recognition (ASR), but their use was largely confined to shallow acoustic models. In this work, we revisit articulatory information in the era of deep learning and propose a framework that leverages articulatory representations both as an auxiliary task and as a pseudo-input to the recognition model. Specifically, we employ speech inversion as an auxiliary prediction task, and the predicted articulatory features are injected into the model as a query stream in a cross-attention module with acoustic embeddings as keys and values. Experiments on LibriSpeech demonstrate that our approach yields consistent improvements over strong transformer-based baselines, particularly under low-resource conditions. These findings suggest that articulatory features, once sidelined in ASR research, can provide meaningful benefits when reintroduced with modern architectures.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "280",
        "title": "Dynamic Stress Detection: A Study of Temporal Progression Modelling of Stress in Speech",
        "author": [
            "Vishakha Lall",
            "Yisi Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08586",
        "abstract": "Detecting psychological stress from speech is critical in high-pressure settings. While prior work has leveraged acoustic features for stress detection, most treat stress as a static label. In this work, we model stress as a temporally evolving phenomenon influenced by historical emotional state. We propose a dynamic labelling strategy that derives fine-grained stress annotations from emotional labels and introduce cross-attention-based sequential models, a Unidirectional LSTM and a Transformer Encoder, to capture temporal stress progression. Our approach achieves notable accuracy gains on MuSE (+5%) and StressID (+18%) over existing baselines, and generalises well to a custom real-world dataset. These results highlight the value of modelling stress as a dynamic construct in speech.",
        "tags": [
            "Detection",
            "Transformer"
        ]
    },
    {
        "id": "281",
        "title": "Look before Transcription: End-to-End SlideASR with Visually-Anchored Policy Optimization",
        "author": [
            "Rui Hu",
            "Delai Qiu",
            "Yining Wang",
            "Shengping Liu",
            "Jitao Sang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08618",
        "abstract": "Automatic speech recognition (ASR) systems often struggle with domain-specific terminology, especially in specialized settings such as academic lectures. To address this, we define the SlideASR task, which leverages the rich visual information from presentation slides to improve transcription accuracy. Existing pipeline methods for this task tend to be complex and underperform. Although omni-modal large language models (OLLMs) provide a promising end-to-end framework, they frequently fail in practice by degenerating into simple optical character recognition (OCR) systems. To overcome this, we propose Visually-Anchored Policy Optimization (VAPO), a novel post-training method designed to control the model's reasoning process. Drawing on the Chain-of-Thought reasoning paradigm, VAPO enforces a structured \"Look before Transcription\" procedure using a <think><answer> format. Specifically, the model first performs OCR on the slide content within the think step, then generates the transcription by referencing this recognized visual information in the answer step. This reasoning process is optimized via reinforcement learning with four distinct rewards targeting format compliance, OCR accuracy, ASR quality, and visual anchoring consistency. To support further research, we construct SlideASR-Bench, a new entity-rich benchmark consisting of a synthetic dataset for training and testing, and a challenging real-world set for evaluation. Extensive experiments demonstrate that VAPO significantly improves recognition of domain-specific terms, establishing an effective end-to-end paradigm for SlideASR.",
        "tags": [
            "CoT",
            "LLM",
            "RL"
        ]
    },
    {
        "id": "282",
        "title": "Exploring Teachers' Perceptions of ChatGPT Through Prompt Engineering",
        "author": [
            "Dimitrios Gousopoulos"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08634",
        "abstract": "Artificial Intelligence and especially Large Language Models (LLM), such as ChatGPT has revolutionized the way educators work. The results we get from LLMs depend on how we ask them to help us. The process and the technique behind an effective input is called prompt engineering. The aim of this study is to investigate whether science educators in secondary education improve their attitude toward ChatGPT as a learning assistant after appropriate training in prompt engineering. The results of the pilot study presented in this paper show an improvement in the previously mentioned teachers perceptions.",
        "tags": [
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "283",
        "title": "QuIRK: Quantum-Inspired Re-uploading KAN",
        "author": [
            "Vinayak Sharma",
            "Ashish Padhy",
            "Vijay Jagdish Karanjkar",
            "Sourav Behera",
            "Lord Sen",
            "Shyamapada Mukherjee",
            "Aviral Shrivastava"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08650",
        "abstract": "Kolmogorov-Arnold Networks or KANs have shown the ability to outperform classical Deep Neural Networks, while using far fewer trainable parameters for regression problems on scientific domains. Even more powerful has been their interpretability due to their structure being composed of univariate B-Spline functions. This enables us to derive closed-form equations from trained KANs for a wide range of problems. This paper introduces a quantum-inspired variant of the KAN based on Quantum Data Re-uploading~(DR) models. The Quantum-Inspired Re-uploading KAN or QuIRK model replaces B-Splines with single-qubit DR models as the univariate function approximator, allowing them to match or outperform traditional KANs while using even fewer parameters. This is especially apparent in the case of periodic functions. Additionally, since the model utilizes only single-qubit circuits, it remains classically tractable to simulate with straightforward GPU acceleration. Finally, we also demonstrate that QuIRK retains the interpretability advantages and the ability to produce closed-form solutions.",
        "tags": [
            "KAN"
        ]
    },
    {
        "id": "284",
        "title": "A Design-based Solution for Causal Inference with Text: Can a Language Model Be Too Large?",
        "author": [
            "Graham Tierney",
            "Srikar Katta",
            "Christopher Bail",
            "Sunshine Hillygus",
            "Alexander Volfovsky"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08758",
        "abstract": "Many social science questions ask how linguistic properties causally affect an audience's attitudes and behaviors. Because text properties are often interlinked (e.g., angry reviews use profane language), we must control for possible latent confounding to isolate causal effects. Recent literature proposes adapting large language models (LLMs) to learn latent representations of text that successfully predict both treatment and the outcome. However, because the treatment is a component of the text, these deep learning methods risk learning representations that actually encode the treatment itself, inducing overlap bias. Rather than depending on post-hoc adjustments, we introduce a new experimental design that handles latent confounding, avoids the overlap issue, and unbiasedly estimates treatment effects. We apply this design in an experiment evaluating the persuasiveness of expressing humility in political communication. Methodologically, we demonstrate that LLM-based methods perform worse than even simple bag-of-words models using our real text and outcomes from our experiment. Substantively, we isolate the causal effect of expressing humility on the perceived persuasiveness of political statements, offering new insights on communication effects for social media platforms, policy makers, and social scientists.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "285",
        "title": "Mirror Flow Matching with Heavy-Tailed Priors for Generative Modeling on Convex Domains",
        "author": [
            "Yunrui Guan",
            "Krishnakumar Balasubramanian",
            "Shiqian Ma"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08929",
        "abstract": "We study generative modeling on convex domains using flow matching and mirror maps, and identify two fundamental challenges. First, standard log-barrier mirror maps induce heavy-tailed dual distributions, leading to ill-posed dynamics. Second, coupling with Gaussian priors performs poorly when matching heavy-tailed targets. To address these issues, we propose Mirror Flow Matching based on a \\emph{regularized mirror map} that controls dual tail behavior and guarantees finite moments, together with coupling to a Student-$t$ prior that aligns with heavy-tailed targets and stabilizes training. We provide theoretical guarantees, including spatial Lipschitzness and temporal regularity of the velocity field, Wasserstein convergence rates for flow matching with Student-$t$ priors and primal-space guarantees for constrained generation, under $\\varepsilon$-accurate learned velocity fields. Empirically, our method outperforms baselines in synthetic convex-domain simulations and achieves competitive sample quality on real-world constrained generative tasks.",
        "tags": [
            "Flow Matching"
        ]
    },
    {
        "id": "286",
        "title": "Physically Valid Biomolecular Interaction Modeling with Gauss-Seidel Projection",
        "author": [
            "Siyuan Chen",
            "Minghao Guo",
            "Caoliwen Wang",
            "Anka He Chen",
            "Yikun Zhang",
            "Jingjing Chai",
            "Yin Yang",
            "Wojciech Matusik",
            "Peter Yichen Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08946",
        "abstract": "Biomolecular interaction modeling has been substantially advanced by foundation models, yet they often produce all-atom structures that violate basic steric feasibility. We address this limitation by enforcing physical validity as a strict constraint during both training and inference with a uniffed module. At its core is a differentiable projection that maps the provisional atom coordinates from the diffusion model to the nearest physically valid conffguration. This projection is achieved using a Gauss-Seidel scheme, which exploits the locality and sparsity of the constraints to ensure stable and fast convergence at scale. By implicit differentiation to obtain gradients, our module integrates seamlessly into existing frameworks for end-to-end ffnetuning. With our Gauss-Seidel projection module in place, two denoising steps are sufffcient to produce biomolecular complexes that are both physically valid and structurally accurate. Across six benchmarks, our 2-step model achieves the same structural accuracy as state-of-the-art 200-step diffusion baselines, delivering approximately 10 times faster wall-clock speed while guaranteeing physical validity.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "287",
        "title": "Application of Deep Reinforcement Learning to At-the-Money S&P 500 Options Hedging",
        "author": [
            "Zofia Bracha",
            "PaweÅ Sakowski",
            "Jakub MichaÅkÃ³w"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09247",
        "abstract": "This paper explores the application of deep Q-learning to hedging at-the-money options on the S\\&P~500 index. We develop an agent based on the Twin Delayed Deep Deterministic Policy Gradient (TD3) algorithm, trained to simulate hedging decisions without making explicit model assumptions on price dynamics. The agent was trained on historical intraday prices of S\\&P~500 call options across years 2004--2024, using a single time series of six predictor variables: option price, underlying asset price, moneyness, time to maturity, realized volatility, and current hedge position. A walk-forward procedure was applied for training, which led to nearly 17~years of out-of-sample evaluation. The performance of the deep reinforcement learning (DRL) agent is benchmarked against the Black--Scholes delta-hedging strategy over the same period. We assess both approaches using metrics such as annualized return, volatility, information ratio, and Sharpe ratio. To test the models' adaptability, we performed simulations across varying market conditions and added constraints such as transaction costs and risk-awareness penalties. Our results show that the DRL agent can outperform traditional hedging methods, particularly in volatile or high-cost environments, highlighting its robustness and flexibility in practical trading contexts. While the agent consistently outperforms delta-hedging, its performance deteriorates when the risk-awareness parameter is higher. We also observed that the longer the time interval used for volatility estimation, the more stable the results.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "288",
        "title": "Smart navigation of a gravity-driven glider with adjustable centre-of-mass",
        "author": [
            "X. Jiang",
            "J. Qiu",
            "K. Gustavsson",
            "B. Mehlig",
            "L. Zhao"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09250",
        "abstract": "Artificial gliders are designed to disperse as they settle through a fluid, requiring precise navigation to reach target locations. We show that a compact glider settling in a viscous fluid can navigate by dynamically adjusting its centre-of-mass. Using fully resolved direct numerical simulations (DNS) and reinforcement learning, we find two optimal navigation strategies that allow the glider to reach its target location accurately. These strategies depend sensitively on how the glider interacts with the surrounding fluid. The nature of this interaction changes as the particle Reynolds number Re$_p$ changes. Our results explain how the optimal strategy depends on Re$_p$. At large Re$_p$, the glider learns to tumble rapidly by moving its centre-of-mass as its orientation changes. This generates a large horizontal inertial lift force, which allows the glider to travel far. At small Re$_p$, by contrast, high viscosity hinders tumbling. In this case, the glider learns to adjust its centre-of-mass so that it settles with a steady, inclined orientation that results in a horizontal viscous force. The horizontal range is much smaller than for large Re$_p$, because this viscous force is much smaller than the inertial lift force at large Re$_p$.\n*These authors contributed equally.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "289",
        "title": "Parametrized Topological Complexity for a Multi-Robot System with Variable Tasks",
        "author": [
            "Gopal Chandra Dutta",
            "Amit Kumar Paul",
            "Subhankar Sau"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09323",
        "abstract": "We study a generalized motion planning problem involving multiple autonomous robots navigating in a $d$-dimensional Euclidean space in the presence of a set of obstacles whose positions are unknown a priori. Each robot is required to visit sequentially a prescribed set of target states, with the number of targets varying between robots. This heterogeneous setting generalizes the framework considered in the prior works on sequential parametrized topological complexity by Farber and the second author of this article. To determine the topological complexity of our problem, we formulate it mathematically by constructing an appropriate fibration. Our main contribution is the determination of this invariant in the generalized setting, which captures the minimal algorithmic instability required for designing collision-free motion planning algorithms under parameter-dependent constraints. We provide a detailed analysis for both odd and even-dimensional ambient spaces, including the essential cohomological computations and explicit constructions of corresponding motion planning algorithms.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "290",
        "title": "Adaptive Decoding via Hierarchical Neural Information Gradients in Mouse Visual Tasks",
        "author": [
            "Jingyi Feng",
            "Xiang Feng"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09451",
        "abstract": "Understanding the encoding and decoding mechanisms of dynamic neural responses to different visual stimuli is an important topic in exploring how the brain represents visual information. Currently, hierarchically deep neural networks (DNNs) have played a significant role as tools for mining the core features of complex data. However, most methods often overlook the dynamic generation process of neural data, such as hierarchical brain's visual data, within the brain's structure. In the decoding of brain's visual data, two main paradigms are 'fine-grained decoding tests' and 'rough-grained decoding tests', which we define as focusing on a single brain region and studying the overall structure across multiple brain regions, respectively. In this paper, we mainly use the Visual Coding Neuropixel dataset from the Allen Brain Institute, and the hierarchical information extracted from some single brain regions (i.e., fine-grained decoding tests) is provided to the proposed method for studying the adaptive topological decoding between brain regions, called the Adaptive Topological Vision Transformer, or AT-ViT. In numerous experiments, the results reveal the importance of the proposed method in hierarchical networks in the visual tasks, and also validate the hypothesis that \"the hierarchical information content in brain regions of the visual system can be quantified by decoding outcomes to reflect an information hierarchy.\" Among them, we found that neural data collected in the hippocampus can have a random decoding performance, and this negative impact on performance still holds significant scientific value.",
        "tags": [
            "Transformer",
            "ViT"
        ]
    },
    {
        "id": "291",
        "title": "Conditional Flow Matching for Bayesian Posterior Inference",
        "author": [
            "So Won Jeong",
            "Percy S. Zhai",
            "Veronika RoÄovÃ¡"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09534",
        "abstract": "We propose a generative multivariate posterior sampler via flow matching. It offers a simple training objective, and does not require access to likelihood evaluation. The method learns a dynamic, block-triangular velocity field in the joint space of data and parameters, which results in a deterministic transport map from a source distribution to the desired posterior. The inverse map, named vector rank, is accessible by reversibly integrating the velocity over time. It is advantageous to leverage the dynamic design: proper constraints on the velocity yield a monotone map, which leads to a conditional Brenier map, enabling a fast and simultaneous generation of Bayesian credible sets whose contours correspond to level sets of Monge-Kantorovich data depth. Our approach is computationally lighter compared to GAN-based and diffusion-based counterparts, and is capable of capturing complex posterior structures. Finally, frequentist theoretical guarantee on the consistency of the recovered posterior distribution, and of the corresponding Bayesian credible sets, is provided.",
        "tags": [
            "Diffusion",
            "Flow Matching",
            "GAN"
        ]
    }
]