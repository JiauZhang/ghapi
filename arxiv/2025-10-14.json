[
    {
        "id": "1",
        "title": "Hound: Relation-First Knowledge Graphs for Complex-System Reasoning in Security Audits",
        "author": [
            "Bernhard Mueller"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09633",
        "abstract": "Hound introduces a relation-first graph engine that improves system-level reasoning across interrelated components in complex codebases. The agent designs flexible, analyst-defined views with compact annotations (e.g., monetary/value flows, authentication/authorization roles, call graphs, protocol invariants) and uses them to anchor exact retrieval: for any question, it loads precisely the code that matters (often across components) so it can zoom out to system structure and zoom in to the decisive lines. A second contribution is a persistent belief system: long-lived vulnerability hypotheses whose confidence is updated as evidence accrues. The agent employs coverage-versus-intuition planning and a QA finalizer to confirm or reject hypotheses. On a five-project subset of ScaBench[1], Hound improves recall and F1 over a baseline LLM analyzer (micro recall 31.2% vs. 8.3%; F1 14.2% vs. 9.8%) with a modest precision trade-off. We attribute these gains to flexible, relation-first graphs that extend model understanding beyond call/dataflow to abstract aspects, plus the hypothesis-centric loop; code and artifacts are released to support reproduction.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "2",
        "title": "A Method for Quantifying Human Risk and a Blueprint for LLM Integration",
        "author": [
            "Giuseppe Canale"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09635",
        "abstract": "This paper presents the Cybersecurity Psychology Framework (CPF), a novel methodology for quantifying human-centric vulnerabilities in security operations through systematic integration of established psychological constructs with operational security telemetry. While individual human factors-alert fatigue, compliance fatigue, cognitive overload, and risk perception biases-have been extensively studied in isolation, no framework provides end-to-end operationalization across the full spectrum of psychological vulnerabilities. We address this gap by: (1) defining specific, measurable algorithms that quantify key psychological states using standard SOC tooling (SIEM, ticketing systems, communication platforms); (2) proposing a lightweight, privacy-preserving LLM architecture based on Retrieval-Augmented Generation (RAG) and domain-specific fine-tuning to analyze structured and unstructured data for latent psychological risks; (3) detailing a rigorous mixed-methods validation strategy acknowledging the inherent difficulty of obtaining sensitive cybersecurity data. Our implementation of CPF indicators has been demonstrated in a proof-of-concept deployment using small language models achieving 0.92 F1-score on synthetic data. This work provides the theoretical and methodological foundation necessary for industry partnerships to conduct empirical validation with real operational data.",
        "tags": [
            "LLM",
            "RAG"
        ]
    },
    {
        "id": "3",
        "title": "Enhanced Urban Traffic Management Using CCTV Surveillance Videos and Multi-Source Data Current State Prediction and Frequent Episode Mining",
        "author": [
            "Shaharyar Alam Ansari",
            "Mohammad Luqman",
            "Aasim Zafar",
            "Savir Ali"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09644",
        "abstract": "Rapid urbanization has intensified traffic congestion, environmental strain, and inefficiencies in transportation systems, creating an urgent need for intelligent and adaptive traffic management solutions. Conventional systems relying on static signals and manual monitoring are inadequate for the dynamic nature of modern traffic. This research aims to develop a unified framework that integrates CCTV surveillance videos with multi-source data descriptors to enhance real-time urban traffic prediction. The proposed methodology incorporates spatio-temporal feature fusion, Frequent Episode Mining for sequential traffic pattern discovery, and a hybrid LSTM-Transformer model for robust traffic state forecasting. The framework was evaluated on the CityFlowV2 dataset comprising 313,931 annotated bounding boxes across 46 cameras. It achieved a high prediction accuracy of 98.46 percent, with a macro precision of 0.9800, macro recall of 0.9839, and macro F1-score of 0.9819. FEM analysis revealed significant sequential patterns such as moderate-congested transitions with confidence levels exceeding 55 percent. The 46 sustained congestion alerts are system-generated, which shows practical value for proactive congestion management. This emphasizes the need for the incorporation of video stream analytics with data from multiple sources for the design of real-time, responsive, adaptable multi-level intelligent transportation systems, which makes urban mobility smarter and safer.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "4",
        "title": "Real-Time Health Analytics Using Ontology-Driven Complex Event Processing and LLM Reasoning: A Tuberculosis Case Study",
        "author": [
            "Ritesh Chandra",
            "Sonali Agarwal",
            "Navjot Singh"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09646",
        "abstract": "Timely detection of critical health conditions remains a major challenge in public health analytics, especially in Big Data environments characterized by high volume, rapid velocity, and diverse variety of clinical data. This study presents an ontology-enabled real-time analytics framework that integrates Complex Event Processing (CEP) and Large Language Models (LLMs) to enable intelligent health event detection and semantic reasoning over heterogeneous, high-velocity health data streams. The architecture leverages the Basic Formal Ontology (BFO) and Semantic Web Rule Language (SWRL) to model diagnostic rules and domain knowledge. Patient data is ingested and processed using Apache Kafka and Spark Streaming, where CEP engines detect clinically significant event patterns. LLMs support adaptive reasoning, event interpretation, and ontology refinement. Clinical information is semantically structured as Resource Description Framework (RDF) triples in Graph DB, enabling SPARQL-based querying and knowledge-driven decision support. The framework is evaluated using a dataset of 1,000 Tuberculosis (TB) patients as a use case, demonstrating low-latency event detection, scalable reasoning, and high model performance (in terms of precision, recall, and F1-score). These results validate the system's potential for generalizable, real-time health analytics in complex Big Data scenarios.",
        "tags": [
            "Detection",
            "LLM"
        ]
    },
    {
        "id": "5",
        "title": "Ultralytics YOLO Evolution: An Overview of YOLO26, YOLO11, YOLOv8 and YOLOv5 Object Detectors for Computer Vision and Pattern Recognition",
        "author": [
            "Ranjan Sapkota",
            "Manoj Karkee"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09653",
        "abstract": "This paper presents a comprehensive overview of the Ultralytics YOLO(You Only Look Once) family of object detectors, focusing the architectural evolution, benchmarking, deployment perspectives, and future challenges. The review begins with the most recent release, YOLO26 (YOLOv26), which introduces key innovations including Distribution Focal Loss (DFL) removal, native NMS-free inference, Progressive Loss Balancing (ProgLoss), Small-Target-Aware Label Assignment (STAL), and the MuSGD optimizer for stable training. The progression is then traced through YOLO11, with its hybrid task assignment and efficiency-focused modules; YOLOv8, which advanced with a decoupled detection head and anchor-free predictions; and YOLOv5, which established the modular PyTorch foundation that enabled modern YOLO development. Benchmarking on the MS COCO dataset provides a detailed quantitative comparison of YOLOv5, YOLOv8, YOLO11, and YOLO26, alongside cross-comparisons with YOLOv12, YOLOv13, RT-DETR, and DEIM. Metrics including precision, recall, F1 score, mean Average Precision, and inference speed are analyzed to highlight trade-offs between accuracy and efficiency. Deployment and application perspectives are further discussed, covering export formats, quantization strategies, and real-world use in robotics, agriculture, surveillance, and manufacturing. Finally, the paper identifies challenges and future directions, including dense-scene limitations, hybrid CNN-Transformer integration, open-vocabulary detection, and edge-aware training approaches.",
        "tags": [
            "Detection",
            "Robotics",
            "Transformer"
        ]
    },
    {
        "id": "6",
        "title": "Generative Models for Helmholtz Equation Solutions: A Dataset of Acoustic Materials",
        "author": [
            "Riccardo Fosco Gramaccioni",
            "Christian Marinoni",
            "Fabrizio Frezza",
            "Aurelio Uncini",
            "Danilo Comminiello"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09657",
        "abstract": "Accurate simulation of wave propagation in complex acoustic materials is crucial for applications in sound design, noise control, and material engineering. Traditional numerical solvers, such as finite element methods, are computationally expensive, especially when dealing with large-scale or real-time scenarios. In this work, we introduce a dataset of 31,000 acoustic materials, named HA30K, designed and simulated solving the Helmholtz equations. For each material, we provide the geometric configuration and the corresponding pressure field solution, enabling data-driven approaches to learn Helmholtz equation solutions. As a baseline, we explore a deep learning approach based on Stable Diffusion with ControlNet, a state-of-the-art model for image generation. Unlike classical solvers, our approach leverages GPU parallelization to process multiple simulations simultaneously, drastically reducing computation time. By representing solutions as images, we bypass the need for complex simulation software and explicit equation-solving. Additionally, the number of diffusion steps can be adjusted at inference time, balancing speed and quality. We aim to demonstrate that deep learning-based methods are particularly useful in early-stage research, where rapid exploration is more critical than absolute accuracy.",
        "tags": [
            "ControlNet",
            "Diffusion"
        ]
    },
    {
        "id": "7",
        "title": "Learning What Matters: Steering Diffusion via Spectrally Anisotropic Forward Noise",
        "author": [
            "Luca Scimeca",
            "Thomas Jiralerspong",
            "Berton Earnshaw",
            "Jason Hartford",
            "Yoshua Bengio"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09660",
        "abstract": "Diffusion Probabilistic Models (DPMs) have achieved strong generative performance, yet their inductive biases remain largely implicit. In this work, we aim to build inductive biases into the training and sampling of diffusion models to better accommodate the target distribution of the data to model. We introduce an anisotropic noise operator that shapes these biases by replacing the isotropic forward covariance with a structured, frequency-diagonal covariance. This operator unifies band-pass masks and power-law weightings, allowing us to emphasize or suppress designated frequency bands, while keeping the forward process Gaussian. We refer to this as spectrally anisotropic Gaussian diffusion (SAGD). In this work, we derive the score relation for anisotropic covariances and show that, under full support, the learned score converges to the true data score as $t\\!\\to\\!0$, while anisotropy reshapes the probability-flow path from noise to data. Empirically, we show the induced anisotropy outperforms standard diffusion across several vision datasets, and enables selective omission: learning while ignoring known corruptions confined to specific bands. Together, these results demonstrate that carefully designed anisotropic forward noise provides a simple, yet principled, handle to tailor inductive bias in DPMs.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "8",
        "title": "Adversarial-Resilient RF Fingerprinting: A CNN-GAN Framework for Rogue Transmitter Detection",
        "author": [
            "Raju Dhakal",
            "Prashant Shekhar",
            "Laxima Niure Kandel"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09663",
        "abstract": "Radio Frequency Fingerprinting (RFF) has evolved as an effective solution for authenticating devices by leveraging the unique imperfections in hardware components involved in the signal generation process. In this work, we propose a Convolutional Neural Network (CNN) based framework for detecting rogue devices and identifying genuine ones using softmax probability thresholding. We emulate an attack scenario in which adversaries attempt to mimic the RF characteristics of genuine devices by training a Generative Adversarial Network (GAN) using In-phase and Quadrature (IQ) samples from genuine devices. The proposed approach is verified using IQ samples collected from ten different ADALM-PLUTO Software Defined Radios (SDRs), with seven devices considered genuine, two as rogue, and one used for validation to determine the threshold.",
        "tags": [
            "Detection",
            "GAN"
        ]
    },
    {
        "id": "9",
        "title": "LMCache: An Efficient KV Cache Layer for Enterprise-Scale LLM Inference",
        "author": [
            "Yihua Cheng",
            "Yuhan Liu",
            "Jiayi Yao",
            "Yuwei An",
            "Xiaokun Chen",
            "Shaoting Feng",
            "Yuyang Huang",
            "Samuel Shen",
            "Kuntai Du",
            "Junchen Jiang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09665",
        "abstract": "Today's LLM inference systems treat individual engines and queries independently for simplicity, but this causes significant resource inefficiencies. While there are proposals to avoid redundant computation by reusing KV caches across queries and to increase GPU utilization by disaggregating a single query to different engines, their promises cannot be realized without efficiently offloading and communicating KV cache across LLM inference engines and queries.\nWe present LMCache, the first and so far the most efficient open-source KV caching solution, which extracts and stores KV caches generated by modern LLM engines (vLLM and SGLang) and shares the KV caches across engines and queries. LMCache exposes KV caches in the LLM engine interface, effectively transforming LLM engines from individual token processors to a collection of engines with KV cache as the storage and communication medium. In particular, it supports both cache offloading (prefix reuse across queries) and prefill-decode disaggregation (cross-engine cache transfer). LMCache's high performance and wide adoption stem from the following contributions: highly optimized KV cache data movement with performance optimizations including batched data movement operations, compute and I/O pipelining; a modular KV cache connector component, decoupling LMCache from the rapid evolution of inference engines; a first-class control API, such as pinning, lookup, cleanup, movement, and compression, for flexible cache orchestration across GPU, CPU, storage, and network layers. Evaluation shows that combining LMCache with vLLM achieves up to 15x improvement in throughput across diverse workloads. With a growing community, LMCache has seen dramatic growth in adoption by enterprise inference systems, which provides valuable lessons for future KV caching solutions. The source code of LMCache is at: https://github.com/LMCache/LMCache.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "10",
        "title": "OmniSAT: Compact Action Token, Faster Auto Regression",
        "author": [
            "Huaihai Lyu",
            "Chaofan Chen",
            "Senwei Xie",
            "Pengwei Wang",
            "Xiansheng Chen",
            "Shanghang Zhang",
            "Changsheng Xu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09667",
        "abstract": "Existing Vision-Language-Action (VLA) models can be broadly categorized into diffusion-based and auto-regressive (AR) approaches: diffusion models capture continuous action distributions but rely on computationally heavy iterative denoising. In contrast, AR models enable efficient optimization and flexible sequence construction, making them better suited for large-scale pretraining. To further improve AR efficiency, particularly when action chunks induce extended and high-dimensional sequences, prior work applies entropy-guided and token-frequency techniques to shorten the sequence length. However, such compression struggled with \\textit{poor reconstruction or inefficient compression}. Motivated by this, we introduce an Omni Swift Action Tokenizer, which learns a compact, transferable action representation. Specifically, we first normalize value ranges and temporal horizons to obtain a consistent representation with B-Spline encoding. Then, we apply multi-stage residual quantization to the position, rotation, and gripper subspaces, producing compressed discrete tokens with coarse-to-fine granularity for each part. After pre-training on the large-scale dataset Droid, the resulting discrete tokenization shortens the training sequence by 6.8$\\times$, and lowers the target entropy. To further explore the potential of OmniSAT, we develop a cross-embodiment learning strategy that builds on the unified action-pattern space and jointly leverages robot and human demonstrations. It enables scalable auxiliary supervision from heterogeneous egocentric videos. Across diverse real-robot and simulation experiments, OmniSAT encompasses higher compression while preserving reconstruction quality, enabling faster AR training convergence and model performance.",
        "tags": [
            "Diffusion",
            "Robotics"
        ]
    },
    {
        "id": "11",
        "title": "Population synthesis with geographic coordinates",
        "author": [
            "Jacopo Lenti",
            "Lorenzo Costantini",
            "Ariadna Fosch",
            "Anna Monticelli",
            "David Scala",
            "Marco Pangallo"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09669",
        "abstract": "It is increasingly important to generate synthetic populations with explicit coordinates rather than coarse geographic areas, yet no established methods exist to achieve this. One reason is that latitude and longitude differ from other continuous variables, exhibiting large empty spaces and highly uneven densities. To address this, we propose a population synthesis algorithm that first maps spatial coordinates into a more regular latent space using Normalizing Flows (NF), and then combines them with other features in a Variational Autoencoder (VAE) to generate synthetic populations. This approach also learns the joint distribution between spatial and non-spatial features, exploiting spatial autocorrelations. We demonstrate the method by generating synthetic homes with the same statistical properties of real homes in 121 datasets, corresponding to diverse geographies. We further propose an evaluation framework that measures both spatial accuracy and practical utility, while ensuring privacy preservation. Our results show that the NF+VAE architecture outperforms popular benchmarks, including copula-based methods and uniform allocation within geographic areas. The ability to generate geolocated synthetic populations at fine spatial resolution opens the door to applications requiring detailed geography, from household responses to floods, to epidemic spread, evacuation planning, and transport modeling.",
        "tags": [
            "Normalizing Flows",
            "VAE"
        ]
    },
    {
        "id": "12",
        "title": "Leveraging LLMs to Streamline the Review of Public Funding Applications",
        "author": [
            "Joao D.S. Marques",
            "Andre V. Duarte",
            "Andre Carvalho",
            "Gil Rocha",
            "Bruno Martins",
            "Arlindo L. Oliveira"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09674",
        "abstract": "Every year, the European Union and its member states allocate millions of euros to fund various development initiatives. However, the increasing number of applications received for these programs often creates significant bottlenecks in evaluation processes, due to limited human capacity. In this work, we detail the real-world deployment of AI-assisted evaluation within the pipeline of two government initiatives: (i) corporate applications aimed at international business expansion, and (ii) citizen reimbursement claims for investments in energy-efficient home improvements. While these two cases involve distinct evaluation procedures, our findings confirm that AI effectively enhanced processing efficiency and reduced workload across both types of applications. Specifically, in the citizen reimbursement claims initiative, our solution increased reviewer productivity by 20.1%, while keeping a negligible false-positive rate based on our test set observations. These improvements resulted in an overall reduction of more than 2 months in the total evaluation time, illustrating the impact of AI-driven automation in large-scale evaluation workflows.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "13",
        "title": "Knowledge-Aware Mamba for Joint Change Detection and Classification from MODIS Times Series",
        "author": [
            "Zhengsen Xu",
            "Yimin Zhu",
            "Zack Dewis",
            "Mabel Heffring",
            "Motasem Alkayid",
            "Saeid Taleghanidoozdoozan",
            "Lincoln Linlin Xu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09679",
        "abstract": "Although change detection using MODIS time series is critical for environmental monitoring, it is a highly challenging task due to key MODIS difficulties, e.g., mixed pixels, spatial-spectral-temporal information coupling effect, and background class heterogeneity. This paper presents a novel knowledge-aware Mamba (KAMamba) for enhanced MODIS change detection, with the following contributions. First, to leverage knowledge regarding class transitions, we design a novel knowledge-driven transition-matrix-guided approach, leading to a knowledge-aware transition loss (KAT-loss) that can enhance detection accuracies. Second, to improve model constraints, a multi-task learning approach is designed, where three losses, i.e., pre-change classification loss (PreC-loss), post-change classification loss (PostC-loss), and change detection loss (Chg-loss) are used for improve model learning. Third, to disentangle information coupling in MODIS time series, novel spatial-spectral-temporal Mamba (SSTMamba) modules are designed. Last, to improve Mamba model efficiency and remove computational cost, a sparse and deformable Mamba (SDMamba) backbone is used in SSTMamba. On the MODIS time-series dataset for Saskatchewan, Canada, we evaluate the method on land-cover change detection and LULC classification; results show about 1.5-6% gains in average F1 for change detection over baselines, and about 2% improvements in OA, AA, and Kappa for LULC classification.",
        "tags": [
            "Detection",
            "Mamba"
        ]
    },
    {
        "id": "14",
        "title": "Fortifying LLM-Based Code Generation with Graph-Based Reasoning on Secure Coding Practices",
        "author": [
            "Rupam Patir",
            "Keyan Guo",
            "Haipeng Cai",
            "Hongxin Hu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09682",
        "abstract": "The code generation capabilities of Large Language Models (LLMs) have transformed the field of software development. However, this advancement also presents significant security challenges, as LLM-generated code often contains vulnerabilities. One direction of research strengthens LLMs by injecting or refining security knowledge through curated datasets, model tuning, or static analyzers. While effective in certain settings, these methods can be resource-intensive, less adaptable to zero-day vulnerabilities, and often inapplicable to proprietary models. To address these challenges, we introduce GRASP, which explores a new direction that focuses on structured reasoning over Secure Coding Practices(SCPs) rather than additional training or external feedback. GRASP comprises two key ideas: (1) an SCP graph that organizes SCPs into a Directed Acyclic Graph (DAG) capturing dependencies and relationships, and (2) a graph-based reasoning process that systematically guides LLMs through relevant SCPs for code generation. This design enables interpretable, model-agnostic, and scalable security improvements, particularly for previously unseen vulnerabilities. Our evaluation shows that GRASP consistently achieves Security Rates (SR) exceeding 80% across multiple LLMs, and delivers up to 88% improvements over baselines on zero-day vulnerabilities.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "15",
        "title": "Using LLMs to Directly Guess Conditional Expectations Can Improve Efficiency in Causal Estimation",
        "author": [
            "Chris Engh",
            "P. M. Aronow"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09684",
        "abstract": "We propose a simple yet effective use of LLM-powered AI tools to improve causal estimation. In double machine learning, the accuracy of causal estimates of the effect of a treatment on an outcome in the presence of a high-dimensional confounder depends on the performance of estimators of conditional expectation functions. We show that predictions made by generative models trained on historical data can be used to improve the performance of these estimators relative to approaches that solely rely on adjusting for embeddings extracted from these models. We argue that the historical knowledge and reasoning capacities associated with these generative models can help overcome curse-of-dimensionality problems in causal inference problems. We consider a case study using a small dataset of online jewelry auctions, and demonstrate that inclusion of LLM-generated guesses as predictors can improve efficiency in estimation.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "16",
        "title": "Stop DDoS Attacking the Research Community with AI-Generated Survey Papers",
        "author": [
            "Jianghao Lin",
            "Rong Shan",
            "Jiachen Zhu",
            "Yunjia Xi",
            "Yong Yu",
            "Weinan Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09686",
        "abstract": "Survey papers are foundational to the scholarly progress of research communities, offering structured overviews that guide both novices and experts across disciplines. However, the recent surge of AI-generated surveys, especially enabled by large language models (LLMs), has transformed this traditionally labor-intensive genre into a low-effort, high-volume output. While such automation lowers entry barriers, it also introduces a critical threat: the phenomenon we term the \"survey paper DDoS attack\" to the research community. This refers to the unchecked proliferation of superficially comprehensive but often redundant, low-quality, or even hallucinated survey manuscripts, which floods preprint platforms, overwhelms researchers, and erodes trust in the scientific record. In this position paper, we argue that we must stop uploading massive amounts of AI-generated survey papers (i.e., survey paper DDoS attack) to the research community, by instituting strong norms for AI-assisted review writing. We call for restoring expert oversight and transparency in AI usage and, moreover, developing new infrastructures such as Dynamic Live Surveys, community-maintained, version-controlled repositories that blend automated updates with human curation. Through quantitative trend analysis, quality audits, and cultural impact discussion, we show that safeguarding the integrity of surveys is no longer optional but imperative to the research community.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "17",
        "title": "CREST-Search: Comprehensive Red-teaming for Evaluating Safety Threats in Large Language Models Powered by Web Search",
        "author": [
            "Haoran Ou",
            "Kangjie Chen",
            "Xingshuo Han",
            "Gelei Deng",
            "Jie Zhang",
            "Han Qiu",
            "Tianwei Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09689",
        "abstract": "Large Language Models (LLMs) excel at tasks such as dialogue, summarization, and question answering, yet they struggle to adapt to specialized domains and evolving facts. To overcome this, web search has been integrated into LLMs, allowing real-time access to online content. However, this connection magnifies safety risks, as adversarial prompts combined with untrusted sources can cause severe vulnerabilities. We investigate red teaming for LLMs with web search and present CREST-Search, a framework that systematically exposes risks in such systems. Unlike existing methods for standalone LLMs, CREST-Search addresses the complex workflow of search-enabled models by generating adversarial queries with in-context learning and refining them through iterative feedback. We further construct WebSearch-Harm, a search-specific dataset to fine-tune LLMs into efficient red-teaming agents. Experiments show that CREST-Search effectively bypasses safety filters and reveals vulnerabilities in modern web-augmented LLMs, underscoring the need for specialized defenses to ensure trustworthy deployment.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "18",
        "title": "Emotionally Charged, Logically Blurred: AI-driven Emotional Framing Impairs Human Fallacy Detection",
        "author": [
            "Yanran Chen",
            "Lynn Greschner",
            "Roman Klinger",
            "Michael Klenk",
            "Steffen Eger"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09695",
        "abstract": "Logical fallacies are common in public communication and can mislead audiences; fallacious arguments may still appear convincing despite lacking soundness, because convincingness is inherently subjective. We present the first computational study of how emotional framing interacts with fallacies and convincingness, using large language models (LLMs) to systematically change emotional appeals in fallacious arguments. We benchmark eight LLMs on injecting emotional appeal into fallacious arguments while preserving their logical structures, then use the best models to generate stimuli for a human study. Our results show that LLM-driven emotional framing reduces human fallacy detection in F1 by 14.5% on average. Humans perform better in fallacy detection when perceiving enjoyment than fear or sadness, and these three emotions also correlate with significantly higher convincingness compared to neutral or other emotion states. Our work has implications for AI-driven emotional manipulation in the context of fallacious argumentation.",
        "tags": [
            "Detection",
            "LLM"
        ]
    },
    {
        "id": "19",
        "title": "VisualDAN: Exposing Vulnerabilities in VLMs with Visual-Driven DAN Commands",
        "author": [
            "Aofan Liu",
            "Lulu Tang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09699",
        "abstract": "Vision-Language Models (VLMs) have garnered significant attention for their remarkable ability to interpret and generate multimodal content. However, securing these models against jailbreak attacks continues to be a substantial challenge. Unlike text-only models, VLMs integrate additional modalities, introducing novel vulnerabilities such as image hijacking, which can manipulate the model into producing inappropriate or harmful responses. Drawing inspiration from text-based jailbreaks like the \"Do Anything Now\" (DAN) command, this work introduces VisualDAN, a single adversarial image embedded with DAN-style commands. Specifically, we prepend harmful corpora with affirmative prefixes (e.g., \"Sure, I can provide the guidance you need\") to trick the model into responding positively to malicious queries. The adversarial image is then trained on these DAN-inspired harmful texts and transformed into the text domain to elicit malicious outputs. Extensive experiments on models such as MiniGPT-4, MiniGPT-v2, InstructBLIP, and LLaVA reveal that VisualDAN effectively bypasses the safeguards of aligned VLMs, forcing them to execute a broad range of harmful instructions that severely violate ethical standards. Our results further demonstrate that even a small amount of toxic content can significantly amplify harmful outputs once the model's defenses are compromised. These findings highlight the urgent need for robust defenses against image-based attacks and offer critical insights for future research into the alignment and security of VLMs.",
        "tags": [
            "LLaVA",
            "VLM"
        ]
    },
    {
        "id": "20",
        "title": "A Multi-Component Reward Function with Policy Gradient for Automated Feature Selection with Dynamic Regularization and Bias Mitigation",
        "author": [
            "Sudip Khadka",
            "L.S. Paudel"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09705",
        "abstract": "Static feature exclusion strategies often fail to prevent bias when hidden dependencies influence the model predictions. To address this issue, we explore a reinforcement learning (RL) framework that integrates bias mitigation and automated feature selection within a single learning process. Unlike traditional heuristic-driven filter or wrapper approaches, our RL agent adaptively selects features using a reward signal that explicitly integrates predictive performance with fairness considerations. This dynamic formulation allows the model to balance generalization, accuracy, and equity throughout the training process, rather than rely exclusively on pre-processing adjustments or post hoc correction mechanisms. In this paper, we describe the construction of a multi-component reward function, the specification of the agents action space over feature subsets, and the integration of this system with ensemble learning. We aim to provide a flexible and generalizable way to select features in environments where predictors are correlated and biases can inadvertently re-emerge.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "21",
        "title": "The Idola Tribus of AI: Large Language Models tend to perceive order where none exists",
        "author": [
            "Shin-nosuke Ishikawa",
            "Masato Todo",
            "Taiki Ogihara",
            "Hirotsugu Ohba"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09709",
        "abstract": "We present a tendency of large language models (LLMs) to generate absurd patterns despite their clear inappropriateness in a simple task of identifying regularities in number series. Several approaches have been proposed to apply LLMs to complex real-world tasks, such as providing knowledge through retrieval-augmented generation and executing multi-step tasks using AI agent frameworks. However, these approaches rely on the logical consistency and self-coherence of LLMs, making it crucial to evaluate these aspects and consider potential countermeasures. To identify cases where LLMs fail to maintain logical consistency, we conducted an experiment in which LLMs were asked to explain the patterns in various integer sequences, ranging from arithmetic sequences to randomly generated integer series. While the models successfully identified correct patterns in arithmetic and geometric sequences, they frequently over-recognized patterns that were inconsistent with the given numbers when analyzing randomly generated series. This issue was observed even in multi-step reasoning models, including OpenAI o3, o4-mini, and Google Gemini 2.5 Flash Preview Thinking. This tendency to perceive non-existent patterns can be interpreted as the AI model equivalent of Idola Tribus and highlights potential limitations in their capability for applied tasks requiring logical reasoning, even when employing chain-of-thought reasoning mechanisms.",
        "tags": [
            "CoT",
            "LLM"
        ]
    },
    {
        "id": "22",
        "title": "SeCon-RAG: A Two-Stage Semantic Filtering and Conflict-Free Framework for Trustworthy RAG",
        "author": [
            "Xiaonan Si",
            "Meilin Zhu",
            "Simeng Qin",
            "Lijia Yu",
            "Lijun Zhang",
            "Shuaitong Liu",
            "Xinfeng Li",
            "Ranjie Duan",
            "Yang Liu",
            "Xiaojun Jia"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09710",
        "abstract": "Retrieval-augmented generation (RAG) systems enhance large language models (LLMs) with external knowledge but are vulnerable to corpus poisoning and contamination attacks, which can compromise output integrity. Existing defenses often apply aggressive filtering, leading to unnecessary loss of valuable information and reduced reliability in generation. To address this problem, we propose a two-stage semantic filtering and conflict-free framework for trustworthy RAG. In the first stage, we perform a joint filter with semantic and cluster-based filtering which is guided by the Entity-intent-relation extractor (EIRE). EIRE extracts entities, latent objectives, and entity relations from both the user query and filtered documents, scores their semantic relevance, and selectively adds valuable documents into the clean retrieval database. In the second stage, we proposed an EIRE-guided conflict-aware filtering module, which analyzes semantic consistency between the query, candidate answers, and retrieved knowledge before final answer generation, filtering out internal and external contradictions that could mislead the model. Through this two-stage process, SeCon-RAG effectively preserves useful knowledge while mitigating conflict contamination, achieving significant improvements in both generation robustness and output trustworthiness. Extensive experiments across various LLMs and datasets demonstrate that the proposed SeCon-RAG markedly outperforms state-of-the-art defense methods.",
        "tags": [
            "LLM",
            "RAG"
        ]
    },
    {
        "id": "23",
        "title": "ReaLM: Residual Quantization Bridging Knowledge Graph Embeddings and Large Language Models",
        "author": [
            "Wenbin Guo",
            "Xin Wang",
            "Jiaoyan Chen",
            "Lingbing Guo",
            "Zhao Li",
            "Zirui Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09711",
        "abstract": "Large Language Models (LLMs) have recently emerged as a powerful paradigm for Knowledge Graph Completion (KGC), offering strong reasoning and generalization capabilities beyond traditional embedding-based approaches. However, existing LLM-based methods often struggle to fully exploit structured semantic representations, as the continuous embedding space of pretrained KG models is fundamentally misaligned with the discrete token space of LLMs. This discrepancy hinders effective semantic transfer and limits their performance. To address this challenge, we propose ReaLM, a novel and effective framework that bridges the gap between KG embeddings and LLM tokenization through the mechanism of residual vector quantization. ReaLM discretizes pretrained KG embeddings into compact code sequences and integrates them as learnable tokens within the LLM vocabulary, enabling seamless fusion of symbolic and contextual knowledge. Furthermore, we incorporate ontology-guided class constraints to enforce semantic consistency, refining entity predictions based on class-level compatibility. Extensive experiments on two widely used benchmark datasets demonstrate that ReaLM achieves state-of-the-art performance, confirming its effectiveness in aligning structured knowledge with large-scale language models.",
        "tags": [
            "LLM",
            "Vector Quantization"
        ]
    },
    {
        "id": "24",
        "title": "Group-Adaptive Adversarial Learning for Robust Fake News Detection Against Malicious Comments",
        "author": [
            "Zhao Tong",
            "Chunlin Gong",
            "Yimeng Gu",
            "Haichao Shi",
            "Qiang Liu",
            "Shu Wu",
            "Xiao-Yu Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09712",
        "abstract": "The spread of fake news online distorts public judgment and erodes trust in social media platforms. Although recent fake news detection (FND) models perform well in standard settings, they remain vulnerable to adversarial comments-authored by real users or by large language models (LLMs)-that subtly shift model decisions. In view of this, we first present a comprehensive evaluation of comment attacks to existing fake news detectors and then introduce a group-adaptive adversarial training strategy to improve the robustness of FND models. To be specific, our approach comprises three steps: (1) dividing adversarial comments into three psychologically grounded categories: perceptual, cognitive, and societal; (2) generating diverse, category-specific attacks via LLMs to enhance adversarial training; and (3) applying a Dirichlet-based adaptive sampling mechanism (InfoDirichlet Adjusting Mechanism) that dynamically adjusts the learning focus across different comment categories during training. Experiments on benchmark datasets show that our method maintains strong detection accuracy while substantially increasing robustness to a wide range of adversarial comment perturbations.",
        "tags": [
            "Detection",
            "LLM"
        ]
    },
    {
        "id": "25",
        "title": "High-Power Training Data Identification with Provable Statistical Guarantees",
        "author": [
            "Zhenlong Liu",
            "Hao Zeng",
            "Weiran Huang",
            "Hongxin Wei"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09717",
        "abstract": "Identifying training data within large-scale models is critical for copyright litigation, privacy auditing, and ensuring fair evaluation. The conventional approaches treat it as a simple binary classification task without statistical guarantees. A recent approach is designed to control the false discovery rate (FDR), but its guarantees rely on strong, easily violated assumptions. In this paper, we introduce Provable Training Data Identification (PTDI), a rigorous method that identifies a set of training data with strict false discovery rate (FDR) control. Specifically, our method computes p-values for each data point using a set of known unseen data, and then constructs a conservative estimator for the data usage proportion of the test set, which allows us to scale these p-values. Our approach then selects the final set of training data by identifying all points whose scaled p-values fall below a data-dependent threshold. This entire procedure enables the discovery of training data with provable, strict FDR control and significantly boosted power. Extensive experiments across a wide range of models (LLMs and VLMs), and datasets demonstrate that PTDI strictly controls the FDR and achieves higher power.",
        "tags": [
            "LLM",
            "VLM"
        ]
    },
    {
        "id": "26",
        "title": "ICL-Router: In-Context Learned Model Representations for LLM Routing",
        "author": [
            "Chenxu Wang",
            "Hao Li",
            "Yiqun Zhang",
            "Linyao Chen",
            "Jianhao Chen",
            "Ping Jian",
            "Peng Ye",
            "Qiaosheng Zhang",
            "Shuyue Hu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09719",
        "abstract": "Large language models (LLMs) often exhibit complementary strengths. Model routing harnesses these strengths by dynamically directing each query to the most suitable model, given a candidate model pool. However, routing performance relies on accurate model representations, and adding new models typically requires retraining, limiting scalability. To address these challenges, we propose a novel routing method using in-context vectors to represent model capabilities. The method proceeds in two stages. First, queries are embedded and projected into vectors, with a projector and LLM-based router trained to reconstruct the original queries, aligning vector representations with the router's semantic space. Second, each candidate model is profiled on a query set, and the router learns -- based on in-context vectors of query and model performance -- to predict whether each model can correctly answer new queries. Extensive experiments demonstrate that our method achieves state-of-the-art routing performance in both in-distribution and out-of-distribution tasks. Moreover, our method allows for seamless integration of new models without retraining the router. The code is available at https://github.com/lalalamdbf/ICL-Router.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "27",
        "title": "Preference-Aware Memory Update for Long-Term LLM Agents",
        "author": [
            "Haoran Sun",
            "Zekun Zhang",
            "Shaoning Zeng"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09720",
        "abstract": "One of the key factors influencing the reasoning capabilities of LLM-based agents is their ability to leverage long-term memory. Integrating long-term memory mechanisms allows agents to make informed decisions grounded in historical interactions. While recent advances have significantly improved the storage and retrieval components, by encoding memory into dense vectors for similarity search or organizing memory as structured knowledge graphs most existing approaches fall short in memory updating. In particular, they lack mechanisms for dynamically refining preference memory representations in response to evolving user behaviors and contexts. To address this gap, we propose a Preference-Aware Memory Update Mechanism (PAMU) that enables dynamic and personalized memory refinement. By integrating sliding window averages (SW) with exponential moving averages (EMA), PAMU constructs a fused preference-aware representation that captures both short-term fluctuations and long-term user tendencies. We conduct experiments on five task scenarios of the LoCoMo dataset, and the results show that our mechanism can significantly improve the output quality of LLM in five baselines, validating its effectiveness in long-term conversations.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "28",
        "title": "A Comprehensive Survey on Benchmarks and Solutions in Software Engineering of LLM-Empowered Agentic System",
        "author": [
            "Jiale Guo",
            "Suizhi Huang",
            "Mei Li",
            "Dong Huang",
            "Xingsheng Chen",
            "Regina Zhang",
            "Zhijiang Guo",
            "Han Yu",
            "Siu-Ming Yiu",
            "Christian Jensen",
            "Pietro Lio",
            "Kwok-Yan Lam"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09721",
        "abstract": "The integration of LLMs into software engineering has catalyzed a paradigm shift from traditional rule-based systems to sophisticated agentic systems capable of autonomous problem-solving. Despite this transformation, the field lacks a comprehensive understanding of how benchmarks and solutions interconnect, hindering systematic progress and evaluation. This survey presents the first holistic analysis of LLM-empowered software engineering, bridging the critical gap between evaluation and solution approaches. We analyze 150+ recent papers and organize them into a comprehensive taxonomy spanning two major dimensions: (1) Solutions, categorized into prompt-based, fine-tuning-based, and agent-based paradigms, and (2) Benchmarks, covering code generation, translation, repair, and other tasks. Our analysis reveals how the field has evolved from simple prompt engineering to complex agentic systems incorporating planning and decomposition, reasoning and self-refinement, memory mechanisms, and tool augmentation. We present a unified pipeline that illustrates the complete workflow from task specification to final deliverables, demonstrating how different solution paradigms address varying complexity levels across software engineering tasks. Unlike existing surveys that focus on isolated aspects, we provide full-spectrum coverage connecting 50+ benchmarks with their corresponding solution strategies, enabling researchers to identify optimal approaches for specific evaluation criteria. Furthermore, we identify critical research gaps and propose actionable future directions, including multi-agent collaboration frameworks, self-evolving code generation systems, and integration of formal verification with LLM-based methods. This survey serves as a foundational resource for researchers and practitioners seeking to understand, evaluate, and advance LLM-empowered software engineering systems.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "29",
        "title": "Layout-Aware Parsing Meets Efficient LLMs: A Unified, Scalable Framework for Resume Information Extraction and Evaluation",
        "author": [
            "Fanwei Zhu",
            "Jinke Yu",
            "Zulong Chen",
            "Ying Zhou",
            "Junhao Ji",
            "Zhibo Yang",
            "Yuxue Zhang",
            "Haoyuan Hu",
            "Zhenghao Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09722",
        "abstract": "Automated resume information extraction is critical for scaling talent acquisition, yet its real-world deployment faces three major challenges: the extreme heterogeneity of resume layouts and content, the high cost and latency of large language models (LLMs), and the lack of standardized datasets and evaluation tools. In this work, we present a layout-aware and efficiency-optimized framework for automated extraction and evaluation that addresses all three challenges. Our system combines a fine-tuned layout parser to normalize diverse document formats, an inference-efficient LLM extractor based on parallel prompting and instruction tuning, and a robust two-stage automated evaluation framework supported by new benchmark datasets. Extensive experiments show that our framework significantly outperforms strong baselines in both accuracy and efficiency. In particular, we demonstrate that a fine-tuned compact 0.6B LLM achieves top-tier accuracy while significantly reducing inference latency and computational cost. The system is fully deployed in Alibaba's intelligent HR platform, supporting real-time applications across its business units.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "30",
        "title": "InteractScience: Programmatic and Visually-Grounded Evaluation of Interactive Scientific Demonstration Code Generation",
        "author": [
            "Qiaosheng Chen",
            "Yang Liu",
            "Lei Li",
            "Kai Chen",
            "Qipeng Guo",
            "Gong Cheng",
            "Fei Yuan"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09724",
        "abstract": "Large Language Models (LLMs) are increasingly capable of generating complete applications from natural language instructions, creating new opportunities in science and education. In these domains, interactive scientific demonstrations are particularly valuable for explaining concepts, supporting new teaching methods, and presenting research findings. Generating such demonstrations requires models to combine accurate scientific knowledge with the ability to implement interactive front-end code that behaves correctly and responds to user actions. This capability goes beyond the scope of existing benchmarks, which typically evaluate either knowledge question answering without grounding in code or static web code generation without scientific interactivity. To evaluate this integrated ability, we design a hybrid framework that combines programmatic functional testing to rigorously verify interaction logic with visually-grounded qualitative testing to assess rendered outputs against reference snapshots. Building on this framework, we present InteractScience, a benchmark consisting of a substantial set of carefully designed questions across five scientific domains, each paired with unit tests, reference snapshots, and checklists. We evaluate 30 leading open- and closed-source LLMs and report results that highlight ongoing weaknesses in integrating domain knowledge with interactive front-end coding. Our work positions InteractScience as the first benchmark to automatically measure this combined capability with realistic interactive operations, providing a foundation for advancing reliable and educationally useful scientific demonstration code generation. All code and data are publicly available at https://github.com/open-compass/InteractScience.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "31",
        "title": "Multi Camera Connected Vision System with Multi View Analytics: A Comprehensive Survey",
        "author": [
            "Muhammad Munsif",
            "Waqas Ahmad",
            "Amjid Ali",
            "Mohib Ullah",
            "Adnan Hussain",
            "Sung Wook Baik"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09731",
        "abstract": "Connected Vision Systems (CVS) are transforming a variety of applications, including autonomous vehicles, smart cities, surveillance, and human-robot interaction. These systems harness multi-view multi-camera (MVMC) data to provide enhanced situational awareness through the integration of MVMC tracking, re-identification (Re-ID), and action understanding (AU). However, deploying CVS in real-world, dynamic environments presents a number of challenges, particularly in addressing occlusions, diverse viewpoints, and environmental variability. Existing surveys have focused primarily on isolated tasks such as tracking, Re-ID, and AU, often neglecting their integration into a cohesive system. These reviews typically emphasize single-view setups, overlooking the complexities and opportunities provided by multi-camera collaboration and multi-view data analysis. To the best of our knowledge, this survey is the first to offer a comprehensive and integrated review of MVMC that unifies MVMC tracking, Re-ID, and AU into a single framework. We propose a unique taxonomy to better understand the critical components of CVS, dividing it into four key parts: MVMC tracking, Re-ID, AU, and combined methods. We systematically arrange and summarize the state-of-the-art datasets, methodologies, results, and evaluation metrics, providing a structured view of the field's progression. Furthermore, we identify and discuss the open research questions and challenges, along with emerging technologies such as lifelong learning, privacy, and federated learning, that need to be addressed for future advancements. The paper concludes by outlining key research directions for enhancing the robustness, efficiency, and adaptability of CVS in complex, real-world applications. We hope this survey will inspire innovative solutions and guide future research toward the next generation of intelligent and adaptive CVS.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "32",
        "title": "Evaluating LLM-Based Process Explanations under Progressive Behavioral-Input Reduction",
        "author": [
            "P. van Oerle",
            "R. H. Bemthuis",
            "F. A. Bukhsh"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09732",
        "abstract": "Large Language Models (LLMs) are increasingly used to generate textual explanations of process models discovered from event logs. Producing explanations from large behavioral abstractions (e.g., directly-follows graphs or Petri nets) can be computationally expensive. This paper reports an exploratory evaluation of explanation quality under progressive behavioral-input reduction, where models are discovered from progressively smaller prefixes of a fixed log. Our pipeline (i) discovers models at multiple input sizes, (ii) prompts an LLM to generate explanations, and (iii) uses a second LLM to assess completeness, bottleneck identification, and suggested improvements. On synthetic logs, explanation quality is largely preserved under moderate reduction, indicating a practical cost-quality trade-off. The study is exploratory, as the scores are LLM-based (comparative signals rather than ground truth) and the data are synthetic. The results suggest a path toward more computationally efficient, LLM-assisted process analysis in resource-constrained settings.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "33",
        "title": "VisRAG 2.0: Evidence-Guided Multi-Image Reasoning in Visual Retrieval-Augmented Generation",
        "author": [
            "Yubo Sun",
            "Chunyi Peng",
            "Yukun Yan",
            "Shi Yu",
            "Zhenghao Liu",
            "Chi Chen",
            "Zhiyuan Liu",
            "Maosong Sun"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09733",
        "abstract": "Visual retrieval-augmented generation (VRAG) augments vision-language models (VLMs) with external visual knowledge to ground reasoning and reduce hallucinations. Yet current VRAG systems often fail to reliably perceive and integrate evidence across multiple images, leading to weak grounding and erroneous conclusions. In this paper, we propose EVisRAG, an end-to-end framework that learns to reason with evidence-guided multi-image to address this issue. The model first observes retrieved images and records per-image evidence, then derives the final answer from the aggregated evidence. To train EVisRAG effectively, we introduce Reward-Scoped Group Relative Policy Optimization (RS-GRPO), which binds fine-grained rewards to scope-specific tokens to jointly optimize visual perception and reasoning abilities of VLMs. Experimental results on multiple visual question answering benchmarks demonstrate that EVisRAG delivers substantial end-to-end gains over backbone VLM with 27\\% improvements on average. Further analysis shows that, powered by RS-GRPO, EVisRAG improves answer accuracy by precisely perceiving and localizing question-relevant evidence across multiple images and deriving the final answer from that evidence, much like a real detective.",
        "tags": [
            "GRPO",
            "VLM"
        ]
    },
    {
        "id": "34",
        "title": "ARROW: An Adaptive Rollout and Routing Method for Global Weather Forecasting",
        "author": [
            "Jindong Tian",
            "Yifei Ding",
            "Ronghui Xu",
            "Hao Miao",
            "Chenjuan Guo",
            "Bin Yang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09734",
        "abstract": "Weather forecasting is a fundamental task in spatiotemporal data analysis, with broad applications across a wide range of domains. Existing data-driven forecasting methods typically model atmospheric dynamics over a fixed short time interval (e.g., 6 hours) and rely on naive autoregression-based rollout for long-term forecasting (e.g., 138 hours). However, this paradigm suffers from two key limitations: (1) it often inadequately models the spatial and multi-scale temporal dependencies inherent in global weather systems, and (2) the rollout strategy struggles to balance error accumulation with the capture of fine-grained atmospheric variations. In this study, we propose ARROW, an Adaptive-Rollout Multi-scale temporal Routing method for Global Weather Forecasting. To contend with the first limitation, we construct a multi-interval forecasting model that forecasts weather across different time intervals. Within the model, the Shared-Private Mixture-of-Experts captures both shared patterns and specific characteristics of atmospheric dynamics across different time scales, while Ring Positional Encoding accurately encodes the circular latitude structure of the Earth when representing spatial information. For the second limitation, we develop an adaptive rollout scheduler based on reinforcement learning, which selects the most suitable time interval to forecast according to the current weather state. Experimental results demonstrate that ARROW achieves state-of-the-art performance in global weather forecasting, establishing a promising paradigm in this field.",
        "tags": [
            "MoE",
            "RL"
        ]
    },
    {
        "id": "35",
        "title": "InterCorpRel-LLM: Enhancing Financial Relational Understanding with Graph-Language Models",
        "author": [
            "Qianyou Sun",
            "Jiexin Zheng",
            "Bohan Jin",
            "Lihua Chen",
            "Yijie Peng"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09735",
        "abstract": "Identifying inter-firm relationships such as supply and competitive ties is critical for financial analysis and corporate governance, yet remains challenging due to the scale, sparsity, and contextual dependence of corporate data. Graph-based methods capture structure but miss semantic depth, while large language models (LLMs) excel at text but remain limited in their ability to represent relational dependencies. To address this, we propose InterCorpRel-LLM, a cross-modal framework that integrates GNNs with LLMs, supported by a proprietary dataset derived from FactSet supply chain records and three tailored training tasks: company graph matching, industry classification, and supply relation prediction. This design enables effective joint modeling of structure and semantics. Experiments show that InterCorpRel-LLM substantially outperforms strong baselines, including GPT-5, on a supply relation identification task, achieving an F-score of 0.8543 vs. 0.2287 with only a 7B-parameter backbone and lightweight training. The model also generalizes to zero-shot competitor identification, underscoring its ability to capture nuanced inter-firm dynamics. Our framework thus provides analysts and strategists with a robust tool for mapping and reasoning about complex corporate networks, enhancing decision-making and risk management in dynamic markets.",
        "tags": [
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "36",
        "title": "Judge's Verdict: A Comprehensive Analysis of LLM Judge Capability Through Human Agreement",
        "author": [
            "Steve Han",
            "Gilberto Titericz Junior",
            "Tom Balough",
            "Wenfei Zhou"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09738",
        "abstract": "This research introduces the Judge's Verdict Benchmark, a novel two-step methodology to evaluate Large Language Models (LLMs) as judges for response accuracy evaluation tasks. We assess how well 54 LLMs can replicate human judgment when scoring responses from RAG (Retrieval-Augmented Generation) or Agentic pipelines against ground truth answers. Our methodology progresses from traditional correlation analysis to comprehensive Cohen's Kappa analysis that measures actual agreement patterns. The two-step approach includes: (1) a correlation test that filters judges with strong alignment, followed by (2) a human-likeness test using z-scores to identify two distinct judgment patterns: human-like judgment (|z| < 1) that mimics natural human variation, and super-consistent judgment (z > 1) that exceeds typical human-to-human agreement levels. This methodology reveals that 27 out of 54 tested LLMs achieve Tier 1 performance: 23 models exhibit human-like patterns that preserve the nuances of human judgment, while 4 models demonstrate super-consistent behavior, a pattern that could indicate either enhanced reliability or oversimplification of complex judgments. Testing 43 open-source models (1B-405B parameters) and 11 closed models (GPT, Gemini, Claude variants), we demonstrate that judge excellence is not solely dependent on model size but on specific training strategies. Our key contributions include: (1) establishing that correlation alone is insufficient for judge evaluation, (2) introducing a \"Turing Test for judges\" based on agreement patterns, and (3) providing a standardized benchmark for classifying LLM judges into distinct performance tiers for different evaluation needs.",
        "tags": [
            "GPT",
            "LLM",
            "RAG"
        ]
    },
    {
        "id": "37",
        "title": "Constructive Distortion: Improving MLLMs with Attention-Guided Image Warping",
        "author": [
            "Dwip Dalal",
            "Gautam Vashishtha",
            "Utkarsh Mishra",
            "Jeonghwan Kim",
            "Madhav Kanda",
            "Hyeonjeong Ha",
            "Svetlana Lazebnik",
            "Heng Ji",
            "Unnat Jain"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09741",
        "abstract": "Multimodal large language models (MLLMs) often miss small details and spatial relations in cluttered scenes, leading to errors in fine-grained perceptual grounding. We introduce AttWarp, a lightweight method that allocates more resolution to query-relevant content while compressing less informative areas, all while preserving global context. At test time, the approach uses an MLLM's cross-modal attention to perform rectilinear warping of the input image, reallocating spatial resolution toward regions the model deems important, without changing model weights or architecture. This attention-guided warping preserves all original image information but redistributes it non-uniformly, so small objects and subtle relationships become easier for the same model to read while the global layout remains intact. Across five benchmarks (TextVQA, GQA, DocVQA, POPE, MMMU) and four MLLMs (LLaVA, Qwen-VL, InternVL, and InstructBLIP), AttWarp consistently improves accuracy, strengthens compositional reasoning, and reduces hallucinations, outperforming four competitive baselines that manipulate raw images at test time. Together, these results show that attention-guided warping prioritizes information relevant to the query while preserving context, and that the same MLLMs perform better when given such warped inputs.",
        "tags": [
            "LLM",
            "LLaVA",
            "Qwen"
        ]
    },
    {
        "id": "38",
        "title": "PatentVision: A multimodal method for drafting patent applications",
        "author": [
            "Ruo Yang",
            "Sai Krishna Reddy Mudhiganti",
            "Manali Sharma"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09762",
        "abstract": "Patent drafting is complex due to its need for detailed technical descriptions, legal compliance, and visual elements. Although Large Vision Language Models (LVLMs) show promise across various tasks, their application in automating patent writing remains underexplored. In this paper, we present PatentVision, a multimodal framework that integrates textual and visual inputs such as patent claims and drawings to generate complete patent specifications. Built on advanced LVLMs, PatentVision enhances accuracy by combining fine tuned vision language models with domain specific training tailored to patents. Experiments reveal it surpasses text only methods, producing outputs with greater fidelity and alignment with human written standards. Its incorporation of visual data allows it to better represent intricate design features and functional connections, leading to richer and more precise results. This study underscores the value of multimodal techniques in patent automation, providing a scalable tool to reduce manual workloads and improve consistency. PatentVision not only advances patent drafting but also lays the groundwork for broader use of LVLMs in specialized areas, potentially transforming intellectual property management and innovation processes.",
        "tags": [
            "VLM"
        ]
    },
    {
        "id": "39",
        "title": "Leveraging Shared Prototypes for a Multimodal Pulse Motion Foundation Model",
        "author": [
            "Wanting Mao",
            "Maxwell A Xu",
            "Harish Haresamudram",
            "Mithun Saha",
            "Santosh Kumar",
            "James Matthew Rehg"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09764",
        "abstract": "Modeling multi-modal time-series data is critical for capturing system-level dynamics, particularly in biosignals where modalities such as ECG, PPG, EDA, and accelerometry provide complementary perspectives on interconnected physiological processes. While recent self-supervised learning (SSL) advances have improved unimodal representation learning, existing multi-modal approaches often rely on CLIP-style contrastive objectives that overfit to easily aligned features and misclassify valid cross-modal relationships as negatives, resulting in fragmented and non-generalizable embeddings. To overcome these limitations, we propose ProtoMM, a novel SSL framework that introduces a shared prototype dictionary to anchor heterogeneous modalities in a common embedding space. By clustering representations around shared prototypes rather than explicit negative sampling, our method captures complementary information across modalities and provides a coherent \"common language\" for physiological signals. In this work, we focus on developing a Pulse Motion foundation model with ProtoMM and demonstrate that our approach outperforms contrastive-only and prior multimodal SSL methods, achieving state-of-the-art performance while offering improved interpretability of learned features.",
        "tags": [
            "CLIP"
        ]
    },
    {
        "id": "40",
        "title": "HeSRN: Representation Learning On Heterogeneous Graphs via Slot-Aware Retentive Network",
        "author": [
            "Yifan Lu",
            "Ziyun Zou",
            "Belal Alsinglawi",
            "Islam Al-Qudah",
            "Izzat Alsmadi",
            "Feilong Tang",
            "Pengfei Jiao",
            "Shoaib Jameel"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09767",
        "abstract": "Graph Transformers have recently achieved remarkable progress in graph representation learning by capturing long-range dependencies through self-attention. However, their quadratic computational complexity and inability to effectively model heterogeneous semantics severely limit their scalability and generalization on real-world heterogeneous graphs. To address these issues, we propose HeSRN, a novel Heterogeneous Slot-aware Retentive Network for efficient and expressive heterogeneous graph representation learning. HeSRN introduces a slot-aware structure encoder that explicitly disentangles node-type semantics by projecting heterogeneous features into independent slots and aligning their distributions through slot normalization and retention-based fusion, effectively mitigating the semantic entanglement caused by forced feature-space unification in previous Transformer-based models. Furthermore, we replace the self-attention mechanism with a retention-based encoder, which models structural and contextual dependencies in linear time complexity while maintaining strong expressive power. A heterogeneous retentive encoder is further employed to jointly capture both local structural signals and global heterogeneous semantics through multi-scale retention layers. Extensive experiments on four real-world heterogeneous graph datasets demonstrate that HeSRN consistently outperforms state-of-the-art heterogeneous graph neural networks and Graph Transformer baselines on node classification tasks, achieving superior accuracy with significantly lower computational complexity.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "41",
        "title": "Gold Panning: Turning Positional Bias into Signal for Multi-Document LLM Reasoning",
        "author": [
            "Adam Byerly",
            "Daniel Khashabi"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09770",
        "abstract": "Large language models exhibit a strong position bias in multi-document contexts, systematically prioritizing information based on location rather than relevance. While existing approaches treat this bias as noise to be mitigated, we introduce Gold Panning Bandits, a framework that leverages position bias as a diagnostic signal: by reordering documents and observing shifts in the model's responses, we can efficiently identify the most relevant content. We frame the problem of choosing reorderings as a bipartite matching problem. While an optimal assignment can be computed at each iteration with the Hungarian algorithm in $O(N^3)$ time, we propose a greedy $O(N \\log N)$ strategy that achieves comparable performance by prioritizing the placement of the most uncertain documents in the most informative positions. Our approach identifies relevant documents using up to 65\\% fewer language model queries than random permutation baselines on knowledge-intensive NLP tasks, substantially reducing computational cost without model retraining. This work demonstrates that inherent LLM biases can be transformed from liabilities into assets for efficient, inference-time optimization.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "42",
        "title": "Why Do Transformers Fail to Forecast Time Series In-Context?",
        "author": [
            "Yufa Zhou",
            "Yixiao Wang",
            "Surbhi Goel",
            "Anru R. Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09776",
        "abstract": "Time series forecasting (TSF) remains a challenging and largely unsolved problem in machine learning, despite significant recent efforts leveraging Large Language Models (LLMs), which predominantly rely on Transformer architectures. Empirical evidence consistently shows that even powerful Transformers often fail to outperform much simpler models, e.g., linear models, on TSF tasks; however, a rigorous theoretical understanding of this phenomenon remains limited. In this paper, we provide a theoretical analysis of Transformers' limitations for TSF through the lens of In-Context Learning (ICL) theory. Specifically, under AR($p$) data, we establish that: (1) Linear Self-Attention (LSA) models $\\textit{cannot}$ achieve lower expected MSE than classical linear models for in-context forecasting; (2) as the context length approaches to infinity, LSA asymptotically recovers the optimal linear predictor; and (3) under Chain-of-Thought (CoT) style inference, predictions collapse to the mean exponentially. We empirically validate these findings through carefully designed experiments. Our theory not only sheds light on several previously underexplored phenomena but also offers practical insights for designing more effective forecasting architectures. We hope our work encourages the broader research community to revisit the fundamental theoretical limitations of TSF and to critically evaluate the direct application of increasingly sophisticated architectures without deeper scrutiny.",
        "tags": [
            "CoT",
            "LLM",
            "Transformer"
        ]
    },
    {
        "id": "43",
        "title": "Building a Foundational Guardrail for General Agentic Systems via Synthetic Data",
        "author": [
            "Yue Huang",
            "Hang Hua",
            "Yujun Zhou",
            "Pengcheng Jing",
            "Manish Nagireddy",
            "Inkit Padhi",
            "Greta Dolcetti",
            "Zhangchen Xu",
            "Subhajit Chaudhury",
            "Ambrish Rawat",
            "Liubov Nedoshivina",
            "Pin-Yu Chen",
            "Prasanna Sattigeri",
            "Xiangliang Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09781",
        "abstract": "While LLM agents can plan multi-step tasks, intervening at the planning stage-before any action is executed-is often the safest way to prevent harm, since certain risks can lead to severe consequences once carried out. However, existing guardrails mostly operate post-execution, which is difficult to scale and leaves little room for controllable supervision at the plan level. To address this challenge, we highlight three critical gaps in current research: data gap, model gap, and evaluation gap. To close the data gap, we introduce AuraGen, a controllable engine that (i) synthesizes benign trajectories, (ii) injects category-labeled risks with calibrated difficulty, and (iii) filters outputs via an automated reward model, producing large and reliable corpora for pre-execution safety. To close the guardian model gap, we propose a foundational guardrail Safiron, combining a cross-planner adapter with a compact guardian model. The adapter unifies different input formats, while Safiron flags risky cases, assigns risk types, and generates rationales; trained in two stages with a broadly explored data recipe, Safiron achieves robust transfer across settings. To close the evaluation gap, we release Pre-Exec Bench, a realistic benchmark covering diverse tools and branching trajectories, which measures detection, fine-grained categorization, explanation, and cross-planner generalization in human-verified scenarios. Extensive experiments demonstrate consistent gains of the proposed guardrail over strong baselines on Pre-Exec Bench, and ablations further distill actionable practices, providing a practical template for safer agentic systems.",
        "tags": [
            "Detection",
            "LLM"
        ]
    },
    {
        "id": "44",
        "title": "The Geometry of Reasoning: Flowing Logics in Representation Space",
        "author": [
            "Yufa Zhou",
            "Yixiao Wang",
            "Xunjian Yin",
            "Shuyan Zhou",
            "Anru R. Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09782",
        "abstract": "We study how large language models (LLMs) ``think'' through their representation space. We propose a novel geometric framework that models an LLM's reasoning as flows -- embedding trajectories evolving where logic goes. We disentangle logical structure from semantics by employing the same natural deduction propositions with varied semantic carriers, allowing us to test whether LLMs internalize logic beyond surface form. This perspective connects reasoning with geometric quantities such as position, velocity, and curvature, enabling formal analysis in representation and concept spaces. Our theory establishes: (1) LLM reasoning corresponds to smooth flows in representation space, and (2) logical statements act as local controllers of these flows' velocities. Using learned representation proxies, we design controlled experiments to visualize and quantify reasoning flows, providing empirical validation of our theoretical framework. Our work serves as both a conceptual foundation and practical tools for studying reasoning phenomenon, offering a new lens for interpretability and formal analysis of LLMs' behavior.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "45",
        "title": "Enhancing Diffusion Policy with Classifier-Free Guidance for Temporal Robotic Tasks",
        "author": [
            "Yuang Lu",
            "Song Wang",
            "Xiao Han",
            "Xuri Zhang",
            "Yucong Wu",
            "Zhicheng He"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09786",
        "abstract": "Temporal sequential tasks challenge humanoid robots, as existing Diffusion Policy (DP) and Action Chunking with Transformers (ACT) methods often lack temporal context, resulting in local optima traps and excessive repetitive actions. To address these issues, this paper introduces a Classifier-Free Guidance-Based Diffusion Policy (CFG-DP), a novel framework to enhance DP by integrating Classifier-Free Guidance (CFG) with conditional and unconditional models. Specifically, CFG leverages timestep inputs to track task progression and ensure precise cycle termination. It dynamically adjusts action predictions based on task phase, using a guidance factor tuned to balance temporal coherence and action accuracy. Real-world experiments on a humanoid robot demonstrate high success rates and minimal repetitive actions. Furthermore, we assessed the model's ability to terminate actions and examined how different components and parameter adjustments affect its performance. This framework significantly enhances deterministic control and execution reliability for sequential robotic tasks.",
        "tags": [
            "Diffusion",
            "Robotics"
        ]
    },
    {
        "id": "46",
        "title": "How can we assess human-agent interactions? Case studies in software agent design",
        "author": [
            "Valerie Chen",
            "Rohit Malhotra",
            "Xingyao Wang",
            "Juan Michelini",
            "Xuhui Zhou",
            "Aditya Bharat Soni",
            "Hoang H. Tran",
            "Calvin Smith",
            "Ameet Talwalkar",
            "Graham Neubig"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09801",
        "abstract": "LLM-powered agents are both a promising new technology and a source of complexity, where choices about models, tools, and prompting can affect their usefulness. While numerous benchmarks measure agent accuracy across domains, they mostly assume full automation, failing to represent the collaborative nature of real-world use cases. In this paper, we make two major steps towards the rigorous assessment of human-agent interactions. First, we propose PULSE, a framework for more efficient human-centric evaluation of agent designs, which comprises collecting user feedback, training an ML model to predict user satisfaction, and computing results by combining human satisfaction ratings with model-generated pseudo-labels. Second, we deploy the framework on a large-scale web platform built around the open-source software agent OpenHands, collecting in-the-wild usage data across over 15k users. We conduct case studies around how three agent design decisions -- choice of LLM backbone, planning strategy, and memory mechanisms -- impact developer satisfaction rates, yielding practical insights for software agent design. We also show how our framework can lead to more robust conclusions about agent design, reducing confidence intervals by 40\\% compared to a standard A/B test. Finally, we find substantial discrepancies between in-the-wild results and benchmark performance (e.g., the anti-correlation between results comparing claude-sonnet-4 and gpt-5), underscoring the limitations of benchmark-driven evaluation. Our findings provide guidance for evaluations of LLM agents with humans and identify opportunities for better agent designs.",
        "tags": [
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "47",
        "title": "Task-Aware Resolution Optimization for Visual Large Language Models",
        "author": [
            "Weiqing Luo",
            "Zhen Tan",
            "Yifan Li",
            "Xinyu Zhao",
            "Kwonjoon Lee",
            "Behzad Dariush",
            "Tianlong Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09822",
        "abstract": "Real-world vision-language applications demand varying levels of perceptual granularity. However, most existing visual large language models (VLLMs), such as LLaVA, pre-assume a fixed resolution for downstream tasks, which leads to subpar performance. To address this problem, we first conduct a comprehensive and pioneering investigation into the resolution preferences of different vision-language tasks, revealing a correlation between resolution preferences with image complexity, and uncertainty variance of the VLLM at different image input resolutions. Building on this insight, we propose an empirical formula to determine the optimal resolution for a given vision-language task, combining these two factors. Second, based on rigorous experiments, we propose a novel parameter-efficient fine-tuning technique to extend the visual input resolution of pre-trained VLLMs to the identified optimal resolution. Extensive experiments on various vision-language tasks validate the effectiveness of our method.",
        "tags": [
            "LLM",
            "LLaVA"
        ]
    },
    {
        "id": "48",
        "title": "Text Prompt Injection of Vision Language Models",
        "author": [
            "Ruizhe Zhu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09849",
        "abstract": "The widespread application of large vision language models has significantly raised safety concerns. In this project, we investigate text prompt injection, a simple yet effective method to mislead these models. We developed an algorithm for this type of attack and demonstrated its effectiveness and efficiency through experiments. Compared to other attack methods, our approach is particularly effective for large models without high demand for computational resources.",
        "tags": [
            "VLM"
        ]
    },
    {
        "id": "49",
        "title": "ProxRouter: Proximity-Weighted LLM Query Routing for Improved Robustness to Outliers",
        "author": [
            "Shivam Patel",
            "Neharika Jali",
            "Ankur Mallick",
            "Gauri Joshi"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09852",
        "abstract": "Large language model (LLM) query routers are critical to modern AI platforms as they seek to improve efficiency by assigning inference queries to accurate, yet low-cost models. Parametric routers typically use trained neural networks for LLM selection but suffer from retraining and maintenance overheads. Nonparametric routers are training-free, instead estimating LLM accuracy and cost via similarity between encodings of the input query and training set queries. However, like their parametric counterparts, nonparametric routers struggle to generalize to outlier queries, an issue exacerbated by limited diversity in training sets which are costly to expand and difficult to keep current with ever-evolving use cases. We propose ProxRouter, which applies an exponentially tilted aggregation mechanism to balance bias and variance in nonparametric routers, improving their robustness to outliers. Experiments show ProxRouter enhances outlier routing while preserving inlier performance with minimal overhead.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "50",
        "title": "Cluster-Aware Prompt Ensemble Learning for Few-Shot Vision-Language Model Adaptation",
        "author": [
            "Zhi Chen",
            "Xin Yu",
            "Xiaohui Tao",
            "Yan Li",
            "Zi Huang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09867",
        "abstract": "Vision-language models (VLMs) such as CLIP achieve zero-shot transfer across various tasks by pre-training on numerous image-text pairs. These models often benefit from using an ensemble of context prompts to represent a class. Despite being effective, conventional prompt ensembling that averages textual features of context prompts often yields suboptimal results. This is because feature averaging shifts the class centroids away from the true class distribution. To address this issue, we propose the Cluster-Aware Prompt Ensemble Learning (CAPEL) framework, which preserves the cluster nature of context prompts. CAPEL classifies images into one of several class clusters, each represented by a distinct prompt. Instead of ensembling prompts in the feature space, we perform ensembling in the classification logits space, aligning better with the visual feature distribution. To further optimize prompt fine-tuning while maintaining cluster-specific discriminative power, we introduce a cluster-preserving regularization term. This ensures that prompts remain distinct and specialized for different clusters, preventing collapse into a uniform direction. Additionally, we integrate an adaptive prompt weighting technique to dynamically adjust the attention weights for flawed or ambiguous prompts, ensuring robust performance across diverse datasets and tasks.",
        "tags": [
            "CLIP",
            "VLM"
        ]
    },
    {
        "id": "51",
        "title": "NarraBench: A Comprehensive Framework for Narrative Benchmarking",
        "author": [
            "Sil Hamilton",
            "Matthew Wilkens",
            "Andrew Piper"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09869",
        "abstract": "We present NarraBench, a theory-informed taxonomy of narrative-understanding tasks, as well as an associated survey of 78 existing benchmarks in the area. We find significant need for new evaluations covering aspects of narrative understanding that are either overlooked in current work or are poorly aligned with existing metrics. Specifically, we estimate that only 27% of narrative tasks are well captured by existing benchmarks, and we note that some areas -- including narrative events, style, perspective, and revelation -- are nearly absent from current evaluations. We also note the need for increased development of benchmarks capable of assessing constitutively subjective and perspectival aspects of narrative, that is, aspects for which there is generally no single correct answer. Our taxonomy, survey, and methodology are of value to NLP researchers seeking to test LLM narrative understanding.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "52",
        "title": "WARC-Bench: Web Archive Based Benchmark for GUI Subtask Executions",
        "author": [
            "Sanjari Srivastava",
            "Gang Li",
            "Cheng Chang",
            "Rishu Garg",
            "Manpreet Kaur",
            "Charlene Y. Lee",
            "Yuezhang Li",
            "Yining Mao",
            "Ignacio Cases",
            "Yanan Xie",
            "Peng Qi"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09872",
        "abstract": "Training web agents to navigate complex, real-world websites requires them to master $\\textit{subtasks}$ - short-horizon interactions on multiple UI components (e.g., choosing the correct date in a date picker, or scrolling in a container to extract information). We introduce WARC-Bench (Web Archive Benchmark), a novel web navigation benchmark featuring 438 tasks designed to evaluate multimodal AI agents on subtasks. WARC-Bench enables sandboxed interactions with dynamic and realistic webpages using Web ARChive files. We show that WARC-Bench is challenging for leading computer-use models, with the highest observed success rate being 64.8%. To improve open source models on subtask, we explore two common training techniques: supervised fine-tuning (SFT) and reinforcement learning with verifiable rewards (RLVR). Experiments show that SFT models obtain a 48.8% success rate on the benchmark. Training with RLVR over SFT checkpoints, even in data-scarce settings, improves the score to 52.8% on WARC-Bench, outperforming many frontier models. Our analysis concludes that mastering these subtasks is essential for robust web planning and navigation, and is a capability not extensively evaluated by existing benchmarks.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "53",
        "title": "ROBOPSY PL[AI]: Using Role-Play to Investigate how LLMs Present Collective Memory",
        "author": [
            "Margarete Jahrmann",
            "Thomas Brandstetter",
            "Stefan Glasauer"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09874",
        "abstract": "The paper presents the first results of an artistic research project investigating how Large Language Models (LLMs) curate and present collective memory. In a public installation exhibited during two months in Vienna in 2025, visitors could interact with five different LLMs (ChatGPT with GPT 4o and GPT 4o mini, Mistral Large, DeepSeek-Chat, and a locally run Llama 3.1 model), which were instructed to act as narrators, implementing a role-playing game revolving around the murder of Austrian philosopher Moritz Schlick in 1936. Results of the investigation include protocols of LLM-user interactions during the game and qualitative conversations after the play experience to get insight into the players' reactions to the game. In a quantitative analysis 115 introductory texts for role-playing generated by the LLMs were examined by different methods of natural language processing, including semantic similarity and sentiment analysis. While the qualitative player feedback allowed to distinguish three distinct types of users, the quantitative text analysis showed significant differences between how the different LLMs presented the historical content. Our study thus adds to ongoing efforts to analyse LLM performance, but also suggests a way of how these efforts can be disseminated in a playful way to a general audience.",
        "tags": [
            "DeepSeek",
            "GPT",
            "LLM",
            "LLaMA"
        ]
    },
    {
        "id": "54",
        "title": "Geometry-Aware Scene Configurations for Novel View Synthesis",
        "author": [
            "Minkwan Kim",
            "Changwoon Choi",
            "Young Min Kim"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09880",
        "abstract": "We propose scene-adaptive strategies to efficiently allocate representation capacity for generating immersive experiences of indoor environments from incomplete observations. Indoor scenes with multiple rooms often exhibit irregular layouts with varying complexity, containing clutter, occlusion, and flat walls. We maximize the utilization of limited resources with guidance from geometric priors, which are often readily available after pre-processing stages. We record observation statistics on the estimated geometric scaffold and guide the optimal placement of bases, which greatly improves upon the uniform basis arrangements adopted by previous scalable Neural Radiance Field (NeRF) representations. We also suggest scene-adaptive virtual viewpoints to compensate for geometric deficiencies inherent in view configurations in the input trajectory and impose the necessary regularization. We present a comprehensive analysis and discussion regarding rendering quality and memory requirements in several large-scale indoor scenes, demonstrating significant enhancements compared to baselines that employ regular placements.",
        "tags": [
            "NeRF"
        ]
    },
    {
        "id": "55",
        "title": "LTGS: Long-Term Gaussian Scene Chronology From Sparse View Updates",
        "author": [
            "Minkwan Kim",
            "Seungmin Lee",
            "Junho Kim",
            "Young Min Kim"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09881",
        "abstract": "Recent advances in novel-view synthesis can create the photo-realistic visualization of real-world environments from conventional camera captures. However, acquiring everyday environments from casual captures faces challenges due to frequent scene changes, which require dense observations both spatially and temporally. We propose long-term Gaussian scene chronology from sparse-view updates, coined LTGS, an efficient scene representation that can embrace everyday changes from highly under-constrained casual captures. Given an incomplete and unstructured Gaussian splatting representation obtained from an initial set of input images, we robustly model the long-term chronology of the scene despite abrupt movements and subtle environmental variations. We construct objects as template Gaussians, which serve as structural, reusable priors for shared object tracks. Then, the object templates undergo a further refinement pipeline that modulates the priors to adapt to temporally varying environments based on few-shot observations. Once trained, our framework is generalizable across multiple time steps through simple transformations, significantly enhancing the scalability for a temporal evolution of 3D environments. As existing datasets do not explicitly represent the long-term real-world changes with a sparse capture setup, we collect real-world datasets to evaluate the practicality of our pipeline. Experiments demonstrate that our framework achieves superior reconstruction quality compared to other baselines while enabling fast and light-weight updates.",
        "tags": [
            "3D",
            "Gaussian Splatting"
        ]
    },
    {
        "id": "56",
        "title": "iBERT: Interpretable Style Embeddings via Sense Decomposition",
        "author": [
            "Vishal Anand",
            "Milad Alshomary",
            "Kathleen McKeown"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09882",
        "abstract": "We present iBERT (interpretable-BERT), an encoder to produce inherently interpretable and controllable embeddings - designed to modularize and expose the discriminative cues present in language, such as stylistic and semantic structure. Each input token is represented as a sparse, non-negative mixture over k context-independent sense vectors, which can be pooled into sentence embeddings or used directly at the token level. This enables modular control over representation, before any decoding or downstream use.\nTo demonstrate our model's interpretability, we evaluate it on a suite of style-focused tasks. On the STEL benchmark, it improves style representation effectiveness by ~8 points over SBERT-style baselines, while maintaining competitive performance on authorship verification. Because each embedding is a structured composition of interpretable senses, we highlight how specific style attributes - such as emoji use, formality, or misspelling can be assigned to specific sense vectors. While our experiments center on style, iBERT is not limited to stylistic modeling. Its structural modularity is designed to interpretably decompose whichever discriminative signals are present in the data - enabling generalization even when supervision blends stylistic and semantic factors.",
        "tags": [
            "BERT"
        ]
    },
    {
        "id": "57",
        "title": "DELTA: Dynamic Layer-Aware Token Attention for Efficient Long-Context Reasoning",
        "author": [
            "Hossein Entezari Zarch",
            "Lei Gao",
            "Chaoyi Jiang",
            "Murali Annavarm"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09883",
        "abstract": "Large reasoning models (LRMs) achieve state-of-the-art performance on challenging benchmarks by generating long chains of intermediate steps, but their inference cost is dominated by decoding, where each new token must attend to the entire growing sequence. Existing sparse attention methods reduce computation by pruning the key-value (KV) cache, yet they suffer from severe accuracy degradation on reasoning tasks due to cumulative selection errors and the dynamic importance of tokens over long derivations. We present \\textbf{DELTA}, a training-free sparse attention mechanism that achieves computational efficiency without sacrificing model accuracy. DELTA partitions transformer layers into three groups: initial layers that use full attention, a small set of \\emph{selection layers} that identify salient tokens via aggregated head-level attention scores, and subsequent \\emph{sparse-attention layers} that attend only to the selected subset. This design preserves the full KV cache in GPU memory for accuracy, while avoiding expensive full-attention computation over many layers. On reasoning benchmarks such as AIME and GPQA-Diamond, DELTA matches or surpasses full attention in accuracy, while reducing the number of attended tokens by up to $5\\times$ and delivering $1.5\\times$ end-to-end speedup. Our results show that selective reuse of intermediate attention maps offers a robust path toward efficient long-context reasoning.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "58",
        "title": "Closing the Data-Efficiency Gap Between Autoregressive and Masked Diffusion LLMs",
        "author": [
            "Xu Pan",
            "Ely Hahami",
            "Jingxuan Fan",
            "Ziqian Xie",
            "Haim Sompolinsky"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09885",
        "abstract": "Despite autoregressive large language models (arLLMs) being the current dominant paradigm in language modeling, they resist knowledge injection via fine-tuning due to inherent shortcomings such as the \"reversal curse\" -- the challenge of answering questions that reverse the original information order in the training sample. Masked diffusion large language models (dLLMs) are rapidly emerging as a powerful alternative to the arLLM paradigm, with evidence of better data efficiency and free of the \"reversal curse\" in pre-training. However, it is unknown whether these advantages extend to the post-training phase, i.e. whether pre-trained dLLMs can easily acquire new knowledge through fine-tuning. On three diverse datasets, we fine-tune arLLMs and dLLMs, evaluating them with forward and backward style Question Answering (QA) to probe knowledge generalization and the reversal curse. Our results confirm that arLLMs critically rely on extensive data augmentation via paraphrases for QA generalization, and paraphrases are only effective when their information order matches the QA style. Conversely, dLLMs achieve high accuracies on both forward and backward QAs without paraphrases; adding paraphrases yields only marginal gains. Lastly, inspired by the dLLM's performance, we introduce a novel masked fine-tuning paradigm for knowledge injection into pre-trained arLLMs. This proposed method successfully and drastically improves the data efficiency of arLLM fine-tuning, effectively closing the performance gap with dLLMs.",
        "tags": [
            "Diffusion",
            "LLM"
        ]
    },
    {
        "id": "59",
        "title": "Abductive Preference Learning",
        "author": [
            "Yijin Ni",
            "Peng Qi"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09887",
        "abstract": "Frontier large language models such as GPT-5 and Claude Sonnet remain prone to overconfidence even after alignment through Reinforcement Learning with Human Feedback (RLHF) and Direct Preference Optimization (DPO). For instance, they tend to offer the same conservative answer \"No\" to both questions \"Can I eat the [food / potato chips] that has been left out overnight?\" despite the latter requiring no refridgeration for safe consumption. We find that this failure is potentially attributed to a limitation of existing preference learning: it emphasizes selecting the correct response for a given prompt, while neglecting counterfactual prompts that should alter the response.\nTo address this limitation, we propose abductive preference learning, a fine-tuning paradigm that reverses the conventional conditioning by learning preferences over prompts given a response. To validate this idea, we construct an abductive dataset derived from the HaluEval QA benchmark with 1,001 entries, implementing abductive DPO and its variant DPOP. Experiments reveal complementary strengths: standard methods improve response selection, abductive methods improve prompt discrimination, while a multitask objective unifies both. On the abductive dataset, multitask DPOP boosts accuracy from $90.0\\%$ to $99.5\\%$ in response selection and $54.7\\%$ to $85.0\\%$ in prompt discrimination, with qualitative evidence highlighting improved sensitivity to prompt differences. Finally, evaluation on AlpacaEval shows multitask DPOP improves win rate (from $5.26\\%$ to $6.17\\%$), confirming that abductive preference learning preserves the benefits of conventional preference optimization while addressing the overlooked challenge of counterfactual prompts.",
        "tags": [
            "DPO",
            "GPT",
            "LLM",
            "RL",
            "RLHF"
        ]
    },
    {
        "id": "60",
        "title": "PairSem: LLM-Guided Pairwise Semantic Matching for Scientific Document Retrieval",
        "author": [
            "Wonbin Kweon",
            "Runchu Tian",
            "SeongKu Kang",
            "Pengcheng Jiang",
            "Zhiyong Lu",
            "Jiawei Han",
            "Hwanjo Yu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09897",
        "abstract": "Scientific document retrieval is a critical task for enabling knowledge discovery and supporting research across diverse domains. However, existing dense retrieval methods often struggle to capture fine-grained scientific concepts in texts due to their reliance on holistic embeddings and limited domain understanding. Recent approaches leverage large language models (LLMs) to extract fine-grained semantic entities and enhance semantic matching, but they typically treat entities as independent fragments, overlooking the multi-faceted nature of scientific concepts. To address this limitation, we propose Pairwise Semantic Matching (PairSem), a framework that represents relevant semantics as entity-aspect pairs, capturing complex, multi-faceted scientific concepts. PairSem is unsupervised, base retriever-agnostic, and plug-and-play, enabling precise and context-aware matching without requiring query-document labels or entity annotations. Extensive experiments on multiple datasets and retrievers demonstrate that PairSem significantly improves retrieval performance, highlighting the importance of modeling multi-aspect semantics in scientific information retrieval.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "61",
        "title": "Learning Bug Context for PyTorch-to-JAX Translation with LLMs",
        "author": [
            "Hung Phan",
            "Son Le Vu",
            "Ali Jannesari"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09898",
        "abstract": "Despite recent progress of large language models (LLMs) on code translation among mainstream languages, translating PyTorch to JAX remains nontrivial. The two libraries, though both embedded in Python, differ in core design, execution semantics, and ecosystem maturity; JAX is newer and comparatively underrepresented in public code, and parallel PyTorch--JAX corpora are limited. Weaknesses in existing evaluation further complicate cross-framework benchmarking. We present T2J, a prompt-augmentation framework that strengthens LLM-based PyTorch to JAX translation. Our pipeline (i) assembles two PyTorch sources -- the problem-solving set from TorchLeet (Aroori & Chien, 2025) and a GitHub-derived set from CodeParrot (Wolf et al., 2022) -- and uses GPT-4o-mini to produce initial JAX drafts; (ii) engages two professional developers to iteratively repair those drafts until functional equivalence, yielding a curated fixed-bug dataset of common errors and patches; and (iii) constructs augmented prompts that inject structured guidance from these fixes to steer lightweight LLMs (e.g., GPT-4o-mini). We also introduce three metrics tailored to PyTorch to JAX: T2J CodeTrans Score, T2J FixCost Score (an LLM-based estimate of bug-fix effort), and T2J Comparison Score (LLM-as-judge). Empirically, T2J raises GPT-4o-mini performance by up to 10% on CodeBLEU, 50% on T2J FixCost Score, 1.33 points on T2J CodeTrans Score (0--4 scale), and 100% on T2J Comparison Score; moreover, the generated code runs up to 2.5x faster than the baseline.",
        "tags": [
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "62",
        "title": "Autonomous Agents for Scientific Discovery: Orchestrating Scientists, Language, Code, and Physics",
        "author": [
            "Lianhao Zhou",
            "Hongyi Ling",
            "Cong Fu",
            "Yepeng Huang",
            "Michael Sun",
            "Wendi Yu",
            "Xiaoxuan Wang",
            "Xiner Li",
            "Xingyu Su",
            "Junkai Zhang",
            "Xiusi Chen",
            "Chenxing Liang",
            "Xiaofeng Qian",
            "Heng Ji",
            "Wei Wang",
            "Marinka Zitnik",
            "Shuiwang Ji"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09901",
        "abstract": "Computing has long served as a cornerstone of scientific discovery. Recently, a paradigm shift has emerged with the rise of large language models (LLMs), introducing autonomous systems, referred to as agents, that accelerate discovery across varying levels of autonomy. These language agents provide a flexible and versatile framework that orchestrates interactions with human scientists, natural language, computer language and code, and physics. This paper presents our view and vision of LLM-based scientific agents and their growing role in transforming the scientific discovery lifecycle, from hypothesis discovery, experimental design and execution, to result analysis and refinement. We critically examine current methodologies, emphasizing key innovations, practical achievements, and outstanding limitations. Additionally, we identify open research challenges and outline promising directions for building more robust, generalizable, and adaptive scientific agents. Our analysis highlights the transformative potential of autonomous agents to accelerate scientific discovery across diverse domains.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "63",
        "title": "An uncertainty-aware framework for data-efficient multi-view animal pose estimation",
        "author": [
            "Lenny Aharon",
            "Keemin Lee",
            "Karan Sikka",
            "Selmaan Chettih",
            "Cole Hurwitz",
            "Liam Paninski",
            "Matthew R Whiteway"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09903",
        "abstract": "Multi-view pose estimation is essential for quantifying animal behavior in scientific research, yet current methods struggle to achieve accurate tracking with limited labeled data and suffer from poor uncertainty estimates. We address these challenges with a comprehensive framework combining novel training and post-processing techniques, and a model distillation procedure that leverages the strengths of these techniques to produce a more efficient and effective pose estimator. Our multi-view transformer (MVT) utilizes pretrained backbones and enables simultaneous processing of information across all views, while a novel patch masking scheme learns robust cross-view correspondences without camera calibration. For calibrated setups, we incorporate geometric consistency through 3D augmentation and a triangulation loss. We extend the existing Ensemble Kalman Smoother (EKS) post-processor to the nonlinear case and enhance uncertainty quantification via a variance inflation technique. Finally, to leverage the scaling properties of the MVT, we design a distillation procedure that exploits improved EKS predictions and uncertainty estimates to generate high-quality pseudo-labels, thereby reducing dependence on manual labels. Our framework components consistently outperform existing methods across three diverse animal species (flies, mice, chickadees), with each component contributing complementary benefits. The result is a practical, uncertainty-aware system for reliable pose estimation that enables downstream behavioral analyses under real-world data constraints.",
        "tags": [
            "3D",
            "Pose Estimation",
            "Transformer"
        ]
    },
    {
        "id": "64",
        "title": "Stability of Transformers under Layer Normalization",
        "author": [
            "Kelvin Kan",
            "Xingjian Li",
            "Benjamin J. Zhang",
            "Tuhin Sahai",
            "Stanley Osher",
            "Krishna Kumar",
            "Markos A. Katsoulakis"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09904",
        "abstract": "Despite their widespread use, training deep Transformers can be unstable. Layer normalization, a standard component, improves training stability, but its placement has often been ad-hoc. In this paper, we conduct a principled study on the forward (hidden states) and backward (gradient) stability of Transformers under different layer normalization placements. Our theory provides key insights into the training dynamics: whether training drives Transformers toward regular solutions or pathological behaviors. For forward stability, we derive explicit bounds on the growth of hidden states in trained Transformers. For backward stability, we analyze how layer normalization affects the backpropagation of gradients, thereby explaining the training dynamics of each layer normalization placement. Our analysis also guides the scaling of residual steps in Transformer blocks, where appropriate choices can further improve stability and performance. Our numerical results corroborate our theoretical findings. Beyond these results, our framework provides a principled way to sanity-check the stability of Transformers under new architectural modifications, offering guidance for future designs.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "65",
        "title": "The Personalization Trap: How User Memory Alters Emotional Reasoning in LLMs",
        "author": [
            "Xi Fang",
            "Weijie Xu",
            "Yuchong Zhang",
            "Stephanie Eckman",
            "Scott Nickleach",
            "Chandan K. Reddy"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09905",
        "abstract": "When an AI assistant remembers that Sarah is a single mother working two jobs, does it interpret her stress differently than if she were a wealthy executive? As personalized AI systems increasingly incorporate long-term user memory, understanding how this memory shapes emotional reasoning is critical. We investigate how user memory affects emotional intelligence in large language models (LLMs) by evaluating 15 models on human validated emotional intelligence tests. We find that identical scenarios paired with different user profiles produce systematically divergent emotional interpretations. Across validated user independent emotional scenarios and diverse user profiles, systematic biases emerged in several high-performing LLMs where advantaged profiles received more accurate emotional interpretations. Moreover, LLMs demonstrate significant disparities across demographic factors in emotion understanding and supportive recommendations tasks, indicating that personalization mechanisms can embed social hierarchies into models emotional reasoning. These results highlight a key challenge for memory enhanced AI: systems designed for personalization may inadvertently reinforce social inequalities.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "66",
        "title": "Agentic Property-Based Testing: Finding Bugs Across the Python Ecosystem",
        "author": [
            "Muhammad Maaz",
            "Liam DeVoe",
            "Zac Hatfield-Dodds",
            "Nicholas Carlini"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09907",
        "abstract": "Property-based testing (PBT) is a lightweight formal method, typically implemented as a randomized testing framework. Users specify the input domain for their test using combinators supplied by the PBT framework, and the expected properties or invariants as a unit-test function. The framework then searches for a counterexample, e.g. by generating inputs and calling the test function. In this work, we demonstrate an LLM-based agent which analyzes Python modules, infers function-specific and cross-function properties from code and documentation, synthesizes and executes PBTs, reflects on outputs of these tests to confirm true bugs, and finally outputs actionable bug reports for the developer. We perform an extensive evaluation of our agent across 100 popular Python packages. Of the bug reports generated by the agent, we found after manual review that 56\\% were valid bugs and 32\\% were valid bugs that we would report to maintainers. We then developed a ranking rubric to surface high-priority valid bugs to developers, and found that of the 21 top-scoring bugs, 86\\% were valid and 81\\% we would report. The bugs span diverse failure modes from serialization failures to numerical precision errors to flawed cache implementations. We reported 5 bugs, 4 with patches, including to NumPy and cloud computing SDKs, with 3 patches merged successfully. Our results suggest that LLMs with PBT provides a rigorous and scalable method for autonomously testing software. Our code and artifacts are available at: https://github.com/mmaaz-git/agentic-pbt.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "67",
        "title": "SpectralCA: Bi-Directional Cross-Attention for Next-Generation UAV Hyperspectral Vision",
        "author": [
            "D.V. Brovko"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09912",
        "abstract": "The relevance of this research lies in the growing demand for unmanned aerial vehicles (UAVs) capable of operating reliably in complex environments where conventional navigation becomes unreliable due to interference, poor visibility, or camouflage. Hyperspectral imaging (HSI) provides unique opportunities for UAV-based computer vision by enabling fine-grained material recognition and object differentiation, which are critical for navigation, surveillance, agriculture, and environmental monitoring. The aim of this work is to develop a deep learning architecture integrating HSI into UAV perception for navigation, object detection, and terrain classification. Objectives include: reviewing existing HSI methods, designing a hybrid 2D/3D convolutional architecture with spectral-spatial cross-attention, training, and benchmarking. The methodology is based on the modification of the Mobile 3D Vision Transformer (MDvT) by introducing the proposed SpectralCA block. This block employs bi-directional cross-attention to fuse spectral and spatial features, enhancing accuracy while reducing parameters and inference time. Experimental evaluation was conducted on the WHU-Hi-HongHu dataset, with results assessed using Overall Accuracy, Average Accuracy, and the Kappa coefficient. The findings confirm that the proposed architecture improves UAV perception efficiency, enabling real-time operation for navigation, object recognition, and environmental monitoring tasks.\nKeywords: SpectralCA, deep learning, computer vision, hyperspectral imaging, unmanned aerial vehicle, object detection, semi-supervised learning.",
        "tags": [
            "3D",
            "Detection",
            "Transformer",
            "ViT"
        ]
    },
    {
        "id": "68",
        "title": "Enhancing Faithfulness in Abstractive Summarization via Span-Level Fine-Tuning",
        "author": [
            "Sicong Huang",
            "Qianqi Yan",
            "Shengze Wang",
            "Ian Lane"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09915",
        "abstract": "Abstractive summarization using large language models (LLMs) has become an essential tool for condensing information. However, despite their ability to generate fluent summaries, these models sometimes produce unfaithful summaries, introducing hallucinations at the word, phrase, or concept level. Existing mitigation strategies, such as post-processing corrections or contrastive learning with synthetically generated negative samples, fail to fully address the diverse errors that can occur in LLM-generated summaries. In this paper, we investigate fine-tuning strategies to reduce the occurrence of unfaithful spans in generated summaries. First, we automatically generate summaries for the set of source documents in the training set with a variety of LLMs and then use GPT-4o to annotate any hallucinations it detects at the span-level. Leveraging these annotations, we fine-tune LLMs with both hallucination-free summaries and annotated unfaithful spans to enhance model faithfulness. In this paper, we introduce a new dataset that contains both faithful and unfaithful summaries with span-level labels and we evaluate three techniques to fine-tuning a LLM to improve the faithfulness of the resulting summarization: gradient ascent, unlikelihood training, and task vector negation. Experimental results show that all three approaches successfully leverage span-level annotations to improve faithfulness, with unlikelihood training being the most effective.",
        "tags": [
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "69",
        "title": "Advancing Intoxication Detection: A Smartwatch-Based Approach",
        "author": [
            "Manuel Segura",
            "Pere VergÃ©s",
            "Richard Ky",
            "Ramesh Arangott",
            "Angela Kristine Garcia",
            "Thang Dihn Trong",
            "Makoto Hyodo",
            "Alexandru Nicolau",
            "Tony Givargis",
            "Sergio Gago-Masague"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09916",
        "abstract": "Excess alcohol consumption leads to serious health risks and severe consequences for both individuals and their communities. To advocate for healthier drinking habits, we introduce a groundbreaking mobile smartwatch application approach to just-in-time interventions for intoxication warnings. In this work, we have created a dataset gathering TAC, accelerometer, gyroscope, and heart rate data from the participants during a period of three weeks. This is the first study to combine accelerometer, gyroscope, and heart rate smartwatch data collected over an extended monitoring period to classify intoxication levels. Previous research had used limited smartphone motion data and conventional machine learning (ML) algorithms to classify heavy drinking episodes; in this work, we use smartwatch data and perform a thorough evaluation of different state-of-the-art classifiers such as the Transformer, Bidirectional Long Short-Term Memory (bi-LSTM), Gated Recurrent Unit (GRU), One-Dimensional Convolutional Neural Networks (1D-CNN), and Hyperdimensional Computing (HDC). We have compared performance metrics for the algorithms and assessed their efficiency on resource-constrained environments like mobile hardware. The HDC model achieved the best balance between accuracy and efficiency, demonstrating its practicality for smartwatch-based applications.",
        "tags": [
            "Detection",
            "Transformer"
        ]
    },
    {
        "id": "70",
        "title": "HeadsUp! High-Fidelity Portrait Image Super-Resolution",
        "author": [
            "Renjie Li",
            "Zihao Zhu",
            "Xiaoyu Wang",
            "Zhengzhong Tu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09924",
        "abstract": "Portrait pictures, which typically feature both human subjects and natural backgrounds, are one of the most prevalent forms of photography on social media. Existing image super-resolution (ISR) techniques generally focus either on generic real-world images or strictly aligned facial images (i.e., face super-resolution). In practice, separate models are blended to handle portrait photos: the face specialist model handles the face region, and the general model processes the rest. However, these blending approaches inevitably introduce blending or boundary artifacts around the facial regions due to different model training recipes, while human perception is particularly sensitive to facial fidelity. To overcome these limitations, we study the portrait image supersolution (PortraitISR) problem, and propose HeadsUp, a single-step diffusion model that is capable of seamlessly restoring and upscaling portrait images in an end-to-end manner. Specifically, we build our model on top of a single-step diffusion model and develop a face supervision mechanism to guide the model in focusing on the facial region. We then integrate a reference-based mechanism to help with identity restoration, reducing face ambiguity in low-quality face restoration. Additionally, we have built a high-quality 4K portrait image ISR dataset dubbed PortraitSR-4K, to support model training and benchmarking for portrait images. Extensive experiments show that HeadsUp achieves state-of-the-art performance on the PortraitISR task while maintaining comparable or higher performance on both general image and aligned face datasets.",
        "tags": [
            "Diffusion",
            "Super Resolution"
        ]
    },
    {
        "id": "71",
        "title": "Structured Cooperative Multi-Agent Reinforcement Learning: a Bayesian Network Perspective",
        "author": [
            "Shahbaz P Qadri Syed",
            "He Bai"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09937",
        "abstract": "The empirical success of multi-agent reinforcement learning (MARL) has motivated the search for more efficient and scalable algorithms for large scale multi-agent systems. However, existing state-of-the-art algorithms do not fully exploit inter-agent coupling information to develop MARL algorithms. In this paper, we propose a systematic approach to leverage structures in the inter-agent couplings for efficient model-free reinforcement learning. We model the cooperative MARL problem via a Bayesian network and characterize the subset of agents, termed as the value dependency set, whose information is required by each agent to estimate its local action value function exactly. Moreover, we propose a partially decentralized training decentralized execution (P-DTDE) paradigm based on the value dependency set. We theoretically establish that the total variance of our P-DTDE policy gradient estimator is less than the centralized training decentralized execution (CTDE) policy gradient estimator. We derive a multi-agent policy gradient theorem based on the P-DTDE scheme and develop a scalable actor-critic algorithm. We demonstrate the efficiency and scalability of the proposed algorithm on multi-warehouse resource allocation and multi-zone temperature control examples. For dense value dependency sets, we propose an approximation scheme based on truncation of the Bayesian network and empirically show that it achieves a faster convergence than the exact value dependence set for applications with a large number of agents.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "72",
        "title": "Conformal Sparsification for Bandwidth-Efficient Edge-Cloud Speculative Decoding",
        "author": [
            "Payel Bhattacharjee",
            "Fengwei Tian",
            "Meiyu Zhong",
            "Guangyi Zhang",
            "Osvaldo Simeone",
            "Ravi Tandon"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09942",
        "abstract": "Edge-cloud speculative decoding (SD) accelerates inference by having a cloud-based large language model (LLM) that verifies draft tokens generated by a resource-constrained small language model (SLM) at the edge. A central bottleneck is the limited bandwidth of the edge-cloud link, which necessitates efficient compression of draft token distributions. We first derive an information-theoretic bound that decomposes the token rejection rate into contributions from SLM-LLM distribution mismatch and from quantization distortion. Guided by this analysis, we propose the Sparse Quantize-and-Sample SD (SQS-SD) framework, which exploits distributional sparsity through structured sparsification and lattice-based quantization. Within this framework, K-SQS applies fixed top-K truncation, while C-SQS adaptively adjusts the retained token set via online conformal prediction to ensure bounded deviation from the dense distribution. Empirical results confirm that both approaches improve end-to-end latency and rejection rates in complimentary operating regimes.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "73",
        "title": "Read the Room or Lead the Room: Understanding Socio-Cognitive Dynamics in Human-AI Teaming",
        "author": [
            "Jaeyoon Choi",
            "Mohammad Amin Samadi",
            "Spencer JaQuay",
            "Seehee Park",
            "Nia Nixon"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09944",
        "abstract": "Research on Collaborative Problem Solving (CPS) has traditionally examined how humans rely on one another cognitively and socially to accomplish tasks together. With the rapid advancement of AI and large language models, however, a new question emerge: what happens to team dynamics when one of the \"teammates\" is not human? In this study, we investigate how the integration of an AI teammate -- a fully autonomous GPT-4 agent with social, cognitive, and affective capabilities -- shapes the socio-cognitive dynamics of CPS. We analyze discourse data collected from human-AI teaming (HAT) experiments conducted on a novel platform specifically designed for HAT research. Using two natural language processing (NLP) methods, specifically Linguistic Inquiry and Word Count (LIWC) and Group Communication Analysis (GCA), we found that AI teammates often assumed the role of dominant cognitive facilitators, guiding, planning, and driving group decision-making. However, they did so in a socially detached manner, frequently pushing agenda in a verbose and repetitive way. By contrast, humans working with AI used more language reflecting social processes, suggesting that they assumed more socially oriented roles. Our study highlights how learning analytics can provide critical insights into the socio-cognitive dynamics of human-AI collaboration.",
        "tags": [
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "74",
        "title": "Beyond Fertility: Analyzing STRR as a Metric for Multilingual Tokenization Evaluation",
        "author": [
            "Mir Tafseer Nayeem",
            "Sawsan Alqahtani",
            "Md Tahmid Rahman Laskar",
            "Tasnim Mohiuddin",
            "M Saiful Bari"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09947",
        "abstract": "Tokenization is a crucial but under-evaluated step in large language models (LLMs). The standard metric, fertility (the average number of tokens per word), captures compression efficiency but obscures how vocabularies are allocated across languages and domains. We analyze six widely used tokenizers across seven languages and two domains, finding stable fertility for English, high fertility for Chinese, and little domain sensitivity. To address fertility's blind spots, we propose the Single Token Retention Rate (STRR), which measures the proportion of words preserved as single tokens. STRR reveals systematic prioritization of English, strong support for Chinese, and fragmentation in Hindi, offering an interpretable view of cross-lingual fairness. Our results show that STRR complements fertility and provides practical guidance for designing more equitable multilingual tokenizers.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "75",
        "title": "VG-Mapping: Variation-Aware 3D Gaussians for Online Semi-static Scene Mapping",
        "author": [
            "Yicheng He",
            "Jingwen Yu",
            "Guangcheng Chen",
            "Hong Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09962",
        "abstract": "Maintaining an up-to-date map that accurately reflects recent changes in the environment is crucial, especially for robots that repeatedly traverse the same space. Failing to promptly update the changed regions can degrade map quality, resulting in poor localization, inefficient operations, and even lost robots. 3D Gaussian Splatting (3DGS) has recently seen widespread adoption in online map reconstruction due to its dense, differentiable, and photorealistic properties, yet accurately and efficiently updating the regions of change remains a challenge. In this paper, we propose VG-Mapping, a novel online 3DGS-based mapping system tailored for such semi-static scenes. Our approach introduces a hybrid representation that augments 3DGS with a TSDF-based voxel map to efficiently identify changed regions in a scene, along with a variation-aware density control strategy that inserts or deletes Gaussian primitives in regions undergoing change. Furthermore, to address the absence of public benchmarks for this task, we construct a RGB-D dataset comprising both synthetic and real-world semi-static environments. Experimental results demonstrate that our method substantially improves the rendering quality and map update efficiency in semi-static scenes. The code and dataset are available at https://github.com/heyicheng-never/VG-Mapping.",
        "tags": [
            "3D",
            "Gaussian Splatting"
        ]
    },
    {
        "id": "76",
        "title": "LLM-HBT: Dynamic Behavior Tree Construction for Adaptive Coordination in Heterogeneous Robots",
        "author": [
            "Chaoran Wang",
            "Jingyuan Sun",
            "Yanhui Zhang",
            "Mingyu Zhang",
            "Changju Wu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09963",
        "abstract": "We introduce a novel framework for automatic behavior tree (BT) construction in heterogeneous multi-robot systems, designed to address the challenges of adaptability and robustness in dynamic environments. Traditional robots are limited by fixed functional attributes and cannot efficiently reconfigure their strategies in response to task failures or environmental changes. To overcome this limitation, we leverage large language models (LLMs) to generate and extend BTs dynamically, combining the reasoning and generalization power of LLMs with the modularity and recovery capability of BTs. The proposed framework consists of four interconnected modules task initialization, task assignment, BT update, and failure node detection which operate in a closed loop. Robots tick their BTs during execution, and upon encountering a failure node, they can either extend the tree locally or invoke a centralized virtual coordinator (Alex) to reassign subtasks and synchronize BTs across peers. This design enables long-term cooperative execution in heterogeneous teams. We validate the framework on 60 tasks across three simulated scenarios and in a real-world cafe environment with a robotic arm and a wheeled-legged robot. Results show that our method consistently outperforms baseline approaches in task success rate, robustness, and scalability, demonstrating its effectiveness for multi-robot collaboration in complex scenarios.",
        "tags": [
            "Detection",
            "LLM",
            "Robotics"
        ]
    },
    {
        "id": "77",
        "title": "FORM: Fixed-Lag Odometry with Reparative Mapping utilizing Rotating LiDAR Sensors",
        "author": [
            "Easton R. Potokar",
            "Taylor Pool",
            "Daniel McGann",
            "Michael Kaess"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09966",
        "abstract": "Light Detection and Ranging (LiDAR) sensors have become a de-facto sensor for many robot state estimation tasks, spurring development of many LiDAR Odometry (LO) methods in recent years. While some smoothing-based LO methods have been proposed, most require matching against multiple scans, resulting in sub-real-time performance. Due to this, most prior works estimate a single state at a time and are ``submap''-based. This architecture propagates any error in pose estimation to the fixed submap and can cause jittery trajectories and degrade future registrations. We propose Fixed-Lag Odometry with Reparative Mapping (FORM), a LO method that performs smoothing over a densely connected factor graph while utilizing a single iterative map for matching. This allows for both real-time performance and active correction of the local map as pose estimates are further refined. We evaluate on a wide variety of datasets to show that FORM is robust, accurate, real-time, and provides smooth trajectory estimates when compared to prior state-of-the-art LO methods.",
        "tags": [
            "Detection",
            "Pose Estimation",
            "Robotics"
        ]
    },
    {
        "id": "78",
        "title": "Follow My Lead: Logical Fallacy Classification with Knowledge-Augmented LLMs",
        "author": [
            "Olivia Peiyu Wang",
            "Tashvi Bansal",
            "Ryan Bai",
            "Emily M. Chui",
            "Leilani H. Gilpin"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09970",
        "abstract": "Large Language Models (LLMs) suffer from critical reasoning gaps, including a tendency to hallucinate and poor accuracy in classifying logical fallacies. This limitation stems from their default System 1 processing, which is fast and intuitive, whereas reliable reasoning requires the deliberate, effortful System 2 approach (Kahneman, 2011; Li et al., 2025). Since full System 2 training is often prohibitively expensive, we explore a low-cost, instruction-based intervention to bridge this gap. Our methodology introduces a novel stepwise instruction dataset that decomposes fallacy classification into a series of atomic procedural steps (simple binary questions). We further augment this with a final verification step where models consult a relational knowledge graph of related fallacies. This procedural, rule-based intervention yields a significant improvement in LLM logical fallacy classification. Crucially, the approach also provides enhanced transparency into the LLMs' decision-making, highlighting a practical pathway for Neuro-symbolic architectures to address LLM reasoning deficits.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "79",
        "title": "Reinforcement Fine-Tuning of Flow-Matching Policies for Vision-Language-Action Models",
        "author": [
            "Mingyang Lyu",
            "Yinqian Sun",
            "Erliang Lin",
            "Huangrui Li",
            "Ruolin Chen",
            "Feifei Zhao",
            "Yi Zeng"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09976",
        "abstract": "Vision-Language-Action (VLA) models such as OpenVLA, Octo, and $\\pi_0$ have shown strong generalization by leveraging large-scale demonstrations, yet their performance is still fundamentally constrained by the quality and coverage of supervised data. Reinforcement learning (RL) provides a promising path for improving and fine-tuning VLAs through online interaction. However, conventional policy gradient methods are computationally infeasible in the context of flow-matching based models due to the intractability of the importance sampling process, which requires explicit computation of policy ratios. To overcome this limitation, we propose Flow Policy Optimization (FPO) algorithm, which reformulates importance sampling by leveraging per-sample changes in the conditional flow-matching objective. Furthermore, FPO achieves stable and scalable online reinforcement fine-tuning of the $\\pi_0$ model by integrating structure-aware credit assignment to enhance gradient efficiency, clipped surrogate objectives to stabilize optimization, multi-step latent exploration to encourage diverse policy updates, and a Q-ensemble mechanism to provide robust value estimation. We evaluate FPO on the LIBERO benchmark and the ALOHA simulation task against supervised, preference-aligned, diffusion-based, autoregressive online RL, and $\\pi_0$-FAST baselines, observing consistent improvements over the imitation prior and strong alternatives with stable learning under sparse rewards. In addition, ablation studies and analyses of the latent space dynamics further highlight the contributions of individual components within FPO, validating the effectiveness of the proposed computational modules and the stable convergence of the conditional flow-matching objective during online RL.",
        "tags": [
            "Diffusion",
            "Flow Matching",
            "RL"
        ]
    },
    {
        "id": "80",
        "title": "ATRos: Learning Energy-Efficient Agile Locomotion for Wheeled-legged Robots",
        "author": [
            "Jingyuan Sun",
            "Hongyu Ji",
            "Zihan Qu",
            "Chaoran Wang",
            "Mingyu Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09980",
        "abstract": "Hybrid locomotion of wheeled-legged robots has recently attracted increasing attention due to their advantages of combining the agility of legged locomotion and the efficiency of wheeled motion. But along with expanded performance, the whole-body control of wheeled-legged robots remains challenging for hybrid locomotion. In this paper, we present ATRos, a reinforcement learning (RL)-based hybrid locomotion framework to achieve hybrid walking-driving motions on the wheeled-legged robot. Without giving predefined gait patterns, our planner aims to intelligently coordinate simultaneous wheel and leg movements, thereby achieving improved terrain adaptability and improved energy efficiency. Based on RL techniques, our approach constructs a prediction policy network that could estimate external environmental states from proprioceptive sensory information, and the outputs are then fed into an actor critic network to produce optimal joint commands. The feasibility of the proposed framework is validated through both simulations and real-world experiments across diverse terrains, including flat ground, stairs, and grassy surfaces. The hybrid locomotion framework shows robust performance over various unseen terrains, highlighting its generalization capability.",
        "tags": [
            "RL",
            "Robotics"
        ]
    },
    {
        "id": "81",
        "title": "Scaling Traffic Insights with AI and Language Model-Powered Camera Systems for Data-Driven Transportation Decision Making",
        "author": [
            "Fan Zuo",
            "Donglin Zhou",
            "Jingqin Gao",
            "Kaan Ozbay"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09981",
        "abstract": "Accurate, scalable traffic monitoring is critical for real-time and long-term transportation management, particularly during disruptions such as natural disasters, large construction projects, or major policy changes like New York City's first-in-the-nation congestion pricing program. However, widespread sensor deployment remains limited due to high installation, maintenance, and data management costs. While traffic cameras offer a cost-effective alternative, existing video analytics struggle with dynamic camera viewpoints and massive data volumes from large camera networks. This study presents an end-to-end AI-based framework leveraging existing traffic camera infrastructure for high-resolution, longitudinal analysis at scale. A fine-tuned YOLOv11 model, trained on localized urban scenes, extracts multimodal traffic density and classification metrics in real time. To address inconsistencies from non-stationary pan-tilt-zoom cameras, we introduce a novel graph-based viewpoint normalization method. A domain-specific large language model was also integrated to process massive data from a 24/7 video stream to generate frequent, automated summaries of evolving traffic patterns, a task far exceeding manual capabilities. We validated the system using over 9 million images from roughly 1,000 traffic cameras during the early rollout of NYC congestion pricing in 2025. Results show a 9% decline in weekday passenger vehicle density within the Congestion Relief Zone, early truck volume reductions with signs of rebound, and consistent increases in pedestrian and cyclist activity at corridor and zonal scales. Experiments showed that example-based prompts improved LLM's numerical accuracy and reduced hallucinations. These findings demonstrate the framework's potential as a practical, infrastructure-ready solution for large-scale, policy-relevant traffic monitoring with minimal human intervention.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "82",
        "title": "Unifying Tree Search Algorithm and Reward Design for LLM Reasoning: A Survey",
        "author": [
            "Jiaqi Wei",
            "Xiang Zhang",
            "Yuejin Yang",
            "Wenxuan Huang",
            "Juntai Cao",
            "Sheng Xu",
            "Xiang Zhuang",
            "Zhangyang Gao",
            "Muhammad Abdul-Mageed",
            "Laks V.S. Lakshmanan",
            "Chenyu You",
            "Wanli Ouyang",
            "Siqi Sun"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09988",
        "abstract": "Deliberative tree search is a cornerstone of modern Large Language Model (LLM) research, driving the pivot from brute-force scaling toward algorithmic efficiency. This single paradigm unifies two critical frontiers: \\textbf{Test-Time Scaling (TTS)}, which deploys on-demand computation to solve hard problems, and \\textbf{Self-Improvement}, which uses search-generated data to durably enhance model parameters. However, this burgeoning field is fragmented and lacks a common formalism, particularly concerning the ambiguous role of the reward signal -- is it a transient heuristic or a durable learning target? This paper resolves this ambiguity by introducing a unified framework that deconstructs search algorithms into three core components: the \\emph{Search Mechanism}, \\emph{Reward Formulation}, and \\emph{Transition Function}. We establish a formal distinction between transient \\textbf{Search Guidance} for TTS and durable \\textbf{Parametric Reward Modeling} for Self-Improvement. Building on this formalism, we introduce a component-centric taxonomy, synthesize the state-of-the-art, and chart a research roadmap toward more systematic progress in creating autonomous, self-improving agents.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "83",
        "title": "CLoD-GS: Continuous Level-of-Detail via 3D Gaussian Splatting",
        "author": [
            "Zhigang Cheng",
            "Mingchao Sun",
            "Yu Liu",
            "Zengye Ge",
            "Luyang Tang",
            "Mu Xu",
            "Yangyan Li",
            "Peng Pan"
        ],
        "pdf": "https://arxiv.org/pdf/2510.09997",
        "abstract": "Level of Detail (LoD) is a fundamental technique in real-time computer graphics for managing the rendering costs of complex scenes while preserving visual fidelity. Traditionally, LoD is implemented using discrete levels (DLoD), where multiple, distinct versions of a model are swapped out at different distances. This long-standing paradigm, however, suffers from two major drawbacks: it requires significant storage for multiple model copies and causes jarring visual ``popping\" artifacts during transitions, degrading the user experience. We argue that the explicit, primitive-based nature of the emerging 3D Gaussian Splatting (3DGS) technique enables a more ideal paradigm: Continuous LoD (CLoD). A CLoD approach facilitates smooth, seamless quality scaling within a single, unified model, thereby circumventing the core problems of DLOD. To this end, we introduce CLoD-GS, a framework that integrates a continuous LoD mechanism directly into a 3DGS representation. Our method introduces a learnable, distance-dependent decay parameter for each Gaussian primitive, which dynamically adjusts its opacity based on viewpoint proximity. This allows for the progressive and smooth filtering of less significant primitives, effectively creating a continuous spectrum of detail within one model. To train this model to be robust across all distances, we introduce a virtual distance scaling mechanism and a novel coarse-to-fine training strategy with rendered point count regularization. Our approach not only eliminates the storage overhead and visual artifacts of discrete methods but also reduces the primitive count and memory footprint of the final model. Extensive experiments demonstrate that CLoD-GS achieves smooth, quality-scalable rendering from a single model, delivering high-fidelity results across a wide range of performance targets.",
        "tags": [
            "3D",
            "Gaussian Splatting"
        ]
    },
    {
        "id": "84",
        "title": "RIPRAG: Hack a Black-box Retrieval-Augmented Generation Question-Answering System with Reinforcement Learning",
        "author": [
            "Meng Xi",
            "Sihan Lv",
            "Yechen Jin",
            "Guanjie Cheng",
            "Naibo Wang",
            "Ying Li",
            "Jianwei Yin"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10008",
        "abstract": "Retrieval-Augmented Generation (RAG) systems based on Large Language Models (LLMs) have become a core technology for tasks such as question-answering (QA) and content generation. However, by injecting poisoned documents into the database of RAG systems, attackers can manipulate LLMs to generate text that aligns with their intended preferences. Existing research has primarily focused on white-box attacks against simplified RAG architectures. In this paper, we investigate a more complex and realistic scenario: the attacker lacks knowledge of the RAG system's internal composition and implementation details, and the RAG system comprises components beyond a mere retriever. Specifically, we propose the RIPRAG attack framework, an end-to-end attack pipeline that treats the target RAG system as a black box, where the only information accessible to the attacker is whether the poisoning succeeds. Our method leverages Reinforcement Learning (RL) to optimize the generation model for poisoned documents, ensuring that the generated poisoned document aligns with the target RAG system's preferences. Experimental results demonstrate that this method can effectively execute poisoning attacks against most complex RAG systems, achieving an attack success rate (ASR) improvement of up to 0.72 compared to baseline methods. This highlights prevalent deficiencies in current defensive methods and provides critical insights for LLM security research.",
        "tags": [
            "LLM",
            "RAG",
            "RL"
        ]
    },
    {
        "id": "85",
        "title": "Beyond the limitation of a single query: Train your LLM for query expansion with Reinforcement Learning",
        "author": [
            "Shu Zhao",
            "Tan Yu",
            "Anbang Xu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10009",
        "abstract": "Reasoning-augmented search agents, such as Search-R1, are trained to reason, search, and generate the final answer iteratively. Nevertheless, due to their limited capabilities in reasoning and search, their performance on multi-hop QA benchmarks remains far from satisfactory. To handle complex or compound queries, we train an LLM-based search agent with the native capability of query expansion through reinforcement learning. In each turn, our search agent proposes several query variants, which are searched simultaneously to cover more relevant information. Meanwhile, given limited post-training data and computing resources, it is very challenging for a search agent to master multiple tasks, including query generation, retrieved information understanding, and answer generation. Therefore, we propose incorporating a pre-trained squeezer model that helps the search agent understand the retrieved documents, allowing the search agent to focus on query generation for high retrieval recall. With the assistance of the squeezer model, we discover that even a small-scale 3B LLM can demonstrate a strong capability of query expansion and achieve state-of-the-art accuracy on the multi-hop QA benchmarks. To be specific, our experiments across seven question-answering benchmarks demonstrate that our method, named ExpandSearch, achieves an average improvement of 4.4% compared to state-of-the-art baselines, with strong gains on multi-hop reasoning tasks requiring diverse evidence aggregation.",
        "tags": [
            "LLM",
            "RL"
        ]
    },
    {
        "id": "86",
        "title": "SLEAN: Simple Lightweight Ensemble Analysis Network for Multi-Provider LLM Coordination: Design, Implementation, and Vibe Coding Bug Investigation Case Study",
        "author": [
            "Matheus J. T. Vargas"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10010",
        "abstract": "We present SLEAN (Simple Lightweight Ensemble Analysis Network), a deterministic framework for coordinating multiple LLM providers through text-based prompt orchestration. Unlike complex multi-agent systems requiring specialized infrastructure, SLEAN operates as a simple prompt bridge between LLMs using .txt templates, requiring no deep technical knowledge for deployment. The three-phase protocol formed by independent analysis, cross-critique, and arbitration, filters harmful AI-generated code suggestions before production deployment, addressing how AI-assisted debugging increasingly produces modifications that introduce unnecessary complexity, break existing functionality, or address problems. Evaluating 15 software bugs, we analyzed 69 AI-generated fix propositions. SLEAN's filtering accepted 22 fixes (31.9%, 95% CI 20.9-42.9%) while rejecting 47 that would have been harmful if applied verbatim. The arbitration process reduced code change surface by 83-90% relative to raw AI outputs, enforcing minimal causal edits over scope-expanding modifications. Minimal Type 2 inputs proved more efficient than detailed Type 1 inputs, requiring 2.85 versus 3.56 propositions per accepted fix (35.1% versus 28.1% acceptance, about a 20% efficiency gain). Agreement between AI systems showed weak correlation with fix quality: high convergence (at least 80%) occurred in 4 of 15 cases and improved acceptance by only 2.4% points; arbitration appeared only at exactly 10% convergence in 2 of 15 cases, although low convergence alone did not necessitate arbitration. The file-driven, provider-agnostic architecture enables deployment without specialized coding expertise, making it applicable to security auditing, code review, document verification, and other domains requiring reliable multi-provider synthesis with end-to-end auditability.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "87",
        "title": "Path Drift in Large Reasoning Models:How First-Person Commitments Override Safety",
        "author": [
            "Yuyi Huang",
            "Runzhe Zhan",
            "Lidia S.Chao",
            "Ailin Tao",
            "Derek F.Wong"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10013",
        "abstract": "As large language models (LLMs) are increasingly deployed for complex reasoning tasks, Long Chain-of-Thought (Long-CoT) prompting has emerged as a key paradigm for structured inference. Despite early-stage safeguards enabled by alignment techniques such as RLHF, we identify a previously underexplored vulnerability: reasoning trajectories in Long-CoT models can drift from aligned paths, resulting in content that violates safety constraints. We term this phenomenon Path Drift. Through empirical analysis, we uncover three behavioral triggers of Path Drift: (1) first-person commitments that induce goal-driven reasoning that delays refusal signals; (2) ethical evaporation, where surface-level disclaimers bypass alignment checkpoints; (3) condition chain escalation, where layered cues progressively steer models toward unsafe completions. Building on these insights, we introduce a three-stage Path Drift Induction Framework comprising cognitive load amplification, self-role priming, and condition chain hijacking. Each stage independently reduces refusal rates, while their combination further compounds the effect. To mitigate these risks, we propose a path-level defense strategy incorporating role attribution correction and metacognitive reflection (reflective safety cues). Our findings highlight the need for trajectory-level alignment oversight in long-form reasoning beyond token-level alignment.",
        "tags": [
            "CoT",
            "LLM",
            "RLHF"
        ]
    },
    {
        "id": "88",
        "title": "Q-Adapter: Visual Query Adapter for Extracting Textually-related Features in Video Captioning",
        "author": [
            "Junan Chen",
            "Trung Thanh Nguyen",
            "Takahiro Komamizu",
            "Ichiro Ide"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10022",
        "abstract": "Recent advances in video captioning are driven by large-scale pretrained models, which follow the standard \"pre-training followed by fine-tuning\" paradigm, where the full model is fine-tuned for downstream tasks. Although effective, this approach becomes computationally prohibitive as the model size increases. The Parameter-Efficient Fine-Tuning (PEFT) approach offers a promising alternative, but primarily focuses on the language components of Multimodal Large Language Models (MLLMs). Despite recent progress, PEFT remains underexplored in multimodal tasks and lacks sufficient understanding of visual information during fine-tuning the model. To bridge this gap, we propose Query-Adapter (Q-Adapter), a lightweight visual adapter module designed to enhance MLLMs by enabling efficient fine-tuning for the video captioning task. Q-Adapter introduces learnable query tokens and a gating layer into Vision Encoder, enabling effective extraction of sparse, caption-relevant features without relying on external textual supervision. We evaluate Q-Adapter on two well-known video captioning datasets, MSR-VTT and MSVD, where it achieves state-of-the-art performance among the methods that take the PEFT approach across BLEU@4, METEOR, ROUGE-L, and CIDEr metrics. Q-Adapter also achieves competitive performance compared to methods that take the full fine-tuning approach while requiring only 1.4% of the parameters. We further analyze the impact of key hyperparameters and design choices on fine-tuning effectiveness, providing insights into optimization strategies for adapter-based learning. These results highlight the strong potential of Q-Adapter in balancing caption quality and parameter efficiency, demonstrating its scalability for video-language modeling.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "89",
        "title": "Skill-Targeted Adaptive Training",
        "author": [
            "Yinghui He",
            "Abhishek Panigrahi",
            "Yong Lin",
            "Sanjeev Arora"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10023",
        "abstract": "Language models often show little to no improvement (i.e., \"saturation\") when trained via vanilla supervised fine-tuning (SFT) on data similar to what they saw in their training set (e.g., MATH). We introduce a new fine-tuning strategy, STAT, to train such a student model by using the metacognition ability of a stronger large language model (LLM) as the teacher. The teacher uses the task dataset to create a list of skills needed for the task, and then labels each data point with its required skills (Didolkar et al., 2024). By monitoring the student's answers, the teacher creates a Missing-Skill-Profile for the student, tracking how often they failed to apply each skill in their responses. We use this idea to build a modified training set in one of two ways. In STAT-Sel, the teacher uses an existing set of training examples but adaptively reweights them according to the Missing-Skill-Profile. In STAT-Syn, the teacher synthesizes additional examples involving missing skills. Across extensive experiments on Llama and Qwen models, our methods yield improvements of up to 7.5% on MATH, whereas SFT provides only limited gains. Furthermore, STAT enhances performance on out-of-distribution benchmarks (e.g., AIME24/25, AMC23, etc.) by an average of 4.6%. Crucially, we find that STAT is complementary to RL via GRPO (Shao et al., 2024): after the model is improved using STAT to address skill gaps, GRPO continues to add further gains. We conclude that skill-targeted adaptive training should broadly improve current training pipelines. Our code is available at: https://github.com/princeton-pli/STAT.",
        "tags": [
            "GRPO",
            "LLM",
            "LLaMA",
            "Qwen",
            "RL"
        ]
    },
    {
        "id": "90",
        "title": "Efficient Onboard Vision-Language Inference in UAV-Enabled Low-Altitude Economy Networks via LLM-Enhanced Optimization",
        "author": [
            "Yang Li",
            "Ruichen Zhang",
            "Yinqiu Liu",
            "Guangyuan Liu",
            "Dusit Niyato",
            "Abbas Jamalipour",
            "Xianbin Wang",
            "Dong In Kim"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10028",
        "abstract": "The rapid advancement of Low-Altitude Economy Networks (LAENets) has enabled a variety of applications, including aerial surveillance, environmental sensing, and semantic data collection. To support these scenarios, unmanned aerial vehicles (UAVs) equipped with onboard vision-language models (VLMs) offer a promising solution for real-time multimodal inference. However, ensuring both inference accuracy and communication efficiency remains a significant challenge due to limited onboard resources and dynamic network conditions. In this paper, we first propose a UAV-enabled LAENet system model that jointly captures UAV mobility, user-UAV communication, and the onboard visual question answering (VQA) pipeline. Based on this model, we formulate a mixed-integer non-convex optimization problem to minimize task latency and power consumption under user-specific accuracy constraints. To solve the problem, we design a hierarchical optimization framework composed of two parts: (i) an Alternating Resolution and Power Optimization (ARPO) algorithm for resource allocation under accuracy constraints, and (ii) a Large Language Model-augmented Reinforcement Learning Approach (LLaRA) for adaptive UAV trajectory optimization. The large language model (LLM) serves as an expert in refining reward design of reinforcement learning in an offline fashion, introducing no additional latency in real-time decision-making. Numerical results demonstrate the efficacy of our proposed framework in improving inference performance and communication efficiency under dynamic LAENet conditions.",
        "tags": [
            "LLM",
            "RL",
            "VLM"
        ]
    },
    {
        "id": "91",
        "title": "Experience-Efficient Model-Free Deep Reinforcement Learning Using Pre-Training",
        "author": [
            "Ruoxing Yang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10029",
        "abstract": "We introduce PPOPT - Proximal Policy Optimization using Pretraining, a novel, model-free deep-reinforcement-learning algorithm that leverages pretraining to achieve high training efficiency and stability on very small training samples in physics-based environments. Reinforcement learning agents typically rely on large samples of environment interactions to learn a policy. However, frequent interactions with a (computer-simulated) environment may incur high computational costs, especially when the environment is complex. Our main innovation is a new policy neural network architecture that consists of a pretrained neural network middle section sandwiched between two fully-connected networks. Pretraining part of the network on a different environment with similar physics will help the agent learn the target environment with high efficiency because it will leverage a general understanding of the transferrable physics characteristics from the pretraining environment. We demonstrate that PPOPT outperforms baseline classic PPO on small training samples both in terms of rewards gained and general training stability. While PPOPT underperforms against classic model-based methods such as DYNA DDPG, the model-free nature of PPOPT allows it to train in significantly less time than its model-based counterparts. Finally, we present our implementation of PPOPT as open-source software, available at http://github.com/Davidrxyang/PPOPT.",
        "tags": [
            "PPO",
            "RL"
        ]
    },
    {
        "id": "92",
        "title": "P-4DGS: Predictive 4D Gaussian Splatting with 90$\\times$ Compression",
        "author": [
            "Henan Wang",
            "Hanxin Zhu",
            "Xinliang Gong",
            "Tianyu He",
            "Xin Li",
            "Zhibo Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10030",
        "abstract": "3D Gaussian Splatting (3DGS) has garnered significant attention due to its superior scene representation fidelity and real-time rendering performance, especially for dynamic 3D scene reconstruction (\\textit{i.e.}, 4D reconstruction). However, despite achieving promising results, most existing algorithms overlook the substantial temporal and spatial redundancies inherent in dynamic scenes, leading to prohibitive memory consumption. To address this, we propose P-4DGS, a novel dynamic 3DGS representation for compact 4D scene modeling. Inspired by intra- and inter-frame prediction techniques commonly used in video compression, we first design a 3D anchor point-based spatial-temporal prediction module to fully exploit the spatial-temporal correlations across different 3D Gaussian primitives. Subsequently, we employ an adaptive quantization strategy combined with context-based entropy coding to further reduce the size of the 3D anchor points, thereby achieving enhanced compression efficiency. To evaluate the rate-distortion performance of our proposed P-4DGS in comparison with other dynamic 3DGS representations, we conduct extensive experiments on both synthetic and real-world datasets. Experimental results demonstrate that our approach achieves state-of-the-art reconstruction quality and the fastest rendering speed, with a remarkably low storage footprint (around \\textbf{1MB} on average), achieving up to \\textbf{40$\\times$} and \\textbf{90$\\times$} compression on synthetic and real-world scenes, respectively.",
        "tags": [
            "3D",
            "Gaussian Splatting"
        ]
    },
    {
        "id": "93",
        "title": "Failure-Driven Workflow Refinement",
        "author": [
            "Jusheng Zhang",
            "Kaitong Cai",
            "Qinglin Zeng",
            "Ningyuan Liu",
            "Stephen Fan",
            "Ziliang Chen",
            "Keze Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10035",
        "abstract": "Optimizing LLM-based workflows is typically formulated as a global search, where candidate workflows are evaluated based on a scalar metric. This paradigm, however, suffers from a critical flaw: information collapse. By reducing rich, multi-step execution traces to simple success/failure signals, existing methods are rendered blind to the underlying structure of failures, fundamentally preventing them from modeling the workflow's failure distribution. We reconceptualize this challenge as a distributional problem. We propose a new paradigm where the optimization goal is not to maximize a scalar score, but to directly minimize a workflow's Expected Failure Mass, i.e., the integral of its failure probability density function defined over a high-dimensional Failure Signature Space (FSS). This distributional lens allows us to move from inefficient, zero-order optimization to a principled, gradient-like descent on the failure landscape itself. We introduce CE-Graph, a framework that operationalizes this paradigm through a novel, failure-driven refinement process. CE-Graph approximates the failure distribution from a pool of counterexamples, identifies its densest regions as recurring failure modes, and applies targeted, operator-constrained graph edits via a Propose-and-Verify mechanism to greedily reduce the failure mass. On math, code, and QA benchmarks, our CE-Graph achieves higher robustness at a significantly lower cost than strong baselines. This suggests that a system's reliability emerges not from avoiding failures, but from systematically learning and reshaping the geometric structure of its failure distributions.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "94",
        "title": "Waves of Imagination: Unconditional Spectrogram Generation using Diffusion Architectures",
        "author": [
            "Rahul Vanukuri",
            "Shafi Ullah Khan",
            "Talip Tolga SarÄ±",
            "Gokhan Secinti",
            "Diego PatiÃ±o",
            "Debashri Roy"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10044",
        "abstract": "The growing demand for effective spectrum management and interference mitigation in shared bands, such as the Citizens Broadband Radio Service (CBRS), requires robust radar detection algorithms to protect the military transmission from interference due to commercial wireless transmission. These algorithms, in turn, depend on large, diverse, and carefully labeled spectrogram datasets. However, collecting and annotating real-world radio frequency (RF) spectrogram data remains a significant challenge, as radar signals are rare, and their occurrences are infrequent. This challenge makes the creation of balanced datasets difficult, limiting the performance and generalizability of AI models in this domain.\nTo address this critical issue, we propose a diffusion-based generative model for synthesizing realistic and diverse spectrograms of five distinct categories that integrate LTE, 5G, and radar signals within the CBRS band. We conduct a structural and statistical fidelity analysis of the generated spectrograms using widely accepted evaluation metrics Structural Similarity Index Measure (SSIM) and Peak Signal-to-Noise Ratio (PSNR), to quantify their divergence from the training data. Furthermore, we demonstrate that pre-training on the generated spectrograms significantly improves training efficiency on a real-world radar detection task by enabling $51.5\\%$ faster convergence.",
        "tags": [
            "Detection",
            "Diffusion"
        ]
    },
    {
        "id": "95",
        "title": "LOMORO: Long-term Monitoring of Dynamic Targets with Minimum Robotic Fleet under Resource Constraints",
        "author": [
            "Mingke Lu",
            "Shuaikang Wang",
            "Meng Guo"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10046",
        "abstract": "Long-term monitoring of numerous dynamic targets can be tedious for a human operator and infeasible for a single robot, e.g., to monitor wild flocks, detect intruders, search and rescue. Fleets of autonomous robots can be effective by acting collaboratively and concurrently. However, the online coordination is challenging due to the unknown behaviors of the targets and the limited perception of each robot. Existing work often deploys all robots available without minimizing the fleet size, or neglects the constraints on their resources such as battery and memory. This work proposes an online coordination scheme called LOMORO for collaborative target monitoring, path routing and resource charging. It includes three core components: (I) the modeling of multi-robot task assignment problem under the constraints on resources and monitoring intervals; (II) the resource-aware task coordination algorithm iterates between the high-level assignment of dynamic targets and the low-level multi-objective routing via the Martin's algorithm; (III) the online adaptation algorithm in case of unpredictable target behaviors and robot failures. It ensures the explicitly upper-bounded monitoring intervals for all targets and the lower-bounded resource levels for all robots, while minimizing the average number of active robots. The proposed methods are validated extensively via large-scale simulations against several baselines, under different road networks, robot velocities, charging rates and monitoring intervals.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "96",
        "title": "SwarmSys: Decentralized Swarm-Inspired Agents for Scalable and Adaptive Reasoning",
        "author": [
            "Ruohao Li",
            "Hongjun Liu",
            "Leyi Zhao",
            "Zisu Li",
            "Jiawei Li",
            "Jiajun Jiang",
            "Linning Xu",
            "Chen Zhao",
            "Mingming Fan",
            "Chen Liang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10047",
        "abstract": "Large language model (LLM) agents have shown remarkable reasoning abilities. However, existing multi-agent frameworks often rely on fixed roles or centralized control, limiting scalability and adaptability in long-horizon reasoning. We introduce SwarmSys, a closed-loop framework for distributed multi-agent reasoning inspired by swarm intelligence. Coordination in SwarmSys emerges through iterative interactions among three specialized roles, Explorers, Workers, and Validators, that continuously cycle through exploration, exploitation, and validation. To enable scalable and adaptive collaboration, we integrate adaptive agent and event profiles, embedding-based probabilistic matching, and a pheromone-inspired reinforcement mechanism, supporting dynamic task allocation and self-organizing convergence without global supervision. Across symbolic reasoning, research synthesis, and scientific programming tasks, SwarmSys consistently outperforms baselines, improving both accuracy and reasoning stability. These findings highlight swarm-inspired coordination as a promising paradigm for scalable, robust, and adaptive multi-agent reasoning, suggesting that coordination scaling may rival model scaling in advancing LLM intelligence.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "97",
        "title": "ALLOY: Generating Reusable Agent Workflows from User Demonstration",
        "author": [
            "Jiawen Li",
            "Zheng Ning",
            "Yuan Tian",
            "Toby Jia-jun Li"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10049",
        "abstract": "Large language models (LLMs) enable end-users to delegate complex tasks to autonomous agents through natural language. However, prompt-based interaction faces critical limitations: Users often struggle to specify procedural requirements for tasks, especially those that don't have a factually correct solution but instead rely on personal preferences, such as posting social media content or planning a trip. Additionally, a ''successful'' prompt for one task may not be reusable or generalizable across similar tasks. We present ALLOY, a system inspired by classical HCI theories on Programming by Demonstration (PBD), but extended to enhance adaptability in creating LLM-based web agents. ALLOY enables users to express procedural preferences through natural demonstrations rather than prompts, while making these procedures transparent and editable through visualized workflows that can be generalized across task variations. In a study with 12 participants, ALLOY's demonstration--based approach outperformed prompt-based agents and manual workflows in capturing user intent and procedural preferences in complex web tasks. Insights from the study also show how demonstration--based interaction complements the traditional prompt-based approach.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "98",
        "title": "Complementary and Contrastive Learning for Audio-Visual Segmentation",
        "author": [
            "Sitong Gong",
            "Yunzhi Zhuge",
            "Lu Zhang",
            "Pingping Zhang",
            "Huchuan Lu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10051",
        "abstract": "Audio-Visual Segmentation (AVS) aims to generate pixel-wise segmentation maps that correlate with the auditory signals of objects. This field has seen significant progress with numerous CNN and Transformer-based methods enhancing the segmentation accuracy and robustness. Traditional CNN approaches manage audio-visual interactions through basic operations like padding and multiplications but are restricted by CNNs' limited local receptive field. More recently, Transformer-based methods treat auditory cues as queries, utilizing attention mechanisms to enhance audio-visual cooperation within frames. Nevertheless, they typically struggle to extract multimodal coefficients and temporal dynamics adequately. To overcome these limitations, we present the Complementary and Contrastive Transformer (CCFormer), a novel framework adept at processing both local and global information and capturing spatial-temporal context comprehensively. Our CCFormer initiates with the Early Integration Module (EIM) that employs a parallel bilateral architecture, merging multi-scale visual features with audio data to boost cross-modal complementarity. To extract the intra-frame spatial features and facilitate the perception of temporal coherence, we introduce the Multi-query Transformer Module (MTM), which dynamically endows audio queries with learning capabilities and models the frame and video-level relations simultaneously. Furthermore, we propose the Bi-modal Contrastive Learning (BCL) to promote the alignment across both modalities in the unified feature space. Through the effective combination of those designs, our method sets new state-of-the-art benchmarks across the S4, MS3 and AVSS datasets. Our source code and model weights will be made publicly available at https://github.com/SitongGong/CCFormer",
        "tags": [
            "Segmentation",
            "Transformer"
        ]
    },
    {
        "id": "99",
        "title": "DREAM: A Benchmark Study for Deepfake REalism AssessMent",
        "author": [
            "Bo Peng",
            "Zichuan Wang",
            "Sheng Yu",
            "Xiaochuan Jin",
            "Wei Wang",
            "Jing Dong"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10053",
        "abstract": "Deep learning based face-swap videos, widely known as deepfakes, have drawn wide attention due to their threat to information credibility. Recent works mainly focus on the problem of deepfake detection that aims to reliably tell deepfakes apart from real ones, in an objective way. On the other hand, the subjective perception of deepfakes, especially its computational modeling and imitation, is also a significant problem but lacks adequate study. In this paper, we focus on the visual realism assessment of deepfakes, which is defined as the automatic assessment of deepfake visual realism that approximates human perception of deepfakes. It is important for evaluating the quality and deceptiveness of deepfakes which can be used for predicting the influence of deepfakes on Internet, and it also has potentials in improving the deepfake generation process by serving as a critic. This paper prompts this new direction by presenting a comprehensive benchmark called DREAM, which stands for Deepfake REalism AssessMent. It is comprised of a deepfake video dataset of diverse quality, a large scale annotation that includes 140,000 realism scores and textual descriptions obtained from 3,500 human annotators, and a comprehensive evaluation and analysis of 16 representative realism assessment methods, including recent large vision language model based methods and a newly proposed description-aligned CLIP method. The benchmark and insights included in this study can lay the foundation for future research in this direction and other related areas.",
        "tags": [
            "CLIP",
            "Detection"
        ]
    },
    {
        "id": "100",
        "title": "One4Many-StablePacker: An Efficient Deep Reinforcement Learning Framework for the 3D Bin Packing Problem",
        "author": [
            "Lei Gao",
            "Shihong Huang",
            "Shengjie Wang",
            "Hong Ma",
            "Feng Zhang",
            "Hengda Bao",
            "Qichang Chen",
            "Weihua Zhou"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10057",
        "abstract": "The three-dimensional bin packing problem (3D-BPP) is widely applied in logistics and warehousing. Existing learning-based approaches often neglect practical stability-related constraints and exhibit limitations in generalizing across diverse bin dimensions. To address these limitations, we propose a novel deep reinforcement learning framework, One4Many-StablePacker (O4M-SP). The primary advantage of O4M-SP is its ability to handle various bin dimensions in a single training process while incorporating support and weight constraints common in practice. Our training method introduces two innovative mechanisms. First, it employs a weighted reward function that integrates loading rate and a new height difference metric for packing layouts, promoting improved bin utilization through flatter packing configurations. Second, it combines clipped policy gradient optimization with a tailored policy drifting method to mitigate policy entropy collapse, encouraging exploration at critical decision nodes during packing to avoid suboptimal solutions. Extensive experiments demonstrate that O4M-SP generalizes successfully across diverse bin dimensions and significantly outperforms baseline methods. Furthermore, O4M-SP exhibits strong practical applicability by effectively addressing packing scenarios with stability constraints.",
        "tags": [
            "3D",
            "RL"
        ]
    },
    {
        "id": "101",
        "title": "OBsmith: Testing JavaScript Obfuscator using LLM-powered sketching",
        "author": [
            "Shan Jiang",
            "Chenguang Zhu",
            "Sarfraz Khurshid"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10066",
        "abstract": "JavaScript obfuscators are widely deployed to protect intellectual property and resist reverse engineering, yet their correctness has been largely overlooked compared to performance and resilience. Existing evaluations typically measure resistance to deobfuscation, leaving the critical question of whether obfuscators preserve program semantics unanswered. Incorrect transformations can silently alter functionality, compromise reliability, and erode security-undermining the very purpose of obfuscation. To address this gap, we present OBsmith, a novel framework to systematically test JavaScript obfuscators using large language models (LLMs). OBsmith leverages LLMs to generate program sketches abstract templates capturing diverse language constructs, idioms, and corner cases-which are instantiated into executable programs and subjected to obfuscation under different configurations. Besides LLM-powered sketching, OBsmith also employs a second source: automatic extraction of sketches from real programs. This extraction path enables more focused testing of project specific features and lets developers inject domain knowledge into the resulting test cases. OBsmith uncovers 11 previously unknown correctness bugs. Under an equal program budget, five general purpose state-of-the-art JavaScript fuzzers (FuzzJIT, Jsfunfuzz, Superion, DIE, Fuzzilli) failed to detect these issues, highlighting OBsmith's complementary focus on obfuscation induced misbehavior. An ablation shows that all components except our generic MRs contribute to at least one bug class; the negative MR result suggests the need for obfuscator-specific metamorphic relations. Our results also seed discussion on how to balance obfuscation presets and performance cost. We envision OBsmith as an important step towards automated testing and quality assurance of obfuscators and other semantic-preserving toolchains.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "102",
        "title": "Probabilistic Hyper-Graphs using Multiple Randomly Masked Autoencoders for Semi-supervised Multi-modal Multi-task Learning",
        "author": [
            "PÃ®rvu Mihai-Cristian",
            "Leordeanu Marius"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10068",
        "abstract": "The computer vision domain has greatly benefited from an abundance of data across many modalities to improve on various visual tasks. Recently, there has been a lot of focus on self-supervised pre-training methods through Masked Autoencoders (MAE) \\cite{he2022masked,bachmann2022multimae}, usually used as a first step before optimizing for a downstream task, such as classification or regression. This is very useful as it doesn't require any manually labeled data. In this work, we introduce Probabilistic Hyper-Graphs using Masked Autoencoders (PHG-MAE): a novel model that unifies the classical work on neural graphs \\cite{leordeanu2021semi} with the modern approach of masked autoencoders under a common theoretical framework. Through random masking of entire modalities, not just patches, the model samples from the distribution of hyper-edges on each forward pass. Additionally, the model adapts the standard MAE algorithm by combining pre-training and fine-tuning into a single training loop. Moreover, our approach enables the creation of inference-time ensembles which, through aggregation, boost the final prediction performance and consistency. Lastly, we show that we can apply knowledge distillation on top of the ensembles with little loss in performance, even with models that have fewer than 1M parameters. While our work mostly focuses on outdoor UAV scenes that contain multiple world interpretations and modalities, the same steps can be followed in other similar domains, such as autonomous driving or indoor robotics. In order to streamline the process of integrating external pre-trained experts for computer vision multi-modal multi-task learning (MTL) scenarios, we developed a data-pipeline software. Using this tool, we have created and released a fully-automated extension of the Dronescapes dataset. All the technical details, code and reproduction steps are publicly released.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "103",
        "title": "SyncLipMAE: Contrastive Masked Pretraining for Audio-Visual Talking-Face Representation",
        "author": [
            "Zeyu Ling",
            "Xiaodong Gu",
            "Jiangnan Tang",
            "Changqing Zou"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10069",
        "abstract": "We introduce SyncLipMAE, a self-supervised pretraining framework for talking-face video that learns synchronization-aware and transferable facial dynamics from unlabeled audio-visual streams. Our approach couples masked visual modeling with cross-modal contrastive alignment and employs three per-frame prompt tokens that explicitly encode the essential factors of a talking-face frame - identity, vocal motion (speech-synchronized facial dynamics), and ambient motion (audio-agnostic movements such as blinks and head pose). The contrastive objective uses time-aligned vocal-motion and audio tokens as positives and misaligned pairs as negatives, driving both modalities into a shared embedding space and yielding token-level audio-visual stream synchronization. After pretraining, the aligned audio tokens together with the visual prompt tokens (identity, vocal motion, ambient motion) form a unified interface for four disparate downstream settings: (i) audio-visual stream synchronization; (ii) facial emotion and head/face action recognition; (iii) visual speech recognition; and (iv) visual dubbing, for which we enable indistinguishable audio- or video-driven control within a single model. Across four task families that require distinct capabilities, SyncLipMAE achieves state-of-the-art results, underscoring the effectiveness of synchronization-aware, factorized self-supervised pretraining.",
        "tags": [
            "Talking Face"
        ]
    },
    {
        "id": "104",
        "title": "Unilaw-R1: A Large Language Model for Legal Reasoning with Reinforcement Learning and Iterative Inference",
        "author": [
            "Hua Cai",
            "Shuang Zhao",
            "Liang Zhang",
            "Xuli Shen",
            "Qing Xu",
            "Weilin Shen",
            "Zihao Wen",
            "Tianke Ban"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10072",
        "abstract": "Reasoning-focused large language models (LLMs) are rapidly evolving across various domains, yet their capabilities in handling complex legal problems remains underexplored. In this paper, we introduce Unilaw-R1, a large language model tailored for legal reasoning. With a lightweight 7-billion parameter scale, Unilaw-R1 significantly reduces deployment cost while effectively tackling three core challenges in the legal domain: insufficient legal knowledge, unreliable reasoning logic, and weak business generalization. To address these issues, we first construct Unilaw-R1-Data, a high-quality dataset containing 17K distilled and screened chain-of-thought (CoT) samples. Based on this, we adopt a two-stage training strategy combining Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL), which significantly boosts the performance on complex legal reasoning tasks and supports interpretable decision-making in legal AI applications. To assess legal reasoning ability, we also introduce Unilaw-R1-Eval, a dedicated benchmark designed to evaluate models across single- and multi-choice legal tasks. Unilaw-R1 demonstrates strong results on authoritative benchmarks, outperforming all models of similar scale and achieving performance on par with the much larger DeepSeek-R1-Distill-Qwen-32B (54.9%). Following domain-specific training, it also showed significant gains on LawBench and LexEval, exceeding Qwen-2.5-7B-Instruct (46.6%) by an average margin of 6.6%.",
        "tags": [
            "CoT",
            "DeepSeek",
            "LLM",
            "Qwen",
            "RL"
        ]
    },
    {
        "id": "105",
        "title": "Agentic Troubleshooting Guide Automation for Incident Management",
        "author": [
            "Jiayi Mao",
            "Liqun Li",
            "Yanjie Gao",
            "Zegang Peng",
            "Shilin He",
            "Chaoyun Zhang",
            "Si Qin",
            "Samia Khalid",
            "Qingwei Lin",
            "Saravan Rajmohan",
            "Sitaram Lanka",
            "Dongmei Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10074",
        "abstract": "Effective incident management in large-scale IT systems relies on troubleshooting guides (TSGs), but their manual execution is slow and error-prone. While recent advances in LLMs offer promise for automating incident management tasks, existing LLM-based solutions lack specialized support for several key challenges, including managing TSG quality issues, interpreting complex control flow, handling data-intensive queries, and exploiting execution parallelism. We first conducted an empirical study on 92 real-world TSGs, and, guided by our findings, we present StepFly, a novel end-to-end agentic framework for troubleshooting guide automation. Our approach features a three-stage workflow: the first stage provides a comprehensive guide together with a tool, TSG Mentor, to assist SREs in improving TSG quality; the second stage performs offline preprocessing using LLMs to extract structured execution DAGs from unstructured TSGs and to create dedicated Query Preparation Plugins (QPPs); and the third stage executes online using a DAG-guided scheduler-executor framework with a memory system to guarantee correct workflow and support parallel execution of independent steps. Our empirical evaluation on a collection of real-world TSGs and incidents demonstrates that StepFly achieves a ~94% success rate on GPT-4.1, outperforming baselines with less time and token consumption. Furthermore, it achieves a remarkable execution time reduction of 32.9% to 70.4% for parallelizable TSGs.",
        "tags": [
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "106",
        "title": "A-IPO: Adaptive Intent-driven Preference Optimization",
        "author": [
            "Wenqing Wang",
            "Muhammad Asif Ali",
            "Ali Shoker",
            "Ruohan Yang",
            "Junyang Chen",
            "Ying Sha",
            "Huan Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10077",
        "abstract": "Human preferences are diverse and dynamic, shaped by regional, cultural, and social factors. Existing alignment methods like Direct Preference Optimization (DPO) and its variants often default to majority views, overlooking minority opinions and failing to capture latent user intentions in prompts.\nTo address these limitations, we introduce \\underline{\\textbf{A}}daptive \\textbf{\\underline{I}}ntent-driven \\textbf{\\underline{P}}reference \\textbf{\\underline{O}}ptimization (\\textbf{A-IPO}). Specifically,A-IPO introduces an intention module that infers the latent intent behind each user prompt and explicitly incorporates this inferred intent into the reward function, encouraging stronger alignment between the preferred model's responses and the user's underlying intentions. We demonstrate, both theoretically and empirically, that incorporating an intention--response similarity term increases the preference margin (by a positive shift of $\\lambda\\,\\Delta\\mathrm{sim}$ in the log-odds), resulting in clearer separation between preferred and dispreferred responses compared to DPO.\nFor evaluation, we introduce two new benchmarks, Real-pref, Attack-pref along with an extended version of an existing dataset, GlobalOpinionQA-Ext, to assess real-world and adversarial preference alignment.\nThrough explicit modeling of diverse user intents,A-IPO facilitates pluralistic preference optimization while simultaneously enhancing adversarial robustness in preference alignment. Comprehensive empirical evaluation demonstrates that A-IPO consistently surpasses existing baselines, yielding substantial improvements across key metrics: up to +24.8 win-rate and +45.6 Response-Intention Consistency on Real-pref; up to +38.6 Response Similarity and +52.2 Defense Success Rate on Attack-pref; and up to +54.6 Intention Consistency Score on GlobalOpinionQA-Ext.",
        "tags": [
            "DPO"
        ]
    },
    {
        "id": "107",
        "title": "Pharmacist: Safety Alignment Data Curation for Large Language Models against Harmful Fine-tuning",
        "author": [
            "Guozhi Liu",
            "Qi Mu",
            "Tiansheng Huang",
            "Xinhua Wang",
            "Li Shen",
            "Weiwei Lin",
            "Zhang Li"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10085",
        "abstract": "Harmful fine-tuning issues present significant safety challenges for fine-tuning-as-a-service in large language models. Existing alignment-stage defenses, e.g., Vaccine, Repnoise, Booster, and T-Vaccine, mitigate harmful fine-tuning issues by enhancing the model's robustness during the alignment phase. While these methods have been proposed to mitigate the issue, they often overlook a critical upstream factor: the role of the original safety-alignment data. We observe that their defense performance and computational efficiency remain constrained by the quality and composition of the alignment dataset. To address this limitation, we propose Pharmacist, a safety alignment data curation solution that enhances defense against harmful fine-tuning by selecting a high-quality and safety-critical core subset from the original alignment data. The core idea of Pharmacist is to train an alignment data selector to rank alignment data. Specifically, up-ranking high-quality and safety-critical alignment data, down-ranking low-quality and non-safety-critical data. Empirical results indicate that models trained on datasets selected by Pharmacist outperform those trained on datasets selected by existing selection methods in both defense and inference performance. In addition, Pharmacist can be effectively integrated with mainstream alignment-stage defense methods. For example, when applied to RepNoise and T-Vaccine, using the dataset selected by Pharmacist instead of the full dataset leads to improvements in defense performance by 2.60\\% and 3.30\\%, respectively, and enhances inference performance by 3.50\\% and 1.10\\%. Notably, it reduces training time by 56.83\\% and 57.63\\%, respectively. Our code is available at https://github.com/Lslland/Pharmacist.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "108",
        "title": "CardRewriter: Leveraging Knowledge Cards for Long-Tail Query Rewriting on Short-Video Platforms",
        "author": [
            "Peiyuan Gong",
            "Feiran Zhu",
            "Yaqi Yin",
            "Chenglei Dai",
            "Chao Zhang",
            "Kai Zheng",
            "Wentian Bao",
            "Jiaxin Mao",
            "Yi Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10095",
        "abstract": "Short-video platforms have rapidly become a new generation of information retrieval systems, where users formulate queries to access desired videos. However, user queries, especially long-tail ones, often suffer from spelling errors, incomplete phrasing, and ambiguous intent, resulting in mismatches between user expectations and retrieved results. While large language models (LLMs) have shown success in long-tail query rewriting within e-commerce, they struggle on short-video platforms, where proprietary content such as short videos, live streams, micro dramas, and user social networks falls outside their training distribution. To address this challenge, we introduce \\textbf{CardRewriter}, an LLM-based framework that incorporates domain-specific knowledge to enhance long-tail query rewriting. For each query, our method aggregates multi-source knowledge relevant to the query and summarizes it into an informative and query-relevant knowledge card. This card then guides the LLM to better capture user intent and produce more effective query rewrites. We optimize CardRewriter using a two-stage training pipeline: supervised fine-tuning followed by group relative policy optimization, with a tailored reward system balancing query relevance and retrieval effectiveness. Offline experiments show that CardRewriter substantially improves rewriting quality for queries targeting proprietary content. Online A/B testing further confirms significant gains in long-view rate (LVR) and click-through rate (CTR), along with a notable reduction in initiative query reformulation rate (IQRR). Since September 2025, CardRewriter has been deployed on Kuaishou, one of China's largest short-video platforms, serving hundreds of millions of users daily.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "109",
        "title": "Gesplat: Robust Pose-Free 3D Reconstruction via Geometry-Guided Gaussian Splatting",
        "author": [
            "Jiahui Lu",
            "Haihong Xiao",
            "Xueyan Zhao",
            "Wenxiong Kang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10097",
        "abstract": "Neural Radiance Fields (NeRF) and 3D Gaussian Splatting (3DGS) have advanced 3D reconstruction and novel view synthesis, but remain heavily dependent on accurate camera poses and dense viewpoint coverage. These requirements limit their applicability in sparse-view settings, where pose estimation becomes unreliable and supervision is insufficient. To overcome these challenges, we introduce Gesplat, a 3DGS-based framework that enables robust novel view synthesis and geometrically consistent reconstruction from unposed sparse images. Unlike prior works that rely on COLMAP for sparse point cloud initialization, we leverage the VGGT foundation model to obtain more reliable initial poses and dense point clouds. Our approach integrates several key innovations: 1) a hybrid Gaussian representation with dual position-shape optimization enhanced by inter-view matching consistency; 2) a graph-guided attribute refinement module to enhance scene details; and 3) flow-based depth regularization that improves depth estimation accuracy for more effective supervision. Comprehensive quantitative and qualitative experiments demonstrate that our approach achieves more robust performance on both forward-facing and large-scale complex datasets compared to other pose-free methods.",
        "tags": [
            "3D",
            "Depth Estimation",
            "Gaussian Splatting",
            "NeRF",
            "Pose Estimation"
        ]
    },
    {
        "id": "110",
        "title": "Cooperative Pseudo Labeling for Unsupervised Federated Classification",
        "author": [
            "Kuangpu Guo",
            "Lijun Sheng",
            "Yongcan Yu",
            "Jian Liang",
            "Zilei Wang",
            "Ran He"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10100",
        "abstract": "Unsupervised Federated Learning (UFL) aims to collaboratively train a global model across distributed clients without sharing data or accessing label information. Previous UFL works have predominantly focused on representation learning and clustering tasks. Recently, vision language models (e.g., CLIP) have gained significant attention for their powerful zero-shot prediction capabilities. Leveraging this advancement, classification problems that were previously infeasible under the UFL paradigm now present promising new opportunities, yet remain largely unexplored. In this paper, we extend UFL to the classification problem with CLIP for the first time and propose a novel method, \\underline{\\textbf{Fed}}erated \\underline{\\textbf{Co}}operative \\underline{\\textbf{P}}seudo \\underline{\\textbf{L}}abeling (\\textbf{FedCoPL}). Specifically, clients estimate and upload their pseudo label distribution, and the server adjusts and redistributes them to avoid global imbalance among classes. Moreover, we introduce a partial prompt aggregation protocol for effective collaboration and personalization. In particular, visual prompts containing general image features are aggregated at the server, while text prompts encoding personalized knowledge are retained locally. Extensive experiments demonstrate the superior performance of our FedCoPL compared to baseline methods. Our code is available at \\href{https://github.com/krumpguo/FedCoPL}{https://github.com/krumpguo/FedCoPL}.",
        "tags": [
            "CLIP",
            "VLM"
        ]
    },
    {
        "id": "111",
        "title": "PANTHER: Generative Pretraining Beyond Language for Sequential User Behavior Modeling",
        "author": [
            "Guilin Li",
            "Yun Zhang",
            "Xiuyuan Chen",
            "Chengqi Li",
            "Bo Wang",
            "Linghe Kong",
            "Wenjia Wang",
            "Weiran Huang",
            "Matthias Hwai Yong Tan"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10102",
        "abstract": "Large language models (LLMs) have shown that generative pretraining can distill vast world knowledge into compact token representations. While LLMs encapsulate extensive world knowledge, they remain limited in modeling the behavioral knowledge contained within user interaction histories. User behavior forms a distinct modality, where each action, defined by multi-dimensional attributes such as time, context, and transaction type, constitutes a behavioral token. Modeling these high-cardinality sequences is challenging, and discriminative models often falter under limited supervision. To bridge this gap, we extend generative pretraining to user behavior, learning transferable representations from unlabeled behavioral data analogous to how LLMs learn from text. We present PANTHER, a hybrid generative-discriminative framework that unifies user behavior pretraining and downstream adaptation, enabling large-scale sequential user representation learning and real-time inference. PANTHER introduces: (1) Structured Tokenization to compress multi-dimensional transaction attributes into an interpretable vocabulary; (2) Sequence Pattern Recognition Module (SPRM) for modeling periodic transaction motifs; (3) a Unified User-Profile Embedding that fuses static demographics with dynamic transaction histories; and (4) Real-time scalability enabled by offline caching of pretrained embeddings for millisecond-level inference. Fully deployed and operational online at WeChat Pay, PANTHER delivers a 25.6 percent boost in next-transaction prediction HitRate@1 and a 38.6 percent relative improvement in fraud detection recall over baselines. Cross-domain evaluations on public benchmarks show strong generalization, achieving up to 21 percent HitRate@1 gains over transformer baselines, establishing PANTHER as a scalable, high-performance framework for industrial sequential user behavior modeling.",
        "tags": [
            "Detection",
            "LLM",
            "Transformer"
        ]
    },
    {
        "id": "112",
        "title": "Stop When Enough: Adaptive Early-Stopping for Chain-of-Thought Reasoning",
        "author": [
            "Renliang Sun",
            "Wei Cheng",
            "Dawei Li",
            "Haifeng Chen",
            "Wei Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10103",
        "abstract": "Chain-of-Thought (CoT) reasoning has driven recent gains of large language models (LLMs) on reasoning-intensive tasks by externalizing intermediate steps. However, excessive or redundant reasoning -- so-called overthinking -- can increase inference costs and lead LLMs toward incorrect conclusions. In this paper, we present REFRAIN ($\\underline{REF}$lective-$\\underline{R}$edundancy for $\\underline{A}$daptive $\\underline{IN}$ference), a training-free framework that adaptively determines when to stop reasoning to mitigate overthinking. REFRAIN integrates a two-stage stop discriminator to identify reflective yet redundant reasoning and a sliding-window Upper Confidence Bound (SW-UCB) multi-armed bandit controller to dynamically adjust stopping thresholds according to problem difficulty without supervision or fine-tuning. Across four representative benchmarks and two model families, REFRAIN reduces token usage by 20-55% while maintaining or improving accuracy compared to standard CoT prompting. Extensive ablation and robustness analyses demonstrate its stability across models, scorers, and prompt variations. In summary, our findings highlight when-to-stop as a new and practical axis of test-time scaling -- enabling models to reason not just more, but just enough.",
        "tags": [
            "CoT",
            "LLM"
        ]
    },
    {
        "id": "113",
        "title": "Answer-Consistent Chain-of-thought Reinforcement Learning For Multi-modal Large Langauge Models",
        "author": [
            "Minbin Huang",
            "Runhui Huang",
            "Chuanyang Zheng",
            "Jingyao Li",
            "Guoxuan Chen",
            "Han Shi",
            "Hong Cheng"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10104",
        "abstract": "Recent advances in large language models (LLMs) have demonstrated that reinforcement learning with verifiable rewards (RLVR) can significantly enhance reasoning abilities by directly optimizing correctness, rather than relying solely on supervised imitation. This paradigm has been extended to multimodal LLMs for complex video and image understanding tasks. However, while outcome-driven RL improves answer accuracy, it can inadvertently decouple the reasoning chain from the final answer, leading to situations where models produce inconsistency between the reasoning trace and final answer. In our experiments on multiple-choice visual question-answering tasks, the standard GRPO method yields only 79.7\\% consistency on MMVU between the reasoning steps and the chosen answers, indicating frequent mismatches between answers and reasoning. To this end, we propose Answer-Consistent Reinforcement Learning (ACRE) that modifies the GRPO algorithm with an auxiliary consistency check. After the model generates a chain of thought and an initial answer for a given question, we shuffle the answer options and prompt the model again with the same reasoning trace to predict a second answer. We design a consistency-verification reward that grants a high reward only if both the original and the post-shuffle answers agree and are correct; otherwise, a lower reward is assigned accordingly. This mechanism penalizes reasoning-answer misalignment and discourages the model from relying on spurious patterns, such as option ordering biases. We evaluate ACRE on challenging Video Reasoning benchmarks and multimodal math reasoning benchmarks, achieving an average 2.2\\% and 1.5\\% improvement for Video Reasoning and Math Reasoning tasks over the GRPO baseline.",
        "tags": [
            "CoT",
            "GRPO",
            "LLM",
            "RL"
        ]
    },
    {
        "id": "114",
        "title": "Training-Free In-Context Forensic Chain for Image Manipulation Detection and Localization",
        "author": [
            "Rui Chen",
            "Bin Liu",
            "Changtao Miao",
            "Xinghao Wang",
            "Yi Li",
            "Tao Gong",
            "Qi Chu",
            "Nenghai Yu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10111",
        "abstract": "Advances in image tampering pose serious security threats, underscoring the need for effective image manipulation localization (IML). While supervised IML achieves strong performance, it depends on costly pixel-level annotations. Existing weakly supervised or training-free alternatives often underperform and lack interpretability. We propose the In-Context Forensic Chain (ICFC), a training-free framework that leverages multi-modal large language models (MLLMs) for interpretable IML tasks. ICFC integrates an objectified rule construction with adaptive filtering to build a reliable knowledge base and a multi-step progressive reasoning pipeline that mirrors expert forensic workflows from coarse proposals to fine-grained forensics results. This design enables systematic exploitation of MLLM reasoning for image-level classification, pixel-level localization, and text-level interpretability. Across multiple benchmarks, ICFC not only surpasses state-of-the-art training-free methods but also achieves competitive or superior performance compared to weakly and fully supervised approaches.",
        "tags": [
            "Detection",
            "LLM"
        ]
    },
    {
        "id": "115",
        "title": "LinearRAG: Linear Graph Retrieval Augmented Generation on Large-scale Corpora",
        "author": [
            "Luyao Zhuang",
            "Shengyuan Chen",
            "Yilin Xiao",
            "Huachi Zhou",
            "Yujing Zhang",
            "Hao Chen",
            "Qinggang Zhang",
            "Xiao Huang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10114",
        "abstract": "Retrieval-Augmented Generation (RAG) is widely used to mitigate hallucinations of Large Language Models (LLMs) by leveraging external knowledge. While effective for simple queries, traditional RAG systems struggle with large-scale, unstructured corpora where information is fragmented. Recent advances incorporate knowledge graphs to capture relational structures, enabling more comprehensive retrieval for complex, multi-hop reasoning tasks. However, existing graph-based RAG (GraphRAG) methods rely on unstable and costly relation extraction for graph construction, often producing noisy graphs with incorrect or inconsistent relations that degrade retrieval quality. In this paper, we revisit the pipeline of existing GraphRAG systems and propose LinearRAG (Linear Graph-based Retrieval-Augmented Generation), an efficient framework that enables reliable graph construction and precise passage retrieval. Specifically, LinearRAG constructs a relation-free hierarchical graph, termed Tri-Graph, using only lightweight entity extraction and semantic linking, avoiding unstable relation modeling. This new paradigm of graph construction scales linearly with corpus size and incurs no extra token consumption, providing an economical and reliable indexing of the original passages. For retrieval, LinearRAG adopts a two-stage strategy: (i) relevant entity activation via local semantic bridging, followed by (ii) passage retrieval through global importance aggregation. Extensive experiments on four datasets demonstrate that LinearRAG significantly outperforms baseline models.",
        "tags": [
            "LLM",
            "RAG"
        ]
    },
    {
        "id": "116",
        "title": "Preference-driven Knowledge Distillation for Few-shot Node Classification",
        "author": [
            "Xing Wei",
            "Chunchun Chen",
            "Rui Fan",
            "Xiaofeng Cao",
            "Sourav Medya",
            "Wei Ye"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10116",
        "abstract": "Graph neural networks (GNNs) can efficiently process text-attributed graphs (TAGs) due to their message-passing mechanisms, but their training heavily relies on the human-annotated labels. Moreover, the complex and diverse local topologies of nodes of real-world TAGs make it challenging for a single mechanism to handle. Large language models (LLMs) perform well in zero-/few-shot learning on TAGs but suffer from a scalability challenge. Therefore, we propose a preference-driven knowledge distillation (PKD) framework to synergize the complementary strengths of LLMs and various GNNs for few-shot node classification. Specifically, we develop a GNN-preference-driven node selector that effectively promotes prediction distillation from LLMs to teacher GNNs. To further tackle nodes' intricate local topologies, we develop a node-preference-driven GNN selector that identifies the most suitable teacher GNN for each node, thereby facilitating tailored knowledge distillation from teacher GNNs to the student GNN. Extensive experiments validate the efficacy of our proposed framework in few-shot node classification on real-world TAGs.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "117",
        "title": "DixitWorld: Evaluating Multimodal Abductive Reasoning in Vision-Language Models with Multi-Agent Dixit Gameplay",
        "author": [
            "Yunxiang Mo",
            "Tianshi Zheng",
            "Qing Zong",
            "Jiayu Liu",
            "Baixuan Xu",
            "Yauwai Yim",
            "Chunkit Chan",
            "Jiaxin Bai",
            "Yangqiu Song"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10117",
        "abstract": "Multimodal abductive reasoning--the generation and selection of explanatory hypotheses from partial observations--is a cornerstone of intelligence. Current evaluations of this ability in vision-language models (VLMs) are largely confined to static, single-agent tasks. Inspired by Dixit, we introduce DixitWorld, a comprehensive evaluation suite designed to deconstruct this challenge. DIXITWORLD features two core components: DixitArena, a dynamic, multi-agent environment that evaluates both hypothesis generation (a \"storyteller\" crafting cryptic clues) and hypothesis selection (\"listeners\" choosing the target image from decoys) under imperfect information; and DixitBench, a static QA benchmark that isolates the listener's task for efficient, controlled evaluation. Results from DixitArena reveal distinct, role-dependent behaviors: smaller open-source models often excel as creative storytellers, producing imaginative yet less discriminative clues, whereas larger proprietary models demonstrate superior overall performance, particularly as listeners. Performance on DixitBench strongly correlates with listener results in DixitArena, validating it as a reliable proxy for hypothesis selection. Our findings reveal a key trade-off between generative creativity and discriminative understanding in multimodal abductive reasoning, a central challenge for developing more balanced and capable vision-language agents.",
        "tags": [
            "VLM"
        ]
    },
    {
        "id": "118",
        "title": "IntrinTrans: LLM-based Intrinsic Code Translator for RISC-V Vector",
        "author": [
            "Liutong Han",
            "Zhiyuan Tan",
            "Hongbin Zhang",
            "Pengcheng Wang",
            "Chu Kang",
            "Mingjie Xing",
            "Yanjun Wu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10119",
        "abstract": "The use of intrinsic functions to exploit hardware-specific capabilities is an important approach for optimizing library performance. Many mainstream libraries implement a large number of vectorized algorithms on Arm or x86 SIMD intrinsic functions. With the rapid expansion of the RISC-V hardware-software ecosystem, there is a growing demand for support of the RISC-V Vector (RVV) extension. Translating existing vectorized intrinsic code onto RVV intrinsics is a practical and effective approach. However, current cross-architecture translation largely relies on manual rewriting, which is time-consuming and error-prone. Furthermore, while some rule-based methods can reduce the need for manual intervention, their translation success rate is limited by incomplete rule coverage and syntactic constraints, and the performance suffers from inadequate utilization of RVV-specific features. We present IntrinTrans, a LLM-based multi-agent approach that utilizes compile-and-test feedback to translate intrinsic code across architectures automatically, and further optimizes the generated RVV intrinsics using register-usage information derived from liveness analysis. To evaluate the effectiveness of our approach, we collected 34 vectorized algorithm cases from open-source libraries. Each case includes an Arm Neon intrinsics implementation and a RVV intrinsics implementation contributed by the open-source community, together with correctness and performance tests. Our experiments show that advanced LLMs produce semantically correct RISC-V Vector intrinsics in most cases within a limited number of iterations, and in some cases achieve up to 5.93x the performance of the native implementation from the open-source community.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "119",
        "title": "DeepFusionNet: Autoencoder-Based Low-Light Image Enhancement and Super-Resolution",
        "author": [
            "Halil HÃ¼seyin ÃalÄ±Åkan",
            "Talha Koruk"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10122",
        "abstract": "Computer vision and image processing applications suffer from dark and low-light images, particularly during real-time image transmission. Currently, low light and dark images are converted to bright and colored forms using autoencoders; however, these methods often achieve low SSIM and PSNR scores and require high computational power due to their large number of parameters. To address these challenges, the DeepFusionNet architecture has been developed. According to the results obtained with the LOL-v1 dataset, DeepFusionNet achieved an SSIM of 92.8% and a PSNR score of 26.30, while containing only approximately 2.5 million parameters. On the other hand, conversion of blurry and low-resolution images into high-resolution and blur-free images has gained importance in image processing applications. Unlike GAN-based super-resolution methods, an autoencoder-based super resolution model has been developed that contains approximately 100 thousand parameters and uses the DeepFusionNet architecture. According to the results of the tests, the DeepFusionNet based super-resolution method achieved a PSNR of 25.30 and a SSIM score of 80.7 percent according to the validation set.",
        "tags": [
            "GAN",
            "Super Resolution"
        ]
    },
    {
        "id": "120",
        "title": "Ctrl-World: A Controllable Generative World Model for Robot Manipulation",
        "author": [
            "Yanjiang Guo",
            "Lucy Xiaoyang Shi",
            "Jianyu Chen",
            "Chelsea Finn"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10125",
        "abstract": "Generalist robot policies can now perform a wide range of manipulation skills, but evaluating and improving their ability with unfamiliar objects and instructions remains a significant challenge. Rigorous evaluation requires a large number of real-world rollouts, while systematic improvement demands additional corrective data with expert labels. Both of these processes are slow, costly, and difficult to scale. World models offer a promising, scalable alternative by enabling policies to rollout within imagination space. However, a key challenge is building a controllable world model that can handle multi-step interactions with generalist robot policies. This requires a world model compatible with modern generalist policies by supporting multi-view prediction, fine-grained action control, and consistent long-horizon interactions, which is not achieved by previous works. In this paper, we make a step forward by introducing a controllable multi-view world model that can be used to evaluate and improve the instruction-following ability of generalist robot policies. Our model maintains long-horizon consistency with a pose-conditioned memory retrieval mechanism and achieves precise action control through frame-level action conditioning. Trained on the DROID dataset (95k trajectories, 564 scenes), our model generates spatially and temporally consistent trajectories under novel scenarios and new camera placements for over 20 seconds. We show that our method can accurately rank policy performance without real-world robot rollouts. Moreover, by synthesizing successful trajectories in imagination and using them for supervised fine-tuning, our approach can improve policy success by 44.7\\%.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "121",
        "title": "CacheClip: Accelerating RAG with Effective KV Cache Reuse",
        "author": [
            "Bin Yang",
            "Qiuyu Leng",
            "Jun Zeng",
            "Zhenhua Wu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10129",
        "abstract": "Retrieval-Augmented Generation (RAG) systems suffer from severe time-to-first-token (TTFT) bottlenecks due to long input sequences. Existing KV cache reuse methods face a fundamental trade-off: prefix caching requires identical prefixes that rarely occur in RAG scenarios, while direct precomputation sacrifices quality due to missing inter-chunk attention and repeated attention sinks. Recent methods like APE and CacheBlend partially address these issues but remain inadequate for robust RAG applications. This paper presents CacheClip, a novel framework that achieves both fast TTFT and high generation quality. Our key insight is that small auxiliary LLMs exhibit similar last-layer attention distributions to primary LLMs (the target model for generation), enabling efficient identification of tokens critical for restoring inter-chunk attention, thereby significantly improving response quality on cross-chunk reasoning tasks. CacheClip integrates three techniques: (1) auxiliary-model-guided token selection for selective KV cache recomputation, where the auxiliary model is finetuned to improve selection accuracy, (2) shared prefixes to eliminate redundant attention sinks, and (3) grouping strategy to maintain local coherence during partial KV cache updates. Experiments show CacheClip retains up to 94.8% and 85.0% of full-attention performance on NIAH and LongBench, outperforming APE and CacheBlend by 25.2% and 35.1% on NIAH (with reomp% = 20%). Meanwhile, CacheClip accelerates LLM inference by up to 1.92x in prefill time, providing a practical solution to the efficiency-quality trade-off in RAG systems.",
        "tags": [
            "LLM",
            "RAG"
        ]
    },
    {
        "id": "122",
        "title": "Proof Strategy Extraction from LLMs for Enhancing Symbolic Provers",
        "author": [
            "Jian Fang",
            "Yican Sun",
            "Yingfei Xiong"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10131",
        "abstract": "One important approach to software verification is interactive theorem proving. However, writing formal proofs often requires substantial human effort, making proof automation highly important. Traditionally, proof automation has relied on symbolic provers. Recently, large language models (LLMs) have demonstrated strong capabilities in theorem proving, complementing symbolic provers. Nonetheless, prompting LLMs can be expensive and may pose security risks for confidential codebases. As a result, purely symbolic approaches remain important even in the LLM era, as they are cost-effective, secure, and complement the strengths of LLMs.\nMotivated by these considerations, we ask a new research question: can we extract the internal strategies of LLMs to enhance the capabilities of symbolic provers? As an initial attempt to answer this question, we propose Strat2Rocq, which extracts proof strategies from LLMs and formalizes them as lemmas in Rocq. These lemmas are accessible to symbolic provers such as CoqHammer. With the addition of these LLM-extracted lemmas, CoqHammer is able to prove more theorems. The knowledge extraction process involves analyzing the proof trajectories of LLMs on a training set of proved theorems. For each theorem, we prompt the LLM to generate a natural language proof, then ask it to summarize this proof into formalized lemmas with proofs. We also employ a standard agentic approach to mitigate errors during formalization. Our evaluation demonstrates that, on open-source Rocq projects for software verification, Strat2Rocq enhances the success rate of CoqHammer by 13.41%.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "123",
        "title": "CharCom: Composable Identity Control for Multi-Character Story Illustration",
        "author": [
            "Zhongsheng Wang",
            "Ming Lin",
            "Zhedong Lin",
            "Yaser Shakib",
            "Qian Liu",
            "Jiamou Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10135",
        "abstract": "Ensuring character identity consistency across varying prompts remains a fundamental limitation in diffusion-based text-to-image generation. We propose CharCom, a modular and parameter-efficient framework that achieves character-consistent story illustration through composable LoRA adapters, enabling efficient per-character customization without retraining the base model. Built on a frozen diffusion backbone, CharCom dynamically composes adapters at inference using prompt-aware control. Experiments on multi-scene narratives demonstrate that CharCom significantly enhances character fidelity, semantic alignment, and temporal coherence. It remains robust in crowded scenes and enables scalable multi-character generation with minimal overhead, making it well-suited for real-world applications such as story illustration and animation.",
        "tags": [
            "Diffusion",
            "LoRA",
            "Text-to-Image"
        ]
    },
    {
        "id": "124",
        "title": "PermLLM: Learnable Channel Permutation for N:M Sparse Large Language Models",
        "author": [
            "Lancheng Zou",
            "Shuo Yin",
            "Zehua Pei",
            "Tsung-Yi Ho",
            "Farzan Farnia",
            "Bei Yu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10136",
        "abstract": "Channel permutation is a powerful technique for enhancing the accuracy of N:M sparse models by reordering the channels of weight matrices to prioritize the retention of important weights. However, traditional channel permutation methods rely on handcrafted quality metrics, which often fail to accurately capture the true impact of pruning on model performance. To address this limitation, we propose PermLLM, a novel post-training pruning framework that introduces learnable channel permutation (LCP) for N:M sparsity. LCP leverages Sinkhorn normalization to transform discrete permutation matrices into differentiable soft permutation matrices, enabling end-to-end optimization. Additionally, PermLLM incorporates an efficient block-wise channel permutation strategy, which significantly reduces the number of learnable parameters and computational complexity. PermLLM seamlessly integrates with existing one-shot pruning methods to adaptively optimize channel permutations, effectively mitigating pruning-induced errors. Extensive experiments on the LLaMA series, Qwen, and OPT models demonstrate that PermLLM achieves superior performance in optimizing N:M sparse models. The code is available at https://github.com/lanchengzou/PermLLM.",
        "tags": [
            "LLM",
            "LLaMA",
            "Qwen"
        ]
    },
    {
        "id": "125",
        "title": "Hybrid OCR-LLM Framework for Enterprise-Scale Document Information Extraction Under Copy-heavy Task",
        "author": [
            "Zilong Wang",
            "Xiaoyu Shen"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10138",
        "abstract": "Information extraction from copy-heavy documents, characterized by massive volumes of structurally similar content, represents a critical yet understudied challenge in enterprise document processing. We present a systematic framework that strategically combines OCR engines with Large Language Models (LLMs) to optimize the accuracy-efficiency trade-off inherent in repetitive document extraction tasks. Unlike existing approaches that pursue universal solutions, our method exploits document-specific characteristics through intelligent strategy selection. We implement and evaluate 25 configurations across three extraction paradigms (direct, replacement, and table-based) on identity documents spanning four formats (PNG, DOCX, XLSX, PDF). Through table-based extraction methods, our adaptive framework delivers outstanding results: F1=1.0 accuracy with 0.97s latency for structured documents, and F1=0.997 accuracy with 0.6 s for challenging image inputs when integrated with PaddleOCR, all while maintaining sub-second processing speeds. The 54 times performance improvement compared with multimodal methods over naive approaches, coupled with format-aware routing, enables processing of heterogeneous document streams at production scale. Beyond the specific application to identity extraction, this work establishes a general principle: the repetitive nature of copy-heavy tasks can be transformed from a computational burden into an optimization opportunity through structure-aware method selection.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "126",
        "title": "DiffHeads: Differential Analysis and Inference-Time Masking of Bias Heads in Large Language Models",
        "author": [
            "Tingxu Han",
            "Wei Song",
            "Ziqi Ding",
            "Ziming Li",
            "Chunrong Fang",
            "Yuekang Li",
            "Dongfang Liu",
            "Zhenyu Chen",
            "Zhenting Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10142",
        "abstract": "Large language models (LLMs) increasingly mediate decisions in domains where unfair treatment of demographic groups is unacceptable. Existing work probes when biased outputs appear, but gives little insight into the mechanisms that generate them, leaving existing mitigations largely fragile. In this paper, we conduct a systematic investigation LLM unfairness and propose DiffHeads, a lightweight debiasing framework for LLMs. We first compare Direct-Answer (DA) prompting to Chain-of-Thought (CoT) prompting across eight representative open- and closed-source LLMs. DA will trigger the nature bias part of LLM and improve measured unfairness by 534.5%-391.9% in both one-turn and two-turn dialogues. Next, we define a token-to-head contribution score that traces each token's influence back to individual attention heads. This reveals a small cluster of bias heads that activate under DA but stay largely dormant with CoT, providing the first causal link between prompting strategy and bias emergence. Finally, building on this insight, we propose DiffHeads that identifies bias heads through differential activation analysis between DA and CoT, and selectively masks only those heads. DiffHeads reduces unfairness by 49.4%, and 40.3% under DA and CoT, respectively, without harming model utility.",
        "tags": [
            "CoT",
            "LLM"
        ]
    },
    {
        "id": "127",
        "title": "A Systematic Study on Generating Web Vulnerability Proof-of-Concepts Using Large Language Models",
        "author": [
            "Mengyao Zhao",
            "Kaixuan Li",
            "Lyuye Zhang",
            "Wenjing Dang",
            "Chenggong Ding",
            "Sen Chen",
            "Zheli Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10148",
        "abstract": "Recent advances in Large Language Models (LLMs) have brought remarkable progress in code understanding and reasoning, creating new opportunities and raising new concerns for software security. Among many downstream tasks, generating Proof-of-Concept (PoC) exploits plays a central role in vulnerability reproduction, comprehension, and mitigation. While previous research has focused primarily on zero-day exploitation, the growing availability of rich public information accompanying disclosed CVEs leads to a natural question: can LLMs effectively use this information to automatically generate valid PoCs? In this paper, we present the first empirical study of LLM-based PoC generation for web application vulnerabilities, focusing on the practical feasibility of leveraging publicly disclosed information. We evaluate GPT-4o and DeepSeek-R1 on 100 real-world and reproducible CVEs across three stages of vulnerability disclosure: (1) newly disclosed vulnerabilities with only descriptions, (2) 1-day vulnerabilities with patches, and (3) N-day vulnerabilities with full contextual code. Our results show that LLMs can automatically generate working PoCs in 8%-34% of cases using only public data, with DeepSeek-R1 consistently outperforming GPT-4o. Further analysis shows that supplementing code context improves success rates by 17%-20%, with function-level providing 9%-13% improvement than file-level ones. Further integrating adaptive reasoning strategies to prompt refinement significantly improves success rates to 68%-72%. Our findings suggest that LLMs could reshape vulnerability exploitation dynamics. To date, 23 newly generated PoCs have been accepted by NVD and Exploit DB.",
        "tags": [
            "DeepSeek",
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "128",
        "title": "Robust Learning of Diffusion Models with Extremely Noisy Conditions",
        "author": [
            "Xin Chen",
            "Gillian Dobbie",
            "Xinyu Wang",
            "Feng Liu",
            "Di Wang",
            "Jingfeng Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10149",
        "abstract": "Conditional diffusion models have the generative controllability by incorporating external conditions. However, their performance significantly degrades with noisy conditions, such as corrupted labels in the image generation or unreliable observations or states in the control policy generation. This paper introduces a robust learning framework to address extremely noisy conditions in conditional diffusion models. We empirically demonstrate that existing noise-robust methods fail when the noise level is high. To overcome this, we propose learning pseudo conditions as surrogates for clean conditions and refining pseudo ones progressively via the technique of temporal ensembling. Additionally, we develop a Reverse-time Diffusion Condition (RDC) technique, which diffuses pseudo conditions to reinforce the memorization effect and further facilitate the refinement of the pseudo conditions. Experimentally, our approach achieves state-of-the-art performance across a range of noise levels on both class-conditional image generation and visuomotor policy generation http://tasks.The code can be accessible via the project page https://robustdiffusionpolicy.github.io",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "129",
        "title": "Rethinking Entropy Interventions in RLVR: An Entropy Change Perspective",
        "author": [
            "Zhezheng Hao",
            "Hong Wang",
            "Haoyang Liu",
            "Jian Luo",
            "Jiarui Yu",
            "Hande Dong",
            "Qiang Lin",
            "Can Wang",
            "Jiawei Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10150",
        "abstract": "While Reinforcement Learning with Verifiable Rewards (RLVR) can enhance LLM reasoning, its training process poses a critical risk: entropy collapse. This phenomenon is a rapid loss of policy diversity, stemming from the exploration-exploitation imbalance and leading to a lack of generalization. Recent entropy-intervention methods aim to prevent \\coloredtext{entropy collapse}, yet their underlying mechanisms remain unclear. In this paper, we conduct a quantitative analysis to reveal token-level entropy changes and how existing entropy intervention methods help avoid entropy collapse. Our findings point out a fundamental limitation of existing methods: they attempt to control entropy dynamics indirectly. By only affecting related factors, such as the advantage signal and generation probability, their effectiveness is inherently limited and could potentially fail. To address this limitation, we introduce an entropy-change-aware reweighting scheme, namely Stabilizing Token-level Entropy-changE via Reweighting (STEER), that adaptively stabilizes entropy dynamics through fine-grained token-level adjustments. Our approach mitigates over-exploitation while fostering robust exploration. Extensive experiments demonstrate that STEER significantly mitigates entropy collapse, stabilizes entropy dynamics, and achieves stronger downstream performance across various mathematical reasoning benchmarks \\footnote{Our code is available at https://github.com/zz-haooo/STEER.",
        "tags": [
            "LLM",
            "RL"
        ]
    },
    {
        "id": "130",
        "title": "Color3D: Controllable and Consistent 3D Colorization with Personalized Colorizer",
        "author": [
            "Yecong Wan",
            "Mingwen Shao",
            "Renlong Wu",
            "Wangmeng Zuo"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10152",
        "abstract": "In this work, we present Color3D, a highly adaptable framework for colorizing both static and dynamic 3D scenes from monochromatic inputs, delivering visually diverse and chromatically vibrant reconstructions with flexible user-guided control. In contrast to existing methods that focus solely on static scenarios and enforce multi-view consistency by averaging color variations which inevitably sacrifice both chromatic richness and controllability, our approach is able to preserve color diversity and steerability while ensuring cross-view and cross-time consistency. In particular, the core insight of our method is to colorize only a single key view and then fine-tune a personalized colorizer to propagate its color to novel views and time steps. Through personalization, the colorizer learns a scene-specific deterministic color mapping underlying the reference view, enabling it to consistently project corresponding colors to the content in novel views and video frames via its inherent inductive bias. Once trained, the personalized colorizer can be applied to infer consistent chrominance for all other images, enabling direct reconstruction of colorful 3D scenes with a dedicated Lab color space Gaussian splatting representation. The proposed framework ingeniously recasts complicated 3D colorization as a more tractable single image paradigm, allowing seamless integration of arbitrary image colorization models with enhanced flexibility and controllability. Extensive experiments across diverse static and dynamic 3D colorization benchmarks substantiate that our method can deliver more consistent and chromatically rich renderings with precise user control. Project Page https://yecongwan.github.io/Color3D/.",
        "tags": [
            "3D",
            "Gaussian Splatting"
        ]
    },
    {
        "id": "131",
        "title": "CompassNav: Steering From Path Imitation To Decision Understanding In Navigation",
        "author": [
            "LinFeng Li",
            "Jian Zhao",
            "Yuan Xie",
            "Xin Tan",
            "Xuelong Li"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10154",
        "abstract": "The dominant paradigm for training Large Vision-Language Models (LVLMs) in navigation relies on imitating expert trajectories. This approach reduces the complex navigation task to a sequence-to-sequence replication of a single correct path, fundamentally limiting the agent's ability to explore and generalize. In this work, we argue for and introduce a new paradigm: a shift from Path Imitation to Decision Understanding. The goal of this paradigm is to build agents that do not just follow, but truly understand how to navigate. We materialize this through two core contributions: first, we introduce Compass-Data-22k, a novel 22k-trajectory http://dataset.Its Reinforcement Fine-Tuning (RFT) subset provides a panoramic view of the decision landscape by annotating all feasible actions with A* geodesic distances. Second, we design a novel gap-aware hybrid reward function that dynamically adapts its feedback to decision certainty, shifting between decisive signals for optimal actions and nuanced scores to encourage exploration. Integrated into an SFT-then-RFT recipe, our CompassNav agent is trained not to memorize static routes, but to develop an internal ``compass'' that constantly intuits the direction to the goal by evaluating the relative quality of all possible moves. This approach enables our 7B agent to set a new state-of-the-art on Goal navigation benchmarks, outperforming even larger proprietary models, and achieve robust real-world goal navigation on a physical robot.",
        "tags": [
            "Robotics",
            "VLM"
        ]
    },
    {
        "id": "132",
        "title": "ReMix: Towards a Unified View of Consistent Character Generation and Editing",
        "author": [
            "Benjia Zhou",
            "Bin Fu",
            "Pei Cheng",
            "Yanru Wang",
            "Jiayuan Fan",
            "Tao Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10156",
        "abstract": "Recent advances in large-scale text-to-image diffusion models (e.g., FLUX.1) have greatly improved visual fidelity in consistent character generation and editing. However, existing methods rarely unify these tasks within a single framework. Generation-based approaches struggle with fine-grained identity consistency across instances, while editing-based methods often lose spatial controllability and instruction alignment. To bridge this gap, we propose ReMix, a unified framework for character-consistent generation and editing. It constitutes two core components: the ReMix Module and IP-ControlNet. The ReMix Module leverages the multimodal reasoning ability of MLLMs to edit semantic features of input images and adapt instruction embeddings to the native DiT backbone without fine-tuning. While this ensures coherent semantic layouts, pixel-level consistency and pose controllability remain challenging. To address this, IP-ControlNet extends ControlNet to decouple semantic and layout cues from reference images and introduces an {\\epsilon}-equivariant latent space that jointly denoises the reference and target images within a shared noise space. Inspired by convergent evolution and quantum decoherence,i.e., where environmental noise drives state convergence, this design promotes feature alignment in the hidden space, enabling consistent object generation while preserving identity. ReMix supports a wide range of tasks, including personalized generation, image editing, style transfer, and multi-condition synthesis. Extensive experiments validate its effectiveness and efficiency as a unified framework for character-consistent image generation and editing.",
        "tags": [
            "ControlNet",
            "DiT",
            "Diffusion",
            "FLUX",
            "Image Editing",
            "Style Transfer",
            "Text-to-Image"
        ]
    },
    {
        "id": "133",
        "title": "BILLY: Steering Large Language Models via Merging Persona Vectors for Creative Generation",
        "author": [
            "Tsung-Min Pai",
            "Jui-I Wang",
            "Li-Chun Lu",
            "Shao-Hua Sun",
            "Hung-Yi Lee",
            "Kai-Wei Chang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10157",
        "abstract": "Multi-LLM systems enhance the creativity of large language models by simulating human collective intelligence but suffer from significant drawbacks, such as high computational costs and inference latency. To address these limitations, we propose BILLY (BlendIng persona vectors for Large Language model creativitY), a training-free framework that captures the benefits of multi-LLM collaboration, i.e. inducing diverse perspectives and specialized expertise, within a single model. BILLY operates by extracting and blending multiple distinct persona vectors directly in the model's activation space. We steer the model's generation process with this merged vector while inference, enabling multi-perspective output without explicit multi-LLM communication. Our experiments across creativity-oriented benchmarks demonstrate that BILLY surpasses single model prompting and traditional multi-LLM approaches, while substantially reducing inference time and computational costs. Our analyses further reveal that distinct persona vectors can be blended to achieve both effective control over complementary aspects of generation and greater interpretability.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "134",
        "title": "Multi-Scale Diffusion Transformer for Jointly Simulating User Mobility and Mobile Traffic Pattern",
        "author": [
            "Ziyi Liu",
            "Qingyue Long",
            "Zhiwen Xue",
            "Huandong Wang",
            "Yong Li"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10158",
        "abstract": "User mobility trajectory and mobile traffic data are essential for a wide spectrum of applications including urban planning, network optimization, and emergency management. However, large-scale and fine-grained mobility data remains difficult to obtain due to privacy concerns and collection costs, making it essential to simulate realistic mobility and traffic patterns. User trajectories and mobile traffic are fundamentally coupled, reflecting both physical mobility and cyber behavior in urban environments. Despite this strong interdependence, existing studies often model them separately, limiting the ability to capture cross-modal dynamics. Therefore, a unified framework is crucial. In this paper, we propose MSTDiff, a Multi-Scale Diffusion Transformer for joint simulation of mobile traffic and user trajectories. First, MSTDiff applies discrete wavelet transforms for multi-resolution traffic decomposition. Second, it uses a hybrid denoising network to process continuous traffic volumes and discrete location sequences. A transition mechanism based on urban knowledge graph embedding similarity is designed to guide semantically informed trajectory generation. Finally, a multi-scale Transformer with cross-attention captures dependencies between trajectories and traffic. Experiments show that MSTDiff surpasses state-of-the-art baselines in traffic and trajectory generation tasks, reducing Jensen-Shannon divergence (JSD) across key statistical metrics by up to 17.38% for traffic generation, and by an average of 39.53% for trajectory generation. The source code is available at: https://github.com/tsinghua-fib-lab/MSTDiff .",
        "tags": [
            "DiT",
            "Diffusion",
            "Transformer"
        ]
    },
    {
        "id": "135",
        "title": "SaFiRe: Saccade-Fixation Reiteration with Mamba for Referring Image Segmentation",
        "author": [
            "Zhenjie Mao",
            "Yuhuan Yang",
            "Chaofan Ma",
            "Dongsheng Jiang",
            "Jiangchao Yao",
            "Ya Zhang",
            "Yanfeng Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10160",
        "abstract": "Referring Image Segmentation (RIS) aims to segment the target object in an image given a natural language expression. While recent methods leverage pre-trained vision backbones and more training corpus to achieve impressive results, they predominantly focus on simple expressions--short, clear noun phrases like \"red car\" or \"left girl\". This simplification often reduces RIS to a key word/concept matching problem, limiting the model's ability to handle referential ambiguity in expressions. In this work, we identify two challenging real-world scenarios: object-distracting expressions, which involve multiple entities with contextual cues, and category-implicit expressions, where the object class is not explicitly stated. To address the challenges, we propose a novel framework, SaFiRe, which mimics the human two-phase cognitive process--first forming a global understanding, then refining it through detail-oriented inspection. This is naturally supported by Mamba's scan-then-update property, which aligns with our phased design and enables efficient multi-cycle refinement with linear complexity. We further introduce aRefCOCO, a new benchmark designed to evaluate RIS models under ambiguous referring expressions. Extensive experiments on both standard and proposed datasets demonstrate the superiority of SaFiRe over state-of-the-art baselines.",
        "tags": [
            "Mamba",
            "Segmentation"
        ]
    },
    {
        "id": "136",
        "title": "Large Language Model Sourcing: A Survey",
        "author": [
            "Liang Pang",
            "Kangxi Wu",
            "Sunhao Dai",
            "Zihao Wei",
            "Zenghao Duan",
            "Jia Gu",
            "Xiang Li",
            "Zhiyi Yin",
            "Jun Xu",
            "Huawei Shen",
            "Xueqi Cheng"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10161",
        "abstract": "The rapid advancement of large language models (LLMs) has revolutionized artificial intelligence, shifting from supporting objective tasks (e.g., recognition) to empowering subjective decision-making (e.g., planning, decision). This marks the dawn of general and powerful AI, with applications spanning a wide range of fields, including programming, education, healthcare, finance, and law. However, their deployment introduces multifaceted risks. Due to the black-box nature of LLMs and the human-like quality of their generated content, issues such as hallucinations, bias, unfairness, and copyright infringement become particularly significant. In this context, sourcing information from multiple perspectives is essential.\nThis survey presents a systematic investigation into provenance tracking for content generated by LLMs, organized around four interrelated dimensions that together capture both model- and data-centric perspectives. From the model perspective, Model Sourcing treats the model as a whole, aiming to distinguish content generated by specific LLMs from content authored by humans. Model Structure Sourcing delves into the internal generative mechanisms, analyzing architectural components that shape the outputs of model. From the data perspective, Training Data Sourcing focuses on internal attribution, tracing the origins of generated content back to the training data of model. In contrast, External Data Sourcing emphasizes external validation, identifying external information used to support or influence the responses of model. Moreover, we also propose a dual-paradigm taxonomy that classifies existing sourcing methods into prior-based (proactive traceability embedding) and posterior-based (retrospective inference) approaches. Traceability across these dimensions enhances the transparency, accountability, and trustworthiness of LLMs deployment in real-world applications.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "137",
        "title": "Concise Reasoning in the Lens of Lagrangian Optimization",
        "author": [
            "Chengqian Gao",
            "Haonan Li",
            "Taylor W. Killian",
            "Jianshu She",
            "Renxi Wang",
            "Liqun Ma",
            "Zhoujun Cheng",
            "Shibo Hao",
            "Zhiqiang Xu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10168",
        "abstract": "Concise reasoning in large language models seeks to generate only essential intermediate steps needed to arrive at a final answer, thereby alleviating issues of overthinking. Most proposed approaches hinge on carefully hand-crafted heuristics, struggling to balance concision with performance, often failing to adapt across domains and model scales. In this work, we address these challenges by introducing a principled and pragmatic strategy, performance-aware length updating (PALU). As a principled algorithm, PALU formulates concise reasoning as a constrained optimization problem, minimizing response length subject to a performance constraint, and then applies Lagrangian optimization to convert it into a tractable unconstrained problem. As a pragmatic solution, PALU streamlines complicated update rules through three approximations: (i) estimating performance with off-policy rollouts, (ii) truncating the Lagrange multiplier to two extremes, and (iii) replacing gradient-based updates with quantile-driven length adjustments. PALU reduces output length by 65% while improving accuracy by 15% when applied to DeepSeek-Distill-Qwen-1.5B, averaged over five benchmarks, outperforming a range of alternative methods. Furthermore, PALU is demonstrated to adapt across both domain (logic, STEM and math) and model scale (1.5B, 7B, 14B) entrenching the algorithm as a practical and effective concise reasoning approach.",
        "tags": [
            "DeepSeek",
            "LLM",
            "Qwen"
        ]
    },
    {
        "id": "138",
        "title": "Peransformer: Improving Low-informed Expressive Performance Rendering with Score-aware Discriminator",
        "author": [
            "Xian He",
            "Wei Zeng",
            "Ye Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10175",
        "abstract": "Highly-informed Expressive Performance Rendering (EPR) systems transform music scores with rich musical annotations into human-like expressive performance MIDI files. While these systems have achieved promising results, the availability of detailed music scores is limited compared to MIDI files and are less flexible to work with using a digital audio workstation (DAW). Recent advancements in low-informed EPR systems offer a more accessible alternative by directly utilizing score-derived MIDI as input, but these systems often exhibit suboptimal performance. Meanwhile, existing works are evaluated with diverse automatic metrics and data formats, hindering direct objective comparisons between EPR systems. In this study, we introduce Peransformer, a transformer-based low-informed EPR system designed to bridge the gap between low-informed and highly-informed EPR systems. Our approach incorporates a score-aware discriminator that leverages the underlying score-derived MIDI files and is trained on a score-to-performance paired, note-to-note aligned MIDI dataset. Experimental results demonstrate that Peransformer achieves state-of-the-art performance among low-informed systems, as validated by subjective evaluations. Furthermore, we extend existing automatic evaluation metrics for EPR systems and introduce generalized EPR metrics (GEM), enabling more direct, accurate, and reliable comparisons across EPR systems.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "139",
        "title": "The Mechanical Yes-Man: Emancipatory AI Pedagogy in Higher Education",
        "author": [
            "Linda Rocco"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10176",
        "abstract": "The proliferation of Large Language Models in higher education presents a fundamental challenge to traditional pedagogical frameworks. Drawing on Jacques RanciÃ¨re's theory of intellectual emancipation, this paper examines how generative AI risks becoming a \"mechanical yes-man\" that reinforces passivity rather than fostering intellectual autonomy. Generative AI's statistical logic and lack of causal reasoning, combined with frictionless information access, threatens to hollow out cognitive processes essential for genuine learning. This creates a critical paradox: while generative AI systems are trained for complex reasoning, students increasingly use them to bypass the intellectual work that builds such capabilities. The paper critiques both techno-optimistic and restrictive approaches to generative AI in education, proposing instead an emancipatory pedagogy grounded in verification, mastery, and co-inquiry. This framework positions generative AI as material for intellectual work rather than a substitute for it, emphasising the cultivation of metacognitive awareness and critical interrogation of AI outputs. It requires educators to engage directly with these tools to guide students toward critical AI literacy, transforming pedagogical authority from explication to critical interloping that models intellectual courage and collaborative inquiry.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "140",
        "title": "LLMs are All You Need? Improving Fuzz Testing for MOJO with Large Language Models",
        "author": [
            "Linghan Huang",
            "Peizhou Zhao",
            "Huaming Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10179",
        "abstract": "The rapid development of large language models (LLMs) has revolutionized software testing, particularly fuzz testing, by automating the generation of diverse and effective test inputs. This advancement holds great promise for improving software reliability. Meanwhile, the introduction of MOJO, a high-performance AI programming language blending Python's usability with the efficiency of C and C++, presents new opportunities to enhance AI model scalability and programmability. However, as a new language, MOJO lacks comprehensive testing frameworks and a sufficient corpus for LLM-based testing, which exacerbates model hallucination. In this case, LLMs will generate syntactically valid but semantically incorrect code, significantly reducing the effectiveness of fuzz testing. To address this challenge, we propose MOJOFuzzer, the first adaptive LLM-based fuzzing framework designed for zero-shot learning environments of emerging programming languages. MOJOFuzzer integrates a mutil-phase framework that systematically eliminates low-quality generated inputs before execution, significantly improving test case validity. Furthermore, MOJOFuzzer dynamically adapts LLM prompts based on runtime feedback for test case mutation, enabling an iterative learning process that continuously enhances fuzzing efficiency and bug detection performance. Our experimental results demonstrate that MOJOFuzzer significantly enhances test validity, API coverage, and bug detection performance, outperforming traditional fuzz testing and state-of-the-art LLM-based fuzzing approaches. Using MOJOFuzzer, we have conducted a first large-scale fuzz testing evaluation of MOJO, uncorvering 13 previous unknown bugs. This study not only advances the field of LLM-driven software testing but also establishes a foundational methodology for leveraging LLMs in the testing of emerging programming languages.",
        "tags": [
            "Detection",
            "LLM"
        ]
    },
    {
        "id": "141",
        "title": "TCMA: Text-Conditioned Multi-granularity Alignment for Drone Cross-Modal Text-Video Retrieval",
        "author": [
            "Zixu Zhao",
            "Yang Zhan"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10180",
        "abstract": "Unmanned aerial vehicles (UAVs) have become powerful platforms for real-time, high-resolution data collection, producing massive volumes of aerial videos. Efficient retrieval of relevant content from these videos is crucial for applications in urban management, emergency response, security, and disaster relief. While text-video retrieval has advanced in natural video domains, the UAV domain remains underexplored due to limitations in existing datasets, such as coarse and redundant captions. Thus, in this work, we construct the Drone Video-Text Match Dataset (DVTMD), which contains 2,864 videos and 14,320 fine-grained, semantically diverse captions. The annotations capture multiple complementary aspects, including human actions, objects, background settings, environmental conditions, and visual style, thereby enhancing text-video correspondence and reducing redundancy. Building on this dataset, we propose the Text-Conditioned Multi-granularity Alignment (TCMA) framework, which integrates global video-sentence alignment, sentence-guided frame aggregation, and word-guided patch alignment. To further refine local alignment, we design a Word and Patch Selection module that filters irrelevant content, as well as a Text-Adaptive Dynamic Temperature Mechanism that adapts attention sharpness to text type. Extensive experiments on DVTMD and CapERA establish the first complete benchmark for drone text-video retrieval. Our TCMA achieves state-of-the-art performance, including 45.5% R@1 in text-to-video and 42.8% R@1 in video-to-text retrieval, demonstrating the effectiveness of our dataset and method. The code and dataset will be released.",
        "tags": [
            "Text-to-Video"
        ]
    },
    {
        "id": "142",
        "title": "Dejavu: Post-Deployment Learning for Embodied Agents via Experience Feedback",
        "author": [
            "Shaokai Wu",
            "Yanbiao Ji",
            "Qiuchang Li",
            "Zhiyi Zhang",
            "Qichen He",
            "Wenyuan Xie",
            "Guodong Zhang",
            "Bayram Bayramli",
            "Yue Ding",
            "Hongtao Lu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10181",
        "abstract": "Embodied agents face a fundamental limitation: once deployed in real-world environments to perform specific tasks, they are unable to acquire new useful knowledge to enhance task performance. In this paper, we propose a general post-deployment learning framework called Dejavu, which employs an Experience Feedback Network (EFN) and augments the frozen Vision-Language-Action (VLA) policy with retrieved execution memories. EFN automatically identifies contextually successful prior action experiences and conditions action prediction on this retrieved guidance. We adopt reinforcement learning with semantic similarity rewards on EFN to ensure that the predicted actions align with past successful behaviors under current observations. During deployment, EFN continually enriches its memory with new trajectories, enabling the agent to exhibit \"learning from experience\" despite fixed weights. Experiments across diverse embodied tasks show that EFN significantly improves adaptability, robustness, and success rates over frozen baselines. These results highlight a promising path toward embodied agents that continually refine their behavior after deployment.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "143",
        "title": "A Survey of Inductive Reasoning for Large Language Models",
        "author": [
            "Kedi Chen",
            "Dezhao Ruan",
            "Yuhao Dan",
            "Yaoting Wang",
            "Siyu Yan",
            "Xuecheng Wu",
            "Yinqi Zhang",
            "Qin Chen",
            "Jie Zhou",
            "Liang He",
            "Biqing Qi",
            "Linyang Li",
            "Qipeng Guo",
            "Xiaoming Shi",
            "Wei Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10182",
        "abstract": "Reasoning is an important task for large language models (LLMs). Among all the reasoning paradigms, inductive reasoning is one of the fundamental types, which is characterized by its particular-to-general thinking process and the non-uniqueness of its answers. The inductive mode is crucial for knowledge generalization and aligns better with human cognition, so it is a fundamental mode of learning, hence attracting increasing interest. Despite the importance of inductive reasoning, there is no systematic summary of it. Therefore, this paper presents the first comprehensive survey of inductive reasoning for LLMs. First, methods for improving inductive reasoning are categorized into three main areas: post-training, test-time scaling, and data augmentation. Then, current benchmarks of inductive reasoning are summarized, and a unified sandbox-based evaluation approach with the observation coverage metric is derived. Finally, we offer some analyses regarding the source of inductive ability and how simple model architectures and data help with inductive tasks, providing a solid foundation for future research.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "144",
        "title": "INR-Bench: A Unified Benchmark for Implicit Neural Representations in Multi-Domain Regression and Reconstruction",
        "author": [
            "Linfei Li",
            "Fengyi Zhang",
            "Zhong Wang",
            "Lin Zhang",
            "Ying Shen"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10188",
        "abstract": "Implicit Neural Representations (INRs) have gained success in various signal processing tasks due to their advantages of continuity and infinite resolution. However, the factors influencing their effectiveness and limitations remain underexplored. To better understand these factors, we leverage insights from Neural Tangent Kernel (NTK) theory to analyze how model architectures (classic MLP and emerging KAN), positional encoding, and nonlinear primitives affect the response to signals of varying frequencies. Building on this analysis, we introduce INR-Bench, the first comprehensive benchmark specifically designed for multimodal INR tasks. It includes 56 variants of Coordinate-MLP models (featuring 4 types of positional encoding and 14 activation functions) and 22 Coordinate-KAN models with distinct basis functions, evaluated across 9 implicit multimodal tasks. These tasks cover both forward and inverse problems, offering a robust platform to highlight the strengths and limitations of different neural models, thereby establishing a solid foundation for future research. The code and dataset are available at https://github.com/lif314/INR-Bench.",
        "tags": [
            "KAN"
        ]
    },
    {
        "id": "145",
        "title": "SAFER: Risk-Constrained Sample-then-Filter in Large Language Models",
        "author": [
            "Qingni Wang",
            "Yue Fan",
            "Xin Eric Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10193",
        "abstract": "As large language models (LLMs) are increasingly deployed in risk-sensitive applications such as real-world open-ended question answering (QA), ensuring the trustworthiness of their outputs has become critical. Existing selective conformal prediction (SCP) methods provide statistical guarantees by constructing prediction sets with a constrained miscoverage rate for correct answers. However, prior works unrealistically assume that admissible answers for all instances can be obtained via finite sampling, even for open-ended QA scenarios that lack a fixed and finite solution space. To address this, we introduce a two-stage risk control framework comprising abstention-aware sampling and conformalized filtering (SAFER). Firstly, on a held-out calibration set, SAFER calibrates a sampling budget within the maximum sampling cap, using the Clopper-Pearson exact method at a user-desired risk level (i.e., the maximum allowable miscoverage rate of the sampling sets). If the risk level cannot be satisfied within the cap, we abstain; otherwise, the calibrated sampling budget becomes the minimum requirements at test time. Then, we employ calibration instances where correct answers are attainable under the calibrated budget and apply the conformal risk control method to determine a statistically valid uncertainty threshold, which filters unreliable distractors from the candidate set for each test data point. In this stage, SAFER introduces an additional risk level to guide the calculation of the threshold, thereby controlling the risk of correct answers being excluded. Furthermore, we show that SAFER is compatible with various task-specific admission criteria and calibration-test split ratios, highlighting its robustness and high data efficiency.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "146",
        "title": "Don't Just Fine-tune the Agent, Tune the Environment",
        "author": [
            "Siyuan Lu",
            "Zechuan Wang",
            "Hongxuan Zhang",
            "Qintong Wu",
            "Leilei Gan",
            "Chenyi Zhuang",
            "Jinjie Gu",
            "Tao Lin"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10197",
        "abstract": "Large Language Model (LLM) agents show great promise for complex, multi-turn tool-use tasks, but their development is often hampered by the extreme scarcity of high-quality training data. Supervised fine-tuning (SFT) on synthetic data leads to overfitting, whereas standard reinforcement learning (RL) struggles with a critical cold-start problem and training instability. To address these challenges, we introduce $\\textbf{Environment Tuning}$, a novel training paradigm that enables agents to learn complex behaviors directly from problem instances without relying on pre-collected expert trajectories. $\\textbf{Environment Tuning}$ orchestrates this learning process through a structured curriculum, actionable environment augmentation that provides corrective feedback, and fine-grained progress rewards to ensure stable and efficient exploration. Using only 400 problem instances from Berkeley Function-Calling Leaderboard (BFCL) benchmark, our method not only achieves competitive in-distribution performance against strong baselines but also demonstrates superior out-of-distribution generalization, overcoming the performance collapse common to SFT-based approaches. Our work presents a paradigm shift from supervised fine-tuning on static trajectories to dynamic, environment-based exploration, paving the way for training more robust and data-efficient agents.",
        "tags": [
            "LLM",
            "RL"
        ]
    },
    {
        "id": "147",
        "title": "RLFR: Extending Reinforcement Learning for LLMs with Flow Environment",
        "author": [
            "Jinghao Zhang",
            "Naishan Zheng",
            "Ruilin Li",
            "Dongzhou Cheng",
            "Zheming Liang",
            "Feng Zhao",
            "Jiaqi Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10201",
        "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR) has recently emerged as a promising framework for improving reasoning abilities in Large Language Models (LLMs). However, policy optimized with binary verification prone to overlook potential valuable exploration in reasoning trajectory. In view of heavy annotation cost of golden Process Reward Models (PRMs), recent works attempt using auxiliary signals for reward shaping of process tokens, involving entropy and likelihood collected from logit space. In this work, we offer a novel perspective on shaping RLVR with flow rewards derived from latent space, and propose RLFR, where the flow fields of model latents are constructed from either off-policy high-quality data and on-policy rejection sampling data, and the velocity deviations of policy latents within it are quantified to serve as a reward signal. RLFR first demonstrates that a well-established flow field can be a sound environment for reward signal collection, highlighting the expressive latent space is much underexplored. Moreover, RLFR is able to compress any off-policy expert data as reference for constituting reward signals, and we show that the efficient context dependence compressed within the hidden states are utilized, rather than individual token-level denotation for context comprehending. Experiments on both language and multimodal reasoning benchmarks demonstrate the reliability of flow rewards, and suggesting a promising paradigm for reward shaping with auxiliary signals.",
        "tags": [
            "LLM",
            "RL"
        ]
    },
    {
        "id": "148",
        "title": "Performance Index Shaping for Closed-loop Optimal Control",
        "author": [
            "Ayush Rai",
            "Shaoshuai Mou",
            "Brian D. O. Anderson"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10202",
        "abstract": "The design of the performance index, also referred to as cost or reward shaping, is central to both optimal control and reinforcement learning, as it directly determines the behaviors, trade-offs, and objectives that the resulting control laws seek to achieve. A commonly used approach for this inference task in recent years is differentiable trajectory optimization, which allows gradients to be computed with respect to cost parameters by differentiating through an optimal control solver. However, this method often requires repeated solving of the underlying optimal control problem at every iteration, making the method computationally expensive. In this work, assuming known dynamics, we propose a novel framework that analytically links the performance index to the resulting closed-loop optimal control law, thereby transforming a typically bi-level inverse problem into a tractable single-level formulation. Our approach is motivated by the question: given a closed-loop control law that solves an infinite-horizon optimal control problem, how does this law change when the performance index is modified with additional terms? This formulation yields closed-form characterizations for broad classes of systems and performance indices, which not only facilitate interpretation and stability analysis, but also provide insight into the robust stability and input-to-state stable behavior of the resulting nonlinear closed-loop system. Moreover, this analytical perspective enables the generalization of our approach to diverse design objectives, yielding a unifying framework for performance index shaping. Given specific design objectives, we propose a systematic methodology to guide the shaping of the performance index and thereby design the resulting optimal control law.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "149",
        "title": "PIXEL: Adaptive Steering Via Position-wise Injection with eXact Estimated Levels under Subspace Calibration",
        "author": [
            "Manjiang Yu",
            "Hongji Li",
            "Priyanka Singh",
            "Xue Li",
            "Di Wang",
            "Lijie Hu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10205",
        "abstract": "Reliable behavior control is central to deploying large language models (LLMs) on the web. Activation steering offers a tuning-free route to align attributes (e.g., truthfulness) that ensure trustworthy generation. Prevailing approaches rely on coarse heuristics and lack a principled account of where to steer and how strongly to intervene. To this end, we propose Position-wise Injection with eXact Estimated Levels (PIXEL), a position-wise activation steering framework that, in contrast to prior work, learns a property-aligned subspace from dual views (tail-averaged and end-token) and selects intervention strength via a constrained geometric objective with a closed-form solution, thereby adapting to token-level sensitivity without global hyperparameter tuning. PIXEL further performs sample-level orthogonal residual calibration to refine the global attribute direction and employs a lightweight position-scanning routine to identify receptive injection sites. We additionally provide representation-level guarantees for the minimal-intervention rule, supporting reliable alignment. Across diverse models and evaluation paradigms, PIXEL consistently improves attribute alignment while preserving model general capabilities, offering a practical and principled method for LLMs' controllable generation. Our code is available at https://github.com/V1centNevwake/PIXEL-Adaptive-Steering",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "150",
        "title": "It Takes Two: Learning Interactive Whole-Body Control Between Humanoid Robots",
        "author": [
            "Zuhong Liu",
            "Junhao Ge",
            "Minhao Xiong",
            "Jiahao Gu",
            "Bowei Tang",
            "Wei Jing",
            "Siheng Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10206",
        "abstract": "The true promise of humanoid robotics lies beyond single-agent autonomy: two or more humanoids must engage in physically grounded, socially meaningful whole-body interactions that echo the richness of human social interaction. However, single-humanoid methods suffer from the isolation issue, ignoring inter-agent dynamics and causing misaligned contacts, interpenetrations, and unrealistic motions. To address this, we present Harmanoid , a dual-humanoid motion imitation framework that transfers interacting human motions to two robots while preserving both kinematic fidelity and physical realism. Harmanoid comprises two key components: (i) contact-aware motion retargeting, which restores inter-body coordination by aligning SMPL contacts with robot vertices, and (ii) interaction-driven motion controller, which leverages interaction-specific rewards to enforce coordinated keypoints and physically plausible contacts. By explicitly modeling inter-agent contacts and interaction-aware dynamics, Harmanoid captures the coupled behaviors between humanoids that single-humanoid frameworks inherently overlook. Experiments demonstrate that Harmanoid significantly improves interactive motion imitation, surpassing existing single-humanoid frameworks that largely fail in such scenarios.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "151",
        "title": "Adaptive Dual Reasoner: Large Reasoning Models Can Think Efficiently by Hybrid Reasoning",
        "author": [
            "Yujian Zhang",
            "Keyu Chen",
            "Zhifeng Shen",
            "Ruizhi Qiao",
            "Xing Sun"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10207",
        "abstract": "Although Long Reasoning Models (LRMs) have achieved superior performance on various reasoning scenarios, they often suffer from increased computational costs and inference latency caused by overthinking. To address these limitations, we propose Adaptive Dual Reasoner, which supports two reasoning modes: fast thinking and slow thinking. ADR dynamically alternates between these modes based on the contextual complexity during reasoning. ADR is trained in two stages: (1) A cold-start stage using supervised fine-tuning (SFT) to equip the model with the ability to integrate both fast and slow reasoning modes, in which we construct a hybrid reasoning dataset through a dedicated pipeline to provide large-scale supervision. (2) A reinforcement learning stage for optimizing reasoning effort, where we introduce Entropy-guided Hybrid Policy Optimization EHPO, an RL training framework employing an entropy-guided dynamic rollout strategy for branching at high-entropy units and a difficulty-aware penalty to balance fast and slow reasoning. Across challenging mathematical reasoning benchmarks, ADR achieves an effective balance between reasoning performance and efficiency among state-of-the-art approaches. Specifically, ADR yields a performance gain of up to 6.1%, while reducing the reasoning output length by 49.5% to 59.3%.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "152",
        "title": "Weed Out, Then Harvest: Dual Low-Rank Adaptation is an Effective Noisy Label Detector for Noise-Robust Learning",
        "author": [
            "Bo Yuan",
            "Yulin Chen",
            "Yin Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10208",
        "abstract": "Parameter-efficient fine-tuning (PEFT) large language models (LLMs) have shown impressive performance in various downstream tasks. However, in many real-world scenarios, the collected training data inevitably contains noisy labels. To learn from noisy labels, most solutions select samples with small losses for model training. However, the selected samples, in turn, impact the loss computation in the next iteration. An inaccurate initial selection can create a vicious cycle, leading to suboptimal performance. To break this cycle, we propose Delora, a novel framework that decouples the sample selection from model training. For sample selection, Delora establishes a noisy label detector by introducing clean and noisy LoRA. Benefiting from the memory effect, the clean LoRA is encouraged to memorize clean data, while the noisy LoRA is constrained to memorize mislabeled data, which serves as a learnable threshold for selecting clean and noisy samples. For model training, Delora can use carefully selected samples to fine-tune language models seamlessly. Experimental results on synthetic and real-world noisy datasets demonstrate the effectiveness of Delora in noisy label detection and text classification.",
        "tags": [
            "Detection",
            "LLM",
            "LoRA"
        ]
    },
    {
        "id": "153",
        "title": "Finite element analysis of a nonlinear heat Equation with damping and pumping effects",
        "author": [
            "Rishabh Shukla",
            "Wasim Akram",
            "Manil T. Mohan"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10210",
        "abstract": "We study the following nonlinear heat equation with damping and pumping effects (a reaction-diffusion equation) posed on a bounded simply connected convex domain $\\Omega \\subset \\mathbb{R}^d$, $d \\geq 1$ with Lipschitz boundary $\\partial\\Omega$: $$ \\frac{\\partial u(t)}{\\partial t} - \\nu \\Delta u(t) + \\alpha |u(t)|^{p-2}u(t) - \\sum_{\\ell=1}^M \\beta_{\\ell} |u(t)|^{q_{\\ell}-2}u(t) = f(t), \\quad t>0, $$ subject to homogeneous Dirichlet boundary conditions and the initial condition $u(0)=u_0$, where $2 \\leq p < \\infty$ and $2 \\leq q_{\\ell} < p$ for $1 \\leq \\ell \\leq M$. For $u_0 \\in L^2(\\Omega)$ and $f \\in L^2(0,T;H^{-1}(\\Omega))$, we establish the existence and uniqueness of a weak solution for all dimensions $d \\in \\mathbb{N}$ and damping exponents $2 \\leq p < \\infty$. Furthermore, for $u_0 \\in H^2(\\Omega) \\cap H_0^1(\\Omega)$ and $f \\in H^1(0,T;H^1(\\Omega))$, we obtain regularity results: these hold for every $2 \\leq p < \\infty$ when $1 \\leq d \\leq 4$, and for $2 \\leq p \\leq \\frac{2d-6}{d-4}$ when $d \\geq 5$. We further conduct finite element analysis using conforming, nonconforming, and discontinuous Galerkin methods, deriving a priori error estimates for both semi- and fully discrete schemes, supported by numerical results. To relax restrictions on $p$ in the semidiscrete analysis, we use appropriate projection/interpolation operators: the Ritz projection in the conforming case ($2 \\le p \\le \\frac{2d}{d-2}$), the Scott-Zhang interpolation for $\\frac{2d}{d-2} < p \\le \\frac{2d-6}{d-4}$, the ClÃ©ment interpolation in the nonconforming setting, and the $L^2$-projection in the DG framework. In the fully discrete case, error estimates hold for the above $p$-range under $u_0 \\in D(A^{3/2})$ and $f \\in H^1(0,T;H^1(\\Omega))$.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "154",
        "title": "UF-RNN: Real-Time Adaptive Motion Generation Using Uncertainty-Driven Foresight Prediction",
        "author": [
            "Hyogo Hiruma",
            "Hiroshi Ito",
            "Tetsuya Ogata"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10217",
        "abstract": "Training robots to operate effectively in environments with uncertain states, such as ambiguous object properties or unpredictable interactions, remains a longstanding challenge in robotics. Imitation learning methods typically rely on successful examples and often neglect failure scenarios where uncertainty is most pronounced. To address this limitation, we propose the Uncertainty-driven Foresight Recurrent Neural Network (UF-RNN), a model that combines standard time-series prediction with an active \"Foresight\" module. This module performs internal simulations of multiple future trajectories and refines the hidden state to minimize predicted variance, enabling the model to selectively explore actions under high uncertainty. We evaluate UF-RNN on a door-opening task in both simulation and a real-robot setting, demonstrating that, despite the absence of explicit failure demonstrations, the model exhibits robust adaptation by leveraging self-induced chaotic dynamics in its latent space. When guided by the Foresight module, these chaotic properties stimulate exploratory behaviors precisely when the environment is ambiguous, yielding improved success rates compared to conventional stochastic RNN baselines. These findings suggest that integrating uncertainty-driven foresight into imitation learning pipelines can significantly enhance a robot's ability to handle unpredictable real-world conditions.",
        "tags": [
            "RNN",
            "Robotics"
        ]
    },
    {
        "id": "155",
        "title": "A3RNN: Bi-directional Fusion of Bottom-up and Top-down Process for Developmental Visual Attention in Robots",
        "author": [
            "Hyogo Hiruma",
            "Hiroshi Ito",
            "Hiroki Mori",
            "Tetsuya Ogata"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10221",
        "abstract": "This study investigates the developmental interaction between top-down (TD) and bottom-up (BU) visual attention in robotic learning. Our goal is to understand how structured, human-like attentional behavior emerges through the mutual adaptation of TD and BU mechanisms over time. To this end, we propose a novel attention model $A^3 RNN$ that integrates predictive TD signals and saliency-based BU cues through a bi-directional attention architecture.\nWe evaluate our model in robotic manipulation tasks using imitation learning. Experimental results show that attention behaviors evolve throughout training, from saliency-driven exploration to prediction-driven direction. Initially, BU attention highlights visually salient regions, which guide TD processes, while as learning progresses, TD attention stabilizes and begins to reshape what is perceived as salient. This trajectory reflects principles from cognitive science and the free-energy framework, suggesting the importance of self-organizing attention through interaction between perception and internal prediction. Although not explicitly optimized for stability, our model exhibits more coherent and interpretable attention patterns than baselines, supporting the idea that developmental mechanisms contribute to robust attention formation.",
        "tags": [
            "RNN"
        ]
    },
    {
        "id": "156",
        "title": "You only need 4 extra tokens: Synergistic Test-time Adaptation for LLMs",
        "author": [
            "Yijie Xu",
            "Huizai Yao",
            "Zhiyu Guo",
            "Weiyu Guo",
            "Pengteng Li",
            "Aiwei Liu",
            "Xuming Hu",
            "Hui Xiong"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10223",
        "abstract": "Large language models (LLMs) are increasingly deployed in specialized domains such as finance, medicine, and agriculture, where they face significant distribution shifts from their training data. Domain-specific fine-tuning can mitigate this challenge but relies on high-quality labeled data that is expensive and slow to collect in expertise-limited settings. We study label-free test-time adaptation for language models and present SyTTA, an inference-time framework that adapts models on-the-fly without additional supervision. SyTTA couples two complementary uncertainty signals that arise under distribution shift: input-side perplexity, indicating mismatch with domain-specific terminology and patterns, and output-side predictive entropy, indicating diffuse and unstable token probabilities during generation. Across diverse model architectures and domain-specific benchmarks, SyTTA delivers consistent gains. Notably, on agricultural question answering, SyTTA improves Rouge-LSum by over 120% on Qwen-2.5-7B with only 4 extra tokens per query. These results show that effective test-time adaptation for language models is achievable without labeled examples, supporting deployment in label-scarce domains. The code will be made available upon acceptance.",
        "tags": [
            "LLM",
            "Qwen"
        ]
    },
    {
        "id": "157",
        "title": "Text2Token: Unsupervised Text Representation Learning with Token Target Prediction",
        "author": [
            "Ruize An",
            "Richong Zhang",
            "Zhijie Nie",
            "Zhanyu Wu",
            "Yanzhao Zhang",
            "Dingkun Long"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10224",
        "abstract": "Unsupervised text representation learning (TRL) is a fundamental task in natural language processing, which is beneficial for improving search and recommendations with the web's unlabeled texts. A recent empirical study finds that the high-quality representation aligns with the key token of the input text, uncovering the potential connection between representation space and vocabulary space. Inspired by the findings, we revisit the generative tasks and develop an unsupervised generative framework for TRL, Text2Token. The framework is based on the token target prediction task, utilizing carefully constructed target token distribution as supervisory signals. To construct the high-quality target token distribution, we analyze the token-alignment properties with advanced embedders and identify two essential categories of key tokens: (1) the meaningful tokens in the text and (2) semantically derived tokens beyond the text. Based on these insights, we propose two methods -- data-driven and model-derived -- to construct synthetic token targets from data or the LLM backbone. Experiments on the MTEB v2 benchmark demonstrate that Text2Token achieves performance competitive with the state-of-the-art embedder with unsupervised contrastive learning, LLM2Vec. Our analysis further shows that vocabulary and representation spaces optimize together and toward the optimum solution during training, providing new ideas and insights for future work.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "158",
        "title": "ISAAC: Intelligent, Scalable, Agile, and Accelerated CPU Verification via LLM-aided FPGA Parallelism",
        "author": [
            "Jialin Sun",
            "Yuchen Hu",
            "Dean You",
            "Yushu Du",
            "Hui Wang",
            "Xinwei Fang",
            "Weiwei Shan",
            "Nan Guan",
            "Zhe Jiang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10225",
        "abstract": "Functional verification is a critical bottleneck in integrated circuit development, with CPU verification being especially time-intensive and labour-consuming. Industrial practice relies on differential testing for CPU verification, yet faces bottlenecks at nearly each stage of the framework pipeline: front-end stimulus generation lacks micro-architectural awareness, yielding low-quality and redundant tests that impede coverage closure and miss corner cases. Meanwhile, back-end simulation infrastructure, even with FPGA acceleration, often stalls on long-running tests and offers limited visibility, delaying feedback and prolonging the debugging cycle. Here, we present ISAAC, a full-stack, Large Language Model (LLM)-aided CPU verification framework with FPGA parallelism, from bug categorisation and stimulus generation to simulation infrastructure. To do so, we presented a multi-agent stimulus engine in ISAAC's front-end, infused with micro-architectural knowledge and historical bug patterns, generating highly targeted tests that rapidly achieve coverage goals and capture elusive corner cases. In ISAAC's back-end, we introduce a lightweight forward-snapshot mechanism and a decoupled co-simulation architecture between the Instruction Set Simulator (ISS) and the Design Under Test (DUT), enabling a single ISS to drive multiple DUTs in parallel. By eliminating long-tail test bottlenecks and exploiting FPGA parallelism, the simulation throughput is significantly improved. As a demonstration, we used ISAAC to verify a mature CPU that has undergone multiple successful tape-outs. Results show up to 17,536x speed-up over software RTL simulation, while detecting several previously unknown bugs, two of which are reported in this paper.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "159",
        "title": "SGM: A Statistical Godel Machine for Risk-Controlled Recursive Self-Modification",
        "author": [
            "Xuening Wu",
            "Shenqin Yin",
            "Yanlan Kang",
            "Xinhang Zhang",
            "Qianya Xu",
            "Zeping Chen",
            "Wenqiang Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10232",
        "abstract": "Recursive self-modification is increasingly central in AutoML, neural architecture search, and adaptive optimization, yet no existing framework ensures that such changes are made safely. Godel machines offer a principled safeguard by requiring formal proofs of improvement before rewriting code; however, such proofs are unattainable in stochastic, high-dimensional settings. We introduce the Statistical Godel Machine (SGM), the first statistical safety layer for recursive edits. SGM replaces proof-based requirements with statistical confidence tests (e-values, Hoeffding bounds), admitting a modification only when superiority is certified at a chosen confidence level, while allocating a global error budget to bound cumulative risk across http://rounds.We also propose Confirm-Triggered Harmonic Spending (CTHS), which indexes spending by confirmation events rather than rounds, concentrating the error budget on promising edits while preserving familywise http://validity.Experiments across supervised learning, reinforcement learning, and black-box optimization validate this role: SGM certifies genuine gains on CIFAR-100, rejects spurious improvement on ImageNet-100, and demonstrates robustness on RL and optimization http://benchmarks.Together, these results position SGM as foundational infrastructure for continual, risk-aware self-modification in learning http://systems.Code is available at: https://github.com/gravitywavelet/sgm-anon.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "160",
        "title": "The Achilles' Heel of LLMs: How Altering a Handful of Neurons Can Cripple Language Abilities",
        "author": [
            "Zixuan Qin",
            "Kunlin Lyu",
            "Qingchen Yu",
            "Yifan Sun",
            "Zhaoxin Fan"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10238",
        "abstract": "Large Language Models (LLMs) have become foundational tools in natural language processing, powering a wide range of applications and research. Many studies have shown that LLMs share significant similarities with the human brain. Recent neuroscience research has found that a small subset of biological neurons in the human brain are crucial for core cognitive functions, which raises a fundamental question: do LLMs also contain a small subset of critical neurons? In this paper, we investigate this question by proposing a Perturbation-based Causal Identification of Critical Neurons method to systematically locate such critical neurons in LLMs. Our findings reveal three key insights: (1) LLMs contain ultra-sparse critical neuron sets. Disrupting these critical neurons can cause a 72B-parameter model with over 1.1 billion neurons to completely collapse, with perplexity increasing by up to 20 orders of magnitude; (2) These critical neurons are not uniformly distributed, but tend to concentrate in the outer layers, particularly within the MLP down\\_proj components; (3) Performance degradation exhibits sharp phase transitions, rather than a gradual decline, when these critical neurons are disrupted. Through comprehensive experiments across diverse model architectures and scales, we provide deeper analysis of these phenomena and their implications for LLM robustness and interpretability. These findings can offer guidance for developing more robust model architectures and improving deployment security in safety-critical applications.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "161",
        "title": "ImCoref-CeS: An Improved Lightweight Pipeline for Coreference Resolution with LLM-based Checker-Splitter Refinement",
        "author": [
            "Kangyang Luo",
            "Yuzhuo Bai",
            "Shuzheng Si",
            "Cheng Gao",
            "Zhitong Wang",
            "Yingli Shen",
            "Wenhao Li",
            "Zhu Liu",
            "Yufeng Han",
            "Jiayi Wu",
            "Cunliang Kong",
            "Maosong Sun"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10241",
        "abstract": "Coreference Resolution (CR) is a critical task in Natural Language Processing (NLP). Current research faces a key dilemma: whether to further explore the potential of supervised neural methods based on small language models, whose detect-then-cluster pipeline still delivers top performance, or embrace the powerful capabilities of Large Language Models (LLMs). However, effectively combining their strengths remains underexplored. To this end, we propose \\textbf{ImCoref-CeS}, a novel framework that integrates an enhanced supervised model with LLM-based reasoning. First, we present an improved CR method (\\textbf{ImCoref}) to push the performance boundaries of the supervised neural method by introducing a lightweight bridging module to enhance long-text encoding capability, devising a biaffine scorer to comprehensively capture positional information, and invoking a hybrid mention regularization to improve training efficiency. Importantly, we employ an LLM acting as a multi-role Checker-Splitter agent to validate candidate mentions (filtering out invalid ones) and coreference results (splitting erroneous clusters) predicted by ImCoref. Extensive experiments demonstrate the effectiveness of ImCoref-CeS, which achieves superior performance compared to existing state-of-the-art (SOTA) methods.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "162",
        "title": "ProGress: Structured Music Generation via Graph Diffusion and Hierarchical Music Analysis",
        "author": [
            "Stephen Ni-Hahn",
            "Chao PÃ©ter Yang",
            "Mingchen Ma",
            "Cynthia Rudin",
            "Simon Mak",
            "Yue Jiang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10249",
        "abstract": "Artificial Intelligence (AI) for music generation is undergoing rapid developments, with recent symbolic models leveraging sophisticated deep learning and diffusion model algorithms. One drawback with existing models is that they lack structural cohesion, particularly on harmonic-melodic structure. Furthermore, such existing models are largely \"black-box\" in nature and are not musically interpretable. This paper addresses these limitations via a novel generative music framework that incorporates concepts of Schenkerian analysis (SchA) in concert with a diffusion modeling framework. This framework, which we call ProGress (Prolongation-enhanced DiGress), adapts state-of-the-art deep models for discrete diffusion (in particular, the DiGress model of Vignac et al., 2023) for interpretable and structured music generation. Concretely, our contributions include 1) novel adaptations of the DiGress model for music generation, 2) a novel SchA-inspired phrase fusion methodology, and 3) a framework allowing users to control various aspects of the generation process to create coherent musical compositions. Results from human experiments suggest superior performance to existing state-of-the-art methods.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "163",
        "title": "Audit-of-Understanding: Posterior-Constrained Inference for Mathematical Reasoning in Language Models",
        "author": [
            "Samir Abdaljalil",
            "Erchin Serpedin",
            "Khalid Qaraqe",
            "Hasan Kurban"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10252",
        "abstract": "Large language models (LLMs) often generate reasoning traces that appear coherent but rest on unsupported assumptions, leading to hallucinated conclusions. Prior work mainly addresses factual hallucinations or relies on post-hoc verification, leaving reasoning-induced hallucinations largely unaddressed. We propose Audit-of-Understanding (AoU), a framework that constrains inference to validated premises through three phases: (1) decomposing a query into candidate assumptions, (2) auditing their support, and (3) conditioning inference only on the validated subset. Formally, AoU is \\emph{posterior-constrained inference}, connecting to selective prediction and rejection learning. Our contributions are threefold: (i) theoretical guarantees under perfect validation, (ii) excess-risk bounds under imperfect audits, and (iii) tractability analysis. Empirically, AoU improves both accuracy and faithfulness on GSM8K, MultiArith, and SVAMP, achieving up to +30% gains on GSM8K, +45% on MultiArith, and consistent +20--28% improvements on SVAMP over Chain-of-Thought, Self-Consistency, and CoT-Decoding. Code is available at https://anonymous.4open.science/r/audit-of-understanding-E28B.",
        "tags": [
            "CoT",
            "LLM"
        ]
    },
    {
        "id": "164",
        "title": "Opacity-Gradient Driven Density Control for Compact and Efficient Few-Shot 3D Gaussian Splatting",
        "author": [
            "Abdelrhman Elrawy",
            "Emad A. Mohammed"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10257",
        "abstract": "3D Gaussian Splatting (3DGS) struggles in few-shot scenarios, where its standard adaptive density control (ADC) can lead to overfitting and bloated reconstructions. While state-of-the-art methods like FSGS improve quality, they often do so by significantly increasing the primitive count. This paper presents a framework that revises the core 3DGS optimization to prioritize efficiency. We replace the standard positional gradient heuristic with a novel densification trigger that uses the opacity gradient as a lightweight proxy for rendering error. We find this aggressive densification is only effective when paired with a more conservative pruning schedule, which prevents destructive optimization cycles. Combined with a standard depth-correlation loss for geometric guidance, our framework demonstrates a fundamental improvement in efficiency. On the 3-view LLFF dataset, our model is over 40% more compact (32k vs. 57k primitives) than FSGS, and on the Mip-NeRF 360 dataset, it achieves a reduction of approximately 70%. This dramatic gain in compactness is achieved with a modest trade-off in reconstruction metrics, establishing a new state-of-the-art on the quality-vs-efficiency Pareto frontier for few-shot view synthesis.",
        "tags": [
            "3D",
            "Gaussian Splatting",
            "NeRF"
        ]
    },
    {
        "id": "165",
        "title": "MetaBreak: Jailbreaking Online LLM Services via Special Token Manipulation",
        "author": [
            "Wentian Zhu",
            "Zhen Xiang",
            "Wei Niu",
            "Le Guan"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10271",
        "abstract": "Unlike regular tokens derived from existing text corpora, special tokens are artificially created to annotate structured conversations during the fine-tuning process of Large Language Models (LLMs). Serving as metadata of training data, these tokens play a crucial role in instructing LLMs to generate coherent and context-aware responses. We demonstrate that special tokens can be exploited to construct four attack primitives, with which malicious users can reliably bypass the internal safety alignment of online LLM services and circumvent state-of-the-art (SOTA) external content moderation systems simultaneously. Moreover, we found that addressing this threat is challenging, as aggressive defense mechanisms-such as input sanitization by removing special tokens entirely, as suggested in academia-are less effective than anticipated. This is because such defense can be evaded when the special tokens are replaced by regular ones with high semantic similarity within the tokenizer's embedding space. We systemically evaluated our method, named MetaBreak, on both lab environment and commercial LLM platforms. Our approach achieves jailbreak rates comparable to SOTA prompt-engineering-based solutions when no content moderation is deployed. However, when there is content moderation, MetaBreak outperforms SOTA solutions PAP and GPTFuzzer by 11.6% and 34.8%, respectively. Finally, since MetaBreak employs a fundamentally different strategy from prompt engineering, the two approaches can work synergistically. Notably, empowering MetaBreak on PAP and GPTFuzzer boosts jailbreak rates by 24.3% and 20.2%, respectively.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "166",
        "title": "Integration of the TIAGo Robot into Isaac Sim with Mecanum Drive Modeling and Learned S-Curve Velocity Profiles",
        "author": [
            "Vincent Schoenbach",
            "Marvin Wiedemann",
            "Raphael Memmesheimer",
            "Malte Mosbach",
            "Sven Behnke"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10273",
        "abstract": "Efficient physics simulation has significantly accelerated research progress in robotics applications such as grasping and assembly. The advent of GPU-accelerated simulation frameworks like Isaac Sim has particularly empowered learning-based methods, enabling them to tackle increasingly complex tasks. The PAL Robotics TIAGo++ Omni is a versatile mobile manipulator equipped with a mecanum-wheeled base, allowing omnidirectional movement and a wide range of task capabilities. However, until now, no model of the robot has been available in Isaac Sim. In this paper, we introduce such a model, calibrated to approximate the behavior of the real robot, with a focus on its omnidirectional drive dynamics. We present two control models for the omnidirectional drive: a physically accurate model that replicates real-world wheel dynamics and a lightweight velocity-based model optimized for learning-based applications. With these models, we introduce a learning-based calibration approach to approximate the real robot's S-shaped velocity profile using minimal trajectory data recordings. This simulation should allow researchers to experiment with the robot and perform efficient learning-based control in diverse environments. We provide the integration publicly at https://github.com/AIS-Bonn/tiago_isaac.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "167",
        "title": "X-VLA: Soft-Prompted Transformer as Scalable Cross-Embodiment Vision-Language-Action Model",
        "author": [
            "Jinliang Zheng",
            "Jianxiong Li",
            "Zhihao Wang",
            "Dongxiu Liu",
            "Xirui Kang",
            "Yuchun Feng",
            "Yinan Zheng",
            "Jiayin Zou",
            "Yilun Chen",
            "Jia Zeng",
            "Ya-Qin Zhang",
            "Jiangmiao Pang",
            "Jingjing Liu",
            "Tai Wang",
            "Xianyuan Zhan"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10274",
        "abstract": "Successful generalist Vision-Language-Action (VLA) models rely on effective training across diverse robotic platforms with large-scale, cross-embodiment, heterogeneous datasets. To facilitate and leverage the heterogeneity in rich, diverse robotic data sources, we propose a novel Soft Prompt approach with minimally added parameters, by infusing prompt learning concepts into cross-embodiment robot learning and introducing separate sets of learnable embeddings for each distinct data source. These embeddings serve as embodiment-specific prompts, which in unity empower VLA models with effective exploitation of varying cross-embodiment features. Our new X-VLA, a neat flow-matching-based VLA architecture, relies exclusively on soft-prompted standard Transformer encoders, enjoying both scalability and simplicity. Evaluated across 6 simulations as well as 3 real-world robots, our 0.9B instantiation-X-VLA-0.9B simultaneously achieves SOTA performance over a sweep of benchmarks, demonstrating superior results on a wide axes of capabilities, from flexible dexterity to quick adaptation across embodiments, environments, and tasks. Website: https://thu-air-dream.github.io/X-VLA/",
        "tags": [
            "Flow Matching",
            "Robotics",
            "Transformer"
        ]
    },
    {
        "id": "168",
        "title": "Lost in the Middle: An Emergent Property from Information Retrieval Demands in LLMs",
        "author": [
            "Nikolaus Salvatore",
            "Hao Wang",
            "Qiong Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10276",
        "abstract": "The performance of Large Language Models (LLMs) often degrades when crucial information is in the middle of a long context, a \"lost-in-the-middle\" phenomenon that mirrors the primacy and recency effects in human memory. We propose that this behavior is not simply a flaw indicative of information loss but an adaptation to different information retrieval demands during pre-training: some tasks require uniform recall across the entire input (a long-term memory demand), while others prioritize the most recent information (a short-term memory demand). Consistent with this view, we show that this U-shaped performance curve emerges when LLMs (GPT-2 and Llama variants) are trained from scratch on two simple human memory paradigms simulating long-term and short-term memory demands. Our analysis reveals that while the recency effect directly aligns with short-term memory demand in the training data, the primacy effect is induced by the uniform long-term memory demand and is additionally influenced by the model's autoregressive properties and the formation of attention sinks. Our main findings from simple human memory paradigms also generalize to a sequence completion task, which more closely resembles the next-token prediction process in LLM pre-training. Together, our findings reveal how information retrieval demands, model architecture, and structural attention dynamics during model training can jointly produce positional bias observed in LLMs.",
        "tags": [
            "GPT",
            "LLM",
            "LLaMA"
        ]
    },
    {
        "id": "169",
        "title": "On the Entity-Level Alignment in Crosslingual Consistency",
        "author": [
            "Yihong Liu",
            "Mingyang Wang",
            "FranÃ§ois Yvon",
            "Hinrich SchÃ¼tze"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10280",
        "abstract": "Multilingual large language models (LLMs) are expected to recall factual knowledge consistently across languages. However, the factors that give rise to such crosslingual consistency -- and its frequent failure -- remain poorly understood. In this work, we hypothesize that these inconsistencies may arise from failures in entity alignment, the process of mapping subject and object entities into a shared conceptual space across languages. To test this, we assess alignment through entity-level (subject and object) translation tasks, and find that consistency is strongly correlated with alignment across all studied models, with misalignment of subjects or objects frequently resulting in inconsistencies. Building on this insight, we propose SubSub and SubInj, two effective methods that integrate English translations of subjects into prompts across languages, leading to substantial gains in both factual recall accuracy and consistency. Finally, our mechanistic analysis reveals that these interventions reinforce the entity representation alignment in the conceptual space through model's internal pivot-language processing, offering effective and practical strategies for improving multilingual factual prediction.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "170",
        "title": "ArtPerception: ASCII Art-based Jailbreak on LLMs with Recognition Pre-test",
        "author": [
            "Guan-Yan Yang",
            "Tzu-Yu Cheng",
            "Ya-Wen Teng",
            "Farn Wanga",
            "Kuo-Hui Yeh"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10281",
        "abstract": "The integration of Large Language Models (LLMs) into computer applications has introduced transformative capabilities but also significant security challenges. Existing safety alignments, which primarily focus on semantic interpretation, leave LLMs vulnerable to attacks that use non-standard data representations. This paper introduces ArtPerception, a novel black-box jailbreak framework that strategically leverages ASCII art to bypass the security measures of state-of-the-art (SOTA) LLMs. Unlike prior methods that rely on iterative, brute-force attacks, ArtPerception introduces a systematic, two-phase methodology. Phase 1 conducts a one-time, model-specific pre-test to empirically determine the optimal parameters for ASCII art recognition. Phase 2 leverages these insights to launch a highly efficient, one-shot malicious jailbreak attack. We propose a Modified Levenshtein Distance (MLD) metric for a more nuanced evaluation of an LLM's recognition capability. Through comprehensive experiments on four SOTA open-source LLMs, we demonstrate superior jailbreak performance. We further validate our framework's real-world relevance by showing its successful transferability to leading commercial models, including GPT-4o, Claude Sonnet 3.7, and DeepSeek-V3, and by conducting a rigorous effectiveness analysis against potential defenses such as LLaMA Guard and Azure's content filters. Our findings underscore that true LLM security requires defending against a multi-modal space of interpretations, even within text-only inputs, and highlight the effectiveness of strategic, reconnaissance-based attacks. Content Warning: This paper includes potentially harmful and offensive model outputs.",
        "tags": [
            "DeepSeek",
            "GPT",
            "LLM",
            "LLaMA"
        ]
    },
    {
        "id": "171",
        "title": "SAM2LoRA: Composite Loss-Guided, Parameter-Efficient Finetuning of SAM2 for Retinal Fundus Segmentation",
        "author": [
            "Sayan Mandal",
            "Divyadarshini Karthikeyan",
            "Manas Paldhe"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10288",
        "abstract": "We propose SAM2LoRA, a parameter-efficient fine-tuning strategy that adapts the Segment Anything Model 2 (SAM2) for fundus image segmentation. SAM2 employs a masked autoencoder-pretrained Hierarchical Vision Transformer for multi-scale feature decoding, enabling rapid inference in low-resource settings; however, fine-tuning remains challenging. To address this, SAM2LoRA integrates a low-rank adapter into both the image encoder and mask decoder, requiring fewer than 5\\% of the original trainable parameters. Our analysis indicates that for cross-dataset fundus segmentation tasks, a composite loss function combining segmentationBCE, SoftDice, and FocalTversky losses is essential for optimal network tuning. Evaluated on 11 challenging fundus segmentation datasets, SAM2LoRA demonstrates high performance in both blood vessel and optic disc segmentation under cross-dataset training conditions. It achieves Dice scores of up to 0.86 and 0.93 for blood vessel and optic disc segmentation, respectively, and AUC values of up to 0.98 and 0.99, achieving state-of-the-art performance while substantially reducing training overhead.",
        "tags": [
            "SAM",
            "Segmentation",
            "Transformer",
            "ViT"
        ]
    },
    {
        "id": "172",
        "title": "Grounded AI for Code Review: Resource-Efficient Large-Model Serving in Enterprise Pipelines",
        "author": [
            "Sayan Mandal",
            "Hua Jiang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10290",
        "abstract": "Automated code review adoption lags in compliance-heavy settings, where static analyzers produce high-volume, low-rationale outputs, and naive LLM use risks hallucination and incurring cost overhead. We present a production system for grounded, PR-native review that pairs static-analysis findings with AST-guided context extraction and a single-GPU, on-demand serving stack (quantized open-weight model, multi-tier caching) to deliver concise explanations and remediation guidance. Evaluated on safety-oriented C/C++ standards, the approach achieves sub-minute median first-feedback (offline p50 build+LLM 59.8s) while maintaining competitive violation reduction and lower violation rates versus larger proprietary models. The architecture is decoupled: teams can adopt the grounding/prompting layer or the serving layer independently. A small internal survey (n=8) provides directional signals of reduced triage effort and moderate perceived grounding, with participants reporting fewer human review iterations. We outline operational lessons and limitations, emphasizing reproducibility, auditability, and pathways to broader standards and assisted patching.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "173",
        "title": "From Programs to Poses: Factored Real-World Scene Generation via Learned Program Libraries",
        "author": [
            "Joy Hsu",
            "Emily Jin",
            "Jiajun Wu",
            "Niloy J. Mitra"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10292",
        "abstract": "Real-world scenes, such as those in ScanNet, are difficult to capture, with highly limited data available. Generating realistic scenes with varied object poses remains an open and challenging task. In this work, we propose FactoredScenes, a framework that synthesizes realistic 3D scenes by leveraging the underlying structure of rooms while learning the variation of object poses from lived-in scenes. We introduce a factored representation that decomposes scenes into hierarchically organized concepts of room programs and object poses. To encode structure, FactoredScenes learns a library of functions capturing reusable layout patterns from which scenes are drawn, then uses large language models to generate high-level programs, regularized by the learned library. To represent scene variations, FactoredScenes learns a program-conditioned model to hierarchically predict object poses, and retrieves and places 3D objects in a scene. We show that FactoredScenes generates realistic, real-world rooms that are difficult to distinguish from real ScanNet scenes.",
        "tags": [
            "3D",
            "LLM"
        ]
    },
    {
        "id": "174",
        "title": "SP-MoE: Speculative Decoding and Prefetching for Accelerating MoE-based Model Inference",
        "author": [
            "Liangkun Chen",
            "Zijian Wen",
            "Tian Wu",
            "Xiaoxi Zhang",
            "Chuan Wu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10302",
        "abstract": "The Mixture-of-Experts (MoE) architecture has been widely adopted in large language models (LLMs) to reduce computation cost through model sparsity. Employing speculative decoding (SD) can further accelerate MoE inference by drafting multiple tokens per step and verifying them in parallel. However, combining MoE with SD inflates GPU memory and aggravates CPU-GPU bandwidth contention during multi-token verification. Existing MoE offloading systems are SD-agnostic and do not address this bottleneck. We present SP-MoE, the first SD-aware expert-offloading and compute-communication pipelining framework. SP-MoE introduces: (1) speculative expert prefetching that exploits structural correspondence between the draft and target models to prefetch likely experts ahead of verification; (2) a cutoff-layer policy that bounds per-layer prefetch depth based on empirical profiles and an analytical latency model, guaranteeing just-in-time availability without overfetch; and (3) a pipelined runtime with asynchronous prefetch threads and batched I/O to hide loading latency. Extensive experiments demonstrate that SP-MoE achieves a 1.07-3.5 times TPOT speedup over state-of-the-art methods across diverse datasets, environments, and MoE-based models.",
        "tags": [
            "LLM",
            "MoE"
        ]
    },
    {
        "id": "175",
        "title": "Sample-Efficient Online Learning in LM Agents via Hindsight Trajectory Rewriting",
        "author": [
            "Michael Y. Hu",
            "Benjamin Van Durme",
            "Jacob Andreas",
            "Harsh Jhamtani"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10304",
        "abstract": "Language model (LM) agents deployed in novel environments often exhibit poor sample efficiency when learning from sequential interactions. This significantly hinders the usefulness of such agents in environments where interaction is costly (for example, when they interact with humans or reset physical systems). While a number of existing LM agent architectures incorporate various mechanisms for experience storage and reflection, they make limited use of LMs' abilities to directly generate or reason about full counterfactual trajectories. We introduce ECHO (Experience Consolidation via Hindsight Optimization), a prompting framework that adapts hindsight experience replay from reinforcement learning for language model agents. ECHO generates optimized trajectories for alternative goals that could have been achieved during failed attempts, effectively creating synthetic positive examples from unsuccessful interactions. Our approach consists of two components: a hindsight rule that uses the language model itself to identify relevant subgoals and generate optimized trajectories, and an update rule that maintains compressed trajectory representations in memory. We evaluate ECHO on stateful versions of XMiniGrid, a text-based navigation and planning benchmark, and PeopleJoinQA, a collaborative information-gathering enterprise simulation. Across both domains, ECHO outperforms vanilla language agent baselines by up to 80%; in XMiniGrid, it also outperforms a number of sophisticated agent architectures including Reflexion and AWM, demonstrating faster adaptation to novel environments through more effective utilization of past experiences.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "176",
        "title": "Is Misinformation More Open? A Study of robots.txt Gatekeeping on the Web",
        "author": [
            "Nicolas Steinacker-Olsztyn",
            "Devashish Gosain",
            "Ha Dao"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10315",
        "abstract": "Large Language Models (LLMs) are increasingly relying on web crawling to stay up to date and accurately answer user queries. These crawlers are expected to honor http://robots.txt files, which govern automated access. In this study, for the first time, we investigate whether reputable news websites and misinformation sites differ in how they configure these files, particularly in relation to AI crawlers. Analyzing a curated dataset, we find a stark contrast: 60.0% of reputable sites disallow at least one AI crawler, compared to just 9.1% of misinformation sites in their http://robots.txt files. Reputable sites forbid an average of 15.5 AI user agents, while misinformation sites prohibit fewer than one. We then measure active blocking behavior, where websites refuse to return content when HTTP requests include AI crawler user agents, and reveal that both categories of websites utilize it. Notably, the behavior of reputable news websites in this regard aligns more closely with their declared http://robots.txt directive than that of misinformation websites. Finally, our longitudinal analysis reveals that this gap has widened over time, with AI-blocking by reputable sites rising from 23% in September 2023 to nearly 60% by May 2025. Our findings highlight a growing asymmetry in content accessibility that may shape the training data available to LLMs, raising essential questions for web transparency, data ethics, and the future of AI training practices.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "177",
        "title": "Bridging Semantics & Structure for Software Vulnerability Detection using Hybrid Network Models",
        "author": [
            "Jugal Gajjar",
            "Kaustik Ranaware",
            "Kamalasankari Subramaniakuppusamy"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10321",
        "abstract": "Software vulnerabilities remain a persistent risk, yet static and dynamic analyses often overlook structural dependencies that shape insecure behaviors. Viewing programs as heterogeneous graphs, we capture control- and data-flow relations as complex interaction networks. Our hybrid framework combines these graph representations with light-weight (<4B) local LLMs, uniting topological features with semantic reasoning while avoiding the cost and privacy concerns of large cloud models. Evaluated on Java vulnerability detection (binary classification), our method achieves 93.57% accuracy-an 8.36% gain over Graph Attention Network-based embeddings and 17.81% over pretrained LLM baselines such as Qwen2.5 Coder 3B. Beyond accuracy, the approach extracts salient subgraphs and generates natural language explanations, improving interpretability for developers. These results pave the way for scalable, explainable, and locally deployable tools that can shift vulnerability analysis from purely syntactic checks to deeper structural and semantic insights, facilitating broader adoption in real-world secure software development.",
        "tags": [
            "Detection",
            "LLM"
        ]
    },
    {
        "id": "178",
        "title": "Are LLMs Empathetic to All? Investigating the Influence of Multi-Demographic Personas on a Model's Empathy",
        "author": [
            "Ananya Malik",
            "Nazanin Sabri",
            "Melissa Karnaze",
            "Mai Elsherief"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10328",
        "abstract": "Large Language Models' (LLMs) ability to converse naturally is empowered by their ability to empathetically understand and respond to their users. However, emotional experiences are shaped by demographic and cultural contexts. This raises an important question: Can LLMs demonstrate equitable empathy across diverse user groups? We propose a framework to investigate how LLMs' cognitive and affective empathy vary across user personas defined by intersecting demographic attributes. Our study introduces a novel intersectional analysis spanning 315 unique personas, constructed from combinations of age, culture, and gender, across four LLMs. Results show that attributes profoundly shape a model's empathetic responses. Interestingly, we see that adding multiple attributes at once can attenuate and reverse expected empathy patterns. We show that they broadly reflect real-world empathetic trends, with notable misalignments for certain groups, such as those from Confucian culture. We complement our quantitative findings with qualitative insights to uncover model behaviour patterns across different demographic groups. Our findings highlight the importance of designing empathy-aware LLMs that account for demographic diversity to promote more inclusive and equitable model behaviour.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "179",
        "title": "End-to-end Automatic Speech Recognition and Speech Translation: Integration of Speech Foundational Models and LLMs",
        "author": [
            "Nam Luu",
            "OndÅej Bojar"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10329",
        "abstract": "Speech Translation (ST) is a machine translation task that involves converting speech signals from one language to the corresponding text in another language; this task has two different approaches, namely the traditional cascade and the more recent end-to-end. This paper explores a combined end-to-end architecture of pre-trained speech encoders and Large Language Models (LLMs) for performing both Automatic Speech Recognition (ASR) and ST simultaneously. Experiments with the English-to-German language pair show that our best model not only can achieve better translation results than SeamlessM4T, a large foundational end-to-end, multi-modal translation model, but can also match the performance of a cascaded system with Whisper and NLLB, with up to a score gain of 8% in $\\text{COMET}^{\\text{DA}}_{22}$ metric.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "180",
        "title": "LLM-Friendly Knowledge Representation for Customer Support",
        "author": [
            "Hanchen Su",
            "Wei Luo",
            "Wei Han",
            "Yu Elaine Liu",
            "Yufeng Wayne Zhang",
            "Cen Mia Zhao",
            "Ying Joy Zhang",
            "Yashar Mehdad"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10331",
        "abstract": "We propose a practical approach by integrating Large Language Models (LLMs) with a framework designed to navigate the complexities of Airbnb customer support operations. In this paper, our methodology employs a novel reformatting technique, the Intent, Context, and Action (ICA) format, which transforms policies and workflows into a structure more comprehensible to LLMs. Additionally, we develop a synthetic data generation strategy to create training data with minimal human intervention, enabling cost-effective fine-tuning of our model. Our internal experiments (not applied to Airbnb products) demonstrate that our approach of restructuring workflows and fine-tuning LLMs with synthetic data significantly enhances their performance, setting a new benchmark for their application in customer support. Our solution is not only cost-effective but also improves customer support, as evidenced by both accuracy and manual processing time evaluation metrics.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "181",
        "title": "Towards Safe Maneuvering of Double-Ackermann-Steering Robots with a Soft Actor-Critic Framework",
        "author": [
            "Kohio Deflesselle",
            "MÃ©lodie Daniel",
            "Aly Magassouba",
            "Miguel Aranda",
            "Olivier Ly"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10332",
        "abstract": "We present a deep reinforcement learning framework based on Soft Actor-Critic (SAC) for safe and precise maneuvering of double-Ackermann-steering mobile robots (DASMRs). Unlike holonomic or simpler non-holonomic robots such as differential-drive robots, DASMRs face strong kinematic constraints that make classical planners brittle in cluttered environments. Our framework leverages the Hindsight Experience Replay (HER) and the CrossQ overlay to encourage maneuvering efficiency while avoiding obstacles. Simulation results with a heavy four-wheel-steering rover show that the learned policy can robustly reach up to 97% of target positions while avoiding obstacles. Our framework does not rely on handcrafted trajectories or expert demonstrations.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "182",
        "title": "From Funding to Findings (FIND): An Open Database of NSF Awards and Research Outputs",
        "author": [
            "Kazimier Smith",
            "Yucheng Lu",
            "Qiaochu Fan"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10336",
        "abstract": "Public funding plays a central role in driving scientific discovery. To better understand the link between research inputs and outputs, we introduce FIND (Funding-Impact NSF Database), an open-access dataset that systematically links NSF grant proposals to their downstream research outputs, including publication metadata and abstracts. The primary contribution of this project is the creation of a large-scale, structured dataset that enables transparency, impact evaluation, and metascience research on the returns to public funding. To illustrate the potential of FIND, we present two proof-of-concept NLP applications. First, we analyze whether the language of grant proposals can predict the subsequent citation impact of funded research. Second, we leverage large language models to extract scientific claims from both proposals and resulting publications, allowing us to measure the extent to which funded projects deliver on their stated goals. Together, these applications highlight the utility of FIND for advancing metascience, informing funding policy, and enabling novel AI-driven analyses of the scientific process.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "183",
        "title": "Rise of the Robochemist",
        "author": [
            "Jihong Zhu",
            "Kefeng Huang",
            "Jonathon Pipe",
            "Chris Horbaczewsky",
            "Andy Tyrrell",
            "Ian J. S. Fairlamb"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10337",
        "abstract": "Chemistry, a long-standing discipline, has historically relied on manual and often time-consuming processes. While some automation exists, the field is now on the cusp of a significant evolution driven by the integration of robotics and artificial intelligence (AI), giving rise to the concept of the robochemist: a new paradigm where autonomous systems assist in designing, executing, and analyzing experiments. Robochemists integrate mobile manipulators, advanced perception, teleoperation, and data-driven protocols to execute experiments with greater adaptability, reproducibility, and safety. Rather than a fully automated replacement for human chemists, we envisioned the robochemist as a complementary partner that works collaboratively to enhance discovery, enabling a more efficient exploration of chemical space and accelerating innovation in pharmaceuticals, materials science, and sustainable manufacturing. This article traces the technologies, applications, and challenges that define this transformation, highlighting both the opportunities and the responsibilities that accompany the emergence of the robochemist. Ultimately, the future of chemistry is argued to lie in a symbiotic partnership where human intuition and expertise is amplified by robotic precision and AI-driven insight.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "184",
        "title": "Ordinal Scale Traffic Congestion Classification with Multi-Modal Vision-Language and Motion Analysis",
        "author": [
            "Yu-Hsuan Lin"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10342",
        "abstract": "Accurate traffic congestion classification is essential for intelligent transportation systems and real-time urban traffic management. This paper presents a multimodal framework combining open-vocabulary visual-language reasoning (CLIP), object detection (YOLO-World), and motion analysis via MOG2-based background subtraction. The system predicts congestion levels on an ordinal scale from 1 (free flow) to 5 (severe congestion), enabling semantically aligned and temporally consistent classification. To enhance interpretability, we incorporate motion-based confidence weighting and generate annotated visual outputs. Experimental results show the model achieves 76.7 percent accuracy, an F1 score of 0.752, and a Quadratic Weighted Kappa (QWK) of 0.684, significantly outperforming unimodal baselines. These results demonstrate the framework's effectiveness in preserving ordinal structure and leveraging visual-language and motion modalities. Future enhancements include incorporating vehicle sizing and refined density metrics.",
        "tags": [
            "CLIP",
            "Detection"
        ]
    },
    {
        "id": "185",
        "title": "Staggered time discretization in finitely-strained heterogeneous visco-elastodynamics with damage or diffusion in the Eulerian frame",
        "author": [
            "TomÃ¡Å¡ RoubÃ­Äek"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10355",
        "abstract": "The semi-implicit (partly decoupled, also called staggered or fraction-step) time discretization is applied to compressible nonlinear dynamical models of viscoelastic solids in the Eulerian description, i.e.\\ in the actual deforming configuration, formulated fully in terms of rates. The Kelvin-Voigt rheology and also, in the deviatoric part, the Jeffreys rheology are considered. The numerical stability and, considering the Stokes-type viscosity multipolar of the 2nd-grade, also convergence towards weak solutions are proved in three-dimensional situations, exploiting the convexity of the kinetic energy when written in terms of linear momentum. No (poly)convexity of the stored energy is required and some enhancements (specifically towards damage and diffusion models) are briefly outlined, too.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "186",
        "title": "Learning to Throw-Flip",
        "author": [
            "Yang Liu",
            "Bruno Da Costa",
            "Aude Billard"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10357",
        "abstract": "Dynamic manipulation, such as robot tossing or throwing objects, has recently gained attention as a novel paradigm to speed up logistic operations. However, the focus has predominantly been on the object's landing location, irrespective of its final orientation. In this work, we present a method enabling a robot to accurately \"throw-flip\" objects to a desired landing pose (position and orientation). Conventionally, objects thrown by revolute robots suffer from parasitic rotation, resulting in highly restricted and uncontrollable landing poses. Our approach is based on two key design choices: first, leveraging the impulse-momentum principle, we design a family of throwing motions that effectively decouple the parasitic rotation, significantly expanding the feasible set of landing poses. Second, we combine a physics-based model of free flight with regression-based learning methods to account for unmodeled effects. Real robot experiments demonstrate that our framework can learn to throw-flip objects to a pose target within ($\\pm$5 cm, $\\pm$45 degrees) threshold in dozens of trials. Thanks to data assimilation, incorporating projectile dynamics reduces sample complexity by an average of 40% when throw-flipping to unseen poses compared to end-to-end learning methods. Additionally, we show that past knowledge on in-hand object spinning can be effectively reused, accelerating learning by 70% when throwing a new object with a Center of Mass (CoM) shift. A video summarizing the proposed method and the hardware experiments is available at https://youtu.be/txYc9b1oflU.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "187",
        "title": "Transformer Model Detects Antidepressant Use From a Single Night of Sleep, Unlocking an Adherence Biomarker",
        "author": [
            "Ali Mirzazadeh",
            "Simon Cadavid",
            "Kaiwen Zha",
            "Chao Li",
            "Sultan Alzahrani",
            "Manar Alawajy",
            "Joshua Korzenik",
            "Kreshnik Hoti",
            "Charles Reynolds",
            "David Mischoulon",
            "John Winkelman",
            "Maurizio Fava",
            "Dina Katabi"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10364",
        "abstract": "Antidepressant nonadherence is pervasive, driving relapse, hospitalization, suicide risk, and billions in avoidable costs. Clinicians need tools that detect adherence lapses promptly, yet current methods are either invasive (serum assays, neuroimaging) or proxy-based and inaccurate (pill counts, pharmacy refills). We present the first noninvasive biomarker that detects antidepressant intake from a single night of sleep. A transformer-based model analyzes sleep data from a consumer wearable or contactless wireless sensor to infer antidepressant intake, enabling remote, effortless, daily adherence assessment at home. Across six datasets comprising 62,000 nights from >20,000 participants (1,800 antidepressant users), the biomarker achieved AUROC = 0.84, generalized across drug classes, scaled with dose, and remained robust to concomitant psychotropics. Longitudinal monitoring captured real-world initiation, tapering, and lapses. This approach offers objective, scalable adherence surveillance with potential to improve depression care and outcomes.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "188",
        "title": "PointMAC: Meta-Learned Adaptation for Robust Test-Time Point Cloud Completion",
        "author": [
            "Linlian Jiang",
            "Rui Ma",
            "Li Gu",
            "Ziqiang Wang",
            "Xinxin Zuo",
            "Yang Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10365",
        "abstract": "Point cloud completion is essential for robust 3D perception in safety-critical applications such as robotics and augmented reality. However, existing models perform static inference and rely heavily on inductive biases learned during training, limiting their ability to adapt to novel structural patterns and sensor-induced distortions at test time. To address this limitation, we propose PointMAC, a meta-learned framework for robust test-time adaptation in point cloud completion. It enables sample-specific refinement without requiring additional supervision. Our method optimizes the completion model under two self-supervised auxiliary objectives that simulate structural and sensor-level incompleteness. A meta-auxiliary learning strategy based on Model-Agnostic Meta-Learning (MAML) ensures that adaptation driven by auxiliary objectives is consistently aligned with the primary completion task. During inference, we adapt the shared encoder on-the-fly by optimizing auxiliary losses, with the decoder kept fixed. To further stabilize adaptation, we introduce Adaptive $\\lambda$-Calibration, a meta-learned mechanism for balancing gradients between primary and auxiliary objectives. Extensive experiments on synthetic, simulated, and real-world datasets demonstrate that PointMAC achieves state-of-the-art results by refining each sample individually to produce high-quality completions. To the best of our knowledge, this is the first work to apply meta-auxiliary test-time adaptation to point cloud completion.",
        "tags": [
            "3D",
            "Robotics"
        ]
    },
    {
        "id": "189",
        "title": "Self-Supervised Multi-Scale Transformer with Attention-Guided Fusion for Efficient Crack Detection",
        "author": [
            "Blessing Agyei Kyem",
            "Joshua Kofi Asamoah",
            "Eugene Denteh",
            "Andrews Danyo",
            "Armstrong Aboah"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10378",
        "abstract": "Pavement crack detection has long depended on costly and time-intensive pixel-level annotations, which limit its scalability for large-scale infrastructure monitoring. To overcome this barrier, this paper examines the feasibility of achieving effective pixel-level crack segmentation entirely without manual annotations. Building on this objective, a fully self-supervised framework, Crack-Segmenter, is developed, integrating three complementary modules: the Scale-Adaptive Embedder (SAE) for robust multi-scale feature extraction, the Directional Attention Transformer (DAT) for maintaining linear crack continuity, and the Attention-Guided Fusion (AGF) module for adaptive feature integration. Through evaluations on ten public datasets, Crack-Segmenter consistently outperforms 13 state-of-the-art supervised methods across all major metrics, including mean Intersection over Union (mIoU), Dice score, XOR, and Hausdorff Distance (HD). These findings demonstrate that annotation-free crack detection is not only feasible but also superior, enabling transportation agencies and infrastructure managers to conduct scalable and cost-effective monitoring. This work advances self-supervised learning and motivates pavement cracks detection research.",
        "tags": [
            "Detection",
            "Segmentation",
            "Transformer"
        ]
    },
    {
        "id": "190",
        "title": "RobotFleet: An Open-Source Framework for Centralized Multi-Robot Task Planning",
        "author": [
            "Rohan Gupta",
            "Trevor Asbery",
            "Zain Merchant",
            "Abrar Anwar",
            "Jesse Thomason"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10379",
        "abstract": "Coordinating heterogeneous robot fleets to achieve multiple goals is challenging in multi-robot systems. We introduce an open-source and extensible framework for centralized multi-robot task planning and scheduling that leverages LLMs to enable fleets of heterogeneous robots to accomplish multiple tasks. RobotFleet provides abstractions for planning, scheduling, and execution across robots deployed as containerized services to simplify fleet scaling and management. The framework maintains a shared declarative world state and two-way communication for task execution and replanning. By modularizing each layer of the autonomy stack and using LLMs for open-world reasoning, RobotFleet lowers the barrier to building scalable multi-robot systems. The code can be found here: https://github.com/therohangupta/robot-fleet.",
        "tags": [
            "LLM",
            "Robotics"
        ]
    },
    {
        "id": "191",
        "title": "GrifFinNet: A Graph-Relation Integrated Transformer for Financial Predictions",
        "author": [
            "Chenlanhui Dai",
            "Wenyan Wang",
            "Yusi Fan",
            "Yueying Wang",
            "Lan Huang",
            "Kewei Li",
            "Fengfeng Zhou"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10387",
        "abstract": "Predicting stock returns remains a central challenge in quantitative finance, transitioning from traditional statistical methods to contemporary deep learning techniques. However, many current models struggle with effectively capturing spatio-temporal dynamics and integrating multiple relational data sources. This study proposes GrifFinNet, a Graph-Relation Integrated Transformer for Financial Predictions, which combines multi-relational graph modeling with Transformer-based temporal encoding. GrifFinNet constructs inter-stock relation graphs based on industry sectors and institutional ownership, and incorporates an adaptive gating mechanism to dynamically integrate relational data in response to changing market conditions. This approach enables the model to jointly capture spatial dependencies and temporal patterns, offering a comprehensive representation of market dynamics. Extensive experiments on two Chinese A-share indices show that GrifFinNet consistently outperforms several baseline models and provides valuable, interpretable insights into financial market behavior. The code and data are available at: https://www.healthinformaticslab.org/supp/.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "192",
        "title": "MicroRoboScope: A Portable and Integrated Mechatronic Platform for Magnetic and Acoustic Microrobotic Experimentation",
        "author": [
            "Max Sokolich",
            "Yanda Yang",
            "Subrahmanyam Cherukumilli",
            "Fatma Ceren Kirmizitas",
            "Sambeeta Das"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10392",
        "abstract": "This paper presents MicroRoboScope, a portable, compact, and versatile microrobotic experimentation platform designed for real-time, closed-loop control of both magnetic and acoustic microrobots. The system integrates an embedded computer, microscope, power supplies, and control circuitry into a single, low-cost and fully integrated apparatus. Custom control software developed in Python and Arduino C++ handles live video acquisition, microrobot tracking, and generation of control signals for electromagnetic coils and acoustic transducers. The platform's multi-modal actuation, accessibility, and portability make it suitable not only for specialized research laboratories but also for educational and outreach settings. By lowering the barrier to entry for microrobotic experimentation, this system enables new opportunities for research, education, and translational applications in biomedicine, tissue engineering, and robotics.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "193",
        "title": "AVoCaDO: An Audiovisual Video Captioner Driven by Temporal Orchestration",
        "author": [
            "Xinlong Chen",
            "Yue Ding",
            "Weihong Lin",
            "Jingyun Hua",
            "Linli Yao",
            "Yang Shi",
            "Bozhou Li",
            "Yuanxing Zhang",
            "Qiang Liu",
            "Pengfei Wan",
            "Liang Wang",
            "Tieniu Tan"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10395",
        "abstract": "Audiovisual video captioning aims to generate semantically rich descriptions with temporal alignment between visual and auditory events, thereby benefiting both video understanding and generation. In this paper, we present AVoCaDO, a powerful audiovisual video captioner driven by the temporal orchestration between audio and visual modalities. We propose a two-stage post-training pipeline: (1) AVoCaDO SFT, which fine-tunes the model on a newly curated dataset of 107K high-quality, temporally-aligned audiovisual captions; and (2) AVoCaDO GRPO, which leverages tailored reward functions to further enhance temporal coherence and dialogue accuracy while regularizing caption length and reducing collapse. Experimental results demonstrate that AVoCaDO significantly outperforms existing open-source models across four audiovisual video captioning benchmarks, and also achieves competitive performance on the VDC and DREAM-1K benchmark under visual-only settings.",
        "tags": [
            "GRPO"
        ]
    },
    {
        "id": "194",
        "title": "STEAM: A Semantic-Level Knowledge Editing Framework for Large Language Models",
        "author": [
            "Geunyeong Jeong",
            "Juoh Sun",
            "Seonghee Lee",
            "Harksoo Kim"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10398",
        "abstract": "Large Language Models store extensive factual knowledge acquired during large-scale pre-training. However, this knowledge is inherently static, reflecting only the state of the world at the time of training. Knowledge editing has emerged as a promising solution for updating outdated or incorrect facts without full retraining. However, most existing locate-and-edit methods primarily focus on token-level likelihood optimization without addressing semantic coherence. Our analysis reveals that such edited knowledge is often encoded as isolated residual streams in the model's latent space, distinct from pre-existing knowledge and bypassing natural reasoning process. To address this, we propose \\textsc{Steam}, a semantic-level knowledge editing framework that enhances integration of updated knowledge into the model's knowledge structure. \\textsc{Steam} first identifies target representations as semantic anchors for the updated factual association, then guides the internal representation of the edited fact towards these anchors through an alignment loss during optimization. Experimental results demonstrate that \\textsc{Steam} improves model's ability to reason with edited knowledge and enhances semantic coherence, underscoring the importance of latent-space alignment for reliable and coherent knowledge editing. The code is available at https://github.com/GY-Jeong/STEAM.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "195",
        "title": "PrediQL: Automated Testing of GraphQL APIs with LLMs",
        "author": [
            "Shaolun Liu",
            "Sina Marefat",
            "Omar Tsai",
            "Yu Chen",
            "Zecheng Deng",
            "Jia Wang",
            "Mohammad A. Tayebi"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10407",
        "abstract": "GraphQL's flexible query model and nested data dependencies expose APIs to complex, context-dependent vulnerabilities that are difficult to uncover using conventional testing tools. Existing fuzzers either rely on random payload generation or rigid mutation heuristics, failing to adapt to the dynamic structures of GraphQL schemas and responses. We present PrediQL, the first retrieval-augmented, LLM-guided fuzzer for GraphQL APIs. PrediQL combines large language model reasoning with adaptive feedback loops to generate semantically valid and diverse queries. It models the choice of fuzzing strategy as a multi-armed bandit problem, balancing exploration of new query structures with exploitation of past successes. To enhance efficiency, PrediQL retrieves and reuses execution traces, schema fragments, and prior errors, enabling self-correction and progressive learning across test iterations. Beyond input generation, PrediQL integrates a context-aware vulnerability detector that uses LLM reasoning to analyze responses, interpreting data values, error messages, and status codes to identify issues such as injection flaws, access-control bypasses, and information disclosure. Our evaluation across open-source and benchmark GraphQL APIs shows that PrediQL achieves significantly higher coverage and vulnerability discovery rates compared to state-of-the-art baselines. These results demonstrate that combining retrieval-augmented reasoning with adaptive fuzzing can transform API security testing from reactive enumeration to intelligent exploration.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "196",
        "title": "Trace Length is a Simple Uncertainty Signal in Reasoning Models",
        "author": [
            "Siddartha Devic",
            "Charlotte Peale",
            "Arwen Bradley",
            "Sinead Williamson",
            "Preetum Nakkiran",
            "Aravind Gollakota"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10409",
        "abstract": "Uncertainty quantification for LLMs is a key research direction towards addressing hallucination and other issues that limit their reliable deployment. In this work, we show that reasoning trace length is a simple and useful confidence estimator in large reasoning models. Through comprehensive experiments across multiple models, datasets, and prompts, we show that trace length performs in comparable but complementary ways to other zero-shot confidence estimators such as verbalized confidence. Our work reveals that reasoning post-training fundamentally alters the relationship between trace length and accuracy, going beyond prior work that had shown that post-training causes traces to grow longer in general (e.g., \"overthinking\"). We investigate the mechanisms behind trace length's performance as a confidence signal, observing that the effect remains even after adjusting for confounders such as problem difficulty and GRPO-induced length bias. We identify high-entropy or \"forking\" tokens as playing a key role in the mechanism. Our findings demonstrate that reasoning post-training enhances uncertainty quantification beyond verbal expressions, and establish trace length as a practical confidence measure for large reasoning models.",
        "tags": [
            "GRPO",
            "LLM"
        ]
    },
    {
        "id": "197",
        "title": "Combo-Gait: Unified Transformer Framework for Multi-Modal Gait Recognition and Attribute Analysis",
        "author": [
            "Zhao-Yang Wang",
            "Zhimin Shao",
            "Jieneng Chen",
            "Rama Chellappa"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10417",
        "abstract": "Gait recognition is an important biometric for human identification at a distance, particularly under low-resolution or unconstrained environments. Current works typically focus on either 2D representations (e.g., silhouettes and skeletons) or 3D representations (e.g., meshes and SMPLs), but relying on a single modality often fails to capture the full geometric and dynamic complexity of human walking patterns. In this paper, we propose a multi-modal and multi-task framework that combines 2D temporal silhouettes with 3D SMPL features for robust gait analysis. Beyond identification, we introduce a multitask learning strategy that jointly performs gait recognition and human attribute estimation, including age, body mass index (BMI), and gender. A unified transformer is employed to effectively fuse multi-modal gait features and better learn attribute-related representations, while preserving discriminative identity cues. Extensive experiments on the large-scale BRIAR datasets, collected under challenging conditions such as long-range distances (up to 1 km) and extreme pitch angles (up to 50Â°), demonstrate that our approach outperforms state-of-the-art methods in gait recognition and provides accurate human attribute estimation. These results highlight the promise of multi-modal and multitask learning for advancing gait-based human understanding in real-world scenarios.",
        "tags": [
            "3D",
            "Transformer"
        ]
    },
    {
        "id": "198",
        "title": "Hierarchical Planning for Long-Horizon Multi-Target Tracking Under Target Motion Uncertainty",
        "author": [
            "Junbin Yuan",
            "Brady Moon",
            "Muqing Cao",
            "Sebastian Scherer"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10421",
        "abstract": "Achieving persistent tracking of multiple dynamic targets over a large spatial area poses significant challenges for a single-robot system with constrained sensing capabilities. As the robot moves to track different targets, the ones outside the field of view accumulate uncertainty, making them progressively harder to track. An effective path planning algorithm must manage uncertainty over a long horizon and account for the risk of permanently losing track of targets that remain unseen for too long. However, most existing approaches rely on short planning horizons and assume small, bounded environments, resulting in poor tracking performance and target loss in large-scale scenarios. In this paper, we present a hierarchical planner for tracking multiple moving targets with an aerial vehicle. To address the challenge of tracking non-static targets, our method incorporates motion models and uncertainty propagation during path execution, allowing for more informed decision-making. We decompose the multi-target tracking task into sub-tasks of single target search and detection, and our proposed pipeline consists a novel low-level coverage planner that enables searching for a target in an evolving belief area, and an estimation method to assess the likelihood of success for each sub-task, making it possible to convert the active target tracking task to a Markov decision process (MDP) that we solve with a tree-based algorithm to determine the sequence of sub-tasks. We validate our approach in simulation, demonstrating its effectiveness compared to existing planners for active target tracking tasks, and our proposed planner outperforms existing approaches, achieving a reduction of 11-70% in final uncertainty across different environments.",
        "tags": [
            "Detection",
            "Robotics"
        ]
    },
    {
        "id": "199",
        "title": "Softmax $\\geq$ Linear: Transformers may learn to classify in-context by kernel gradient descent",
        "author": [
            "Sara DragutinoviÄ",
            "Andrew M. Saxe",
            "Aaditya K. Singh"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10425",
        "abstract": "The remarkable ability of transformers to learn new concepts solely by reading examples within the input prompt, termed in-context learning (ICL), is a crucial aspect of intelligent behavior. Here, we focus on understanding the learning algorithm transformers use to learn from context. Existing theoretical work, often based on simplifying assumptions, has primarily focused on linear self-attention and continuous regression tasks, finding transformers can learn in-context by gradient descent. Given that transformers are typically trained on discrete and complex tasks, we bridge the gap from this existing work to the setting of classification, with non-linear (importantly, softmax) activation. We find that transformers still learn to do gradient descent in-context, though on functionals in the kernel feature space and with a context-adaptive learning rate in the case of softmax transformer. These theoretical findings suggest a greater adaptability to context for softmax attention, which we empirically verify and study through ablations. Overall, we hope this enhances theoretical understanding of in-context learning algorithms in more realistic settings, pushes forward our intuitions and enables further theory bridging to larger models.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "200",
        "title": "Taming a Retrieval Framework to Read Images in Humanlike Manner for Augmenting Generation of MLLMs",
        "author": [
            "Suyang Xi",
            "Chenxi Yang",
            "Hong Ding",
            "Yiqing Ni",
            "Catherine C. Liu",
            "Yunhao Liu",
            "Chengqi Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10426",
        "abstract": "Multimodal large language models (MLLMs) often fail in fine-grained visual question answering, producing hallucinations about object identities, positions, and relations because textual queries are not explicitly anchored to visual referents. Retrieval-augmented generation (RAG) alleviates some errors, but it fails to align with human-like processing at both the retrieval and augmentation levels. Specifically, it focuses only on global-level image information but lacks local detail and limits reasoning about fine-grained interactions. To overcome this limitation, we present Human-Like Retrieval-Augmented Generation (HuLiRAG), a framework that stages multimodal reasoning as a ``what--where--reweight'' cascade. Queries are first anchored to candidate referents via open-vocabulary detection (what), then spatially resolved with SAM-derived masks to recover fine-grained precision (where), and adaptively prioritized through the trade-off between local and global alignment (reweight). Mask-guided fine-tuning further injects spatial evidence into the generation process, transforming grounding from a passive bias into an explicit constraint on answer formulation. Extensive experiments demonstrate that this human-like cascade improves grounding fidelity and factual consistency while reducing hallucinations, advancing multimodal question answering toward trustworthy reasoning.",
        "tags": [
            "Detection",
            "LLM",
            "RAG",
            "SAM"
        ]
    },
    {
        "id": "201",
        "title": "MonoSE(3)-Diffusion: A Monocular SE(3) Diffusion Framework for Robust Camera-to-Robot Pose Estimation",
        "author": [
            "Kangjian Zhu",
            "Haobo Jiang",
            "Yigong Zhang",
            "Jianjun Qian",
            "Jian Yang",
            "Jin Xie"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10434",
        "abstract": "We propose MonoSE(3)-Diffusion, a monocular SE(3) diffusion framework that formulates markerless, image-based robot pose estimation as a conditional denoising diffusion process. The framework consists of two processes: a visibility-constrained diffusion process for diverse pose augmentation and a timestep-aware reverse process for progressive pose refinement. The diffusion process progressively perturbs ground-truth poses to noisy transformations for training a pose denoising network. Importantly, we integrate visibility constraints into the process, ensuring the transformations remain within the camera field of view. Compared to the fixed-scale perturbations used in current methods, the diffusion process generates in-view and diverse training poses, thereby improving the network generalization capability. Furthermore, the reverse process iteratively predicts the poses by the denoising network and refines pose estimates by sampling from the diffusion posterior of current timestep, following a scheduled coarse-to-fine procedure. Moreover, the timestep indicates the transformation scales, which guide the denoising network to achieve more accurate pose predictions. The reverse process demonstrates higher robustness than direct prediction, benefiting from its timestep-aware refinement scheme. Our approach demonstrates improvements across two benchmarks (DREAM and RoboKeyGen), achieving a notable AUC of 66.75 on the most challenging dataset, representing a 32.3% gain over the state-of-the-art.",
        "tags": [
            "Diffusion",
            "Pose Estimation",
            "Robotics"
        ]
    },
    {
        "id": "202",
        "title": "Do Audio LLMs Really LISTEN, or Just Transcribe? Measuring Lexical vs. Acoustic Emotion Cues Reliance",
        "author": [
            "Jingyi Chen",
            "Zhimeng Guo",
            "Jiyun Chun",
            "Pichao Wang",
            "Andrew Perrault",
            "Micha Elsner"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10444",
        "abstract": "Understanding emotion from speech requires sensitivity to both lexical and acoustic cues. However, it remains unclear whether large audio language models (LALMs) genuinely process acoustic information or rely primarily on lexical content. We present LISTEN (Lexical vs. Acoustic Speech Test for Emotion in Narratives), a controlled benchmark designed to disentangle lexical reliance from acoustic sensitivity in emotion understanding. Across evaluations of six state-of-the-art LALMs, we observe a consistent lexical dominance. Models predict \"neutral\" when lexical cues are neutral or absent, show limited gains under cue alignment, and fail to classify distinct emotions under cue conflict. In paralinguistic settings, performance approaches chance. These results indicate that current LALMs largely \"transcribe\" rather than \"listen,\" relying heavily on lexical semantics while underutilizing acoustic cues. LISTEN offers a principled framework for assessing emotion understanding in multimodal models.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "203",
        "title": "RECON: Reasoning with Condensation for Efficient Retrieval-Augmented Generation",
        "author": [
            "Zhichao Xu",
            "Minheng Wang",
            "Yawei Wang",
            "Wenqian Ye",
            "Yuntao Du",
            "Yunpu Ma",
            "Yijun Tian"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10448",
        "abstract": "Retrieval-augmented generation (RAG) systems trained using reinforcement learning (RL) with reasoning are hampered by inefficient context management, where long, noisy retrieved documents increase costs and degrade performance. We introduce RECON (REasoning with CONdensation), a framework that integrates an explicit summarization module to compress evidence within the reasoning loop. Our summarizer is trained via a two-stage process: relevance pretraining on QA datasets, followed by multi-aspect distillation from proprietary LLMs to ensure factuality and clarity. Integrated into the Search-R1 pipeline, RECON reduces total context length by 35\\%, leading to improved training speed and inference latency, while simultaneously improving RAG performance on downstream QA benchmarks. Notably, it boosts the average EM score of the 3B model by 14.5\\% and the 7B model by 3.0\\%, showing particular strength in multi-hop QA. RECON demonstrates that learned context compression is essential for building practical, scalable, and performant RAG systems. Our code implementation is made available at https://github.com/allfornancy/RECON.",
        "tags": [
            "LLM",
            "RAG",
            "RL"
        ]
    },
    {
        "id": "204",
        "title": "Towards Dynamic Quadrupedal Gaits: A Symmetry-Guided RL Hierarchy Enables Free Gait Transitions at Varying Speeds",
        "author": [
            "Jiayu Ding",
            "Xulin Chen",
            "Garrett E. Katz",
            "Zhenyu Gan"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10455",
        "abstract": "Quadrupedal robots exhibit a wide range of viable gaits, but generating specific footfall sequences often requires laborious expert tuning of numerous variables, such as touch-down and lift-off events and holonomic constraints for each leg. This paper presents a unified reinforcement learning framework for generating versatile quadrupedal gaits by leveraging the intrinsic symmetries and velocity-period relationship of dynamic legged systems. We propose a symmetry-guided reward function design that incorporates temporal, morphological, and time-reversal symmetries. By focusing on preserved symmetries and natural dynamics, our approach eliminates the need for predefined trajectories, enabling smooth transitions between diverse locomotion patterns such as trotting, bounding, half-bounding, and galloping. Implemented on the Unitree Go2 robot, our method demonstrates robust performance across a range of speeds in both simulations and hardware tests, significantly improving gait adaptability without extensive reward tuning or explicit foot placement control. This work provides insights into dynamic locomotion strategies and underscores the crucial role of symmetries in robotic gait design.",
        "tags": [
            "RL",
            "Robotics"
        ]
    },
    {
        "id": "205",
        "title": "Rethinking LLM Evaluation: Can We Evaluate LLMs with 200x Less Data?",
        "author": [
            "Shaobo Wang",
            "Cong Wang",
            "Wenjie Fu",
            "Yue Min",
            "Mingquan Feng",
            "Isabel Guan",
            "Xuming Hu",
            "Conghui He",
            "Cunxiang Wang",
            "Kexin Yang",
            "Xingzhang Ren",
            "Fei Huang",
            "Dayiheng Liu",
            "Linfeng Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10457",
        "abstract": "As the demand for comprehensive evaluations of diverse model capabilities steadily increases, benchmark suites have correspondingly grown significantly in scale. Despite notable advances in redundancy reduction and subset-level performance prediction, a systematic framework that effectively integrates these methods to ensure both prediction accuracy and ranking consistency is still largely elusive. In this paper, we first perform a sample-level analysis of benchmark redundancy and identify several highly similar samples that can be eliminated. Besides, we frame benchmark compression as an optimization problem with the aim of score reconstruction. Building on these, we then propose EssenceBench, a coarse-to-fine framework utilizing an iterative Genetic Algorithm (GA), which takes the advantages of fitness-based subset search and attribution-based sample search. Compared to previous methods, our approach yields superior compression results with lower reconstruction error and markedly higher efficiency. In particular, on the HellaSwag benchmark (10K samples), our method preserves the ranking of all models shifting within 5% using 25x fewer samples, and achieves 95% ranking preservation shifting within 5% using only 200x fewer samples.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "206",
        "title": "NIM: Neuro-symbolic Ideographic Metalanguage for Inclusive Communication",
        "author": [
            "Prawaal Sharma",
            "Poonam Goyal",
            "Navneet Goyal",
            "Vidisha Sharma"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10459",
        "abstract": "Digital communication has become the cornerstone of modern interaction, enabling rapid, accessible, and interactive exchanges. However, individuals with lower academic literacy often face significant barriers, exacerbating the \"digital divide\". In this work, we introduce a novel, universal ideographic metalanguage designed as an innovative communication framework that transcends academic, linguistic, and cultural boundaries. Our approach leverages principles of Neuro-symbolic AI, combining neural-based large language models (LLMs) enriched with world knowledge and symbolic knowledge heuristics grounded in the linguistic theory of Natural Semantic Metalanguage (NSM). This enables the semantic decomposition of complex ideas into simpler, atomic concepts. Adopting a human-centric, collaborative methodology, we engaged over 200 semi-literate participants in defining the problem, selecting ideographs, and validating the system. With over 80\\% semantic comprehensibility, an accessible learning curve, and universal adaptability, our system effectively serves underprivileged populations with limited formal education.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "207",
        "title": "Testing and Enhancing Multi-Agent Systems for Robust Code Generation",
        "author": [
            "Zongyi Lyu",
            "Songqiang Chen",
            "Zhenlan Ji",
            "Liwen Wang",
            "Shuai Wang",
            "Daoyuan Wu",
            "Wenxuan Wang",
            "Shing-Chi Cheung"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10460",
        "abstract": "Multi-agent systems (MASs) have emerged as a promising paradigm for automated code generation, demonstrating impressive performance on established benchmarks by decomposing complex coding tasks across specialized agents with different roles. Despite their prosperous development and adoption, their robustness remains pressingly under-explored, raising critical concerns for real-world deployment. This paper presents the first comprehensive study examining the robustness of MASs for code generation through a fuzzing-based testing approach. By designing a fuzzing pipeline incorporating semantic-preserving mutation operators and a novel fitness function, we assess mainstream MASs across multiple datasets and LLMs. Our findings reveal substantial robustness flaws of various popular MASs: they fail to solve 7.9%-83.3% of problems they initially resolved successfully after applying the semantic-preserving mutations. Through comprehensive failure analysis, we identify a common yet largely overlooked cause of the robustness issue: miscommunications between planning and coding agents, where plans lack sufficient detail and coding agents misinterpret intricate logic, aligning with the challenges inherent in a multi-stage information transformation process. Accordingly, we also propose a repairing method that encompasses multi-prompt generation and introduces a new monitor agent to address this issue. Evaluation shows that our repairing method effectively enhances the robustness of MASs by solving 40.0%-88.9% of identified failures. Our work uncovers critical robustness flaws in MASs and provides effective mitigation strategies, contributing essential insights for developing more reliable MASs for code generation.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "208",
        "title": "When Images Speak Louder: Mitigating Language Bias-induced Hallucinations in VLMs through Cross-Modal Guidance",
        "author": [
            "Jinjin Cao",
            "Zhiyang Chen",
            "Zijun Wang",
            "Liyuan Ma",
            "Weijian Luo",
            "Guojun Qi"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10466",
        "abstract": "Vision-Language Models (VLMs) have shown solid ability for multimodal understanding of both visual and language contexts. However, existing VLMs often face severe challenges of hallucinations, meaning that VLMs tend to generate responses that are only fluent in the language but irrelevant to images in previous contexts. To address this issue, we analyze how language bias contributes to hallucinations and then introduce Cross-Modal Guidance(CMG), a training-free decoding method that addresses the hallucinations by leveraging the difference between the output distributions of the original model and the one with degraded visual-language attention. In practice, we adaptively mask the attention weight of the most influential image tokens in selected transformer layers to corrupt the visual-language perception as a concrete type of degradation. Such a degradation-induced decoding emphasizes the perception of visual contexts and therefore significantly reduces language bias without harming the ability of VLMs. In experiment sections, we conduct comprehensive studies. All results demonstrate the superior advantages of CMG with neither additional conditions nor training costs. We also quantitatively show CMG can improve different VLM's performance on hallucination-specific benchmarks and generalize effectively.",
        "tags": [
            "Transformer",
            "VLM"
        ]
    },
    {
        "id": "209",
        "title": "AnyBCQ: Hardware Efficient Flexible Binary-Coded Quantization for Multi-Precision LLMs",
        "author": [
            "Gunho Park",
            "Jeongin Bae",
            "Beomseok Kwon",
            "Byeongwook Kim",
            "Se Jung Kwon",
            "Dongsoo Lee"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10467",
        "abstract": "The deployment of large language models (LLMs) is increasingly constrained by memory and latency bottlenecks, motivating the need for quantization techniques that flexibly balance accuracy and efficiency. Recent work has introduced multi-precision models, which enable inference at multiple precisions within a single model depending on runtime constraints. To support such flexibility, quantized weights are often stored as bit-planes, where hardware efficiency improves when the compute operates directly at the bit-plane level and activates only the precision required by each request. In this work, we present AnyBCQ, a hardware-friendly multi-precision extension of Binary-Coded Quantization (BCQ) that supports direct bit-plane operations. By representing weights as binary bit-planes with corresponding scale factors, AnyBCQ enables bit-plane-level computation and maps naturally to accelerator-friendly, bit-parallel arithmetic. Our progressive precision expansion mechanism incrementally refines scaling factors while reusing previously assigned binary codes, yielding monotonic improvements in accuracy as additional bits are enabled. We further co-design a specialized kernel that exploits the BCQ structure to support dynamic per-request precision selection with negligible overhead. Experiments on recent LLMs demonstrate that AnyBCQ significantly narrows the accuracy drop in the low-bit regime (e.g. 2-bit), remains competitive at higher precision, and achieves throughput gains of up to 3.0x over half precision and 1.2x over state-of-the-art multi-precision methods. By aligning algorithmic flexibility with hardware efficiency, AnyBCQ provides a practical foundation for multi-precision LLM deployment across diverse service-level objectives.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "210",
        "title": "Galilean Symmetry in Robotics",
        "author": [
            "Robert Mahony",
            "Jonathan Kelly",
            "Stephan Weiss"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10468",
        "abstract": "Galilean symmetry is the natural symmetry of inertial motion that underpins Newtonian physics. Although rigid-body symmetry is one of the most established and fundamental tools in robotics, there appears to be no comparable treatment of Galilean symmetry for a robotics audience. In this paper, we present a robotics-tailored exposition of Galilean symmetry that leverages the community's familiarity with and understanding of rigid-body transformations and pose representations. Our approach contrasts with common treatments in the physics literature that introduce Galilean symmetry as a stepping stone to Einstein's relativity. A key insight is that the Galilean matrix Lie group can be used to describe two different pose representations, Galilean frames, that use inertial velocity in the state definition, and extended poses, that use coordinate velocity. We provide three examples where applying the Galilean matrix Lie-group algebra to robotics problems is straightforward and yields significant insights: inertial navigation above the rotating Earth, manipulator kinematics, and sensor data fusion under temporal uncertainty. We believe that the time is right for the robotics community to benefit from rediscovering and extending this classical material and applying it to modern problems.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "211",
        "title": "FML-bench: A Benchmark for Automatic ML Research Agents Highlighting the Importance of Exploration Breadth",
        "author": [
            "Qiran Zou",
            "Hou Hei Lam",
            "Wenhao Zhao",
            "Yiming Tang",
            "Tingting Chen",
            "Samson Yu",
            "Tianyi Zhang",
            "Chang Liu",
            "Xiangyang Ji",
            "Dianbo Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10472",
        "abstract": "Large language models (LLMs) have sparked growing interest in automatic machine learning research agents. Among them, agents capable of autonomously proposing ideas and conducting machine learning experiments are particularly promising, as they maximize research automation and accelerate scientific progress by iteratively refining ideas based on experimental results. However, comprehensively evaluating such agents remains challenging. Existing benchmarks tend to overemphasize engineering aspects while neglecting academic rigor, creating barriers that obscure a clear assessment of an agent's scientific capabilities in machine learning research. They also suffer from limited task diversity, an overemphasis on application-oriented tasks over fundamental research problems, and limited scalability to realistic research settings. To address these limitations, we introduce FML-bench, a benchmark designed to evaluate automatic machine learning research agents on 8 diverse and fundamental machine learning research problems. It reduces coding burden, emphasizes fundamental problems rather than specific use cases, offers high task diversity, and is extensible to real-world machine learning GitHub repositories. Furthermore, we present a unified evaluation framework with five complementary metrics, designed to comprehensively assess agent performance on our benchmark. We evaluate state-of-the-art automatic research agents on FML-bench, and find that agents employing broad research exploration strategies outperform those focusing on narrow but deep exploration. These findings suggest that emphasizing the breadth of exploration may lead to more effective research outcomes than focusing solely on incremental refinement. Our benchmark is available at https://github.com/qrzou/FML-bench.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "212",
        "title": "MSF-Mamba: Motion-aware State Fusion Mamba for Efficient Micro-Gesture Recognition",
        "author": [
            "Deng Li",
            "Jun Shao",
            "Bohao Xing",
            "Rong Gao",
            "Bihan Wen",
            "Heikki KÃ¤lviÃ¤inen",
            "Xin Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10478",
        "abstract": "Micro-gesture recognition (MGR) targets the identification of subtle and fine-grained human motions and requires accurate modeling of both long-range and local spatiotemporal dependencies. While CNNs are effective at capturing local patterns, they struggle with long-range dependencies due to their limited receptive fields. Transformer-based models address this limitation through self-attention mechanisms but suffer from high computational costs. Recently, Mamba has shown promise as an efficient model, leveraging state space models (SSMs) to enable linear-time processing However, directly applying the vanilla Mamba to MGR may not be optimal. This is because Mamba processes inputs as 1D sequences, with state updates relying solely on the previous state, and thus lacks the ability to model local spatiotemporal dependencies. In addition, previous methods lack a design of motion-awareness, which is crucial in MGR. To overcome these limitations, we propose motion-aware state fusion mamba (MSF-Mamba), which enhances Mamba with local spatiotemporal modeling by fusing local contextual neighboring states. Our design introduces a motion-aware state fusion module based on central frame difference (CFD). Furthermore, a multiscale version named MSF-Mamba+ has been proposed. Specifically, MSF-Mamba supports multiscale motion-aware state fusion, as well as an adaptive scale weighting module that dynamically weighs the fused states across different scales. These enhancements explicitly address the limitations of vanilla Mamba by enabling motion-aware local spatiotemporal modeling, allowing MSF-Mamba and MSF-Mamba to effectively capture subtle motion cues for MGR. Experiments on two public MGR datasets demonstrate that even the lightweight version, namely, MSF-Mamba, achieves SoTA performance, outperforming existing CNN-, Transformer-, and SSM-based models while maintaining high efficiency.",
        "tags": [
            "Mamba",
            "SSMs",
            "Transformer"
        ]
    },
    {
        "id": "213",
        "title": "UltraLLaDA: Scaling the Context Length to 128K for Diffusion Large Language Models",
        "author": [
            "Guangxin He",
            "Shen Nie",
            "Fengqi Zhu",
            "Yuankang Zhao",
            "Tianyi Bai",
            "Ran Yan",
            "Jie Fu",
            "Chongxuan Li",
            "Binhang Yuan"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10481",
        "abstract": "Diffusion LLMs have attracted growing interest, with plenty of recent work emphasizing their great potential in various downstream tasks; yet the long-context behavior of diffusion LLMs remains largely uncharted. We present a case study of post-training techniques for extending the context window of diffusion LLMs (i.e., LLaDA) without retraining from scratch. We show that a simple modification to the standard Rotary Positional Embeddings (RoPE) extension effectively accommodates the probabilistic modeling inherent in the diffusion process, enabling stable scaling to longer context ranges. We further compare masking strategies used during post-training and analyze their impact on optimization stability and long-range recall. Instantiating these insights, we introduce UltraLLaDA, a diffusion LLM with a 128K-token context window that, in our empirical evaluation on long-context tasks, significantly outperforms training-free baselines. Our experimental results highlight the special positional extension as a key lever for scaling diffusion LLMs to extended contexts and offer practical guidance for practitioners seeking 128K-scale context via efficient post-training.",
        "tags": [
            "Diffusion",
            "LLM",
            "RoPE"
        ]
    },
    {
        "id": "214",
        "title": "Gradient Enhanced Self-Training Physics-Informed Neural Network (gST-PINN) for Solving Nonlinear Partial Differential Equations",
        "author": [
            "Narayan S Iyer",
            "Bivas Bhaumik",
            "Ram S Iyer",
            "Satyasaran Changdar"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10483",
        "abstract": "Partial differential equations (PDEs) provide a mathematical foundation for simulating and understanding intricate behaviors in both physical sciences and engineering. With the growing capabilities of deep learning, data$-$driven approaches like Physics$-$Informed Neural Networks (PINNs) have been developed, offering a mesh$-$free, analytic type framework for efficiently solving PDEs across a wide range of applications. However, traditional PINNs often struggle with challenges such as limited precision, slow training dynamics, lack of labeled data availability, and inadequate handling of multi$-$physics interactions. To overcome these challenging issues of PINNs, we proposed a Gradient Enhanced Self$-$Training PINN (gST$-$PINN) method that specifically introduces a gradient based pseudo point self$-$learning algorithm for solving PDEs. We tested the proposed method on three different types of PDE problems from various fields, each representing distinct scenarios. The effectiveness of the proposed method is evident, as the PINN approach for solving the Burgers$'$ equation attains a mean square error (MSE) on the order of $10^{-3}$, while the diffusion$-$sorption equation achieves an MSE on the order of $10^{-4}$ after 12,500 iterations, with no further improvement as the iterations increase. In contrast, the MSE for both PDEs in the gST$-$PINN model continues to decrease, demonstrating better generalization and reaching an MSE on the order of $10^{-5}$ after 18,500 iterations. Furthermore, the results show that the proposed purely semi$-$supervised gST$-$PINN consistently outperforms the standard PINN method in all cases, even when solution of the PDEs are unavailable. It generalizes both PINN and Gradient$-$enhanced PINN (gPINN), and can be effectively applied in scenarios prone to low accuracy and convergence issues, particularly in the absence of labeled data.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "215",
        "title": "SASER: Stego attacks on open-source LLMs",
        "author": [
            "Ming Tan",
            "Wei Li",
            "Hu Tao",
            "Hailong Ma",
            "Aodi Liu",
            "Qian Chen",
            "Zilong Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10486",
        "abstract": "Open-source large language models (LLMs) have demonstrated considerable dominance over proprietary LLMs in resolving neural processing tasks, thanks to the collaborative and sharing nature. Although full access to source codes, model parameters, and training data lays the groundwork for transparency, we argue that such a full-access manner is vulnerable to stego attacks, and their ill-effects are not fully understood. In this paper, we conduct a systematic formalization for stego attacks on open-source LLMs by enumerating all possible threat models associated with adversary objectives, knowledge, and capabilities. Therein, the threat posed by adversaries with internal knowledge, who inject payloads and triggers during the model sharing phase, is of practical interest. We go even further and propose the first stego attack on open-source LLMs, dubbed SASER, which wields impacts through identifying targeted parameters, embedding payloads, injecting triggers, and executing payloads sequentially. Particularly, SASER enhances the attack robustness against quantization-based local deployment by de-quantizing the embedded payloads. In addition, to achieve stealthiness, SASER devises the performance-aware importance metric to identify targeted parameters with the least degradation of model performance. Extensive experiments on LlaMA2-7B and ChatGLM3-6B, without quantization, show that the stealth rate of SASER outperforms existing stego attacks (for general DNNs) by up to 98.1%, while achieving the same attack success rate (ASR) of 100%. More importantly, SASER improves ASR on quantized models from 0 to 100% in all settings. We appeal for investigations on countermeasures against SASER in view of the significant attack effectiveness.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "216",
        "title": "Towards Self-Refinement of Vision-Language Models with Triangular Consistency",
        "author": [
            "Yunlong Deng",
            "Guangyi Chen",
            "Tianpei Gu",
            "Lingjing Kong",
            "Yan Li",
            "Zeyu Tang",
            "Kun Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10487",
        "abstract": "Vision-Language Models (VLMs) integrate visual knowledge with the analytical capabilities of Large Language Models (LLMs) through supervised visual instruction tuning, using image-question-answer triplets. However, the potential of VLMs trained without supervised instruction remains largely unexplored. This study validates that VLMs possess inherent self-refinement capabilities, enabling them to generate high-quality supervised data without external inputs and thereby learn autonomously. Specifically, to stimulate the self-refinement ability of VLMs, we propose a self-refinement framework based on a Triangular Consistency principle: within the image-query-answer triangle, any masked elements should be consistently and accurately reconstructed. The framework involves three steps: (1) We enable the instruction generation ability of VLMs by adding multi-task instruction tuning like image$\\rightarrow$question-answer or image-answer$\\rightarrow$question. (2) We generate image-query-answer triplets from unlabeled images and use the Triangular Consistency principle for filtering. (3) The model is further updated using the filtered synthetic data. To investigate the underlying mechanisms behind this self-refinement capability, we conduct a theoretical analysis from a causal perspective. Using the widely recognized LLaVA-1.5 as our baseline, our experiments reveal that the model can autonomously achieve consistent, though deliberately modest, improvements across multiple benchmarks without any external supervision, such as human annotations or environmental feedback. We expect that the insights of this study on the self-refinement ability of VLMs can inspire future research on the learning mechanism of VLMs. Code is available at https://github.com/dengyl20/SRF-LLaVA-1.5.",
        "tags": [
            "LLM",
            "LLaVA",
            "VLM"
        ]
    },
    {
        "id": "217",
        "title": "Head-wise Adaptive Rotary Positional Encoding for Fine-Grained Image Generation",
        "author": [
            "Jiaye Li",
            "Baoyou Chen",
            "Hui Li",
            "Zilong Dong",
            "Jingdong Wang",
            "Siyu Zhu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10489",
        "abstract": "Transformers rely on explicit positional encoding to model structure in data. While Rotary Position Embedding (RoPE) excels in 1D domains, its application to image generation reveals significant limitations such as fine-grained spatial relation modeling, color cues, and object counting. This paper identifies key limitations of standard multi-dimensional RoPE-rigid frequency allocation, axis-wise independence, and uniform head treatment-in capturing the complex structural biases required for fine-grained image generation. We propose HARoPE, a head-wise adaptive extension that inserts a learnable linear transformation parameterized via singular value decomposition (SVD) before the rotary mapping. This lightweight modification enables dynamic frequency reallocation, semantic alignment of rotary planes, and head-specific positional receptive fields while rigorously preserving RoPE's relative-position property. Extensive experiments on class-conditional ImageNet and text-to-image generation (Flux and MMDiT) demonstrate that HARoPE consistently improves performance over strong RoPE baselines and other extensions. The method serves as an effective drop-in replacement, offering a principled and adaptable solution for enhancing positional awareness in transformer-based image generative models.",
        "tags": [
            "FLUX",
            "RoPE",
            "Text-to-Image",
            "Transformer"
        ]
    },
    {
        "id": "218",
        "title": "The Hidden DNA of LLM-Generated JavaScript: Structural Patterns Enable High-Accuracy Authorship Attribution",
        "author": [
            "Norbert Tihanyi",
            "Bilel Cherif",
            "Richard A. Dubniczky",
            "Mohamed Amine Ferrag",
            "TamÃ¡s Bisztray"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10493",
        "abstract": "In this paper, we present the first large-scale study exploring whether JavaScript code generated by Large Language Models (LLMs) can reveal which model produced it, enabling reliable authorship attribution and model fingerprinting. With the rapid rise of AI-generated code, attribution is playing a critical role in detecting vulnerabilities, flagging malicious content, and ensuring accountability. While AI-vs-human detection usually treats AI as a single category we show that individual LLMs leave unique stylistic signatures, even among models belonging to the same family or parameter size. To this end, we introduce LLM-NodeJS, a dataset of 50,000 http://Node.js back-end programs from 20 large language models. Each has four transformed variants, yielding 250,000 unique JavaScript samples and two additional representations (JSIR and AST) for diverse research applications. Using this dataset, we benchmark traditional machine learning classifiers against fine-tuned Transformer encoders and introduce CodeT5-JSA, a custom architecture derived from the 770M-parameter CodeT5 model with its decoder removed and a modified classification head. It achieves 95.8% accuracy on five-class attribution, 94.6% on ten-class, and 88.5% on twenty-class tasks, surpassing other tested models such as BERT, CodeBERT, and Longformer. We demonstrate that classifiers capture deeper stylistic regularities in program dataflow and structure, rather than relying on surface-level features. As a result, attribution remains effective even after mangling, comment removal, and heavy code transformations. To support open science and reproducibility, we release the LLM-NodeJS dataset, Google Colab training scripts, and all related materials on GitHub: https://github.com/LLM-NodeJS-dataset.",
        "tags": [
            "BERT",
            "Detection",
            "LLM",
            "Transformer"
        ]
    },
    {
        "id": "219",
        "title": "Jigsaw3D: Disentangled 3D Style Transfer via Patch Shuffling and Masking",
        "author": [
            "Yuteng Ye",
            "Zheng Zhang",
            "Qinchuan Zhang",
            "Di Wang",
            "Youjia Zhang",
            "Wenxiao Zhang",
            "Wei Yang",
            "Yuan Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10497",
        "abstract": "Controllable 3D style transfer seeks to restyle a 3D asset so that its textures match a reference image while preserving the integrity and multi-view consistency. The prevalent methods either rely on direct reference style token injection or score-distillation from 2D diffusion models, which incurs heavy per-scene optimization and often entangles style with semantic content. We introduce Jigsaw3D, a multi-view diffusion based pipeline that decouples style from content and enables fast, view-consistent stylization. Our key idea is to leverage the jigsaw operation - spatial shuffling and random masking of reference patches - to suppress object semantics and isolate stylistic statistics (color palettes, strokes, textures). We integrate these style cues into a multi-view diffusion model via reference-to-view cross-attention, producing view-consistent stylized renderings conditioned on the input mesh. The renders are then style-baked onto the surface to yield seamless textures. Across standard 3D stylization benchmarks, Jigsaw3D achieves high style fidelity and multi-view consistency with substantially lower latency, and generalizes to masked partial reference stylization, multi-object scene styling, and tileable texture generation. Project page is available at: https://babahui.github.io/jigsaw3D.github.io/",
        "tags": [
            "3D",
            "Diffusion",
            "Style Transfer"
        ]
    },
    {
        "id": "220",
        "title": "Align2Act: Instruction-Tuned Models for Human-Aligned Autonomous Driving",
        "author": [
            "Kanishkha Jaisankar",
            "Sunidhi Tandel"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10503",
        "abstract": "Motion planning in complex scenarios is a core challenge in autonomous driving. Conventional methods apply predefined rules or learn from driving data to generate trajectories, while recent approaches leverage large language models (LLMs) for decision-making. However, it remains unclear whether LLMs truly capture human driving logic. We propose Align2Act, a motion planning framework that transforms instruction-tuned LLMs into interpretable planners aligned with human behavior. We derive structured driving instructions based on human reasoning patterns (e.g., anticipate hazards, yield at intersections) and traffic rules (e.g., stop at red lights, maintain lane boundaries). Our Align2ActChain module guides step-by-step reasoning to produce both an interpretable rationale and a safe trajectory. By fine-tuning LLaMA-2-7B with LoRA on one million scenarios from the nuPlan dataset, our method achieves an open-loop score of 85.17 and closed-loop scores of 70.31 (non-reactive) and 66.96 (reactive) on Test14-random. Unlike prior work focused on synthetic or open-loop settings, we demonstrate improved planning quality and human-likeness on the real-world nuPlan closed-loop benchmark. Ablation studies confirm that structured reasoning significantly improves performance over baseline LLM planners.",
        "tags": [
            "LLM",
            "LLaMA",
            "LoRA"
        ]
    },
    {
        "id": "221",
        "title": "SuperEx: Enhancing Indoor Mapping and Exploration using Non-Line-of-Sight Perception",
        "author": [
            "Kush Garg",
            "Akshat Dave"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10506",
        "abstract": "Efficient exploration and mapping in unknown indoor environments is a fundamental challenge, with high stakes in time-critical settings. In current systems, robot perception remains confined to line-of-sight; occluded regions remain unknown until physically traversed, leading to inefficient exploration when layouts deviate from prior assumptions. In this work, we bring non-line-of-sight (NLOS) sensing to robotic exploration. We leverage single-photon LiDARs, which capture time-of-flight histograms that encode the presence of hidden objects - allowing robots to look around blind corners. Recent single-photon LiDARs have become practical and portable, enabling deployment beyond controlled lab settings. Prior NLOS works target 3D reconstruction in static, lab-based scenarios, and initial efforts toward NLOS-aided navigation consider simplified geometries. We introduce SuperEx, a framework that integrates NLOS sensing directly into the mapping-exploration loop. SuperEx augments global map prediction with beyond-line-of-sight cues by (i) carving empty NLOS regions from timing histograms and (ii) reconstructing occupied structure via a two-step physics-based and data-driven approach that leverages structural regularities. Evaluations on complex simulated maps and the real-world KTH Floorplan dataset show a 12% gain in mapping accuracy under < 30% coverage and improved exploration efficiency compared to line-of-sight baselines, opening a path to reliable mapping beyond direct visibility.",
        "tags": [
            "3D",
            "Robotics"
        ]
    },
    {
        "id": "222",
        "title": "MARS-Sep: Multimodal-Aligned Reinforced Sound Separation",
        "author": [
            "Zihan Zhang",
            "Xize Cheng",
            "Zhennan Jiang",
            "Dongjie Fu",
            "Jingyuan Chen",
            "Zhou Zhao",
            "Tao Jin"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10509",
        "abstract": "Universal sound separation faces a fundamental misalignment: models optimized for low-level signal metrics often produce semantically contaminated outputs, failing to suppress perceptually salient interference from acoustically similar sources. To bridge this gap, we introduce MARS-Sep, a reinforcement learning framework that reformulates separation as decision making. Instead of simply regressing ground-truth masks, MARS-Sep learns a factorized Beta mask policy that is optimized by a clipped trust-region surrogate with entropy regularization and group-relative advantage normalization. Concretely, we sample masks from a frozen old policy, reconstruct waveforms, and update the current policy using clipped importance ratios-yielding substantially more stable and sample-efficient learning. Multimodal rewards, derived from an audio-text-vision encoder, directly incentivize semantic consistency with query prompts. We further propose a progressive alignment scheme to fine-tune this encoder, boosting its cross-modal discriminability and improving reward faithfulness. Extensive experiments on multiple benchmarks demonstrate consistent gains in Text-, Audio-, and Image-Queried separation, with notable improvements in signal metrics and semantic quality. Our code is available at https://anonymous.4open.science/r/MARS-Sep. Sound separation samples are available at https://mars-sep.github.io/.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "223",
        "title": "f-INE: A Hypothesis Testing Framework for Estimating Influence under Training Randomness",
        "author": [
            "Subhodip Panda",
            "Dhruv Tarsadiya",
            "Shashwat Sourav",
            "Prathosh A.P",
            "Sai Praneeth Karimireddy"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10510",
        "abstract": "Influence estimation methods promise to explain and debug machine learning by estimating the impact of individual samples on the final model. Yet, existing methods collapse under training randomness: the same example may appear critical in one run and irrelevant in the next. Such instability undermines their use in data curation or cleanup since it is unclear if we indeed deleted/kept the correct datapoints. To overcome this, we introduce *f-influence* -- a new influence estimation framework grounded in hypothesis testing that explicitly accounts for training randomness, and establish desirable properties that make it suitable for reliable influence estimation. We also design a highly efficient algorithm **f**-**IN**fluence **E**stimation (**f-INE**) that computes f-influence **in a single training run**. Finally, we scale up f-INE to estimate influence of instruction tuning data on Llama-3.1-8B and show it can reliably detect poisoned samples that steer model opinions, demonstrating its utility for data cleanup and attributing model behavior.",
        "tags": [
            "LLaMA"
        ]
    },
    {
        "id": "224",
        "title": "Population-Coded Spiking Neural Networks for High-Dimensional Robotic Control",
        "author": [
            "Kanishkha Jaisankar",
            "Xiaoyang Jiang",
            "Feifan Liao",
            "Jeethu Sreenivas Amuthan"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10516",
        "abstract": "Energy-efficient and high-performance motor control remains a critical challenge in robotics, particularly for high-dimensional continuous control tasks with limited onboard resources. While Deep Reinforcement Learning (DRL) has achieved remarkable results, its computational demands and energy consumption limit deployment in resource-constrained environments. This paper introduces a novel framework combining population-coded Spiking Neural Networks (SNNs) with DRL to address these challenges. Our approach leverages the event-driven, asynchronous computation of SNNs alongside the robust policy optimization capabilities of DRL, achieving a balance between energy efficiency and control performance. Central to this framework is the Population-coded Spiking Actor Network (PopSAN), which encodes high-dimensional observations into neuronal population activities and enables optimal policy learning through gradient-based updates. We evaluate our method on the Isaac Gym platform using the PixMC benchmark with complex robotic manipulation tasks. Experimental results on the Franka robotic arm demonstrate that our approach achieves energy savings of up to 96.10% compared to traditional Artificial Neural Networks (ANNs) while maintaining comparable control performance. The trained SNN policies exhibit robust finger position tracking with minimal deviation from commanded trajectories and stable target height maintenance during pick-and-place operations. These results position population-coded SNNs as a promising solution for energy-efficient, high-performance robotic control in resource-constrained applications, paving the way for scalable deployment in real-world robotics systems.",
        "tags": [
            "RL",
            "Robotics"
        ]
    },
    {
        "id": "225",
        "title": "ECO: Enhanced Code Optimization via Performance-Aware Prompting for Code-LLMs",
        "author": [
            "Su-Hyeon Kim",
            "Joonghyuk Hahn",
            "Sooyoung Cha",
            "Yo-Sub Han"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10517",
        "abstract": "Code runtime optimization-the task of rewriting a given code to a faster one-remains challenging, as it requires reasoning about performance trade-offs involving algorithmic and structural choices. Recent approaches employ code-LLMs with slow-fast code pairs provided as optimization guidance, but such pair-based methods obscure the causal factors of performance gains and often lead to superficial pattern imitation rather than genuine performance reasoning. We introduce ECO, a performance-aware prompting framework for code optimization. ECO first distills runtime optimization instructions (ROIs) from reference slow-fast code pairs; Each ROI describes root causes of inefficiency and the rationales that drive performance improvements. For a given input code, ECO in parallel employs (i) a symbolic advisor to produce a bottleneck diagnosis tailored to the code, and (ii) an ROI retriever to return related ROIs. These two outputs are then composed into a performance-aware prompt, providing actionable guidance for code-LLMs. ECO's prompts are model-agnostic, require no fine-tuning, and can be easily prepended to any code-LLM prompt. Our empirical studies highlight that ECO prompting significantly improves code-LLMs' ability to generate efficient code, achieving speedups of up to 7.81x while minimizing correctness loss.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "226",
        "title": "VR-Thinker: Boosting Video Reward Models through Thinking-with-Image Reasoning",
        "author": [
            "Qunzhong Wang",
            "Jie Liu",
            "Jiajun Liang",
            "Yilei Jiang",
            "Yuanxing Zhang",
            "Jinyuan Chen",
            "Yaozhi Zheng",
            "Xintao Wang",
            "Pengfei Wan",
            "Xiangyu Yue",
            "Jiaheng Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10518",
        "abstract": "Recent advancements in multimodal reward models (RMs) have substantially improved post-training for visual generative models. However, current RMs face inherent limitations: (1) visual inputs consume large context budgets, forcing fewer frames and causing loss of fine-grained details; and (2) all visual information is packed into the initial prompt, exacerbating hallucination and forgetting during chain-of-thought reasoning. To overcome these issues, we introduce VideoReward Thinker (VR-Thinker), a thinking-with-image framework that equips the RM with visual reasoning operations (e.g., select frame) and a configurable visual memory window. This allows the RM to actively acquire and update visual evidence within context limits, improving reasoning fidelity and reliability. We activate visual reasoning via a reinforcement fine-tuning pipeline: (i) Cold Start with curated visual chain-of-thought data to distill basic reasoning skills and operation formatting; (ii) select samples whose per-dimension and overall judgments are all correct, then conduct Rejection sampling Fine-Tuning on these high-quality traces to further enhance reasoning; and (iii) apply Group Relative Policy Optimization (GRPO) to strengthen reasoning. Our approach delivers state-of-the-art accuracy among open-source models on video preference benchmarks, especially for longer videos: a 7B VR-Thinker achieves 80.5% on VideoGen Reward, 82.3% on GenAI-Bench, and 75.6% on MJ-Bench-Video. These results validate the effectiveness and promise of thinking-with-image multimodal reward modeling.",
        "tags": [
            "CoT",
            "GRPO"
        ]
    },
    {
        "id": "227",
        "title": "AI-Agents for Culturally Diverse Online Higher Education Environments",
        "author": [
            "Fuze Sun",
            "Paul Craig",
            "Lingyu Li",
            "Shixiangyue Meng",
            "Chuxi Nan"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10520",
        "abstract": "As the global reach of online higher education continues to grow, universities are increasingly accommodating students from diverse cultural backgrounds \\parencite{tereshko2024culturally}. This can present a number of challenges including linguistic barriers \\parencite{ullah2021linguistic}, cultural differences in learning style \\parencite{omidvar2012cultural}, cultural sensitivity in course design \\parencite{nguyen2022cultural} and perceived isolation when students feel their perspectives or experiences are not reflected or valued in the learning environment \\parencite{hansen2022belonging}. Ensuring active engagement and reasonable learning outcomes in such a environments requires distance educational systems that are not only adaptive but also culturally resonant \\parencite{dalle2024cultural}. Both embodied and virtual AI-Agents have great potential in this regard as they can facilitate personalized learning and adapt their interactions and content delivery to align with students' cultural context. In addition Generative AI (GAI), such as, Large Language Models (LLMs) can amplify the potential for these culturally aware AI agents to address educational challenges due to their advanced capacity for understanding and generating contextually relevant content \\parencite{wang2024large}. This chapter reviews existing research and suggests the usage of culturally aware AI-Agents, powered by GAI, to foster engagement and improve learning outcomes in culturally diverse online higher education environments.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "228",
        "title": "Merlin's Whisper: Enabling Efficient Reasoning in LLMs via Black-box Adversarial Prompting",
        "author": [
            "Heming Xia",
            "Cunxiao Du",
            "Rui Li",
            "Chak Tou Leong",
            "Yongqi Li",
            "Wenjie Li"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10528",
        "abstract": "Large reasoning models (LRMs) have demonstrated remarkable proficiency in tackling complex reasoning tasks through step-by-step thinking. However, such a lengthy reasoning process incurs substantial computational and latency overheads, hindering the practical deployment of these models. In this work, we present a new perspective on mitigating overthinking in LRMs via black-box adversarial prompting. By treating both open-source LRMs and closed-source APIs as black-box communicators, we investigate how to elicit concise responses without sacrificing accuracy. We introduce AdvPrompt, an iterative refinement framework that generates high-quality adversarial prompts from diverse perspectives. Experiments across multiple benchmarks demonstrate that AdvPrompt consistently reduces token usage while preserving performance. Notably, AdvPrompt achieves a 3x reduction in average response length on simple GSM8K questions for the Qwen3 model series, and delivers an average ~40% token reduction across four benchmarks. For closed-source APIs, AdvPrompt reduces token usage on MATH-500 by 35% for Claude-3.7 and 47% for Gemini-2.5. Further analysis reveals the generalizability of AdvPrompt across various model scales and families, underscoring the potential of black-box prompting as a practical and effective strategy for enhancing LRM efficiency.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "229",
        "title": "Reinforced Domain Selection for Continuous Domain Adaptation",
        "author": [
            "Hanbing Liu",
            "Huaze Tang",
            "Yanru Wu",
            "Yang Li",
            "Xiao-Ping Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10530",
        "abstract": "Continuous Domain Adaptation (CDA) effectively bridges significant domain shifts by progressively adapting from the source domain through intermediate domains to the target domain. However, selecting intermediate domains without explicit metadata remains a substantial challenge that has not been extensively explored in existing studies. To tackle this issue, we propose a novel framework that combines reinforcement learning with feature disentanglement to conduct domain path selection in an unsupervised CDA setting. Our approach introduces an innovative unsupervised reward mechanism that leverages the distances between latent domain embeddings to facilitate the identification of optimal transfer paths. Furthermore, by disentangling features, our method facilitates the calculation of unsupervised rewards using domain-specific features and promotes domain adaptation by aligning domain-invariant features. This integrated strategy is designed to simultaneously optimize transfer paths and target task performance, enhancing the effectiveness of domain adaptation processes. Extensive empirical evaluations on datasets such as Rotated MNIST and ADNI demonstrate substantial improvements in prediction accuracy and domain selection efficiency, establishing our method's superiority over traditional CDA approaches.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "230",
        "title": "Layout-Independent License Plate Recognition via Integrated Vision and Language Models",
        "author": [
            "Elham Shabaninia",
            "Fatemeh Asadi-zeydabadi",
            "Hossein Nezamabadi-pour"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10533",
        "abstract": "This work presents a pattern-aware framework for automatic license plate recognition (ALPR), designed to operate reliably across diverse plate layouts and challenging real-world conditions. The proposed system consists of a modern, high-precision detection network followed by a recognition stage that integrates a transformer-based vision model with an iterative language modelling mechanism. This unified recognition stage performs character identification and post-OCR refinement in a seamless process, learning the structural patterns and formatting rules specific to license plates without relying on explicit heuristic corrections or manual layout classification. Through this design, the system jointly optimizes visual and linguistic cues, enables iterative refinement to improve OCR accuracy under noise, distortion, and unconventional fonts, and achieves layout-independent recognition across multiple international datasets (IR-LPR, UFPR-ALPR, AOLP). Experimental results demonstrate superior accuracy and robustness compared to recent segmentation-free approaches, highlighting how embedding pattern analysis within the recognition stage bridges computer vision and language modelling for enhanced adaptability in intelligent transportation and surveillance applications.",
        "tags": [
            "Detection",
            "Segmentation",
            "Transformer"
        ]
    },
    {
        "id": "231",
        "title": "Detecting Hallucinations in Authentic LLM-Human Interactions",
        "author": [
            "Yujie Ren",
            "Niklas Gruhlke",
            "Anne Lauscher"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10539",
        "abstract": "As large language models (LLMs) are increasingly applied in sensitive domains such as medicine and law, hallucination detection has become a critical task. Although numerous benchmarks have been proposed to advance research in this area, most of them are artificially constructed--either through deliberate hallucination induction or simulated interactions--rather than derived from genuine LLM-human dialogues. Consequently, these benchmarks fail to fully capture the characteristics of hallucinations that occur in real-world usage. To address this limitation, we introduce AuthenHallu, the first hallucination detection benchmark built entirely from authentic LLM-human interactions. For AuthenHallu, we select and annotate samples from genuine LLM-human dialogues, thereby providing a faithful reflection of how LLMs hallucinate in everyday user interactions. Statistical analysis shows that hallucinations occur in 31.4% of the query-response pairs in our benchmark, and this proportion increases dramatically to 60.0% in challenging domains such as Math & Number Problems. Furthermore, we explore the potential of using vanilla LLMs themselves as hallucination detectors and find that, despite some promise, their current performance remains insufficient in real-world scenarios.",
        "tags": [
            "Detection",
            "LLM"
        ]
    },
    {
        "id": "232",
        "title": "Rethinking RL Evaluation: Can Benchmarks Truly Reveal Failures of RL Methods?",
        "author": [
            "Zihan Chen",
            "Yiming Zhang",
            "Hengguang Zhou",
            "Zenghui Ding",
            "Yining Sun",
            "Cho-Jui Hsieh"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10541",
        "abstract": "Current benchmarks are inadequate for evaluating progress in reinforcement learning (RL) for large language models (LLMs).Despite recent benchmark gains reported for RL, we find that training on these benchmarks' training sets achieves nearly the same performance as training directly on the test sets, suggesting that the benchmarks cannot reliably separate further http://progress.To study this phenomenon, we introduce a diagnostic suite and the Oracle Performance Gap (OPG) metric that quantifies the performance difference between training on the train split versus the test split of a benchmark. We further analyze this phenomenon with stress tests and find that, despite strong benchmark scores, existing RL methods struggle to generalize across distribution shifts, varying levels of difficulty, and counterfactual scenarios: shortcomings that current benchmarks fail to http://reveal.We conclude that current benchmarks are insufficient for evaluating generalization and propose three core principles for designing more faithful benchmarks: sufficient difficulty, balanced evaluation, and distributional robustness.",
        "tags": [
            "LLM",
            "RL"
        ]
    },
    {
        "id": "233",
        "title": "PAC-Bayesian Reinforcement Learning Trains Generalizable Policies",
        "author": [
            "Abdelkrim Zitouni",
            "Mehdi Hennequin",
            "Juba Agoun",
            "Ryan Horache",
            "Nadia Kabachi",
            "Omar Rivasplata"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10544",
        "abstract": "We derive a novel PAC-Bayesian generalization bound for reinforcement learning that explicitly accounts for Markov dependencies in the data, through the chain's mixing time. This contributes to overcoming challenges in obtaining generalization guarantees for reinforcement learning, where the sequential nature of data breaks the independence assumptions underlying classical bounds. Our bound provides non-vacuous certificates for modern off-policy algorithms like Soft Actor-Critic. We demonstrate the bound's practical utility through PB-SAC, a novel algorithm that optimizes the bound during training to guide exploration. Experiments across continuous control tasks show that our approach provides meaningful confidence certificates while maintaining competitive performance.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "234",
        "title": "ELAIPBench: A Benchmark for Expert-Level Artificial Intelligence Paper Understanding",
        "author": [
            "Xinbang Dai",
            "Huikang Hu",
            "Yongrui Chen",
            "Jiaqi Li",
            "Rihui Jin",
            "Yuyang Zhang",
            "Xiaoguang Li",
            "Lifeng Shang",
            "Guilin Qi"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10549",
        "abstract": "While large language models (LLMs) excel at many domain-specific tasks, their ability to deeply comprehend and reason about full-length academic papers remains underexplored. Existing benchmarks often fall short of capturing such depth, either due to surface-level question design or unreliable evaluation metrics. To address this gap, we introduce ELAIPBench, a benchmark curated by domain experts to evaluate LLMs' comprehension of artificial intelligence (AI) research papers. Developed through an incentive-driven, adversarial annotation process, ELAIPBench features 403 multiple-choice questions from 137 papers. It spans three difficulty levels and emphasizes non-trivial reasoning rather than shallow retrieval. Our experiments show that the best-performing LLM achieves an accuracy of only 39.95%, far below human performance. Moreover, we observe that frontier LLMs equipped with a thinking mode or a retrieval-augmented generation (RAG) system fail to improve final results-even harming accuracy due to overthinking or noisy retrieval. These findings underscore the significant gap between current LLM capabilities and genuine comprehension of academic papers.",
        "tags": [
            "LLM",
            "RAG"
        ]
    },
    {
        "id": "235",
        "title": "How Students Use Generative AI for Software Testing: An Observational Study",
        "author": [
            "Baris Ardic",
            "Quentin Le Dilavrec",
            "Andy Zaidman"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10551",
        "abstract": "The integration of generative AI tools like ChatGPT into software engineering workflows opens up new opportunities to boost productivity in tasks such as unit test engineering. However, these AI-assisted workflows can also significantly alter the developer's role, raising concerns about control, output quality, and learning, particularly for novice developers. This study investigates how novice software developers with foundational knowledge in software testing interact with generative AI for engineering unit tests. Our goal is to examine the strategies they use, how heavily they rely on generative AI, and the benefits and challenges they perceive when using generative AI-assisted approaches for test engineering. We conducted an observational study involving 12 undergraduate students who worked with generative AI for unit testing tasks. We identified four interaction strategies, defined by whether the test idea or the test implementation originated from generative AI or the participant. Additionally, we singled out prompting styles that focused on one-shot or iterative test generation, which often aligned with the broader interaction strategy. Students reported benefits including time-saving, reduced cognitive load, and support for test ideation, but also noted drawbacks such as diminished trust, test quality concerns, and lack of ownership. While strategy and prompting styles influenced workflow dynamics, they did not significantly affect test effectiveness or test code quality as measured by mutation score or test smells.",
        "tags": [
            "GPT"
        ]
    },
    {
        "id": "236",
        "title": "BitMar: Low-Bit Multimodal Fusion with Episodic Memory for Edge Devices",
        "author": [
            "Euhid Aman",
            "Esteban Carlin",
            "Hsing-Kuo Pao",
            "Giovanni Beltrame",
            "Ghaluh Indah Permata Sari",
            "Yie-Tarng Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10560",
        "abstract": "Cross-attention transformers and other multimodal vision-language models excel at grounding and generation; however, their extensive, full-precision backbones make it challenging to deploy them on edge devices. Memory-augmented architectures enhance the utilization of past context; however, most works rarely pair them with aggressive edge-oriented quantization. We introduce BitMar, a quantized multimodal transformer that proposes an external human-like episodic memory for effective image-text generation on hardware with limited resources. BitMar utilizes 1.58-bit encoders, one for text (BitNet-style) and one for vision (DiNOv2-based), to create compact embeddings that are combined and used to query a fixed-size key-value episodic memory. During vector retrieval, the BitNet decoder applies per-layer conditioning, which increases the contextual relevance of generated content. The decoder also employs attention sinks with a sliding-window mechanism to process long or streaming inputs under tight memory budgets. The combination of per-layer conditioning and sliding-window attention achieves a strong quality-speed trade-off, delivering competitive captioning and multimodal understanding at low latency with a small model footprint. These characteristics make BitMar well-suited for edge deployment.",
        "tags": [
            "Transformer",
            "VLM"
        ]
    },
    {
        "id": "237",
        "title": "Reinforcement Learning-based Dynamic Adaptation for Sampling-Based Motion Planning in Agile Autonomous Driving",
        "author": [
            "Alexander Langmann",
            "Yevhenii Tokarev",
            "Mattia Piccinini",
            "Korbinian Moller",
            "Johannes Betz"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10567",
        "abstract": "Sampling-based trajectory planners are widely used for agile autonomous driving due to their ability to generate fast, smooth, and kinodynamically feasible trajectories. However, their behavior is often governed by a cost function with manually tuned, static weights, which forces a tactical compromise that is suboptimal across the wide range of scenarios encountered in a race. To address this shortcoming, we propose using a Reinforcement Learning (RL) agent as a high-level behavioral selector that dynamically switches the cost function parameters of an analytical, low-level trajectory planner during runtime. We show the effectiveness of our approach in simulation in an autonomous racing environment where our RL-based planner achieved 0% collision rate while reducing overtaking time by up to 60% compared to state-of-the-art static planners. Our new agent now dynamically switches between aggressive and conservative behaviors, enabling interactive maneuvers unattainable with static configurations. These results demonstrate that integrating reinforcement learning as a high-level selector resolves the inherent trade-off between safety and competitiveness in autonomous racing planners. The proposed methodology offers a pathway toward adaptive yet interpretable motion planning for broader autonomous driving applications.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "238",
        "title": "Injecting Frame-Event Complementary Fusion into Diffusion for Optical Flow in Challenging Scenes",
        "author": [
            "Haonan Wang",
            "Hanyu Zhou",
            "Haoyue Liu",
            "Luxin Yan"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10577",
        "abstract": "Optical flow estimation has achieved promising results in conventional scenes but faces challenges in high-speed and low-light scenes, which suffer from motion blur and insufficient illumination. These conditions lead to weakened texture and amplified noise and deteriorate the appearance saturation and boundary completeness of frame cameras, which are necessary for motion feature matching. In degraded scenes, the frame camera provides dense appearance saturation but sparse boundary completeness due to its long imaging time and low dynamic range. In contrast, the event camera offers sparse appearance saturation, while its short imaging time and high dynamic range gives rise to dense boundary completeness. Traditionally, existing methods utilize feature fusion or domain adaptation to introduce event to improve boundary completeness. However, the appearance features are still deteriorated, which severely affects the mostly adopted discriminative models that learn the mapping from visual features to motion fields and generative models that generate motion fields based on given visual features. So we introduce diffusion models that learn the mapping from noising flow to clear flow, which is not affected by the deteriorated visual features. Therefore, we propose a novel optical flow estimation framework Diff-ABFlow based on diffusion models with frame-event appearance-boundary fusion.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "239",
        "title": "AQORA: A Learned Adaptive Query Optimizer for Spark SQL",
        "author": [
            "Jiahao He",
            "Yutao Cui",
            "Cuiping Li",
            "Jikang Jiang",
            "Yuheng Hou",
            "Hong Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10580",
        "abstract": "Recent studies have identified two main approaches to improve query optimization: learned query optimization (LQO), which generates or selects better query plans before execution based on models trained in advance, and adaptive query processing (AQP), which adapts the query plan during execution based on statistical feedback collected at runtime. Although both approaches have shown promise, they also face critical limitations. LQO must commit to a fixed plan without access to actual cardinalities and typically rely on a single end-to-end feedback signal, making learning inefficient. On the other hand, AQP depends heavily on rule-based heuristics and lacks the ability to learn from experience. In this paper, we present AQORA, an adaptive query optimizer with a reinforcement learning architecture that combines the strengths of both LQO and AQP. AQORA addresses the above challenges through four core strategies: (1) realistic feature encoding, (2) query stage-level feedback and intervention, (3) automatic strategy adaptation, and (4) low-cost integration. Experiments show that AQORA reduces end-to-end execution time by up to 90% compared to other learned methods and by up to 70% compared to Spark SQL's default configuration with adaptive query execution.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "240",
        "title": "GraphTracer: Graph-Guided Failure Tracing in LLM Agents for Robust Multi-Turn Deep Search",
        "author": [
            "Heng Zhang",
            "Yuling Shi",
            "Xiaodong Gu",
            "Haochen You",
            "Zijian Zhang",
            "Lubin Gan",
            "Yilei Yuan",
            "Jin Huang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10581",
        "abstract": "Multi-agent systems powered by Large Language Models excel at complex tasks through coordinated collaboration, yet they face high failure rates in multi-turn deep search scenarios. Existing temporal attribution methods struggle to accurately diagnose root causes, particularly when errors propagate across multiple agents. Attempts to automate failure attribution by analyzing action sequences remain ineffective due to their inability to account for information dependencies that span agents. This paper identifies two core challenges: \\textit{(i) distinguishing symptoms from root causes in multi-agent error propagation}, and \\textit{(ii) tracing information dependencies beyond temporal order}. To address these issues, we introduce \\textbf{GraphTracer}, a framework that redefines failure attribution through information flow analysis. GraphTracer constructs Information Dependency Graphs (IDGs) to explicitly capture how agents reference and build on prior outputs. It localizes root causes by tracing through these dependency structures instead of relying on temporal sequences. GraphTracer also uses graph-aware synthetic data generation to target critical nodes, creating realistic failure scenarios. Evaluations on the Who\\&When benchmark and integration into production systems demonstrate that GraphTracer-8B achieves up to 18.18\\% higher attribution accuracy compared to state-of-the-art models and enables 4.8\\% to 14.2\\% performance improvements in deployed multi-agent frameworks, establishing a robust solution for multi-agent system debugging.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "241",
        "title": "Equipping Vision Foundation Model with Mixture of Experts for Out-of-Distribution Detection",
        "author": [
            "Shizhen Zhao",
            "Jiahui Liu",
            "Xin Wen",
            "Haoru Tan",
            "Xiaojuan Qi"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10584",
        "abstract": "Pre-trained vision foundation models have transformed many computer vision tasks. Despite their strong ability to learn discriminative and generalizable features crucial for out-of-distribution (OOD) detection, their impact on this task remains underexplored. Motivated by this gap, we systematically investigate representative vision foundation models for OOD detection. Our findings reveal that a pre-trained DINOv2 model, even without fine-tuning on in-domain (ID) data, naturally provides a highly discriminative feature space for OOD detection, achieving performance comparable to existing state-of-the-art methods without requiring complex designs. Beyond this, we explore how fine-tuning foundation models on in-domain (ID) data can enhance OOD detection. However, we observe that the performance of vision foundation models remains unsatisfactory in scenarios with a large semantic space. This is due to the increased complexity of decision boundaries as the number of categories grows, which complicates the optimization process. To mitigate this, we propose the Mixture of Feature Experts (MoFE) module, which partitions features into subspaces, effectively capturing complex data distributions and refining decision boundaries. Further, we introduce a Dynamic-$\\beta$ Mixup strategy, which samples interpolation weights from a dynamic beta distribution. This adapts to varying levels of learning difficulty across categories, improving feature learning for more challenging categories. Extensive experiments demonstrate the effectiveness of our approach, significantly outperforming baseline methods.",
        "tags": [
            "Detection",
            "MoE"
        ]
    },
    {
        "id": "242",
        "title": "D3MAS: Decompose, Deduce, and Distribute for Enhanced Knowledge Sharing in Multi-Agent Systems",
        "author": [
            "Heng Zhang",
            "Yuling Shi",
            "Xiaodong Gu",
            "Haochen You",
            "Zijian Zhang",
            "Lubin Gan",
            "Yilei Yuan",
            "Jin Huang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10585",
        "abstract": "Multi-agent systems powered by large language models exhibit strong capabilities in collaborative problem-solving. However, these systems suffer from substantial knowledge redundancy. Agents duplicate efforts in retrieval and reasoning processes. This inefficiency stems from a deeper issue: current architectures lack mechanisms to ensure agents share minimal sufficient information at each operational stage. Empirical analysis reveals an average knowledge duplication rate of 47.3\\% across agent communications. We propose D3MAS (Decompose, Deduce, and Distribute), a hierarchical coordination framework addressing redundancy through structural design rather than explicit optimization. The framework organizes collaboration across three coordinated layers. Task decomposition filters irrelevant sub-problems early. Collaborative reasoning captures complementary inference paths across agents. Distributed memory provides access to non-redundant knowledge. These layers coordinate through structured message passing in a unified heterogeneous graph. This cross-layer alignment ensures information remains aligned with actual task needs. Experiments on four challenging datasets show that D3MAS consistently improves reasoning accuracy by 8.7\\% to 15.6\\% and reduces knowledge redundancy by 46\\% on average.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "243",
        "title": "A Layered Intuition -- Method Model with Scope Extension for LLM Reasoning",
        "author": [
            "Hong Su"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10592",
        "abstract": "Existing studies have introduced method-based reasoning and scope extension as approaches to enhance Large Language Model (LLM) performance beyond direct matrix mappings. Building on these foundations, this paper summarizes and integrates these ideas into a unified Intuition-Method Layered Model with Scope Extension, designed to address indirected (unseen) issues more systematically. In this framework, intuition-based thinking provides rapid first-reaction answers, while method-based thinking decouples questions and solutions into transferable reasoning units. Scope extension is then applied to broaden applicability, including vertical (cause analysis), horizontal (parallel and generalized issues), and for the first time, temporal and spatial extensions, which expand reasoning across time and contextual dimensions. These extensions are organized into systematic knowledge trees that interconnect into a knowledge network, thereby increasing adaptability. To quantitatively evaluate this process, we propose the entropy of method extension, which measures the independence and diversity of extensions as an indicator of the system's capacity to solve unseen questions. By logically connecting existing approaches with new extensions and introducing an entropy-based evaluation framework, this work advances toward a more robust and extensible reasoning paradigm for LLMs in real-world problem-solving.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "244",
        "title": "EA4LLM: A Gradient-Free Approach to Large Language Model Optimization via Evolutionary Algorithms",
        "author": [
            "WenTao Liu",
            "Siyu Song",
            "Hao Hao",
            "Aimin Zhou"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10603",
        "abstract": "In recent years, large language models (LLMs) have made remarkable progress, with model optimization primarily relying on gradient-based optimizers such as Adam. However, these gradient-based methods impose stringent hardware requirements, demanding high-concurrency, high-memory GPUs. Moreover, they require all neural network operations to be differentiable, thereby excluding many promising non-differentiable architectures from practical use. To address these limitations, we propose a method for optimizing LLMs using evolutionary algorithms (EA4LLM) and, for the first time, successfully demonstrate its capability to train a 1-billion-parameter LLM from the pre-trained stage. We conduct extensive experiments and provide key insights into how evolutionary algorithms can effectively optimize neural networks. Our work challenges the prevailing assumption that gradient-based optimization is the only viable approach for training neural networks. It also holds significant potential to reduce the computational cost of training large language models, thereby enabling groups with limited computational resources to participate in deep learning research.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "245",
        "title": "ViSurf: Visual Supervised-and-Reinforcement Fine-Tuning for Large Vision-and-Language Models",
        "author": [
            "Yuqi Liu",
            "Liangyu Chen",
            "Jiazhen Liu",
            "Mingkang Zhu",
            "Zhisheng Zhong",
            "Bei Yu",
            "Jiaya Jia"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10606",
        "abstract": "Typical post-training paradigms for Large Vision-and-Language Models (LVLMs) include Supervised Fine-Tuning (SFT) and Reinforcement Learning with Verifiable Rewards (RLVR). SFT leverages external guidance to inject new knowledge, whereas RLVR utilizes internal reinforcement to enhance reasoning capabilities and overall performance. However, our analysis reveals that SFT often leads to sub-optimal performance, while RLVR struggles with tasks that exceed the model's internal knowledge base. To address these limitations, we propose ViSurf (\\textbf{Vi}sual \\textbf{Su}pervised-and-\\textbf{R}einforcement \\textbf{F}ine-Tuning), a unified post-training paradigm that integrates the strengths of both SFT and RLVR within a single stage. We analyze the derivation of the SFT and RLVR objectives to establish the ViSurf objective, providing a unified perspective on these two paradigms. The core of ViSurf involves injecting ground-truth labels into the RLVR rollouts, thereby providing simultaneous external supervision and internal reinforcement. Furthermore, we introduce three novel reward control strategies to stabilize and optimize the training process. Extensive experiments across several diverse benchmarks demonstrate the effectiveness of ViSurf, outperforming both individual SFT, RLVR, and two-stage SFT \\textrightarrow RLVR. In-depth analysis corroborates these findings, validating the derivation and design principles of ViSurf.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "246",
        "title": "OmniQuality-R: Advancing Reward Models Through All-Encompassing Quality Assessment",
        "author": [
            "Yiting Lu",
            "Fengbin Guan",
            "Yixin Gao",
            "Yan Zhong",
            "Xinge Peng",
            "Jiakang Yuan",
            "Yihao Liu",
            "Bo Zhang",
            "Xin Li",
            "Zhibo Chen",
            "Weisi Lin"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10609",
        "abstract": "Current visual evaluation approaches are typically constrained to a single task. To address this, we propose OmniQuality-R, a unified reward modeling framework that transforms multi-task quality reasoning into continuous and interpretable reward signals for policy optimization. Inspired by subjective experiments, where participants are given task-specific instructions outlining distinct assessment principles prior to evaluation, we propose OmniQuality-R, a structured reward modeling framework that transforms multi-dimensional reasoning into continuous and interpretable reward signals. To enable this, we construct a reasoning-enhanced reward modeling dataset by sampling informative plan-reason trajectories via rejection sampling, forming a reliable chain-of-thought (CoT) dataset for supervised fine-tuning (SFT). Building on this, we apply Group Relative Policy Optimization (GRPO) for post-training, using a Gaussian-based reward to support continuous score prediction. To further stabilize the training and improve downstream generalization, we incorporate standard deviation (STD) filtering and entropy gating mechanisms during reinforcement learning. These techniques suppress unstable updates and reduce variance in policy optimization. We evaluate OmniQuality-R on three key IQA tasks: aesthetic quality assessment, technical quality evaluation, and text-image alignment.",
        "tags": [
            "CoT",
            "GRPO",
            "RL"
        ]
    },
    {
        "id": "247",
        "title": "Dynamic Topic Evolution with Temporal Decay and Attention in Large Language Models",
        "author": [
            "Di Wu abd Shuaidong Pan"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10613",
        "abstract": "This paper proposes a modeling framework for dynamic topic evolution based on temporal large language models. The method first uses a large language model to obtain contextual embeddings of text and then introduces a temporal decay function and an attention mechanism. These components allow the model to adjust the importance of semantic units according to time intervals and capture topic variations across different periods. The temporal representations are then mapped into a latent topic space, where a state transition matrix is applied to describe the dynamic evolution of topics. A joint optimization objective constrains both semantic modeling and temporal consistency, ensuring diversity and smoothness in topic generation. The design emphasizes the unified modeling of semantic representation and temporal evolution, which improves topic coherence and diversity while enhancing stability and interpretability over time. Experiments on real-world corpora show that the framework effectively captures the generation, expansion, and decline of topics and outperforms existing models across multiple metrics. Overall, the proposed method provides a systematic solution for understanding dynamic semantic patterns in large-scale text, enriches the research paradigm of topic modeling, and supports complex text analysis tasks in multiple domains.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "248",
        "title": "Assessing Policy Updates: Toward Trust-Preserving Intelligent User Interfaces",
        "author": [
            "Matan Solomon",
            "Ofra Amir",
            "Omer Ben-Porat"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10616",
        "abstract": "Reinforcement learning agents are often updated with human feedback, yet such updates can be unreliable: reward misspecification, preference conflicts, or limited data may leave policies unchanged or even worse. Because policies are difficult to interpret directly, users face the challenge of deciding whether an update has truly helped. We propose that assessing model updates -- not just a single model -- is a critical design challenge for intelligent user interfaces. In a controlled study, participants provided feedback to an agent in a gridworld and then compared its original and updated policies. We evaluated four strategies for communicating updates: no demonstration, same-context, random-context, and salient-contrast demonstrations designed to highlight informative differences. Salient-contrast demonstrations significantly improved participants' ability to detect when updates helped or harmed performance, mitigating participants' bias towards assuming that feedback is always beneficial, and supported better trust calibration across contexts.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "249",
        "title": "Encoder Decoder Generative Adversarial Network Model for Stock Market Prediction",
        "author": [
            "Bahadur Yadav",
            "Sanjay Kumar Mohanty"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10617",
        "abstract": "Forecasting stock prices remains challenging due to the volatile and non-linear nature of financial markets. Despite the promise of deep learning, issues such as mode collapse, unstable training, and difficulty in capturing temporal and feature level correlations have limited the applications of GANs in this domain. We propose a GRU-based Encoder-Decoder GAN (EDGAN) model that strikes a balance between expressive power and simplicity. The model introduces key innovations such as a temporal decoder with residual connections for precise reconstruction, conditioning on static and dynamic covariates for contextual learning, and a windowing mechanism to capture temporal dynamics. Here, the generator uses a dense encoder-decoder framework with residual GRU blocks. Extensive experiments on diverse stock datasets demonstrate that EDGAN achieves superior forecasting accuracy and training stability, even in volatile markets. It consistently outperforms traditional GAN variants in forecasting accuracy and convergence stability under market conditions.",
        "tags": [
            "GAN"
        ]
    },
    {
        "id": "250",
        "title": "Preserving LLM Capabilities through Calibration Data Curation: From Analysis to Optimization",
        "author": [
            "Bowei He",
            "Lihao Yin",
            "Huiling Zhen",
            "Shuqi Liu",
            "Han Wu",
            "Xiaokun Zhang",
            "Mingxuan Yuan",
            "Chen Ma"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10618",
        "abstract": "Post-training compression has been a widely employed approach to scale down large language model (LLM) and facilitate efficient inference. In various proposed compression methods, including pruning and quantization, calibration data plays a vital role by informing the weight importance and activation dynamic ranges. However, how calibration data impacts the LLM capability after compression is less explored. Few of the existing works, though recognizing the significance of this study, only investigate the language modeling or commonsense reasoning performance degradation from limited angles, like the data sources or sample amounts. More systematic research is still needed to examine the impacts on different LLM capabilities in terms of compositional properties and domain correspondence of calibration data. In this work, we aim at bridging this gap and further analyze underlying influencing mechanisms from the activation pattern perspective. Especially, we explore the calibration data's impacts on high-level complex reasoning capabilities, like math problem solving and code generation. Delving into the underlying mechanism, we find that the representativeness and diversity in activation space more fundamentally determine the quality of calibration data. Finally, we propose a calibration data curation framework based on such observations and analysis, enhancing the performance of existing post-training compression methods on preserving critical LLM capabilities. Our code is provided in \\href{https://github.com/BokwaiHo/COLA.git}{Link}.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "251",
        "title": "ADiP: Adaptive Precision Systolic Array for Matrix Multiplication Acceleration",
        "author": [
            "Ahmed J. Abdelmaksoud",
            "Cristian Sestito",
            "Shiwei Wang",
            "Themis Prodromakis"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10623",
        "abstract": "Transformers are at the core of modern AI nowadays. They rely heavily on matrix multiplication and require efficient acceleration due to their substantial memory and computational requirements. Quantization plays a vital role in reducing memory usage, and can be exploited for computations by designing reconfigurable architectures that enhance matrix multiplication by dynamically adjusting the precision. This paper proposes ADiP, a novel adaptive-precision systolic array architecture designed for efficient matrix multiplication http://acceleration.The proposed architecture consists of NxN adaptive-precision processing elements (PEs) and shared accumulators. ADiP supports multiple computation modes, including symmetric single-matrix multiplication as well as asymmetric multi-matrix multiplication with a shared input matrix, thereby improving data-reuse and PE utilization. In addition, ADiP maximizes the computational density by adapting to different precisions, such as 8bitx8bit, 8bitx4bit, and 8bitx2bit. Analytical models are developed for ADiP architecture, including latency and throughput for versatile architecture configurations. A comprehensive hardware design space exploration is demonstrated using 22nm commercial technology, achieving up to a 4x higher computational throughput. Furthermore, ADiP is evaluated on different transformer workloads from GPT-2 Medium, BERT Large, and BitNet-1.58B models, delivering latency improvement up to 53.6%, and energy improvement up to 24.4% for BitNet-1.58B MHA workloads. At a 64x64 size with 4096 PEs, ADiP achieves a peak throughput of 8.192 TOPS, 16.384 TOPS, and 32.768 TOPS for 8bitx8bit, 8bitx4bit, and 8bitx2bit operations, respectively.",
        "tags": [
            "BERT",
            "GPT",
            "Transformer"
        ]
    },
    {
        "id": "252",
        "title": "GraphTARIF: Linear Graph Transformer with Augmented Rank and Improved Focus",
        "author": [
            "Zhaolin Hu",
            "Kun Li",
            "Hehe Fan",
            "Yi Yang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10631",
        "abstract": "Linear attention mechanisms have emerged as efficient alternatives to full self-attention in Graph Transformers, offering linear time complexity. However, existing linear attention models often suffer from a significant drop in expressiveness due to low-rank projection structures and overly uniform attention distributions. We theoretically prove that these properties reduce the class separability of node representations, limiting the model's classification ability. To address this, we propose a novel hybrid framework that enhances both the rank and focus of attention. Specifically, we enhance linear attention by attaching a gated local graph network branch to the value matrix, thereby increasing the rank of the resulting attention map. Furthermore, to alleviate the excessive smoothing effect inherent in linear attention, we introduce a learnable log-power function into the attention scores to reduce entropy and sharpen focus. We theoretically show that this function decreases entropy in the attention distribution, enhancing the separability of learned embeddings. Extensive experiments on both homophilic and heterophilic graph benchmarks demonstrate that our method achieves competitive performance while preserving the scalability of linear attention.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "253",
        "title": "Collaborative Text-to-Image Generation via Multi-Agent Reinforcement Learning and Semantic Fusion",
        "author": [
            "Jiabao Shi",
            "Minfeng Qi",
            "Lefeng Zhang",
            "Di Wang",
            "Yingjie Zhao",
            "Ziying Li",
            "Yalong Xing",
            "Ningran Li"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10633",
        "abstract": "Multimodal text-to-image generation remains constrained by the difficulty of maintaining semantic alignment and professional-level detail across diverse visual domains. We propose a multi-agent reinforcement learning framework that coordinates domain-specialized agents (e.g., focused on architecture, portraiture, and landscape imagery) within two coupled subsystems: a text enhancement module and an image generation module, each augmented with multimodal integration components. Agents are trained using Proximal Policy Optimization (PPO) under a composite reward function that balances semantic similarity, linguistic visual quality, and content diversity. Cross-modal alignment is enforced through contrastive learning, bidirectional attention, and iterative feedback between text and image. Across six experimental settings, our system significantly enriches generated content (word count increased by 1614%) while reducing ROUGE-1 scores by 69.7%. Among fusion methods, Transformer-based strategies achieve the highest composite score (0.521), despite occasional stability issues. Multimodal ensembles yield moderate consistency (ranging from 0.444 to 0.481), reflecting the persistent challenges of cross-modal semantic grounding. These findings underscore the promise of collaborative, specialization-driven architectures for advancing reliable multimodal generative systems.",
        "tags": [
            "PPO",
            "RL",
            "Text-to-Image",
            "Transformer"
        ]
    },
    {
        "id": "254",
        "title": "High-Fidelity Simulated Data Generation for Real-World Zero-Shot Robotic Manipulation Learning with Gaussian Splatting",
        "author": [
            "Haoyu Zhao",
            "Cheng Zeng",
            "Linghao Zhuang",
            "Yaxi Zhao",
            "Shengke Xue",
            "Hao Wang",
            "Xingyue Zhao",
            "Zhongyu Li",
            "Kehan Li",
            "Siteng Huang",
            "Mingxiu Chen",
            "Xin Li",
            "Deli Zhao",
            "Hua Zou"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10637",
        "abstract": "The scalability of robotic learning is fundamentally bottlenecked by the significant cost and labor of real-world data collection. While simulated data offers a scalable alternative, it often fails to generalize to the real world due to significant gaps in visual appearance, physical properties, and object interactions. To address this, we propose RoboSimGS, a novel Real2Sim2Real framework that converts multi-view real-world images into scalable, high-fidelity, and physically interactive simulation environments for robotic manipulation. Our approach reconstructs scenes using a hybrid representation: 3D Gaussian Splatting (3DGS) captures the photorealistic appearance of the environment, while mesh primitives for interactive objects ensure accurate physics simulation. Crucially, we pioneer the use of a Multi-modal Large Language Model (MLLM) to automate the creation of physically plausible, articulated assets. The MLLM analyzes visual data to infer not only physical properties (e.g., density, stiffness) but also complex kinematic structures (e.g., hinges, sliding rails) of objects. We demonstrate that policies trained entirely on data generated by RoboSimGS achieve successful zero-shot sim-to-real transfer across a diverse set of real-world manipulation tasks. Furthermore, data from RoboSimGS significantly enhances the performance and generalization capabilities of SOTA methods. Our results validate RoboSimGS as a powerful and scalable solution for bridging the sim-to-real gap.",
        "tags": [
            "3D",
            "Gaussian Splatting"
        ]
    },
    {
        "id": "255",
        "title": "UniCoD: Enhancing Robot Policy via Unified Continuous and Discrete Representation Learning",
        "author": [
            "Jianke Zhang",
            "Yucheng Hu",
            "Yanjiang Guo",
            "Xiaoyu Chen",
            "Yichen Liu",
            "Wenna Chen",
            "Chaochao Lu",
            "Jianyu Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10642",
        "abstract": "Building generalist robot policies that can handle diverse tasks in open-ended environments is a central challenge in robotics. To leverage knowledge from large-scale pretraining, prior work has typically built generalist policies either on top of vision-language understanding models (VLMs) or generative models. However, both semantic understanding from vision-language pretraining and visual dynamics modeling from visual-generation pretraining are crucial for embodied robots. Recent unified models of generation and understanding have demonstrated strong capabilities in both comprehension and generation through large-scale pretraining. We posit that robotic policy learning can likewise benefit from the combined strengths of understanding, planning and continuous future representation learning. Building on this insight, we introduce UniCoD, which acquires the ability to dynamically model high-dimensional visual features through pretraining on over 1M internet-scale instructional manipulation videos. Subsequently, UniCoD is fine-tuned on data collected from the robot embodiment, enabling the learning of mappings from predictive representations to action tokens. Extensive experiments show our approach consistently outperforms baseline methods in terms of 9\\% and 12\\% across simulation environments and real-world out-of-distribution tasks.",
        "tags": [
            "Robotics",
            "VLM"
        ]
    },
    {
        "id": "256",
        "title": "Hierarchical Optimization via LLM-Guided Objective Evolution for Mobility-on-Demand Systems",
        "author": [
            "Yi Zhang",
            "Yushen Long",
            "Yun Ni",
            "Liping Huang",
            "Xiaohong Wang",
            "Jun Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10644",
        "abstract": "Online ride-hailing platforms aim to deliver efficient mobility-on-demand services, often facing challenges in balancing dynamic and spatially heterogeneous supply and demand. Existing methods typically fall into two categories: reinforcement learning (RL) approaches, which suffer from data inefficiency, oversimplified modeling of real-world dynamics, and difficulty enforcing operational constraints; or decomposed online optimization methods, which rely on manually designed high-level objectives that lack awareness of low-level routing dynamics. To address this issue, we propose a novel hybrid framework that integrates large language model (LLM) with mathematical optimization in a dynamic hierarchical system: (1) it is training-free, removing the need for large-scale interaction data as in RL, and (2) it leverages LLM to bridge cognitive limitations caused by problem decomposition by adaptively generating high-level objectives. Within this framework, LLM serves as a meta-optimizer, producing semantic heuristics that guide a low-level optimizer responsible for constraint enforcement and real-time decision execution. These heuristics are refined through a closed-loop evolutionary process, driven by harmony search, which iteratively adapts the LLM prompts based on feasibility and performance feedback from the optimization layer. Extensive experiments based on scenarios derived from both the New York and Chicago taxi datasets demonstrate the effectiveness of our approach, achieving an average improvement of 16% compared to state-of-the-art baselines.",
        "tags": [
            "LLM",
            "RL"
        ]
    },
    {
        "id": "257",
        "title": "Unlocking Exploration in RLVR: Uncertainty-aware Advantage Shaping for Deeper Reasoning",
        "author": [
            "Can Xie",
            "Ruotong Pan",
            "Xiangyu Wu",
            "Yunfei Zhang",
            "Jiayi Fu",
            "Tingting Gao",
            "Guorui Zhou"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10649",
        "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR) has shown significant promise for enhancing the reasoning capabilities of large language models (LLMs). However, prevailing algorithms like GRPO broadcast a uniform advantage signal across all tokens in a sequence. This coarse-grained approach overlooks the pivotal role of uncertain, high-stakes decisions during reasoning, leading to inefficient exploration and the well-documented problem of entropy collapse. To address this, we introduce UnCertainty-aware Advantage Shaping (UCAS), a model-free method that refines credit assignment by leveraging the model's internal uncertainty signals. UCAS operates in two stages: it first modulates the response-level advantage using the model's overall self-confidence, and then applies a token-level penalty based on raw logit certainty. This dual mechanism encourages exploration of high-uncertainty paths that yield correct answers while penalizing overconfident yet erroneous reasoning, effectively balancing the exploration-exploitation trade-off. Extensive experiments on five mathematical reasoning benchmarks show that UCAS significantly outperforms strong RLVR baselines across multiple model scales, including 1.5B and 7B. Our analysis confirms that UCAS not only achieves higher rewards but also promotes greater reasoning diversity and successfully mitigates entropy collapse.",
        "tags": [
            "GRPO",
            "LLM",
            "RL"
        ]
    },
    {
        "id": "258",
        "title": "DEMO: Disentangled Motion Latent Flow Matching for Fine-Grained Controllable Talking Portrait Synthesis",
        "author": [
            "Peiyin Chen",
            "Zhuowei Yang",
            "Hui Feng",
            "Sheng Jiang",
            "Rui Yan"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10650",
        "abstract": "Audio-driven talking-head generation has advanced rapidly with diffusion-based generative models, yet producing temporally coherent videos with fine-grained motion control remains challenging. We propose DEMO, a flow-matching generative framework for audio-driven talking-portrait video synthesis that delivers disentangled, high-fidelity control of lip motion, head pose, and eye gaze. The core contribution is a motion auto-encoder that builds a structured latent space in which motion factors are independently represented and approximately orthogonalized. On this disentangled motion space, we apply optimal-transport-based flow matching with a transformer predictor to generate temporally smooth motion trajectories conditioned on audio. Extensive experiments across multiple benchmarks show that DEMO outperforms prior methods in video realism, lip-audio synchronization, and motion fidelity. These results demonstrate that combining fine-grained motion disentanglement with flow-based generative modeling provides a powerful new paradigm for controllable talking-head video synthesis.",
        "tags": [
            "Diffusion",
            "Flow Matching",
            "Talking Head",
            "Talking Portrait",
            "Transformer"
        ]
    },
    {
        "id": "259",
        "title": "Scalable Face Security Vision Foundation Model for Deepfake, Diffusion, and Spoofing Detection",
        "author": [
            "Gaojian Wang",
            "Feng Lin",
            "Tong Wu",
            "Zhisheng Yan",
            "Kui Ren"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10663",
        "abstract": "With abundant, unlabeled real faces, how can we learn robust and transferable facial representations to boost generalization across various face security tasks? We make the first attempt and propose FS-VFM, a scalable self-supervised pre-training framework, to learn fundamental representations of real face images. We introduce three learning objectives, namely 3C, that synergize masked image modeling (MIM) and instance discrimination (ID), empowering FS-VFM to encode both local patterns and global semantics of real faces. Specifically, we formulate various facial masking strategies for MIM and devise a simple yet effective CRFR-P masking, which explicitly prompts the model to pursue meaningful intra-region Consistency and challenging inter-region Coherency. We present a reliable self-distillation mechanism that seamlessly couples MIM with ID to establish underlying local-to-global Correspondence. After pre-training, vanilla vision transformers (ViTs) serve as universal Vision Foundation Models for downstream Face Security tasks: cross-dataset deepfake detection, cross-domain face anti-spoofing, and unseen diffusion facial forensics. To efficiently transfer the pre-trained FS-VFM, we further propose FS-Adapter, a lightweight plug-and-play bottleneck atop the frozen backbone with a novel real-anchor contrastive objective. Extensive experiments on 11 public benchmarks demonstrate that our FS-VFM consistently generalizes better than diverse VFMs, spanning natural and facial domains, fully, weakly, and self-supervised paradigms, small, base, and large ViT scales, and even outperforms SOTA task-specific methods, while FS-Adapter offers an excellent efficiency-performance trade-off. The code and models are available on https://fsfm-3c.github.io/fsvfm.html.",
        "tags": [
            "Detection",
            "Diffusion",
            "ViT"
        ]
    },
    {
        "id": "260",
        "title": "BrowserAgent: Building Web Agents with Human-Inspired Web Browsing Actions",
        "author": [
            "Zhengbo Zhang",
            "Zhiheng Lyu",
            "Junhao Gong",
            "Hongzhu Yi",
            "Xinming Wang",
            "Yuxuan Zhou",
            "Jiabing Yang",
            "Ping Nie",
            "Yan Huang",
            "Wenhu Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10666",
        "abstract": "Efficiently solving real-world problems with LLMs increasingly hinges on their ability to interact with dynamic web environments and autonomously acquire external information. While recent research like Search-R1 and WebDancer demonstrates strong performance in solving web tasks, they heavily rely on additional tools to convert the interactive web environment into static text content. This is in contrast to human browsing behaviors, which involve diverse interactions with the browser, such as scrolling, clicking, and typing. In this paper, we propose BrowserAgent, a more interactive agent that solves complex tasks through human-inspired browser actions. BrowserAgent operates directly on raw web pages via Playwright through a set of predefined browser actions. We adopt a two-stage training (Supervised Fine-Tuning (SFT) and Rejection Fine-Tuning (RFT)) to improve the model's generalization abilities. Despite using significantly less training data than Search-R1, BrowserAgent achieves more competitive results across different Open-QA tasks. Additionally, we introduce an explicit memory mechanism to store key conclusions across steps, further enhancing the model's reasoning capabilities for long-horizon tasks. Notably, BrowserAgent-7B can achieve around 20\\% improvement over Search-R1 on multi-hop QA tasks like HotpotQA, 2Wiki, and Bamboogle. These results indicate that BrowserAgent can serve as a more advanced framework for more interactive and scalable web agents.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "261",
        "title": "Novel superconvergence and ultraconvergence structures for the finite volume element method",
        "author": [
            "Xiang Wang",
            "Yuqing Zhang",
            "Zhimin Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10668",
        "abstract": "This paper develops novel natural superconvergence and ultraconvergence structures for the bi-$k$-order finite volume element (FVE) method on rectangular meshes. These structures furnish tunable and possibly asymmetric superconvergence and ultraconvergence points. We achieve one-order-higher superconvergence for both derivatives and function values, and two-orders-higher ultraconvergence for derivatives--a phenomenon that standard bi-$k$-order finite elements do not exhibit. Derivative ultraconvergence requires three conditions: a diagonal diffusion tensor, zero convection coefficients, and the FVE scheme satisfying tensorial $k$-$k$-order orthogonality (imposed via dual mesh constraints). This two-dimensional derivative ultraconvergence is not a trivial tensor-product extension of the one-dimensional phenomena; its analysis is also considerably more complex due to directional coupling. Theoretically, we introduce the asymmetric-enabled M-decompositions (AMD-Super and AMD-Ultra) to rigorously prove these phenomena. Numerical experiments confirm the theory.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "262",
        "title": "AdaViewPlanner: Adapting Video Diffusion Models for Viewpoint Planning in 4D Scenes",
        "author": [
            "Yu Li",
            "Menghan Xia",
            "Gongye Liu",
            "Jianhong Bai",
            "Xintao Wang",
            "Conglang Zhang",
            "Yuxuan Lin",
            "Ruihang Chu",
            "Pengfei Wan",
            "Yujiu Yang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10670",
        "abstract": "Recent Text-to-Video (T2V) models have demonstrated powerful capability in visual simulation of real-world geometry and physical laws, indicating its potential as implicit world models. Inspired by this, we explore the feasibility of leveraging the video generation prior for viewpoint planning from given 4D scenes, since videos internally accompany dynamic scenes with natural viewpoints. To this end, we propose a two-stage paradigm to adapt pre-trained T2V models for viewpoint prediction, in a compatible manner. First, we inject the 4D scene representation into the pre-trained T2V model via an adaptive learning branch, where the 4D scene is viewpoint-agnostic and the conditional generated video embeds the viewpoints visually. Then, we formulate viewpoint extraction as a hybrid-condition guided camera extrinsic denoising process. Specifically, a camera extrinsic diffusion branch is further introduced onto the pre-trained T2V model, by taking the generated video and 4D scene as input. Experimental results show the superiority of our proposed method over existing competitors, and ablation studies validate the effectiveness of our key technical designs. To some extent, this work proves the potential of video generation models toward 4D interaction in real world.",
        "tags": [
            "Diffusion",
            "Text-to-Video",
            "Video Generation"
        ]
    },
    {
        "id": "263",
        "title": "Simpliflow: A Lightweight Open-Source Framework for Rapid Creation and Deployment of Generative Agentic AI Workflows",
        "author": [
            "Deven Panchal"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10675",
        "abstract": "Generative Agentic AI systems are emerging as a powerful paradigm for automating complex, multi-step tasks. However, many existing frameworks for building these systems introduce significant complexity, a steep learning curve, and substantial boilerplate code, hindering rapid prototyping and deployment. This paper introduces simpliflow, a lightweight, open-source Python framework designed to address these challenges. simpliflow enables the rapid development and orchestration of linear, deterministic agentic workflows through a declarative, JSON-based configuration. Its modular architecture decouples agent management, workflow execution, and post-processing, promoting ease of use and extensibility. By integrating with LiteLLM, it supports over 100 Large Language Models (LLMs) out-of-the-box. We present the architecture, operational flow, and core features of simpliflow, demonstrating its utility through diverse use cases ranging from software development simulation to real-time system interaction. A comparative analysis with prominent frameworks like LangChain and AutoGen highlights simpliflow's unique position as a tool optimized for simplicity, control, and speed in deterministic workflow environments.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "264",
        "title": "Unlocking LLM Safeguards for Low-Resource Languages via Reasoning and Alignment with Minimal Training Data",
        "author": [
            "Zhuowei Chen",
            "Bowei Zhang",
            "Nankai Lin",
            "Tian Hou",
            "Lianxi Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10677",
        "abstract": "Recent advances in LLMs have enhanced AI capabilities, but also increased the risk posed by malicious requests, highlighting the need for effective LLM safeguards to detect such queries. Existing approaches largely rely on classifier-based methods that lack interpretability and perform poorly on low-resource languages. To address these limitations, we propose ConsistentGuard, a novel reasoning-based multilingual safeguard, which enhances explainability via reasoning and boosts knowledge transfer between languages through alignment. With only 1,000 training samples, our method demonstrates superior performance on three datasets across six languages, outperforming larger models trained with significantly more data, and exhibits strong interpretability and generalization ability. We also contribute a multilingual benchmark extension and release our codes to support future research.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "265",
        "title": "RePro: Training Language Models to Faithfully Recycle the Web for Pretraining",
        "author": [
            "Zichun Yu",
            "Chenyan Xiong"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10681",
        "abstract": "High-quality pretraining data is the fossil fuel of large language models (LLMs), yet its reserves are running low for frontier models. In this paper, we introduce RePro, a novel web recycling method that trains a relatively small LM with reinforcement learning to generate effective and faithful rephrasings of pretraining data. Specifically, we design one quality reward and three faithfulness rewards, optimizing the LM rephraser to convert organic data into high-quality rephrasings while maintaining its core semantics and structure. In our experiment, we train a 4B rephraser to recycle 72B tokens sampled from DCLM-RefinedWeb. Pretraining results on 400M and 1.4B models demonstrate that RePro delivers 4.7%-14.0% relative accuracy gains over organic-only baseline on 22 downstream tasks. RePro also outperforms ReWire, the state-of-the-art web recycling method that prompts a 70B rephraser, as well as the organic baseline with a 4x larger data pool. Experiments with different amounts of recycled data highlight that RePro improves organic data efficiency by 2-3x. Individual and distributional analyses validate that RePro preserves more critical information and faithfully reflects the characteristics of organic data compared to prompting-based methods. Together, these results show that RePro provides an efficient and controllable path to effectively harness the fossil fuel of LLM pretraining. We open-source our code, rephraser, and recycled data at https://github.com/cxcscmu/RePro.",
        "tags": [
            "LLM",
            "RL"
        ]
    },
    {
        "id": "266",
        "title": "OmniVideoBench: Towards Audio-Visual Understanding Evaluation for Omni MLLMs",
        "author": [
            "Caorui Li",
            "Yu Chen",
            "Yiyan Ji",
            "Jin Xu",
            "Zhenyu Cui",
            "Shihao Li",
            "Yuanxing Zhang",
            "Jiafu Tang",
            "Zhenghao Song",
            "Dingling Zhang",
            "Ying He",
            "Haoxiang Liu",
            "Yuxuan Wang",
            "Qiufeng Wang",
            "Zhenhe Wu",
            "Jiehui Luo",
            "Zhiyu Pan",
            "Weihao Xie",
            "Chenchen Zhang",
            "Zhaohui Wang",
            "Jiayi Tian",
            "Yanghai Wang",
            "Zhe Cao",
            "Minxin Dai",
            "Ke Wang",
            "Runzhe Wen",
            "Yinghao Ma",
            "Yaning Pan",
            "Sungkyun Chang",
            "Termeh Taheri",
            "Haiwen Xia",
            "Christos Plachouras",
            "Emmanouil Benetos",
            "Yizhi Li",
            "Ge Zhang",
            "Jian Yang",
            "Tianhao Peng",
            "Zili Wang",
            "Minghao Liu",
            "Junran Peng",
            "Zhaoxiang Zhang",
            "Jiaheng Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10689",
        "abstract": "Recent advances in multimodal large language models (MLLMs) have demonstrated substantial potential in video understanding. However, existing benchmarks fail to comprehensively evaluate synergistic reasoning capabilities across audio and visual modalities, often neglecting either one of the modalities or integrating them in a logically inconsistent manner. To bridge this gap, we introduce OmniVideoBench, a large-scale and rigorously designed benchmark dedicated to assessing synergistic audio-visual understanding, with a strong emphasis on modality complementarity and logical consistency. Specifically, OmniVideoBench comprises 1000 high-quality question-answer(QA) pairs, each annotated with step-by-step reasoning traces, derived from 628 diverse videos ranging from several seconds to 30 minutes, and manually verified to guarantee complete correctness and uniqueness. Moreover, OmniVideoBench encompasses 13 carefully designed question types, covering temporal reasoning, spatial localization, counting, causal inference, summarization, and beyond, thereby capturing the essential challenges of video understanding. Evaluation of multiple MLLMs on OmniVideoBench reveals a pronounced gap between model performance and human reasoning, with open-source models lagging significantly behind their closed-source counterparts, underscoring the inherent difficulty of genuine audio-visual reasoning. We will release OmniVideoBench to foster the development of MLLMs with stronger and more generalizable reasoning capabilities.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "267",
        "title": "Dynamic Gaussian Splatting from Defocused and Motion-blurred Monocular Videos",
        "author": [
            "Xuankai Zhang",
            "Junjin Xiao",
            "Qing Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10691",
        "abstract": "This paper presents a unified framework that allows high-quality dynamic Gaussian Splatting from both defocused and motion-blurred monocular videos. Due to the significant difference between the formation processes of defocus blur and motion blur, existing methods are tailored for either one of them, lacking the ability to simultaneously deal with both of them. Although the two can be jointly modeled as blur kernel-based convolution, the inherent difficulty in estimating accurate blur kernels greatly limits the progress in this direction. In this work, we go a step further towards this direction. Particularly, we propose to estimate per-pixel reliable blur kernels using a blur prediction network that exploits blur-related scene and camera information and is subject to a blur-aware sparsity constraint. Besides, we introduce a dynamic Gaussian densification strategy to mitigate the lack of Gaussians for incomplete regions, and boost the performance of novel view synthesis by incorporating unseen view information to constrain scene optimization. Extensive experiments show that our method outperforms the state-of-the-art methods in generating photorealistic novel view synthesis from defocused and motion-blurred monocular videos. Our code and trained model will be made publicly available.",
        "tags": [
            "Gaussian Splatting"
        ]
    },
    {
        "id": "268",
        "title": "Digital Twin-enabled Multi-generation Control Co-Design with Deep Reinforcement Learning",
        "author": [
            "Ying-Kuan Tsai",
            "Vispi Karkaria",
            "Yi-Ping Chen",
            "Wei Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10694",
        "abstract": "Control Co-Design (CCD) integrates physical and control system design to improve the performance of dynamic and autonomous systems. Despite advances in uncertainty-aware CCD methods, real-world uncertainties remain highly unpredictable. Multi-generation design addresses this challenge by considering the full lifecycle of a product: data collected from each generation informs the design of subsequent generations, enabling progressive improvements in robustness and efficiency. Digital Twin (DT) technology further strengthens this paradigm by creating virtual representations that evolve over the lifecycle through real-time sensing, model updating, and adaptive re-optimization. This paper presents a DT-enabled CCD framework that integrates Deep Reinforcement Learning (DRL) to jointly optimize physical design and controller. DRL accelerates real-time decision-making by allowing controllers to continuously learn from data and adapt to uncertain environments. Extending this approach, the framework employs a multi-generation paradigm, where each cycle of deployment, operation, and redesign uses collected data to refine DT models, improve uncertainty quantification through quantile regression, and inform next-generation designs of both physical components and controllers. The framework is demonstrated on an active suspension system, where DT-enabled learning from road conditions and driving behaviors yields smoother and more stable control trajectories. Results show that the method significantly enhances dynamic performance, robustness, and efficiency. Contributions of this work include: (1) extending CCD into a lifecycle-oriented multi-generation framework, (2) leveraging DTs for continuous model updating and informed design, and (3) employing DRL to accelerate adaptive real-time decision-making.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "269",
        "title": "Adaptive Selection of Symbolic Languages for Improving LLM Logical Reasoning",
        "author": [
            "Xiangyu Wang",
            "Haocheng Yang",
            "Fengxiang Cheng",
            "Fenrong Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10703",
        "abstract": "Large Language Models (LLMs) still struggle with complex logical reasoning. While previous works achieve remarkable improvements, their performance is highly dependent on the correctness of translating natural language (NL) problems into a symbolic language (SL). Though numerous works focusing on improving this translation accuracy, they only consider the similarity between the meaning of SL and NL, overlooking another crucial influencing factor, the selection of the target SL type itself. For example, first-order logic language specializes in logical reasoning with categorical syllogisms and complex quantifiers, while Boolean satisfiability formalism excels at representing constraint satisfaction like partial problems. To our knowledge, this is the first paper to claim and verify that different NL logical reasoning problem corresponds to different optimal SL formalization for translation. Based on this, we propose a methods to improve the logical reasoning performance of LLMs by adaptively selecting the most suitable SL for each problem prior to translation. Specifically, we leverage LLMs to select the target SL among first-order logic, logic programming and Boolean satisfiability and then translate the problem in NL to target SL expressions as well as employ the corresponding logical solver to derive the final answer. Experimental results on benchmarks show that our adaptive selection method significantly outperforms translating all into single SL and randomly selecting the SL. On a mixed dataset of these benchmarks, our approach achieves 96% accuracy, which improving performance by 25% compared to the second highest accuracy from the first-order logic translation.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "270",
        "title": "VLM-Guided Adaptive Negative Prompting for Creative Generation",
        "author": [
            "Shelly Golan",
            "Yotam Nitzan",
            "Zongze Wu",
            "Or Patashnik"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10715",
        "abstract": "Creative generation is the synthesis of new, surprising, and valuable samples that reflect user intent yet cannot be envisioned in advance. This task aims to extend human imagination, enabling the discovery of visual concepts that exist in the unexplored spaces between familiar domains. While text-to-image diffusion models excel at rendering photorealistic scenes that faithfully match user prompts, they still struggle to generate genuinely novel content. Existing approaches to enhance generative creativity either rely on interpolation of image features, which restricts exploration to predefined categories, or require time-intensive procedures such as embedding optimization or model fine-tuning. We propose VLM-Guided Adaptive Negative-Prompting, a training-free, inference-time method that promotes creative image generation while preserving the validity of the generated object. Our approach utilizes a vision-language model (VLM) that analyzes intermediate outputs of the generation process and adaptively steers it away from conventional visual concepts, encouraging the emergence of novel and surprising outputs. We evaluate creativity through both novelty and validity, using statistical metrics in the CLIP embedding space. Through extensive experiments, we show consistent gains in creative novelty with negligible computational overhead. Moreover, unlike existing methods that primarily generate single objects, our approach extends to complex scenarios, such as generating coherent sets of creative objects and preserving creativity within elaborate compositional prompts. Our method integrates seamlessly into existing diffusion pipelines, offering a practical route to producing creative outputs that venture beyond the constraints of textual descriptions.",
        "tags": [
            "CLIP",
            "Diffusion",
            "Text-to-Image",
            "VLM"
        ]
    },
    {
        "id": "271",
        "title": "Deployment and Development of a Cognitive Teleoreactive Framework for Deep Sea Autonomy",
        "author": [
            "Christopher Thierauf"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10716",
        "abstract": "A new AUV mission planning and execution software has been tested on AUV Sentry. Dubbed DINOS-R, it draws inspiration from cognitive architectures and AUV control systems to replace the legacy MC architecture. Unlike these existing architectures, however, DINOS-R is built from the ground-up to unify symbolic decision making (for understandable, repeatable, provable behavior) with machine learning techniques and reactive behaviors, for field-readiness across oceanographic platforms. Implemented primarily in Python3, DINOS-R is extensible, modular, and reusable, with an emphasis on non-expert use as well as growth for future research in oceanography and robot algorithms. Mission specification is flexible, and can be specified declaratively. Behavior specification is similarly flexible, supporting simultaneous use of real-time task planning and hard-coded user specified plans. These features were demonstrated in the field on Sentry, in addition to a variety of simulated cases. These results are discussed, and future work is outlined.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "272",
        "title": "Sarcasm Detection Using Deep Convolutional Neural Networks: A Modular Deep Learning Framework",
        "author": [
            "Manas Zambre",
            "Sarika Bobade"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10729",
        "abstract": "Sarcasm is a nuanced and often misinterpreted form of communication, especially in text, where tone and body language are absent. This paper proposes a modular deep learning framework for sarcasm detection, leveraging Deep Convolutional Neural Networks (DCNNs) and contextual models such as BERT to analyze linguistic, emotional, and contextual cues. The system integrates sentiment analysis, contextual embeddings, linguistic feature extraction, and emotion detection through a multi-layer architecture. While the model is in the conceptual stage, it demonstrates feasibility for real-world applications such as chatbots and social media analysis.",
        "tags": [
            "BERT",
            "Detection"
        ]
    },
    {
        "id": "273",
        "title": "Provable Anytime Ensemble Sampling Algorithms in Nonlinear Contextual Bandits",
        "author": [
            "Jiazheng Sun",
            "Weixin Wang",
            "Pan Xu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10730",
        "abstract": "We provide a unified algorithmic framework for ensemble sampling in nonlinear contextual bandits and develop corresponding regret bounds for two most common nonlinear contextual bandit settings: Generalized Linear Ensemble Sampling (\\texttt{GLM-ES}) for generalized linear bandits and Neural Ensemble Sampling (\\texttt{Neural-ES}) for neural contextual bandits. Both methods maintain multiple estimators for the reward model parameters via maximum likelihood estimation on randomly perturbed data. We prove high-probability frequentist regret bounds of $\\mathcal{O}(d^{3/2} \\sqrt{T} + d^{9/2})$ for \\texttt{GLM-ES} and $\\mathcal{O}(\\widetilde{d} \\sqrt{T})$ for \\texttt{Neural-ES}, where $d$ is the dimension of feature vectors, $\\widetilde{d}$ is the effective dimension of a neural tangent kernel matrix, and $T$ is the number of rounds. These regret bounds match the state-of-the-art results of randomized exploration algorithms in nonlinear contextual bandit settings. In the theoretical analysis, we introduce techniques that address challenges specific to nonlinear models. Practically, we remove fixed-time horizon assumptions by developing anytime versions of our algorithms, suitable when $T$ is unknown. Finally, we empirically evaluate \\texttt{GLM-ES}, \\texttt{Neural-ES}, and their anytime variants, demonstrating strong performance. Overall, our results establish ensemble sampling as a provable and practical randomized exploration approach for nonlinear contextual bandits.",
        "tags": [
            "GLM"
        ]
    },
    {
        "id": "274",
        "title": "A Stochastic Differential Equation Framework for Multi-Objective LLM Interactions: Dynamical Systems Analysis with Code Generation Applications",
        "author": [
            "Shivani Shukla",
            "Himanshu Joshi"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10739",
        "abstract": "We introduce a general stochastic differential equation framework for modelling multiobjective optimization dynamics in iterative Large Language Model (LLM) interactions. Our framework captures the inherent stochasticity of LLM responses through explicit diffusion terms and reveals systematic interference patterns between competing objectives via an interference matrix formulation. We validate our theoretical framework using iterative code generation as a proof-of-concept application, analyzing 400 sessions across security, efficiency, and functionality objectives. Our results demonstrate strategy-dependent convergence behaviors with rates ranging from 0.33 to 1.29, and predictive accuracy achieving R2 = 0.74 for balanced approaches. This work proposes the feasibility of dynamical systems analysis for multi-objective LLM interactions, with code generation serving as an initial validation domain.",
        "tags": [
            "Diffusion",
            "LLM"
        ]
    },
    {
        "id": "275",
        "title": "Gain Tuning Is Not What You Need: Reward Gain Adaptation for Constrained Locomotion Learning",
        "author": [
            "Arthicha Srisuchinnawong",
            "Poramate Manoonpong"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10759",
        "abstract": "Existing robot locomotion learning techniques rely heavily on the offline selection of proper reward weighting gains and cannot guarantee constraint satisfaction (i.e., constraint violation) during training. Thus, this work aims to address both issues by proposing Reward-Oriented Gains via Embodied Regulation (ROGER), which adapts reward-weighting gains online based on penalties received throughout the embodied interaction process. The ratio between the positive reward (primary reward) and negative reward (penalty) gains is automatically reduced as the learning approaches the constraint thresholds to avoid violation. Conversely, the ratio is increased when learning is in safe states to prioritize performance. With a 60-kg quadruped robot, ROGER achieved near-zero constraint violation throughout multiple learning trials. It also achieved up to 50% more primary reward than the equivalent state-of-the-art techniques. In MuJoCo continuous locomotion benchmarks, including a single-leg hopper, ROGER exhibited comparable or up to 100% higher performance and 60% less torque usage and orientation deviation compared to those trained with the default reward function. Finally, real-world locomotion learning of a physical quadruped robot was achieved from scratch within one hour without any falls. Therefore, this work contributes to constraint-satisfying real-world continual robot locomotion learning and simplifies reward weighting gain tuning, potentially facilitating the development of physical robots and those that learn in the real world.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "276",
        "title": "Large Language Models for Full-Text Methods Assessment: A Case Study on Mediation Analysis",
        "author": [
            "Wenqing Zhang",
            "Trang Nguyen",
            "Elizabeth A. Stuart",
            "Yiqun T. Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10762",
        "abstract": "Systematic reviews are crucial for synthesizing scientific evidence but remain labor-intensive, especially when extracting detailed methodological information. Large language models (LLMs) offer potential for automating methodological assessments, promising to transform evidence synthesis. Here, using causal mediation analysis as a representative methodological domain, we benchmarked state-of-the-art LLMs against expert human reviewers across 180 full-text scientific articles. Model performance closely correlated with human judgments (accuracy correlation 0.71; F1 correlation 0.97), achieving near-human accuracy on straightforward, explicitly stated methodological criteria. However, accuracy sharply declined on complex, inference-intensive assessments, lagging expert reviewers by up to 15%. Errors commonly resulted from superficial linguistic cues -- for instance, models frequently misinterpreted keywords like \"longitudinal\" or \"sensitivity\" as automatic evidence of rigorous methodological approache, leading to systematic misclassifications. Longer documents yielded lower model accuracy, whereas publication year showed no significant effect. Our findings highlight an important pattern for practitioners using LLMs for methods review and synthesis from full texts: current LLMs excel at identifying explicit methodological features but require human oversight for nuanced interpretations. Integrating automated information extraction with targeted expert review thus provides a promising approach to enhance efficiency and methodological rigor in evidence synthesis across diverse scientific fields.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "277",
        "title": "Understanding Sampler Stochasticity in Training Diffusion Models for RLHF",
        "author": [
            "Jiayuan Sheng",
            "Hanyang Zhao",
            "Haoxian Chen",
            "David D. Yao",
            "Wenpin Tang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10767",
        "abstract": "Reinforcement Learning from Human Feedback (RLHF) is increasingly used to fine-tune diffusion models, but a key challenge arises from the mismatch between stochastic samplers used during training and deterministic samplers used during inference. In practice, models are fine-tuned using stochastic SDE samplers to encourage exploration, while inference typically relies on deterministic ODE samplers for efficiency and stability. This discrepancy induces a reward gap, raising concerns about whether high-quality outputs can be expected during inference. In this paper, we theoretically characterize this reward gap and provide non-vacuous bounds for general diffusion models, along with sharper convergence rates for Variance Exploding (VE) and Variance Preserving (VP) Gaussian models. Methodologically, we adopt the generalized denoising diffusion implicit models (gDDIM) framework to support arbitrarily high levels of stochasticity, preserving data marginals throughout. Empirically, our findings through large-scale experiments on text-to-image models using denoising diffusion policy optimization (DDPO) and mixed group relative policy optimization (MixGRPO) validate that reward gaps consistently narrow over training, and ODE sampling quality improves when models are updated using higher-stochasticity SDE training.",
        "tags": [
            "Diffusion",
            "ODE",
            "RL",
            "RLHF",
            "SDE",
            "Text-to-Image"
        ]
    },
    {
        "id": "278",
        "title": "ParsVoice: A Large-Scale Multi-Speaker Persian Speech Corpus for Text-to-Speech Synthesis",
        "author": [
            "Mohammad Javad Ranjbar Kalahroodi",
            "Heshaam Faili",
            "Azadeh Shakery"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10774",
        "abstract": "Persian Language, despite being spoken by over 100 million people worldwide, remains severely underrepresented in high-quality speech corpora, particularly for text-to-speech (TTS) synthesis applications. Existing Persian speech datasets are typically smaller than their English counterparts, which creates a key limitation for developing Persian speech technologies. We address this gap by introducing ParsVoice, the largest Persian speech corpus designed specifically for TTS applications. We created an automated pipeline that transforms raw audiobook content into TTS-ready data, incorporating components such as a BERT-based sentence completion detector, a binary search boundary optimization method for precise audio-text alignment, and multi-dimensional quality assessment frameworks tailored to Persian. The pipeline processes 2,000 audiobooks, yielding 3,526 hours of clean speech, which was further filtered into a 1,804-hour high-quality subset suitable for TTS, featuring more than 470 speakers. ParsVoice is the largest high-quality Persian speech dataset, offering speaker diversity and audio quality comparable to major English corpora. The complete dataset has been made publicly available to accelerate the development of Persian speech technologies and to serve as a template for other low-resource languages. The ParsVoice dataset is publicly available at ParsVoice (https://huggingface.co/datasets/MohammadJRanjbar/ParsVoice).",
        "tags": [
            "BERT"
        ]
    },
    {
        "id": "279",
        "title": "HiligayNER: A Baseline Named Entity Recognition Model for Hiligaynon",
        "author": [
            "James Ald Teves",
            "Ray Daniel Cal",
            "Josh Magdiel Villaluz",
            "Jean Malolos",
            "Mico Magtira",
            "Ramon Rodriguez",
            "Mideth Abisado",
            "Joseph Marvin Imperial"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10776",
        "abstract": "The language of Hiligaynon, spoken predominantly by the people of Panay Island, Negros Occidental, and Soccsksargen in the Philippines, remains underrepresented in language processing research due to the absence of annotated corpora and baseline models. This study introduces HiligayNER, the first publicly available baseline model for the task of Named Entity Recognition (NER) in Hiligaynon. The dataset used to build HiligayNER contains over 8,000 annotated sentences collected from publicly available news articles, social media posts, and literary texts. Two Transformer-based models, mBERT and XLM-RoBERTa, were fine-tuned on this collected corpus to build versions of HiligayNER. Evaluation results show strong performance, with both models achieving over 80% in precision, recall, and F1-score across entity types. Furthermore, cross-lingual evaluation with Cebuano and Tagalog demonstrates promising transferability, suggesting the broader applicability of HiligayNER for multilingual NLP in low-resource settings. This work aims to contribute to language technology development for underrepresented Philippine languages, specifically for Hiligaynon, and support future research in regional language processing.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "280",
        "title": "Real2USD: Scene Representations in Universal Scene Description Language",
        "author": [
            "Christopher D. Hsu",
            "Pratik Chaudhari"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10778",
        "abstract": "Large Language Models (LLMs) can help robots reason about abstract task specifications. This requires augmenting classical representations of the environment used by robots with natural language-based priors. There are a number of existing approaches to doing so, but they are tailored to specific tasks, e.g., visual-language models for navigation, language-guided neural radiance fields for mapping, etc. This paper argues that the Universal Scene Description (USD) language is an effective and general representation of geometric, photometric and semantic information in the environment for LLM-based robotics tasks. Our argument is simple: a USD is an XML-based scene graph, readable by LLMs and humans alike, and rich enough to support essentially any task -- Pixar developed this language to store assets, scenes and even movies. We demonstrate a ``Real to USD'' system using a Unitree Go2 quadruped robot carrying LiDAR and a RGB camera that (i) builds an explicit USD representation of indoor environments with diverse objects and challenging settings with lots of glass, and (ii) parses the USD using Google's Gemini to demonstrate scene understanding, complex inferences, and planning. We also study different aspects of this system in simulated warehouse and hospital settings using Nvidia's Issac Sim. Code is available at https://github.com/grasp-lyrl/Real2USD .",
        "tags": [
            "LLM",
            "Robotics"
        ]
    },
    {
        "id": "281",
        "title": "Review of Inference-Time Scaling Strategies: Reasoning, Search and RAG",
        "author": [
            "Zhichao Wang",
            "Cheng Wan",
            "Dong Nie"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10787",
        "abstract": "The performance gains of LLMs have historically been driven by scaling up model size and training data. However, the rapidly diminishing availability of high-quality training data is introducing a fundamental bottleneck, shifting the focus of research toward inference-time scaling. This paradigm uses additional computation at the time of deployment to substantially improve LLM performance on downstream tasks without costly model re-training. This review systematically surveys the diverse techniques contributing to this new era of inference-time scaling, organizing the rapidly evolving field into two comprehensive perspectives: Output-focused and Input-focused methods. Output-focused techniques encompass complex, multi-step generation strategies, including reasoning (e.g., CoT, ToT, ReAct), various search and decoding methods (e.g., MCTS, beam search), training for long CoT (e.g., RLVR, GRPO), and model ensemble methods. Input-focused techniques are primarily categorized by few-shot and RAG, with RAG as the central focus. The RAG section is further detailed through a structured examination of query expansion, data, retrieval and reranker, LLM generation methods, and multi-modal RAG.",
        "tags": [
            "CoT",
            "GRPO",
            "LLM",
            "RAG"
        ]
    },
    {
        "id": "282",
        "title": "MSCloudCAM: Cross-Attention with Multi-Scale Context for Multispectral Cloud Segmentation",
        "author": [
            "Md Abdullah Al Mazid",
            "Liangdong Deng",
            "Naphtali Rishe"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10802",
        "abstract": "Clouds remain a critical challenge in optical satellite imagery, hindering reliable analysis for environmental monitoring, land cover mapping, and climate research. To overcome this, we propose MSCloudCAM, a Cross-Attention with Multi-Scale Context Network tailored for multispectral and multi-sensor cloud segmentation. Our framework exploits the spectral richness of Sentinel-2 (CloudSEN12) and Landsat-8 (L8Biome) data to classify four semantic categories: clear sky, thin cloud, thick cloud, and cloud shadow. MSCloudCAM combines a Swin Transformer backbone for hierarchical feature extraction with multi-scale context modules ASPP and PSP for enhanced scale-aware learning. A Cross-Attention block enables effective multisensor and multispectral feature fusion, while the integration of an Efficient Channel Attention Block (ECAB) and a Spatial Attention Module adaptively refine feature representations. Comprehensive experiments on CloudSEN12 and L8Biome demonstrate that MSCloudCAM delivers state-of-the-art segmentation accuracy, surpassing leading baseline architectures while maintaining competitive parameter efficiency and FLOPs. These results underscore the model's effectiveness and practicality, making it well-suited for large-scale Earth observation tasks and real-world applications.",
        "tags": [
            "Segmentation",
            "Transformer"
        ]
    },
    {
        "id": "283",
        "title": "Representing Data in Robotic Tactile Perception -- A Review",
        "author": [
            "Alessandro Albini",
            "Mohsen Kaboli",
            "Giorgio Cannata",
            "Perla Maiolino"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10804",
        "abstract": "Robotic tactile perception is a complex process involving several computational steps performed at different levels. Tactile information is shaped by the interplay of robot actions, the mechanical properties of its body, and the software that processes the data. In this respect, high-level computation, required to process and extract information, is commonly performed by adapting existing techniques from other domains, such as computer vision, which expects input data to be properly structured. Therefore, it is necessary to transform tactile sensor data to match a specific data structure. This operation directly affects the tactile information encoded and, as a consequence, the task execution. This survey aims to address this specific aspect of the tactile perception pipeline, namely Data Representation. The paper first clearly defines its contributions to the perception pipeline and then reviews how previous studies have dealt with the problem of representing tactile information, investigating the relationships among hardware, representations, and high-level computation methods. The analysis has led to the identification of six structures commonly used in the literature to represent data. The manuscript provides discussions and guidelines for properly selecting a representation depending on operating conditions, including the available hardware, the tactile information required to be encoded, and the task at hand.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "284",
        "title": "Is Implicit Knowledge Enough for LLMs? A RAG Approach for Tree-based Structures",
        "author": [
            "Mihir Gupte",
            "Paolo Giusto",
            "Ramesh S"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10806",
        "abstract": "Large Language Models (LLMs) are adept at generating responses based on information within their context. While this ability is useful for interacting with structured data like code files, another popular method, Retrieval-Augmented Generation (RAG), retrieves relevant documents to augment the model's in-context learning. However, it is not well-explored how to best represent this retrieved knowledge for generating responses on structured data, particularly hierarchical structures like trees. In this work, we propose a novel bottom-up method to linearize knowledge from tree-like structures (like a GitHub repository) by generating implicit, aggregated summaries at each hierarchical level. This approach enables the knowledge to be stored in a knowledge base and used directly with RAG. We then compare our method to using RAG on raw, unstructured code, evaluating the accuracy and quality of the generated responses. Our results show that while response quality is comparable across both methods, our approach generates over 68% fewer documents in the retriever, a significant gain in efficiency. This finding suggests that leveraging implicit, linearized knowledge may be a highly effective and scalable strategy for handling complex, hierarchical data structures.",
        "tags": [
            "LLM",
            "RAG"
        ]
    },
    {
        "id": "285",
        "title": "Crisis-Aware Regime-Conditioned Diffusion with CVaR Allocation",
        "author": [
            "Ali Atiah Alzahrani"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10807",
        "abstract": "We study whether regime-conditioned generative scenarios, coupled with a convex CVaR allocator, improve portfolio decisions under regime shifts. We introduce Multi-Agent Regime-Conditioned Diffusion (MARCD), which (i) infers latent regimes via a Gaussian HMM, (ii) trains a diffusion model with a tail-weighted objective and a regime-specialized mixture-of-experts (MoE) denoiser to enrich crisis co-movements, and (iii) feeds the generated scenarios into a turnover-aware CVaR epigraph quadratic program with explicit governance. In strict walk-forward tests on liquid multi-asset ETFs (2005-2025), MARCD outperforms standard allocators and improves calibration relative to popular generators. Over 2020-2025 out-of-sample (monthly; 10 bps), MARCD attains Sharpe 1.23 (BL 1.02) and MaxDD 9.3 percent (BL 14.1 percent), a 34 percent reduction, at comparable turnover; stationary block-bootstrap intervals indicate the Sharpe uplift is significant at 5 percent. We provide theory linking tail-weighted diffusion to spectral-risk control of the decision-relevant CVaR gap, oracle/consistency results for the regime-MoE denoiser, and Lipschitz/regret guarantees for the allocator. Together, MARCD offers a reproducible bridge from tail-faithful scenario modeling to governed portfolio decisions with materially improved drawdown control.",
        "tags": [
            "Diffusion",
            "MoE"
        ]
    },
    {
        "id": "286",
        "title": "LLMs as Strategic Agents: Beliefs, Best Response Behavior, and Emergent Heuristics",
        "author": [
            "Enric Junque de Fortuny",
            "Veronica Roberta Cappelli"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10813",
        "abstract": "Large Language Models (LLMs) are increasingly applied to domains that require reasoning about other agents' behavior, such as negotiation, policy design, and market simulation, yet existing research has mostly evaluated their adherence to equilibrium play or their exhibited depth of reasoning. Whether they display genuine strategic thinking, understood as the coherent formation of beliefs about other agents, evaluation of possible actions, and choice based on those beliefs, remains unexplored. We develop a framework to identify this ability by disentangling beliefs, evaluation, and choice in static, complete-information games, and apply it across a series of non-cooperative environments. By jointly analyzing models' revealed choices and reasoning traces, and introducing a new context-free game to rule out imitation from memorization, we show that current frontier models exhibit belief-coherent best-response behavior at targeted reasoning depths. When unconstrained, they self-limit their depth of reasoning and form differentiated conjectures about human and synthetic opponents, revealing an emergent form of meta-reasoning. Under increasing complexity, explicit recursion gives way to internally generated heuristic rules of choice that are stable, model-specific, and distinct from known human biases. These findings indicate that belief coherence, meta-reasoning, and novel heuristic formation can emerge jointly from language modeling objectives, providing a structured basis for the study of strategic cognition in artificial agents.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "287",
        "title": "DRIFT: Decompose, Retrieve, Illustrate, then Formalize Theorems",
        "author": [
            "Meiru Zhang",
            "Philipp Borchert",
            "Milan Gritta",
            "Gerasimos Lampouras"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10815",
        "abstract": "Automating the formalization of mathematical statements for theorem proving remains a major challenge for Large Language Models (LLMs). LLMs struggle to identify and utilize the prerequisite mathematical knowledge and its corresponding formal representation in languages like Lean. Current retrieval-augmented autoformalization methods query external libraries using the informal statement directly, but overlook a fundamental limitation: informal mathematical statements are often complex and offer limited context on the underlying math concepts. To address this, we introduce DRIFT, a novel framework that enables LLMs to decompose informal mathematical statements into smaller, more tractable ''sub-components''. This facilitates targeted retrieval of premises from mathematical libraries such as Mathlib. Additionally, DRIFT retrieves illustrative theorems to help models use premises more effectively in formalization tasks. We evaluate DRIFT across diverse benchmarks (ProofNet, ConNF, and MiniF2F-test) and find that it consistently improves premise retrieval, nearly doubling the F1 score compared to the DPR baseline on ProofNet. Notably, DRIFT demonstrates strong performance on the out-of-distribution ConNF benchmark, with BEq+@10 improvements of 37.14% and 42.25% using GPT-4.1 and DeepSeek-V3.1, respectively. Our analysis shows that retrieval effectiveness in mathematical autoformalization depends heavily on model-specific knowledge boundaries, highlighting the need for adaptive retrieval strategies aligned with each model's capabilities.",
        "tags": [
            "DeepSeek",
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "288",
        "title": "Generative AI and the Transformation of Software Development Practices",
        "author": [
            "Vivek Acharya"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10819",
        "abstract": "Generative AI is reshaping how software is designed, written, and maintained. Advances in large language models (LLMs) are enabling new development styles - from chat-oriented programming and 'vibe coding' to agentic programming - that can accelerate productivity and broaden access. This paper examines how AI-assisted techniques are changing software engineering practice, and the related issues of trust, accountability, and shifting skills. We survey iterative chat-based development, multi-agent systems, dynamic prompt orchestration, and integration via the Model Context Protocol (MCP). Using case studies and industry data, we outline both the opportunities (faster cycles, democratized coding) and the challenges (model reliability and cost) of applying generative AI to coding. We describe new roles, skills, and best practices for using AI in a responsible and effective way.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "289",
        "title": "Agentic RAG for Software Testing with Hybrid Vector-Graph and Multi-Agent Orchestration",
        "author": [
            "Mohanakrishnan Hariharan",
            "Satish Arvapalli",
            "Seshu Barma",
            "Evangeline Sheela"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10824",
        "abstract": "We present an approach to software testing automation using Agentic Retrieval-Augmented Generation (RAG) systems for Quality Engineering (QE) artifact creation. We combine autonomous AI agents with hybrid vector-graph knowledge systems to automate test plan, case, and QE metric generation. Our approach addresses traditional software testing limitations by leveraging LLMs such as Gemini and Mistral, multi-agent orchestration, and enhanced contextualization. The system achieves remarkable accuracy improvements from 65% to 94.8% while ensuring comprehensive document traceability throughout the quality engineering lifecycle. Experimental validation of enterprise Corporate Systems Engineering and SAP migration projects demonstrates an 85% reduction in testing timeline, an 85% improvement in test suite efficiency, and projected 35% cost savings, resulting in a 2-month acceleration of go-live.",
        "tags": [
            "LLM",
            "RAG"
        ]
    },
    {
        "id": "290",
        "title": "Software Defect Prediction using Autoencoder Transformer Model",
        "author": [
            "Seshu Barma",
            "Mohanakrishnan Hariharan",
            "Satish Arvapalli"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10840",
        "abstract": "An AI-ML-powered quality engineering approach uses AI-ML to enhance software quality assessments by predicting defects. Existing ML models struggle with noisy data types, imbalances, pattern recognition, feature extraction, and generalization. To address these challenges, we develop a new model, Adaptive Differential Evolution (ADE) based Quantum Variational Autoencoder-Transformer (QVAET) Model (ADE-QVAET). ADE combines with QVAET to obtain high-dimensional latent features and maintain sequential dependencies, resulting in enhanced defect prediction accuracy. ADE optimization enhances model convergence and predictive performance. ADE-QVAET integrates AI-ML techniques such as tuning hyperparameters for scalable and accurate software defect prediction, representing an AI-ML-driven technology for quality engineering. During training with a 90% training percentage, ADE-QVAET achieves high accuracy, precision, recall, and F1-score of 98.08%, 92.45%, 94.67%, and 98.12%, respectively, when compared to the Differential Evolution (DE) ML model.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "291",
        "title": "Contact Sensing via Joint Torque Sensors and a Force/Torque Sensor for Legged Robots",
        "author": [
            "Jared Grinberg",
            "Yanran Ding"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10843",
        "abstract": "This paper presents a method for detecting and localizing contact along robot legs using distributed joint torque sensors and a single hip-mounted force-torque (FT) sensor using a generalized momentum-based observer framework. We designed a low-cost strain-gauge-based joint torque sensor that can be installed on every joint to provide direct torque measurements, eliminating the need for complex friction models and providing more accurate torque readings than estimation based on motor current. Simulation studies on a floating-based 2-DoF robot leg verified that the proposed framework accurately recovers contact force and location along the thigh and shin links. Through a calibration procedure, our torque sensor achieved an average 96.4% accuracy relative to ground truth measurements. Building upon the torque sensor, we performed hardware experiments on a 2-DoF manipulator, which showed sub-centimeter contact localization accuracy and force errors below 0.2 N.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "292",
        "title": "DUAL-Bench: Measuring Over-Refusal and Robustness in Vision-Language Models",
        "author": [
            "Kaixuan Ren",
            "Preslav Nakov",
            "Usman Naseem"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10846",
        "abstract": "As vision-language models become increasingly capable, maintaining a balance between safety and usefulness remains a central challenge. Safety mechanisms, while essential, can backfire, causing over-refusal, where models decline benign requests out of excessive caution. Yet, no existing benchmark has systematically addressed over-refusal in the visual modality. This setting introduces unique challenges, such as dual-use cases where an instruction is harmless, but the accompanying image contains harmful content. Models frequently fail in such scenarios, either refusing too conservatively or completing tasks unsafely, which highlights the need for more fine-grained alignment. The ideal behavior is safe completion, i.e., fulfilling the benign parts of a request while explicitly warning about any potentially harmful elements. To address this, we present DUAL-Bench, the first multimodal benchmark focused on over-refusal and safe completion in VLMs. We evaluated 18 VLMs across 12 hazard categories, with focus on their robustness under semantics-preserving visual perturbations. The results reveal substantial room for improvement: GPT-5-Nano achieves 12.9% safe completion, GPT-5 models average 7.9%, and Qwen models only 3.9%. We hope that DUAL-Bench will foster the development of more nuanced alignment strategies that ensure models remain both safe and useful in complex multimodal settings.",
        "tags": [
            "GPT",
            "Qwen",
            "VLM"
        ]
    },
    {
        "id": "293",
        "title": "Glance for Context: Learning When to Leverage LLMs for Node-Aware GNN-LLM Fusion",
        "author": [
            "Donald Loveland",
            "Yao-An Yang",
            "Danai Koutra"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10849",
        "abstract": "Learning on text-attributed graphs has motivated the use of Large Language Models (LLMs) for graph learning. However, most fusion strategies are applied uniformly across all nodes and attain only small overall performance gains. We argue this result stems from aggregate metrics that obscure when LLMs provide benefit, inhibiting actionable signals for new strategies. In this work, we reframe LLM-GNN fusion around nodes where GNNs typically falter. We first show that performance can significantly differ between GNNs and LLMs, with each excelling on distinct structural patterns, such as local homophily. To leverage this finding, we propose GLANCE (GNN with LLM Assistance for Neighbor- and Context-aware Embeddings), a framework that invokes an LLM to refine a GNN's prediction. GLANCE employs a lightweight router that, given inexpensive per-node signals, decides whether to query the LLM. Since the LLM calls are non-differentiable, the router is trained with an advantage-based objective that compares the utility of querying the LLM against relying solely on the GNN. Across multiple benchmarks, GLANCE achieves the best performance balance across node subgroups, achieving significant gains on heterophilous nodes (up to $+13\\%$) while simultaneously achieving top overall performance. Our findings highlight the value of adaptive, node-aware GNN-LLM architectures, where selectively invoking the LLM enables scalable deployment on large graphs without incurring high computational costs.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "294",
        "title": "Preference-Conditioned Multi-Objective RL for Integrated Command Tracking and Force Compliance in Humanoid Locomotion",
        "author": [
            "Tingxuan Leng",
            "Yushi Wang",
            "Tinglong Zheng",
            "Changsheng Luo",
            "Mingguo Zhao"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10851",
        "abstract": "Humanoid locomotion requires not only accurate command tracking for navigation but also compliant responses to external forces during human interaction. Despite significant progress, existing RL approaches mainly emphasize robustness, yielding policies that resist external forces but lack compliance-particularly challenging for inherently unstable humanoids. In this work, we address this by formulating humanoid locomotion as a multi-objective optimization problem that balances command tracking and external force compliance. We introduce a preference-conditioned multi-objective RL (MORL) framework that integrates rigid command following and compliant behaviors within a single omnidirectional locomotion policy. External forces are modeled via velocity-resistance factor for consistent reward design, and training leverages an encoder-decoder structure that infers task-relevant privileged features from deployable observations. We validate our approach in both simulation and real-world experiments on a humanoid robot. Experimental results indicate that our framework not only improves adaptability and convergence over standard pipelines, but also realizes deployable preference-conditioned humanoid locomotion.",
        "tags": [
            "RL",
            "Robotics"
        ]
    },
    {
        "id": "295",
        "title": "Discrete State Diffusion Models: A Sample Complexity Perspective",
        "author": [
            "Aadithya Srikanth",
            "Mudit Gaur",
            "Vaneet Aggarwal"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10854",
        "abstract": "Diffusion models have demonstrated remarkable performance in generating high-dimensional samples across domains such as vision, language, and the sciences. Although continuous-state diffusion models have been extensively studied both empirically and theoretically, discrete-state diffusion models, essential for applications involving text, sequences, and combinatorial structures, remain significantly less understood from a theoretical standpoint. In particular, all existing analyses of discrete-state models assume score estimation error bounds without studying sample complexity results. In this work, we present a principled theoretical framework for discrete-state diffusion, providing the first sample complexity bound of $\\widetilde{\\mathcal{O}}(\\epsilon^{-2})$. Our structured decomposition of the score estimation error into statistical, approximation, optimization, and clipping components offers critical insights into how discrete-state models can be trained efficiently. This analysis addresses a fundamental gap in the literature and establishes the theoretical tractability and practical relevance of discrete-state diffusion models.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "296",
        "title": "GRIP: A Unified Framework for Grid-Based Relay and Co-Occurrence-Aware Planning in Dynamic Environments",
        "author": [
            "Ahmed Alanazi",
            "Duy Ho",
            "Yugyung Lee"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10865",
        "abstract": "Robots navigating dynamic, cluttered, and semantically complex environments must integrate perception, symbolic reasoning, and spatial planning to generalize across diverse layouts and object categories. Existing methods often rely on static priors or limited memory, constraining adaptability under partial observability and semantic ambiguity. We present GRIP, Grid-based Relay with Intermediate Planning, a unified, modular framework with three scalable variants: GRIP-L (Lightweight), optimized for symbolic navigation via semantic occupancy grids; GRIP-F (Full), supporting multi-hop anchor chaining and LLM-based introspection; and GRIP-R (Real-World), enabling physical robot deployment under perceptual uncertainty. GRIP integrates dynamic 2D grid construction, open-vocabulary object grounding, co-occurrence-aware symbolic planning, and hybrid policy execution using behavioral cloning, D* search, and grid-conditioned control. Empirical results on AI2-THOR and RoboTHOR benchmarks show that GRIP achieves up to 9.6% higher success rates and over $2\\times$ improvement in path efficiency (SPL and SAE) on long-horizon tasks. Qualitative analyses reveal interpretable symbolic plans in ambiguous scenes. Real-world deployment on a Jetbot further validates GRIP's generalization under sensor noise and environmental variation. These results position GRIP as a robust, scalable, and explainable framework bridging simulation and real-world navigation.",
        "tags": [
            "LLM",
            "Robotics"
        ]
    },
    {
        "id": "297",
        "title": "FastHMR: Accelerating Human Mesh Recovery via Token and Layer Merging with Diffusion Decoding",
        "author": [
            "Soroush Mehraban",
            "Andrea Iaboni",
            "Babak Taati"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10868",
        "abstract": "Recent transformer-based models for 3D Human Mesh Recovery (HMR) have achieved strong performance but often suffer from high computational cost and complexity due to deep transformer architectures and redundant tokens. In this paper, we introduce two HMR-specific merging strategies: Error-Constrained Layer Merging (ECLM) and Mask-guided Token Merging (Mask-ToMe). ECLM selectively merges transformer layers that have minimal impact on the Mean Per Joint Position Error (MPJPE), while Mask-ToMe focuses on merging background tokens that contribute little to the final prediction. To further address the potential performance drop caused by merging, we propose a diffusion-based decoder that incorporates temporal context and leverages pose priors learned from large-scale motion capture datasets. Experiments across multiple benchmarks demonstrate that our method achieves up to 2.3x speed-up while slightly improving performance over the baseline.",
        "tags": [
            "3D",
            "Diffusion",
            "Transformer"
        ]
    },
    {
        "id": "298",
        "title": "Where on Earth? A Vision-Language Benchmark for Probing Model Geolocation Skills Across Scales",
        "author": [
            "Zhaofang Qian",
            "Hardy Chen",
            "Zeyu Wang",
            "Li Zhang",
            "Zijun Wang",
            "Xiaoke Huang",
            "Hui Liu",
            "Xianfeng Tang",
            "Zeyu Zheng",
            "Haoqin Tu",
            "Cihang Xie",
            "Yuyin Zhou"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10880",
        "abstract": "Vision-language models (VLMs) have advanced rapidly, yet their capacity for image-grounded geolocation in open-world conditions, a task that is challenging and of demand in real life, has not been comprehensively evaluated. We present EarthWhere, a comprehensive benchmark for VLM image geolocation that evaluates visual recognition, step-by-step reasoning, and evidence use. EarthWhere comprises 810 globally distributed images across two complementary geolocation scales: WhereCountry (i.e., 500 multiple-choice question-answering, with country-level answer and panoramas) and WhereStreet (i.e., 310 fine-grained street-level identification tasks requiring multi-step reasoning with optional web search). For evaluation, we adopt the final-prediction metrics: location accuracies within k km (Acc@k) for coordinates and hierarchical path scores for textual localization. Beyond this, we propose to explicitly score intermediate reasoning chains using human-verified key visual clues and a Shapley-reweighted thinking score that attributes credit to each clue's marginal contribution. We benchmark 13 state-of-the-art VLMs with web searching tools on our EarthWhere and report different types of final answer accuracies as well as the calibrated model thinking scores. Overall, Gemini-2.5-Pro achieves the best average accuracy at 56.32%, while the strongest open-weight model, GLM-4.5V, reaches 34.71%. We reveal that web search and reasoning do not guarantee improved performance when visual clues are limited, and models exhibit regional biases, achieving up to 42.7% higher scores in certain areas than others. These findings highlight not only the promise but also the persistent challenges of models to mitigate bias and achieve robust, fine-grained localization. We open-source our benchmark at https://github.com/UCSC-VLAA/EarthWhere.",
        "tags": [
            "GLM",
            "VLM"
        ]
    },
    {
        "id": "299",
        "title": "Topological Alignment of Shared Vision-Language Embedding Space",
        "author": [
            "Junwon You",
            "Dasol Kang",
            "Jae-Hun Jung"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10889",
        "abstract": "Contrastive Vision-Language Models (VLMs) have demonstrated strong zero-shot capabilities. However, their cross-modal alignment remains biased toward English due to limited multilingual multimodal data. Recent multilingual extensions have alleviated this gap but enforce instance-level alignment while neglecting the global geometry of the shared embedding space. We address this problem by introducing ToMCLIP (Topological Alignment for Multilingual CLIP), a topology-aware framework aligning embedding spaces with topology-preserving constraints. The proposed method applies persistent homology to define a topological alignment loss and approximates persistence diagram with theoretical error bounds using graph sparsification strategy. This work validates the proposed approach, showing enhanced structural coherence of multilingual representations, higher zero-shot accuracy on the CIFAR-100, and stronger multilingual retrieval performance on the xFlickr&CO. Beyond VLMs, the proposed approach provides a general method for incorporating topological alignment into representation learning.",
        "tags": [
            "CLIP",
            "VLM"
        ]
    },
    {
        "id": "300",
        "title": "LLM$\\times$MapReduce-V3: Enabling Interactive In-Depth Survey Generation through a MCP-Driven Hierarchically Modular Agent System",
        "author": [
            "Yu Chao",
            "Siyu Lin",
            "xiaorong wang",
            "Zhu Zhang",
            "Zihan Zhou",
            "Haoyu Wang",
            "Shuo Wang",
            "Jie Zhou",
            "Zhiyuan Liu",
            "Maosong Sun"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10890",
        "abstract": "We introduce LLM x MapReduce-V3, a hierarchically modular agent system designed for long-form survey generation. Building on the prior work, LLM x MapReduce-V2, this version incorporates a multi-agent architecture where individual functional components, such as skeleton initialization, digest construction, and skeleton refinement, are implemented as independent model-context-protocol (MCP) servers. These atomic servers can be aggregated into higher-level servers, creating a hierarchically structured system. A high-level planner agent dynamically orchestrates the workflow by selecting appropriate modules based on their MCP tool descriptions and the execution history. This modular decomposition facilitates human-in-the-loop intervention, affording users greater control and customization over the research process. Through a multi-turn interaction, the system precisely captures the intended research perspectives to generate a comprehensive skeleton, which is then developed into an in-depth survey. Human evaluations demonstrate that our system surpasses representative baselines in both content depth and length, highlighting the strength of MCP-based modular planning.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "301",
        "title": "Multiscale Graph Reduction for Heterogeneous and Anisotropic Discrete Diffusion Processes",
        "author": [
            "Maria Vasilyeva",
            "James Brannick",
            "Ben S. Southworth"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10894",
        "abstract": "We present multiscale graph-based reduction algorithms for upscaling heterogeneous and anisotropic diffusion problems. The proposed coarsening approaches begin by constructing a partitioning of the computational domain into a set of balanced local subdomains, resulting in a standard type of domain decomposition. Given this initial decomposition, general coarsening techniques based on spectral clustering are applied within each subgraph in order to accurately identify the key microscopic features of a given system. The spectral clustering algorithm is based on local generalized eigen-decompositions applied to the signed graph Laplacian. The resulting coarse-fine splittings are combined with two variants of energy-minimizing strategies for constructing coarse bases for diffusion problems. The first is an unconstrained minimization formulation in which local harmonic extensions are applied column-wise to construct multi-vector preserving interpolation in each region, whereas the second approach is a variant of the constrained energy minimization formulations derived in the context of non-local multi-continua upscaling techniques. We apply the resulting upscaling algorithms to a variety of tests coming from the graph Laplacian, including diffusion in the perforated domain, channelized media, highly anisotropic settings, and discrete pore network models to demonstrate the potential and robustness of the proposed coarsening approaches. We show numerically and theoretically that the proposed approaches lead to accurate coarse-scale models.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "302",
        "title": "LLM-Empowered Agentic MAC Protocols: A Dynamic Stackelberg Game Approach",
        "author": [
            "Renxuan Tan",
            "Rongpeng Li",
            "Fei Wang",
            "Chenghui Peng",
            "Shaoyun Wu",
            "Zhifeng Zhao",
            "Honggang Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10895",
        "abstract": "Medium Access Control (MAC) protocols, essential for wireless networks, are typically manually configured. While deep reinforcement learning (DRL)-based protocols enhance task-specified network performance, they suffer from poor generalizability and resilience, demanding costly retraining to adapt to dynamic environments. To overcome this limitation, we introduce a game-theoretic LLM-empowered multi-agent DRL (MARL) framework, in which the uplink transmission between a base station and a varying number of user equipments is modeled as a dynamic multi-follower Stackelberg game (MFSG), capturing the network's natural hierarchical structure. Within this game, LLM-driven agents, coordinated through proximal policy optimization (PPO), synthesize adaptive, semantic MAC protocols in response to network dynamics. Protocol action grammar (PAG) is employed to ensure the reliability and efficiency of this process. Under this system, we further analyze the existence and convergence behavior in terms of a Stackelberg equilibrium by studying the learning dynamics of LLM-empowered unified policies in response to changing followers. Simulations corroborate that our framework achieves a 77.6% greater throughput and a 65.2% fairness improvement over conventional baselines. Besides, our framework generalizes excellently to a fluctuating number of users without requiring retraining or architectural changes.",
        "tags": [
            "LLM",
            "PPO",
            "RL"
        ]
    },
    {
        "id": "303",
        "title": "Towards a Unified Understanding of Robot Manipulation: A Comprehensive Survey",
        "author": [
            "Shuanghao Bai",
            "Wenxuan Song",
            "Jiayi Chen",
            "Yuheng Ji",
            "Zhide Zhong",
            "Jin Yang",
            "Han Zhao",
            "Wanqi Zhou",
            "Wei Zhao",
            "Zhe Li",
            "Pengxiang Ding",
            "Cheng Chi",
            "Haoang Li",
            "Chang Xu",
            "Xiaolong Zheng",
            "Donglin Wang",
            "Shanghang Zhang",
            "Badong Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10903",
        "abstract": "Embodied intelligence has witnessed remarkable progress in recent years, driven by advances in computer vision, natural language processing, and the rise of large-scale multimodal models. Among its core challenges, robot manipulation stands out as a fundamental yet intricate problem, requiring the seamless integration of perception, planning, and control to enable interaction within diverse and unstructured environments. This survey presents a comprehensive overview of robotic manipulation, encompassing foundational background, task-organized benchmarks and datasets, and a unified taxonomy of existing methods. We extend the classical division between high-level planning and low-level control by broadening high-level planning to include language, code, motion, affordance, and 3D representations, while introducing a new taxonomy of low-level learning-based control grounded in training paradigms such as input modeling, latent learning, and policy learning. Furthermore, we provide the first dedicated taxonomy of key bottlenecks, focusing on data collection, utilization, and generalization, and conclude with an extensive review of real-world applications. Compared with prior surveys, our work offers both a broader scope and deeper insight, serving as an accessible roadmap for newcomers and a structured reference for experienced researchers. All related resources, including research papers, open-source datasets, and projects, are curated for the community at https://github.com/BaiShuanghao/Awesome-Robotics-Manipulation.",
        "tags": [
            "3D",
            "Robotics"
        ]
    },
    {
        "id": "304",
        "title": "PaperArena: An Evaluation Benchmark for Tool-Augmented Agentic Reasoning on Scientific Literature",
        "author": [
            "Daoyu Wang",
            "Mingyue Cheng",
            "Qi Liu",
            "Shuo Yu",
            "Zirui Liu",
            "Ze Guo"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10909",
        "abstract": "Understanding and reasoning on the web-scale scientific literature is a crucial touchstone for large language model (LLM) based agents designed to support complex knowledge-intensive tasks. However, existing works are mainly restricted to tool-free tasks within isolated papers, largely due to the lack of a benchmark for cross-paper reasoning and multi-tool orchestration in real research scenarios. In this work, we propose PaperArena, an evaluation benchmark for agents to address real-world research questions that typically require integrating information across multiple papers with the assistance of external tools. Given a research question, agents should integrate diverse formats across multiple papers through reasoning and interacting with appropriate tools, thereby producing a well-grounded answer. To support standardized evaluation, we provide a modular and extensible platform for agent execution, offering tools such as multimodal parsing, context retrieval, and programmatic computation. Experimental results reveal that even the most advanced LLM powering a well-established agent system achieves merely 38.78% average accuracy. On the hard subset, accuracy drops to only 18.47%, highlighting great potential for improvement. We also present several empirical findings, including that all agents tested exhibit inefficient tool usage, often invoking more tools than necessary to solve a task. We invite the community to adopt PaperArena to develop and evaluate more capable agents for scientific discovery. Our code and data are available https://github.com/Melmaphother/PaperArena.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "305",
        "title": "SceneTextStylizer: A Training-Free Scene Text Style Transfer Framework with Diffusion Model",
        "author": [
            "Honghui Yuan",
            "Keiji Yanai"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10910",
        "abstract": "With the rapid development of diffusion models, style transfer has made remarkable progress. However, flexible and localized style editing for scene text remains an unsolved challenge. Although existing scene text editing methods have achieved text region editing, they are typically limited to content replacement and simple styles, which lack the ability of free-style transfer. In this paper, we introduce SceneTextStylizer, a novel training-free diffusion-based framework for flexible and high-fidelity style transfer of text in scene images. Unlike prior approaches that either perform global style transfer or focus solely on textual content modification, our method enables prompt-guided style transformation specifically for text regions, while preserving both text readability and stylistic consistency. To achieve this, we design a feature injection module that leverages diffusion model inversion and self-attention to transfer style features effectively. Additionally, a region control mechanism is introduced by applying a distance-based changing mask at each denoising step, enabling precise spatial control. To further enhance visual quality, we incorporate a style enhancement module based on the Fourier transform to reinforce stylistic richness. Extensive experiments demonstrate that our method achieves superior performance in scene text style transformation, outperforming existing state-of-the-art methods in both visual fidelity and text preservation.",
        "tags": [
            "Diffusion",
            "Style Transfer"
        ]
    },
    {
        "id": "306",
        "title": "ADVICE: Answer-Dependent Verbalized Confidence Estimation",
        "author": [
            "Ki Jung Seo",
            "Sehun Lim",
            "Taeuk Kim"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10913",
        "abstract": "Recent progress in large language models (LLMs) has enabled them to express their confidence in natural language, enhancing transparency and reliability. However, their confidence often exhibits overconfidence, the cause of which remains poorly understood. In this work, we conduct a detailed analysis of the dynamics underlying verbalized confidence and identify answer-independence as a key factor, defined as the model's failure to condition confidence on its own answer. To address this, we propose ADVICE (Answer-Dependent Verbalized Confidence Estimation), a fine-tuning framework that facilitates answer-grounded confidence estimation. Extensive experiments show that ADVICE substantially improves confidence calibration while preserving task performance. Further analyses confirm that ADVICE strengthens answer-groundedness, leading to more balanced and well-calibrated confidence distributions. Our findings shed light on the origin of overconfidence and establish a framework for more trustworthy confidence verbalization.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "307",
        "title": "DreamMakeup: Face Makeup Customization using Latent Diffusion Models",
        "author": [
            "Geon Yeong Park",
            "Inhwa Han",
            "Serin Yang",
            "Yeobin Hong",
            "Seongmin Jeong",
            "Heechan Jeon",
            "Myeongjin Goh",
            "Sung Won Yi",
            "Jin Nam",
            "Jong Chul Ye"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10918",
        "abstract": "The exponential growth of the global makeup market has paralleled advancements in virtual makeup simulation technology. Despite the progress led by GANs, their application still encounters significant challenges, including training instability and limited customization capabilities. Addressing these challenges, we introduce DreamMakup - a novel training-free Diffusion model based Makeup Customization method, leveraging the inherent advantages of diffusion models for superior controllability and precise real-image editing. DreamMakeup employs early-stopped DDIM inversion to preserve the facial structure and identity while enabling extensive customization through various conditioning inputs such as reference images, specific RGB colors, and textual descriptions. Our model demonstrates notable improvements over existing GAN-based and recent diffusion-based frameworks - improved customization, color-matching capabilities, identity preservation and compatibility with textual descriptions or LLMs with affordable computational costs.",
        "tags": [
            "DDIM",
            "Diffusion",
            "GAN",
            "Image Editing",
            "LLM"
        ]
    },
    {
        "id": "308",
        "title": "FG-CLIP 2: A Bilingual Fine-grained Vision-Language Alignment Model",
        "author": [
            "Chunyu Xie",
            "Bin Wang",
            "Fanjing Kong",
            "Jincheng Li",
            "Dawei Liang",
            "Ji Ao",
            "Dawei Leng",
            "Yuhui Yin"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10921",
        "abstract": "Fine-grained vision-language understanding requires precise alignment between visual content and linguistic descriptions, a capability that remains limited in current models, particularly in non-English settings. While models like CLIP perform well on global alignment, they often struggle to capture fine-grained details in object attributes, spatial relations, and linguistic expressions, with limited support for bilingual comprehension. To address these challenges, we introduce FG-CLIP 2, a bilingual vision-language model designed to advance fine-grained alignment for both English and Chinese. Our approach leverages rich fine-grained supervision, including region-text matching and long-caption modeling, alongside multiple discriminative objectives. We further introduce the Textual Intra-modal Contrastive (TIC) loss to better distinguish semantically similar captions. Trained on a carefully curated mixture of large-scale English and Chinese data, FG-CLIP 2 achieves powerful bilingual performance. To enable rigorous evaluation, we present a new benchmark for Chinese multimodal understanding, featuring long-caption retrieval and bounding box classification. Extensive experiments on 29 datasets across 8 tasks show that FG-CLIP 2 outperforms existing methods, achieving state-of-the-art results in both languages. We release the model, code, and benchmark to facilitate future research on bilingual fine-grained alignment.",
        "tags": [
            "CLIP"
        ]
    },
    {
        "id": "309",
        "title": "PoU: Proof-of-Use to Counter Tool-Call Hacking in DeepResearch Agents",
        "author": [
            "SHengjie Ma",
            "Chenlong Deng",
            "Jiaxin Mao",
            "Jiadeng Huang",
            "Teng Wang",
            "Junjie Wu",
            "Changwang Zhang",
            "Jun wang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10931",
        "abstract": "Retrieval-augmented generation (RAG) agents, such as recent DeepResearch-style systems, extend large language models (LLMs) with autonomous information-seeking capabilities through external tools. While reinforcement learning (RL) has enabled impressive multi-step reasoning, we identify a previously overlooked failure mode, Tool-Call Hacking, where agents inflate reward signals by issuing superficially correct tool calls without genuinely leveraging the retrieved evidence. This results in (i) mode collapse into repetitive reliance on a single source and (ii) spurious grounding, where answers are only weakly supported by cited content.\nTo address this, we propose Proof-of-Use (PoU), an evidence-grounded RL framework that enforces verifiable causal links between retrieved evidence, reasoning traces, and final answers. PoU operationalizes this through a unified step-wise contract combining syntactic citation validation, perturbation-based sensitivity rewards, and answer-evidence alignment objectives, ensuring that tool usage remains both interpretable and functionally grounded.\nAcross seven QA benchmarks spanning in-domain, out-of-domain, and out-of-tool-distribution settings, PoU consistently outperforms strong DeepResearch baselines in factual accuracy, evidence faithfulness, and tool-routing balance. These findings highlight the necessity of grounding RL-trained agents not merely in task outcomes but in the causal use of retrieved information, offering a principled path toward trustworthy retrieval-augmented reasoning.",
        "tags": [
            "LLM",
            "RAG",
            "RL"
        ]
    },
    {
        "id": "310",
        "title": "Scalable and Explainable Enterprise Knowledge Discovery Using Graph-Centric Hybrid Retrieval",
        "author": [
            "Nilima Rao",
            "Jagriti Srivastava",
            "Pradeep Kumar Sharma",
            "Hritvik Shrivastava"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10942",
        "abstract": "Modern enterprises manage vast knowledge distributed across heterogeneous systems such as Jira, Git repositories, Confluence, and wikis. Conventional retrieval methods based on keyword search or static embeddings often fail to answer complex queries that require contextual reasoning and multi-hop inference across artifacts. We present a modular hybrid retrieval framework for adaptive enterprise information access that integrates Knowledge Base Language-Augmented Models (KBLam), DeepGraph representations, and embedding-driven semantic search. The framework builds a unified knowledge graph from parsed repositories including code, pull requests, and commit histories, enabling semantic similarity search, structural inference, and multi-hop reasoning. Query analysis dynamically determines the optimal retrieval strategy, supporting both structured and unstructured data sources through independent or fused processing. An interactive interface provides graph visualizations, subgraph exploration, and context-aware query routing to generate concise and explainable answers. Experiments on large-scale Git repositories show that the unified reasoning layer improves answer relevance by up to 80 percent compared with standalone GPT-based retrieval pipelines. By combining graph construction, hybrid reasoning, and interactive visualization, the proposed framework offers a scalable, explainable, and user-centric foundation for intelligent knowledge assistants in enterprise environments.",
        "tags": [
            "GPT"
        ]
    },
    {
        "id": "311",
        "title": "The Social Cost of Intelligence: Emergence, Propagation, and Amplification of Stereotypical Bias in Multi-Agent Systems",
        "author": [
            "Thi-Nhung Nguyen",
            "Linhao Luo",
            "Thuy-Trang Vu",
            "Dinh Phung"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10943",
        "abstract": "Bias in large language models (LLMs) remains a persistent challenge, manifesting in stereotyping and unfair treatment across social groups. While prior research has primarily focused on individual models, the rise of multi-agent systems (MAS), where multiple LLMs collaborate and communicate, introduces new and largely unexplored dynamics in bias emergence and propagation. In this work, we present a comprehensive study of stereotypical bias in MAS, examining how internal specialization, underlying LLMs and inter-agent communication protocols influence bias robustness, propagation, and amplification. We simulate social contexts where agents represent different social groups and evaluate system behavior under various interaction and adversarial scenarios. Experiments on three bias benchmarks reveal that MAS are generally less robust than single-agent systems, with bias often emerging early through in-group favoritism. However, cooperative and debate-based communication can mitigate bias amplification, while more robust underlying LLMs improve overall system stability. Our findings highlight critical factors shaping fairness and resilience in multi-agent LLM systems.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "312",
        "title": "Project-Level C-to-Rust Translation via Synergistic Integration of Knowledge Graphs and Large Language Models",
        "author": [
            "Zhiqiang Yuan",
            "Wenjun Mao",
            "Zhuo Chen",
            "Xiyue Shang",
            "Chong Wang",
            "Yiling Lou",
            "Xin Peng"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10956",
        "abstract": "Translating C code into safe Rust is an effective way to ensure its memory safety. Compared to rule-based translation which produces Rust code that remains largely unsafe, LLM-based methods can generate more idiomatic and safer Rust code because LLMs have been trained on vast amount of human-written idiomatic code. Although promising, existing LLM-based methods still struggle with project-level C-to-Rust translation. They typically partition a C project into smaller units (\\eg{} functions) based on call graphs and translate them bottom-up to resolve program dependencies. However, this bottom-up, unit-by-unit paradigm often fails to translate pointers due to the lack of a global perspective on their usage. To address this problem, we propose a novel C-Rust Pointer Knowledge Graph (KG) that enriches a code-dependency graph with two types of pointer semantics: (i) pointer-usage information which record global behaviors such as points-to flows and map lower-level struct usage to higher-level units; and (ii) Rust-oriented annotations which encode ownership, mutability, nullability, and lifetime. Synthesizing the \\kg{} with LLMs, we further propose \\ourtool{}, which implements a project-level C-to-Rust translation technique. In \\ourtool{}, the \\kg{} provides LLMs with comprehensive pointer semantics from a global perspective, thus guiding LLMs towards generating safe and idiomatic Rust code from a given C project. Our experiments show that \\ourtool{} reduces unsafe usages in translated Rust by 99.9\\% compared to both rule-based translation and traditional LLM-based rewriting, while achieving an average 29.3\\% higher functional correctness than those fuzzing-enhanced LLM methods.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "313",
        "title": "Rediscovering Entropy Regularization: Adaptive Coefficient Unlocks Its Potential for LLM Reinforcement Learning",
        "author": [
            "Xiaoyun Zhang",
            "Xiaojian Yuan",
            "Di Huang",
            "Wang You",
            "Chen Hu",
            "Jingqing Ruan",
            "Kejiang Chen",
            "Xing Hu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10959",
        "abstract": "Reasoning ability has become a defining capability of Large Language Models (LLMs), with Reinforcement Learning with Verifiable Rewards (RLVR) emerging as a key paradigm to enhance it. However, RLVR training often suffers from policy entropy collapse, where the policy becomes overly deterministic, hindering exploration and limiting reasoning performance. While entropy regularization is a common remedy, its effectiveness is highly sensitive to the fixed coefficient, making it unstable across tasks and models. In this work, we revisit entropy regularization in RLVR and argue that its potential has been largely underestimated. Our analysis shows that (i) tasks of varying difficulty demand distinct exploration intensities, and (ii) balanced exploration may require the policy entropy to be maintained within a moderate range below its initial level. Therefore, we propose Adaptive Entropy Regularization (AER)--a framework that dynamically balances exploration and exploitation via three components: difficulty-aware coefficient allocation, initial-anchored target entropy, and dynamic global coefficient adjustment. Experiments on multiple mathematical reasoning benchmarks show that AER consistently outperforms baselines, improving both reasoning accuracy and exploration capability.",
        "tags": [
            "LLM",
            "RL"
        ]
    },
    {
        "id": "314",
        "title": "Game-Theoretic Risk-Shaped Reinforcement Learning for Safe Autonomous Driving",
        "author": [
            "Dong Hu",
            "Fenqing Hu",
            "Lidong Yang",
            "Chao Huang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10960",
        "abstract": "Ensuring safety in autonomous driving (AD) remains a significant challenge, especially in highly dynamic and complex traffic environments where diverse agents interact and unexpected hazards frequently emerge. Traditional reinforcement learning (RL) methods often struggle to balance safety, efficiency, and adaptability, as they primarily focus on reward maximization without explicitly modeling risk or safety constraints. To address these limitations, this study proposes a novel game-theoretic risk-shaped RL (GTR2L) framework for safe AD. GTR2L incorporates a multi-level game-theoretic world model that jointly predicts the interactive behaviors of surrounding vehicles and their associated risks, along with an adaptive rollout horizon that adjusts dynamically based on predictive uncertainty. Furthermore, an uncertainty-aware barrier mechanism enables flexible modulation of safety boundaries. A dedicated risk modeling approach is also proposed, explicitly capturing both epistemic and aleatoric uncertainty to guide constrained policy optimization and enhance decision-making in complex environments. Extensive evaluations across diverse and safety-critical traffic scenarios show that GTR2L significantly outperforms state-of-the-art baselines, including human drivers, in terms of success rate, collision and violation reduction, and driving efficiency. The code is available at https://github.com/DanielHu197/GTR2L.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "315",
        "title": "KOTOX: A Korean Toxic Dataset for Deobfuscation and Detoxification",
        "author": [
            "Yejin Lee",
            "Su-Hyeon Kim",
            "Hyundong Jin",
            "Dayoung Kim",
            "Yeonsoo Kim",
            "Yo-Sub Han"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10961",
        "abstract": "Toxic content has become an increasingly critical social issue with the rapid expansion of online communication. While numerous studies explored methods for detecting and detoxifying such content, most have focused primarily on English, leaving low-resource language underrepresented. Consequently, Large Language Models~(LLMs) often struggle to identify and neutralize toxic expressions in these languages. This challenge becomes even more pronounced when user employ obfuscation techniques to evade detection systems. Therefore, we propose a \\textbf{KOTOX: Korean Toxic Dataset} for deobfuscation and detoxicification to address this issue. We categorize various obfuscation approaches based on linguistic characteristics of Korean and define a set of transformation rules grounded in real-word examples. Using these rules, we construct three dataset versions (easy, normal, and hard) representing different levels of obfuscation difficulty. This is the first dataset that simultaneously supports deobfuscation and detoxification for the Korean language. We expect it to facilitate better understanding and mitigating of obfuscated toxic content in LLM for low-resource languages. Our code and data are available at https://github.com/leeyejin1231/KOTOX.",
        "tags": [
            "Detection",
            "LLM"
        ]
    },
    {
        "id": "316",
        "title": "MC#: Mixture Compressor for Mixture-of-Experts Large Models",
        "author": [
            "Wei Huang",
            "Yue Liao",
            "Yukang Chen",
            "Jianhui Liu",
            "Haoru Tan",
            "Si Liu",
            "Shiming Zhang",
            "Shuicheng Yan",
            "Xiaojuan Qi"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10962",
        "abstract": "Mixture-of-Experts (MoE) effectively scales large language models (LLMs) and vision-language models (VLMs) by increasing capacity through sparse activation. However, preloading all experts into memory and activating multiple experts per input introduces significant computational and memory overhead, making the expert module a major contributor to model size and inference cost. To address this, we propose MC# (Mixture-Compressor-sharp), a framework that combines static quantization and dynamic expert pruning by leveraging the significance of experts and tokens for aggressive compression of MoE-LLMs/VLMs. To reduce storage and loading costs, we introduce Pre-Loading Mixed-Precision Quantization (PMQ), which optimizes bit allocation via linear programming, balancing expert importance and quantization error for a Pareto-optimal trade-off between size and performance. To reduce runtime computation, Online Top-any Pruning (OTP) uses Gumbel-Softmax sampling to dynamically select a subset of experts per token, enabling fine-grained control over activation. By combining PMQ's static bit-width optimization with OTP's dynamic routing, MC# achieves extreme compression with minimal accuracy loss. On DeepSeek-VL2, MC# achieves a 6.2 times weight reduction at 2.57 average bits with only a 1.7% accuracy drop across five multimodal benchmarks. Additionally, OTP reduces expert activation over 20% with less than 1% performance degradation, demonstrating strong potential for efficient MoE-based model deployment.",
        "tags": [
            "DeepSeek",
            "LLM",
            "MoE",
            "VLM"
        ]
    },
    {
        "id": "317",
        "title": "APLOT: Robust Reward Modeling via Adaptive Preference Learning with Optimal Transport",
        "author": [
            "Zhuo Li",
            "Yuege Feng",
            "Dandan Guo",
            "Jinpeng Hu",
            "Anningzhe Gao",
            "Xiang Wan"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10963",
        "abstract": "The reward model (RM) plays a crucial role in aligning Large Language Models (LLMs) with human preferences through Reinforcement Learning, where the Bradley-Terry (BT) objective has been recognized as simple yet powerful, specifically for pairwise preference learning. However, BT-based RMs often struggle to effectively distinguish between similar preference responses, leading to insufficient separation between preferred and non-preferred outputs. Consequently, they may easily overfit easy samples and cannot generalize well to Out-Of-Distribution (OOD) samples, resulting in suboptimal performance. To address these challenges, this paper introduces an effective enhancement to BT-based RMs through an adaptive margin mechanism. Specifically, we design to dynamically adjust the RM focus on more challenging samples through margins, based on both semantic similarity and model-predicted reward differences, which is approached from a distributional perspective solvable with Optimal Transport (OT). By incorporating these factors into a principled OT cost matrix design, our adaptive margin enables the RM to better capture distributional differences between chosen and rejected responses, yielding significant improvements in performance, convergence speed, and generalization capabilities. Experimental results across multiple benchmarks demonstrate that our method outperforms several existing RM techniques, showcasing enhanced performance in both In-Distribution (ID) and OOD settings. Moreover, RLHF experiments support our practical effectiveness in better aligning LLMs with human preferences. Our code is available at https://github.com/BIRlz/APLOT",
        "tags": [
            "LLM",
            "RL",
            "RLHF"
        ]
    },
    {
        "id": "318",
        "title": "Not All Bits Are Equal: Scale-Dependent Memory Optimization Strategies for Reasoning Models",
        "author": [
            "Junhyuck Kim",
            "Ethan Ewer",
            "Taehong Moon",
            "Jongho Park",
            "Dimitris Papailiopoulos"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10964",
        "abstract": "While 4-bit quantization has emerged as a memory-optimal choice for non-reasoning models and zero-shot tasks across scales, we show that this universal prescription fails for reasoning models, where the KV cache rather than model size can dominate memory. Through systematic experiments across 1,700 inference scenarios on AIME25 and GPQA-Diamond, we find a scale-dependent trade-off: models with an effective size below 8-bit 4B parameters achieve better accuracy by allocating memory to more weights rather than longer generation, while larger models achieve better accuracy by allocating memory to longer generations. This scale threshold also determines when parallel scaling becomes memory-efficient and whether KV cache eviction outperforms KV quantization. Our findings show that memory optimization for LLMs cannot be scale-agnostic, while providing principled guidelines: for small reasoning models, prioritize model capacity over test-time compute, while for larger ones, maximize test-time compute. Our results suggest that optimizing reasoning models for deployment requires fundamentally different strategies from those established for non-reasoning models.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "319",
        "title": "Judge Before Answer: Can MLLM Discern the False Premise in Question?",
        "author": [
            "Jidong Li",
            "Lingyong Fang",
            "Haodong Zhao",
            "Sufeng Duan",
            "Gongshen Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10965",
        "abstract": "Multimodal large language models (MLLMs) have witnessed astonishing advancements in recent years. Despite these successes, MLLMs remain vulnerable to flase premise problems. However, existing benchmarks targeting this issue are limited in scope: they often lack fine-grained categorization, exhibit insufficient coverage, and thus fail to provide a rigorous evaluation of the ability of models to recognize false premises. To bridge this gap, we introduce a fully automated pipeline for constructing a comprehensive benchmark of false premise questions. Our method systematically categorizes the premises into three main types and thirteen subtypes according to the abilities required to identify the premises, resulting in the JBA http://dataset.Results show current MLLMs still struggle with false premise recognition. Building upon this benchmark, we further propose a recognition enhancement framework tailored to strengthen the robustness of MLLMs to detect false premises. Extensive experiments demonstrate that models trained with our framework achieve significant improvements in false premise recognition.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "320",
        "title": "Blade: A Derivative-free Bayesian Inversion Method using Diffusion Priors",
        "author": [
            "Hongkai Zheng",
            "Austin Wang",
            "Zihui Wu",
            "Zhengyu Huang",
            "Ricardo Baptista",
            "Yisong Yue"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10968",
        "abstract": "Derivative-free Bayesian inversion is an important task in many science and engineering applications, particularly when computing the forward model derivative is computationally and practically challenging. In this paper, we introduce Blade, which can produce accurate and well-calibrated posteriors for Bayesian inversion using an ensemble of interacting particles. Blade leverages powerful data-driven priors based on diffusion models, and can handle nonlinear forward models that permit only black-box access (i.e., derivative-free). Theoretically, we establish a non-asymptotic convergence analysis to characterize the effects of forward model and prior estimation errors. Empirically, Blade achieves superior performance compared to existing derivative-free Bayesian inversion methods on various inverse problems, including challenging highly nonlinear fluid dynamics.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "321",
        "title": "IUT-Plug: A Plug-in tool for Interleaved Image-Text Generation",
        "author": [
            "Zeteng Lin",
            "Xingxing Li",
            "Wen You",
            "Xiaoyang Li",
            "Zehan Lu",
            "Yujun Cai",
            "Jing Tang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10969",
        "abstract": "Existing vision language models (VLMs), including GPT-4 and DALL-E, often struggle to preserve logic, object identity, and style in multimodal image-text generation. This limitation significantly hinders the generalization capability of VLMs in complex image-text input-output scenarios. To address this issue, we propose IUT-Plug, a module grounded in an Image Understanding Tree (IUT), which enhances existing interleaved VLMs through explicit structured reasoning, thereby mitigating context drift in logic, entity identity, and style. The proposed framework operates in two stages. (1) A dynamic IUT-Plug extraction module parses visual scenes into hierarchical symbolic structures. (2) A coordinated narrative-flow and image synthesis mechanism ensures cross-modal consistency. To evaluate our approach, we construct a novel benchmark based on 3,000 real human-generated question-answer pairs over fine-tuned large models, introducing a dynamic evaluation protocol for quantifying context drift in interleaved VLMs. Experimental results demonstrate that IUT-Plug not only improves accuracy on established benchmarks but also effectively alleviates the three critical forms of context drift across diverse multimodal question answering (QA) scenarios.",
        "tags": [
            "GPT",
            "VLM"
        ]
    },
    {
        "id": "322",
        "title": "RV-HATE: Reinforced Multi-Module Voting for Implicit Hate Speech Detection",
        "author": [
            "Yejin Lee",
            "Hyeseon Ahn",
            "Yo-Sub Han"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10971",
        "abstract": "Hate speech remains prevalent in human society and continues to evolve in its forms and expressions. Modern advancements in internet and online anonymity accelerate its rapid spread and complicate its detection. However, hate speech datasets exhibit diverse characteristics primarily because they are constructed from different sources and platforms, each reflecting different linguistic styles and social contexts. Despite this diversity, prior studies on hate speech detection often rely on fixed methodologies without adapting to data-specific features. We introduce RV-HATE, a detection framework designed to account for the dataset-specific characteristics of each hate speech dataset. RV-HATE consists of multiple specialized modules, where each module focuses on distinct linguistic or contextual features of hate speech. The framework employs reinforcement learning to optimize weights that determine the contribution of each module for a given dataset. A voting mechanism then aggregates the module outputs to produce the final decision. RV-HATE offers two primary advantages: (1)~it improves detection accuracy by tailoring the detection process to dataset-specific attributes, and (2)~it also provides interpretable insights into the distinctive features of each dataset. Consequently, our approach effectively addresses implicit hate speech and achieves superior performance compared to conventional static methods. Our code is available at https://github.com/leeyejin1231/RV-HATE.",
        "tags": [
            "Detection",
            "RL"
        ]
    },
    {
        "id": "323",
        "title": "Chart-RVR: Reinforcement Learning with Verifiable Rewards for Explainable Chart Reasoning",
        "author": [
            "Sanchit Sinha",
            "Oana Frunza",
            "Kashif Rasul",
            "Yuriy Nevmyvaka",
            "Aidong Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10973",
        "abstract": "The capabilities of Large Vision-Language Models (LVLMs) have reached state-of-the-art on many visual reasoning tasks, including chart reasoning, yet they still falter on out-of-distribution (OOD) data, and degrade further when asked to produce their chain-of-thought (CoT) rationales, limiting explainability. We present Chart-RVR, a general framework that fine-tunes LVLMs to be more robust and explainable for chart reasoning by coupling Group Relative Policy Optimization (GRPO) with automatically verifiable rewards. Our framework comprises of three rewards that maximize: (i) correct chart-type classification, (ii) faithful chart table reconstruction, and (iii) process conformity. Applied to 3-billion-parameter LVLMs, Chart-RVR consistently outperforms standard supervised fine-tuning (SFT) on both in-distribution and out-of-distribution datasets, closing the OOD performance gap while improving rationale fidelity. The resulting models, the Chart-RVR-3B series, achieve state-of-the-art results on six chart-reasoning benchmarks spanning in-domain and OOD settings, surpassing all existing models of comparable size. Beyond accuracy, Chart-RVR yields more interpretable CoT rationales, strengthening trust and reliability - showcasing the power of verifiable rewards with GRPO for training reliable, interpretable chart-reasoning models.",
        "tags": [
            "CoT",
            "GRPO",
            "RL",
            "VLM"
        ]
    },
    {
        "id": "324",
        "title": "Enhancing Large Language Model Reasoning via Selective Critical Token Fine-Tuning",
        "author": [
            "Zhiwen Ruan",
            "Yixia Li",
            "He Zhu",
            "Yun Chen",
            "Peng Li",
            "Yang Liu",
            "Guanhua Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10974",
        "abstract": "Large language models (LLMs) primarily rely on supervised fine-tuning (SFT) as a key method to adapt pre-trained models to domain-specific tasks such as mathematical reasoning. However, standard SFT uniformly penalizes all tokens, neglecting that only a small subset of critical tokens determines reasoning correctness. This uniform supervision often causes reduced output diversity and limited generalization. We propose Critical Token Fine-tuning (CFT), a simple yet effective approach that updates only tokens identified as functionally indispensable via counterfactual perturbations. By focusing gradient signals on these decisive reasoning steps while preserving the diversity of non-critical tokens, CFT can enhance both generation and diversity. Extensive experiments on five models across three families (Qwen, OLMo, LLaMA) and eleven mathematical reasoning benchmarks show that CFT, despite fine-tuning on less than 12% of tokens, consistently outperforms standard SFT. Moreover, CFT enables test-time scaling through improved sampling diversity and provides a stronger initialization for reinforcement learning, sustaining performance gains in later training stages while maintaining higher entropy for better exploration. These results highlight CFT as a practical and general framework for efficient and robust LLM fine-tuning.",
        "tags": [
            "LLM",
            "LLaMA",
            "Qwen",
            "RL"
        ]
    },
    {
        "id": "325",
        "title": "RoVer: Robot Reward Model as Test-Time Verifier for Vision-Language-Action Model",
        "author": [
            "Mingtong Dai",
            "Lingbo Liu",
            "Yongjie Bai",
            "Yang Liu",
            "Zhouxia Wang",
            "Rui SU",
            "Chunjie Chen",
            "Liang Lin",
            "Xinyu Wu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10975",
        "abstract": "Vision-Language-Action (VLA) models have become a prominent paradigm for embodied intelligence, yet further performance improvements typically rely on scaling up training data and model size -- an approach that is prohibitively expensive for robotics and fundamentally limited by data collection http://costs.We address this limitation with $\\mathbf{RoVer}$, an embodied test-time scaling framework that uses a $\\mathbf{Ro}$bot Process Reward Model (PRM) as a Test-Time $\\mathbf{Ver}$ifier to enhance the capabilities of existing VLA models without modifying their architectures or weights. Specifically, RoVer (i) assigns scalar-based process rewards to evaluate the reliability of candidate actions, and (ii) predicts an action-space direction for candidate expansion/refinement. During inference, RoVer generates multiple candidate actions concurrently from the base policy, expands them along PRM-predicted directions, and then scores all candidates with PRM to select the optimal action for execution. Notably, by caching shared perception features, it can amortize perception cost and evaluate more candidates under the same test-time computational budget. Essentially, our approach effectively transforms available computing resources into better action decision-making, realizing the benefits of test-time scaling without extra training overhead. Our contributions are threefold: (1) a general, plug-and-play test-time scaling framework for VLAs; (2) a PRM that jointly provides scalar process rewards and an action-space direction to guide exploration; and (3) an efficient direction-guided sampling strategy that leverages a shared perception cache to enable scalable candidate generation and selection during inference.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "326",
        "title": "Video-STR: Reinforcing MLLMs in Video Spatio-Temporal Reasoning with Relation Graph",
        "author": [
            "Wentao Wang",
            "Heqing Zou",
            "Tianze Luo",
            "Rui Huang",
            "Yutian Zhao",
            "Zhuochen Wang",
            "Hansheng Zhang",
            "Chengwei Qin",
            "Yan Wang",
            "Lin Zhao",
            "Huaijian Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10976",
        "abstract": "Recent progress in Multimodal Large Language Models (MLLMs) has demonstrated strong semantic understanding capabilities, but struggles to perform precise spatio-temporal understanding. Existing spatio-temporal methods primarily focus on the video itself, while overlooking the physical information within the video, such as multi-object layouts and motion. Such limitations restrict the use of MLLMs in downstream applications that demand high precision, including embodied intelligence and VR. To address this issue, we present Video-STR, a novel graph-based reinforcement method for precise Video Spatio-Temporal Reasoning. Building upon the capacity of Reinforcement Learning with Verifiable Reward (RLVR) to improve model abilities, we introduce a reasoning mechanism using graph-based Group Relative Policy Optimization (GRPO) method to guide the model in inferring the underlying spatio-temporal topology of scenarios during the thinking process. To resolve the lack of spatio-temporal training data, we construct the STV-205k dataset with 205k question-answering pairs, covering dynamic multi-object scenes in both indoor and outdoor environments, to support the model training. Experiments show that Video-STR achieves state-of-the-art results on various benchmarks, outperforming the base model by 13% on STI-Bench, and demonstrating the effectiveness of our approach and dataset. Code, model, and data will be released.",
        "tags": [
            "GRPO",
            "LLM",
            "RL"
        ]
    },
    {
        "id": "327",
        "title": "Catch-Only-One: Non-Transferable Examples for Model-Specific Authorization",
        "author": [
            "Zihan Wang",
            "Zhiyong Ma",
            "Zhongkui Ma",
            "Shuofeng Liu",
            "Akide Liu",
            "Derui Wang",
            "Minhui Xue",
            "Guangdong Bai"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10982",
        "abstract": "Recent AI regulations call for data that remain useful for innovation while resistant to misuse, balancing utility with protection at the model level. Existing approaches either perturb data to make it unlearnable or retrain models to suppress transfer, but neither governs inference by unknown models, and both typically require control over training. We propose non-transferable examples (NEs), a training-free and data-agnostic input-side usage-control mechanism. We recode inputs within a model-specific low-sensitivity subspace, preserving outputs for the authorized model while reducing performance on unauthorized models through subspace misalignment. We establish formal bounds that guarantee utility for the authorized model and quantify deviation for unauthorized ones, with the Hoffman-Wielandt inequality linking degradation to spectral differences. Empirically, NEs retain performance on diverse vision backbones and state-of-the-art vision-language models under common preprocessing, whereas non-target models collapse even with reconstruction attempts. These results establish NEs as a practical means to preserve intended data utility while preventing unauthorized exploitation. Our project is available at https://trusted-system-lab.github.io/model-specificity",
        "tags": [
            "VLM"
        ]
    },
    {
        "id": "328",
        "title": "Secret-Protected Evolution for Differentially Private Synthetic Text Generation",
        "author": [
            "Tianze Wang",
            "Zhaoyu Chen",
            "Jian Du",
            "Yingtai Xiao",
            "Linjun Zhang",
            "Qiang Yan"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10990",
        "abstract": "Text data has become extremely valuable on large language models (LLMs) and even lead to general artificial intelligence (AGI). A lot of high-quality text in the real world is private and cannot be freely used due to privacy concerns. Therefore, differentially private (DP) synthetic text generation has been proposed, aiming to produce high-utility synthetic data while protecting sensitive information. However, existing DP synthetic text generation imposes uniform guarantees that often overprotect non-sensitive content, resulting in substantial utility loss and computational overhead. Therefore, we propose Secret-Protected Evolution (SecPE), a novel framework that extends private evolution with secret-aware protection. Theoretically, we show that SecPE satisfies $(\\mathrm{p}, \\mathrm{r})$-secret protection, constituting a relaxation of Gaussian DP that enables tighter utility-privacy trade-offs, while also substantially reducing computational complexity relative to baseline methods. Empirically, across the OpenReview, PubMed, and Yelp benchmarks, SecPE consistently achieves lower FrÃ©chet Inception Distance (FID) and higher downstream task accuracy than GDP-based Aug-PE baselines, while requiring less noise to attain the same level of protection. Our results highlight that secret-aware guarantees can unlock more practical and effective privacy-preserving synthetic text generation.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "329",
        "title": "A Survey on Agentic Multimodal Large Language Models",
        "author": [
            "Huanjin Yao",
            "Ruifei Zhang",
            "Jiaxing Huang",
            "Jingyi Zhang",
            "Yibo Wang",
            "Bo Fang",
            "Ruolin Zhu",
            "Yongcheng Jing",
            "Shunyu Liu",
            "Guanbin Li",
            "Dacheng Tao"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10991",
        "abstract": "With the recent emergence of revolutionary autonomous agentic systems, research community is witnessing a significant shift from traditional static, passive, and domain-specific AI agents toward more dynamic, proactive, and generalizable agentic AI. Motivated by the growing interest in agentic AI and its potential trajectory toward AGI, we present a comprehensive survey on Agentic Multimodal Large Language Models (Agentic MLLMs). In this survey, we explore the emerging paradigm of agentic MLLMs, delineating their conceptual foundations and distinguishing characteristics from conventional MLLM-based agents. We establish a conceptual framework that organizes agentic MLLMs along three fundamental dimensions: (i) Agentic internal intelligence functions as the system's commander, enabling accurate long-horizon planning through reasoning, reflection, and memory; (ii) Agentic external tool invocation, whereby models proactively use various external tools to extend their problem-solving capabilities beyond their intrinsic knowledge; and (iii) Agentic environment interaction further situates models within virtual or physical environments, allowing them to take actions, adapt strategies, and sustain goal-directed behavior in dynamic real-world scenarios. To further accelerate research in this area for the community, we compile open-source training frameworks, training and evaluation datasets for developing agentic MLLMs. Finally, we review the downstream applications of agentic MLLMs and outline future research directions for this rapidly evolving field. To continuously track developments in this rapidly evolving field, we will also actively update a public repository at https://github.com/HJYao00/Awesome-Agentic-MLLMs.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "330",
        "title": "Perspective-aware 3D Gaussian Inpainting with Multi-view Consistency",
        "author": [
            "Yuxin Cheng",
            "Binxiao Huang",
            "Taiqiang Wu",
            "Wenyong Zhou",
            "Chenchen Ding",
            "Zhengwu Liu",
            "Graziano Chesi",
            "Ngai Wong"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10993",
        "abstract": "3D Gaussian inpainting, a critical technique for numerous applications in virtual reality and multimedia, has made significant progress with pretrained diffusion models. However, ensuring multi-view consistency, an essential requirement for high-quality inpainting, remains a key challenge. In this work, we present PAInpainter, a novel approach designed to advance 3D Gaussian inpainting by leveraging perspective-aware content propagation and consistency verification across multi-view inpainted images. Our method iteratively refines inpainting and optimizes the 3D Gaussian representation with multiple views adaptively sampled from a perspective graph. By propagating inpainted images as prior information and verifying consistency across neighboring views, PAInpainter substantially enhances global consistency and texture fidelity in restored 3D scenes. Extensive experiments demonstrate the superiority of PAInpainter over existing methods. Our approach achieves superior 3D inpainting quality, with PSNR scores of 26.03 dB and 29.51 dB on the SPIn-NeRF and NeRFiller datasets, respectively, highlighting its effectiveness and generalization capability.",
        "tags": [
            "3D",
            "Diffusion",
            "Inpainting",
            "NeRF"
        ]
    },
    {
        "id": "331",
        "title": "DeepResearchGuard: Deep Research with Open-Domain Evaluation and Multi-Stage Guardrails for Safety",
        "author": [
            "Wei-Chieh Huang",
            "Henry Peng Zou",
            "Yaozu Wu",
            "Dongyuan Li",
            "Yankai Chen",
            "Weizhi Zhang",
            "Yangning Li",
            "Angelo Zangari",
            "Jizhou Guo",
            "Chunyu Miao",
            "Liancheng Fang",
            "Langzhou He",
            "Renhe Jiang",
            "Philip S. Yu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10994",
        "abstract": "Deep research frameworks have shown promising capabilities in synthesizing comprehensive reports from web sources. While deep research possesses significant potential to address complex issues through planning and research cycles, existing frameworks are deficient in sufficient evaluation procedures and stage-specific protections. They typically treat evaluation as exact match accuracy of question-answering, but overlook crucial aspects of report quality such as credibility, coherence, breadth, depth, and safety. This oversight may result in hazardous or malicious sources being integrated into the final report. To address these issues, we introduce DEEPRESEARCHGUARD, a comprehensive framework featuring four-stage safeguards with open-domain evaluation of references and reports. We assess performance across multiple metrics, e.g., defense success rate and over-refusal rate, and five key report dimensions. In the absence of a suitable safety benchmark, we introduce DRSAFEBENCH, a stage-wise benchmark for deep research safety. Our evaluation spans diverse state-of-the-art LLMs, including GPT-4o, Gemini-2.5-flash, DeepSeek-v3, and o4-mini. DEEPRESEARCHGUARD achieves an average defense success rate improvement of 18.16% while reducing over-refusal rate by 6%. The input guard provides the most substantial early-stage protection by filtering out obvious risks, while the plan and research guards enhance citation discipline and source credibility. Through extensive experiments, we show that DEEPRESEARCHGUARD enables comprehensive open-domain evaluation and stage-aware defenses that effectively block harmful content propagation, while systematically improving report quality without excessive over-refusal rates. The code can be found via https://github.com/Jasonya/DeepResearchGuard.",
        "tags": [
            "DeepSeek",
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "332",
        "title": "ABLEIST: Intersectional Disability Bias in LLM-Generated Hiring Scenarios",
        "author": [
            "Mahika Phutane",
            "Hayoung Jung",
            "Matthew Kim",
            "Tanushree Mitra",
            "Aditya Vashistha"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10998",
        "abstract": "Large language models (LLMs) are increasingly under scrutiny for perpetuating identity-based discrimination in high-stakes domains such as hiring, particularly against people with disabilities (PwD). However, existing research remains largely Western-centric, overlooking how intersecting forms of marginalization--such as gender and caste--shape experiences of PwD in the Global South. We conduct a comprehensive audit of six LLMs across 2,820 hiring scenarios spanning diverse disability, gender, nationality, and caste profiles. To capture subtle intersectional harms and biases, we introduce ABLEIST (Ableism, Inspiration, Superhumanization, and Tokenism), a set of five ableism-specific and three intersectional harm metrics grounded in disability studies literature. Our results reveal significant increases in ABLEIST harms towards disabled candidates--harms that many state-of-the-art models failed to detect. These harms were further amplified by sharp increases in intersectional harms (e.g., Tokenism) for gender and caste-marginalized disabled candidates, highlighting critical blind spots in current safety tools and the need for intersectional safety evaluations of frontier models in high-stakes domains like hiring.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "333",
        "title": "ContextGen: Contextual Layout Anchoring for Identity-Consistent Multi-Instance Generation",
        "author": [
            "Ruihang Xu",
            "Dewei Zhou",
            "Fan Ma",
            "Yi Yang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11000",
        "abstract": "Multi-instance image generation (MIG) remains a significant challenge for modern diffusion models due to key limitations in achieving precise control over object layout and preserving the identity of multiple distinct subjects. To address these limitations, we introduce ContextGen, a novel Diffusion Transformer framework for multi-instance generation that is guided by both layout and reference images. Our approach integrates two key technical contributions: a Contextual Layout Anchoring (CLA) mechanism that incorporates the composite layout image into the generation context to robustly anchor the objects in their desired positions, and Identity Consistency Attention (ICA), an innovative attention mechanism that leverages contextual reference images to ensure the identity consistency of multiple instances. Recognizing the lack of large-scale, hierarchically-structured datasets for this task, we introduce IMIG-100K, the first dataset with detailed layout and identity annotations. Extensive experiments demonstrate that ContextGen sets a new state-of-the-art, outperforming existing methods in control precision, identity fidelity, and overall visual quality.",
        "tags": [
            "DiT",
            "Diffusion",
            "Transformer"
        ]
    },
    {
        "id": "334",
        "title": "DND: Boosting Large Language Models with Dynamic Nested Depth",
        "author": [
            "Tieyuan Chen",
            "Xiaodong Chen",
            "Haoxing Chen",
            "Zhenzhong Lan",
            "Weiyao Lin",
            "Jianguo Li"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11001",
        "abstract": "We introduce Dynamic Nested Depth (DND), a novel method that improves performance for off-the-shelf LLMs by selecting critical tokens to reprocess in a nested depth manner. Specifically, at the end of the given transformer layer, DND identifies more critical tokens with a router and feeds them back for an extra round of processing, effectively ``reviewing\" difficult tokens while avoiding redundant computation for easier ones. The dynamic selection mechanism is tailored for precise control via two novel strategies: a router controlling loss to enhance token selection distinguishability, and a threshold control scheme to ensure selection stability. We demonstrate the effectiveness of DND by directly integrating it into pre-trained dense and MoE models during a post-training phase. On diverse benchmarks, this approach boosts the performances of the dense Qwen3-1.7B by 1.88% and the MoE Qwen3-30B-A3B by 0.87%, all with a minimal parameter and computing increase.",
        "tags": [
            "LLM",
            "MoE",
            "Transformer"
        ]
    },
    {
        "id": "335",
        "title": "Automating Structural Engineering Workflows with Large Language Model Agents",
        "author": [
            "Haoran Liang",
            "Yufa Zhou",
            "Mohammad Talebi Kalaleh",
            "Qipei Mei"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11004",
        "abstract": "We introduce $\\textbf{MASSE}$, the first Multi-Agent System for Structural Engineering, effectively integrating large language model (LLM)-based agents with real-world engineering workflows. Structural engineering is a fundamental yet traditionally stagnant domain, with core workflows remaining largely unchanged for decades despite its substantial economic impact and global market size. Recent advancements in LLMs have significantly enhanced their ability to perform complex reasoning, long-horizon planning, and precise tool utilization -- capabilities well aligned with structural engineering tasks such as interpreting design codes, executing load calculations, and verifying structural capacities. We present a proof-of-concept showing that most real-world structural engineering workflows can be fully automated through a training-free LLM-based multi-agent system. MASSE enables immediate deployment in professional environments, and our comprehensive validation on real-world case studies demonstrates that it can reduce expert workload from approximately two hours to mere minutes, while enhancing both reliability and accuracy in practical engineering scenarios.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "336",
        "title": "COCO-Tree: Compositional Hierarchical Concept Trees for Enhanced Reasoning in Vision Language Models",
        "author": [
            "Sanchit Sinha",
            "Guangzhi Xiong",
            "Aidong Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11012",
        "abstract": "Compositional reasoning remains a persistent weakness of modern vision language models (VLMs): they often falter when a task hinges on understanding how multiple objects, attributes, and relations interact within an image. Multiple research works have attempted to improve compositionality performance by creative tricks such as improving prompt structure, chain of thought reasoning, etc. A more recent line of work attempts to impart additional reasoning in VLMs using well-trained Large Language Models (LLMs), which are far superior in linguistic understanding than VLMs to compensate for the limited linguistic prowess of VLMs. However, these approaches are either resource-intensive or do not provide an interpretable reasoning process. In this paper, we present 'COCO-Tree' - a novel approach that augments VLM outputs with carefully designed neurosymbolic concept trees learned from LLMs to improve VLM's linguistic reasoning. COCO-Tree's beam search-inspired reasoning process boosts compositionality performance and provides a rationale behind VLM predictions. Empirical results on four compositionality benchmarks, Winoground, EqBench, ColorSwap, and SugarCrepe, in seven different open-source VLMs with varying sizes, demonstrate that COCO-Tree significantly improves compositional generalization by 5-10% over baselines.",
        "tags": [
            "CoT",
            "LLM",
            "VLM"
        ]
    },
    {
        "id": "337",
        "title": "Into the Unknown: Towards using Generative Models for Sampling Priors of Environment Uncertainty for Planning in Configuration Spaces",
        "author": [
            "Subhransu S. Bhattacharjee",
            "Hao Lu",
            "Dylan Campbell",
            "Rahul Shome"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11014",
        "abstract": "Priors are vital for planning under partial observability, yet difficult to obtain in practice. We present a sampling-based pipeline that leverages large-scale pretrained generative models to produce probabilistic priors capturing environmental uncertainty and spatio-semantic relationships in a zero-shot manner. Conditioned on partial observations, the pipeline recovers complete RGB-D point cloud samples with occupancy and target semantics, formulated to be directly useful in configuration-space planning. We establish a Matterport3D benchmark of rooms partially visible through doorways, where a robot must navigate to an unobserved target object. Effective priors for this setting must represent both occupancy and target-location uncertainty in unobserved regions. Experiments show that our approach recovers commonsense spatial semantics consistent with ground truth, yielding diverse, clean 3D point clouds usable in motion planning, highlight the promise of generative models as a rich source of priors for robotic planning.",
        "tags": [
            "3D",
            "Robotics"
        ]
    },
    {
        "id": "338",
        "title": "High-Resolution Spatiotemporal Modeling with Global-Local State Space Models for Video-Based Human Pose Estimation",
        "author": [
            "Runyang Feng",
            "Hyung Jin Chang",
            "Tze Ho Elden Tse",
            "Boeun Kim",
            "Yi Chang",
            "Yixing Gao"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11017",
        "abstract": "Modeling high-resolution spatiotemporal representations, including both global dynamic contexts (e.g., holistic human motion tendencies) and local motion details (e.g., high-frequency changes of keypoints), is essential for video-based human pose estimation (VHPE). Current state-of-the-art methods typically unify spatiotemporal learning within a single type of modeling structure (convolution or attention-based blocks), which inherently have difficulties in balancing global and local dynamic modeling and may bias the network to one of them, leading to suboptimal performance. Moreover, existing VHPE models suffer from quadratic complexity when capturing global dependencies, limiting their applicability especially for high-resolution sequences. Recently, the state space models (known as Mamba) have demonstrated significant potential in modeling long-range contexts with linear complexity; however, they are restricted to 1D sequential data. In this paper, we present a novel framework that extends Mamba from two aspects to separately learn global and local high-resolution spatiotemporal representations for VHPE. Specifically, we first propose a Global Spatiotemporal Mamba, which performs 6D selective space-time scan and spatial- and temporal-modulated scan merging to efficiently extract global representations from high-resolution sequences. We further introduce a windowed space-time scan-based Local Refinement Mamba to enhance the high-frequency details of localized keypoint motions. Extensive experiments on four benchmark datasets demonstrate that the proposed model outperforms state-of-the-art VHPE approaches while achieving better computational trade-offs.",
        "tags": [
            "Mamba",
            "Pose Estimation",
            "SSMs"
        ]
    },
    {
        "id": "339",
        "title": "GeoVLMath: Enhancing Geometry Reasoning in Vision-Language Models via Cross-Modal Reward for Auxiliary Line Creation",
        "author": [
            "Shasha Guo",
            "Liang Pang",
            "Xi Wang",
            "Yanling Wang",
            "Huawei Shen",
            "Jing Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11020",
        "abstract": "Auxiliary lines are essential for solving complex geometric problems but remain challenging for large vision-language models (LVLMs). Rather than editing diagrams to draw auxiliary lines, which current image editing models struggle to render with geometric precision, we generate textual descriptions of auxiliary-line constructions to better align with the representational strengths of LVLMs. To bridge the gap between textual descriptions and spatial structure, we propose a reinforcement learning framework that enhances diagram-text alignment. At the core of our approach is a cross-modal reward that evaluates how well the generated auxiliary-line description for an original diagram matches a ground-truth auxiliary-line diagram. Built on this reward, we present GeoVLMath, an open-source LVLM tailored to auxiliary-line reasoning in solid geometry. This fine-grained signal drives a GRPO-based RL stage, yielding precise diagram-text alignment. To support training, we develop a scalable data creation pipeline and construct AuxSolidMath, a dataset of 3,018 real-exam geometry problems with paired diagrams and aligned textual fields. At the 3B and 7B scales, GeoVLMath achieves competitive and often superior performance compared with strong open-source and proprietary LVLMs on auxiliary-line reasoning benchmarks.",
        "tags": [
            "GRPO",
            "Image Editing",
            "RL",
            "VLM"
        ]
    },
    {
        "id": "340",
        "title": "Parareal in time and spectral in space fast L1 quasilinear subdiffusion solver",
        "author": [
            "Josefa Caballero",
            "Åukasz PÅociniczak",
            "Kishin Sadarangani"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11023",
        "abstract": "We consider the initial-boundary value problem for a quasilinear time-fractional diffusion equation, and develop a fully discrete solver combining the parareal algorithm in time with a L1 finite-difference approximation of the Caputo derivative and a spectral Galerkin discretization in space. Our main contribution is the first rigorous convergence proof for the parareal-L1 scheme in this nonlinear subdiffusive setting. By constructing suitable energy norms and exploiting the orthogonality of the spectral basis, we establish that the parareal iterations converge exactly to the fully serial L1-spectral solution in a finite number of steps, with rates independent of the fractional exponent. The spectral spatial discretization yields exponential accuracy in space, while the parareal structure induces a clock speedup proportional to the number of processors, making the overall method highly efficient. Numerical experiments for both subdiffusive and classical diffusion problems confirm our theoretical estimates and demonstrate up to an order of magnitude reduction in computational time compared to the conventional sequential solver. We observe that the speedup of the parareal method increases linearly with the fine integrator degrees of freedom.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "341",
        "title": "GIR-Bench: Versatile Benchmark for Generating Images with Reasoning",
        "author": [
            "Hongxiang Li",
            "Yaowei Li",
            "Bin Lin",
            "Yuwei Niu",
            "Yuhang Yang",
            "Xiaoshuang Huang",
            "Jiayin Cai",
            "Xiaolong Jiang",
            "Yao Hu",
            "Long Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11026",
        "abstract": "Unified multimodal models integrate the reasoning capacity of large language models with both image understanding and generation, showing great promise for advanced multimodal intelligence. However, the community still lacks a rigorous reasoning-centric benchmark to systematically evaluate the alignment between understanding and generation, and their generalization potential in complex visual tasks. To this end, we introduce \\textbf{GIR-Bench}, a comprehensive benchmark that evaluates unified models across three complementary perspectives. Firstly, we investigate understanding-generation consistency (GIR-Bench-UGC), asking whether models can consistently leverage the same knowledge in both understanding and generation tasks. Secondly, we investigate whether models can perform reasoning-centric text-to-image generation that requires applying logical constraints and implicit knowledge to generate faithful visual content (GIR-Bench-T2I). Thirdly, we evaluate whether models can handle multi-step reasoning in editing (GIR-Bench-Edit). For each subset, we carefully design different task-specific evaluation pipelines tailored for each task. This enables fine-grained and interpretable evaluation while mitigating biases from the prevalent MLLM-as-a-Judge paradigm. Extensive ablations over various unified models and generation-only systems have shown that: Although unified models are more capable of reasoning-driven visual tasks, they still exhibit a persistent gap between understanding and generation. The data and code for GIR-Bench are available at \\href{https://hkust-longgroup.github.io/GIR-Bench}{https://hkust-longgroup.github.io/GIR-Bench}.",
        "tags": [
            "LLM",
            "Text-to-Image"
        ]
    },
    {
        "id": "342",
        "title": "Vlaser: Vision-Language-Action Model with Synergistic Embodied Reasoning",
        "author": [
            "Ganlin Yang",
            "Tianyi Zhang",
            "Haoran Hao",
            "Weiyun Wang",
            "Yibin Liu",
            "Dehui Wang",
            "Guanzhou Chen",
            "Zijian Cai",
            "Junting Chen",
            "Weijie Su",
            "Wengang Zhou",
            "Yu Qiao",
            "Jifeng Dai",
            "Jiangmiao Pang",
            "Gen Luo",
            "Wenhai Wang",
            "Yao Mu",
            "Zhi Hou"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11027",
        "abstract": "While significant research has focused on developing embodied reasoning capabilities using Vision-Language Models (VLMs) or integrating advanced VLMs into Vision-Language-Action (VLA) models for end-to-end robot control, few studies directly address the critical gap between upstream VLM-based reasoning and downstream VLA policy learning. In this work, we take an initial step toward bridging embodied reasoning with VLA policy learning by introducing Vlaser - a Vision-Language-Action Model with synergistic embodied reasoning capability, which is a foundational vision-language model designed to integrate high-level reasoning with low-level control for embodied agents. Built upon the high-quality Vlaser-6M dataset, Vlaser achieves state-of-the-art performance across a range of embodied reasoning benchmarks - including spatial reasoning, embodied grounding, embodied QA, and task planning. Furthermore, we systematically examine how different VLM initializations affect supervised VLA fine-tuning, offering novel insights into mitigating the domain shift between internet-scale pre-training data and embodied-specific policy learning data. Based on these insights, our approach achieves state-of-the-art results on the WidowX benchmark and competitive performance on the Google Robot benchmark.",
        "tags": [
            "Robotics",
            "VLM"
        ]
    },
    {
        "id": "343",
        "title": "LogiNumSynth: Synthesizing Joint Logical-Numerical Reasoning Problems for Language Models",
        "author": [
            "Yiwei Liu",
            "Yucheng Li",
            "Xiao Li",
            "Gong Cheng"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11031",
        "abstract": "Joint logical-numerical reasoning remains a major challenge for language models, yet existing datasets rely on fixed rule sets and offer limited control over task complexity, constraining their generalizability for evaluation and training. We present LogiNumSynth, a flexible natural language problem synthesizer that synthesizes tasks requiring proficiency in joint logical reasoning (e.g., rule-based reasoning) and numerical reasoning (e.g., arithmetic computation). LogiNumSynth supports fine-grained control over reasoning world richness, logical reasoning depth, and the complexity of numerical computations, enabling flexible data synthesis across difficulty levels. We demonstrate three key contributions: (1) Synthesizer -- synthesizing fully controllable joint reasoning tasks over natural language; (2) Evaluation & Process Analysis -- evaluating both process accuracy and answer accuracy; (3) Targeted Training -- using synthesized data to enhance LLMs' reasoning performance. Experiments with multiple LLMs highlight persistent weaknesses in logical-numerical reasoning, showing that LogiNumSynth can serve as both a diagnostic tool and a source of targeted supervision for advancing integrated reasoning skills.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "344",
        "title": "SusBench: An Online Benchmark for Evaluating Dark Pattern Susceptibility of Computer-Use Agents",
        "author": [
            "Longjie Guo",
            "Chenjie Yuan",
            "Mingyuan Zhong",
            "Robert Wolfe",
            "Ruican Zhong",
            "Yue Xu",
            "Bingbing Wen",
            "Hua Shen",
            "Lucy Lu Wang",
            "Alexis Hiniker"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11035",
        "abstract": "As LLM-based computer-use agents (CUAs) begin to autonomously interact with real-world interfaces, understanding their vulnerability to manipulative interface designs becomes increasingly critical. We introduce SusBench, an online benchmark for evaluating the susceptibility of CUAs to UI dark patterns, designs that aim to manipulate or deceive users into taking unintentional actions. Drawing nine common dark pattern types from existing taxonomies, we developed a method for constructing believable dark patterns on real-world consumer websites through code injections, and designed 313 evaluation tasks across 55 websites. Our study with 29 participants showed that humans perceived our dark pattern injections to be highly realistic, with the vast majority of participants not noticing that these had been injected by the research team. We evaluated five state-of-the-art CUAs on the benchmark. We found that both human participants and agents are particularly susceptible to the dark patterns of Preselection, Trick Wording, and Hidden Information, while being resilient to other overt dark patterns. Our findings inform the development of more trustworthy CUAs, their use as potential human proxies in evaluating deceptive designs, and the regulation of an online environment increasingly navigated by autonomous agents.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "345",
        "title": "Unveiling Uncertainty-Aware Autonomous Cooperative Learning Based Planning Strategy",
        "author": [
            "Shiyao Zhang",
            "Liwei Deng",
            "Shuyu Zhang",
            "Weijie Yuan",
            "Hong Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11041",
        "abstract": "In future intelligent transportation systems, autonomous cooperative planning (ACP), becomes a promising technique to increase the effectiveness and security of multi-vehicle interactions. However, multiple uncertainties cannot be fully addressed for existing ACP strategies, e.g. perception, planning, and communication uncertainties. To address these, a novel deep reinforcement learning-based autonomous cooperative planning (DRLACP) framework is proposed to tackle various uncertainties on cooperative motion planning schemes. Specifically, the soft actor-critic (SAC) with the implementation of gate recurrent units (GRUs) is adopted to learn the deterministic optimal time-varying actions with imperfect state information occurred by planning, communication, and perception uncertainties. In addition, the real-time actions of autonomous vehicles (AVs) are demonstrated via the Car Learning to Act (CARLA) simulation platform. Evaluation results show that the proposed DRLACP learns and performs cooperative planning effectively, which outperforms other baseline methods under different scenarios with imperfect AV state information.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "346",
        "title": "Zero-shot Face Editing via ID-Attribute Decoupled Inversion",
        "author": [
            "Yang Hou",
            "Minggu Wang",
            "Jianjun Zhao"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11050",
        "abstract": "Recent advancements in text-guided diffusion models have shown promise for general image editing via inversion techniques, but often struggle to maintain ID and structural consistency in real face editing tasks. To address this limitation, we propose a zero-shot face editing method based on ID-Attribute Decoupled Inversion. Specifically, we decompose the face representation into ID and attribute features, using them as joint conditions to guide both the inversion and the reverse diffusion processes. This allows independent control over ID and attributes, ensuring strong ID preservation and structural consistency while enabling precise facial attribute manipulation. Our method supports a wide range of complex multi-attribute face editing tasks using only text prompts, without requiring region-specific input, and operates at a speed comparable to DDIM inversion. Comprehensive experiments demonstrate its practicality and effectiveness.",
        "tags": [
            "DDIM",
            "Diffusion",
            "Image Editing"
        ]
    },
    {
        "id": "347",
        "title": "Latent Refinement Decoding: Enhancing Diffusion-Based Language Models by Refining Belief States",
        "author": [
            "Qinglin Zhu",
            "Yizhen Yao",
            "Runcong Zhao",
            "Yanzheng Xiang",
            "Amrutha Saseendran",
            "Chen Jin",
            "Philip Alexander Teare",
            "Bin Liang",
            "Yulan He",
            "Lin Gui"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11052",
        "abstract": "Autoregressive (AR) models remain the standard for natural language generation but still suffer from high latency due to strictly sequential decoding. Recent diffusion-inspired approaches, such as LlaDA and Dream, mitigate this by generating in parallel, yet they suffer from two core limitations: information loss, as predictive distributions for non-finalized tokens are discarded at each step, and premature commitment, where local decisions are made without sufficient global coordination. We introduce Latent Refinement Decoding (LRD), a two-stage framework with Latent Refinement and a Predictive Feedback Loop. The first stage maintains masked positions as distributional mixtures of predicted tokens and the mask embedding, allowing the model to establish more globally consistent beliefs. The second stage progressively finalizes confident tokens while retaining uncertain ones for iterative feedback. KL-divergence dynamics provide a principled and reliable criterion for convergence and early stopping. Experiments across coding (HumanEval +6.3, MBPP +2.6) and reasoning (GSM8K +2.9, MATH500 +3.8) show that LRD improves accuracy while delivering speedups of up to 10.6x, making it a strong and versatile alternative for parallel sequence generation.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "348",
        "title": "From Reasoning LLMs to BERT: A Two-Stage Distillation Framework for Search Relevance",
        "author": [
            "Runze Xia",
            "Yupeng Ji",
            "Yuxi Zhou",
            "Haodong Liu",
            "Teng Zhang",
            "Piji Li"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11056",
        "abstract": "Query-service relevance prediction in e-commerce search systems faces strict latency requirements that prevent the direct application of Large Language Models (LLMs). To bridge this gap, we propose a two-stage reasoning distillation framework to transfer reasoning capabilities from a powerful teacher LLM to a lightweight, deployment-friendly student model. In the first stage, we address the limitations of general-purpose LLMs by constructing a domain-adapted teacher model. This is achieved through a three-step process: domain-adaptive pre-training to inject platform knowledge, supervised fine-tuning to elicit reasoning skills, and preference optimization with a multi-dimensional reward model to ensure the generation of reliable and preference-aligned reasoning paths. This teacher can then automatically annotate massive query-service pairs from search logs with both relevance labels and reasoning chains. In the second stage, to address the challenges of architectural heterogeneity in standard distillation, we introduce Contrastive Reasoning Self-Distillation (CRSD). By modeling the behavior of the same student model under \"standard\" and \"reasoning-augmented\" inputs as a teacher-student relationship, CRSD enables the lightweight model to internalize the teacher's complex decision-making mechanisms without needing the explicit reasoning path at inference. Offline evaluations and online A/B testing in the Meituan search advertising system demonstrate that our framework achieves significant improvements across multiple metrics, validating its effectiveness and practical value.",
        "tags": [
            "BERT",
            "LLM"
        ]
    },
    {
        "id": "349",
        "title": "Temporal Alignment Guidance: On-Manifold Sampling in Diffusion Models",
        "author": [
            "Youngrok Park",
            "Hojung Jung",
            "Sangmin Bae",
            "Se-Young Yun"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11057",
        "abstract": "Diffusion models have achieved remarkable success as generative models. However, even a well-trained model can accumulate errors throughout the generation process. These errors become particularly problematic when arbitrary guidance is applied to steer samples toward desired properties, which often breaks sample fidelity. In this paper, we propose a general solution to address the off-manifold phenomenon observed in diffusion models. Our approach leverages a time predictor to estimate deviations from the desired data manifold at each timestep, identifying that a larger time gap is associated with reduced generation quality. We then design a novel guidance mechanism, `Temporal Alignment Guidance' (TAG), attracting the samples back to the desired manifold at every timestep during generation. Through extensive experiments, we demonstrate that TAG consistently produces samples closely aligned with the desired manifold at each timestep, leading to significant improvements in generation quality across various downstream tasks.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "350",
        "title": "Robust Photoplethysmography Signal Denoising via Mamba Networks",
        "author": [
            "I Chiu",
            "Yu-Tung Liu",
            "Kuan-Chen Wang",
            "Hung-Yu Wei",
            "Yu Tsao"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11058",
        "abstract": "Photoplethysmography (PPG) is widely used in wearable health monitoring, but its reliability is often degraded by noise and motion artifacts, limiting downstream applications such as heart rate (HR) estimation. This paper presents a deep learning framework for PPG denoising with an emphasis on preserving physiological information. In this framework, we propose DPNet, a Mamba-based denoising backbone designed for effective temporal modeling. To further enhance denoising performance, the framework also incorporates a scale-invariant signal-to-distortion ratio (SI-SDR) loss to promote waveform fidelity and an auxiliary HR predictor (HRP) that provides physiological consistency through HR-based supervision. Experiments on the BIDMC dataset show that our method achieves strong robustness against both synthetic noise and real-world motion artifacts, outperforming conventional filtering and existing neural models. Our method can effectively restore PPG signals while maintaining HR accuracy, highlighting the complementary roles of SI-SDR loss and HR-guided supervision. These results demonstrate the potential of our approach for practical deployment in wearable healthcare systems.",
        "tags": [
            "Mamba"
        ]
    },
    {
        "id": "351",
        "title": "Defects4C: Benchmarking Large Language Model Repair Capability with C/C++ Bugs",
        "author": [
            "Jian Wang",
            "Xiaofei Xie",
            "Qiang Hu",
            "Shangqing Liu",
            "Jiongchi Yu",
            "Jiaolong Klong",
            "Yi Li"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11059",
        "abstract": "Automated Program Repair (APR) plays a critical role in enhancing the quality and reliability of software systems. While substantial progress has been made in Java-based APR, largely facilitated by benchmarks like Defects4J, there remains a significant gap in research on C/C++ program repair, despite the widespread use of C/C++ and the prevalence of associated vulnerabilities. This gap is primarily due to the lack of high-quality, open-source benchmarks tailored for C/C++.\nTo address this issue, we introduce Defects4C, a comprehensive and executable benchmark specifically designed for C/C++ program repair. Our dataset is constructed from real-world C/C++ repositories and includes a large collection of bug-relevant commits (9M in total), 248 high-quality buggy functions, and 102 vulnerable functions, all paired with test cases for reproduction. These resources enable rigorous evaluation of repair techniques and support the retraining of learning-based approaches for enhanced performance.\nUsing Defects4C, we conduct a comprehensive empirical study evaluating the effectiveness of 24 state-of-the-art large language models (LLMs) in repairing C/C++ faults. Our findings offer valuable insights into the strengths and limitations of current LLM-based APR techniques in this domain, highlighting both the need for more robust methods and the critical role of Defects4C in advancing future research",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "352",
        "title": "Stronger Together: On-Policy Reinforcement Learning for Collaborative LLMs",
        "author": [
            "Yujie Zhao",
            "Lanxiang Hu",
            "Yang Wang",
            "Minmin Hou",
            "Hao Zhang",
            "Ke Ding",
            "Jishen Zhao"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11062",
        "abstract": "Multi-agent systems (MAS) and reinforcement learning (RL) are widely used to enhance the agentic capabilities of large language models (LLMs). MAS improves task performance through role-based orchestration, while RL uses environmental rewards to learn stronger policies, such as GRPO-style optimization. However, applying on-policy RL to MAS remains underexplored and presents unique challenges. Algorithmically, standard GRPO grouping assumptions break down because prompts vary by role and by turn. System-wise, the training stack must support MAS-workflow rollouts and on-policy updates for both single-policy and multi-policy models.\nWe propose AT-GRPO, which includes (i) an agent- and turn-wise grouped RL algorithm tailored to MAS and (ii) a training system that supports both single- and multi-policy regimes. Across game, planning, coding, and math tasks, AT-GRPO delivers substantial gains. On long-horizon planning, it increases accuracy from a 14.0 to 47.0 percent single-agent RL baseline to 96.0 to 99.5 percent. It also improves reasoning performance, with average gains of 3.87 to 7.62 percent on coding tasks and 9.0 to 17.93 percent on math. Code and environments are available at: https://github.com/pettingllms-ai/PettingLLMs.",
        "tags": [
            "GRPO",
            "LLM",
            "RL"
        ]
    },
    {
        "id": "353",
        "title": "LSVOS 2025 Challenge Report: Recent Advances in Complex Video Object Segmentation",
        "author": [
            "Chang Liu",
            "Henghui Ding",
            "Kaining Ying",
            "Lingyi Hong",
            "Ning Xu",
            "Linjie Yang",
            "Yuchen Fan",
            "Mingqi Gao",
            "Jingkun Chen",
            "Yunqi Miao",
            "Gengshen Wu",
            "Zhijin Qin",
            "Jungong Han",
            "Zhixiong Zhang",
            "Shuangrui Ding",
            "Xiaoyi Dong",
            "Yuhang Zang",
            "Yuhang Cao",
            "Jiaqi Wang",
            "Chang Soo Lim",
            "Joonyoung Moon",
            "Donghyeon Cho",
            "Tingmin Li",
            "Yixuan Li",
            "Yang Yang",
            "An Yan",
            "Leilei Cao",
            "Feng Lu",
            "Ran Hong",
            "Youhai Jiang",
            "Fengjie Zhu",
            "Yujie Xie",
            "Hongyang Zhang",
            "Zhihui Liu",
            "Shihai Ruan",
            "Quanzhu Niu",
            "Dengxian Gong",
            "Shihao Chen",
            "Tao Zhang",
            "Yikang Zhou",
            "Haobo Yuan",
            "Lu Qi",
            "Xiangtai Li",
            "Shunping Ji",
            "Ran Hong",
            "Feng Lu",
            "Leilei Cao",
            "An Yan",
            "Alexey Nekrasov",
            "Ali Athar",
            "Daan de Geus",
            "Alexander Hermans",
            "Bastian Leibe"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11063",
        "abstract": "This report presents an overview of the 7th Large-scale Video Object Segmentation (LSVOS) Challenge held in conjunction with ICCV 2025. Besides the two traditional tracks of LSVOS that jointly target robustness in realistic video scenarios: Classic VOS (VOS), and Referring VOS (RVOS), the 2025 edition features a newly introduced track, Complex VOS (MOSEv2). Building upon prior insights, MOSEv2 substantially increases difficulty, introducing more challenging but realistic scenarios including denser small objects, frequent disappear/reappear events, severe occlusions, adverse weather and lighting, etc., pushing long-term consistency and generalization beyond curated benchmarks. The challenge retains standard ${J}$, $F$, and ${J\\&F}$ metrics for VOS and RVOS, while MOSEv2 adopts ${J\\&\\dot{F}}$ as the primary ranking metric to better evaluate objects across scales and disappearance cases. We summarize datasets and protocols, highlight top-performing solutions, and distill emerging trends, such as the growing role of LLM/MLLM components and memory-aware propagation, aiming to chart future directions for resilient, language-aware video segmentation in the wild.",
        "tags": [
            "LLM",
            "Segmentation"
        ]
    },
    {
        "id": "354",
        "title": "Detecting Gender Stereotypes in Scratch Programming Tutorials",
        "author": [
            "Isabella GraÃl",
            "Benedikt Fein",
            "Gordon Fraser"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11064",
        "abstract": "Gender stereotypes in introductory programming courses often go unnoticed, yet they can negatively influence young learners' interest and learning, particularly under-represented groups such as girls. Popular tutorials on block-based programming with Scratch may unintentionally reinforce biases through character choices, narrative framing, or activity types. Educators currently lack support in identifying and addressing such bias. With large language models~(LLMs) increasingly used to generate teaching materials, this problem is potentially exacerbated by LLMs trained on biased datasets. However, LLMs also offer an opportunity to address this issue. In this paper, we explore the use of LLMs for automatically identifying gender-stereotypical elements in Scratch tutorials, thus offering feedback on how to improve teaching content. We develop a framework for assessing gender bias considering characters, content, instructions, and programming concepts. Analogous to how code analysis tools provide feedback on code in terms of code smells, we operationalise this framework using an automated tool chain that identifies *gender stereotype smells*. Evaluation on 73 popular Scratch tutorials from leading educational platforms demonstrates that stereotype smells are common in practice. LLMs are not effective at detecting them, but our gender bias evaluation framework can guide LLMs in generating tutorials with fewer stereotype smells.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "355",
        "title": "DebugTA: An LLM-Based Agent for Simplifying Debugging and Teaching in Programming Education",
        "author": [
            "Lingyue Fu",
            "Haowei Yuan",
            "Datong Chen",
            "Xinyi Dai",
            "Qingyao Li",
            "Weinan Zhang",
            "Weiwen Liu",
            "Yong Yu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11076",
        "abstract": "In programming education, Debugging and Teaching (DT) task is a common scenario where students receive assistance in correcting their erroneous code. The task involves multiple inputs, including erroneous code, error messages, reference solutions, and the question description, with the goal of generating modification suggestions to the erroneous code. However, two key challenges hinder the effectiveness of existing approaches. Firstly, the complexity and heterogeneity of inputs inherent in DT tasks significantly elevate the reasoning challenges faced by LLMs. Second, existing approaches often fail to fully leverage the availability of standard code in DT tasks, forcing models to rely solely on complex multi-step reasoning, which limits the potential of LLMs in addressing DT tasks effectively. To address these challenges, we propose DebugTA, a novel LLM-based debugging and teaching agent with specialized tools for standard code retrieval, variable substitution to align reference code, and an external compiler for real-time code analysis. Guided by explicit pedagogical and debugging principles, DebugTA acts as an agent that decomposes a complex task into sequential LLM interactions, each utilizing distinct tools for specific subtasks, thereby simplifying the logical reasoning at each step and reducing overall reasoning complexity. Furthermore, DebugTA utilizes tool calls to align the standard code with the erroneous code as much as possible, allowing the LLM to focus on logic errors within the erroneous code and improving the accuracy of the generated suggestions. To rigorously assess the quality of modification suggestions, we introduce a student simulator-teacher interaction paradigm. Experimental results on three real-world code datasets demonstrate that DebugTA consistently improves teaching effectiveness while significantly reducing computational costs.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "356",
        "title": "Flow Matching-Based Autonomous Driving Planning with Advanced Interactive Behavior Modeling",
        "author": [
            "Tianyi Tan",
            "Yinan Zheng",
            "Ruiming Liang",
            "Zexu Wang",
            "Kexin Zheng",
            "Jinliang Zheng",
            "Jianxiong Li",
            "Xianyuan Zhan",
            "Jingjing Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11083",
        "abstract": "Modeling interactive driving behaviors in complex scenarios remains a fundamental challenge for autonomous driving planning. Learning-based approaches attempt to address this challenge with advanced generative models, removing the dependency on over-engineered architectures for representation fusion. However, brute-force implementation by simply stacking transformer blocks lacks a dedicated mechanism for modeling interactive behaviors that are common in real driving scenarios. The scarcity of interactive driving data further exacerbates this problem, leaving conventional imitation learning methods ill-equipped to capture high-value interactive behaviors. We propose Flow Planner, which tackles these problems through coordinated innovations in data modeling, model architecture, and learning scheme. Specifically, we first introduce fine-grained trajectory tokenization, which decomposes the trajectory into overlapping segments to decrease the complexity of whole trajectory modeling. With a sophisticatedly designed architecture, we achieve efficient temporal and spatial fusion of planning and scene information, to better capture interactive behaviors. In addition, the framework incorporates flow matching with classifier-free guidance for multi-modal behavior generation, which dynamically reweights agent interactions during inference to maintain coherent response strategies, providing a critical boost for interactive scenario understanding. Experimental results on the large-scale nuPlan dataset and challenging interactive interPlan dataset demonstrate that Flow Planner achieves state-of-the-art performance among learning-based approaches while effectively modeling interactive behaviors in complex driving scenarios.",
        "tags": [
            "Flow Matching",
            "Transformer"
        ]
    },
    {
        "id": "357",
        "title": "Source-Free Object Detection with Detection Transformer",
        "author": [
            "Huizai Yao",
            "Sicheng Zhao",
            "Shuo Lu",
            "Hui Chen",
            "Yangyang Li",
            "Guoping Liu",
            "Tengfei Xing",
            "Chenggang Yan",
            "Jianhua Tao",
            "Guiguang Ding"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11090",
        "abstract": "Source-Free Object Detection (SFOD) enables knowledge transfer from a source domain to an unsupervised target domain for object detection without access to source data. Most existing SFOD approaches are either confined to conventional object detection (OD) models like Faster R-CNN or designed as general solutions without tailored adaptations for novel OD architectures, especially Detection Transformer (DETR). In this paper, we introduce Feature Reweighting ANd Contrastive Learning NetworK (FRANCK), a novel SFOD framework specifically designed to perform query-centric feature enhancement for DETRs. FRANCK comprises four key components: (1) an Objectness Score-based Sample Reweighting (OSSR) module that computes attention-based objectness scores on multi-scale encoder feature maps, reweighting the detection loss to emphasize less-recognized regions; (2) a Contrastive Learning with Matching-based Memory Bank (CMMB) module that integrates multi-level features into memory banks, enhancing class-wise contrastive learning; (3) an Uncertainty-weighted Query-fused Feature Distillation (UQFD) module that improves feature distillation through prediction quality reweighting and query feature fusion; and (4) an improved self-training pipeline with a Dynamic Teacher Updating Interval (DTUI) that optimizes pseudo-label quality. By leveraging these components, FRANCK effectively adapts a source-pre-trained DETR model to a target domain with enhanced robustness and generalization. Extensive experiments on several widely used benchmarks demonstrate that our method achieves state-of-the-art performance, highlighting its effectiveness and compatibility with DETR-based SFOD models.",
        "tags": [
            "Detection",
            "Transformer"
        ]
    },
    {
        "id": "358",
        "title": "Text-Enhanced Panoptic Symbol Spotting in CAD Drawings",
        "author": [
            "Xianlin Liu",
            "Yan Gong",
            "Bohao Li",
            "Jiajing Huang",
            "Bowen Du",
            "Junchen Ye",
            "Liyan Xu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11091",
        "abstract": "With the widespread adoption of Computer-Aided Design(CAD) drawings in engineering, architecture, and industrial design, the ability to accurately interpret and analyze these drawings has become increasingly critical. Among various subtasks, panoptic symbol spotting plays a vital role in enabling downstream applications such as CAD automation and design retrieval. Existing methods primarily focus on geometric primitives within the CAD drawings to address this task, but they face following major problems: they usually overlook the rich textual annotations present in CAD drawings and they lack explicit modeling of relationships among primitives, resulting in incomprehensive understanding of the holistic drawings. To fill this gap, we propose a panoptic symbol spotting framework that incorporates textual annotations. The framework constructs unified representations by jointly modeling geometric and textual primitives. Then, using visual features extract by pretrained CNN as the initial representations, a Transformer-based backbone is employed, enhanced with a type-aware attention mechanism to explicitly model the different types of spatial dependencies between various primitives. Extensive experiments on the real-world dataset demonstrate that the proposed method outperforms existing approaches on symbol spotting tasks involving textual annotations, and exhibits superior robustness when applied to complex CAD drawings.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "359",
        "title": "Design and Koopman Model Predictive Control of A Soft Exoskeleton Based on Origami-Inspired Pneumatic Actuator for Knee Rehabilitation",
        "author": [
            "Junxiang Wang",
            "Han Zhang",
            "Zehao Wang",
            "Huaiyuan Chen",
            "Pu Wang",
            "Weidong Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11094",
        "abstract": "Effective rehabilitation methods are essential for the recovery of lower limb dysfunction caused by stroke. Nowadays, robotic exoskeletons have shown great potentials in rehabilitation. Nevertheless, traditional rigid exoskeletons are usually heavy and need a lot of work to help the patients to put them on. Moreover, it also requires extra compliance control to guarantee the safety. In contrast, soft exoskeletons are easy and comfortable to wear and have intrinsic compliance, but their complex nonlinear human-robot interaction dynamics would pose significant challenges for control. In this work, based on the pneumatic actuators inspired by origami, we design a rehabilitation exoskeleton for knee that is easy and comfortable to wear. To guarantee the control performance and enable a nice human-robot interaction, we first use Deep Koopman Network to model the human-robot interaction dynamics. In particular, by viewing the electromyography (EMG) signals and the duty cycle of the PWM wave that controls the pneumatic robot's valves and pump as the inputs, the linear Koopman model accurately captures the complex human-robot interaction dynamics. Next, based on the obtained Koopman model, we further use Model Predictive Control (MPC) to control the soft robot and help the user to do rehabilitation training in real-time. The goal of the rehabilitation training is to track a given reference signal shown on the screen. Experiments show that by integrating the EMG signals into the Koopman model, we have improved the model accuracy to great extent. In addition, a personalized Koopman model trained from the individual's own data performs better than the non-personalized model. Consequently, our control framework outperforms the traditional PID control in both passive and active training modes. Hence the proposed method provides a new control framework for soft rehabilitation robots.",
        "tags": [
            "MPC",
            "Robotics"
        ]
    },
    {
        "id": "360",
        "title": "HoMer: Addressing Heterogeneities by Modeling Sequential and Set-wise Contexts for CTR Prediction",
        "author": [
            "Shuwei Chen",
            "Jiajun Cui",
            "Zhengqi Xu",
            "Fan Zhang",
            "Jiangke Fan",
            "Teng Zhang",
            "Xingxing Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11100",
        "abstract": "Click-through rate (CTR) prediction, which models behavior sequence and non-sequential features (e.g., user/item profiles or cross features) to infer user interest, underpins industrial recommender systems. However, most methods face three forms of heterogeneity that degrade predictive performance: (i) Feature Heterogeneity persists when limited sequence side features provide less granular interest representation compared to extensive non-sequential features, thereby impairing sequence modeling performance; (ii) Context Heterogeneity arises because a user's interest in an item will be influenced by other items, yet point-wise prediction neglects cross-item interaction context from the entire item set; (iii) Architecture Heterogeneity stems from the fragmented integration of specialized network modules, which compounds the model's effectiveness, efficiency and scalability in industrial deployments. To tackle the above limitations, we propose HoMer, a Homogeneous-Oriented TransforMer for modeling sequential and set-wise contexts. First, we align sequence side features with non-sequential features for accurate sequence modeling and fine-grained interest representation. Second, we shift the prediction paradigm from point-wise to set-wise, facilitating cross-item interaction in a highly parallel manner. Third, HoMer's unified encoder-decoder architecture achieves dual optimization through structural simplification and shared computation, ensuring computational efficiency while maintaining scalability with model size. Without arduous modification to the prediction pipeline, HoMer successfully scales up and outperforms our industrial baseline by 0.0099 in the AUC metric, and enhances online business metrics like CTR/RPM by 1.99%/2.46%. Additionally, HoMer saves 27% of GPU resources via preliminary engineering optimization, further validating its superiority and practicality.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "361",
        "title": "A Primer on SO(3) Action Representations in Deep Reinforcement Learning",
        "author": [
            "Martin Schuck",
            "Sherif Samy",
            "Angela P. Schoellig"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11103",
        "abstract": "Many robotic control tasks require policies to act on orientations, yet the geometry of SO(3) makes this nontrivial. Because SO(3) admits no global, smooth, minimal parameterization, common representations such as Euler angles, quaternions, rotation matrices, and Lie algebra coordinates introduce distinct constraints and failure modes. While these trade-offs are well studied for supervised learning, their implications for actions in reinforcement learning remain unclear. We systematically evaluate SO(3) action representations across three standard continuous control algorithms, PPO, SAC, and TD3, under dense and sparse rewards. We compare how representations shape exploration, interact with entropy regularization, and affect training stability through empirical studies and analyze the implications of different projections for obtaining valid rotations from Euclidean network outputs. Across a suite of robotics benchmarks, we quantify the practical impact of these choices and distill simple, implementation-ready guidelines for selecting and using rotation actions. Our results highlight that representation-induced geometry strongly influences exploration and optimization and show that representing actions as tangent vectors in the local frame yields the most reliable results across algorithms.",
        "tags": [
            "PPO",
            "RL",
            "Robotics"
        ]
    },
    {
        "id": "362",
        "title": "Enhancing LLM Reasoning via Non-Human-Like Reasoning Path Preference Optimization",
        "author": [
            "Junjie Lu",
            "Yuliang Liu",
            "Chaofeng Qu",
            "Wei Shen",
            "Zhouhan Lin",
            "Min Xu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11104",
        "abstract": "Current approaches for strengthening LLM reasoning tend to introduce a training bias toward human-like reasoning trajectories. In step-wise preference optimization, in particular, dependence on human or higher-capacity model annotations for intermediate steps limits exploration of alternative, non-human-like reasoning paths and thus constrains achievable performance. Furthermore, through a small-scale pilot study, we observed that in approximately 75% of cases, the model's first erroneous step occurs after the lowest-confidence point. This suggests that guiding the model at its lowest-confidence point before an error provides more accurate supervision than locating the first explicit error. In this paper, we propose Confidence-Guided Reasoning Path Preference Optimization (CGPO), a method that leverages a confidence signal to identify points of maximal uncertainty in the model's reasoning process and applies self-generated, non-human-like reasoning-path guidance to mitigate trajectory drift. Our experiments span diverse models applied to both code and mathematical reasoning tasks. The results show that, with the same amount of training data, our method using data generated by a small model can achieve better performance in most cases compared with approaches using data generated by a strong model or human-annotated.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "363",
        "title": "MoMaps: Semantics-Aware Scene Motion Generation with Motion Maps",
        "author": [
            "Jiahui Lei",
            "Kyle Genova",
            "George Kopanas",
            "Noah Snavely",
            "Leonidas Guibas"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11107",
        "abstract": "This paper addresses the challenge of learning semantically and functionally meaningful 3D motion priors from real-world videos, in order to enable prediction of future 3D scene motion from a single input image. We propose a novel pixel-aligned Motion Map (MoMap) representation for 3D scene motion, which can be generated from existing generative image models to facilitate efficient and effective motion prediction. To learn meaningful distributions over motion, we create a large-scale database of MoMaps from over 50,000 real videos and train a diffusion model on these representations. Our motion generation not only synthesizes trajectories in 3D but also suggests a new pipeline for 2D video synthesis: first generate a MoMap, then warp an image accordingly and complete the warped point-based renderings. Experimental results demonstrate that our approach generates plausible and semantically consistent 3D scene motion.",
        "tags": [
            "3D",
            "Diffusion"
        ]
    },
    {
        "id": "364",
        "title": "A Vision for Access Control in LLM-based Agent Systems",
        "author": [
            "Xinfeng Li",
            "Dong Huang",
            "Jie Li",
            "Hongyi Cai",
            "Zhenhong Zhou",
            "Wei Dong",
            "XiaoFeng Wang",
            "Yang Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11108",
        "abstract": "The autonomy and contextual complexity of LLM-based agents render traditional access control (AC) mechanisms insufficient. Static, rule-based systems designed for predictable environments are fundamentally ill-equipped to manage the dynamic information flows inherent in agentic interactions. This position paper argues for a paradigm shift from binary access control to a more sophisticated model of information governance, positing that the core challenge is not merely about permission, but about governing the flow of information. We introduce Agent Access Control (AAC), a novel framework that reframes AC as a dynamic, context-aware process of information flow governance. AAC operates on two core modules: (1) multi-dimensional contextual evaluation, which assesses not just identity but also relationships, scenarios, and norms; and (2) adaptive response formulation, which moves beyond simple allow/deny decisions to shape information through redaction, summarization, and paraphrasing. This vision, powered by a dedicated AC reasoning engine, aims to bridge the gap between human-like nuanced judgment and scalable Al safety, proposing a new conceptual lens for future research in trustworthy agent design.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "365",
        "title": "Graph Neural Network-Based Multicast Routing for On-Demand Streaming Services in 6G Networks",
        "author": [
            "Xiucheng Wang",
            "Zien Wang",
            "Nan Cheng",
            "Wenchao Xu",
            "Wei Quan",
            "Xuemin Shen"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11109",
        "abstract": "The increase of bandwidth-intensive applications in sixth-generation (6G) wireless networks, such as real-time volumetric streaming and multi-sensory extended reality, demands intelligent multicast routing solutions capable of delivering differentiated quality-of-service (QoS) at scale. Traditional shortest-path and multicast routing algorithms are either computationally prohibitive or structurally rigid, and they often fail to support heterogeneous user demands, leading to suboptimal resource utilization. Neural network-based approaches, while offering improved inference speed, typically lack topological generalization and scalability. To address these limitations, this paper presents a graph neural network (GNN)-based multicast routing framework that jointly minimizes total transmission cost and supports user-specific video quality requirements. The routing problem is formulated as a constrained minimum-flow optimization task, and a reinforcement learning algorithm is developed to sequentially construct efficient multicast trees by reusing paths and adapting to network dynamics. A graph attention network (GAT) is employed as the encoder to extract context-aware node embeddings, while a long short-term memory (LSTM) module models the sequential dependencies in routing decisions. Extensive simulations demonstrate that the proposed method closely approximates optimal dynamic programming-based solutions while significantly reducing computational complexity. The results also confirm strong generalization to large-scale and dynamic network topologies, highlighting the method's potential for real-time deployment in 6G multimedia delivery scenarios. Code is available at https://github.com/UNIC-Lab/GNN-Routing.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "366",
        "title": "Connecting Giants: Synergistic Knowledge Transfer of Large Multimodal Models for Few-Shot Learning",
        "author": [
            "Hao Tang",
            "Shengfeng He",
            "Jing Qin"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11115",
        "abstract": "Few-shot learning (FSL) addresses the challenge of classifying novel classes with limited training samples. While some methods leverage semantic knowledge from smaller-scale models to mitigate data scarcity, these approaches often introduce noise and bias due to the data's inherent simplicity. In this paper, we propose a novel framework, Synergistic Knowledge Transfer (SynTrans), which effectively transfers diverse and complementary knowledge from large multimodal models to empower the off-the-shelf few-shot learner. Specifically, SynTrans employs CLIP as a robust teacher and uses a few-shot vision encoder as a weak student, distilling semantic-aligned visual knowledge via an unsupervised proxy task. Subsequently, a training-free synergistic knowledge mining module facilitates collaboration among large multimodal models to extract high-quality semantic knowledge. Building upon this, a visual-semantic bridging module enables bi-directional knowledge transfer between visual and semantic spaces, transforming explicit visual and implicit semantic knowledge into category-specific classifier weights. Finally, SynTrans introduces a visual weight generator and a semantic weight reconstructor to adaptively construct optimal multimodal FSL classifiers. Experimental results on four FSL datasets demonstrate that SynTrans, even when paired with a simple few-shot vision encoder, significantly outperforms current state-of-the-art methods.",
        "tags": [
            "CLIP"
        ]
    },
    {
        "id": "367",
        "title": "Demystifying Numerosity in Diffusion Models -- Limitations and Remedies",
        "author": [
            "Yaqi Zhao",
            "Xiaochen Wang",
            "Li Dong",
            "Wentao Zhang",
            "Yuhui Yuan"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11117",
        "abstract": "Numerosity remains a challenge for state-of-the-art text-to-image generation models like FLUX and GPT-4o, which often fail to accurately follow counting instructions in text prompts. In this paper, we aim to study a fundamental yet often overlooked question: Can diffusion models inherently generate the correct number of objects specified by a textual prompt simply by scaling up the dataset and model size? To enable rigorous and reproducible evaluation, we construct a clean synthetic numerosity benchmark comprising two complementary datasets: GrayCount250 for controlled scaling studies, and NaturalCount6 featuring complex naturalistic scenes. Second, we empirically show that the scaling hypothesis does not hold: larger models and datasets alone fail to improve counting accuracy on our benchmark. Our analysis identifies a key reason: diffusion models tend to rely heavily on the noise initialization rather than the explicit numerosity specified in the prompt. We observe that noise priors exhibit biases toward specific object counts. In addition, we propose an effective strategy for controlling numerosity by injecting count-aware layout information into the noise prior. Our method achieves significant gains, improving accuracy on GrayCount250 from 20.0\\% to 85.3\\% and on NaturalCount6 from 74.8\\% to 86.3\\%, demonstrating effective generalization across settings.",
        "tags": [
            "Diffusion",
            "FLUX",
            "GPT",
            "Text-to-Image"
        ]
    },
    {
        "id": "368",
        "title": "Improving AI Efficiency in Data Centres by Power Dynamic Response",
        "author": [
            "Andrea Marinoni",
            "Sai Shivareddy",
            "Pietro Lio'",
            "Weisi Lin",
            "Erik Cambria",
            "Clare Grey"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11119",
        "abstract": "The steady growth of artificial intelligence (AI) has accelerated in the recent years, facilitated by the development of sophisticated models such as large language models and foundation models. Ensuring robust and reliable power infrastructures is fundamental to take advantage of the full potential of AI. However, AI data centres are extremely hungry for power, putting the problem of their power management in the spotlight, especially with respect to their impact on environment and sustainable development. In this work, we investigate the capacity and limits of solutions based on an innovative approach for the power management of AI data centres, i.e., making part of the input power as dynamic as the power used for data-computing functions. The performance of passive and active devices are quantified and compared in terms of computational gain, energy efficiency, reduction of capital expenditure, and management costs by analysing power trends from multiple data platforms worldwide. This strategy, which identifies a paradigm shift in the AI data centre power management, has the potential to strongly improve the sustainability of AI hyperscalers, enhancing their footprint on environmental, financial, and societal fields.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "369",
        "title": "Refining Hybrid Genetic Search for CVRP via Reinforcement Learning-Finetuned LLM",
        "author": [
            "Rongjie Zhu",
            "Cong Zhang",
            "Zhiguang Cao"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11121",
        "abstract": "While large language models (LLMs) are increasingly used as automated heuristic designers for vehicle routing problems (VRPs), current state-of-the-art methods predominantly rely on prompting massive, general-purpose models like GPT-4. This work challenges that paradigm by demonstrating that a smaller, specialized LLM, when meticulously fine-tuned, can generate components that surpass expert-crafted heuristics within advanced solvers. We propose RFTHGS, a novel Reinforcement learning (RL) framework for Fine-Tuning a small LLM to generate high-performance crossover operators for the Hybrid Genetic Search (HGS) solver, applied to the Capacitated VRP (CVRP). Our method employs a multi-tiered, curriculum-based reward function that progressively guides the LLM to master generating first compilable, then executable, and finally, superior-performing operators that exceed human expert designs. This is coupled with an operator caching mechanism that discourages plagiarism and promotes diversity during training. Comprehensive experiments show that our fine-tuned LLM produces crossover operators which significantly outperform the expert-designed ones in HGS. The performance advantage remains consistent, generalizing from small-scale instances to large-scale problems with up to 1000 nodes. Furthermore, RFTHGS exceeds the performance of leading neuro-combinatorial baselines, prompt-based methods, and commercial LLMs such as GPT-4o and GPT-4o-mini.",
        "tags": [
            "GPT",
            "LLM",
            "RL"
        ]
    },
    {
        "id": "370",
        "title": "DyKnow-RAG: Dynamic Knowledge Utilization Reinforcement Framework for Noisy Retrieval-Augmented Generation in E-commerce Search Relevance",
        "author": [
            "Tingqiao Xu",
            "Shaowei Yao",
            "Chenhe Dong",
            "Yiming Jin",
            "Zerui Huang",
            "Dan Ou",
            "Haihong Tang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11122",
        "abstract": "Accurately modeling query-item relevance drives e-commerce ranking, yet long-tail, knowledge-heavy, and fast-evolving queries exceed parametric LLM coverage. External context (reviews, attribute encyclopedias, UGC) can help but is noisy, and single-pass latency and cost forbid any clean-then-summarize step. The model must, per query, judge relevance and decide whether to use, partially use, or ignore the context. DyKnow-RAG is a dynamic noisy-RAG framework built on Group Relative Policy Optimization. It trains two rollout groups (no external context vs a single retrieved chunk) and applies posterior-driven inter-group advantage scaling that adaptively reweights their contributions by the per-query correctness gap. This teaches when to trust retrieval versus fall back to parametric knowledge, without process labels, value networks, or extra inference passes, preserving single-pass, single-chunk deployment under production latency. Training combines: (1) supervised initialization with a structured rationale that explicitly records the context-usage decision; (2) an RL pool prioritized by SFT uncertainty to focus where context choice is most consequential; and (3) an optional lightweight DPO warm start to stabilize with-context calibration. Under a unified retrieval/index and fixed latency budget, DyKnow-RAG outperforms SFT, DPO, and vanilla GRPO in offline tests, and delivers consistent lifts on GSB, Query Goodrate, and Item Goodrate in Taobao A/B testing. It is deployed in Taobao's production relevance system, serving live traffic. To our knowledge, it is among the first single-pass RAG solutions for e-commerce relevance, turning noisy external signals into reliable gains without added online complexity.",
        "tags": [
            "DPO",
            "GRPO",
            "LLM",
            "RAG",
            "RL"
        ]
    },
    {
        "id": "371",
        "title": "video-SALMONN S: Streaming Audio-Visual LLMs Beyond Length Limits via Memory",
        "author": [
            "Guangzhi Sun",
            "Yixuan Li",
            "Xiaodong Wu",
            "Yudong Yang",
            "Wei Li",
            "Zejun Ma",
            "Chao Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11129",
        "abstract": "Continuous, high-frame-rate, high-resolution processing of long video streams is critical for future AI agents, yet current video-understanding LLMs struggle to scale. Offline, fixed-frame-number methods require the stream length to adapt frame rates; streaming methods constrain memory by merging or discarding tokens, losing information. We propose video-SALMONN S, a streaming audio-visual LLM that, to our knowledge, is the first to process 3-hour videos at 1 FPS and 360p resolution under a fixed memory budget. Our model introduces (i) a test-time-training (TTT) memory module that continually updates token representations to capture long-range dependencies by replacing token merging, and (ii) a prompt-dependent memory reader that selectively retrieves context-relevant content from fixed-size memory. The TTT module is optimised with a Hessian-free conjugate-gradient procedure (TTT_HF) for efficient adaptation. On long-video benchmarks (Video-MME, LVBench, VideoEvalPro), video-SALMONN S sustains high-quality understanding on multi-hour videos with 10k frames and 1M tokens. Our 8B-parameter model achieves 74.2% overall and 67.8% on the Video-MME long split, outperforming both offline and streaming baselines.",
        "tags": [
            "LLM",
            "TTT"
        ]
    },
    {
        "id": "372",
        "title": "SocioBench: Modeling Human Behavior in Sociological Surveys with Large Language Models",
        "author": [
            "Jia Wang",
            "Ziyu Zhao",
            "Tingjuntao Ni",
            "Zhongyu Wei"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11131",
        "abstract": "Large language models (LLMs) show strong potential for simulating human social behaviors and interactions, yet lack large-scale, systematically constructed benchmarks for evaluating their alignment with real-world social attitudes. To bridge this gap, we introduce SocioBench-a comprehensive benchmark derived from the annually collected, standardized survey data of the International Social Survey Programme (ISSP). The benchmark aggregates over 480,000 real respondent records from more than 30 countries, spanning 10 sociological domains and over 40 demographic attributes. Our experiments indicate that LLMs achieve only 30-40% accuracy when simulating individuals in complex survey scenarios, with statistically significant differences across domains and demographic subgroups. These findings highlight several limitations of current LLMs in survey scenarios, including insufficient individual-level data coverage, inadequate scenario diversity, and missing group-level modeling.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "373",
        "title": "CoSPED: Consistent Soft Prompt Targeted Data Extraction and Defense",
        "author": [
            "Yang Zhuochen",
            "Fok Kar Wai",
            "Thing Vrizlynn"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11137",
        "abstract": "Large language models have gained widespread attention recently, but their potential security vulnerabilities, especially privacy leakage, are also becoming apparent. To test and evaluate for data extraction risks in LLM, we proposed CoSPED, short for Consistent Soft Prompt targeted data Extraction and Defense. We introduce several innovative components, including Dynamic Loss, Additive Loss, Common Loss, and Self Consistency Decoding Strategy, and tested to enhance the consistency of the soft prompt tuning process. Through extensive experimentation with various combinations, we achieved an extraction rate of 65.2% at a 50-token prefix comparison. Our comparisons of CoSPED with other reference works confirm our superior extraction rates. We evaluate CoSPED on more scenarios, achieving Pythia model extraction rate of 51.7% and introducing cross-model comparison. Finally, we explore defense through Rank-One Model Editing and achieve a reduction in the extraction rate to 1.6%, which proves that our analysis of extraction mechanisms can directly inform effective mitigation strategies against soft prompt-based attacks.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "374",
        "title": "What Slows Down FMware Development? An Empirical Study of Developer Challenges and Resolution Times",
        "author": [
            "Zitao Wang",
            "Zhimin Zhao",
            "Michael W. Godfrey"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11138",
        "abstract": "Foundation Models (FMs), such as OpenAI's GPT, are fundamentally transforming the practice of software engineering by enabling the development of \\emph{FMware} -- applications and infrastructures built around these models. FMware systems now support tasks such as code generation, natural-language interaction, knowledge integration, and multi-modal content creation, underscoring their disruptive impact on current software engineering workflows. However, the design, implementation, and evolution of FMware present significant new challenges, particularly across cloud-based and on-premise platforms where goals, processes, and tools often diverge from those of traditional software development.\nTo our knowledge, this is the first large-scale analysis of FMware development across both cloud-based platforms and open-source repositories. We empirically investigate the FMware ecosystem through three focus areas: (1) the most common application domains of FMware, (2) the key challenges developers encounter, and (3) the types of issues that demand the greatest effort to resolve. Our analysis draws on data from GitHub repositories and from leading FMware platforms, including HuggingFace, GPTStore, Ora, and Poe. Our findings reveal a strong focus on education, content creation, and business strategy, alongside persistent technical challenges in memory management, dependency handling, and tokenizer configuration. On GitHub, bug reports and core functionality issues are the most frequently reported problems, while code review, similarity search, and prompt template design are the most time-consuming to resolve.\nBy uncovering developer practices and pain points, this study points to opportunities to improve FMware tools, workflows, and community support, and provides actionable insights to help guide the future of FMware development.",
        "tags": [
            "GPT"
        ]
    },
    {
        "id": "375",
        "title": "Validation of an Artificial Intelligence Tool for the Detection of Sperm DNA Fragmentation Using the TUNEL In Situ Hybridization Assay",
        "author": [
            "Byron Alexander Jacobs",
            "Aqeel Morris",
            "Ifthakaar Shaik",
            "Frando Lin"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11142",
        "abstract": "Sperm DNA fragmentation (SDF) is a critical parameter in male fertility assessment that conventional semen analysis fails to evaluate. This study presents the validation of a novel artificial intelligence (AI) tool designed to detect SDF through digital analysis of phase contrast microscopy images, using the terminal deoxynucleotidyl transferase dUTP nick end labeling (TUNEL) assay as the gold standard reference. Utilising the established link between sperm morphology and DNA integrity, the present work proposes a morphology assisted ensemble AI model that combines image processing techniques with state-of-the-art transformer based machine learning models (GC-ViT) for the prediction of DNA fragmentation in sperm from phase contrast images. The ensemble model is benchmarked against a pure transformer `vision' model as well as a `morphology-only` model. Promising results show the proposed framework is able to achieve sensitivity of 60\\% and specificity of 75\\%. This non-destructive methodology represents a significant advancement in reproductive medicine by enabling real-time sperm selection based on DNA integrity for clinical diagnostic and therapeutic applications.",
        "tags": [
            "Detection",
            "Transformer",
            "ViT"
        ]
    },
    {
        "id": "376",
        "title": "$How^{2}$: How to learn from procedural How-to questions",
        "author": [
            "Gautier Dagan",
            "Frank Keller",
            "Alex Lascarides"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11144",
        "abstract": "An agent facing a planning problem can use answers to how-to questions to reduce uncertainty and fill knowledge gaps, helping it solve both current and future tasks. However, their open ended nature, where valid answers to \"How do I X?\" range from executable actions to high-level descriptions of X's sub-goals, makes them challenging for AI agents to ask, and for AI experts to answer, in ways that support efficient planning. We introduce $How^{2}$, a memory agent framework that enables agents to ask how-to questions, store the answers, and reuse them for lifelong learning in interactive environments. We evaluate our approach in Plancraft, a Minecraft crafting environment, where agents must complete an assembly task by manipulating inventory items. Using teacher models that answer at varying levels of abstraction, from executable action sequences to high-level subgoal descriptions, we show that lifelong learning agents benefit most from answers that are abstracted and decoupled from the current state. $How^{2}$ offers a way for LLM-based agents to improve their planning capabilities over time by asking questions in interactive environments.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "377",
        "title": "TypePilot: Leveraging the Scala Type System for Secure LLM-generated Code",
        "author": [
            "Alexander Sternfeld",
            "Andrei Kucharavy",
            "Ljiljana Dolamic"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11151",
        "abstract": "Large language Models (LLMs) have shown remarkable proficiency in code generation tasks across various programming languages. However, their outputs often contain subtle but critical vulnerabilities, posing significant risks when deployed in security-sensitive or mission-critical systems. This paper introduces TypePilot, an agentic AI framework designed to enhance the security and robustness of LLM-generated code by leveraging strongly typed and verifiable languages, using Scala as a representative example. We evaluate the effectiveness of our approach in two settings: formal verification with the Stainless framework and general-purpose secure code generation. Our experiments with leading open-source LLMs reveal that while direct code generation often fails to enforce safety constraints, just as naive prompting for more secure code, our type-focused agentic pipeline substantially mitigates input validation and injection vulnerabilities. The results demonstrate the potential of structured, type-guided LLM workflows to improve the SotA of the trustworthiness of automated code generation in high-assurance domains.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "378",
        "title": "Emergence of hybrid computational dynamics through reinforcement learning",
        "author": [
            "Roman A. Kononov",
            "Nikita A. Pospelov",
            "Konstantin V. Anokhin",
            "Vladimir V. Nekorkin",
            "Oleg V. Maslennikov"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11162",
        "abstract": "Understanding how learning algorithms shape the computational strategies that emerge in neural networks remains a fundamental challenge in machine intelligence. While network architectures receive extensive attention, the role of the learning paradigm itself in determining emergent dynamics remains largely unexplored. Here we demonstrate that reinforcement learning (RL) and supervised learning (SL) drive recurrent neural networks (RNNs) toward fundamentally different computational solutions when trained on identical decision-making tasks. Through systematic dynamical systems analysis, we reveal that RL spontaneously discovers hybrid attractor architectures, combining stable fixed-point attractors for decision maintenance with quasi-periodic attractors for flexible evidence integration. This contrasts sharply with SL, which converges almost exclusively to simpler fixed-point-only solutions. We further show that RL sculpts functionally balanced neural populations through a powerful form of implicit regularization -- a structural signature that enhances robustness and is conspicuously absent in the more heterogeneous solutions found by SL-trained networks. The prevalence of these complex dynamics in RL is controllably modulated by weight initialization and correlates strongly with performance gains, particularly as task complexity increases. Our results establish the learning algorithm as a primary determinant of emergent computation, revealing how reward-based optimization autonomously discovers sophisticated dynamical mechanisms that are less accessible to direct gradient-based optimization. These findings provide both mechanistic insights into neural computation and actionable principles for designing adaptive AI systems.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "379",
        "title": "Bridging Gaps in Hate Speech Detection: Meta-Collections and Benchmarks for Low-Resource Iberian Languages",
        "author": [
            "Paloma Piot",
            "JosÃ© Ramom Pichel Campos",
            "Javier Parapar"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11167",
        "abstract": "Hate speech poses a serious threat to social cohesion and individual well-being, particularly on social media, where it spreads rapidly. While research on hate speech detection has progressed, it remains largely focused on English, resulting in limited resources and benchmarks for low-resource languages. Moreover, many of these languages have multiple linguistic varieties, a factor often overlooked in current approaches. At the same time, large language models require substantial amounts of data to perform reliably, a requirement that low-resource languages often cannot meet. In this work, we address these gaps by compiling a meta-collection of hate speech datasets for European Spanish, standardised with unified labels and metadata. This collection is based on a systematic analysis and integration of existing resources, aiming to bridge the data gap and support more consistent and scalable hate speech detection. We extended this collection by translating it into European Portuguese and into a Galician standard that is more convergent with Spanish and another Galician variant that is more convergent with Portuguese, creating aligned multilingual corpora. Using these resources, we establish new benchmarks for hate speech detection in Iberian languages. We evaluate state-of-the-art large language models in zero-shot, few-shot, and fine-tuning settings, providing baseline results for future research. Moreover, we perform a cross-lingual analysis with our target languages. Our findings underscore the importance of multilingual and variety-aware approaches in hate speech detection and offer a foundation for improved benchmarking in underrepresented European languages.",
        "tags": [
            "Detection",
            "LLM"
        ]
    },
    {
        "id": "380",
        "title": "CoPRS: Learning Positional Prior from Chain-of-Thought for Reasoning Segmentation",
        "author": [
            "Zhenyu Lu",
            "Liupeng Li",
            "Jinpeng Wang",
            "Yan Feng",
            "Bin Chen",
            "Ke Chen",
            "Yaowei Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11173",
        "abstract": "Existing works on reasoning segmentation either connect hidden features from a language model directly to a mask decoder or represent positions in text, which limits interpretability and semantic detail. To solve this, we present CoPRS, a Multi-modal Chain-of-Thought (MCoT)-based positional perception model that bridges language reasoning to segmentation through a differentiable and interpretable positional prior instantiated as a heatmap. By making the reasoning process clear via MCoT and expressing it as a dense, differentiable heatmap, this interface enhances interpretability and diagnostic analysis and yields more concentrated evidence on the target. A learnable concentration token aggregates features of the image and reasoning text to generate this positional prior, which is decoded to precise masks through a lightweight decoder, providing a direct connection between reasoning and segmentation. Across the RefCOCO series and ReasonSeg, CoPRS matches or surpasses the best reported metrics on each standard split under comparable protocols, with performance at or above prior state of the art across both validation and test partitions. Extensive experiments reveal that the quality of the heatmap strongly influences the resulting mask quality, supporting a consistent association between the reasoning output and downstream mask generation. Collectively, these findings support the utility of this paradigm in bridging reasoning and segmentation and show advantages in concentration driven by reasoning and predicting masks more precisely. Code, checkpoints and logs are released at https://github.com/ZhenyuLU-Heliodore/CoPRS.git.",
        "tags": [
            "CoT",
            "Segmentation"
        ]
    },
    {
        "id": "381",
        "title": "BLEnD-Vis: Benchmarking Multimodal Cultural Understanding in Vision Language Models",
        "author": [
            "Bryan Chen Zhengyu Tan",
            "Zheng Weihua",
            "Zhengyuan Liu",
            "Nancy F. Chen",
            "Hwaran Lee",
            "Kenny Tsu Wei Choo",
            "Roy Ka-Wei Lee"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11178",
        "abstract": "As vision-language models (VLMs) are deployed globally, their ability to understand culturally situated knowledge becomes essential. Yet, existing evaluations largely assess static recall or isolated visual grounding, leaving unanswered whether VLMs possess robust and transferable cultural understanding. We introduce BLEnD-Vis, a multimodal, multicultural benchmark designed to evaluate the robustness of everyday cultural knowledge in VLMs across linguistic rephrasings and visual modalities. Building on the BLEnD dataset, BLEnD-Vis constructs 313 culturally grounded question templates spanning 16 regions and generates three aligned multiple-choice formats: (i) a text-only baseline querying from Region $\\to$ Entity, (ii) an inverted text-only variant (Entity $\\to$ Region), and (iii) a VQA-style version of (ii) with generated images. The resulting benchmark comprises 4,916 images and over 21,000 multiple-choice question (MCQ) instances, validated through human annotation. BLEnD-Vis reveals significant fragility in current VLM cultural knowledge; models exhibit performance drops under linguistic rephrasing and, whilst visual cues often aid performance, low cross-modal consistency highlights challenges in robustly integrating textual and visual understanding, particularly for lower-resource regions. BLEnD-Vis thus provides a crucial testbed for systematically analysing cultural robustness and multimodal grounding, exposing limitations and guiding the development of more culturally competent VLMs.",
        "tags": [
            "VLM"
        ]
    },
    {
        "id": "382",
        "title": "Can Tool-Integrated Reinforcement Learning Generalize Across Diverse Domains?",
        "author": [
            "Zhengyu Chen",
            "Jinluan Yang",
            "Teng Xiao",
            "Ruochen Zhou",
            "Luan Zhang",
            "Xiangyu Xi",
            "Xiaowei Shi",
            "Wei Wang",
            "Jinggang Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11184",
        "abstract": "Recent advances in large language models (LLMs) have demonstrated remarkable capabilities in reasoning and tool utilization. However, the generalization of tool-augmented reinforcement learning (RL) across diverse domains remains underexplored. In this work, we investigate the cross-domain generalization of an LLM agent equipped with a code interpreter tool, which is exclusively trained on mathematical problem-solving tasks. Despite the restricted training domain, we evaluate the agent's performance across several distinct reasoning domains. The results reveal that RL-based tool usage learned from mathematical tasks can be effectively transferred to complex tasks in other domains, enabling great task performance and high token efficiency. To facilitate this cross-domain transfer, we propose a Tool Generalization Reinforcement Learning (TGRL) framework designed to promote domain-agnostic learning and skill migration, encompassing: (i) a standardized tool interface that abstracts domain-specific nuances through consistent formatting and explicit termination, fostering transferable invocation patterns; (ii) a dual-component reward system that decomposes rewards to incentivize generalizable behaviors like tool efficiency and reasoning abstraction, ensuring alignment and robustness across domain shifts; and (iii) an XML-based prompt template that separates thinking, tool calls, and responses to encourage modular, domain-invariant planning and coherent multi-turn interactions. Extensive experiments across diverse benchmarks validate our approach, achieving state-of-the-art performance and highlighting the cross-domain potential of Tool RL for LLM reasoning.",
        "tags": [
            "LLM",
            "RL"
        ]
    },
    {
        "id": "383",
        "title": "FlexAC: Towards Flexible Control of Associative Reasoning in Multimodal Large Language Models",
        "author": [
            "Shengming Yuan",
            "Xinyu Lyu",
            "Shuailong Wang",
            "Beitao Chen",
            "Jingkuan Song",
            "Lianli Gao"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11190",
        "abstract": "Multimodal large language models (MLLMs) face an inherent trade-off between faithfulness and creativity, as different tasks require varying degrees of associative reasoning. However, existing methods lack the flexibility to modulate this reasoning strength, limiting MLLMs' adaptability across factual and creative scenarios. To bridge this gap, we propose equipping MLLMs with mechanisms that enable flexible control over associative reasoning. We begin by investigating the internal mechanisms underlying associative behavior in MLLMs and find that: (1) middle layers play a pivotal role in shaping model's associative tendencies, (2) modifying representations in these layers effectively regulates associative reasoning strength, and (3) hallucinations can be exploited to derive steering vectors that guide this modulation. Building on these findings, we introduce Flexible Association Control (FlexAC), a lightweight and training-free framework for modulating associative behavior in MLLMs. FlexAC first induces hallucination-guided intermediate representations to encode associative directions. Then, it selects high-association instances to construct effective associative steering vectors, whose strengths are adaptively calibrated to balance creative guidance with output stability. Finally, recognizing the multi-dimensional nature of associative reasoning, FlexAC incorporates task-specific associative vectors derived from a forward pass on a few target-domain samples, enabling models to follow diverse associative directions and better adapt to creative tasks. Notably, our method achieves up to a 5.8x improvement in creativity on Creation-MMBench and a 29% reduction in hallucination rate on CHAIR, surpassing existing baselines and demonstrating its effectiveness in enabling flexible control over associative reasoning in MLLMs. Our code is available at https://github.com/ylhz/FlexAC.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "384",
        "title": "Efficient In-Memory Acceleration of Sparse Block Diagonal LLMs",
        "author": [
            "JoÃ£o Paulo Cardoso de Lima",
            "Marc Dietrich",
            "Jeronimo Castrillon",
            "Asif Ali Khan"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11192",
        "abstract": "Structured sparsity enables deploying large language models (LLMs) on resource-constrained systems. Approaches like dense-to-sparse fine-tuning are particularly compelling, achieving remarkable structured sparsity by reducing the model size by over 6.7x, while still maintaining acceptable accuracy. Despite this reduction, LLM inference, especially the decode stage being inherently memory-bound, is extremely expensive on conventional Von-Neumann architectures. Compute-in-memory (CIM) architectures mitigate this by performing computations directly in memory, and when paired with sparse LLMs, enable storing and computing the entire model in memory, eliminating the data movement on the off-chip bus and improving efficiency. Nonetheless, naively mapping sparse matrices onto CIM arrays leads to poor array utilization and diminished computational efficiency. In this paper, we present an automated framework with novel mapping and scheduling strategies to accelerate sparse LLM inference on CIM accelerators. By exploiting block-diagonal sparsity, our approach improves CIM array utilization by over 50%, achieving more than 4x reduction in both memory footprint and the number of required floating-point operations.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "385",
        "title": "Aligning Deep Implicit Preferences by Learning to Reason Defensively",
        "author": [
            "Peiming Li",
            "Zhiyuan Hu",
            "Yang Tang",
            "Shiyu Li",
            "Xi Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11194",
        "abstract": "Personalized alignment is crucial for enabling Large Language Models (LLMs) to engage effectively in user-centric interactions. However, current methods face a dual challenge: they fail to infer users' deep implicit preferences (including unstated goals, semantic context and risk tolerances), and they lack the defensive reasoning required to navigate real-world ambiguity. This cognitive gap leads to responses that are superficial, brittle and short-sighted. To address this, we propose Critique-Driven Reasoning Alignment (CDRA), which reframes alignment from a scalar reward-matching task into a structured reasoning process. First, to bridge the preference inference gap, we introduce the DeepPref benchmark. This dataset, comprising 3000 preference-query pairs across 20 topics, is curated by simulating a multi-faceted cognitive council that produces critique-annotated reasoning chains to deconstruct query semantics and reveal latent risks. Second, to instill defensive reasoning, we introduce the Personalized Generative Process Reward Model (Pers-GenPRM), which frames reward modeling as a personalized reasoning task. It generates a critique chain to evaluate a response's alignment with user preferences before outputting a final score based on this rationale. Ultimately, this interpretable, structured reward signal guides policy model through Critique-Driven Policy Alignment, a process-level online reinforcement learning algorithm integrating both numerical and natural language feedback. Experiments demonstrate that CDRA excels at discovering and aligning with users' true preferences while executing robust reasoning. Our code and dataset are available at https://github.com/Zephyrian-Hugh/Deep-pref.",
        "tags": [
            "LLM",
            "RL"
        ]
    },
    {
        "id": "386",
        "title": "RAG-Pull: Imperceptible Attacks on RAG Systems for Code Generation",
        "author": [
            "Vasilije Stambolic",
            "Aritra Dhar",
            "Lukas Cavigelli"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11195",
        "abstract": "Retrieval-Augmented Generation (RAG) increases the reliability and trustworthiness of the LLM response and reduces hallucination by eliminating the need for model retraining. It does so by adding external data into the LLM's context. We develop a new class of black-box attack, RAG-Pull, that inserts hidden UTF characters into queries or external code repositories, redirecting retrieval toward malicious code, thereby breaking the models' safety alignment. We observe that query and code perturbations alone can shift retrieval toward attacker-controlled snippets, while combined query-and-target perturbations achieve near-perfect success. Once retrieved, these snippets introduce exploitable vulnerabilities such as remote code execution and SQL injection. RAG-Pull's minimal perturbations can alter the model's safety alignment and increase preference towards unsafe code, therefore opening up a new class of attacks on LLMs.",
        "tags": [
            "LLM",
            "RAG"
        ]
    },
    {
        "id": "387",
        "title": "Class Prototypes based Contrastive Learning for Classifying Multi-Label and Fine-Grained Educational Videos",
        "author": [
            "Rohit Gupta",
            "Anirban Roy",
            "Claire Christensen",
            "Sujeong Kim",
            "Sarah Gerard",
            "Madeline Cincebeaux",
            "Ajay Divakaran",
            "Todd Grindal",
            "Mubarak Shah"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11204",
        "abstract": "The recent growth in the consumption of online media by children during early childhood necessitates data-driven tools enabling educators to filter out appropriate educational content for young learners. This paper presents an approach for detecting educational content in online videos. We focus on two widely used educational content classes: literacy and math. For each class, we choose prominent codes (sub-classes) based on the Common Core Standards. For example, literacy codes include `letter names', `letter sounds', and math codes include `counting', `sorting'. We pose this as a fine-grained multilabel classification problem as videos can contain multiple types of educational content and the content classes can get visually similar (e.g., `letter names' vs `letter sounds'). We propose a novel class prototypes based supervised contrastive learning approach that can handle fine-grained samples associated with multiple labels. We learn a class prototype for each class and a loss function is employed to minimize the distances between a class prototype and the samples from the class. Similarly, distances between a class prototype and the samples from other classes are maximized. As the alignment between visual and audio cues are crucial for effective comprehension, we consider a multimodal transformer network to capture the interaction between visual and audio cues in videos while learning the embedding for videos. For evaluation, we present a dataset, APPROVE, employing educational videos from YouTube labeled with fine-grained education classes by education researchers. APPROVE consists of 193 hours of expert-annotated videos with 19 classes. The proposed approach outperforms strong baselines on APPROVE and other benchmarks such as Youtube-8M, and COIN. The dataset is available at https://github.com/rohit-gupta/MMContrast/tree/main/APPROVE",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "388",
        "title": "Discursive Circuits: How Do Language Models Understand Discourse Relations?",
        "author": [
            "Yisong Miao",
            "Min-Yen Kan"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11210",
        "abstract": "Which components in transformer language models are responsible for discourse understanding? We hypothesize that sparse computational graphs, termed as discursive circuits, control how models process discourse relations. Unlike simpler tasks, discourse relations involve longer spans and complex reasoning. To make circuit discovery feasible, we introduce a task called Completion under Discourse Relation (CuDR), where a model completes a discourse given a specified relation. To support this task, we construct a corpus of minimal contrastive pairs tailored for activation patching in circuit discovery. Experiments show that sparse circuits ($\\approx 0.2\\%$ of a full GPT-2 model) recover discourse understanding in the English PDTB-based CuDR task. These circuits generalize well to unseen discourse frameworks such as RST and SDRT. Further analysis shows lower layers capture linguistic features such as lexical semantics and coreference, while upper layers encode discourse-level abstractions. Feature utility is consistent across frameworks (e.g., coreference supports Expansion-like relations).",
        "tags": [
            "GPT",
            "Transformer"
        ]
    },
    {
        "id": "389",
        "title": "An Explorative Study on Distributed Computing Techniques in Training and Inference of Large Language Models",
        "author": [
            "Sheikh Azizul Hakim",
            "Saem Hasan"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11211",
        "abstract": "Large language models (LLM) are advanced AI systems trained on extensive textual data, leveraging deep learning techniques to understand and generate human-like language. Today's LLMs with billions of parameters are so huge that hardly any single computing node can train, fine-tune, or infer from them. Therefore, several distributed computing techniques are being introduced in the literature to properly utilize LLMs. We have explored the application of distributed computing techniques in LLMs from two angles.\n\\begin{itemize}\n\\item We study the techniques that democratize the LLM, that is, how large models can be run on consumer-grade computers. Here, we also implement a novel metaheuristics-based modification to an existing system.\n\\item We perform a comparative study on three state-of-the-art LLM serving techniques. \\end{itemize}",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "390",
        "title": "Domain-Specific Data Generation Framework for RAG Adaptation",
        "author": [
            "Chris Xing Tian",
            "Weihao Xie",
            "Zhen Chen",
            "Zhengyuan Yi",
            "Hui Liu",
            "Haoliang Li",
            "Shiqi Wang",
            "Siwei Ma"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11217",
        "abstract": "Retrieval-Augmented Generation (RAG) combines the language understanding and reasoning power of large language models (LLMs) with external retrieval to enable domain-grounded responses. Effectively adapting RAG systems to domain-specific settings requires specialized, context-rich training data beyond general-purpose question-answering. Here, we propose RAGen, a scalable and modular framework for generating domain-grounded question-answer-context (QAC) triples tailored to diverse RAG adaptation approaches. RAGen produces these QAC triples by identifying key concepts in documents, generating diverse questions guided by Bloom's Taxonomy-inspired principles, and pairing them with precise answers extracted from relevant contexts. RAGen supports multiple RAG adaptation strategies, including the optimization of key components such as the LLM, retriever, and embedding model, etc. Its modular pipeline features semantic chunking, hierarchical concept extraction, and multi-chunk retrieval, along with the introduction of curated distractor contexts to promote robust reasoning. Designed for scalability, RAGen efficiently handles large and evolving document corpora without redundant processing, making it especially suitable for dynamic evolving domains such as scientific research and enterprise knowledge bases.",
        "tags": [
            "LLM",
            "RAG"
        ]
    },
    {
        "id": "391",
        "title": "The Curious Case of Factual (Mis)Alignment between LLMs' Short- and Long-Form Answers",
        "author": [
            "Saad Obaid ul Islam",
            "Anne Lauscher",
            "Goran GlavaÅ¡"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11218",
        "abstract": "Large language models (LLMs) can correctly answer \"When was Einstein born?\" yet fail to provide the same date when writing about Einstein's life revealing a fundamental inconsistency in how models access factual knowledge across task complexities. While models display impressive accuracy on factual question-answering benchmarks, the reliability gap between simple and complex queries remains poorly understood, eroding their trustworthiness. In this work, we introduce Short-Long Form Alignment for Factual Question Answering (SLAQ), a controlled evaluation framework that compares LLMs' answers to the same factual questions asked (a) in isolation (short) vs. (b) integrated into complex queries (long). Looking at 16 LLMs across 600 queries, we find a systematic misalignment of answers to the corresponding short and long queries. We further uncover position-dependent accuracy loss and momentum effects where consecutive correct or incorrect answers create self-reinforcing patterns. Through mechanistic analysis, we find that aligned facts activate overlapping model internals, and that metrics based on mechanistic similarity can predict short-long answer alignment with up to 78% accuracy. Our work establishes factual consistency over query complexity as an important aspect of LLMs' trustworthiness and challenges current evaluation practices, which implicitly assume that good performance for simple factual queries implies reliability in more complex knowledge-seeking tasks too.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "392",
        "title": "WebRouter: Query-specific Router via Variational Information Bottleneck for Cost-sensitive Web Agent",
        "author": [
            "Tao Li",
            "Jinlong Hu",
            "Yang Wang",
            "Junfeng Liu",
            "Xuejun Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11221",
        "abstract": "LLM-brained web agents offer powerful capabilities for web automation but face a critical cost-performance trade-off. The challenge is amplified by web agents' inherently complex prompts that include goals, action histories, and environmental states, leading to degraded LLM ensemble performance. To address this, we introduce WebRouter, a novel query-specific router trained from an information-theoretic perspective. Our core contribution is a cost-aware Variational Information Bottleneck (ca-VIB) objective, which learns a compressed representation of the input prompt while explicitly penalizing the expected operational cost. Experiments on five real-world websites from the WebVoyager benchmark show that WebRouter reduces operational costs by a striking 87.8\\% compared to a GPT-4o baseline, while incurring only a 3.8\\% accuracy drop.",
        "tags": [
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "393",
        "title": "Fairness Metric Design Exploration in Multi-Domain Moral Sentiment Classification using Transformer-Based Models",
        "author": [
            "Battemuulen Naranbat",
            "Seyed Sahand Mohammadi Ziabari",
            "Yousuf Nasser Al Husaini",
            "Ali Mohammed Mansoor Alsahag"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11222",
        "abstract": "Ensuring fairness in natural language processing for moral sentiment classification is challenging, particularly under cross-domain shifts where transformer models are increasingly deployed. Using the Moral Foundations Twitter Corpus (MFTC) and Moral Foundations Reddit Corpus (MFRC), this work evaluates BERT and DistilBERT in a multi-label setting with in-domain and cross-domain protocols. Aggregate performance can mask disparities: we observe pronounced asymmetry in transfer, with Twitter->Reddit degrading micro-F1 by 14.9% versus only 1.5% for Reddit->Twitter. Per-label analysis reveals fairness violations hidden by overall scores; notably, the authority label exhibits Demographic Parity Differences of 0.22-0.23 and Equalized Odds Differences of 0.40-0.41. To address this gap, we introduce the Moral Fairness Consistency (MFC) metric, which quantifies the cross-domain stability of moral foundation detection. MFC shows strong empirical validity, achieving a perfect negative correlation with Demographic Parity Difference (rho = -1.000, p < 0.001) while remaining independent of standard performance metrics. Across labels, loyalty demonstrates the highest consistency (MFC = 0.96) and authority the lowest (MFC = 0.78). These findings establish MFC as a complementary, diagnosis-oriented metric for fairness-aware evaluation of moral reasoning models, enabling more reliable deployment across heterogeneous linguistic contexts. .",
        "tags": [
            "BERT",
            "Detection",
            "Transformer"
        ]
    },
    {
        "id": "394",
        "title": "A Theorem-Proving-Based Evaluation of Neural Semantic Parsing",
        "author": [
            "Hayate Funakura",
            "Hyunsoo Kim",
            "Koji Mineshima"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11225",
        "abstract": "Graph-matching metrics such as Smatch are the de facto standard for evaluating neural semantic parsers, yet they capture surface overlap rather than logical equivalence. We reassess evaluation by pairing graph-matching with automated theorem proving. We compare two approaches to building parsers: supervised fine-tuning (T5-Small/Base) and few-shot in-context learning (GPT-4o/4.1/5), under normalized and unnormalized targets. We evaluate outputs using graph-matching, bidirectional entailment between source and target formulas with a first-order logic theorem prover, and well-formedness. Across settings, we find that models performing well on graph-matching often fail to produce logically equivalent formulas. Normalization reduces incidental target variability, improves well-formedness, and strengthens logical adequacy. Error analysis shows performance degrades with increasing formula complexity and with coordination, prepositional phrases, and passive voice; the dominant failures involve variable binding and indexing, and predicate naming. These findings highlight limits of graph-based metrics for reasoning-oriented applications and motivate logic-sensitive evaluation and training objectives together with simplified, normalized target representations. All code and data for our experiments are publicly available.",
        "tags": [
            "GPT"
        ]
    },
    {
        "id": "395",
        "title": "XQuant: Achieving Ultra-Low Bit KV Cache Quantization with Cross-Layer Compression",
        "author": [
            "Haoqi Yang",
            "Yao Yao",
            "Zuchao Li",
            "Baoyuan Qi",
            "Guoming Liu",
            "Hai Zhao"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11236",
        "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities across diverse natural language processing tasks. However, their extensive memory requirements, particularly due to KV cache growth during long-text understanding and generation, present significant challenges for deployment in resource-constrained environments. Quantization has emerged as a promising solution to reduce memory consumption while preserving historical information. We propose XQuant, a training-free and plug-and-play framework that achieves ultra-low equivalent bit-width KV cache quantization. XQuant introduces two key innovations: a computationally negligible data-free calibration method and cross-layer KV cache compression, enabling quantization to sub-1.4 bits. Extensive experiments on TruthfulQA and LongBench demonstrate that XQuant outperforms state-of-the-art methods (e.g., KIVI-2bit and AsymKV-1.5bit) by achieving lower bit-width while maintaining superior performance, establishing a better trade-off between memory efficiency and model accuracy.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "396",
        "title": "Learning the Structure of Connection Graphs",
        "author": [
            "Leonardo Di Nino",
            "Gabriele D'Acunto",
            "Sergio Barbarossa",
            "Paolo Di Lorenzo"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11245",
        "abstract": "Connection graphs (CGs) extend traditional graph models by coupling network topology with orthogonal transformations, enabling the representation of global geometric consistency. They play a key role in applications such as synchronization, Riemannian signal processing, and neural sheaf diffusion. In this work, we address the inverse problem of learning CGs directly from observed signals. We propose a principled framework based on maximum pseudo-likelihood under a consistency assumption, which enforces spectral properties linking the connection Laplacian to the underlying combinatorial Laplacian. Based on this formulation, we introduce the Structured Connection Graph Learning (SCGL) algorithm, a block-optimization procedure over Riemannian manifolds that jointly infers network topology, edge weights, and geometric structure. Our experiments show that SCGL consistently outperforms existing baselines in both topological recovery and geometric fidelity, while remaining computationally efficient.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "397",
        "title": "Do Psychometric Tests Work for Large Language Models? Evaluation of Tests on Sexism, Racism, and Morality",
        "author": [
            "Jana Jung",
            "Marlene Lutz",
            "Indira Sen",
            "Markus Strohmaier"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11254",
        "abstract": "Psychometric tests are increasingly used to assess psychological constructs in large language models (LLMs). However, it remains unclear whether these tests -- originally developed for humans -- yield meaningful results when applied to LLMs. In this study, we systematically evaluate the reliability and validity of human psychometric tests for three constructs: sexism, racism, and morality. We find moderate reliability across multiple item and prompt variations. Validity is evaluated through both convergent (i.e., testing theory-based inter-test correlations) and ecological approaches (i.e., testing the alignment between tests scores and behavior in real-world downstream tasks). Crucially, we find that psychometric test scores do not align, and in some cases even negatively correlate with, model behavior in downstream tasks, indicating low ecological validity. Our results highlight that systematic evaluations of psychometric tests is essential before interpreting their scores. They also suggest that psychometric tests designed for humans cannot be applied directly to LLMs without adaptation.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "398",
        "title": "DemoHLM: From One Demonstration to Generalizable Humanoid Loco-Manipulation",
        "author": [
            "Yuhui Fu",
            "Feiyang Xie",
            "Chaoyi Xu",
            "Jing Xiong",
            "Haoqi Yuan",
            "Zongqing Lu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11258",
        "abstract": "Loco-manipulation is a fundamental challenge for humanoid robots to achieve versatile interactions in human environments. Although recent studies have made significant progress in humanoid whole-body control, loco-manipulation remains underexplored and often relies on hard-coded task definitions or costly real-world data collection, which limits autonomy and generalization. We present DemoHLM, a framework for humanoid loco-manipulation that enables generalizable loco-manipulation on a real humanoid robot from a single demonstration in simulation. DemoHLM adopts a hierarchy that integrates a low-level universal whole-body controller with high-level manipulation policies for multiple tasks. The whole-body controller maps whole-body motion commands to joint torques and provides omnidirectional mobility for the humanoid robot. The manipulation policies, learned in simulation via our data generation and imitation learning pipeline, command the whole-body controller with closed-loop visual feedback to execute challenging loco-manipulation tasks. Experiments show a positive correlation between the amount of synthetic data and policy performance, underscoring the effectiveness of our data generation pipeline and the data efficiency of our approach. Real-world experiments on a Unitree G1 robot equipped with an RGB-D camera validate the sim-to-real transferability of DemoHLM, demonstrating robust performance under spatial variations across ten loco-manipulation tasks.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "399",
        "title": "A Large-Language-Model Assisted Automated Scale Bar Detection and Extraction Framework for Scanning Electron Microscopic Images",
        "author": [
            "Yuxuan Chen",
            "Ruotong Yang",
            "Zhengyang Zhang",
            "Mehreen Ahmed",
            "Yanming Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11260",
        "abstract": "Microscopic characterizations, such as Scanning Electron Microscopy (SEM), are widely used in scientific research for visualizing and analyzing microstructures. Determining the scale bars is an important first step of accurate SEM analysis; however, currently, it mainly relies on manual operations, which is both time-consuming and prone to errors. To address this issue, we propose a multi-modal and automated scale bar detection and extraction framework that provides concurrent object detection, text detection and text recognition with a Large Language Model (LLM) agent. The proposed framework operates in four phases; i) Automatic Dataset Generation (Auto-DG) model to synthesize a diverse dataset of SEM images ensuring robust training and high generalizability of the model, ii) scale bar object detection, iii) information extraction using a hybrid Optical Character Recognition (OCR) system with DenseNet and Convolutional Recurrent Neural Network (CRNN) based algorithms, iv) an LLM agent to analyze and verify accuracy of the results. The proposed model demonstrates a strong performance in object detection and accurate localization with a precision of 100%, recall of 95.8%, and a mean Average Precision (mAP) of 99.2% at IoU=0.5 and 69.1% at IoU=0.5:0.95. The hybrid OCR system achieved 89% precision, 65% recall, and a 75% F1 score on the Auto-DG dataset, significantly outperforming several mainstream standalone engines, highlighting its reliability for scientific image analysis. The LLM is introduced as a reasoning engine as well as an intelligent assistant that suggests follow-up steps and verifies the results. This automated method powered by an LLM agent significantly enhances the efficiency and accuracy of scale bar detection and extraction in SEM images, providing a valuable tool for microscopic analysis and advancing the field of scientific imaging.",
        "tags": [
            "Detection",
            "LLM",
            "RNN"
        ]
    },
    {
        "id": "400",
        "title": "Learning Hanzi Character Through VR-Based Mortise-Tenon",
        "author": [
            "Conglin Ma",
            "Jiatong Li",
            "Sen-Zhe Xu",
            "Ju Dai",
            "Jie Liu",
            "Feng Zhou"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11264",
        "abstract": "This paper introduces a novel VR-based system that redefines the acquisition of Hanzi character literacy by integrating traditional mortise-tenon joinery principles (HVRMT).Addressing the challenge of abstract character memorization in digital learning,our system deconstructs Hanzi components into interactive \"structural radicals\"akin to wooden joint http://modules.Leveraging PICO's 6DoF spatial tracking and LLM's morphological analysis,learners assemble stroke sequences with haptic feedback simulating wood-to-wood http://friction.Our system also supports multiplayer online experiences, enhancing engagement and memory retention while preserving intangible cultural heritage. This innovative approach not only enhances engagement and memory retention but also reconstructs the craft wisdom embedded in Chinese writing systems, offering new pathways for preserving intangible cultural heritage in digital http://ecosystems.For the demo,please refer to this link{https://youtu.be/oUwfFTRpFyo}.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "401",
        "title": "From Prompts to Packets: A View from the Network on ChatGPT, Copilot, and Gemini",
        "author": [
            "Antonio Montieri",
            "Alfredo Nascita",
            "Antonio PescapÃ¨"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11269",
        "abstract": "Generative AI (GenAI) chatbots are now pervasive in digital ecosystems, yet their network traffic remains largely underexplored. This study presents an in-depth investigation of traffic generated by three leading chatbots (ChatGPT, Copilot, and Gemini) when accessed via Android mobile apps for both text and image generation. Using a dedicated capture architecture, we collect and label two complementary workloads: a 60-hour generic dataset with unconstrained prompts, and a controlled dataset built from identical prompts across GenAI apps and replicated via conventional messaging apps to enable one-to-one comparisons. This dual design allows us to address practical research questions on the distinctiveness of GenAI traffic, its differences from widely deployed traffic categories, and its novel implications for network usage. To this end, we provide fine-grained traffic characterization at trace, flow, and protocol levels, and model packet-sequence dynamics with Multimodal Markov Chains. Our analyses reveal app- and content-specific traffic patterns, particularly in volume, uplink/downlink profiles, and protocol adoption. We highlight the predominance of TLS, with Gemini extensively leveraging QUIC, ChatGPT exclusively using TLS 1.3, and app- and content-specific Server Name Indication (SNI) values. A payload-based occlusion analysis quantifies SNI's contribution to classification: masking it reduces F1-score by up to 20 percentage points in GenAI app traffic classification. Finally, compared with conventional messaging apps when carrying the same content, GenAI chatbots exhibit unique traffic characteristics, highlighting new stress factors for mobile networks, such as sustained upstream activity, with direct implications for network monitoring and management. We publicly release the datasets to support reproducibility and foster extensions to other use cases.",
        "tags": [
            "GPT"
        ]
    },
    {
        "id": "402",
        "title": "FedLoRA-Optimizer: Federated LoRA Fine-Tuning with Global and Local Optimization in Heterogeneous Data Scenarios",
        "author": [
            "Jianzhe Zhao",
            "Hailin Zhu",
            "Yu Zhang",
            "Ziqi Chen",
            "Guibing Guo"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11274",
        "abstract": "Federated efficient fine-tuning has emerged as an approach that leverages distributed data and computational resources across nodes to address the challenges of large-scale fine-tuning and privacy preservation. The Low-Rank Adaptation (LoRA) enables efficient fine-tuning of large-scale pre-trained models by introducing trainable low-rank matrices into weight http://updates.However, in heterogeneous data scenarios, client drift weakens the generalization of the global model, and local models often fail to meet the personalized needs of individual http://clients.Moreover, existing federated LoRA efficient fine-tuning techniques overlook fine-grained analysis of the tuning matrices. To address this, we conducted preliminary experiments and found that different LoRA matrices exhibit different sensitivity to changes in the direction and magnitude of their http://vectors.We thus propose a fine-grained federated LoRA tuning method. By fine-tuning the more sensitive directional vectors in the A matrix, which encode shared knowledge, our method learns shared features more effectively across clients and enhances global generalization. Simultaneously, by fine-tuning the more sensitive magnitude vectors in the B matrix, which encode personalized knowledge, our method better captures personalized knowledge, enabling detailed adaptation to local data. The method uses a pipeline combining global and local optimizers. Global optimization further improves local models, achieving collaborative optimization between global and local levels. This improves both the generalization ability of the global model and the personalized adaptation of local models under heterogeneous data scenarios. Experiments on Databricks-Dolly-15k and Natural Instructions with LLaMA2-7B and Deepseek-7B confirm that our method improves global performance by 0.39% and local performance by 0.59%.",
        "tags": [
            "DeepSeek",
            "LoRA"
        ]
    },
    {
        "id": "403",
        "title": "Towards Real-Time Fake News Detection under Evidence Scarcity",
        "author": [
            "Guangyu Wei",
            "Ke Han",
            "Yueming Lyu",
            "Yu Luo",
            "Yue Jiang",
            "Caifeng Shan",
            "Nicu Sebe"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11277",
        "abstract": "Fake news detection becomes particularly challenging in real-time scenarios, where emerging events often lack sufficient supporting evidence. Existing approaches often rely heavily on external evidence and therefore struggle to generalize under evidence scarcity. To address this issue, we propose Evaluation-Aware Selection of Experts (EASE), a novel framework for real-time fake news detection that dynamically adapts its decision-making process according to the assessed sufficiency of available evidence. EASE introduces a sequential evaluation mechanism comprising three independent perspectives: (1) Evidence-based evaluation, which assesses evidence and incorporates it into decision-making only when the evidence is sufficiently supportive; (2) Reasoning-based evaluation, which leverages the world knowledge of large language models (LLMs) and applies them only when their reliability is adequately established; and (3) Sentiment-based fallback, which integrates sentiment cues when neither evidence nor reasoning is reliable. To enhance the accuracy of evaluation processes, EASE employs instruction tuning with pseudo labels to guide each evaluator in justifying its perspective-specific knowledge through interpretable reasoning. Furthermore, the expert modules integrate the evaluators' justified assessments with the news content to enable evaluation-aware decision-making, thereby enhancing overall detection accuracy. Moreover, we introduce RealTimeNews-25, a new benchmark comprising recent news for evaluating model generalization on emerging news with limited evidence. Extensive experiments demonstrate that EASE not only achieves state-of-the-art performance across multiple benchmarks, but also significantly improves generalization to real-time news. The code and dataset are available: https://github.com/wgyhhhh/EASE.",
        "tags": [
            "Detection",
            "LLM"
        ]
    },
    {
        "id": "404",
        "title": "ENIGMA: The Geometry of Reasoning and Alignment in Large-Language Models",
        "author": [
            "Gareth Seneque",
            "Lap-Hang Ho",
            "Nafise Erfanian Saeedi",
            "Jeffrey Molendijk",
            "Ariel Kupermann",
            "Tim Elson"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11278",
        "abstract": "We present Entropic Mutual-Information Geometry Large-Language Model Alignment (ENIGMA), a novel approach to Large-Language Model (LLM) training that jointly improves reasoning, alignment and robustness by treating an organisation's policies/principles as directions to move on a model's information manifold. Our single-loop trainer combines Group-Relative Policy Optimisation (GRPO), an on-policy, critic-free RL method with Chain-of-Thought (CoT)-format only rewards; a Self-Supervised Alignment with Mutual Information (SAMI)-style symmetric InfoNCE auxiliary; and an entropic Sinkhorn optimal-transport regulariser on hidden-state distributions to bound geometry drift. We also introduce infoNCE metrics that specialise to a standard MI lower bound under matched negatives to measure how strongly a model's CoT encodes these policies. These metrics include a Sufficiency Index (SI) that enables the selection and creation of principles that maximise downstream performance prior to training. In our experiments using small (1B) LLMs, high-SI principles predict steadier training dynamics and improved benchmark performance over GRPO ablations. Our information-geometry analysis of trained models validates desirable structural change in the manifold. These results support our hypothesis that reasoning, alignment, and robustness are projections of a single informationgeometric objective, and that models trained using ENIGMA demonstrate principled reasoning without the use of a reward model, offering a path to trusted capability",
        "tags": [
            "CoT",
            "GRPO",
            "LLM",
            "RL"
        ]
    },
    {
        "id": "405",
        "title": "PADME: Procedure Aware DynaMic Execution",
        "author": [
            "Deepeka Garg",
            "Sihan Zeng",
            "Annapoorani L. Narayanan",
            "Sumitra Ganesh",
            "Leo Ardon"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11281",
        "abstract": "Learning to autonomously execute long-horizon procedures from natural language remains a core challenge for intelligent agents. Free-form instructions such as recipes, scientific protocols, or business workflows encode rich procedural knowledge, but their variability and lack of structure cause agents driven by large language models (LLMs) to drift or fail during execution. We introduce Procedure Aware DynaMic Execution (PADME), an agent framework that produces and exploits a graph-based representation of procedures. Unlike prior work that relies on manual graph construction or unstructured reasoning, PADME autonomously transforms procedural text into executable graphs that capture task dependencies, decision points, and reusable subroutines. Central to PADME is a two-phase methodology; Teach phase, which focuses on systematic structuring, enrichment with executable logic of procedures, followed by Execute phase, which enables dynamic execution in response to real-time inputs and environment feedback. This separation ensures quality assurance and scalability, allowing expert knowledge to be encoded once and reliably reused across varying contexts. The graph representation also provides an inductive bias that reduces error accumulation in long-horizon reasoning, underscoring the importance of structured procedure modeling for reliable agent-driven automation. Empirically, PADME achieves state-of-the-art performance on four diverse benchmarks, including ALFWorld and ScienceWorld. These results demonstrate that agents equipped with graph-based procedure representations offer a powerful intermediate abstraction for robust and generalizable execution.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "406",
        "title": "Gym-TORAX: Open-source software for integrating RL with plasma control simulators",
        "author": [
            "Antoine Mouchamps",
            "Arthur Malherbe",
            "Adrien Bolland",
            "Damien Ernst"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11283",
        "abstract": "This paper presents Gym-TORAX, a Python package enabling the implementation of Reinforcement Learning (RL) environments for simulating plasma dynamics and control in tokamaks. Users define succinctly a set of control actions and observations, and a control objective from which Gym-TORAX creates a Gymnasium environment that wraps TORAX for simulating the plasma dynamics. The objective is formulated through rewards depending on the simulated state of the plasma and control action to optimize specific characteristics of the plasma, such as performance and stability. The resulting environment instance is then compatible with a wide range of RL algorithms and libraries and will facilitate RL research in plasma control. In its current version, one environment is readily available, based on a ramp-up scenario of the International Thermonuclear Experimental Reactor (ITER).",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "407",
        "title": "Emergent Misalignment via In-Context Learning: Narrow in-context examples can produce broadly misaligned LLMs",
        "author": [
            "Nikita Afonin",
            "Nikita Andriyanov",
            "Nikhil Bageshpura",
            "Kyle Liu",
            "Kevin Zhu",
            "Sunishchal Dev",
            "Ashwinee Panda",
            "Alexander Panchenko",
            "Oleg Rogov",
            "Elena Tutubalina",
            "Mikhail Seleznyov"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11288",
        "abstract": "Recent work has shown that narrow finetuning can produce broadly misaligned LLMs, a phenomenon termed emergent misalignment (EM). While concerning, these findings were limited to finetuning and activation steering, leaving out in-context learning (ICL). We therefore ask: does EM emerge in ICL? We find that it does: across three datasets, three frontier models produce broadly misaligned responses at rates between 2% and 17% given 64 narrow in-context examples, and up to 58% with 256 examples. We also examine mechanisms of EM by eliciting step-by-step reasoning (while leaving in-context examples unchanged). Manual analysis of the resulting chain-of-thought shows that 67.5% of misaligned traces explicitly rationalize harmful outputs by adopting a reckless or dangerous ''persona'', echoing prior results on finetuning-induced EM.",
        "tags": [
            "CoT",
            "LLM"
        ]
    },
    {
        "id": "408",
        "title": "Evolution in Simulation: AI-Agent School with Dual Memory for High-Fidelity Educational Dynamics",
        "author": [
            "Sheng Jin",
            "Haoming Wang",
            "Zhiqi Gao",
            "Yongbo Yang",
            "Bao Chunjia",
            "Chengliang Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11290",
        "abstract": "Large language models (LLMs) based Agents are increasingly pivotal in simulating and understanding complex human systems and interactions. We propose the AI-Agent School (AAS) system, built around a self-evolving mechanism that leverages agents for simulating complex educational dynamics. Addressing the fragmented issues in teaching process modeling and the limitations of agents performance in simulating diverse educational participants, AAS constructs the Zero-Exp strategy, employs a continuous \"experience-reflection-optimization\" cycle, grounded in a dual memory base comprising experience and knowledge bases and incorporating short-term and long-term memory components. Through this mechanism, agents autonomously evolve via situated interactions within diverse simulated school scenarios. This evolution enables agents to more accurately model the nuanced, multi-faceted teacher-student engagements and underlying learning processes found in physical schools. Experiment confirms that AAS can effectively simulate intricate educational dynamics and is effective in fostering advanced agent cognitive abilities, providing a foundational stepping stone from the \"Era of Experience\" to the \"Era of Simulation\" by generating high-fidelity behavioral and interaction data.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "409",
        "title": "Human Uncertainty-Aware Data Selection and Automatic Labeling in Visual Question Answering",
        "author": [
            "Jian Lan",
            "Zhicheng Liu",
            "Udo Schlegel",
            "Raoyuan Zhao",
            "Yihong Liu",
            "Hinrich SchÃ¼tze",
            "Michael A. Hedderich",
            "Thomas Seidl"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11295",
        "abstract": "Large vision-language models (VLMs) achieve strong performance in Visual Question Answering but still rely heavily on supervised fine-tuning (SFT) with massive labeled datasets, which is costly due to human annotations. Crucially, real-world datasets often exhibit human uncertainty (HU) -- variation in human confidence across annotations -- but standard SFT simply optimizes toward the most frequent label, disregarding HU distributions. This leaves two open questions: How does HU affect SFT, and how can HU be effectively leveraged in training? In this work, we first conduct a systematic evaluation of VLMs across varying HU levels. We have two key findings: (i) surprisingly, high-HU samples contribute little or even degrade model performance, and (ii) naively training on the full dataset yields under-calibrated models that fail to capture HU distributions. Motivated by these findings, we introduce HaDola, a human uncertainty-aware data selection and automatic labeling framework. HaDola operates in four stages -- discriminate, self-annotate, error trigger, and training -- to iteratively identify harmful samples, prioritize informative ones, and bootstrap from a small seed set (5\\% of data). Our approach substantially reduces reliance on costly HU annotations and makes VLMs more accurate and better calibrated. Extensive experiments on VQAv2 and VizWiz datasets demonstrate that HaDola consistently matches or outperforms state-of-the-art baselines with less training data. Our work highlights the importance of explicitly modeling HU in SFT, suggesting that better utilization of HU is more effective than merely scaling up dataset size.",
        "tags": [
            "VLM"
        ]
    },
    {
        "id": "410",
        "title": "$Î\\mathrm{Energy}$: Optimizing Energy Change During Vision-Language Alignment Improves both OOD Detection and OOD Generalization",
        "author": [
            "Lin Zhu",
            "Yifeng Yang",
            "Xinbing Wang",
            "Qinying Gu",
            "Nanyang Ye"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11296",
        "abstract": "Recent approaches for vision-language models (VLMs) have shown remarkable success in achieving fast downstream adaptation. When applied to real-world downstream tasks, VLMs inevitably encounter both the in-distribution (ID) data and out-of-distribution (OOD) data. The OOD datasets often include both covariate shifts (e.g., known classes with changes in image styles) and semantic shifts (e.g., test-time unseen classes). This highlights the importance of improving VLMs' generalization ability to covariate-shifted OOD data, while effectively detecting open-set semantic-shifted OOD classes. In this paper, inspired by the substantial energy change observed in closed-set data when re-aligning vision-language modalities (specifically by directly reducing the maximum cosine similarity to a low value), we introduce a novel OOD score, named {\\Delta}Energy. {\\Delta}Energy significantly outperforms the vanilla energy-based OOD score and provides a more reliable approach for OOD detection. Furthermore, {\\Delta}Energy can simultaneously improve OOD generalization under covariate shifts, which is achieved by lower-bound maximization for {\\Delta}Energy (termed EBM). EBM is theoretically proven to not only enhance OOD detection but also yields a domain-consistent Hessian, which serves as a strong indicator for OOD generalization. Based on this finding, we developed a unified fine-tuning framework that allows for improving VLMs' robustness in both OOD generalization and OOD detection. Extensive experiments on challenging OOD detection and generalization benchmarks demonstrate the superiority of our method, outperforming recent approaches by 10% to 25% in AUROC.",
        "tags": [
            "Detection",
            "VLM"
        ]
    },
    {
        "id": "411",
        "title": "Are Large Language Models Effective Knowledge Graph Constructors?",
        "author": [
            "Ruirui Chen",
            "Weifeng Jiang",
            "Chengwei Qin",
            "Bo Xiong",
            "Fiona Liausvia",
            "Dongkyu Choi",
            "Boon Kiat Quek"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11297",
        "abstract": "Knowledge graphs (KGs) are vital for knowledge-intensive tasks and have shown promise in reducing hallucinations in large language models (LLMs). However, constructing high-quality KGs remains difficult, requiring accurate information extraction and structured representations that support interpretability and downstream utility. Existing LLM-based approaches often focus narrowly on entity and relation extraction, limiting coverage to sentence-level contexts or relying on predefined schemas. We propose a hierarchical extraction framework that organizes information at multiple levels, enabling the creation of semantically rich and well-structured KGs. Using state-of-the-art LLMs, we extract and construct knowledge graphs and evaluate them comprehensively from both structural and semantic perspectives. Our results highlight the strengths and shortcomings of current LLMs in KG construction and identify key challenges for future work. To advance research in this area, we also release a curated dataset of LLM-generated KGs derived from research papers on children's mental well-being. This resource aims to foster more transparent, reliable, and impactful applications in high-stakes domains such as healthcare.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "412",
        "title": "Beyond touch-based HMI: Control your machines in natural language by utilizing large language models and OPC UA",
        "author": [
            "Bernd Hofmann",
            "Sven Kreitlein",
            "Joerg Franke",
            "Patrick Bruendl"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11300",
        "abstract": "This paper proposes an agent-based approach toward a more natural interface between humans and machines. Large language models equipped with tools and the communication standard OPC UA are utilized to control machines in natural language. Instead of touch interaction, which is currently the state-of-the-art medium for interaction in operations, the proposed approach enables operators to talk or text with machines. This allows commands such as 'Please decrease the temperature by 20 % in machine 1 and set the motor speed to 5000 rpm in machine 2.' The large language model receives the user input and selects one of three predefined tools that connect to an OPC UA server and either change or read the value of a node. Afterwards, the result of the tool execution is passed back to the language model, which then provides a final response to the user. The approach is universally designed and can therefore be applied to any machine that supports the OPC UA standard. The large language model is neither fine-tuned nor requires training data, only the relevant machine credentials and a parameter dictionary are included within the system prompt. The approach is evaluated on a Siemens S7-1500 programmable logic controller with four machine parameters in a case study of fifty synthetically generated commands on five different models. The results demonstrate high success rate, with proprietary GPT 5 models achieving accuracies between 96.0 % and 98.0 %, and open-weight models reaching up to 90.0 %. The proposed approach of this empirical study contributes to advancing natural interaction in industrial human-machine interfaces.",
        "tags": [
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "413",
        "title": "When Does Supervised Training Pay Off? The Hidden Economics of Object Detection in the Era of Vision-Language Models",
        "author": [
            "Samer Al-Hamadani"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11302",
        "abstract": "Object detection systems have traditionally relied on supervised learning with manually annotated bounding boxes, achieving high accuracy at the cost of substantial annotation investment. The emergence of Vision-Language Models (VLMs) offers an alternative paradigm enabling zero-shot detection through natural language queries, eliminating annotation requirements but operating with reduced accuracy. This paper presents the first comprehensive cost-effectiveness analysis comparing supervised detection (YOLO) with zero-shot VLM inference (Gemini Flash 2.5). Through systematic evaluation on 1,000 stratified COCO images and 200 diverse product images spanning consumer electronics and rare categories, combined with detailed Total Cost of Ownership modeling, we establish quantitative break-even thresholds governing architecture selection. Our findings reveal that supervised YOLO achieves 91.2% accuracy versus 68.5% for zero-shot Gemini on standard categories, representing a 22.7 percentage point advantage that costs $10,800 in annotation for 100-category systems. However, this advantage justifies investment only beyond 55 million inferences, equivalent to 151,000 images daily for one year. Zero-shot Gemini demonstrates 52.3% accuracy on diverse product categories (ranging from highly web-prevalent consumer electronics at 75-85% to rare specialized equipment at 25-40%) where supervised YOLO achieves 0% due to architectural constraints preventing detection of untrained classes. Cost per Correct Detection analysis reveals substantially lower per-detection costs for Gemini ($0.00050 vs $0.143) at 100,000 inferences despite accuracy deficits. We develop decision frameworks demonstrating that optimal architecture selection depends critically on deployment volume, category stability, budget constraints, and accuracy requirements rather than purely technical performance metrics.",
        "tags": [
            "Detection",
            "VLM"
        ]
    },
    {
        "id": "414",
        "title": "FOSSIL: Harnessing Feedback on Suboptimal Samples for Data-Efficient Generalisation with Imitation Learning for Embodied Vision-and-Language Tasks",
        "author": [
            "Sabrina McCallum",
            "Amit Parekh",
            "Alessandro Suglia"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11307",
        "abstract": "Current approaches to embodied AI tend to learn policies from expert demonstrations. However, without a mechanism to evaluate the quality of demonstrated actions, they are limited to learning from optimal behaviour, or they risk replicating errors and inefficiencies. While reinforcement learning offers one alternative, the associated exploration typically results in sacrificing data efficiency. This work explores how agents trained with imitation learning can learn robust representations from both optimal and suboptimal demonstrations when given access to constructive language feedback as a means to contextualise different modes of behaviour. We directly provide language feedback embeddings as part of the input sequence into a Transformer-based policy, and optionally complement the traditional next action prediction objective with auxiliary self-supervised learning objectives for feedback prediction. We test our approach on a range of embodied Vision-and-Language tasks in our custom BabyAI-XGen environment and show significant improvements in agents' compositional generalisation abilities and robustness, suggesting that our data-efficient method allows models to successfully convert suboptimal behaviour into learning opportunities. Overall, our results suggest that language feedback is a competitive and intuitive alternative to intermediate scalar rewards for language-specified embodied tasks.",
        "tags": [
            "RL",
            "Transformer"
        ]
    },
    {
        "id": "415",
        "title": "Adap-RPF: Adaptive Trajectory Sampling for Robot Person Following in Dynamic Crowded Environments",
        "author": [
            "Weixi Situ",
            "Hanjing Ye",
            "Jianwei Peng",
            "Yu Zhan",
            "Hong Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11308",
        "abstract": "Robot person following (RPF) is a core capability in human-robot interaction, enabling robots to assist users in daily activities, collaborative work, and other service scenarios. However, achieving practical RPF remains challenging due to frequent occlusions, particularly in dynamic and crowded environments. Existing approaches often rely on fixed-point following or sparse candidate-point selection with oversimplified heuristics, which cannot adequately handle complex occlusions caused by moving obstacles such as pedestrians. To address these limitations, we propose an adaptive trajectory sampling method that generates dense candidate points within socially aware zones and evaluates them using a multi-objective cost function. Based on the optimal point, a person-following trajectory is estimated relative to the predicted motion of the target. We further design a prediction-aware model predictive path integral (MPPI) controller that simultaneously tracks this trajectory and proactively avoids collisions using predicted pedestrian motions. Extensive experiments show that our method outperforms state-of-the-art baselines in smoothness, safety, robustness, and human comfort, with its effectiveness further demonstrated on a mobile robot in real-world scenarios.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "416",
        "title": "Automated Skill Decomposition Meets Expert Ontologies: Bridging the Granularity Gap with LLMs",
        "author": [
            "Le Ngoc Luyen",
            "Marie-HÃ©lÃ¨ne Abel"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11313",
        "abstract": "This paper investigates automated skill decomposition using Large Language Models (LLMs) and proposes a rigorous, ontology-grounded evaluation framework. Our framework standardizes the pipeline from prompting and generation to normalization and alignment with ontology nodes. To evaluate outputs, we introduce two metrics: a semantic F1-score that uses optimal embedding-based matching to assess content accuracy, and a hierarchy-aware F1-score that credits structurally correct placements to assess granularity. We conduct experiments on ROME-ESCO-DecompSkill, a curated subset of parents, comparing two prompting strategies: zero-shot and leakage-safe few-shot with exemplars. Across diverse LLMs, zero-shot offers a strong baseline, while few-shot consistently stabilizes phrasing and granularity and improves hierarchy-aware alignment. A latency analysis further shows that exemplar-guided prompts are competitive - and sometimes faster - than unguided zero-shot due to more schema-compliant completions. Together, the framework, benchmark, and metrics provide a reproducible foundation for developing ontology-faithful skill decomposition systems.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "417",
        "title": "Template-Based Text-to-Image Alignment for Language Accessibility: A Study on Visualizing Text Simplifications",
        "author": [
            "Belkiss Souayed",
            "Sarah Ebling",
            "Yingqiang Gao"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11314",
        "abstract": "Individuals with intellectual disabilities often have difficulties in comprehending complex texts. While many text-to-image models prioritize aesthetics over accessibility, it is not clear how visual illustrations relate to text simplifications (TS) generated from them. This paper presents a structured vision-language model (VLM) prompting framework for generating accessible images from simplified texts. We designed five prompt templates, i.e., Basic Object Focus, Contextual Scene, Educational Layout, Multi-Level Detail, and Grid Layout, each following distinct spatial arrangements while adhering to accessibility constraints such as object count limits, spatial separation, and content restrictions. Using 400 sentence-level simplifications from four established TS datasets (OneStopEnglish, SimPA, Wikipedia, and ASSET), we conducted a two-phase evaluation: Phase 1 assessed prompt template effectiveness with CLIPScores, and Phase 2 involved human annotation of generated images across ten visual styles by four accessibility experts. Results show that the Basic Object Focus prompt template achieved the highest semantic alignment, indicating that visual minimalism enhances language accessibility. Expert evaluation further identified Retro style as the most accessible and Wikipedia as the most effective data source. Inter-annotator agreement varied across dimensions, with Text Simplicity showing strong reliability and Image Quality proving more subjective. Overall, our framework offers practical guidelines for accessible content generation and underscores the importance of structured prompting in AI-generated visual accessibility tools.",
        "tags": [
            "Text-to-Image",
            "VLM"
        ]
    },
    {
        "id": "418",
        "title": "Next Interest Flow: A Generative Pre-training Paradigm for Recommender Systems by Modeling All-domain Movelines",
        "author": [
            "Chen Gao",
            "Zixin Zhao",
            "Lv Shao",
            "Tong Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11317",
        "abstract": "Click-Through Rate (CTR) prediction, a cornerstone of modern recommender systems, has been dominated by discriminative models that react to past user behavior rather than proactively modeling user intent. Existing generative paradigms attempt to address this but suffer from critical limitations: Large Language Model (LLM) based methods create a semantic mismatch by forcing e-commerce signals into a linguistic space, while ID-based generation is constrained by item memorization and cold-start issues. To overcome these limitations, we propose a novel generative pre-training paradigm. Our model learns to predict the Next Interest Flow, a dense vector sequence representing a user's future intent, while simultaneously modeling its internal Interest Diversity and Interest Evolution Velocity to ensure the representation is both rich and coherent. However, this two-stage approach introduces a critical objective mismatch between the generative and discriminative stages. We resolve this via a bidirectional alignment strategy, which harmonizes the two stages through cross-stage weight initialization and a dynamic Semantic Alignment Module for fine-tuning. Additionally, we enhance the underlying discriminative model with a Temporal Sequential Pairwise (TSP) mechanism to better capture temporal causality. We present the All-domain Moveline Evolution Network (AMEN), a unified framework implementing our entire pipeline. Extensive offline experiments validate AMEN's superiority over strong baselines, and a large-scale online A/B test demonstrates its significant real-world impact, delivering substantial improvements in key business metrics.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "419",
        "title": "Do LLMs \"Feel\"? Emotion Circuits Discovery and Control",
        "author": [
            "Chenxi Wang",
            "Yixuan Zhang",
            "Ruiji Yu",
            "Yufei Zheng",
            "Lang Gao",
            "Zirui Song",
            "Zixiang Xu",
            "Gus Xia",
            "Huishuai Zhang",
            "Dongyan Zhao",
            "Xiuying Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11328",
        "abstract": "As the demand for emotional intelligence in large language models (LLMs) grows, a key challenge lies in understanding the internal mechanisms that give rise to emotional expression and in controlling emotions in generated text. This study addresses three core questions: (1) Do LLMs contain context-agnostic mechanisms shaping emotional expression? (2) What form do these mechanisms take? (3) Can they be harnessed for universal emotion control? We first construct a controlled dataset, SEV (Scenario-Event with Valence), to elicit comparable internal states across emotions. Subsequently, we extract context-agnostic emotion directions that reveal consistent, cross-context encoding of emotion (Q1). We identify neurons and attention heads that locally implement emotional computation through analytical decomposition and causal analysis, and validate their causal roles via ablation and enhancement interventions. Next, we quantify each sublayer's causal influence on the model's final emotion representation and integrate the identified local components into coherent global emotion circuits that drive emotional expression (Q2). Directly modulating these circuits achieves 99.65% emotion-expression accuracy on the test set, surpassing prompting- and steering-based methods (Q3). To our knowledge, this is the first systematic study to uncover and validate emotion circuits in LLMs, offering new insights into interpretability and controllable emotional intelligence.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "420",
        "title": "Diffusion-Link: Diffusion Probabilistic Model for Bridging the Audio-Text Modality Gap",
        "author": [
            "KiHyun Nam",
            "Jongmin Choi",
            "Hyeongkeun Lee",
            "Jungwoo Heo",
            "Joon Son Chung"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11330",
        "abstract": "Contrastive audio-language pretraining yields powerful joint representations, yet a persistent audio-text modality gap limits the benefits of coupling multimodal encoders with large language models (LLMs). We present Diffusion-Link, a diffusion-based modality-bridging module that generatively maps audio embeddings into the text-embedding distribution. The module is trained at the output embedding from the frozen multimodal encoder and implemented as a lightweight network with three residual MLP blocks. To assess the effect of Diffusion-Link on multimodal encoder-LLM coupling, we evaluate on Automatic Audio Captioning (AAC); to our knowledge, this is the first application of diffusion-based modality bridging to AAC. We report two results. (1) Modality-gap analysis: on similarity and geometric criteria, Diffusion-Link reduces the modality gap the most among prior diffusion-based methods and shows a collective migration of audio embeddings toward the text distribution. (2) Downstream AAC: attaching Diffusion-Link to the same multimodal LLM baseline achieves state-of-the-art on AudioCaps in both zero-shot and fully supervised captioning without external knowledge, with relative gains up to 52.5% and 7.5%, respectively. These findings show that closing the modality gap is pivotal for effective coupling between multimodal encoders and LLMs, and diffusion-based modality bridging offers a promising direction beyond knowledge-retrieval-centric designs. Code will be released upon acceptance https://github.com/DevKiHyun/Diffusion-Link",
        "tags": [
            "Diffusion",
            "LLM"
        ]
    },
    {
        "id": "421",
        "title": "Efficient LLM Inference over Heterogeneous Edge Networks with Speculative Decoding",
        "author": [
            "Bingjie Zhu",
            "Zhixiong Chen",
            "Liqiang Zhao",
            "Hyundong Shin",
            "Arumugam Nallanathan"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11331",
        "abstract": "Large language model (LLM) inference at the network edge is a promising serving paradigm that leverages distributed edge resources to run inference near users and enhance privacy. Existing edge-based LLM inference systems typically adopt autoregressive decoding (AD), which only generates one token per forward pass. This iterative process, compounded by the limited computational resources of edge nodes, results in high serving latency and constrains the system's ability to support multiple users under growing http://demands.To address these challenges, we propose a speculative decoding (SD)-based LLM serving framework that deploys small and large models across heterogeneous edge nodes to collaboratively deliver inference services. Specifically, the small model rapidly generates draft tokens that the large model verifies in parallel, enabling multi-token generation per forward pass and thus reducing serving latency. To improve resource utilization of edge nodes, we incorporate pipeline parallelism to overlap drafting and verification across multiple inference tasks. Based on this framework, we analyze and derive a comprehensive latency model incorporating both communication and inference latency. Then, we formulate a joint optimization problem for speculation length, task batching, and wireless communication resource allocation to minimize total serving latency. To address this problem, we derive the closed-form solutions for wireless communication resource allocation, and develop a dynamic programming algorithm for joint batching and speculation control strategies. Experimental results demonstrate that the proposed framework achieves lower serving latency compared to AD-based serving systems. In addition,the proposed joint optimization method delivers up to 44.9% latency reduction compared to benchmark schemes.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "422",
        "title": "InternSVG: Towards Unified SVG Tasks with Multimodal Large Language Models",
        "author": [
            "Haomin Wang",
            "Jinhui Yin",
            "Qi Wei",
            "Wenguang Zeng",
            "Lixin Gu",
            "Shenglong Ye",
            "Zhangwei Gao",
            "Yaohui Wang",
            "Yanting Zhang",
            "Yuanqi Li",
            "Yanwen Guo",
            "Wenhai Wang",
            "Kai Chen",
            "Yu Qiao",
            "Hongjie Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11341",
        "abstract": "General SVG modeling remains challenging due to fragmented datasets, limited transferability of methods across tasks, and the difficulty of handling structural complexity. In response, we leverage the strong transfer and generalization capabilities of multimodal large language models (MLLMs) to achieve unified modeling for SVG understanding, editing, and generation. We present the InternSVG family, an integrated data-benchmark-model suite. At its core is SAgoge, the largest and most comprehensive multimodal dataset for SVG tasks, encompassing both static graphics and dynamic animations. It covers icons, long-sequence illustrations, scientific diagrams, and dynamic animations, supporting tasks of varied difficulty levels and providing deeper hierarchies with richer attributes compared to previous datasets. Based on this resource, we introduce SArena, a companion benchmark with comprehensive task definitions and standardized evaluation that aligns with the domains and difficulty spectrum covered by SAgoge. Building on these foundations, we propose InternSVG, a unified MLLM for SVG understanding, editing, and generation with SVG-specific special tokens, subword-based embedding initialization, and a two-stage training strategy that progresses from short static SVGs to long-sequence illustrations and complex animations. This unified formulation induces positive transfer and improves overall performance. Experiments on SArena and prior benchmark confirm that InternSVG achieves substantial gains and consistently outperforms leading open and proprietary counterparts.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "423",
        "title": "Part II: ROLL Flash -- Accelerating RLVR and Agentic Training with Asynchrony",
        "author": [
            "Han Lu",
            "Zichen Liu",
            "Shaopan Xiong",
            "Yancheng He",
            "Wei Gao",
            "Yanan Wu",
            "Weixun Wang",
            "Jiashun Liu",
            "Yang Li",
            "Haizhou Zhao",
            "Ju Huang",
            "Siran Yang",
            "Xiaoyang Li",
            "Yijia Luo",
            "Zihe Liu",
            "Ling Pan",
            "Junchi Yan",
            "Wei Wang",
            "Wenbo Su",
            "Jiamang Wang",
            "Lin Qu",
            "Bo Zheng"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11345",
        "abstract": "Synchronous Reinforcement Learning (RL) post-training has emerged as a crucial step for enhancing Large Language Models (LLMs) with diverse capabilities. However, many systems designed to accelerate RL post-training still suffer from low resource utilization and limited scalability. We present ROLL Flash, a system that extends ROLL with native support for asynchronous RL post-training. ROLL Flash is built upon two core design principles: fine-grained parallelism and rollout-train decoupling. Guided by these principles, ROLL Flash provides flexible programming interfaces that enable a fully asynchronous training architecture and support efficient rollout mechanisms, including queue scheduling and environment-level asynchronous execution. Through comprehensive theoretical analysis and extensive experiments, we demonstrate that ROLL Flash significantly improves resource utilization and scalability over synchronous RL post-training. ROLL Flash achieves up to 2.24x speedup on RLVR tasks and 2.72x on agentic tasks, using the same GPU budget as synchronous baselines. Furthermore, we implement several popular off-policy algorithms and verify that asynchronous training can achieve performance on par with synchronous training.",
        "tags": [
            "LLM",
            "RL"
        ]
    },
    {
        "id": "424",
        "title": "Uncertainty-Aware ControlNet: Bridging Domain Gaps with Synthetic Image Generation",
        "author": [
            "Joshua Niemeijer",
            "Jan Ehrhardt",
            "Heinz Handels",
            "Hristina Uzunova"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11346",
        "abstract": "Generative Models are a valuable tool for the controlled creation of high-quality image data. Controlled diffusion models like the ControlNet have allowed the creation of labeled distributions. Such synthetic datasets can augment the original training distribution when discriminative models, like semantic segmentation, are trained. However, this augmentation effect is limited since ControlNets tend to reproduce the original training distribution.\nThis work introduces a method to utilize data from unlabeled domains to train ControlNets by introducing the concept of uncertainty into the control mechanism. The uncertainty indicates that a given image was not part of the training distribution of a downstream task, e.g., segmentation. Thus, two types of control are engaged in the final network: an uncertainty control from an unlabeled dataset and a semantic control from the labeled dataset. The resulting ControlNet allows us to create annotated data with high uncertainty from the target domain, i.e., synthetic data from the unlabeled distribution with labels. In our scenario, we consider retinal OCTs, where typically high-quality Spectralis images are available with given ground truth segmentations, enabling the training of segmentation networks. The recent development in Home-OCT devices, however, yields retinal OCTs with lower quality and a large domain shift, such that out-of-the-pocket segmentation networks cannot be applied for this type of data. Synthesizing annotated images from the Home-OCT domain using the proposed approach closes this gap and leads to significantly improved segmentation results without adding any further supervision. The advantage of uncertainty-guidance becomes obvious when compared to style transfer: it enables arbitrary domain shifts without any strict learning of an image style. This is also demonstrated in a traffic scene experiment.",
        "tags": [
            "ControlNet",
            "Diffusion",
            "Segmentation",
            "Style Transfer"
        ]
    },
    {
        "id": "425",
        "title": "LLM-Specific Utility: A New Perspective for Retrieval-Augmented Generation",
        "author": [
            "Hengran Zhang",
            "Keping Bi",
            "Jiafeng Guo",
            "Jiaming Zhang",
            "Shuaiqiang Wang",
            "Dawei Yin",
            "Xueqi Cheng"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11358",
        "abstract": "Retrieval-augmented generation (RAG) enhances large language models (LLMs) by incorporating external knowledge. While traditional retrieval focuses on relevance, RAG's effectiveness depends on the utility of retrieved passages, i.e., the usefulness in facilitating the generation of an accurate and comprehensive answer. Existing studies often treat utility as a generic attribute, ignoring the fact that different LLMs may benefit differently from the same passage due to variations in internal knowledge and comprehension ability. In this work, we introduce and systematically investigate the notion of LLM-specific utility. Through large-scale experiments across multiple datasets and LLMs, we demonstrate that human-annotated passages are not optimal for LLMs and that ground-truth utilitarian passages are not transferable across different LLMs. These findings highlight the necessity of adopting the LLM-specific utility in RAG research. Our findings indicate that some human-annotated passages are not ground-truth utilitarian passages for specific LLMs, partially due to the varying readability of queries and passages for LLMs, a tendency for which perplexity is a key metric. Based on these findings, we propose a benchmarking procedure for LLM-specific utility judgments. We evaluate existing utility judgment methods on six datasets and find that while verbalized methods using pseudo-answers perform robustly, LLMs struggle to assess utility effectively-failing to reject all passages for known queries and to select truly useful ones for unknown queries.",
        "tags": [
            "LLM",
            "RAG"
        ]
    },
    {
        "id": "426",
        "title": "Reasoning as Representation: Rethinking Visual Reinforcement Learning in Image Quality Assessment",
        "author": [
            "Shijie Zhao",
            "Xuanyu Zhang",
            "Weiqi Li",
            "Junlin Li",
            "Li Zhang",
            "Tianfan Xue",
            "Jian Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11369",
        "abstract": "Reasoning-based image quality assessment (IQA) models trained through reinforcement learning (RL) exhibit exceptional generalization, yet the underlying mechanisms and critical factors driving this capability remain underexplored in current research. Moreover, despite their superior performance, these models incur inference energy usage and latency orders of magnitude higher than their earlier counterparts, restricting their deployment in specific scenarios. Through extensive experiments, this paper verifies and elaborates that through RL training, MLLMs leverage their reasoning capability to convert redundant visual representations into compact, cross-domain aligned text representations. This conversion is precisely the source of the generalization exhibited by these reasoning-based IQA models. Building on this fundamental insight, we propose a novel algorithm, RALI, which employs contrastive learning to directly align images with these generalizable text representations learned by RL. This approach eliminates the reliance on reasoning processes and even obviates the need to load an LLM. For the quality scoring task, this framework achieves generalization performance comparable to reasoning-based models while requiring less than 5% of their model parameters and inference time.",
        "tags": [
            "LLM",
            "RL"
        ]
    },
    {
        "id": "427",
        "title": "Stabilizing MoE Reinforcement Learning by Aligning Training and Inference Routers",
        "author": [
            "Wenhan Ma",
            "Hailin Zhang",
            "Liang Zhao",
            "Yifan Song",
            "Yudong Wang",
            "Zhifang Sui",
            "Fuli Luo"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11370",
        "abstract": "Reinforcement learning (RL) has emerged as a crucial approach for enhancing the capabilities of large language models. However, in Mixture-of-Experts (MoE) models, the routing mechanism often introduces instability, even leading to catastrophic RL training collapse. We analyze the training-inference consistency of MoE models and identify a notable discrepancy in routing behaviors between the two phases. Moreover, even under identical conditions, the routing framework can yield divergent expert selections across repeated forward passes. To address this foundational inconsistency, we propose Rollout Routing Replay (R3), a method that records routing distributions from the inference engine and replays them during training. R3 significantly reduces training-inference policy KL divergence and mitigates extreme discrepancies without compromising training speed. Extensive experiments on various settings confirm that R3 succeeds in stabilizing RL training, preventing collapse and outperforming methods such as GSPO and TIS. We believe this work can offer a new solution for stabilizing RL in MoE models.",
        "tags": [
            "LLM",
            "MoE",
            "RL"
        ]
    },
    {
        "id": "428",
        "title": "Early Detection and Reduction of Memorisation for Domain Adaptation and Instruction Tuning",
        "author": [
            "Dean L. Slack",
            "Noura Al Moubayed"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11372",
        "abstract": "Although large language models excel across many tasks, they can memorise training data and thereby expose private or copyrighted text. Most defences target the pre-training stage, leaving memorisation during fine-tuning, especially for domain adaptation and instruction tuning, poorly understood. We fine-tune Pythia, Llama3, and Mistral models spanning 1.4B-70B parameters on common evaluation datasets and track verbatim memorisation throughout training. We find that memorisation increases dramatically in the first few epochs, often significantly before either validation perplexity or evaluation performance is optimised. We use a simple but effective n-gram memorisation score which reliably precedes verbatim memorisation; using it as an early-stopping criterion mitigates memorisation with minimal performance loss. Further, we introduce an n-gram-aware loss regulariser and show that it reduces memorisation across all model families tested by up to 40% while minimising evaluation performance trade-offs when compared to an existing memorisation mitigation strategy. These results yield practical, scalable insights into memorisation dynamics during language model fine-tuning.",
        "tags": [
            "Detection",
            "LLM"
        ]
    },
    {
        "id": "429",
        "title": "MaterialRefGS: Reflective Gaussian Splatting with Multi-view Consistent Material Inference",
        "author": [
            "Wenyuan Zhang",
            "Jimin Tang",
            "Weiqi Zhang",
            "Yi Fang",
            "Yu-Shen Liu",
            "Zhizhong Han"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11387",
        "abstract": "Modeling reflections from 2D images is essential for photorealistic rendering and novel view synthesis. Recent approaches enhance Gaussian primitives with reflection-related material attributes to enable physically based rendering (PBR) with Gaussian Splatting. However, the material inference often lacks sufficient constraints, especially under limited environment modeling, resulting in illumination aliasing and reduced generalization. In this work, we revisit the problem from a multi-view perspective and show that multi-view consistent material inference with more physically-based environment modeling is key to learning accurate reflections with Gaussian Splatting. To this end, we enforce 2D Gaussians to produce multi-view consistent material maps during deferred shading. We also track photometric variations across views to identify highly reflective regions, which serve as strong priors for reflection strength terms. To handle indirect illumination caused by inter-object occlusions, we further introduce an environment modeling strategy through ray tracing with 2DGS, enabling photorealistic rendering of indirect radiance. Experiments on widely used benchmarks show that our method faithfully recovers both illumination and geometry, achieving state-of-the-art rendering quality in novel views synthesis.",
        "tags": [
            "Gaussian Splatting"
        ]
    },
    {
        "id": "430",
        "title": "Beyond Survival: Evaluating LLMs in Social Deduction Games with Human-Aligned Strategies",
        "author": [
            "Zirui Song",
            "Yuan Huang",
            "Junchang Liu",
            "Haozhe Luo",
            "Chenxi Wang",
            "Lang Gao",
            "Zixiang Xu",
            "Mingfei Han",
            "Xiaojun Chang",
            "Xiuying Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11389",
        "abstract": "Social deduction games like Werewolf combine language, reasoning, and strategy, providing a testbed for studying natural language and social intelligence. However, most studies reduce the game to LLM-based self-play, yielding templated utterances and anecdotal cases that overlook the richness of social gameplay. Evaluation further relies on coarse metrics such as survival time or subjective scoring due to the lack of quality reference data. To address these gaps, we curate a high-quality, human-verified multimodal Werewolf dataset containing over 100 hours of video, 32.4M utterance tokens, and 15 rule variants. Based on this dataset, we propose a novel strategy-alignment evaluation that leverages the winning faction's strategies as ground truth in two stages: 1) Speech evaluation, formulated as multiple-choice-style tasks that assess whether the model can adopt appropriate stances across five dimensions of social ability; and 2) Decision evaluation, which assesses the model's voting choices and opponent-role inferences. This framework enables a fine-grained evaluation of models' linguistic and reasoning capabilities, while capturing their ability to generate strategically coherent gameplay. Our experiments show that state-of-the-art LLMs show diverse performance, with roughly half remain below 0.50, revealing clear gaps in deception and counterfactual reasoning. We hope our dataset further inspires research on language, reasoning, and strategy in multi-agent interaction.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "431",
        "title": "DocReward: A Document Reward Model for Structuring and Stylizing",
        "author": [
            "Junpeng Liu",
            "Yuzhong Zhao",
            "Bowen Cao",
            "Jiayu Ding",
            "Yilin Jia",
            "Tengchao Lv",
            "Yupan Huang",
            "Shaohan Huang",
            "Nan Yang",
            "Li Dong",
            "Lei Cui",
            "Tao Ge",
            "Xun Wang",
            "Huitian Jiao",
            "Sun Mao",
            "FNU Kartik",
            "Si-Qing Chen",
            "Wai Lam",
            "Furu Wei"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11391",
        "abstract": "Recent advances in agentic workflows have enabled the automation of tasks such as professional document generation. However, they primarily focus on textual quality, neglecting visual structure and style, which are crucial for readability and engagement. This gap arises mainly from the absence of suitable reward models to guide agentic workflows toward producing documents with stronger structural and stylistic quality. To address this, we propose DocReward, a document reward model that evaluates documents based on their structure and style. We construct a multi-domain dataset DocPair of 117K paired documents, covering 32 domains and 267 document types, each including a high- and low-professionalism document with identical content but different structure and style. This enables the model to evaluate professionalism comprehensively, and in a textual-quality-agnostic way. DocReward is trained using the Bradley-Terry loss to score documents, penalizing predictions that contradict the annotated ranking. To assess the performance of reward models, we create a test dataset containing document bundles ranked by well-educated human evaluators. Notably, DocReward outperforms GPT-4o and GPT-5 in accuracy by 30.6 and 19.4 percentage points, respectively, demonstrating its superiority over baselines. In an extrinsic evaluation of document generation, DocReward achieves a significantly higher win rate of 60.8%, compared to GPT-5's 37.7% win rate, demonstrating its utility in guiding generation agents toward producing human-preferred documents.",
        "tags": [
            "GPT"
        ]
    },
    {
        "id": "432",
        "title": "VeriCite: Towards Reliable Citations in Retrieval-Augmented Generation via Rigorous Verification",
        "author": [
            "Haosheng Qian",
            "Yixing Fan",
            "Jiafeng Guo",
            "Ruqing Zhang",
            "Qi Chen",
            "Dawei Yin",
            "Xueqi Cheng"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11394",
        "abstract": "Retrieval-Augmented Generation (RAG) has emerged as a crucial approach for enhancing the responses of large language models (LLMs) with external knowledge sources. Despite the impressive performance in complex question-answering tasks, RAG still struggles with hallucinations. Attributing RAG-generated content through in-line citations has demonstrated potential in reducing hallucinations and facilitating human verification. Existing citation generation methods primarily rely on either fine-tuning the generator or employing post-processing approaches for citation matching. However, the former approach demands substantial annotated data and computational resources, while the latter often encounters difficulties in managing multiple citations and frequently produces suboptimal results. In this paper, we introduce a novel framework, called VeriCite, designed to rigorously validate supporting evidence and enhance answer attribution. Specifically, VeriCite breaks down into a three-stage generation: 1) The initial answer generation first generates a response based on all available contexts and has its claims verified through the NLI model; 2) the supporting evidence selection assesses the utility of each document and extracts useful supporting evidences; 3) the final answer refinement integrates the initial response and collected evidences to produce the final, refined http://answer.We conduct experiments across five open-source LLMs and four datasets, demonstrating that VeriCite can significantly improve citation quality while maintaining the correctness of the answers.",
        "tags": [
            "LLM",
            "RAG"
        ]
    },
    {
        "id": "433",
        "title": "Living Off the LLM: How LLMs Will Change Adversary Tactics",
        "author": [
            "Sean Oesch",
            "Jack Hutchins",
            "Luke Koch",
            "Kevin Kurian"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11398",
        "abstract": "In living off the land attacks, malicious actors use legitimate tools and processes already present on a system to avoid detection. In this paper, we explore how the on-device LLMs of the future will become a security concern as threat actors integrate LLMs into their living off the land attack pipeline and ways the security community may mitigate this threat.",
        "tags": [
            "Detection",
            "LLM"
        ]
    },
    {
        "id": "434",
        "title": "KnowRL: Teaching Language Models to Know What They Know",
        "author": [
            "Sahil Kale",
            "Devendra Singh Dhami"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11407",
        "abstract": "Truly reliable AI requires more than simply scaling up knowledge; it demands the ability to know what it knows and when it does not. Yet recent research shows that even the best LLMs misjudge their own competence in more than one in five cases, making any response born of such internal uncertainty impossible to fully trust. Inspired by self-improvement reinforcement learning techniques that require minimal data, we present a simple but powerful framework KnowRL that strengthens a model's internal understanding of its own feasibility boundaries, enabling safer and more responsible behaviour. Our framework combines two components: (i) introspection, where the model generates and classifies tasks it judges feasible or infeasible, and (ii) consensus-based rewarding, where stability of self-knowledge assessment is reinforced through internal agreement. By using internally generated data, this design strengthens consistency in self-knowledge and entirely avoids costly external supervision. In experiments on LLaMA-3.1-8B and Qwen-2.5-7B, KnowRL steadily improved self-knowledge, validated by both intrinsic self-consistency and extrinsic benchmarking. With nothing more than a small seed set and no external supervision, our method drove gains as high as 28% in accuracy and 12% in F1, outperforming baselines in just a few iterations. Our framework essentially unlocks the untapped capacity of LLMs to self-improve their knowledge awareness, opening the door to reliable, more accountable AI and safer deployment in critical applications. Owing to its simplicity and independence from external effort, we encourage applying this reliability-enhancing process to all future models.",
        "tags": [
            "LLM",
            "LLaMA",
            "Qwen",
            "RL"
        ]
    },
    {
        "id": "435",
        "title": "Valid Survey Simulations with Limited Human Data: The Roles of Prompting, Fine-Tuning, and Rectification",
        "author": [
            "Stefan Krsteski",
            "Giuseppe Russo",
            "Serina Chang",
            "Robert West",
            "Kristina GligoriÄ"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11408",
        "abstract": "Surveys provide valuable insights into public opinion and behavior, but their execution is costly and slow. Large language models (LLMs) have been proposed as a scalable, low-cost substitute for human respondents, but their outputs are often biased and yield invalid estimates. We study the interplay between synthesis methods that use LLMs to generate survey responses and rectification methods that debias population estimates, and explore how human responses are best allocated between them. Using two panel surveys with questions on nutrition, politics, and economics, we find that synthesis alone introduces substantial bias (24-86%), whereas combining it with rectification reduces bias below 5% and increases effective sample size by up to 14%. Overall, we challenge the common practice of using all human responses for fine-tuning, showing that under a fixed budget, allocating most to rectification results in far more effective estimation.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "436",
        "title": "Leveraging LLMs for Semi-Automatic Corpus Filtration in Systematic Literature Reviews",
        "author": [
            "Lucas Joos",
            "Daniel A. Keim",
            "Maximilian T. Fischer"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11409",
        "abstract": "The creation of systematic literature reviews (SLR) is critical for analyzing the landscape of a research field and guiding future research directions. However, retrieving and filtering the literature corpus for an SLR is highly time-consuming and requires extensive manual effort, as keyword-based searches in digital libraries often return numerous irrelevant publications. In this work, we propose a pipeline leveraging multiple large language models (LLMs), classifying papers based on descriptive prompts and deciding jointly using a consensus scheme. The entire process is human-supervised and interactively controlled via our open-source visual analytics web interface, LLMSurver, which enables real-time inspection and modification of model outputs. We evaluate our approach using ground-truth data from a recent SLR comprising over 8,000 candidate papers, benchmarking both open and commercial state-of-the-art LLMs from mid-2024 and fall 2025. Results demonstrate that our pipeline significantly reduces manual effort while achieving lower error rates than single human annotators. Furthermore, modern open-source models prove sufficient for this task, making the method accessible and cost-effective. Overall, our work demonstrates how responsible human-AI collaboration can accelerate and enhance systematic literature reviews within academic workflows.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "437",
        "title": "Autonomous vehicles need social awareness to find optima in multi-agent reinforcement learning routing games",
        "author": [
            "Anastasia Psarou",
            "Åukasz Gorczyca",
            "Dominik GaweÅ",
            "RafaÅ Kucharski"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11410",
        "abstract": "Previous work has shown that when multiple selfish Autonomous Vehicles (AVs) are introduced to future cities and start learning optimal routing strategies using Multi-Agent Reinforcement Learning (MARL), they may destabilize traffic systems, as they would require a significant amount of time to converge to the optimal solution, equivalent to years of real-world commuting.\nWe demonstrate that moving beyond the selfish component in the reward significantly relieves this issue. If each AV, apart from minimizing its own travel time, aims to reduce its impact on the system, this will be beneficial not only for the system-wide performance but also for each individual player in this routing game.\nBy introducing an intrinsic reward signal based on the marginal cost matrix, we significantly reduce training time and achieve convergence more reliably. Marginal cost quantifies the impact of each individual action (route-choice) on the system (total travel time). Including it as one of the components of the reward can reduce the degree of non-stationarity by aligning agents' objectives. Notably, the proposed counterfactual formulation preserves the system's equilibria and avoids oscillations.\nOur experiments show that training MARL algorithms with our novel reward formulation enables the agents to converge to the optimal solution, whereas the baseline algorithms fail to do so. We show these effects in both a toy network and the real-world network of Saint-Arnoult. Our results optimistically indicate that social awareness (i.e., including marginal costs in routing decisions) improves both the system-wide and individual performance of future urban systems with AVs.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "438",
        "title": "Uncertainty-Aware, Risk-Adaptive Access Control for Agentic Systems using an LLM-Judged TBAC Model",
        "author": [
            "Charles Fleming",
            "Ashish Kundu",
            "Ramana Kompella"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11414",
        "abstract": "The proliferation of autonomous AI agents within enterprise environments introduces a critical security challenge: managing access control for emergent, novel tasks for which no predefined policies exist. This paper introduces an advanced security framework that extends the Task-Based Access Control (TBAC) model by using a Large Language Model (LLM) as an autonomous, risk-aware judge. This model makes access control decisions not only based on an agent's intent but also by explicitly considering the inherent \\textbf{risk associated with target resources} and the LLM's own \\textbf{model uncertainty} in its decision-making process. When an agent proposes a novel task, the LLM judge synthesizes a just-in-time policy while also computing a composite risk score for the task and an uncertainty estimate for its own reasoning. High-risk or high-uncertainty requests trigger more stringent controls, such as requiring human approval. This dual consideration of external risk and internal confidence allows the model to enforce a more robust and adaptive version of the principle of least privilege, paving the way for safer and more trustworthy autonomous systems.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "439",
        "title": "Robust Ego-Exo Correspondence with Long-Term Memory",
        "author": [
            "Yijun Hu",
            "Bing Fan",
            "Xin Gu",
            "Haiqing Ren",
            "Dongfang Liu",
            "Heng Fan",
            "Libo Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11417",
        "abstract": "Establishing object-level correspondence between egocentric and exocentric views is essential for intelligent assistants to deliver precise and intuitive visual guidance. However, this task faces numerous challenges, including extreme viewpoint variations, occlusions, and the presence of small objects. Existing approaches usually borrow solutions from video object segmentation models, but still suffer from the aforementioned challenges. Recently, the Segment Anything Model 2 (SAM 2) has shown strong generalization capabilities and excellent performance in video object segmentation. Yet, when simply applied to the ego-exo correspondence (EEC) task, SAM 2 encounters severe difficulties due to ineffective ego-exo feature fusion and limited long-term memory capacity, especially for long videos. Addressing these problems, we propose a novel EEC framework based on SAM 2 with long-term memories by presenting a dual-memory architecture and an adaptive feature routing module inspired by Mixture-of-Experts (MoE). Compared to SAM 2, our approach features (i) a Memory-View MoE module which consists of a dual-branch routing mechanism to adaptively assign contribution weights to each expert feature along both channel and spatial dimensions, and (ii) a dual-memory bank system with a simple yet effective compression strategy to retain critical long-term information while eliminating redundancy. In the extensive experiments on the challenging EgoExo4D benchmark, our method, dubbed LM-EEC, achieves new state-of-the-art results and significantly outperforms existing methods and the SAM 2 baseline, showcasing its strong generalization across diverse scenarios. Our code and model are available at https://github.com/juneyeeHu/LM-EEC.",
        "tags": [
            "MoE",
            "SAM",
            "Segmentation"
        ]
    },
    {
        "id": "440",
        "title": "Beyond the Crowd: LLM-Augmented Community Notes for Governing Health Misinformation",
        "author": [
            "Jiaying Wu",
            "Zihang Fu",
            "Haonan Wang",
            "Fanxiao Li",
            "Min-Yen Kan"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11423",
        "abstract": "Community Notes, the crowd-sourced misinformation governance system on X (formerly Twitter), enables users to flag misleading posts, attach contextual notes, and vote on their helpfulness. However, our analysis of 30.8K health-related notes reveals significant latency, with a median delay of 17.6 hours before the first note receives a helpfulness status. To improve responsiveness during real-world misinformation surges, we propose CrowdNotes+, a unified framework that leverages large language models (LLMs) to augment Community Notes for faster and more reliable health misinformation governance. CrowdNotes+ integrates two complementary modes: (1) evidence-grounded note augmentation and (2) utility-guided note automation, along with a hierarchical three-step evaluation that progressively assesses relevance, correctness, and helpfulness. We instantiate the framework through HealthNotes, a benchmark of 1.2K helpfulness-annotated health notes paired with a fine-tuned helpfulness judge. Experiments on fifteen LLMs reveal an overlooked loophole in current helpfulness evaluation, where stylistic fluency is mistaken for factual accuracy, and demonstrate that our hierarchical evaluation and LLM-augmented generation jointly enhance factual precision and evidence utility. These results point toward a hybrid human-AI governance model that improves both the rigor and timeliness of crowd-sourced fact-checking.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "441",
        "title": "Who are you, ChatGPT? Personality and Demographic Style in LLM-Generated Content",
        "author": [
            "Dana Sotto Porat",
            "Ella Rabinovich"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11434",
        "abstract": "Generative large language models (LLMs) have become central to everyday life, producing human-like text across diverse domains. A growing body of research investigates whether these models also exhibit personality- and demographic-like characteristics in their language. In this work, we introduce a novel, data-driven methodology for assessing LLM personality without relying on self-report questionnaires, applying instead automatic personality and gender classifiers to model replies on open-ended questions collected from Reddit. Comparing six widely used models to human-authored responses, we find that LLMs systematically express higher Agreeableness and lower Neuroticism, reflecting cooperative and stable conversational tendencies. Gendered language patterns in model text broadly resemble those of human writers, though with reduced variation, echoing prior findings on automated agents. We contribute a new dataset of human and model responses, along with large-scale comparative analyses, shedding new light on the topic of personality and demographic patterns of generative AI.",
        "tags": [
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "442",
        "title": "What Generative Search Engines Like and How to Optimize Web Content Cooperatively",
        "author": [
            "Yujiang Wu",
            "Shanshan Zhong",
            "Yubin Kim",
            "Chenyan Xiong"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11438",
        "abstract": "By employing large language models (LLMs) to retrieve documents and generate natural language responses, Generative Engines, such as Google AI overview and ChatGPT, provide significantly enhanced user experiences and have rapidly become the new form of search. Their rapid adoption also drives the needs of Generative Engine Optimization (GEO), as content providers are eager to gain more traction from them. In this paper, we introduce AutoGEO, a framework to automatically learn generative engine preferences when using retrieved contents for response generation, and rewrite web contents for more such traction. AutoGEO first prompts frontier LLMs to explain generative engine preferences and extract meaningful preference rules from these explanations. Then it uses preference rules as context engineering for AutoGEO$_\\text{API}$, a prompt-based GEO system, and as rule-based rewards to train AutoGEO$_\\text{Mini}$, a cost-effective GEO model. Experiments on the standard GEO-Bench and two newly constructed benchmarks using real user queries demonstrate the effectiveness of AutoGEO in enhancing content traction while preserving search utility. Analyses confirm the learned rules' robustness and abilities to capture unique preferences in variant domains, and AutoGEO systems' ability to embed them in content optimization. The code is released at https://github.com/cxcscmu/AutoGEO.",
        "tags": [
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "443",
        "title": "Audio-Maestro: Enhancing Large Audio-Language Models with Tool-Augmented Reasoning",
        "author": [
            "Kuan-Yi Lee",
            "Tsung-En Lin",
            "Hung-Yi Lee"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11454",
        "abstract": "Recent advancements in large multimodal models (LMMs) have shown strong capabilities in audio understanding. However, most systems rely solely on end-to-end reasoning, limiting interpretability and accuracy for tasks that require structured knowledge or specialized signal analysis. In this work, we present Audio-Maestro -- a tool-augmented audio reasoning framework that enables audio-language models to autonomously call external tools and integrate their timestamped outputs into the reasoning process. This design allows the model to analyze, transform, and interpret audio signals through specialized tools rather than relying solely on end-to-end inference. Experiments show that Audio-Maestro consistently improves general audio reasoning performance: Gemini-2.5-flash's average accuracy on MMAU-Test rises from 67.4% to 72.1%, DeSTA-2.5 from 58.3% to 62.8%, and GPT-4o from 60.8% to 63.9%. To our knowledge, Audio-Maestro is the first framework to integrate structured tool output into the large audio language model reasoning process.",
        "tags": [
            "GPT"
        ]
    },
    {
        "id": "444",
        "title": "From <Answer> to <Think>: Multidimensional Supervision of Reasoning Process for LLM Optimization",
        "author": [
            "Beining Wang",
            "Weihang Su",
            "Hongtao Tian",
            "Tao Yang",
            "Yujia Zhou",
            "Ting Yao",
            "Qingyao Ai",
            "Yiqun Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11457",
        "abstract": "Improving the multi-step reasoning ability of Large Language Models (LLMs) is a critical yet challenging task. The dominant paradigm, outcome-supervised reinforcement learning (RLVR), rewards only correct final answers, often propagating flawed reasoning and suffering from sparse reward signals. While process-level reward models (PRMs) provide denser, step-by-step feedback, they lack generalizability and interpretability, requiring task-specific segmentation of the reasoning process. To this end, we propose the Dimension-level Reward Model (DRM), a new supervision framework that bridges the gap between these two approaches. DRM evaluates the quality of a reasoning process along three fundamental, complementary, and interpretable dimensions: Confidence for uncertainty calibration, Relevance for semantic alignment, and Coherence for logical consistency. Together, these dimensions capture aspects beyond final answer correctness and enable interpretable assessment without requiring ground truth answers. Experimental results show that DRM provides effective supervision signals, guides the optimization of LLMs and enhances their reasoning ability. In particular, DRM-supervised training achieves consistent gains on both in-distribution and out-of-distribution open-domain tasks, including mathematics, question answering, code execution, and puzzles. Our findings demonstrate that multidimensional supervision of the reasoning process can improve the generalized reasoning ability of LLMs beyond the training distribution.",
        "tags": [
            "LLM",
            "RL",
            "Segmentation"
        ]
    },
    {
        "id": "445",
        "title": "Unifying Deductive and Abductive Reasoning in Knowledge Graphs with Masked Diffusion Model",
        "author": [
            "Yisen Gao",
            "Jiaxin Bai",
            "Yi Huang",
            "Xingcheng Fu",
            "Qingyun Sun",
            "Yangqiu Song"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11462",
        "abstract": "Deductive and abductive reasoning are two critical paradigms for analyzing knowledge graphs, enabling applications from financial query answering to scientific discovery. Deductive reasoning on knowledge graphs usually involves retrieving entities that satisfy a complex logical query, while abductive reasoning generates plausible logical hypotheses from observations. Despite their clear synergistic potential, where deduction can validate hypotheses and abduction can uncover deeper logical patterns, existing methods address them in isolation. To bridge this gap, we propose DARK, a unified framework for Deductive and Abductive Reasoning in Knowledge graphs. As a masked diffusion model capable of capturing the bidirectional relationship between queries and conclusions, DARK has two key innovations. First, to better leverage deduction for hypothesis refinement during abductive reasoning, we introduce a self-reflective denoising process that iteratively generates and validates candidate hypotheses against the observed conclusion. Second, to discover richer logical associations, we propose a logic-exploration reinforcement learning approach that simultaneously masks queries and conclusions, enabling the model to explore novel reasoning compositions. Extensive experiments on multiple benchmark knowledge graphs show that DARK achieves state-of-the-art performance on both deductive and abductive reasoning tasks, demonstrating the significant benefits of our unified approach.",
        "tags": [
            "Diffusion",
            "RL"
        ]
    },
    {
        "id": "446",
        "title": "Iterative Amortized Inference: Unifying In-Context Learning and Learned Optimizers",
        "author": [
            "Sarthak Mittal",
            "Divyat Mahajan",
            "Guillaume Lajoie",
            "Mohammad Pezeshki"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11471",
        "abstract": "Modern learning systems increasingly rely on amortized learning - the idea of reusing computation or inductive biases shared across tasks to enable rapid generalization to novel problems. This principle spans a range of approaches, including meta-learning, in-context learning, prompt tuning, learned optimizers and more. While motivated by similar goals, these approaches differ in how they encode and leverage task-specific information, often provided as in-context examples. In this work, we propose a unified framework which describes how such methods differ primarily in the aspects of learning they amortize - such as initializations, learned updates, or predictive mappings - and how they incorporate task data at inference. We introduce a taxonomy that categorizes amortized models into parametric, implicit, and explicit regimes, based on whether task adaptation is externalized, internalized, or jointly modeled. Building on this view, we identify a key limitation in current approaches: most methods struggle to scale to large datasets because their capacity to process task data at inference (e.g., context length) is often limited. To address this, we propose iterative amortized inference, a class of models that refine solutions step-by-step over mini-batches, drawing inspiration from stochastic optimization. Our formulation bridges optimization-based meta-learning with forward-pass amortization in models like LLMs, offering a scalable and extensible foundation for general-purpose task adaptation.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "447",
        "title": "VA-GS: Enhancing the Geometric Representation of Gaussian Splatting via View Alignment",
        "author": [
            "Qing Li",
            "Huifang Feng",
            "Xun Gong",
            "Yu-Shen Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11473",
        "abstract": "3D Gaussian Splatting has recently emerged as an efficient solution for high-quality and real-time novel view synthesis. However, its capability for accurate surface reconstruction remains underexplored. Due to the discrete and unstructured nature of Gaussians, supervision based solely on image rendering loss often leads to inaccurate geometry and inconsistent multi-view alignment. In this work, we propose a novel method that enhances the geometric representation of 3D Gaussians through view alignment (VA). Specifically, we incorporate edge-aware image cues into the rendering loss to improve surface boundary delineation. To enforce geometric consistency across views, we introduce a visibility-aware photometric alignment loss that models occlusions and encourages accurate spatial relationships among Gaussians. To further mitigate ambiguities caused by lighting variations, we incorporate normal-based constraints to refine the spatial orientation of Gaussians and improve local surface estimation. Additionally, we leverage deep image feature embeddings to enforce cross-view consistency, enhancing the robustness of the learned geometry under varying viewpoints and illumination. Extensive experiments on standard benchmarks demonstrate that our method achieves state-of-the-art performance in both surface reconstruction and novel view synthesis. The source code is available at https://github.com/LeoQLi/VA-GS.",
        "tags": [
            "3D",
            "Gaussian Splatting"
        ]
    },
    {
        "id": "448",
        "title": "Coordinated Strategies in Realistic Air Combat by Hierarchical Multi-Agent Reinforcement Learning",
        "author": [
            "Ardian Selmonaj",
            "Giacomo Del Rio",
            "Adrian Schneider",
            "Alessandro Antonucci"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11474",
        "abstract": "Achieving mission objectives in a realistic simulation of aerial combat is highly challenging due to imperfect situational awareness and nonlinear flight dynamics. In this work, we introduce a novel 3D multi-agent air combat environment and a Hierarchical Multi-Agent Reinforcement Learning framework to tackle these challenges. Our approach combines heterogeneous agent dynamics, curriculum learning, league-play, and a newly adapted training algorithm. To this end, the decision-making process is organized into two abstraction levels: low-level policies learn precise control maneuvers, while high-level policies issue tactical commands based on mission objectives. Empirical results show that our hierarchical approach improves both learning efficiency and combat performance in complex dogfight scenarios.",
        "tags": [
            "3D",
            "RL"
        ]
    },
    {
        "id": "449",
        "title": "Investigating Large Language Models' Linguistic Abilities for Text Preprocessing",
        "author": [
            "Marco Braga",
            "Gian Carlo Milanese",
            "Gabriella Pasi"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11482",
        "abstract": "Text preprocessing is a fundamental component of Natural Language Processing, involving techniques such as stopword removal, stemming, and lemmatization to prepare text as input for further processing and analysis. Despite the context-dependent nature of the above techniques, traditional methods usually ignore contextual information. In this paper, we investigate the idea of using Large Language Models (LLMs) to perform various preprocessing tasks, due to their ability to take context into account without requiring extensive language-specific annotated resources. Through a comprehensive evaluation on web-sourced data, we compare LLM-based preprocessing (specifically stopword removal, lemmatization and stemming) to traditional algorithms across multiple text classification tasks in six European languages. Our analysis indicates that LLMs are capable of replicating traditional stopword removal, lemmatization, and stemming methods with accuracies reaching 97%, 82%, and 74%, respectively. Additionally, we show that ML algorithms trained on texts preprocessed by LLMs achieve an improvement of up to 6% with respect to the $F_1$ measure compared to traditional techniques. Our code, prompts, and results are publicly available at https://github.com/GianCarloMilanese/llm_pipeline_wi-iat.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "450",
        "title": "Constraint-Aware Reinforcement Learning via Adaptive Action Scaling",
        "author": [
            "Murad Dawood",
            "Usama Ahmed Siddiquie",
            "Shahram Khorshidi",
            "Maren Bennewitz"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11491",
        "abstract": "Safe reinforcement learning (RL) seeks to mitigate unsafe behaviors that arise from exploration during training by reducing constraint violations while maintaining task performance. Existing approaches typically rely on a single policy to jointly optimize reward and safety, which can cause instability due to conflicting objectives, or they use external safety filters that override actions and require prior system knowledge. In this paper, we propose a modular cost-aware regulator that scales the agent's actions based on predicted constraint violations, preserving exploration through smooth action modulation rather than overriding the policy. The regulator is trained to minimize constraint violations while avoiding degenerate suppression of actions. Our approach integrates seamlessly with off-policy RL methods such as SAC and TD3, and achieves state-of-the-art return-to-cost ratios on Safety Gym locomotion tasks with sparse costs, reducing constraint violations by up to 126 times while increasing returns by over an order of magnitude compared to prior methods.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "451",
        "title": "How Reinforcement Learning After Next-Token Prediction Facilitates Learning",
        "author": [
            "Nikolaos Tsilivis",
            "Eran Malach",
            "Karen Ullrich",
            "Julia Kempe"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11495",
        "abstract": "Recent advances in reasoning domains with neural networks have primarily been enabled by a training recipe that optimizes Large Language Models, previously trained to predict the next-token in a sequence, with reinforcement learning algorithms. We introduce a framework to study the success of this paradigm, and we theoretically expose the optimization mechanisms by which reinforcement learning improves over next-token prediction in this setting. We study learning from mixture distributions of short and long ``chain-of-thought'' sequences encoding a single task. In particular, when the task consists of predicting the parity of $d$ bits and long sequences are rare, we show how reinforcement learning after next-token prediction enables autoregressive transformers to generalize, whereas mere next-token prediction requires extreme statistical or computational resources to do so. We further explain how reinforcement learning leverages increased test-time computation, manifested in longer responses, to facilitate this learning process. In a simplified setting, we theoretically prove that autoregressive linear models following this training recipe can efficiently learn to predict the parity of $d$ bits as long as the proportion of long demonstrations in the data mix is not exponentially small in the input dimension $d$. Finally, we demonstrate these same phenomena in other settings, including the post-training of Llama-series models on mixture variations of common mathematical reasoning benchmarks.",
        "tags": [
            "CoT",
            "LLM",
            "LLaMA",
            "RL"
        ]
    },
    {
        "id": "452",
        "title": "AndesVL Technical Report: An Efficient Mobile-side Multimodal Large Language Model",
        "author": [
            "Zhiwei Jin",
            "Xiaohui Song",
            "Nan Wang",
            "Yafei Liu",
            "Chao Li",
            "Xin Li",
            "Ruichen Wang",
            "Zhihao Li",
            "Qi Qi",
            "Long Cheng",
            "Dongze Hao",
            "Quanlong Zheng",
            "Yanhao Zhang",
            "Haobo Ji",
            "Jian Ma",
            "Zhitong Zheng",
            "Zhenyi Lin",
            "Haolin Deng",
            "Xin Zou",
            "Xiaojie Yin",
            "Ruilin Wang",
            "Liankai Cai",
            "Haijing Liu",
            "Yuqing Qiu",
            "Ke Chen",
            "Zixian Li",
            "Chi Xie",
            "Huafei Li",
            "Chenxing Li",
            "Chuangchuang Wang",
            "Kai Tang",
            "Zhiguang Zhu",
            "Kai Tang",
            "Wenmei Gao",
            "Rui Wang",
            "Jun Wu",
            "Chao Liu",
            "Qin Xie",
            "Chen Chen",
            "Haonan Lu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11496",
        "abstract": "In recent years, while cloud-based MLLMs such as QwenVL, InternVL, GPT-4o, Gemini, and Claude Sonnet have demonstrated outstanding performance with enormous model sizes reaching hundreds of billions of parameters, they significantly surpass the limitations in memory, power consumption, and computing capacity of edge devices such as mobile phones. This paper introduces AndesVL, a suite of mobile-side MLLMs with 0.6B to 4B parameters based on Qwen3's LLM and various visual encoders. We comprehensively outline the model architectures, training pipeline, and training data of AndesVL, which achieves first-tier performance across a wide range of open-source benchmarks, including fields such as text-rich image understanding, reasoning and math, multi-image comprehension, general VQA, hallucination mitigation, multilingual understanding, and GUI-related tasks when compared with state-of-the-art models of a similar scale. Furthermore, we introduce a 1+N LoR",
        "tags": [
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "453",
        "title": "ReLook: Vision-Grounded RL with a Multimodal LLM Critic for Agentic Web Coding",
        "author": [
            "Yuhang Li",
            "Chenchen Zhang",
            "Ruilin Lv",
            "Ao Liu",
            "Ken Deng",
            "Yuanxing Zhang",
            "Jiaheng Liu",
            "Wiggin Zhou",
            "Bo Zhou"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11498",
        "abstract": "While Large Language Models (LLMs) excel at algorithmic code generation, they struggle with front-end development, where correctness is judged on rendered pixels and interaction. We present ReLook, an agentic, vision-grounded reinforcement learning framework that empowers an agent to close a robust generate--diagnose--refine loop by invoking a multimodal LLM (MLLM) as a tool. During training, the agent uses the MLLM-in-the-loop both as a visual critic--scoring code with screenshots--and as a source of actionable, vision-grounded feedback; a strict zero-reward rule for invalid renders anchors renderability and prevents reward hacking. To prevent behavioral collapse, we introduce Forced Optimization, a strict acceptance rule that admits only improving revisions, yielding monotonically better trajectories. At inference, we decouple the critic and run a lightweight, critic-free self-edit cycle, keeping latency comparable to base decoding while retaining most of the gains. Across three widely used benchmarks, ReLook consistently outperforms strong baselines in vision-grounded front-end code generation, highlighting the benefits of agentic perception, visual rewards, and training-inference decoupling.",
        "tags": [
            "LLM",
            "RL"
        ]
    },
    {
        "id": "454",
        "title": "Offline Reinforcement Learning with Generative Trajectory Policies",
        "author": [
            "Xinsong Feng",
            "Leshu Tang",
            "Chenan Wang",
            "Haipeng Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11499",
        "abstract": "Generative models have emerged as a powerful class of policies for offline reinforcement learning (RL) due to their ability to capture complex, multi-modal behaviors. However, existing methods face a stark trade-off: slow, iterative models like diffusion policies are computationally expensive, while fast, single-step models like consistency policies often suffer from degraded performance. In this paper, we demonstrate that it is possible to bridge this gap. The key to moving beyond the limitations of individual methods, we argue, lies in a unifying perspective that views modern generative models, including diffusion, flow matching, and consistency models, as specific instances of learning a continuous-time generative trajectory governed by an Ordinary Differential Equation (ODE). This principled foundation provides a clearer design space for generative policies in RL and allows us to propose Generative Trajectory Policies (GTPs), a new and more general policy paradigm that learns the entire solution map of the underlying ODE. To make this paradigm practical for offline RL, we further introduce two key theoretically principled adaptations. Empirical results demonstrate that GTP achieves state-of-the-art performance on D4RL benchmarks - it significantly outperforms prior generative policies, achieving perfect scores on several notoriously hard AntMaze tasks.",
        "tags": [
            "Consistency Models",
            "Diffusion",
            "Flow Matching",
            "ODE",
            "RL"
        ]
    },
    {
        "id": "455",
        "title": "Context-Aware Model-Based Reinforcement Learning for Autonomous Racing",
        "author": [
            "Emran Yasser Moustafa",
            "Ivana Dusparic"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11501",
        "abstract": "Autonomous vehicles have shown promising potential to be a groundbreaking technology for improving the safety of road users. For these vehicles, as well as many other safety-critical robotic technologies, to be deployed in real-world applications, we require algorithms that can generalize well to unseen scenarios and data. Model-based reinforcement learning algorithms (MBRL) have demonstrated state-of-the-art performance and data efficiency across a diverse set of domains. However, these algorithms have also shown susceptibility to changes in the environment and its transition dynamics.\nIn this work, we explore the performance and generalization capabilities of MBRL algorithms for autonomous driving, specifically in the simulated autonomous racing environment, Roboracer (formerly F1Tenth). We frame the head-to-head racing task as a learning problem using contextual Markov decision processes and parameterize the driving behavior of the adversaries using the context of the episode, thereby also parameterizing the transition and reward dynamics. We benchmark the behavior of MBRL algorithms in this environment and propose a novel context-aware extension of the existing literature, cMask. We demonstrate that context-aware MBRL algorithms generalize better to out-of-distribution adversary behaviors relative to context-free approaches. We also demonstrate that cMask displays strong generalization capabilities, as well as further performance improvement relative to other context-aware MBRL approaches when racing against adversaries with in-distribution behaviors.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "456",
        "title": "Situat3DChange: Situated 3D Change Understanding Dataset for Multimodal Large Language Model",
        "author": [
            "Ruiping Liu",
            "Junwei Zheng",
            "Yufan Chen",
            "Zirui Wang",
            "Kunyu Peng",
            "Kailun Yang",
            "Jiaming Zhang",
            "Marc Pollefeys",
            "Rainer Stiefelhagen"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11509",
        "abstract": "Physical environments and circumstances are fundamentally dynamic, yet current 3D datasets and evaluation benchmarks tend to concentrate on either dynamic scenarios or dynamic situations in isolation, resulting in incomplete comprehension. To overcome these constraints, we introduce Situat3DChange, an extensive dataset supporting three situation-aware change understanding tasks following the perception-action model: 121K question-answer pairs, 36K change descriptions for perception tasks, and 17K rearrangement instructions for the action task. To construct this large-scale dataset, Situat3DChange leverages 11K human observations of environmental changes to establish shared mental models and shared situational awareness for human-AI collaboration. These observations, enriched with egocentric and allocentric perspectives as well as categorical and coordinate spatial relations, are integrated using an LLM to support understanding of situated changes. To address the challenge of comparing pairs of point clouds from the same scene with minor changes, we propose SCReasoner, an efficient 3D MLLM approach that enables effective point cloud comparison with minimal parameter overhead and no additional tokens required for the language decoder. Comprehensive evaluation on Situat3DChange tasks highlights both the progress and limitations of MLLMs in dynamic scene and situation understanding. Additional experiments on data scaling and cross-domain transfer demonstrate the task-agnostic effectiveness of using Situat3DChange as a training dataset for MLLMs.",
        "tags": [
            "3D",
            "LLM"
        ]
    },
    {
        "id": "457",
        "title": "LikePhys: Evaluating Intuitive Physics Understanding in Video Diffusion Models via Likelihood Preference",
        "author": [
            "Jianhao Yuan",
            "Fabio Pizzati",
            "Francesco Pinto",
            "Lars Kunze",
            "Ivan Laptev",
            "Paul Newman",
            "Philip Torr",
            "Daniele De Martini"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11512",
        "abstract": "Intuitive physics understanding in video diffusion models plays an essential role in building general-purpose physically plausible world simulators, yet accurately evaluating such capacity remains a challenging task due to the difficulty in disentangling physics correctness from visual appearance in generation. To the end, we introduce LikePhys, a training-free method that evaluates intuitive physics in video diffusion models by distinguishing physically valid and impossible videos using the denoising objective as an ELBO-based likelihood surrogate on a curated dataset of valid-invalid pairs. By testing on our constructed benchmark of twelve scenarios spanning over four physics domains, we show that our evaluation metric, Plausibility Preference Error (PPE), demonstrates strong alignment with human preference, outperforming state-of-the-art evaluator baselines. We then systematically benchmark intuitive physics understanding in current video diffusion models. Our study further analyses how model design and inference settings affect intuitive physics understanding and highlights domain-specific capacity variations across physical laws. Empirical results show that, despite current models struggling with complex and chaotic dynamics, there is a clear trend of improvement in physics understanding as model capacity and inference settings scale.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "458",
        "title": "A Physics-Informed Reinforcement Learning Approach for Degradation-Aware Long-Term Charging Optimization in Batteries",
        "author": [
            "Shanthan Kumar Padisala",
            "Bharatkumar Hegde",
            "Ibrahim Haskara",
            "Satadru Dey"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11515",
        "abstract": "Batteries degrade with usage and continuous cycling. This aging is typically reflected through the resistance growth and the capacity fade of battery cells. Over the years, various charging methods have been presented in the literature that proposed current profiles in order to enable optimal, fast, and/or health-conscious charging. However, very few works have attempted to make the ubiquitous Constant Current Constant Voltage (CCCV) charging protocol adaptive to the changing battery health as it cycles. This work aims to address this gap and proposes a framework that optimizes the constant current part of the CCCV protocol adapting to long-term battery degradation. Specifically, a physics-informed Reinforcement Learning (RL) approach has been used that not only estimates a key battery degradation mechanism, namely, Loss of Active Material (LAM), but also adjusts the current magnitude of CCCV as a result of this particular degradation. The proposed framework has been implemented by combining PyBamm, an open-source battery modeling tool, and Stable-baselines where the RL agent was trained using a Proximal Policy Optimization (PPO) network. Simulation results show the potential of the proposed framework for enhancing the widely used CCCV protocol by embedding physics information in RL algorithm. A comparative study of this proposed agent has also been discussed with 2 other charging protocols generated by a non-physics-based RL agent and a constant CCCV for all the cycles.",
        "tags": [
            "PPO",
            "RL"
        ]
    },
    {
        "id": "459",
        "title": "Cracking CodeWhisperer: Analyzing Developers' Interactions and Patterns During Programming Tasks",
        "author": [
            "Jeena Javahar",
            "Tanya Budhrani",
            "Manaal Basha",
            "Cleidson R. B. de Souza",
            "Ivan Beschastnikh",
            "Gema Rodriguez-Perez"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11516",
        "abstract": "The use of AI code-generation tools is becoming increasingly common, making it important to understand how software developers are adopting these tools. In this study, we investigate how developers engage with Amazon's CodeWhisperer, an LLM-based code-generation tool. We conducted two user studies with two groups of 10 participants each, interacting with CodeWhisperer - the first to understand which interactions were critical to capture and the second to collect low-level interaction data using a custom telemetry plugin. Our mixed-methods analysis identified four behavioral patterns: 1) incremental code refinement, 2) explicit instruction using natural language comments, 3) baseline structuring with model suggestions, and 4) integrative use with external sources. We provide a comprehensive analysis of these patterns .",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "460",
        "title": "mmWalk: Towards Multi-modal Multi-view Walking Assistance",
        "author": [
            "Kedi Ying",
            "Ruiping Liu",
            "Chongyan Chen",
            "Mingzhe Tao",
            "Hao Shi",
            "Kailun Yang",
            "Jiaming Zhang",
            "Rainer Stiefelhagen"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11520",
        "abstract": "Walking assistance in extreme or complex environments remains a significant challenge for people with blindness or low vision (BLV), largely due to the lack of a holistic scene understanding. Motivated by the real-world needs of the BLV community, we build mmWalk, a simulated multi-modal dataset that integrates multi-view sensor and accessibility-oriented features for outdoor safe navigation. Our dataset comprises 120 manually controlled, scenario-categorized walking trajectories with 62k synchronized frames. It contains over 559k panoramic images across RGB, depth, and semantic modalities. Furthermore, to emphasize real-world relevance, each trajectory involves outdoor corner cases and accessibility-specific landmarks for BLV users. Additionally, we generate mmWalkVQA, a VQA benchmark with over 69k visual question-answer triplets across 9 categories tailored for safe and informed walking assistance. We evaluate state-of-the-art Vision-Language Models (VLMs) using zero- and few-shot settings and found they struggle with our risk assessment and navigational tasks. We validate our mmWalk-finetuned model on real-world datasets and show the effectiveness of our dataset for advancing multi-modal walking assistance.",
        "tags": [
            "VLM"
        ]
    },
    {
        "id": "461",
        "title": "Hallucination Detection via Internal States and Structured Reasoning Consistency in Large Language Models",
        "author": [
            "Yusheng Song",
            "Lirong Qiu",
            "Xi Zhang",
            "Zhihao Tang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11529",
        "abstract": "The detection of sophisticated hallucinations in Large Language Models (LLMs) is hampered by a ``Detection Dilemma'': methods probing internal states (Internal State Probing) excel at identifying factual inconsistencies but fail on logical fallacies, while those verifying externalized reasoning (Chain-of-Thought Verification) show the opposite behavior. This schism creates a task-dependent blind spot: Chain-of-Thought Verification fails on fact-intensive tasks like open-domain QA where reasoning is ungrounded, while Internal State Probing is ineffective on logic-intensive tasks like mathematical reasoning where models are confidently wrong. We resolve this with a unified framework that bridges this critical gap. However, unification is hindered by two fundamental challenges: the Signal Scarcity Barrier, as coarse symbolic reasoning chains lack signals directly comparable to fine-grained internal states, and the Representational Alignment Barrier, a deep-seated mismatch between their underlying semantic spaces. To overcome these, we introduce a multi-path reasoning mechanism to obtain more comparable, fine-grained signals, and a segment-aware temporalized cross-attention module to adaptively fuse these now-aligned representations, pinpointing subtle dissonances. Extensive experiments on three diverse benchmarks and two leading LLMs demonstrate that our framework consistently and significantly outperforms strong baselines. Our code is available: https://github.com/peach918/HalluDet.",
        "tags": [
            "CoT",
            "Detection",
            "LLM"
        ]
    },
    {
        "id": "462",
        "title": "IntersectioNDE: Learning Complex Urban Traffic Dynamics based on Interaction Decoupling Strategy",
        "author": [
            "Enli Lin",
            "Ziyuan Yang",
            "Qiujing Lu",
            "Jianming Hu",
            "Shuo Feng"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11534",
        "abstract": "Realistic traffic simulation is critical for ensuring the safety and reliability of autonomous vehicles (AVs), especially in complex and diverse urban traffic environments. However, existing data-driven simulators face two key challenges: a limited focus on modeling dense, heterogeneous interactions at urban intersections - which are prevalent, crucial, and practically significant in countries like China, featuring diverse agents including motorized vehicles (MVs), non-motorized vehicles (NMVs), and pedestrians - and the inherent difficulty in robustly learning high-dimensional joint distributions for such high-density scenes, often leading to mode collapse and long-term simulation instability. We introduce City Crossings Dataset (CiCross), a large-scale dataset collected from a real-world urban intersection, uniquely capturing dense, heterogeneous multi-agent interactions, particularly with a substantial proportion of MVs, NMVs and pedestrians. Based on this dataset, we propose IntersectioNDE (Intersection Naturalistic Driving Environment), a data-driven simulator tailored for complex urban intersection scenarios. Its core component is the Interaction Decoupling Strategy (IDS), a training paradigm that learns compositional dynamics from agent subsets, enabling the marginal-to-joint simulation. Integrated into a scene-aware Transformer network with specialized training techniques, IDS significantly enhances simulation robustness and long-term stability for modeling heterogeneous interactions. Experiments on CiCross show that IntersectioNDE outperforms baseline methods in simulation fidelity, stability, and its ability to replicate complex, distribution-level urban traffic dynamics.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "463",
        "title": "A Flexible Multi-Agent Deep Reinforcement Learning Framework for Dynamic Routing and Scheduling of Latency-Critical Services",
        "author": [
            "Vincenzo Norman Vitale",
            "Antonia Maria Tulino",
            "Andreas F. Molisch",
            "Jaime Llorca"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11535",
        "abstract": "Timely delivery of delay-sensitive information over dynamic, heterogeneous networks is increasingly essential for a range of interactive applications, such as industrial automation, self-driving vehicles, and augmented reality. However, most existing network control solutions target only average delay performance, falling short of providing strict End-to-End (E2E) peak latency guarantees. This paper addresses the challenge of reliably delivering packets within application-imposed deadlines by leveraging recent advancements in Multi-Agent Deep Reinforcement Learning (MA-DRL). After introducing the Delay-Constrained Maximum-Throughput (DCMT) dynamic network control problem, and highlighting the limitations of current solutions, we present a novel MA-DRL network control framework that leverages a centralized routing and distributed scheduling architecture. The proposed framework leverages critical networking domain knowledge for the design of effective MA-DRL strategies based on the Multi-Agent Deep Deterministic Policy Gradient (MADDPG) technique, where centralized routing and distributed scheduling agents dynamically assign paths and schedule packet transmissions according to packet lifetimes, thereby maximizing on-time packet delivery. The generality of the proposed framework allows integrating both data-driven \\blue{Deep Reinforcement Learning (DRL)} agents and traditional rule-based policies in order to strike the right balance between performance and learning complexity. Our results confirm the superiority of the proposed framework with respect to traditional stochastic optimization-based approaches and provide key insights into the role and interplay between data-driven DRL agents and new rule-based policies for both efficient and high-performance control of latency-critical services.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "464",
        "title": "CodeWatcher: IDE Telemetry Data Extraction Tool for Understanding Coding Interactions with LLMs",
        "author": [
            "Manaal Basha",
            "AimeÃª M. Ribeiro",
            "Jeena Javahar",
            "Cleidson R. B. de Souza",
            "Gema RodrÃ­guez-PÃ©rez"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11536",
        "abstract": "Understanding how developers interact with code generation tools (CGTs) requires detailed, real-time data on programming behavior which is often difficult to collect without disrupting workflow. We present \\textit{CodeWatcher}, a lightweight, unobtrusive client-server system designed to capture fine-grained interaction events from within the Visual Studio Code (VS Code) editor. \\textit{CodeWatcher} logs semantically meaningful events such as insertions made by CGTs, deletions, copy-paste actions, and focus shifts, enabling continuous monitoring of developer activity without modifying user workflows. The system comprises a VS Code plugin, a Python-based RESTful API, and a MongoDB backend, all containerized for scalability and ease of deployment. By structuring and timestamping each event, \\textit{CodeWatcher} enables post-hoc reconstruction of coding sessions and facilitates rich behavioral analyses, including how and when CGTs are used during development. This infrastructure is crucial for supporting research on responsible AI, developer productivity, and the human-centered evaluation of CGTs. Please find the demo, diagrams, and tool here: https://osf.io/j2kru/overview.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "465",
        "title": "Massive Activations are the Key to Local Detail Synthesis in Diffusion Transformers",
        "author": [
            "Chaofan Gan",
            "Zicheng Zhao",
            "Yuanpeng Tu",
            "Xi Chen",
            "Ziran Qin",
            "Tieyuan Chen",
            "Mehrtash Harandi",
            "Weiyao Lin"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11538",
        "abstract": "Diffusion Transformers (DiTs) have recently emerged as a powerful backbone for visual generation. Recent observations reveal \\emph{Massive Activations} (MAs) in their internal feature maps, yet their function remains poorly understood. In this work, we systematically investigate these activations to elucidate their role in visual generation. We found that these massive activations occur across all spatial tokens, and their distribution is modulated by the input timestep embeddings. Importantly, our investigations further demonstrate that these massive activations play a key role in local detail synthesis, while having minimal impact on the overall semantic content of output. Building on these insights, we propose \\textbf{D}etail \\textbf{G}uidance (\\textbf{DG}), a MAs-driven, training-free self-guidance strategy to explicitly enhance local detail fidelity for DiTs. Specifically, DG constructs a degraded ``detail-deficient'' model by disrupting MAs and leverages it to guide the original network toward higher-quality detail synthesis. Our DG can seamlessly integrate with Classifier-Free Guidance (CFG), enabling further refinements of fine-grained details. Extensive experiments demonstrate that our DG consistently improves fine-grained detail quality across various pre-trained DiTs (\\eg, SD3, SD3.5, and Flux).",
        "tags": [
            "Diffusion",
            "FLUX"
        ]
    },
    {
        "id": "466",
        "title": "Query-Specific GNN: A Comprehensive Graph Representation Learning Method for Retrieval Augmented Generation",
        "author": [
            "Yuchen Yan",
            "Zhihua Liu",
            "Hao Wang",
            "Weiming Li",
            "Xiaoshuai Hao"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11541",
        "abstract": "Retrieval-augmented generation (RAG) has demonstrated its ability to enhance Large Language Models (LLMs) by integrating external knowledge sources. However, multi-hop questions, which require the identification of multiple knowledge targets to form a synthesized answer, raise new challenges for RAG systems. Under the multi-hop settings, existing methods often struggle to fully understand the questions with complex semantic structures and are susceptible to irrelevant noise during the retrieval of multiple information targets. To address these limitations, we propose a novel graph representation learning framework for multi-hop question retrieval. We first introduce a Multi-information Level Knowledge Graph (Multi-L KG) to model various information levels for a more comprehensive understanding of multi-hop questions. Based on this, we design a Query-Specific Graph Neural Network (QSGNN) for representation learning on the Multi-L KG. QSGNN employs intra/inter-level message passing mechanisms, and in each message passing the information aggregation is guided by the query, which not only facilitates multi-granular information aggregation but also significantly reduces the impact of noise. To enhance its ability to learn robust representations, we further propose two synthesized data generation strategies for pre-training the QSGNN. Extensive experimental results demonstrate the effectiveness of our framework in multi-hop scenarios, especially in high-hop questions the improvement can reach 33.8\\%. The code is available at: https://github.com/Jerry2398/QSGNN.",
        "tags": [
            "LLM",
            "RAG"
        ]
    },
    {
        "id": "467",
        "title": "NaviGait: Navigating Dynamically Feasible Gait Libraries using Deep Reinforcement Learning",
        "author": [
            "Neil C. Janwani",
            "Varun Madabushi",
            "Maegan Tucker"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11542",
        "abstract": "Reinforcement learning (RL) has emerged as a powerful method to learn robust control policies for bipedal locomotion. Yet, it can be difficult to tune desired robot behaviors due to unintuitive and complex reward design. In comparison, offline trajectory optimization methods, like Hybrid Zero Dynamics, offer more tuneable, interpretable, and mathematically grounded motion plans for high-dimensional legged systems. However, these methods often remain brittle to real-world disturbances like external perturbations.\nIn this work, we present NaviGait, a hierarchical framework that combines the structure of trajectory optimization with the adaptability of RL for robust and intuitive locomotion control. NaviGait leverages a library of offline-optimized gaits and smoothly interpolates between them to produce continuous reference motions in response to high-level commands. The policy provides both joint-level and velocity command residual corrections to modulate and stabilize the reference trajectories in the gait library. One notable advantage of NaviGait is that it dramatically simplifies reward design by encoding rich motion priors from trajectory optimization, reducing the need for finely tuned shaping terms and enabling more stable and interpretable learning. Our experimental results demonstrate that NaviGait enables faster training compared to conventional and imitation-based RL, and produces motions that remain closest to the original reference. Overall, by decoupling high-level motion generation from low-level correction, NaviGait offers a more scalable and generalizable approach for achieving dynamic and robust locomotion.",
        "tags": [
            "RL",
            "Robotics"
        ]
    },
    {
        "id": "468",
        "title": "Information-Preserving Reformulation of Reasoning Traces for Antidistillation",
        "author": [
            "Jiayu Ding",
            "Lei Cui",
            "Li Dong",
            "Nanning Zheng",
            "Furu Wei"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11545",
        "abstract": "Recent advances in Large Language Models (LLMs) show that extending the length of reasoning chains significantly improves performance on complex tasks. While revealing these reasoning traces helps users better follow, verify, and learn from the model's problem-solving process, it also makes them highly vulnerable to unauthorized distillation. To mitigate this risk, proprietary model providers often adopt aggressive protection strategies, such as replacing detailed reasoning with brief summaries, which deprive users of valuable intermediate information. To address this trade-off, we propose PART, an information-preserving antidistillation reformulation of reasoning traces. Motivated by the difference between how humans understand reasoning traces and how LLMs exploit them for supervised fine-tuning, we design a simple but effective two-step reformulation: removing self-talk behaviors and reordering sub-conclusions. A small auxiliary model is trained to perform this reformulation, incurring minimal computational overhead. Extensive experiments demonstrate that PART consistently disrupts distillation across student models of different sizes and types on various reasoning benchmarks. For instance, when training on reformulated traces, even the performance of a large 32B student model decreases from 54.17 to 46.88 on AIME 2024, corresponding to a 13.5% degradation.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "469",
        "title": "ODI-Bench: Can MLLMs Understand Immersive Omnidirectional Environments?",
        "author": [
            "Liu Yang",
            "Huiyu Duan",
            "Ran Tao",
            "Juntao Cheng",
            "Sijing Wu",
            "Yunhao Li",
            "Jing Liu",
            "Xiongkuo Min",
            "Guangtao Zhai"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11549",
        "abstract": "Omnidirectional images (ODIs) provide full 360x180 view which are widely adopted in VR, AR and embodied intelligence applications. While multi-modal large language models (MLLMs) have demonstrated remarkable performance on conventional 2D image and video understanding benchmarks, their ability to comprehend the immersive environments captured by ODIs remains largely unexplored. To address this gap, we first present ODI-Bench, a novel comprehensive benchmark specifically designed for omnidirectional image understanding. ODI-Bench contains 2,000 high-quality omnidirectional images and over 4,000 manually annotated question-answering (QA) pairs across 10 fine-grained tasks, covering both general-level and spatial-level ODI understanding. Extensive experiments are conducted to benchmark 20 representative MLLMs, including proprietary and open-source models, under both close-ended and open-ended settings. Experimental results reveal that current MLLMs still struggle to capture the immersive context provided by ODIs. To this end, we further introduce Omni-CoT, a training-free method which significantly enhances MLLMs' comprehension ability in the omnidirectional environment through chain-of-thought reasoning across both textual information and visual cues. Both the benchmark and the code will be released upon the publication.",
        "tags": [
            "CoT",
            "LLM"
        ]
    },
    {
        "id": "470",
        "title": "Robot Soccer Kit: Omniwheel Tracked Soccer Robots for Education",
        "author": [
            "Gregoire Passault",
            "Clement Gaspard",
            "Olivier Ly"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11552",
        "abstract": "Recent developments of low cost off-the-shelf programmable components, their modularity, and also rapid prototyping made educational robotics flourish, as it is accessible in most schools today. They allow to illustrate and embody theoretical problems in practical and tangible applications, and gather multidisciplinary skills. They also give a rich natural context for project-oriented pedagogy. However, most current robot kits all are limited to egocentric aspect of the robots perception. This makes it difficult to access more high-level problems involving e.g. coordinates or navigation. In this paper we introduce an educational holonomous robot kit that comes with an external tracking system, which lightens the constraint on embedded systems, but allows in the same time to discover high-level aspects of robotics, otherwise unreachable.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "471",
        "title": "Personalized and Constructive Feedback for Computer Science Students Using the Large Language Model (LLM)",
        "author": [
            "Javed Ali Khan",
            "Muhammad Yaqoob",
            "Mamoona Tasadduq",
            "Hafsa Shareef Dar",
            "Aitezaz Ahsan"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11556",
        "abstract": "The evolving pedagogy paradigms are leading toward educational transformations. One fundamental aspect of effective learning is relevant, immediate, and constructive feedback to students. Providing constructive feedback to large cohorts in academia is an ongoing challenge. Therefore, academics are moving towards automated assessment to provide immediate feedback. However, current approaches are often limited in scope, offering simplistic responses that do not provide students with personalized feedback to guide them toward improvements. This paper addresses this limitation by investigating the performance of Large Language Models (LLMs) in processing students assessments with predefined rubrics and marking criteria to generate personalized feedback for in-depth learning. We aim to leverage the power of existing LLMs for Marking Assessments, Tracking, and Evaluation (LLM-MATE) with personalized feedback to enhance students learning. To evaluate the performance of LLM-MATE, we consider the Software Architecture (SA) module as a case study. The LLM-MATE approach can help module leaders overcome assessment challenges with large cohorts. Also, it helps students improve their learning by obtaining personalized feedback in a timely manner. Additionally, the proposed approach will facilitate the establishment of ground truth for automating the generation of students assessment feedback using the ChatGPT API, thereby reducing the overhead associated with large cohort assessments.",
        "tags": [
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "472",
        "title": "Invisible Languages of the LLM Universe",
        "author": [
            "Saurabh Khanna",
            "Xinxu Li"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11557",
        "abstract": "Large Language Models are trained on massive multilingual corpora, yet this abundance masks a profound crisis: of the world's 7,613 living languages, approximately 2,000 languages with millions of speakers remain effectively invisible in digital ecosystems. We propose a critical framework connecting empirical measurements of language vitality (real world demographic strength) and digitality (online presence) with postcolonial theory and epistemic injustice to explain why linguistic inequality in AI systems is not incidental but structural. Analyzing data across all documented human languages, we identify four categories: Strongholds (33%, high vitality and digitality), Digital Echoes (6%, high digitality despite declining vitality), Fading Voices (36%, low on both dimensions), and critically, Invisible Giants (27%, high vitality but near-zero digitality) - languages spoken by millions yet absent from the LLM universe. We demonstrate that these patterns reflect continuities from colonial-era linguistic hierarchies to contemporary AI development, constituting what we term digital epistemic injustice. Our analysis reveals that English dominance in AI is not a technical necessity but an artifact of power structures that systematically exclude marginalized linguistic knowledge. We conclude with implications for decolonizing language technology and democratizing access to AI benefits.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "473",
        "title": "Zero Data Retention in LLM-based Enterprise AI Assistants: A Comparative Study of Market Leading Agentic AI Products",
        "author": [
            "Komal Gupta",
            "Aditya Shrivastava"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11558",
        "abstract": "Governance of data, compliance, and business privacy matters, particularly for healthcare and finance businesses. Since the recent emergence of AI enterprise AI assistants enhancing business productivity, safeguarding private data and compliance is now a priority. With the implementation of AI assistants across the enterprise, the zero data retention can be achieved by implementing zero data retention policies by Large Language Model businesses like Open AI and Anthropic and Meta. In this work, we explore zero data retention policies for the Enterprise apps of large language models (LLMs). Our key contribution is defining the architectural, compliance, and usability trade-offs of such systems in parallel. In this research work, we examine the development of commercial AI assistants with two industry leaders and market titans in this arena - Salesforce and Microsoft. Both of these companies used distinct technical architecture to support zero data retention policies. Salesforce AgentForce and Microsoft Copilot are among the leading AI assistants providing much-needed push to business productivity in customer care. The purpose of this paper is to analyze the technical architecture and deployment of zero data retention policy by consuming applications as well as big language models service providers like Open Ai, Anthropic, and Meta.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "474",
        "title": "Characterizing Web Search in The Age of Generative AI",
        "author": [
            "Elisabeth Kirsten",
            "Jost Grosse Perdekamp",
            "Mihir Upadhyay",
            "Krishna P. Gummadi",
            "Muhammad Bilal Zafar"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11560",
        "abstract": "The advent of LLMs has given rise to a new type of web search: Generative search, where LLMs retrieve web pages related to a query and generate a single, coherent text as a response. This output modality stands in stark contrast to traditional web search, where results are returned as a ranked list of independent web pages. In this paper, we ask: Along what dimensions do generative search outputs differ from traditional web search? We compare Google, a traditional web search engine, with four generative search engines from two providers (Google and OpenAI) across queries from four domains. Our analysis reveals intriguing differences. Most generative search engines cover a wider range of sources compared to web search. Generative search engines vary in the degree to which they rely on internal knowledge contained within the model parameters v.s. external knowledge retrieved from the web. Generative search engines surface varying sets of concepts, creating new opportunities for enhancing search diversity and serendipity. Our results also highlight the need for revisiting evaluation criteria for web search in the age of Generative AI.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "475",
        "title": "Ontolearn-A Framework for Large-scale OWL Class Expression Learning in Python",
        "author": [
            "Caglar Demir",
            "Alkid Baci",
            "N'Dah Jean Kouagou",
            "Leonie Nora Sieger",
            "Stefan Heindorf",
            "Simon Bin",
            "Lukas BlÃ¼baum",
            "Alexander Bigerl",
            "Axel-Cyrille Ngonga Ngomo"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11561",
        "abstract": "In this paper, we present Ontolearn-a framework for learning OWL class expressions over large knowledge graphs. Ontolearn contains efficient implementations of recent stateof-the-art symbolic and neuro-symbolic class expression learners including EvoLearner and DRILL. A learned OWL class expression can be used to classify instances in the knowledge graph. Furthermore, Ontolearn integrates a verbalization module based on an LLM to translate complex OWL class expressions into natural language sentences. By mapping OWL class expressions into respective SPARQL queries, Ontolearn can be easily used to operate over a remote triplestore. The source code of Ontolearn is available at https://github.com/dice-group/Ontolearn.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "476",
        "title": "Culturally-Aware Conversations: A Framework & Benchmark for LLMs",
        "author": [
            "Shreya Havaldar",
            "Sunny Rai",
            "Young-Min Cho",
            "Lyle Ungar"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11563",
        "abstract": "Existing benchmarks that measure cultural adaptation in LLMs are misaligned with the actual challenges these models face when interacting with users from diverse cultural backgrounds. In this work, we introduce the first framework and benchmark designed to evaluate LLMs in realistic, multicultural conversational settings. Grounded in sociocultural theory, our framework formalizes how linguistic style - a key element of cultural communication - is shaped by situational, relational, and cultural context. We construct a benchmark dataset based on this framework, annotated by culturally diverse raters, and propose a new set of desiderata for cross-cultural evaluation in NLP: conversational framing, stylistic sensitivity, and subjective correctness. We evaluate today's top LLMs on our benchmark and show that these models struggle with cultural adaptation in a conversational setting.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "477",
        "title": "SNAP: Towards Segmenting Anything in Any Point Cloud",
        "author": [
            "Aniket Gupta",
            "Hanhui Wang",
            "Charles Saunders",
            "Aruni RoyChowdhury",
            "Hanumant Singh",
            "Huaizu Jiang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11565",
        "abstract": "Interactive 3D point cloud segmentation enables efficient annotation of complex 3D scenes through user-guided prompts. However, current approaches are typically restricted in scope to a single domain (indoor or outdoor), and to a single form of user interaction (either spatial clicks or textual prompts). Moreover, training on multiple datasets often leads to negative transfer, resulting in domain-specific tools that lack generalizability. To address these limitations, we present \\textbf{SNAP} (\\textbf{S}egment a\\textbf{N}ything in \\textbf{A}ny \\textbf{P}oint cloud), a unified model for interactive 3D segmentation that supports both point-based and text-based prompts across diverse domains. Our approach achieves cross-domain generalizability by training on 7 datasets spanning indoor, outdoor, and aerial environments, while employing domain-adaptive normalization to prevent negative transfer. For text-prompted segmentation, we automatically generate mask proposals without human intervention and match them against CLIP embeddings of textual queries, enabling both panoptic and open-vocabulary segmentation. Extensive experiments demonstrate that SNAP consistently delivers high-quality segmentation results. We achieve state-of-the-art performance on 8 out of 9 zero-shot benchmarks for spatial-prompted segmentation and demonstrate competitive results on all 5 text-prompted benchmarks. These results show that a unified model can match or exceed specialized domain-specific approaches, providing a practical tool for scalable 3D annotation. Project page is at, https://neu-vi.github.io/SNAP/",
        "tags": [
            "3D",
            "CLIP",
            "Segmentation"
        ]
    },
    {
        "id": "478",
        "title": "SCOOP'D: Learning Mixed-Liquid-Solid Scooping via Sim2Real Generative Policy",
        "author": [
            "Kuanning Wang",
            "Yongchong Gu",
            "Yuqian Fu",
            "Zeyu Shangguan",
            "Sicheng He",
            "Xiangyang Xue",
            "Yanwei Fu",
            "Daniel Seita"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11566",
        "abstract": "Scooping items with tools such as spoons and ladles is common in daily life, ranging from assistive feeding to retrieving items from environmental disaster sites. However, developing a general and autonomous robotic scooping policy is challenging since it requires reasoning about complex tool-object interactions. Furthermore, scooping often involves manipulating deformable objects, such as granular media or liquids, which is challenging due to their infinite-dimensional configuration spaces and complex dynamics. We propose a method, SCOOP'D, which uses simulation from OmniGibson (built on NVIDIA Omniverse) to collect scooping demonstrations using algorithmic procedures that rely on privileged state information. Then, we use generative policies via diffusion to imitate demonstrations from observational input. We directly apply the learned policy in diverse real-world scenarios, testing its performance on various item quantities, item characteristics, and container types. In zero-shot deployment, our method demonstrates promising results across 465 trials in diverse scenarios, including objects of different difficulty levels that we categorize as \"Level 1\" and \"Level 2.\" SCOOP'D outperforms all baselines and ablations, suggesting that this is a promising approach to acquiring robotic scooping skills. Project page is at https://scoopdiff.github.io/.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "479",
        "title": "A Framework for Low-Effort Training Data Generation for Urban Semantic Segmentation",
        "author": [
            "Denis Zavadski",
            "Damjan KalÅ¡an",
            "Tim KÃ¼chler",
            "Haebom Lee",
            "Stefan Roth",
            "Carsten Rother"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11567",
        "abstract": "Synthetic datasets are widely used for training urban scene recognition models, but even highly realistic renderings show a noticeable gap to real imagery. This gap is particularly pronounced when adapting to a specific target domain, such as Cityscapes, where differences in architecture, vegetation, object appearance, and camera characteristics limit downstream performance. Closing this gap with more detailed 3D modelling would require expensive asset and scene design, defeating the purpose of low-cost labelled data. To address this, we present a new framework that adapts an off-the-shelf diffusion model to a target domain using only imperfect pseudo-labels. Once trained, it generates high-fidelity, target-aligned images from semantic maps of any synthetic dataset, including low-effort sources created in hours rather than months. The method filters suboptimal generations, rectifies image-label misalignments, and standardises semantics across datasets, transforming weak synthetic data into competitive real-domain training sets. Experiments on five synthetic datasets and two real target datasets show segmentation gains of up to +8.0%pt. mIoU over state-of-the-art translation methods, making rapidly constructed synthetic datasets as effective as high-effort, time-intensive synthetic datasets requiring extensive manual design. This work highlights a valuable collaborative paradigm where fast semantic prototyping, combined with generative models, enables scalable, high-quality training data creation for urban scene understanding.",
        "tags": [
            "3D",
            "Diffusion",
            "Segmentation"
        ]
    },
    {
        "id": "480",
        "title": "Bag of Tricks for Subverting Reasoning-based Safety Guardrails",
        "author": [
            "Shuo Chen",
            "Zhen Han",
            "Haokun Chen",
            "Bailan He",
            "Shengyun Si",
            "Jingpei Wu",
            "Philip Torr",
            "Volker Tresp",
            "Jindong Gu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11570",
        "abstract": "Recent reasoning-based safety guardrails for Large Reasoning Models (LRMs), such as deliberative alignment, have shown strong defense against jailbreak attacks. By leveraging LRMs' reasoning ability, these guardrails help the models to assess the safety of user inputs before generating final responses. The powerful reasoning ability can analyze the intention of the input query and will refuse to assist once it detects the harmful intent hidden by the jailbreak methods. Such guardrails have shown a significant boost in defense, such as the near-perfect refusal rates on the open-source gpt-oss series. Unfortunately, we find that these powerful reasoning-based guardrails can be extremely vulnerable to subtle manipulation of the input prompts, and once hijacked, can lead to even more harmful results. Specifically, we first uncover a surprisingly fragile aspect of these guardrails: simply adding a few template tokens to the input prompt can successfully bypass the seemingly powerful guardrails and lead to explicit and harmful responses. To explore further, we introduce a bag of jailbreak methods that subvert the reasoning-based guardrails. Our attacks span white-, gray-, and black-box settings and range from effortless template manipulations to fully automated optimization. Along with the potential for scalable implementation, these methods also achieve alarmingly high attack success rates (e.g., exceeding 90% across 5 different benchmarks on gpt-oss series on both local host models and online API services). Evaluations across various leading open-source LRMs confirm that these vulnerabilities are systemic, underscoring the urgent need for stronger alignment techniques for open-sourced LRMs to prevent malicious misuse. Code is open-sourced at https://chenxshuo.github.io/bag-of-tricks.",
        "tags": [
            "GPT"
        ]
    },
    {
        "id": "481",
        "title": "Survey Response Generation: Generating Closed-Ended Survey Responses In-Silico with Large Language Models",
        "author": [
            "Georg Ahnert",
            "Anna-Carolina Haensch",
            "Barbara Plank",
            "Markus Strohmaier"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11586",
        "abstract": "Many in-silico simulations of human survey responses with large language models (LLMs) focus on generating closed-ended survey responses, whereas LLMs are typically trained to generate open-ended text instead. Previous research has used a diverse range of methods for generating closed-ended survey responses with LLMs, and a standard practice remains to be identified. In this paper, we systematically investigate the impact that various Survey Response Generation Methods have on predicted survey responses. We present the results of 32 mio. simulated survey responses across 8 Survey Response Generation Methods, 4 political attitude surveys, and 10 open-weight language models. We find significant differences between the Survey Response Generation Methods in both individual-level and subpopulation-level alignment. Our results show that Restricted Generation Methods perform best overall, and that reasoning output does not consistently improve alignment. Our work underlines the significant impact that Survey Response Generation Methods have on simulated survey responses, and we develop practical recommendations on the application of Survey Response Generation Methods.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "482",
        "title": "Analyzing and Internalizing Complex Policy Documents for LLM Agents",
        "author": [
            "Jiateng Liu",
            "Zhenhailong Wang",
            "Xiaojiang Huang",
            "Yingjie Li",
            "Xing Fan",
            "Xiang Li",
            "Chenlei Guo",
            "Ruhi Sarikaya",
            "Heng Ji"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11588",
        "abstract": "Large Language Model (LLM)-based agentic systems rely on in-context policy documents encoding diverse business rules. As requirements grow, these documents expand rapidly, causing high computational overhead. This motivates developing internalization methods that embed policy documents into model priors while preserving performance. Prior prompt compression work targets generic prompts, but agentic policy documents span multiple complexity levels and require deeper reasoning, making internalization harder. We introduce CC-Gen, an agentic benchmark generator with Controllable Complexity across four levels, enabling systematic evaluation of agents' ability to handle complexity and offering a unified framework for assessing policy internalization. Our analysis shows that complex policy specifications governing workflows pose major reasoning challenges. Supporting internalization with gold user agent interaction trajectories containing chain-of-thought (CoT) annotations via supervised fine-tuning (SFT) is data-intensive and degrades sharply as policy complexity increases. To mitigate data and reasoning burdens, we propose Category-Aware Policy Continued Pretraining (CAP-CPT). Our automated pipeline parses policy documents to extract key specifications, grouping them into factual, behavioral, and conditional categories, and isolating complex conditions that drive workflow complexity. This guides targeted data synthesis and enables agents to internalize policy information through an autoregressive pretraining loss. Experiments show CAP-CPT improves SFT baselines in all settings, with up to 41% and 22% gains on Qwen-3-32B, achieving 97.3% prompt length reduction on CC-Gen and further enhancing tau-Bench with minimal SFT data.",
        "tags": [
            "CoT",
            "LLM",
            "Qwen"
        ]
    },
    {
        "id": "483",
        "title": "Diffusion-DFL: Decision-focused Diffusion Models for Stochastic Optimization",
        "author": [
            "Zihao Zhao",
            "Christopher Yeh",
            "Lingkai Kong",
            "Kai Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11590",
        "abstract": "Decision-focused learning (DFL) integrates predictive modeling and optimization by training predictors to optimize the downstream decision target rather than merely minimizing prediction error. To date, existing DFL methods typically rely on deterministic point predictions, which are often insufficient to capture the intrinsic stochasticity of real-world environments. To address this challenge, we propose the first diffusion-based DFL approach, which trains a diffusion model to represent the distribution of uncertain parameters and optimizes the decision by solving a stochastic optimization with samples drawn from the diffusion model. Our contributions are twofold. First, we formulate diffusion DFL using the reparameterization trick, enabling end-to-end training through diffusion. While effective, it is memory and compute-intensive due to the need to differentiate through the diffusion sampling process. Second, we propose a lightweight score function estimator that uses only several forward diffusion passes and avoids backpropagation through the sampling. This follows from our results that backpropagating through stochastic optimization can be approximated by a weighted score function formulation. We empirically show that our diffusion DFL approach consistently outperforms strong baselines in decision quality. The source code for all experiments is available at the project repository: https://github.com/GT-KOALA/Diffusion_DFL.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "484",
        "title": "MeTA-LoRA: Data-Efficient Multi-Task Fine-Tuning for Large Language Models",
        "author": [
            "Bo Cheng",
            "Xu Wang",
            "Jinda Liu",
            "Yi Chang",
            "Yuan Wu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11598",
        "abstract": "Low-Rank Adaptation (LoRA) has emerged as one of the most widely used parameter-efficient fine-tuning (PEFT) methods for adapting large language models (LLMs) to downstream tasks. While highly effective in single-task settings, it struggles to efficiently leverage inter-task knowledge in complex multi-task learning scenarios, often requiring substantial task-specific data to achieve optimal performance. To address this limitation, we introduce MeTA-LoRA, a two-stage optimization framework that significantly improves data efficiency in multi-task adaptation. In the first stage, task-specific LoRA adapters are learned using only a few samples from each involved dataset, enabling rapid adaptation without large-scale supervision. In the second stage, the shared LoRA adapter is updated by aggregating gradients from multiple tasks to promote knowledge transfer across tasks, further reducing data usage by leveraging common patterns. In both multi-task learning and multilingual learning scenarios, our method matches or surpasses the performance of traditional full-data LoRA fine-tuning approaches, while using significantly less task-specific data.",
        "tags": [
            "LLM",
            "LoRA"
        ]
    },
    {
        "id": "485",
        "title": "Deconstructing Attention: Investigating Design Principles for Effective Language Modeling",
        "author": [
            "Huiyin Xue",
            "Nafise Sadat Moosavi",
            "Nikolaos Aletras"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11602",
        "abstract": "The success of Transformer language models is widely credited to their dot-product attention mechanism, which interweaves a set of key design principles: mixing information across positions (enabling multi-token interactions), sequence-dependent activations (where attention weights adapt to each input), a specific mathematical form (dot-product similarities plus softmax weighting), and coupling of queries and keys to evolving hidden states (grounding attention in the current layer). However, the necessity of each of these principles remains largely untested. In this work, we systematically deconstruct attention by designing controlled variants that selectively relax these principles, applied both uniformly across all layers and in hybrid architectures where only some layers retain standard attention. Our empirical analysis reveals that mechanisms for mixing tokens are indispensable, as their absence collapses models to near-random behavior, while the exact mathematical form and sequence dependency can be substantially relaxed, especially when preserved in just a subset of layers. Surprisingly, even variants that fail in isolation can achieve robust performance when interleaved with standard attention, highlighting a cooperative effect. These findings deepen our understanding of what truly underpins attention's effectiveness and open new avenues for simplifying language models without sacrificing performance.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "486",
        "title": "ACE-G: Improving Generalization of Scene Coordinate Regression Through Query Pre-Training",
        "author": [
            "Leonard Bruns",
            "Axel Barroso-Laguna",
            "Tommaso Cavallari",
            "Ãron Monszpart",
            "Sowmya Munukutla",
            "Victor Adrian Prisacariu",
            "Eric Brachmann"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11605",
        "abstract": "Scene coordinate regression (SCR) has established itself as a promising learning-based approach to visual relocalization. After mere minutes of scene-specific training, SCR models estimate camera poses of query images with high accuracy. Still, SCR methods fall short of the generalization capabilities of more classical feature-matching approaches. When imaging conditions of query images, such as lighting or viewpoint, are too different from the training views, SCR models fail. Failing to generalize is an inherent limitation of previous SCR frameworks, since their training objective is to encode the training views in the weights of the coordinate regressor itself. The regressor essentially overfits to the training views, by design. We propose to separate the coordinate regressor and the map representation into a generic transformer and a scene-specific map code. This separation allows us to pre-train the transformer on tens of thousands of scenes. More importantly, it allows us to train the transformer to generalize from mapping images to unseen query images during pre-training. We demonstrate on multiple challenging relocalization datasets that our method, ACE-G, leads to significantly increased robustness while keeping the computational footprint attractive.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "487",
        "title": "ExpVid: A Benchmark for Experiment Video Understanding & Reasoning",
        "author": [
            "Yicheng Xu",
            "Yue Wu",
            "Jiashuo Yu",
            "Ziang Yan",
            "Tianxiang Jiang",
            "Yinan He",
            "Qingsong Zhao",
            "Kai Chen",
            "Yu Qiao",
            "Limin Wang",
            "Manabu Okumura",
            "Yi Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11606",
        "abstract": "Multimodal Large Language Models (MLLMs) hold promise for accelerating scientific discovery by interpreting complex experimental procedures. However, their true capabilities are poorly understood, as existing benchmarks neglect the fine-grained and long-horizon nature of authentic laboratory work, especially in wet-lab settings. To bridge this gap, we introduce ExpVid, the first benchmark designed to systematically evaluate MLLMs on scientific experiment videos. Curated from peer-reviewed video publications, ExpVid features a new three-level task hierarchy that mirrors the scientific process: (1) Fine-grained Perception of tools, materials, and actions; (2) Procedural Understanding of step order and completeness; and (3) Scientific Reasoning that connects the full experiment to its published conclusions. Our vision-centric annotation pipeline, combining automated generation with multi-disciplinary expert validation, ensures that tasks require visual grounding. We evaluate 19 leading MLLMs on ExpVid and find that while they excel at coarse-grained recognition, they struggle with disambiguating fine details, tracking state changes over time, and linking experimental procedures to scientific outcomes. Our results reveal a notable performance gap between proprietary and open-source models, particularly in high-order reasoning. ExpVid not only provides a diagnostic tool but also charts a roadmap for developing MLLMs capable of becoming trustworthy partners in scientific experimentation.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "488",
        "title": "ParaCook: On Time-Efficient Planning for Multi-Agent Systems",
        "author": [
            "Shiqi Zhang",
            "Xinbei Ma",
            "Yunqing Xu",
            "Zouying Cao",
            "Pengrui Lu",
            "Haobo Yuan",
            "Tiancheng Shen",
            "Zhuosheng Zhang",
            "Hai Zhao",
            "Ming-Hsuan Yang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11608",
        "abstract": "Large Language Models (LLMs) exhibit strong reasoning abilities for planning long-horizon, real-world tasks, yet existing agent benchmarks focus on task completion while neglecting time efficiency in parallel and asynchronous operations. To address this, we present ParaCook, a benchmark for time-efficient collaborative planning. Inspired by the Overcooked game, ParaCook provides an environment for various challenging interaction planning of multi-agent systems that are instantiated as cooking tasks, with a simplified action space to isolate the core challenge of strategic parallel planning. Through a comprehensive evaluation of state-of-the-art LLMs, we find that current approaches achieve suboptimal plans, which struggle with parallel actions or coordination. Our analysis also reveals LLMs' potential on abstract tasks where they can focus on high-level parallel optimization. ParaCook provides a scalable evaluation framework with adjustable complexity, establishing a foundation for developing and assessing time efficiency-aware multi-agent planning. The code and data are available at https://github.com/zsq259/ParaCook.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "489",
        "title": "High-resolution Photo Enhancement in Real-time: A Laplacian Pyramid Network",
        "author": [
            "Feng Zhang",
            "Haoyou Deng",
            "Zhiqiang Li",
            "Lida Li",
            "Bin Xu",
            "Qingbo Lu",
            "Zisheng Cao",
            "Minchen Wei",
            "Changxin Gao",
            "Nong Sang",
            "Xiang Bai"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11613",
        "abstract": "Photo enhancement plays a crucial role in augmenting the visual aesthetics of a photograph. In recent years, photo enhancement methods have either focused on enhancement performance, producing powerful models that cannot be deployed on edge devices, or prioritized computational efficiency, resulting in inadequate performance for real-world applications. To this end, this paper introduces a pyramid network called LLF-LUT++, which integrates global and local operators through closed-form Laplacian pyramid decomposition and reconstruction. This approach enables fast processing of high-resolution images while also achieving excellent performance. Specifically, we utilize an image-adaptive 3D LUT that capitalizes on the global tonal characteristics of downsampled images, while incorporating two distinct weight fusion strategies to achieve coarse global image enhancement. To implement this strategy, we designed a spatial-frequency transformer weight predictor that effectively extracts the desired distinct weights by leveraging frequency features. Additionally, we apply local Laplacian filters to adaptively refine edge details in high-frequency components. After meticulously redesigning the network structure and transformer model, LLF-LUT++ not only achieves a 2.64 dB improvement in PSNR on the HDR+ dataset, but also further reduces runtime, with 4K resolution images processed in just 13 ms on a single GPU. Extensive experimental results on two benchmark datasets further show that the proposed approach performs favorably compared to state-of-the-art methods. The source code will be made publicly available at https://github.com/fengzhang427/LLF-LUT.",
        "tags": [
            "3D",
            "Transformer"
        ]
    },
    {
        "id": "490",
        "title": "LLM-Oriented Token-Adaptive Knowledge Distillation",
        "author": [
            "Xurong Xie",
            "Zhucun Xue",
            "Jiafu Wu",
            "Jian Li",
            "Yabiao Wang",
            "Xiaobin Hu",
            "Yong Liu",
            "Jiangning Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11615",
        "abstract": "Knowledge distillation (KD) is a key technique for compressing large-scale language models (LLMs), yet prevailing logit-based methods typically employ static strategies that are misaligned with the dynamic learning process of student models. These methods typically treat all tokens indiscriminately and apply a single, fixed temperature, resulting in suboptimal knowledge transfer. To address these limitations, we propose LLM-Oriented Token-Adaptive Knowledge Distillation (AdaKD), a novel framework that adapts the distillation process to the real-time learning state of each token. AdaKD consists of two synergistic modules driven by a unified token difficulty metric. First, our Loss-Driven Adaptive Token Focusing (LATF) module dynamically adjusts the distillation focus by monitoring the student's learning stability, concentrating computational resources on the most valuable tokens at each training phase. Second, we introduce Inverse Difficulty Temperature Scaling (IDTS), a counterintuitive yet effective token-level temperature strategy. It employs low temperatures for difficult tokens for targeted error correction, and high temperatures for easy tokens to encourage students to learn from the teacher's complete and smooth output distribution, thereby enhancing generalization. As a plug-and-play framework, AdaKD can consistently improve the performance of various distillation methods on multiple model architectures and benchmarks.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "491",
        "title": "StoryBox: Collaborative Multi-Agent Simulation for Hybrid Bottom-Up Long-Form Story Generation Using Large Language Models",
        "author": [
            "Zehao Chen",
            "Rong Pan",
            "Haoran Li"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11618",
        "abstract": "Human writers often begin their stories with an overarching mental scene, where they envision the interactions between characters and their environment. Inspired by this creative process, we propose a novel approach to long-form story generation, termed hybrid bottom-up long-form story generation, using multi-agent simulations. In our method, agents interact within a dynamic sandbox environment, where their behaviors and interactions with one another and the environment generate emergent events. These events form the foundation for the story, enabling organic character development and plot progression. Unlike traditional top-down approaches that impose rigid structures, our hybrid bottom-up approach allows for the natural unfolding of events, fostering more spontaneous and engaging storytelling. The system is capable of generating stories exceeding 10,000 words while maintaining coherence and consistency, addressing some of the key challenges faced by current story generation models. We achieve state-of-the-art performance across several metrics. This approach offers a scalable and innovative solution for creating dynamic, immersive long-form stories that evolve organically from agent-driven interactions.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "492",
        "title": "Enhancing Long Chain-of-Thought Reasoning through Multi-Path Plan Aggregation",
        "author": [
            "Siheng Xiong",
            "Ali Payani",
            "Faramarz Fekri"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11620",
        "abstract": "Inference-time scaling enhances the reasoning ability of a language model (LM) by extending its chain-of-thought (CoT). However, existing approaches typically generate the entire reasoning chain in a single forward pass, which often leads to CoT derailment, i.e., the reasoning trajectory drifting off course due to compounding errors. This problem is particularly severe for smaller LMs with long CoTs due to their limited capacity. To address this, we analyze raw long CoTs and uncover a reasoning hierarchy consisting of planning and execution steps. Our analysis reveals that most reasoning errors stem from incorrect planning. Motivated by this observation, we propose Multi-Path Plan Aggregation (MPPA), a framework that augments single-pass reasoning with plan exploration and aggregation. Following a variable interval schedule based on the token position, MPPA generates multiple candidate plans and aggregates them into a refined planning step. To maintain efficiency, we adopt a minimal design in which the base LM serves as the primary policy, while a lightweight LoRA module implements the plan aggregation policy. We further observe that outcome-reward RL is inefficient for long trajectories (e.g., exceeding 4K tokens). To overcome this, we introduce online Step-DPO, a process-level preference optimization scheme that leverages Twisted Sequential Monte Carlo (TSMC) to provide scalable stepwise supervision using small LMs. This yields more efficient training, improved stability, and higher accuracy. Extensive experiments on challenging math, science, and logical reasoning benchmarks demonstrate that, with only 10% SFT data and 5% of preference pairs, our method outperforms both the DeepSeek-R1 distillation baseline and the outcome-reward RL baseline across multiple base models and tasks.",
        "tags": [
            "CoT",
            "DPO",
            "DeepSeek",
            "LoRA",
            "RL"
        ]
    },
    {
        "id": "493",
        "title": "EvoCAD: Evolutionary CAD Code Generation with Vision Language Models",
        "author": [
            "Tobias Preintner",
            "Weixuan Yuan",
            "Adrian KÃ¶nig",
            "Thomas BÃ¤ck",
            "Elena Raponi",
            "Niki van Stein"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11631",
        "abstract": "Combining large language models with evolutionary computation algorithms represents a promising research direction leveraging the remarkable generative and in-context learning capabilities of LLMs with the strengths of evolutionary algorithms. In this work, we present EvoCAD, a method for generating computer-aided design (CAD) objects through their symbolic representations using vision language models and evolutionary optimization. Our method samples multiple CAD objects, which are then optimized using an evolutionary approach with vision language and reasoning language models. We assess our method using GPT-4V and GPT-4o, evaluating it on the CADPrompt benchmark dataset and comparing it to prior methods. Additionally, we introduce two new metrics based on topological properties defined by the Euler characteristic, which capture a form of semantic similarity between 3D objects. Our results demonstrate that EvoCAD outperforms previous approaches on multiple metrics, particularly in generating topologically correct objects, which can be efficiently evaluated using our two novel metrics that complement existing spatial metrics.",
        "tags": [
            "3D",
            "GPT",
            "LLM",
            "VLM"
        ]
    },
    {
        "id": "494",
        "title": "LRQ-Solver: A Transformer-Based Neural Operator for Fast and Accurate Solving of Large-scale 3D PDEs",
        "author": [
            "Peijian Zeng",
            "Guan Wang",
            "Haohao Gu",
            "Xiaoguang Hu",
            "TiezhuGao",
            "Zhuowei Wang",
            "Aimin Yang",
            "Xiaoyu Song"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11636",
        "abstract": "Solving large-scale Partial Differential Equations (PDEs) on complex three-dimensional geometries represents a central challenge in scientific and engineering computing, often impeded by expensive pre-processing stages and substantial computational overhead. We introduce Low-Rank Query-based PDE Solver (LRQ-Solver), a physics-integrated framework engineered for rapid, accurate, and highly scalable simulations of industrial-grade models. This framework is built upon two primary technical innovations. First, our Parameter Conditioned Lagrangian Modeling (PCLM) approach explicitly couples local physical states with global design parameters, enabling robust predictions across varied simulation configurations. By embedding physical consistency directly into the learning architecture, PCLM ensures that predictions remain physically meaningful even under unseen design conditions, significantly enhancing generalization and reliability. Second, the Low-Rank Query Attention (LR-QA) module leverages the second-order statistics of physical fields to construct a global coherence kernel, reducing the computational complexity of attention from O(N2) to O(NC2 + C3). By replacing point-wise clustering with covariance decomposition, LRQ-Solver achieves exceptional scalability efficiently processing up to 2 million points on a single GPU. Validated on standard benchmarks, LRQ-Solver achieves a 38.9% error reduction on the DrivAer++ dataset and 28.76% on the 3D Beam dataset, alongside a training speedup of up to 50 times. Our results establish that LRQ-Solver offers a powerful paradigm for multi-configuration physics simulations, delivering a SOTA combination of accuracy, scalability, and efficiency. Code to reproduce the experiments is available at https://github.com/LilaKen/LRQ-Solver.",
        "tags": [
            "3D",
            "Transformer"
        ]
    },
    {
        "id": "495",
        "title": "IVEBench: Modern Benchmark Suite for Instruction-Guided Video Editing Assessment",
        "author": [
            "Yinan Chen",
            "Jiangning Zhang",
            "Teng Hu",
            "Yuxiang Zeng",
            "Zhucun Xue",
            "Qingdong He",
            "Chengjie Wang",
            "Yong Liu",
            "Xiaobin Hu",
            "Shuicheng Yan"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11647",
        "abstract": "Instruction-guided video editing has emerged as a rapidly advancing research direction, offering new opportunities for intuitive content transformation while also posing significant challenges for systematic evaluation. Existing video editing benchmarks fail to support the evaluation of instruction-guided video editing adequately and further suffer from limited source diversity, narrow task coverage and incomplete evaluation metrics. To address the above limitations, we introduce IVEBench, a modern benchmark suite specifically designed for instruction-guided video editing assessment. IVEBench comprises a diverse database of 600 high-quality source videos, spanning seven semantic dimensions, and covering video lengths ranging from 32 to 1,024 frames. It further includes 8 categories of editing tasks with 35 subcategories, whose prompts are generated and refined through large language models and expert review. Crucially, IVEBench establishes a three-dimensional evaluation protocol encompassing video quality, instruction compliance and video fidelity, integrating both traditional metrics and multimodal large language model-based assessments. Extensive experiments demonstrate the effectiveness of IVEBench in benchmarking state-of-the-art instruction-guided video editing methods, showing its ability to provide comprehensive and human-aligned evaluation outcomes.",
        "tags": [
            "LLM",
            "Video Editing"
        ]
    },
    {
        "id": "496",
        "title": "PhySIC: Physically Plausible 3D Human-Scene Interaction and Contact from a Single Image",
        "author": [
            "Pradyumna Yalandur Muralidhar",
            "Yuxuan Xue",
            "Xianghui Xie",
            "Margaret Kostyrko",
            "Gerard Pons-Moll"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11649",
        "abstract": "Reconstructing metrically accurate humans and their surrounding scenes from a single image is crucial for virtual reality, robotics, and comprehensive 3D scene understanding. However, existing methods struggle with depth ambiguity, occlusions, and physically inconsistent contacts. To address these challenges, we introduce PhySIC, a framework for physically plausible Human-Scene Interaction and Contact reconstruction. PhySIC recovers metrically consistent SMPL-X human meshes, dense scene surfaces, and vertex-level contact maps within a shared coordinate frame from a single RGB image. Starting from coarse monocular depth and body estimates, PhySIC performs occlusion-aware inpainting, fuses visible depth with unscaled geometry for a robust metric scaffold, and synthesizes missing support surfaces like floors. A confidence-weighted optimization refines body pose, camera parameters, and global scale by jointly enforcing depth alignment, contact priors, interpenetration avoidance, and 2D reprojection consistency. Explicit occlusion masking safeguards invisible regions against implausible configurations. PhySIC is efficient, requiring only 9 seconds for joint human-scene optimization and under 27 seconds end-to-end. It naturally handles multiple humans, enabling reconstruction of diverse interactions. Empirically, PhySIC outperforms single-image baselines, reducing mean per-vertex scene error from 641 mm to 227 mm, halving PA-MPJPE to 42 mm, and improving contact F1 from 0.09 to 0.51. Qualitative results show realistic foot-floor interactions, natural seating, and plausible reconstructions of heavily occluded furniture. By converting a single image into a physically plausible 3D human-scene pair, PhySIC advances scalable 3D scene understanding. Our implementation is publicly available at https://yuxuan-xue.com/physic.",
        "tags": [
            "3D",
            "Inpainting",
            "Robotics"
        ]
    },
    {
        "id": "497",
        "title": "InfiniHuman: Infinite 3D Human Creation with Precise Control",
        "author": [
            "Yuxuan Xue",
            "Xianghui Xie",
            "Margaret Kostyrko",
            "Gerard Pons-Moll"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11650",
        "abstract": "Generating realistic and controllable 3D human avatars is a long-standing challenge, particularly when covering broad attribute ranges such as ethnicity, age, clothing styles, and detailed body shapes. Capturing and annotating large-scale human datasets for training generative models is prohibitively expensive and limited in scale and diversity. The central question we address in this paper is: Can existing foundation models be distilled to generate theoretically unbounded, richly annotated 3D human data? We introduce InfiniHuman, a framework that synergistically distills these models to produce richly annotated human data at minimal cost and with theoretically unlimited scalability. We propose InfiniHumanData, a fully automatic pipeline that leverages vision-language and image generation models to create a large-scale multi-modal dataset. User study shows our automatically generated identities are undistinguishable from scan renderings. InfiniHumanData contains 111K identities spanning unprecedented diversity. Each identity is annotated with multi-granularity text descriptions, multi-view RGB images, detailed clothing images, and SMPL body-shape parameters. Building on this dataset, we propose InfiniHumanGen, a diffusion-based generative pipeline conditioned on text, body shape, and clothing assets. InfiniHumanGen enables fast, realistic, and precisely controllable avatar generation. Extensive experiments demonstrate significant improvements over state-of-the-art methods in visual quality, generation speed, and controllability. Our approach enables high-quality avatar generation with fine-grained control at effectively unbounded scale through a practical and affordable solution. We will publicly release the automatic data generation pipeline, the comprehensive InfiniHumanData dataset, and the InfiniHumanGen models at https://yuxuan-xue.com/infini-human.",
        "tags": [
            "3D",
            "Diffusion"
        ]
    },
    {
        "id": "498",
        "title": "ACADREASON: Exploring the Limits of Reasoning Models with Academic Research Problems",
        "author": [
            "Xin Gui",
            "King Zhu",
            "JinCheng Ren",
            "Qianben Chen",
            "Zekun Moore Wang",
            "Yizhi LI",
            "Xinpeng Liu",
            "Xiaowan Li",
            "Wenli Ren",
            "Linyu Miao",
            "Tianrui Qin",
            "Ziqi Shu",
            "He Zhu",
            "Xiangru Tang",
            "Dingfeng Shi",
            "Jiaheng Liu",
            "Yuchen Eleanor Jiang",
            "Minghao Liu",
            "Ge Zhang",
            "Wangchunshu Zhou"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11652",
        "abstract": "In recent years, the research focus of large language models (LLMs) and agents has shifted increasingly from demonstrating novel capabilities to complex reasoning and tackling challenging tasks. However, existing evaluations focus mainly on math/code contests or general tasks, while existing multi-domain academic benchmarks lack sufficient reasoning depth, leaving the field without a rigorous benchmark for high-level reasoning. To fill this gap, we introduce the Acadreason benchmark, designed to evaluate the ability of LLMs and agents to acquire and reason over academic knowledge. It consists of 50 expert-annotated academic problems across five high-reasoning domains, including computer science, economics, law, mathematics, and philosophy. All questions are sourced from top-tier publications in recent years and undergo rigorous annotation and quality control to ensure they are both challenging and answerable. We conduct systematic evaluations of over 10 mainstream LLMs and agents. The results show that most LLMs scored below 20 points, with even the cutting-edge GPT-5 achieving only 16 points. While agents achieved higher scores, none exceeded 40 points. This demonstrates the current capability gap between LLMs and agents in super-intelligent academic research tasks and highlights the challenges of Acadreason.",
        "tags": [
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "499",
        "title": "MATH-Beyond: A Benchmark for RL to Expand Beyond the Base Model",
        "author": [
            "Prasanna Mayilvahanan",
            "Ricardo Dominguez-Olmedo",
            "ThaddÃ¤us Wiedemer",
            "Wieland Brendel"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11653",
        "abstract": "With the advent of DeepSeek-R1, a new wave of reinforcement learning (RL) methods has emerged that seem to unlock stronger mathematical reasoning. However, a closer look at the open-source ecosystem reveals a critical limitation: with sufficiently many draws (e.g., $\\texttt{pass@1024}$), many existing base models already solve nearly all questions on widely used math benchmarks such as MATH-500 and AIME 2024. This suggests that the RL fine-tuning methods prevalent in the LLM reasoning literature largely sharpen existing solution modes rather than discovering entirely new ones. Such sharpening stands in contrast to the broader promise of RL: to foster exploration and to acquire new skills. To move beyond this plateau, we introduce MATH-Beyond (MATH-B), a benchmark deliberately constructed to defeat common open-source models of up to 8B parameters even under large sampling budgets. Improving performance on our benchmark via RL requires methods that learn to reason in ways that go beyond base model capabilities in repeated sampling. Since the problems are drawn from subsets of DAPO-Math-17K and DeepScaleR datasets, they remain topically equivalent to standard high-school math. Validating our premise, RL fine-tuned models such as Nemotron-Research-Reasoning-Qwen-1.5B and DeepScaleR-1.5B-Preview perform poorly on MATH-B at $\\texttt{pass@1024}$, showing how existing approaches fall short on tackling harder instances. We hope MATH-B will catalyze exploration-driven RL approaches that elicit deeper reasoning capabilities. We release MATH-B at https://huggingface.co/datasets/brendel-group/MATH-Beyond.",
        "tags": [
            "DeepSeek",
            "LLM",
            "Qwen",
            "RL"
        ]
    },
    {
        "id": "500",
        "title": "SR-Scientist: Scientific Equation Discovery With Agentic AI",
        "author": [
            "Shijie Xia",
            "Yuhan Sun",
            "Pengfei Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11661",
        "abstract": "Recently, Large Language Models (LLMs) have been applied to scientific equation discovery, leveraging their embedded scientific knowledge for hypothesis generation. However, current methods typically confine LLMs to the role of an equation proposer within search algorithms like genetic programming. In this paper, we present SR-Scientist, a framework that elevates the LLM from a simple equation proposer to an autonomous AI scientist that writes code to analyze data, implements the equation as code, submits it for evaluation, and optimizes the equation based on experimental feedback. Specifically, we wrap the code interpreter into a set of tools for data analysis and equation evaluation. The agent is instructed to optimize the equation by utilizing these tools over a long horizon with minimal human-defined pipelines. Empirical results show that SR-Scientist outperforms baseline methods by an absolute margin of 6% to 35% on datasets covering four science disciplines. Additionally, we demonstrate our method's robustness to noise, the generalization of the discovered equations to out-of-domain data, and their symbolic accuracy. Furthermore, we develop an end-to-end reinforcement learning framework to enhance the agent's capabilities.",
        "tags": [
            "LLM",
            "RL"
        ]
    },
    {
        "id": "501",
        "title": "Chronologically Consistent Generative AI",
        "author": [
            "Songrun He",
            "Linying Lv",
            "Asaf Manela",
            "Jimmy Wu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11677",
        "abstract": "We introduce a family of chronologically consistent, instruction-following large language models to eliminate lookahead bias. Each model is trained only on data available before a clearly defined knowledge-cutoff date, ensuring strict temporal separation from any post-cutoff data. The resulting framework offers (i) a simple, conversational chat interface, (ii) fully open, fixed model weights that guarantee replicability, and (iii) a conservative lower bound on forecast accuracy, isolating the share of predictability that survives once training leakage is removed. Together, these features provide researchers with an easy-to-use generative AI tool useful for a wide range of prediction tasks that is free of lookahead bias.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "502",
        "title": "Ego-Vision World Model for Humanoid Contact Planning",
        "author": [
            "Hang Liu",
            "Yuman Gao",
            "Sangli Teng",
            "Yufeng Chi",
            "Yakun Sophia Shao",
            "Zhongyu Li",
            "Maani Ghaffari",
            "Koushil Sreenath"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11682",
        "abstract": "Enabling humanoid robots to exploit physical contact, rather than simply avoid collisions, is crucial for autonomy in unstructured environments. Traditional optimization-based planners struggle with contact complexity, while on-policy reinforcement learning (RL) is sample-inefficient and has limited multi-task ability. We propose a framework combining a learned world model with sampling-based Model Predictive Control (MPC), trained on a demonstration-free offline dataset to predict future outcomes in a compressed latent space. To address sparse contact rewards and sensor noise, the MPC uses a learned surrogate value function for dense, robust planning. Our single, scalable model supports contact-aware tasks, including wall support after perturbation, blocking incoming objects, and traversing height-limited arches, with improved data efficiency and multi-task capability over on-policy RL. Deployed on a physical humanoid, our system achieves robust, real-time contact planning from proprioception and ego-centric depth images. Website: https://ego-vcp.github.io/",
        "tags": [
            "MPC",
            "RL"
        ]
    },
    {
        "id": "503",
        "title": "Boundary-Guided Policy Optimization for Memory-efficient RL of Diffusion Large Language Models",
        "author": [
            "Nianyi Lin",
            "Jiajie Zhang",
            "Lei Hou",
            "Juanzi Li"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11683",
        "abstract": "A key challenge in applying reinforcement learning (RL) to diffusion large language models (dLLMs) lies in the intractability of their likelihood functions, which are essential for the RL objective, necessitating corresponding approximation in each training step. While existing methods approximate the log-likelihoods by their evidence lower bounds (ELBOs) via customized Monte Carlo (MC) sampling, the forward computational graphs of all MC samples need to be retained for the gradient computation of non-linear terms in the RL objective, resulting in significant memory overhead. This constraint restricts feasible sample sizes, leading to imprecise likelihood approximations and ultimately distorting the RL objective. To overcome this limitation, we propose \\emph{Boundary-Guided Policy Optimization} (BGPO), a memory-efficient RL algorithm that maximizes a specially constructed lower bound of the ELBO-based objective. This lower bound is carefully designed to satisfy two key properties: (1) Linearity: it is formulated in a linear sum where each term depends only on a single MC sample, thereby enabling gradient accumulation across samples and ensuring constant memory usage; (2) Equivalence: Both the value and gradient of this lower bound are equal to those of the ELBO-based objective in on-policy training, making it also an effective approximation for the original RL objective. These properties allow BGPO to adopt a large MC sample size, resulting in more accurate likelihood approximations and improved RL objective estimation, which in turn leads to enhanced performance. Experiments show that BGPO significantly outperforms previous RL algorithms for dLLMs in math problem solving, code generation, and planning tasks.",
        "tags": [
            "Diffusion",
            "LLM",
            "RL"
        ]
    },
    {
        "id": "504",
        "title": "Representation-Based Exploration for Language Models: From Test-Time to Post-Training",
        "author": [
            "Jens Tuyls",
            "Dylan J. Foster",
            "Akshay Krishnamurthy",
            "Jordan T. Ash"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11686",
        "abstract": "Reinforcement learning (RL) promises to expand the capabilities of language models, but it is unclear if current RL techniques promote the discovery of novel behaviors, or simply sharpen those already present in the base model. In this paper, we investigate the value of deliberate exploration -- explicitly incentivizing the model to discover novel and diverse behaviors -- and aim to understand how the knowledge in pre-trained models can guide this search. Our main finding is that exploration with a simple, principled, representation-based bonus derived from the pre-trained language model's hidden states significantly improves diversity and pass@k rates -- both for post-training, and in a novel inference-time scaling setting we introduce. For inference-time, exploration with representation-based diversity improves efficiency, consistently improving pass@k rates across a variety of models and reasoning tasks. For example, for Qwen-2.5-14b-Instruct we obtain over 50% improvement in verifier efficiency on almost all tasks. For post-training, we show that integrating this exploration strategy into an RL pipeline improves reasoning performance over that of the initial model and over standard RL post-training. For example, on AIME 2024, our post-trained Qwen-2.5-7b-Instruct's pass@80 matches the pass@256 of GRPO on the same model, demonstrating a 3x improvement in test-time sample efficiency. Overall, our findings suggest that deliberate exploration -- with the right notion of diversity -- is a practical path toward discovery of new behaviors beyond sharpening.",
        "tags": [
            "GRPO",
            "Qwen",
            "RL"
        ]
    },
    {
        "id": "505",
        "title": "Beyond 'Templates': Category-Agnostic Object Pose, Size, and Shape Estimation from a Single View",
        "author": [
            "Jinyu Zhang",
            "Haitao Lin",
            "Jiashu Hou",
            "Xiangyang Xue",
            "Yanwei Fu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11687",
        "abstract": "Estimating an object's 6D pose, size, and shape from visual input is a fundamental problem in computer vision, with critical applications in robotic grasping and manipulation. Existing methods either rely on object-specific priors such as CAD models or templates, or suffer from limited generalization across categories due to pose-shape entanglement and multi-stage pipelines. In this work, we propose a unified, category-agnostic framework that simultaneously predicts 6D pose, size, and dense shape from a single RGB-D image, without requiring templates, CAD models, or category labels at test time. Our model fuses dense 2D features from vision foundation models with partial 3D point clouds using a Transformer encoder enhanced by a Mixture-of-Experts, and employs parallel decoders for pose-size estimation and shape reconstruction, achieving real-time inference at 28 FPS. Trained solely on synthetic data from 149 categories in the SOPE dataset, our framework is evaluated on four diverse benchmarks SOPE, ROPE, ObjaversePose, and HANDAL, spanning over 300 categories. It achieves state-of-the-art accuracy on seen categories while demonstrating remarkably strong zero-shot generalization to unseen real-world objects, establishing a new standard for open-set 6D understanding in robotics and embodied AI.",
        "tags": [
            "3D",
            "MoE",
            "RoPE",
            "Robotics",
            "Transformer"
        ]
    },
    {
        "id": "506",
        "title": "PACEbench: A Framework for Evaluating Practical AI Cyber-Exploitation Capabilities",
        "author": [
            "Zicheng Liu",
            "Lige Huang",
            "Jie Zhang",
            "Dongrui Liu",
            "Yuan Tian",
            "Jing Shao"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11688",
        "abstract": "The increasing autonomy of Large Language Models (LLMs) necessitates a rigorous evaluation of their potential to aid in cyber offense. Existing benchmarks often lack real-world complexity and are thus unable to accurately assess LLMs' cybersecurity capabilities. To address this gap, we introduce PACEbench, a practical AI cyber-exploitation benchmark built on the principles of realistic vulnerability difficulty, environmental complexity, and cyber defenses. Specifically, PACEbench comprises four scenarios spanning single, blended, chained, and defense vulnerability exploitations. To handle these complex challenges, we propose PACEagent, a novel agent that emulates human penetration testers by supporting multi-phase reconnaissance, analysis, and exploitation. Extensive experiments with seven frontier LLMs demonstrate that current models struggle with complex cyber scenarios, and none can bypass defenses. These findings suggest that current models do not yet pose a generalized cyber offense threat. Nonetheless, our work provides a robust benchmark to guide the trustworthy development of future models.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "507",
        "title": "Phys2Real: Fusing VLM Priors with Interactive Online Adaptation for Uncertainty-Aware Sim-to-Real Manipulation",
        "author": [
            "Maggie Wang",
            "Stephen Tian",
            "Aiden Swann",
            "Ola Shorinwa",
            "Jiajun Wu",
            "Mac Schwager"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11689",
        "abstract": "Learning robotic manipulation policies directly in the real world can be expensive and time-consuming. While reinforcement learning (RL) policies trained in simulation present a scalable alternative, effective sim-to-real transfer remains challenging, particularly for tasks that require precise dynamics. To address this, we propose Phys2Real, a real-to-sim-to-real RL pipeline that combines vision-language model (VLM)-inferred physical parameter estimates with interactive adaptation through uncertainty-aware fusion. Our approach consists of three core components: (1) high-fidelity geometric reconstruction with 3D Gaussian splatting, (2) VLM-inferred prior distributions over physical parameters, and (3) online physical parameter estimation from interaction data. Phys2Real conditions policies on interpretable physical parameters, refining VLM predictions with online estimates via ensemble-based uncertainty quantification. On planar pushing tasks of a T-block with varying center of mass (CoM) and a hammer with an off-center mass distribution, Phys2Real achieves substantial improvements over a domain randomization baseline: 100% vs 79% success rate for the bottom-weighted T-block, 57% vs 23% in the challenging top-weighted T-block, and 15% faster average task completion for hammer pushing. Ablation studies indicate that the combination of VLM and interaction information is essential for success. Project website: https://phys2real.github.io/ .",
        "tags": [
            "3D",
            "Gaussian Splatting",
            "RL",
            "VLM"
        ]
    },
    {
        "id": "508",
        "title": "Diffusion Transformers with Representation Autoencoders",
        "author": [
            "Boyang Zheng",
            "Nanye Ma",
            "Shengbang Tong",
            "Saining Xie"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11690",
        "abstract": "Latent generative modeling, where a pretrained autoencoder maps pixels into a latent space for the diffusion process, has become the standard strategy for Diffusion Transformers (DiT); however, the autoencoder component has barely evolved. Most DiTs continue to rely on the original VAE encoder, which introduces several limitations: outdated backbones that compromise architectural simplicity, low-dimensional latent spaces that restrict information capacity, and weak representations that result from purely reconstruction-based training and ultimately limit generative quality. In this work, we explore replacing the VAE with pretrained representation encoders (e.g., DINO, SigLIP, MAE) paired with trained decoders, forming what we term Representation Autoencoders (RAEs). These models provide both high-quality reconstructions and semantically rich latent spaces, while allowing for a scalable transformer-based architecture. Since these latent spaces are typically high-dimensional, a key challenge is enabling diffusion transformers to operate effectively within them. We analyze the sources of this difficulty, propose theoretically motivated solutions, and validate them empirically. Our approach achieves faster convergence without auxiliary representation alignment losses. Using a DiT variant equipped with a lightweight, wide DDT head, we achieve strong image generation results on ImageNet: 1.51 FID at 256x256 (no guidance) and 1.13 at both 256x256 and 512x512 (with guidance). RAE offers clear advantages and should be the new default for diffusion transformer training.",
        "tags": [
            "DiT",
            "Diffusion",
            "Transformer",
            "VAE"
        ]
    },
    {
        "id": "509",
        "title": "Scaling Language-Centric Omnimodal Representation Learning",
        "author": [
            "Chenghao Xiao",
            "Hou Pong Chan",
            "Hao Zhang",
            "Weiwen Xu",
            "Mahani Aljunied",
            "Yu Rong"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11693",
        "abstract": "Recent multimodal embedding approaches leveraging multimodal large language models (MLLMs) fine-tuned with contrastive learning (CL) have shown promising results, yet the underlying reasons behind their superiority remain underexplored. This work argues that a crucial advantage of MLLM-based approaches stems from implicit cross-modal alignment achieved during generative pretraining, where the language decoder learns to exploit multimodal signals within a shared representation space for generating unimodal outputs. Through analysis of anisotropy and kernel similarity structure, we empirically confirm that latent alignment emerges within MLLM representations, allowing CL to serve as a lightweight refinement stage. Leveraging this insight, we propose a Language-Centric Omnimodal Embedding framework, termed LCO-Emb. Extensive experiments across diverse backbones and benchmarks demonstrate its effectiveness, achieving state-of-the-art performance across modalities. Furthermore, we identify a Generation-Representation Scaling Law (GRSL), showing that the representational capabilities gained through contrastive refinement scales positively with the MLLM's generative capabilities. This suggests that improving generative abilities evolves as an effective paradigm for enhancing representation quality. We provide a theoretical explanation of GRSL, which formally links the MLLM's generative quality to the upper bound on its representation performance, and validate it on a challenging, low-resource visual-document retrieval task, showing that continual generative pretraining before CL can further enhance the potential of a model's embedding capabilities. Codes, models, and resources are available at https://github.com/LCO-Embedding/LCO-Embedding.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "510",
        "title": "When Agents Trade: Live Multi-Market Trading Benchmark for LLM Agents",
        "author": [
            "Lingfei Qian",
            "Xueqing Peng",
            "Yan Wang",
            "Vincent Jim Zhang",
            "Huan He",
            "Hanley Smith",
            "Yi Han",
            "Yueru He",
            "Haohang Li",
            "Yupeng Cao",
            "Yangyang Yu",
            "Alejandro Lopez-Lira",
            "Peng Lu",
            "Jian-Yun Nie",
            "Guojun Xiong",
            "Jimin Huang",
            "Sophia Ananiadou"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11695",
        "abstract": "Although Large Language Model (LLM)-based agents are increasingly used in financial trading, it remains unclear whether they can reason and adapt in live markets, as most studies test models instead of agents, cover limited periods and assets, and rely on unverified data. To address these gaps, we introduce Agent Market Arena (AMA), the first lifelong, real-time benchmark for evaluating LLM-based trading agents across multiple markets. AMA integrates verified trading data, expert-checked news, and diverse agent architectures within a unified trading framework, enabling fair and continuous comparison under real conditions. It implements four agents, including InvestorAgent as a single-agent baseline, TradeAgent and HedgeFundAgent with different risk styles, and DeepFundAgent with memory-based reasoning, and evaluates them across GPT-4o, GPT-4.1, Claude-3.5-haiku, Claude-sonnet-4, and Gemini-2.0-flash. Live experiments on both cryptocurrency and stock markets demonstrate that agent frameworks display markedly distinct behavioral patterns, spanning from aggressive risk-taking to conservative decision-making, whereas model backbones contribute less to outcome variation. AMA thus establishes a foundation for rigorous, reproducible, and continuously evolving evaluation of financial reasoning and trading intelligence in LLM-based agents.",
        "tags": [
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "511",
        "title": "QeRL: Beyond Efficiency -- Quantization-enhanced Reinforcement Learning for LLMs",
        "author": [
            "Wei Huang",
            "Yi Ge",
            "Shuai Yang",
            "Yicheng Xiao",
            "Huizi Mao",
            "Yujun Lin",
            "Hanrong Ye",
            "Sifei Liu",
            "Ka Chun Cheung",
            "Hongxu Yin",
            "Yao Lu",
            "Xiaojuan Qi",
            "Song Han",
            "Yukang Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11696",
        "abstract": "We propose QeRL, a Quantization-enhanced Reinforcement Learning framework for large language models (LLMs). While RL is essential for LLMs' reasoning capabilities, it is resource-intensive, requiring substantial GPU memory and long rollout durations. QeRL addresses these issues by combining NVFP4 quantization with Low-Rank Adaptation (LoRA), accelerating rollout phase of RL while reducing memory overhead. Beyond efficiency, our findings show that quantization noise increases policy entropy, enhancing exploration, and enabling the discovery of better strategies during RL. To further optimize exploration, QeRL introduces an Adaptive Quantization Noise (AQN) mechanism, which dynamically adjusts noise during training. Experiments demonstrate that QeRL delivers over 1.5 times speedup in the rollout phase. Moreover, this is the first framework to enable RL training of a 32B LLM on a single H100 80GB GPU, while delivering overall speedups for RL training. It also achieves faster reward growth and higher final accuracy than 16-bit LoRA and QLoRA, while matching the performance of full-parameter fine-tuning on mathematical benchmarks such as GSM8K (90.8%) and MATH 500 (77.4%) in the 7B model. These results establish QeRL as an efficient and effective framework for RL training in LLMs.",
        "tags": [
            "LLM",
            "LoRA",
            "RL"
        ]
    },
    {
        "id": "512",
        "title": "Demystifying Reinforcement Learning in Agentic Reasoning",
        "author": [
            "Zhaochen Yu",
            "Ling Yang",
            "Jiaru Zou",
            "Shuicheng Yan",
            "Mengdi Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11701",
        "abstract": "Recently, the emergence of agentic RL has showcased that RL could also effectively improve the agentic reasoning ability of LLMs, yet the key design principles and optimal practices remain unclear. In this work, we conduct a comprehensive and systematic investigation to demystify reinforcement learning in agentic reasoning from three key perspectives: data, algorithm, and reasoning mode. We highlight our key insights: (i) Replacing stitched synthetic trajectories with real end-to-end tool-use trajectories yields a far stronger SFT initialization; high-diversity, model-aware datasets sustain exploration and markedly improve RL performance. (ii) Exploration-friendly techniques are crucial for agentic RL, such as clip higher, overlong reward shaping, and maintaining adequate policy entropy could improve the training efficiency. (iii) A deliberative strategy with fewer tool calls outperforms frequent tool calls or verbose self-reasoning, improving tool efficiency and final accuracy. Together, these simple practices consistently enhance agentic reasoning and training efficiency, achieving strong results on challenging benchmarks with smaller models, and establishing a practical baseline for future agentic RL research. Beyond these empirical insights, we further contribute a high-quality, real end-to-end agentic SFT dataset along with a high-quality RL dataset, and demonstrate the effectiveness of our insights in boosting the agentic reasoning ability of LLMs across four challenging benchmarks, including AIME2024/AIME2025, GPQA-Diamond, and LiveCodeBench-v6. With our recipes, 4B-sized models could also achieve superior agentic reasoning performance compared to 32B-sized models. Code and models: https://github.com/Gen-Verse/Open-AgentRL",
        "tags": [
            "CLIP",
            "LLM",
            "RL"
        ]
    },
    {
        "id": "513",
        "title": "Reinforced sequential Monte Carlo for amortised sampling",
        "author": [
            "Sanghyeok Choi",
            "Sarthak Mittal",
            "VÃ­ctor Elvira",
            "Jinkyoo Park",
            "Nikolay Malkin"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11711",
        "abstract": "This paper proposes a synergy of amortised and particle-based methods for sampling from distributions defined by unnormalised density functions. We state a connection between sequential Monte Carlo (SMC) and neural sequential samplers trained by maximum-entropy reinforcement learning (MaxEnt RL), wherein learnt sampling policies and value functions define proposal kernels and twist functions. Exploiting this connection, we introduce an off-policy RL training procedure for the sampler that uses samples from SMC -- using the learnt sampler as a proposal -- as a behaviour policy that better explores the target distribution. We describe techniques for stable joint training of proposals and twist functions and an adaptive weight tempering scheme to reduce training signal variance. Furthermore, building upon past attempts to use experience replay to guide the training of neural samplers, we derive a way to combine historical samples with annealed importance sampling weights within a replay buffer. On synthetic multi-modal targets (in both continuous and discrete spaces) and the Boltzmann distribution of alanine dipeptide conformations, we demonstrate improvements in approximating the true distribution as well as training stability compared to both amortised and Monte Carlo methods.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "514",
        "title": "DiT360: High-Fidelity Panoramic Image Generation via Hybrid Training",
        "author": [
            "Haoran Feng",
            "Dizhe Zhang",
            "Xiangtai Li",
            "Bo Du",
            "Lu Qi"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11712",
        "abstract": "In this work, we propose DiT360, a DiT-based framework that performs hybrid training on perspective and panoramic data for panoramic image generation. For the issues of maintaining geometric fidelity and photorealism in generation quality, we attribute the main reason to the lack of large-scale, high-quality, real-world panoramic data, where such a data-centric view differs from prior methods that focus on model design. Basically, DiT360 has several key modules for inter-domain transformation and intra-domain augmentation, applied at both the pre-VAE image level and the post-VAE token level. At the image level, we incorporate cross-domain knowledge through perspective image guidance and panoramic refinement, which enhance perceptual quality while regularizing diversity and photorealism. At the token level, hybrid supervision is applied across multiple modules, which include circular padding for boundary continuity, yaw loss for rotational robustness, and cube loss for distortion awareness. Extensive experiments on text-to-panorama, inpainting, and outpainting tasks demonstrate that our method achieves better boundary consistency and image fidelity across eleven quantitative metrics. Our code is available at https://github.com/Insta360-Research-Team/DiT360.",
        "tags": [
            "DiT",
            "Inpainting",
            "VAE"
        ]
    },
    {
        "id": "515",
        "title": "Point Prompting: Counterfactual Tracking with Video Diffusion Models",
        "author": [
            "Ayush Shrivastava",
            "Sanyam Mehta",
            "Daniel Geng",
            "Andrew Owens"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11715",
        "abstract": "Trackers and video generators solve closely related problems: the former analyze motion, while the latter synthesize it. We show that this connection enables pretrained video diffusion models to perform zero-shot point tracking by simply prompting them to visually mark points as they move over time. We place a distinctively colored marker at the query point, then regenerate the rest of the video from an intermediate noise level. This propagates the marker across frames, tracing the point's trajectory. To ensure that the marker remains visible in this counterfactual generation, despite such markers being unlikely in natural videos, we use the unedited initial frame as a negative prompt. Through experiments with multiple image-conditioned video diffusion models, we find that these \"emergent\" tracks outperform those of prior zero-shot methods and persist through occlusions, often obtaining performance that is competitive with specialized self-supervised models.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "516",
        "title": "Ev4DGS: Novel-view Rendering of Non-Rigid Objects from Monocular Event Streams",
        "author": [
            "Takuya Nakabayashi",
            "Navami Kairanda",
            "Hideo Saito",
            "Vladislav Golyanik"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11717",
        "abstract": "Event cameras offer various advantages for novel view rendering compared to synchronously operating RGB cameras, and efficient event-based techniques supporting rigid scenes have been recently demonstrated in the literature. In the case of non-rigid objects, however, existing approaches additionally require sparse RGB inputs, which can be a substantial practical limitation; it remains unknown if similar models could be learned from event streams only. This paper sheds light on this challenging open question and introduces Ev4DGS, i.e., the first approach for novel view rendering of non-rigidly deforming objects in the explicit observation space (i.e., as RGB or greyscale images) from monocular event streams. Our method regresses a deformable 3D Gaussian Splatting representation through 1) a loss relating the outputs of the estimated model with the 2D event observation space, and 2) a coarse 3D deformation model trained from binary masks generated from events. We perform experimental comparisons on existing synthetic and newly recorded real datasets with non-rigid objects. The results demonstrate the validity of Ev4DGS and its superior performance compared to multiple naive baselines that can be applied in our setting. We will release our models and the datasets used in the evaluation for research purposes; see the project webpage: https://4dqv.mpi-inf.mpg.de/Ev4DGS/.",
        "tags": [
            "3D",
            "Gaussian Splatting"
        ]
    },
    {
        "id": "517",
        "title": "CodePlot-CoT: Mathematical Visual Reasoning by Thinking with Code-Driven Images",
        "author": [
            "Chengqi Duan",
            "Kaiyue Sun",
            "Rongyao Fang",
            "Manyuan Zhang",
            "Yan Feng",
            "Ying Luo",
            "Yufang Liu",
            "Ke Wang",
            "Peng Pei",
            "Xunliang Cai",
            "Hongsheng Li",
            "Yi Ma",
            "Xihui Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11718",
        "abstract": "Recent advances in Large Language Models (LLMs) and Vision Language Models (VLMs) have shown significant progress in mathematical reasoning, yet they still face a critical bottleneck with problems requiring visual assistance, such as drawing auxiliary lines or plotting functions to solve the problems. Most LLMs and VLMs are constrained to text-only reasoning chains, while multimodal unified models that can generate interleaved text and images lack the necessary precision and controllability for such tasks. To address this, we propose CodePlot-CoT, a code-driven Chain-of-Thought paradigm for \"thinking with images\" in mathematics. Our approach leverages the VLM to generate text reasoning as well as executable plotting code, which is then rendered into images as \"visual thought\", to solve mathematical problems. To achieve this, we first construct Math-VR, the first large-scale, bilingual dataset and benchmark for Mathematics problems with Visual Reasoning, comprising 178K samples. Second, to create high-quality training data, we develop a state-of-the-art image-to-code converter specialized for parsing complex mathematical figures into codes. Finally, using these training data, we train the CodePlot-CoT model for solving mathematical problems. Experimental results show that our model achieves up to 21% increase over base model on our new benchmark, fully validating the efficacy of our proposed code-driven reasoning paradigm. Our work opens a new direction for multimodal mathematical reasoning and provides the community with the first large-scale dataset, comprehensive benchmark, and strong approach for such problems. To facilitate future research, we make our datasets, code, and pretrained models publicly available at https://github.com/HKU-MMLab/Math-VR-CodePlot-CoT.",
        "tags": [
            "CoT",
            "LLM",
            "VLM"
        ]
    },
    {
        "id": "518",
        "title": "Neural variational inference for cutting feedback during uncertainty propagation",
        "author": [
            "Jiafang Song",
            "Sandipan Pramanik",
            "Abhirup Datta"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10268",
        "abstract": "In many scientific applications, uncertainty of estimates from an earlier (upstream) analysis needs to be propagated in subsequent (downstream) Bayesian analysis, without feedback. Cutting feedback methods, also termed cut-Bayes, achieve this by constructing a cut-posterior distribution that prevents backward information flow. Cutting feedback like nested MCMC is computationally challenging while variational inference (VI) cut-Bayes methods need two variational approximations and require access to the upstream data and model. In this manuscript we propose, NeVI-Cut, a provably accurate and modular neural network-based variational inference method for cutting feedback. We directly utilize samples from the upstream analysis without requiring access to the upstream data or model. This simultaneously preserves modularity of analysis and reduces approximation errors by avoiding a variational approximation for the upstream model. We then use normalizing flows to specify the conditional variational family for the downstream parameters and estimate the conditional cut-posterior as a variational solution of Monte Carlo average loss over all the upstream samples. We provide theoretical guarantees on the NeVI-Cut estimate to approximate any cut-posterior. Our results are in a fixed-data regime and provide convergence rates of the actual variational solution, quantifying how richness of the neural architecture and the complexity of the target cut-posterior dictate the approximation quality. In the process, we establish new results on uniform Kullback-Leibler approximation rates of conditional normalizing flows. Simulation studies and two real-world analyses illustrate how NeVI-Cut achieves significant computational gains over traditional cutting feedback methods and is considerably more accurate than parametric variational cut approaches.",
        "tags": [
            "Normalizing Flows"
        ]
    },
    {
        "id": "519",
        "title": "Generative Modeling of Aerosol State Representations",
        "author": [
            "Ehsan Saleh",
            "Saba Ghaffari",
            "Jeffrey H. Curtis",
            "Lekha Patel",
            "Peter A. Bosler",
            "Nicole Riemer",
            "Matthew West"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10361",
        "abstract": "Aerosol-cloud--radiation interactions remain among the most uncertain components of the Earth's climate system, in partdue to the high dimensionality of aerosol state representations and the difficulty of obtaining complete \\textit{in situ} measurements. Addressing these challenges requires methods that distill complex aerosol properties into compact yet physically meaningful forms. Generative autoencoder models provide such a pathway. We present a framework for learning deep variational autoencoder (VAE) models of speciated mass and number concentration distributions, which capture detailed aerosol size-composition characteristics. By compressing hundreds of original dimensions into ten latent variables, the approach enables efficient storage and processing while preserving the fidelity of key diagnostics, including cloud condensation nuclei (CCN) spectra, optical scattering and absorption coefficients, and ice nucleation properties. Results show that CCN spectra are easiest to reconstruct accurately, optical properties are moderately difficult, and ice nucleation properties are the most challenging. To improve performance, we introduce a preprocessing optimization strategy that avoids repeated retraining and yields latent representations resilient to high-magnitude Gaussian noise, boosting accuracy for CCN spectra, optical coefficients, and frozen fraction spectra. Finally, we propose a novel realism metric -- based on the sliced Wasserstein distance between generated samples and a held-out test set -- for optimizing the KL divergence weight in VAEs. Together, these contributions enable compact, robust, and physically meaningful representations of aerosol states for large-scale climate applications.",
        "tags": [
            "VAE"
        ]
    },
    {
        "id": "520",
        "title": "Towards Efficient 3D Gaussian Human Avatar Compression: A Prior-Guided Framework",
        "author": [
            "Shanzhi Yin",
            "Bolin Chen",
            "Xinju Wu",
            "Ru-Ling Liao",
            "Jie Chen",
            "Shiqi Wang",
            "Yan Ye"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10492",
        "abstract": "This paper proposes an efficient 3D avatar coding framework that leverages compact human priors and canonical-to-target transformation to enable high-quality 3D human avatar video compression at ultra-low bit rates. The framework begins by training a canonical Gaussian avatar using articulated splatting in a network-free manner, which serves as the foundation for avatar appearance modeling. Simultaneously, a human-prior template is employed to capture temporal body movements through compact parametric representations. This decomposition of appearance and temporal evolution minimizes redundancy, enabling efficient compression: the canonical avatar is shared across the sequence, requiring compression only once, while the temporal parameters, consisting of just 94 parameters per frame, are transmitted with minimal bit-rate. For each frame, the target human avatar is generated by deforming canonical avatar via Linear Blend Skinning transformation, facilitating temporal coherent video reconstruction and novel view synthesis. Experimental results demonstrate that the proposed method significantly outperforms conventional 2D/3D codecs and existing learnable dynamic 3D Gaussian splatting compression method in terms of rate-distortion performance on mainstream multi-view human video datasets, paving the way for seamless immersive multimedia experiences in meta-verse applications.",
        "tags": [
            "3D",
            "Gaussian Splatting"
        ]
    },
    {
        "id": "521",
        "title": "Integrating Large Language Models and Reinforcement Learning for Sentiment-Driven Quantitative Trading",
        "author": [
            "Wo Long",
            "Wenxin Zeng",
            "Xiaoyu Zhang",
            "Ziyao Zhou"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10526",
        "abstract": "This research develops a sentiment-driven quantitative trading system that leverages a large language model, FinGPT, for sentiment analysis, and explores a novel method for signal integration using a reinforcement learning algorithm, Twin Delayed Deep Deterministic Policy Gradient (TD3). We compare the performance of strategies that integrate sentiment and technical signals using both a conventional rule-based approach and a reinforcement learning framework. The results suggest that sentiment signals generated by FinGPT offer value when combined with traditional technical indicators, and that reinforcement learning algorithm presents a promising approach for effectively integrating heterogeneous signals in dynamic trading environments.",
        "tags": [
            "LLM",
            "RL"
        ]
    },
    {
        "id": "522",
        "title": "Identifying and Quantifying Financial Bubbles with the Hyped Log-Periodic Power Law Model",
        "author": [
            "Zheng Cao",
            "Xingran Shao",
            "Yuheng Yan",
            "Helyette Geman"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10878",
        "abstract": "We propose a novel model, the Hyped Log-Periodic Power Law Model (HLPPL), to the problem of quantifying and detecting financial bubbles, an ever-fascinating one for academics and practitioners alike. Bubble labels are generated using a Log-Periodic Power Law (LPPL) model, sentiment scores, and a hype index we introduced in previous research on NLP forecasting of stock return volatility. Using these tools, a dual-stream transformer model is trained with market data and machine learning methods, resulting in a time series of confidence scores as a Bubble Score. A distinctive feature of our framework is that it captures phases of extreme overpricing and underpricing within a unified structure.\nWe achieve an average yield of 34.13 percentage annualized return when backtesting U.S. equities during the period 2018 to 2024, while the approach exhibits a remarkable generalization ability across industry sectors. Its conservative bias in predicting bubble periods minimizes false positives, a feature which is especially beneficial for market signaling and decision-making. Overall, this approach utilizes both theoretical and empirical advances for real-time positive and negative bubble identification and measurement with HLPPL signals.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "523",
        "title": "In-Context Learning Is Provably Bayesian Inference: A Generalization Theory for Meta-Learning",
        "author": [
            "Tomoya Wakayama",
            "Taiji Suzuki"
        ],
        "pdf": "https://arxiv.org/pdf/2510.10981",
        "abstract": "This paper develops a finite-sample statistical theory for in-context learning (ICL), analyzed within a meta-learning framework that accommodates mixtures of diverse task types. We introduce a principled risk decomposition that separates the total ICL risk into two orthogonal components: Bayes Gap and Posterior Variance. The Bayes Gap quantifies how well the trained model approximates the Bayes-optimal in-context predictor. For a uniform-attention Transformer, we derive a non-asymptotic upper bound on this gap, which explicitly clarifies the dependence on the number of pretraining prompts and their context length. The Posterior Variance is a model-independent risk representing the intrinsic task uncertainty. Our key finding is that this term is determined solely by the difficulty of the true underlying task, while the uncertainty arising from the task mixture vanishes exponentially fast with only a few in-context examples. Together, these results provide a unified view of ICL: the Transformer selects the optimal meta-algorithm during pretraining and rapidly converges to the optimal algorithm for the true task at test time.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "524",
        "title": "CSI Prediction Using Diffusion Models",
        "author": [
            "Mehdi Sattari",
            "Javad Aliakbari",
            "Alexandre Graell i Amat",
            "Tommy Svensson"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11214",
        "abstract": "Acquiring accurate channel state information (CSI) is critical for reliable and efficient wireless communication, but challenges such as high pilot overhead and channel aging hinder timely and accurate CSI acquisition. CSI prediction, which forecasts future CSI from historical observations, offers a promising solution. Recent deep learning approaches, including recurrent neural networks and Transformers, have achieved notable success but typically learn deterministic mappings, limiting their ability to capture the stochastic and multimodal nature of wireless channels. In this paper, we introduce a novel probabilistic framework for CSI prediction based on diffusion models, offering a flexible design that supports integration of diverse prediction schemes. We decompose the CSI prediction task into two components: a temporal encoder, which extracts channel dynamics, and a diffusion-based generator, which produces future CSI samples. We investigate two inference schemes-autoregressive and sequence-to-sequence- and explore multiple diffusion backbones, including U-Net and Transformer-based architectures. Furthermore, we examine a diffusion-based approach without an explicit temporal encoder and utilize the DDIM scheduling to reduce model complexity. Extensive simulations demonstrate that our diffusion-based models significantly outperform state-of-the-art baselines.",
        "tags": [
            "DDIM",
            "Diffusion",
            "Transformer"
        ]
    },
    {
        "id": "525",
        "title": "Hierarchical Qubit-Merging Transformer for Quantum Error Correction",
        "author": [
            "Seong-Joon Park",
            "Hee-Youl Kwak",
            "Yongjune Kim"
        ],
        "pdf": "https://arxiv.org/pdf/2510.11593",
        "abstract": "For reliable large-scale quantum computation, a quantum error correction (QEC) scheme must effectively resolve physical errors to protect logical information. Leveraging recent advances in deep learning, neural network-based decoders have emerged as a promising approach to enhance the reliability of QEC. We propose the Hierarchical Qubit-Merging Transformer (HQMT), a novel and general decoding framework that explicitly leverages the structural graph of stabilizer codes to learn error correlations across multiple scales. Our architecture first computes attention locally on structurally related groups of stabilizers and then systematically merges these qubit-centric representations to build a global view of the error syndrome. The proposed HQMT achieves substantially lower logical error rates for surface codes by integrating a dedicated qubit-merging layer within the transformer architecture. Across various code distances, HQMT significantly outperforms previous neural network-based QEC decoders as well as a powerful belief propagation with ordered statistics decoding (BP+OSD) baseline. This hierarchical approach provides a scalable and effective framework for surface code decoding, advancing the realization of reliable quantum computing.",
        "tags": [
            "Transformer"
        ]
    }
]