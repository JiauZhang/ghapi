[
    {
        "id": "1",
        "title": "Excitation of Looped Bistable Bands for High-Speed Linear Actuation",
        "author": [
            "Sareum Kim",
            "Josie Hughes"
        ],
        "pdf": "https://arxiv.org/pdf/2510.19834",
        "abstract": "Soft robotics increasingly relies on smart materials and innovative structures, with bistable tape springs emerging as a promising option. These structures exhibit intriguing dynamic behaviors, such as oscillation, due to their inherent bistability. This paper explores the high-speed linear amplification of motion achieved through the excitation of a looped bistable tape spring. When looped, the tape spring forms two distinct joints, facilitating smooth oscillation. Mounted on a linear guide and driven by a crank mechanism with varying frequency, the system converts input oscillations into amplified linear motion at resonance. This study highlights the potential of bistable tape springs high speed reciprocating linear motion.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "2",
        "title": "Benchmarking Reasoning Reliability in Artificial Intelligence Models for Energy-System Analysis",
        "author": [
            "Eliseo Curcio"
        ],
        "pdf": "https://arxiv.org/pdf/2510.19836",
        "abstract": "Artificial intelligence and machine learning are increasingly used for forecasting, optimization, and policy design in the energy sector, yet no standardized framework exists to evaluate whether these systems reason correctly. Current validation practices focus on predictive accuracy or computational efficiency, leaving the logical integrity of analytical conclusions untested. This study introduces the Analytical Reliability Benchmark (ARB), a reproducible framework that quantifies reasoning reliability in large language models applied to energy system analysis. The benchmark integrates five submetrics: accuracy, reasoning reliability, uncertainty discipline, policy consistency, and transparency, and evaluates model performance across deterministic, probabilistic, and epistemic scenarios using open technoeconomic datasets (NREL ATB 2024, DOE H2A/H2New, IEA WEO 2024). Four frontier models (GPT-4/5, Claude 4.5 Sonnet, Gemini 2.5 Pro, Llama 3 70B) were tested under identical factual and regulatory conditions. Results show that reasoning reliability can be objectively measured. GPT-4/5 and Claude 4.5 Sonnet achieved consistent and policy-compliant reasoning (Analytical Reliability Index greater than 90), Gemini 2.5 Pro demonstrated moderate stability, and Llama 3 70B remained below professional thresholds. Statistical validation confirmed that these differences are significant and reproducible. The ARB establishes the first quantitative method in the energy literature for verifying causal, probabilistic, and policy-driven reasoning in artificial intelligence systems, providing a reference framework for trustworthy and transparent analytical applications in the global energy transition.",
        "tags": [
            "GPT",
            "LLM",
            "LLaMA"
        ]
    },
    {
        "id": "3",
        "title": "Branch-and-Browse: Efficient and Controllable Web Exploration with Tree-Structured Reasoning and Action Memory",
        "author": [
            "Shiqi He",
            "Yue Cui",
            "Xinyu Ma",
            "Yaliang Li",
            "Bolin Ding",
            "Mosharaf Chowdhury"
        ],
        "pdf": "https://arxiv.org/pdf/2510.19838",
        "abstract": "Autonomous web agents powered by large language models (LLMs) show strong potential for performing goal-oriented tasks such as information retrieval, report generation, and online transactions. These agents mark a key step toward practical embodied reasoning in open web environments. However, existing approaches remain limited in reasoning depth and efficiency: vanilla linear methods fail at multi-step reasoning and lack effective backtracking, while other search strategies are coarse-grained and computationally costly. We introduce Branch-and-Browse, a fine-grained web agent framework that unifies structured reasoning-acting, contextual memory, and efficient execution. It (i) employs explicit subtask management with tree-structured exploration for controllable multi-branch reasoning, (ii) bootstraps exploration through efficient web state replay with background reasoning, and (iii) leverages a page action memory to share explored actions within and across sessions. On the WebArena benchmark, Branch-and-Browse achieves a task success rate of 35.8\\% and reduces execution time by up to 40.4\\% relative to state-of-the-art methods. These results demonstrate that Branch-and-Browse is a reliable and efficient framework for LLM-based web agents.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "4",
        "title": "Finite Element and Machine Learning Modeling of Autogenous Self-Healing Concrete",
        "author": [
            "William Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.19839",
        "abstract": "A time-dependent modeling framework for autogenous self-healing concrete that couples moisture diffusion with damage evolution was developed. Water transport follows Fick's second law with a damage-dependent diffusivity obtained by power-law interpolation between intact concrete and crack space. Healing reduces damage in proportion to local moisture and a smoothed cement availability field computed via a Helmholtz filter. Two finite element variants were implemented in FEniCSx over time horizons up to $5\\times10^6$ seconds: a Crack Diffusion Model (CDM) with standard diffusion and a Crack Membrane Model (CMM) that gates cross-crack transport until a critical moisture threshold is reached. Key control parameters are the initial crack orientation and size, the diffusion coefficients of intact and cracked concrete, the healing rate constant, and the cement availability smoothing parameter. Simulations on a unit square domain show that healing time varies non-monotonically with crack orientation, peaking near $45^\\circ$ and $135^\\circ$ and minimizing near $90^\\circ$, consistent with diffusion distance to crack endpoints dominating the process. The dependence on crack width reverses with material parameters: healing time increases when $D_{\\text{cracked}}<D_{\\text{intact}}$ and decreases when $D_{\\text{cracked}}>D_{\\text{intact}}$. The CMM reproduces staged moisture penetration with delayed gate activation but lengthens total healing time, whereas the CDM is efficient for parametric sweeps. Machine learning classifiers trained on one million simulation samples predict binary healing outcomes $H(\\sigma,\\gamma,t)$ (healed or not) with high accuracy (up to 0.998 for neural networks). Although experimental calibration is still required, the framework provides a versatile tool for guiding laboratory studies and implementations of self-healing concrete.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "5",
        "title": "Fourier-Based GAN Fingerprint Detection using ResNet50",
        "author": [
            "Sai Teja Erukude",
            "Viswa Chaitanya Marella",
            "Suhasnadh Reddy Veluru"
        ],
        "pdf": "https://arxiv.org/pdf/2510.19840",
        "abstract": "The rapid rise of photorealistic images produced from Generative Adversarial Networks (GANs) poses a serious challenge for image forensics and industrial systems requiring reliable content authenticity. This paper uses frequency-domain analysis combined with deep learning to solve the problem of distinguishing StyleGAN-generated images from real ones. Specifically, a two-dimensional Discrete Fourier Transform (2D DFT) was applied to transform images into the Fourier domain, where subtle periodic artifacts become detectable. A ResNet50 neural network is trained on these transformed images to differentiate between real and synthetic ones. The experiments demonstrate that the frequency-domain model achieves a 92.8 percent and an AUC of 0.95, significantly outperforming the equivalent model trained on raw spatial-domain images. These results indicate that the GAN-generated images have unique frequency-domain signatures or \"fingerprints\". The method proposed highlights the industrial potential of combining signal processing techniques and deep learning to enhance digital forensics and strengthen the trustworthiness of industrial AI systems.",
        "tags": [
            "Detection",
            "GAN",
            "StyleGAN"
        ]
    },
    {
        "id": "6",
        "title": "DAG-Math: Graph-Guided Mathematical Reasoning in LLMs",
        "author": [
            "Yuanhe Zhang",
            "Ilja Kuzborskij",
            "Jason D. Lee",
            "Chenlei Leng",
            "Fanghui Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.19842",
        "abstract": "Large Language Models (LLMs) demonstrate strong performance on mathematical problems when prompted with Chain-of-Thought (CoT), yet it remains unclear whether this success stems from search, rote procedures, or rule-consistent reasoning. To address this, we propose modeling CoT as a certain rule-based stochastic process over directed acyclic graphs (DAGs), where nodes represent intermediate derivation states and edges encode rule applications. Within this framework, we introduce logical closeness, a metric that quantifies how well a model's CoT trajectory (i.e., the LLM's final output) adheres to the DAG structure, providing evaluation beyond classical PASS@k metrics. Building on this, we introduce the DAG-MATH CoT format and construct a benchmark that guides LLMs to generate CoT trajectories in this format, thereby enabling the evaluation of their reasoning ability under our framework. Across standard mathematical reasoning datasets, our analysis uncovers statistically significant differences in reasoning fidelity among representative LLM families-even when PASS@k is comparable-highlighting gaps between final-answer accuracy and rule-consistent derivation. Our framework provides a balance between free-form CoT and formal proofs systems, offering actionable diagnostics for LLMs reasoning evaluation. Our benchmark and code are available at: https://github.com/YuanheZ/DAG-MATH-Formatted-CoT.",
        "tags": [
            "CoT",
            "LLM"
        ]
    },
    {
        "id": "7",
        "title": "CourtGuard: A Local, Multiagent Prompt Injection Classifier",
        "author": [
            "Isaac Wu",
            "Michael Maslowski"
        ],
        "pdf": "https://arxiv.org/pdf/2510.19844",
        "abstract": "As large language models (LLMs) become integrated into various sensitive applications, prompt injection, the use of prompting to induce harmful behaviors from LLMs, poses an ever increasing risk. Prompt injection attacks can cause LLMs to leak sensitive data, spread misinformation, and exhibit harmful behaviors. To defend against these attacks, we propose CourtGuard, a locally-runnable, multiagent prompt injection classifier. In it, prompts are evaluated in a court-like multiagent LLM system, where a \"defense attorney\" model argues the prompt is benign, a \"prosecution attorney\" model argues the prompt is a prompt injection, and a \"judge\" model gives the final classification. CourtGuard has a lower false positive rate than the Direct Detector, an LLM as-a-judge. However, CourtGuard is generally a worse prompt injection detector. Nevertheless, this lower false positive rate highlights the importance of considering both adversarial and benign scenarios for the classification of a prompt. Additionally, the relative performance of CourtGuard in comparison to other prompt injection classifiers advances the use of multiagent systems as a defense against prompt injection attacks. The implementations of CourtGuard and the Direct Detector with full prompts for Gemma-3-12b-it, Llama-3.3-8B, and Phi-4-mini-instruct are available at https://github.com/isaacwu2000/CourtGuard.",
        "tags": [
            "LLM",
            "LLaMA"
        ]
    },
    {
        "id": "8",
        "title": "Prompt Decorators: A Declarative and Composable Syntax for Reasoning, Formatting, and Control in LLMs",
        "author": [
            "Mostapha Kalami Heris"
        ],
        "pdf": "https://arxiv.org/pdf/2510.19850",
        "abstract": "Large Language Models (LLMs) are central to reasoning, writing, and decision-support workflows, yet users lack consistent control over how they reason and express outputs. Conventional prompt engineering relies on verbose natural-language instructions, limiting reproducibility, modularity, and interpretability. This paper introduces Prompt Decorators, a declarative, composable syntax that governs LLM behavior through compact control tokens such as +++Reasoning, +++Tone(style=formal), and +++Import(topic=\"Systems Thinking\"). Each decorator modifies a behavioral dimension, such as reasoning style, structure, or tone, without changing task content. The framework formalizes twenty core decorators organized into two functional families (Cognitive & Generative and Expressive & Systemic), each further decomposed into subcategories that govern reasoning, interaction, expression, and session-control. It defines a unified syntax, scoping model, and deterministic processing pipeline enabling predictable and auditable behavior composition. By decoupling task intent from execution behavior, Prompt Decorators create a reusable and interpretable interface for prompt design. Illustrative use cases demonstrate improved reasoning transparency, reduced prompt complexity, and standardized model behavior across domains. The paper concludes with implications for interoperability, behavioral consistency, and the development of declarative interfaces for scalable AI systems.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "9",
        "title": "Can Reasoning Models Obfuscate Reasoning? Stress-Testing Chain-of-Thought Monitorability",
        "author": [
            "Artur Zolkowski",
            "Wen Xing",
            "David Lindner",
            "Florian TramÃ¨r",
            "Erik Jenner"
        ],
        "pdf": "https://arxiv.org/pdf/2510.19851",
        "abstract": "Recent findings suggest that misaligned models may exhibit deceptive behavior, raising concerns about output trustworthiness. Chain-of-thought (CoT) is a promising tool for alignment monitoring: when models articulate their reasoning faithfully, monitors can detect and mitigate harmful behaviors before undesirable outcomes occur. However, a key uncertainty is: Can models obfuscate their CoT in order to pursue hidden adversarial objectives while evading detection? To answer this question and thus stress-test CoT monitorability, we develop a composable and quantifiable taxonomy of prompts to elicit CoT obfuscation. We evaluate both internal CoT (reasoning traces) and external CoT (prompted reasoning in outputs) using toy tasks and more realistic environments in SHADE-Arena. We show that: (i) CoT monitoring performs accurately and efficiently without obfuscation pressure. (ii) Under strong obfuscation pressure, some models successfully complete adversarial tasks while evading detection. (iii) Models do not obfuscate their internal CoT as much as their external CoT (under prompt pressure). These results suggest that while CoT provides valuable oversight in benign settings, robust deployment requires model-specific stress-testing of monitorability.",
        "tags": [
            "CoT",
            "Detection"
        ]
    },
    {
        "id": "10",
        "title": "A Specification's Realm: Characterizing the Knowledge Required for Executing a Given Algorithm Specification",
        "author": [
            "Assaf Marron",
            "David Harel"
        ],
        "pdf": "https://arxiv.org/pdf/2510.19853",
        "abstract": "An algorithm specification in natural language or pseudocode is expected to be clear and explicit enough to enable mechanical execution. In this position paper we contribute an initial characterization of the knowledge that an executing agent, human or machine, should possess in order to be able to carry out the instructions of a given algorithm specification as a stand-alone entity, independent of any system implementation. We argue that, for that algorithm specification, such prerequisite knowledge, whether unique or shared with other specifications, can be summarized in a document of practical size. We term this document the realm of the algorithm specification. The generation of such a realm is itself a systematic analytical process, significant parts of which can be automated with the help of large language models and the reuse of existing documents. The algorithm-specification's realm would consist of specification language syntax and semantics, domain knowledge restricted to the referenced entities, inter-entity relationships, relevant underlying cause-and-effect rules, and detailed instructions and means for carrying out certain operations. Such characterization of the realm can contribute to methodological implementation of the algorithm specification in diverse systems and to its formalization for mechanical verification. The paper also touches upon the question of assessing execution faithfulness, which is distinct from correctness: in the absence of a reference interpretation of natural language or pseudocode specification with a given vocabulary, how can we determine if an observed agent's execution indeed complies with the input specification.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "11",
        "title": "Model Context Contracts - MCP-Enabled Framework to Integrate LLMs With Blockchain Smart Contracts",
        "author": [
            "Eranga Bandara",
            "Sachin Shetty",
            "Ravi Mukkamala",
            "Ross Gore",
            "Peter Foytik",
            "Safdar H. Bouk",
            "Abdul Rahman",
            "Xueping Liang",
            "Ng Wee Keong",
            "Kasun De Zoysa",
            "Aruna Withanage",
            "Nilaan Loganathan"
        ],
        "pdf": "https://arxiv.org/pdf/2510.19856",
        "abstract": "In recent years, blockchain has experienced widespread adoption across various industries, becoming integral to numerous enterprise applications. Concurrently, the rise of generative AI and LLMs has transformed human-computer interactions, offering advanced capabilities in understanding and generating human-like text. The introduction of the MCP has further enhanced AI integration by standardizing communication between AI systems and external data sources. Despite these advancements, there is still no standardized method for seamlessly integrating LLM applications and blockchain. To address this concern, we propose \"MCC: Model Context Contracts\" a novel framework that enables LLMs to interact directly with blockchain smart contracts through MCP-like protocol. This integration allows AI agents to invoke blockchain smart contracts, facilitating more dynamic and context-aware interactions between users and blockchain networks. Essentially, it empowers users to interact with blockchain systems and perform transactions using queries in natural language. Within this proposed architecture, blockchain smart contracts can function as intelligent agents capable of recognizing user input in natural language and executing the corresponding transactions. To ensure that the LLM accurately interprets natural language inputs and maps them to the appropriate MCP functions, the LLM was fine-tuned using a custom dataset comprising user inputs paired with their corresponding MCP server functions. This fine-tuning process significantly improved the platform's performance and accuracy. To validate the effectiveness of MCC, we have developed an end-to-end prototype implemented on the Rahasak blockchain with the fine-tuned Llama-4 LLM. To the best of our knowledge, this research represents the first approach to using the concept of Model Context Protocol to integrate LLMs with blockchain.",
        "tags": [
            "LLM",
            "LLaMA"
        ]
    },
    {
        "id": "12",
        "title": "DeBERTa-KC: A Transformer-Based Classifier for Knowledge Construction in Online Learning Discourse",
        "author": [
            "Jindi Wang",
            "Yidi Zhang",
            "Zhaoxing Li"
        ],
        "pdf": "https://arxiv.org/pdf/2510.19858",
        "abstract": "This study presents DeBERTa-KC, a transformer-based model for automatic classification of knowledge construction (KC) levels in online science learning discourse. Using comments collected from four popular YouTube science channels (2022--2024), a balanced corpus of 20,000 manually annotated samples was created across four KC categories: \\textit{nonKC}, \\textit{Share}, \\textit{Explore}, and \\textit{Negotiate}. The proposed model extends DeBERTa-v3 with Focal Loss, Label Smoothing, and R-Drop regularization to address class imbalance and enhance generalization. A reproducible end-to-end pipeline was implemented, encompassing data extraction, annotation, preprocessing, training, and evaluation. Across 10-fold stratified cross-validation, DeBERTa-KC achieved a macro-F1 of $0.836 \\pm 0.008$, significantly out-performing both classical and transformer baselines ($p<0.01$). Per-category results indicate strong sensitivity to higher-order epistemic engagement, particularly in \\textit{Explore} and \\textit{Negotiate} discourse. These findings demonstrate that large language models can effectively capture nuanced indicators of knowledge construction in informal digital learning environments, offering scalable, theory-informed approaches to discourse analysis and the development of automated tools for assessing epistemic engagement.",
        "tags": [
            "LLM",
            "Transformer"
        ]
    },
    {
        "id": "13",
        "title": "E-Test: E'er-Improving Test Suites",
        "author": [
            "Ketai Qiu",
            "Luca Di Grazia",
            "Leonardo Mariani",
            "Mauro PezzÃ¨"
        ],
        "pdf": "https://arxiv.org/pdf/2510.19860",
        "abstract": "Test suites are inherently imperfect, and testers can always enrich a suite with new test cases that improve its quality and, consequently, the reliability of the target software system. However, finding test cases that explore execution scenarios beyond the scope of an existing suite can be extremely challenging and labor-intensive, particularly when managing large test suites over extended periods.\nIn this paper, we propose E-Test, an approach that reduces the gap between the execution space explored with a test suite and the executions experienced after testing by augmenting the test suite with test cases that explore execution scenarios that emerge in production. E-Test (i) identifies executions that have not yet been tested from large sets of scenarios, such as those monitored during intensive production usage, and (ii) generates new test cases that enhance the test suite. E-Test leverages Large Language Models (LLMs) to pinpoint scenarios that the current test suite does not adequately cover, and augments the suite with test cases that execute these scenarios.\nOur evaluation on a dataset of 1,975 scenarios, collected from highly-starred open-source Java projects already in production and Defects4J, demonstrates that E-Test retrieves not-yet-tested execution scenarios significantly better than state-of-the-art approaches. While existing regression testing and field testing approaches for this task achieve a maximum F1-score of 0.34, and vanilla LLMs achieve a maximum F1-score of 0.39, E-Test reaches 0.55. These results highlight the impact of E-Test in enhancing test suites by effectively targeting not-yet-tested execution scenarios and reducing manual effort required for maintaining test suites.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "14",
        "title": "Some Attention is All You Need for Retrieval",
        "author": [
            "Felix Michalak",
            "Steven Abreu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.19861",
        "abstract": "We demonstrate complete functional segregation in hybrid SSM-Transformer architectures: retrieval depends exclusively on self-attention layers. Across RecurrentGemma-2B/9B and Jamba-Mini-1.6, attention ablation causes catastrophic retrieval failure (0% accuracy), while SSM layers show no compensatory mechanisms even with improved prompting. Conversely, sparsifying attention to just 15% of heads maintains near-perfect retrieval while preserving 84% MMLU performance, suggesting self-attention specializes primarily for retrieval tasks. We identify precise mechanistic requirements for retrieval: needle tokens must be exposed during generation and sufficient context must be available during prefill or generation. This strict functional specialization challenges assumptions about redundancy in hybrid architectures and suggests these models operate as specialized modules rather than integrated systems, with immediate implications for architecture optimization and interpretability.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "15",
        "title": "SODBench: A Large Language Model Approach to Documenting Spreadsheet Operations",
        "author": [
            "Amila Indika",
            "Igor Molybog"
        ],
        "pdf": "https://arxiv.org/pdf/2510.19864",
        "abstract": "Numerous knowledge workers utilize spreadsheets in business, accounting, and finance. However, a lack of systematic documentation methods for spreadsheets hinders automation, collaboration, and knowledge transfer, which risks the loss of crucial institutional knowledge. This paper introduces Spreadsheet Operations Documentation (SOD), an AI task that involves generating human-readable explanations from spreadsheet operations. Many previous studies have utilized Large Language Models (LLMs) for generating spreadsheet manipulation code; however, translating that code into natural language for SOD is a less-explored area. To address this, we present a benchmark of 111 spreadsheet manipulation code snippets, each paired with a corresponding natural language summary. We evaluate five LLMs, GPT-4o, GPT-4o-mini, LLaMA-3.3-70B, Mixtral-8x7B, and Gemma2-9B, using BLEU, GLEU, ROUGE-L, and METEOR metrics. Our findings suggest that LLMs can generate accurate spreadsheet documentation, making SOD a feasible prerequisite step toward enhancing reproducibility, maintainability, and collaborative workflows in spreadsheets, although there are challenges that need to be addressed.",
        "tags": [
            "GPT",
            "LLM",
            "LLaMA"
        ]
    },
    {
        "id": "16",
        "title": "An Evaluation of the Pedagogical Soundness and Usability of AI-Generated Lesson Plans Across Different Models and Prompt Frameworks in High-School Physics",
        "author": [
            "Xincheng Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.19866",
        "abstract": "This study evaluates the pedagogical soundness and usability of AI-generated lesson plans across five leading large language models: ChatGPT (GPT-5), Claude Sonnet 4.5, Gemini 2.5 Flash, DeepSeek V3.2, and Grok 4. Beyond model choice, three structured prompt frameworks were tested: TAG (Task, Audience, Goal), RACE (Role, Audience, Context, Execution), and COSTAR (Context, Objective, Style, Tone, Audience, Response Format).\nFifteen lesson plans were generated for a single high-school physics topic, The Electromagnetic Spectrum. The lesson plans were analyzed through four automated computational metrics: (1) readability and linguistic complexity, (2) factual accuracy and hallucination detection, (3) standards and curriculum alignment, and (4) cognitive demand of learning objectives.\nResults indicate that model selection exerted the strongest influence on linguistic accessibility, with DeepSeek producing the most readable teaching plan (FKGL = 8.64) and Claude generating the densest language (FKGL = 19.89).\nThe prompt framework structure most strongly affected the factual accuracy and pedagogical completeness, with the RACE framework yielding the lowest hallucination index and the highest incidental alignment with NGSS curriculum standards. Across all models, the learning objectives in the fifteen lesson plans clustered at the Remember and Understand tiers of Bloom's taxonomy. There were limited higher-order verbs in the learning objectives extracted.\nOverall, the findings suggest that readability is significantly governed by model design, while instructional reliability and curricular alignment depend more on the prompt framework. The most effective configuration for lesson plans identified in the results was to combine a readability-optimized model with the RACE framework and an explicit checklist of physics concepts, curriculum standards, and higher-order objectives.",
        "tags": [
            "DeepSeek",
            "Detection",
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "17",
        "title": "Knowledge-Guided Multi-Agent Framework for Application-Level Software Code Generation",
        "author": [
            "Qian Xiong",
            "Bo Yang",
            "Weisong Sun",
            "Yiran Zhang",
            "Tianlin Li",
            "Yang Liu",
            "Zhi Jin"
        ],
        "pdf": "https://arxiv.org/pdf/2510.19868",
        "abstract": "Automated code generation driven by Large Lan- guage Models (LLMs) has enhanced development efficiency, yet generating complex application-level software code remains challenging. Multi-agent frameworks show potential, but existing methods perform inadequately in large-scale application-level software code generation, failing to ensure reasonable orga- nizational structures of project code and making it difficult to maintain the code generation process. To address this, this paper envisions a Knowledge-Guided Application-Level Code Generation framework named KGACG, which aims to trans- form software requirements specification and architectural design document into executable code through a collaborative closed- loop of the Code Organization & Planning Agent (COPA), Coding Agent (CA), and Testing Agent (TA), combined with a feedback mechanism. We demonstrate the collaborative process of the agents in KGACG in a Java Tank Battle game case study while facing challenges. KGACG is dedicated to advancing the automation of application-level software development.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "18",
        "title": "From Denoising to Refining: A Corrective Framework for Vision-Language Diffusion Model",
        "author": [
            "Yatai Ji",
            "Teng Wang",
            "Yuying Ge",
            "Zhiheng Liu",
            "Sidi Yang",
            "Ying Shan",
            "Ping Luo"
        ],
        "pdf": "https://arxiv.org/pdf/2510.19871",
        "abstract": "Discrete diffusion models have emerged as a promising direction for vision-language tasks, offering bidirectional context modeling and theoretical parallelization. However, their practical application is severely hindered by a train-inference discrepancy, which leads to catastrophic error cascades: initial token errors during parallel decoding pollute the generation context, triggering a chain reaction of compounding errors and leading to syntactic errors and semantic hallucinations. To address this fundamental challenge, we reframe the generation process from passive denoising to active refining. We introduce ReDiff, a refining-enhanced diffusion framework that teaches the model to identify and correct its own errors. Our approach features a two-stage training process: first, we instill a foundational revision capability by training the model to revise synthetic errors; second, we implement a novel online self-correction loop where the model is explicitly trained to revise its own flawed drafts by learning from an expert's corrections. This mistake-driven learning endows the model with the crucial ability to revisit and refine its already generated output, effectively breaking the error cascade. Extensive experiments demonstrate that ReDiff significantly improves the coherence and factual accuracy of generated content, enabling stable and efficient parallel generation far superior to traditional denoising methods. Our codes and models are available at https://rediff-hku.github.io/.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "19",
        "title": "An Integrated Approach to Neural Architecture Search for Deep Q-Networks",
        "author": [
            "Iman Rahmani",
            "Saman Yazdannik",
            "Morteza Tayefi",
            "Jafar Roshanian"
        ],
        "pdf": "https://arxiv.org/pdf/2510.19872",
        "abstract": "The performance of deep reinforcement learning agents is fundamentally constrained by their neural network architecture, a choice traditionally made through expensive hyperparameter searches and then fixed throughout training. This work investigates whether online, adaptive architecture optimization can escape this constraint and outperform static designs. We introduce NAS-DQN, an agent that integrates a learned neural architecture search controller directly into the DRL training loop, enabling dynamic network reconfiguration based on cumulative performance feedback. We evaluate NAS-DQN against three fixed-architecture baselines and a random search control on a continuous control task, conducting experiments over multiple random seeds. Our results demonstrate that NAS-DQN achieves superior final performance, sample efficiency, and policy stability while incurring negligible computational overhead. Critically, the learned search strategy substantially outperforms both undirected random architecture exploration and poorly-chosen fixed designs, indicating that intelligent, performance-guided search is the key mechanism driving success. These findings establish that architecture adaptation is not merely beneficial but necessary for optimal sample efficiency in online deep reinforcement learning, and suggest that the design of RL agents need not be a static offline choice but can instead be seamlessly integrated as a dynamic component of the learning process itself.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "20",
        "title": "From Large to Small: Transferring CUDA Optimization Expertise via Reasoning Graph",
        "author": [
            "Junfeng Gong",
            "Zhiyi Wei",
            "Junying Chen",
            "Cheng Liu",
            "Huawei Li"
        ],
        "pdf": "https://arxiv.org/pdf/2510.19873",
        "abstract": "Despite significant evolution of CUDA programming and domain-specific libraries, effectively utilizing GPUs with massively parallel engines remains difficult. Large language models (LLMs) show strong potential in generating optimized CUDA code from sequential code. However, using LLMs in practice faces two major challenges: cloud-based APIs pose risks of code leakage, and local deployment is often computationally expensive and inefficient. These drawbacks have spurred interest in small language models (SLMs), which are more lightweight and privacy-friendly. Encouragingly, recent studies show that SLMs can achieve performance comparable to LLMs on specific tasks. While SLMs can match LLMs on domain-specific tasks, their limited reasoning abilities lead to suboptimal performance in complex CUDA generation according to our experiments. To bridge this gap, we propose ReGraphT, a training-free, retrieval-augmented generation framework that transfers LLM-level reasoning to smaller models. ReGraphT organizes CUDA optimization trajectories into a structured reasoning graph, modeling the combined CUDA optimizations as state transitions, and leverages Monte Carlo Graph Search (MCGS) for efficient exploration. We also present a CUDA-specific benchmark with difficulty tiers defined by reasoning complexity to evaluate models more comprehensively. Experiments show that ReGraphT outperforms HPC-specific fine-tuned models and other retrieval-augmented approaches, achieving an average 2.33X speedup on CUDAEval and ParEval. When paired with DeepSeek-Coder-V2-Lite-Instruct and Qwen2.5-Coder-7B-Instruct, ReGraphT enables SLMs to approach LLM-level performance without the associated privacy risks or excessive computing overhead.",
        "tags": [
            "DeepSeek",
            "LLM"
        ]
    },
    {
        "id": "21",
        "title": "Stream: Scaling up Mechanistic Interpretability to Long Context in LLMs via Sparse Attention",
        "author": [
            "J Rosser",
            "JosÃ© Luis Redondo GarcÃ­a",
            "Gustavo Penha",
            "Konstantina Palla",
            "Hugues Bouchard"
        ],
        "pdf": "https://arxiv.org/pdf/2510.19875",
        "abstract": "As Large Language Models (LLMs) scale to million-token contexts, traditional Mechanistic Interpretability techniques for analyzing attention scale quadratically with context length, demanding terabytes of memory beyond 100,000 tokens. We introduce Sparse Tracing, a novel technique that leverages dynamic sparse attention to efficiently analyze long context attention patterns. We present Stream, a compilable hierarchical pruning algorithm that estimates per-head sparse attention masks in near-linear time $O(T \\log T)$ and linear space $O(T)$, enabling one-pass interpretability at scale. Stream performs a binary-search-style refinement to retain only the top-$k$ key blocks per query while preserving the model's next-token behavior. We apply Stream to long chain-of-thought reasoning traces and identify thought anchors while pruning 97-99\\% of token interactions. On the RULER benchmark, Stream preserves critical retrieval paths while discarding 90-96\\% of interactions and exposes layer-wise routes from the needle to output. Our method offers a practical drop-in tool for analyzing attention patterns and tracing information flow without terabytes of caches. By making long context interpretability feasible on consumer GPUs, Sparse Tracing helps democratize chain-of-thought monitoring. Code is available at https://anonymous.4open.science/r/stream-03B8/.",
        "tags": [
            "CoT",
            "LLM"
        ]
    },
    {
        "id": "22",
        "title": "An Expert-grounded benchmark of General Purpose LLMs in LCA",
        "author": [
            "Artur Donaldson",
            "Bharathan Balaji",
            "Cajetan Oriekezie",
            "Manish Kumar",
            "Laure Patouillard"
        ],
        "pdf": "https://arxiv.org/pdf/2510.19886",
        "abstract": "Purpose: Artificial intelligence (AI), and in particular large language models (LLMs), are increasingly being explored as tools to support life cycle assessment (LCA). While demonstrations exist across environmental and social domains, systematic evidence on their reliability, robustness, and usability remains limited. This study provides the first expert-grounded benchmark of LLMs in LCA, addressing the absence of standardized evaluation frameworks in a field where no clear ground truth or consensus protocols exist.\nMethods: We evaluated eleven general-purpose LLMs, spanning both commercial and open-source families, across 22 LCA-related tasks. Seventeen experienced practitioners reviewed model outputs against criteria directly relevant to LCA practice, including scientific accuracy, explanation quality, robustness, verifiability, and adherence to instructions. We collected 168 expert reviews.\nResults: Experts judged 37% of responses to contain inaccurate or misleading information. Ratings of accuracy and quality of explanation were generally rated average or good on many models even smaller models, and format adherence was generally rated favourably. Hallucination rates varied significantly, with some models producing hallucinated citations at rates of up to 40%. There was no clear-cut distinction between ratings on open-weight versus closed-weight LLMs, with open-weight models outperforming or competing on par with closed-weight models on criteria such as accuracy and quality of explanation.\nConclusion: These findings highlight the risks of applying LLMs naÃ¯vely in LCA, such as when LLMs are treated as free-form oracles, while also showing benefits especially around quality of explanation and alleviating labour intensiveness of simple tasks. The use of general-purpose LLMs without grounding mechanisms presents ...",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "23",
        "title": "From Optimization to Prediction: Transformer-Based Path-Flow Estimation to the Traffic Assignment Problem",
        "author": [
            "Mostafa Ameli",
            "Van Anh Le",
            "Sulthana Shams",
            "Alexander Skabardonis"
        ],
        "pdf": "https://arxiv.org/pdf/2510.19889",
        "abstract": "The traffic assignment problem is essential for traffic flow analysis, traditionally solved using mathematical programs under the Equilibrium principle. These methods become computationally prohibitive for large-scale networks due to non-linear growth in complexity with the number of OD pairs. This study introduces a novel data-driven approach using deep neural networks, specifically leveraging the Transformer architecture, to predict equilibrium path flows directly. By focusing on path-level traffic distribution, the proposed model captures intricate correlations between OD pairs, offering a more detailed and flexible analysis compared to traditional link-level approaches. The Transformer-based model drastically reduces computation time, while adapting to changes in demand and network structure without the need for recalculation. Numerical experiments are conducted on the Manhattan-like synthetic network, the Sioux Falls network, and the Eastern-Massachusetts network. The results demonstrate that the proposed model is orders of magnitude faster than conventional optimization. It efficiently estimates path-level traffic flows in multi-class networks, reducing computational costs and improving prediction accuracy by capturing detailed trip and flow information. The model also adapts flexibly to varying demand and network conditions, supporting traffic management and enabling rapid `what-if' analyses for enhanced transportation planning and policy-making.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "24",
        "title": "Deep Sequence-to-Sequence Models for GNSS Spoofing Detection",
        "author": [
            "Jan Zelinka",
            "Oliver Kost",
            "Marek HrÃºz"
        ],
        "pdf": "https://arxiv.org/pdf/2510.19890",
        "abstract": "We present a data generation framework designed to simulate spoofing attacks and randomly place attack scenarios worldwide. We apply deep neural network-based models for spoofing detection, utilizing Long Short-Term Memory networks and Transformer-inspired architectures. These models are specifically designed for online detection and are trained using the generated dataset. Our results demonstrate that deep learning models can accurately distinguish spoofed signals from genuine ones, achieving high detection performance. The best results are achieved by Transformer-inspired architectures with early fusion of the inputs resulting in an error rate of 0.16%.",
        "tags": [
            "Detection",
            "Transformer"
        ]
    },
    {
        "id": "25",
        "title": "Can They Dixit? Yes they Can! Dixit as a Playground for Multimodal Language Model Capabilities",
        "author": [
            "Nishant Balepur",
            "Dang Nguyen",
            "Dayeon Ki"
        ],
        "pdf": "https://arxiv.org/pdf/2510.19892",
        "abstract": "Multi-modal large language models (MLMs) are often assessed on static, individual benchmarks -- which cannot jointly assess MLM capabilities in a single task -- or rely on human or model pairwise comparisons -- which is highly subjective, expensive, and allows models to exploit superficial shortcuts (e.g., verbosity) to inflate their win-rates. To overcome these issues, we propose game-based evaluations to holistically assess MLM capabilities. Games require multiple abilities for players to win, are inherently competitive, and are governed by fix, objective rules, and makes evaluation more engaging, providing a robust framework to address the aforementioned challenges. We manifest this evaluation specifically through Dixit, a fantasy card game where players must generate captions for a card that trick some, but not all players, into selecting the played card. Our quantitative experiments with five MLMs show Dixit win-rate rankings are perfectly correlated with those on popular MLM benchmarks, while games between human and MLM players in Dixit reveal several differences between agent strategies and areas of improvement for MLM reasoning.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "26",
        "title": "Large Language Model enabled Mathematical Modeling",
        "author": [
            "Guoyun Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.19895",
        "abstract": "The integration of Large Language Models (LLMs) with optimization modeling offers a promising avenue for advancing decision-making in operations research (OR). Traditional optimization methods,such as linear programming, mixed integer programming, and simulation depend heavily on domain expertise to translate real-world problems into solvable mathematical models. While solvers like Gurobi and COPT are powerful, expert input remains essential for defining objectives, constraints, and variables. This research investigates the potential of LLMs, specifically the DeepSeek-R1 model, to bridge this formulation gap using natural language understanding and code generation. Although prior models like GPT-4, Claude, and Bard have shown strong performance in NLP and reasoning tasks, their high token costs and tendency toward hallucinations limit real-world applicability in supply chain contexts. In contrast, DeepSeek-R1, a cost-efficient and high-performing model trained with reinforcement learning, presents a viable alternative. Despite its success in benchmarks such as LiveCodeBench and Math-500, its effectiveness in applied OR scenarios remains under explored. This study systematically evaluates DeepSeek-R1 across four key OR benchmarks: NL4OPT, IndustryOR, EasyLP, and ComplexOR. Our methodology includes baseline assessments, the development of a hallucination taxonomy, and the application of mitigation strategies like LLM-as-a-Judge, Few-shot Learning (FSL), Tool Calling, and a Multi-agent Framework. These techniques aim to reduce hallucinations, enhance formulation accuracy, and better align model outputs with user intent.",
        "tags": [
            "DeepSeek",
            "GPT",
            "LLM",
            "RL"
        ]
    },
    {
        "id": "27",
        "title": "Learning from Supervision with Semantic and Episodic Memory: A Reflective Approach to Agent Adaptation",
        "author": [
            "Jackson Hassell",
            "Dan Zhang",
            "Hannah Kim",
            "Tom Mitchell",
            "Estevam Hruschka"
        ],
        "pdf": "https://arxiv.org/pdf/2510.19897",
        "abstract": "We investigate how agents built on pretrained large language models can learn target classification functions from labeled examples without parameter updates. While conventional approaches like fine-tuning are often costly, inflexible, and opaque, we propose a memory-augmented framework that leverages both labeled data and LLM-generated critiques. Our framework uses episodic memory to store instance-level critiques-capturing specific past experiences-and semantic memory to distill these into reusable, task-level guidance. Across a diverse set of tasks, incorporating critiques yields up to a 24.8 percent accuracy improvement over retrieval-based (RAG-style) baselines that rely only on labels. Through extensive empirical evaluation, we uncover distinct behavioral differences between OpenAI and opensource models, particularly in how they handle fact-oriented versus preference-based data. To interpret how models respond to different representations of supervision encoded in memory, we introduce a novel metric, suggestibility. This helps explain observed behaviors and illuminates how model characteristics and memory strategies jointly shape learning dynamics. Our findings highlight the promise of memory-driven, reflective learning for building more adaptive and interpretable LLM agents.",
        "tags": [
            "LLM",
            "RAG"
        ]
    },
    {
        "id": "28",
        "title": "Robust Reinforcement Learning in Finance: Modeling Market Impact with Elliptic Uncertainty Sets",
        "author": [
            "Shaocong Ma",
            "Heng Huang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.19950",
        "abstract": "In financial applications, reinforcement learning (RL) agents are commonly trained on historical data, where their actions do not influence prices. However, during deployment, these agents trade in live markets where their own transactions can shift asset prices, a phenomenon known as market impact. This mismatch between training and deployment environments can significantly degrade performance. Traditional robust RL approaches address this model misspecification by optimizing the worst-case performance over a set of uncertainties, but typically rely on symmetric structures that fail to capture the directional nature of market impact. To address this issue, we develop a novel class of elliptic uncertainty sets. We establish both implicit and explicit closed-form solutions for the worst-case uncertainty under these sets, enabling efficient and tractable robust policy evaluation. Experiments on single-asset and multi-asset trading tasks demonstrate that our method achieves superior Sharpe ratio and remains robust under increasing trade volumes, offering a more faithful and scalable approach to RL in financial markets.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "29",
        "title": "Synthetic social data: trials and tribulations",
        "author": [
            "Guido Ivetta",
            "Laura Moradbakhti",
            "Rafael A. Calvo"
        ],
        "pdf": "https://arxiv.org/pdf/2510.19952",
        "abstract": "Large Language Models are being used in conversational agents that simulate human conversations and generate social studies data. While concerns about the models' biases have been raised and discussed in the literature, much about the data generated is still unknown. In this study we explore the statistical representation of social values across four countries (UK, Argentina, USA and China) for six LLMs, with equal representation for open and closed weights. By comparing machine-generated outputs with actual human survey data, we assess whether algorithmic biases in LLMs outweigh the biases inherent in real- world sampling, including demographic and response biases. Our findings suggest that, despite the logistical and financial constraints of human surveys, even a small, skewed sample of real respondents may provide more reliable insights than synthetic data produced by LLMs. These results highlight the limitations of using AI-generated text for social research and emphasize the continued importance of empirical human data collection.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "30",
        "title": "A new wave of vehicle insurance fraud fueled by generative AI",
        "author": [
            "Amir Hever",
            "Itai Orr"
        ],
        "pdf": "https://arxiv.org/pdf/2510.19957",
        "abstract": "Generative AI is supercharging insurance fraud by making it easier to falsify accident evidence at scale and in rapid time. Insurance fraud is a pervasive and costly problem, amounting to tens of billions of dollars in losses each year. In the vehicle insurance sector, fraud schemes have traditionally involved staged accidents, exaggerated damage, or forged documents. The rise of generative AI, including deepfake image and video generation, has introduced new methods for committing fraud at scale. Fraudsters can now fabricate highly realistic crash photos, damage evidence, and even fake identities or documents with minimal effort, exploiting AI tools to bolster false insurance claims. Insurers have begun deploying countermeasures such as AI-based deepfake detection software and enhanced verification processes to detect and mitigate these AI-driven scams. However, current mitigation strategies face significant limitations. Detection tools can suffer from false positives and negatives, and sophisticated fraudsters continuously adapt their tactics to evade automated checks. This cat-and-mouse arms race between generative AI and detection technology, combined with resource and cost barriers for insurers, means that combating AI-enabled insurance fraud remains an ongoing challenge. In this white paper, we present UVeye layered solution for vehicle fraud, representing a major leap forward in the ability to detect, mitigate and deter this new wave of fraud.",
        "tags": [
            "Detection",
            "Video Generation"
        ]
    },
    {
        "id": "31",
        "title": "Configuration-Dependent Robot Kinematics Model and Calibration",
        "author": [
            "Chen-Lung Lu",
            "Honglu He",
            "Agung Julius",
            "John T. Wen"
        ],
        "pdf": "https://arxiv.org/pdf/2510.19962",
        "abstract": "Accurate robot kinematics is essential for precise tool placement in articulated robots, but non-geometric factors can introduce configuration-dependent model discrepancies. This paper presents a configuration-dependent kinematic calibration framework for improving accuracy across the entire workspace. Local Product-of-Exponential (POE) models, selected for their parameterization continuity, are identified at multiple configurations and interpolated into a global model. Inspired by joint gravity load expressions, we employ Fourier basis function interpolation parameterized by the shoulder and elbow joint angles, achieving accuracy comparable to neural network and autoencoder methods but with substantially higher training efficiency. Validation on two 6-DoF industrial robots shows that the proposed approach reduces the maximum positioning error by over 50%, meeting the sub-millimeter accuracy required for cold spray manufacturing. Robots with larger configuration-dependent discrepancies benefit even more. A dual-robot collaborative task demonstrates the framework's practical applicability and repeatability.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "32",
        "title": "LyriCAR: A Difficulty-Aware Curriculum Reinforcement Learning Framework For Controllable Lyric Translation",
        "author": [
            "Le Ren",
            "Xiangjian Zeng",
            "Qingqiang Wu",
            "Ruoxuan Liang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.19967",
        "abstract": "Lyric translation is a challenging task that requires balancing multiple musical constraints. Existing methods often rely on hand-crafted rules and sentence-level modeling, which restrict their ability to internalize musical-linguistic patterns and to generalize effectively at the paragraph level, where cross-line coherence and global rhyme are crucial. In this work, we propose LyriCAR, a novel framework for controllable lyric translation that operates in a fully unsupervised manner. LyriCAR introduces a difficulty-aware curriculum designer and an adaptive curriculum strategy, ensuring efficient allocation of training resources, accelerating convergence, and improving overall translation quality by guiding the model with increasingly complex challenges. Extensive experiments on the EN-ZH lyric translation task show that LyriCAR achieves state-of-the-art results across both standard translation metrics and multi-dimensional reward scores, surpassing strong baselines. Notably, the adaptive curriculum strategy reduces training steps by nearly 40% while maintaining superior performance. Code, data and model can be accessed at https://github.com/rle27/LyriCAR.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "33",
        "title": "A Tutorial on Cognitive Biases in Agentic AI-Driven 6G Autonomous Networks",
        "author": [
            "Hatim Chergui",
            "Farhad Rezazadeh",
            "Merouane Debbah",
            "Christos Verikoukis"
        ],
        "pdf": "https://arxiv.org/pdf/2510.19973",
        "abstract": "The path to higher network autonomy in 6G lies beyond the mere optimization of key performance indicators (KPIs). While KPIs have enabled automation gains under TM Forum Levels 1--3, they remain numerical abstractions that act only as proxies for the real essence of communication networks: seamless connectivity, fairness, adaptability, and resilience. True autonomy requires perceiving and reasoning over the network environment as it is. Such progress can be achieved through \\emph{agentic AI}, where large language model (LLM)-powered agents perceive multimodal telemetry, reason with memory, negotiate across domains, and act via APIs to achieve multi-objective goals. However, deploying such agents introduces the challenge of cognitive biases inherited from human design, which can distort reasoning, negotiation, tool use, and actuation. Between neuroscience and AI, this paper provides a tutorial on a selection of well-known biases, including their taxonomy, definition, mathematical formulation, emergence in telecom systems and the commonly impacted agentic components. The tutorial also presents various mitigation strategies tailored to each type of bias. The article finally provides two practical use-cases, which tackle the emergence, impact and mitigation gain of some famous biases in 6G inter-slice and cross-domain management. In particular, anchor randomization, temporal decay and inflection bonus techniques are introduced to specifically address anchoring, temporal and confirmation biases. This avoids that agents stick to the initial high resource allocation proposal or decisions that are recent and/or confirming a prior hypothesis. By grounding decisions in a richer and fairer set of past experiences, the quality and bravery of the agentic agreements in the second use-case, for instance, are leading to $\\times 5$ lower latency and around $40\\%$ higher energy saving.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "34",
        "title": "Push Anything: Single- and Multi-Object Pushing From First Sight with Contact-Implicit MPC",
        "author": [
            "Hien Bui",
            "Yufeiyang Gao",
            "Haoran Yang",
            "Eric Cui",
            "Siddhant Mody",
            "Brian Acosta",
            "Thomas Stephen Felix",
            "Bibit Bianchini",
            "Michael Posa"
        ],
        "pdf": "https://arxiv.org/pdf/2510.19974",
        "abstract": "Non-prehensile manipulation of diverse objects remains a core challenge in robotics, driven by unknown physical properties and the complexity of contact-rich interactions. Recent advances in contact-implicit model predictive control (CI-MPC), with contact reasoning embedded directly in the trajectory optimization, have shown promise in tackling the task efficiently and robustly, yet demonstrations have been limited to narrowly curated examples. In this work, we showcase the broader capabilities of CI-MPC through precise planar pushing tasks over a wide range of object geometries, including multi-object domains. These scenarios demand reasoning over numerous inter-object and object-environment contacts to strategically manipulate and de-clutter the environment, challenges that were intractable for prior CI-MPC methods. To achieve this, we introduce Consensus Complementarity Control Plus (C3+), an enhanced CI-MPC algorithm integrated into a complete pipeline spanning object scanning, mesh reconstruction, and hardware execution. Compared to its predecessor C3, C3+ achieves substantially faster solve times, enabling real-time performance even in multi-object pushing tasks. On hardware, our system achieves overall 98% success rate across 33 objects, reaching pose goals within tight tolerances. The average time-to-goal is approximately 0.5, 1.6, 3.2, and 5.3 minutes for 1-, 2-, 3-, and 4-object tasks, respectively. Project page: https://dairlab.github.io/push-anything.",
        "tags": [
            "MPC",
            "Robotics"
        ]
    },
    {
        "id": "35",
        "title": "SecureInfer: Heterogeneous TEE-GPU Architecture for Privacy-Critical Tensors for Large Language Model Deployment",
        "author": [
            "Tushar Nayan",
            "Ziqi Zhang",
            "Ruimin Sun"
        ],
        "pdf": "https://arxiv.org/pdf/2510.19979",
        "abstract": "With the increasing deployment of Large Language Models (LLMs) on mobile and edge platforms, securing them against model extraction attacks has become a pressing concern. However, protecting model privacy without sacrificing the performance benefits of untrusted AI accelerators, such as GPUs, presents a challenging trade-off. In this paper, we initiate the study of high-performance execution on LLMs and present SecureInfer, a hybrid framework that leverages a heterogeneous Trusted Execution Environments (TEEs)-GPU architecture to isolate privacy-critical components while offloading compute-intensive operations to untrusted accelerators. Building upon an outsourcing scheme, SecureInfer adopts an information-theoretic and threat-informed partitioning strategy: security-sensitive components, including non-linear layers, projection of attention head, FNN transformations, and LoRA adapters, are executed inside an SGX enclave, while other linear operations (matrix multiplication) are performed on the GPU after encryption and are securely restored within the enclave. We implement a prototype of SecureInfer using the LLaMA-2 model and evaluate it across performance and security metrics. Our results show that SecureInfer offers strong security guarantees with reasonable performance, offering a practical solution for secure on-device model inference.",
        "tags": [
            "LLM",
            "LLaMA",
            "LoRA"
        ]
    },
    {
        "id": "36",
        "title": "Abstain Mask Retain Core: Time Series Prediction by Adaptive Masking Loss with Representation Consistency",
        "author": [
            "Renzhao Liang",
            "Sizhe Xu",
            "Chenggang Xie",
            "Jingru Chen",
            "Feiyang Ren",
            "Shu Yang",
            "Takahiro Yabe"
        ],
        "pdf": "https://arxiv.org/pdf/2510.19980",
        "abstract": "Time series forecasting plays a pivotal role in critical domains such as energy management and financial markets. Although deep learning-based approaches (e.g., MLP, RNN, Transformer) have achieved remarkable progress, the prevailing \"long-sequence information gain hypothesis\" exhibits inherent limitations. Through systematic experimentation, this study reveals a counterintuitive phenomenon: appropriately truncating historical data can paradoxically enhance prediction accuracy, indicating that existing models learn substantial redundant features (e.g., noise or irrelevant fluctuations) during training, thereby compromising effective signal extraction. Building upon information bottleneck theory, we propose an innovative solution termed Adaptive Masking Loss with Representation Consistency (AMRC), which features two core components: 1) Dynamic masking loss, which adaptively identified highly discriminative temporal segments to guide gradient descent during model training; 2) Representation consistency constraint, which stabilized the mapping relationships among inputs, labels, and predictions. Experimental results demonstrate that AMRC effectively suppresses redundant feature learning while significantly improving model performance. This work not only challenges conventional assumptions in temporal modeling but also provides novel theoretical insights and methodological breakthroughs for developing efficient and robust forecasting models.",
        "tags": [
            "RNN",
            "Transformer"
        ]
    },
    {
        "id": "37",
        "title": "FutrTrack: A Camera-LiDAR Fusion Transformer for 3D Multiple Object Tracking",
        "author": [
            "Martha Teiko Teye",
            "Ori Maoz",
            "Matthias Rottmann"
        ],
        "pdf": "https://arxiv.org/pdf/2510.19981",
        "abstract": "We propose FutrTrack, a modular camera-LiDAR multi-object tracking framework that builds on existing 3D detectors by introducing a transformer-based smoother and a fusion-driven tracker. Inspired by query-based tracking frameworks, FutrTrack employs a multimodal two-stage transformer refinement and tracking pipeline. Our fusion tracker integrates bounding boxes with multimodal bird's-eye-view (BEV) fusion features from multiple cameras and LiDAR without the need for an explicit motion model. The tracker assigns and propagates identities across frames, leveraging both geometric and semantic cues for robust re-identification under occlusion and viewpoint changes. Prior to tracking, we refine sequences of bounding boxes with a temporal smoother over a moving window to refine trajectories, reduce jitter, and improve spatial consistency. Evaluated on nuScenes and KITTI, FutrTrack demonstrates that query-based transformer tracking methods benefit significantly from multimodal sensor features compared with previous single-sensor approaches. With an aMOTA of 74.7 on the nuScenes test set, FutrTrack achieves strong performance on 3D MOT benchmarks, reducing identity switches while maintaining competitive accuracy. Our approach provides an efficient framework for improving transformer-based trackers to compete with other neural-network-based methods even with limited data and without pretraining.",
        "tags": [
            "3D",
            "Transformer"
        ]
    },
    {
        "id": "38",
        "title": "Automating Iconclass: LLMs and RAG for Large-Scale Classification of Religious Woodcuts",
        "author": [
            "Drew B. Thomas"
        ],
        "pdf": "https://arxiv.org/pdf/2510.19986",
        "abstract": "This paper presents a novel methodology for classifying early modern religious images by using Large Language Models (LLMs) and vector databases in combination with Retrieval-Augmented Generation (RAG). The approach leverages the full-page context of book illustrations from the Holy Roman Empire, allowing the LLM to generate detailed descriptions that incorporate both visual and textual elements. These descriptions are then matched to relevant Iconclass codes through a hybrid vector search. This method achieves 87% and 92% precision at five and four levels of classification, significantly outperforming traditional image and keyword-based searches. By employing full-page descriptions and RAG, the system enhances classification accuracy, offering a powerful tool for large-scale analysis of early modern visual archives. This interdisciplinary approach demonstrates the growing potential of LLMs and RAG in advancing research within art history and digital humanities.",
        "tags": [
            "LLM",
            "RAG"
        ]
    },
    {
        "id": "39",
        "title": "LLM-Augmented Symbolic NLU System for More Reliable Continuous Causal Statement Interpretation",
        "author": [
            "Xin Lian",
            "Kenneth D. Forbus"
        ],
        "pdf": "https://arxiv.org/pdf/2510.19988",
        "abstract": "Despite the broad applicability of large language models (LLMs), their reliance on probabilistic inference makes them vulnerable to errors such as hallucination in generated facts and inconsistent output structure in natural language understanding (NLU) tasks. By contrast, symbolic NLU systems provide interpretable understanding grounded in curated lexicons, semantic resources, and syntactic & semantic interpretation rules. They produce relational representations that can be used for accurate reasoning and planning, as well as incremental debuggable learning. However, symbolic NLU systems tend to be more limited in coverage than LLMs and require scarce knowledge representation and linguistics skills to extend and maintain. This paper explores a hybrid approach that integrates the broad-coverage language processing of LLMs with the symbolic NLU capabilities of producing structured relational representations to hopefully get the best of both approaches. We use LLMs for rephrasing and text simplification, to provide broad coverage, and as a source of information to fill in knowledge gaps more automatically. We use symbolic NLU to produce representations that can be used for reasoning and for incremental learning. We evaluate this approach on the task of extracting and interpreting quantities and causal laws from commonsense science texts, along with symbolic- and LLM-only pipelines. Our results suggest that our hybrid method works significantly better than the symbolic-only pipeline.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "40",
        "title": "No Compute Left Behind: Rethinking Reasoning and Sampling with Masked Diffusion Models",
        "author": [
            "Zachary Horvitz",
            "Raghav Singhal",
            "Hao Zou",
            "Carles Domingo-Enrich",
            "Zhou Yu",
            "Rajesh Ranganath",
            "Kathleen McKeown"
        ],
        "pdf": "https://arxiv.org/pdf/2510.19990",
        "abstract": "Masked diffusion language models (MDLMs) are trained to in-fill positions in randomly masked sequences, in contrast to next-token prediction models. Discussions around MDLMs focus on two benefits: (1) any-order decoding and 2) multi-token decoding. However, we observe that for math and coding tasks, any-order algorithms often underperform or behave similarly to left-to-right sampling, and standard multi-token decoding significantly degrades performance. At inference time, MDLMs compute the conditional distribution of all masked positions. A natural question is: How can we justify this additional compute when left-to-right one-token-at-a-time decoding is on par with any-order decoding algorithms? First, we propose reasoning-as-infilling. By using MDLMs to infill a reasoning template, we can structure outputs and distinguish between reasoning and answer tokens. In turn, this enables measuring answer uncertainty during reasoning, and early exits when the model converges on an answer. Next, given an answer, reasoning-as-infilling enables sampling from the MDLM posterior over reasoning traces conditioned on the answer, providing a new source of high-quality data for post-training. On GSM8k, we observe that fine-tuning LLaDA-8B Base on its posterior reasoning traces provides a performance boost on par with fine-tuning on human-written reasoning traces. Additionally, given an answer, reasoning-as-infilling provides a method for scoring the correctness of the reasoning process at intermediate steps. Second, we propose multi-token entropy decoding (MED), a simple adaptive sampler that minimizes the error incurred by decoding positions in parallel based on the conditional entropies of those positions. MED preserves performance across benchmarks and leads to 2.7x fewer steps. Our work demonstrates that the training and compute used by MDLMs unlock many new inference and post-training methods.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "41",
        "title": "Communication to Completion: Modeling Collaborative Workflows with Intelligent Multi-Agent Communication",
        "author": [
            "Yiming Lu",
            "Xun Wang",
            "Simin Ma",
            "Shujian Liu",
            "Sathish Reddy Indurthi",
            "Song Wang",
            "Haoyun Deng",
            "Fei Liu",
            "Kaiqiang Song"
        ],
        "pdf": "https://arxiv.org/pdf/2510.19995",
        "abstract": "Teamwork in workspace for complex tasks requires diverse communication strategies, but current multi-agent LLM systems lack systematic frameworks for task oriented communication. We introduce Communication to Completion (C2C), a scalable framework that addresses this gap through two key innovations: (1) the Alignment Factor (AF), a novel metric quantifying agent task alignment that directly impacts work efficiency, and (2) a Sequential Action Framework that integrates stepwise execution with intelligent communication decisions. C2C enables agents to make cost aware communication choices, dynamically improving task understanding through targeted interactions. We evaluated C2C on realistic coding workflows across three complexity tiers and team sizes from 5 to 17 agents, comparing against no communication and fixed steps baselines. The results show that C2C reduces the task completion time by about 40% with acceptable communication costs. The framework completes all tasks successfully in standard configurations and maintains effectiveness at scale. C2C establishes both a theoretical foundation for measuring communication effectiveness in multi-agent systems and a practical framework for complex collaborative tasks.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "42",
        "title": "A Framework for the Adoption and Integration of Generative AI in Midsize Organizations and Enterprises (FAIGMOE)",
        "author": [
            "Abraham Itzhak Weinberg"
        ],
        "pdf": "https://arxiv.org/pdf/2510.19997",
        "abstract": "Generative Artificial Intelligence (GenAI) presents transformative opportunities for organizations, yet both midsize organizations and larger enterprises face distinctive adoption challenges. Midsize organizations encounter resource constraints and limited AI expertise, while enterprises struggle with organizational complexity and coordination challenges. Existing technology adoption frameworks, including TAM (Technology Acceptance Model), TOE (Technology Organization Environment), and DOI (Diffusion of Innovations) theory, lack the specificity required for GenAI implementation across these diverse contexts, creating a critical gap in adoption literature. This paper introduces FAIGMOE (Framework for the Adoption and Integration of Generative AI in Midsize Organizations and Enterprises), a conceptual framework addressing the unique needs of both organizational types. FAIGMOE synthesizes technology adoption theory, organizational change management, and innovation diffusion perspectives into four interconnected phases: Strategic Assessment, Planning and Use Case Development, Implementation and Integration, and Operationalization and Optimization. Each phase provides scalable guidance on readiness assessment, strategic alignment, risk governance, technical architecture, and change management adaptable to organizational scale and complexity. The framework incorporates GenAI specific considerations including prompt engineering, model orchestration, and hallucination management that distinguish it from generic technology adoption frameworks. As a perspective contribution, FAIGMOE provides the first comprehensive conceptual framework explicitly addressing GenAI adoption across midsize and enterprise organizations, offering actionable implementation protocols, assessment instruments, and governance templates requiring empirical validation through future research.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "43",
        "title": "Forging GEMs: Advancing Greek NLP through Quality-Based Corpus Curation and Specialized Pre-training",
        "author": [
            "Alexandra Apostolopoulou",
            "Konstantinos Kanaris",
            "Athanasios Koursaris",
            "Dimitris Tsakalidis",
            "George Domalis",
            "Ioannis E. Livieris"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20002",
        "abstract": "The advancement of natural language processing for morphologically rich, moderately-resourced languages like Modern Greek is often hindered by a fragmented research landscape, a lack of architectural diversity and reliance on limited context-length models. This is particularly true in specialized, high-value domains such as law, where existing models are frequently confined to early transformer architectures with a restrictive 512-token window, insufficient for analyzing long legal documents. To address these challenges, this paper presents Greek Embedding Models, a new family of transformer models for Greek language built upon a foundation of extensive, quality-driven data curation. We detail the construction of several large-scale Greek corpora, emphasizing a rigorous, quality-based filtering and preprocessing methodology to create high-value training datasets from both general-domain and specialized legal sources. On this carefully curated foundation, we pre-train and systematically evaluate a diverse suite of modern architectures, which has not previously applied to Greek language, such as ELECTRA, ConvBERT and ModernBERT. Furthermore, we propose the first bilingual Greek-English Embedding Models tailored for the legal domain. The extensive experiments on downstream tasks demonstrate that the new class of models establish the effectiveness of the proposed approach, highlighting that the GEM-RoBERTa and GEM-ConvBERT models significantly outperform existing baselines.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "44",
        "title": "Simultaneous learning of state-to-state minimum-time planning and control",
        "author": [
            "Swati Dantu",
            "Robert PÄniÄka",
            "Martin Saska"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20008",
        "abstract": "This paper tackles the challenge of learning a generalizable minimum-time flight policy for UAVs, capable of navigating between arbitrary start and goal states while balancing agile flight and stable hovering. Traditional approaches, particularly in autonomous drone racing, achieve impressive speeds and agility but are constrained to predefined track layouts, limiting real-world applicability. To address this, we propose a reinforcement learning-based framework that simultaneously learns state-to-state minimum-time planning and control and generalizes to arbitrary state-to-state flights. Our approach leverages Point Mass Model (PMM) trajectories as proxy rewards to approximate the true optimal flight objective and employs curriculum learning to scale the training process efficiently and to achieve generalization. We validate our method through simulation experiments, comparing it against Nonlinear Model Predictive Control (NMPC) tracking PMM-generated trajectories and conducting ablation studies to assess the impact of curriculum learning. Finally, real-world experiments confirm the robustness of our learned policy in outdoor environments, demonstrating its ability to generalize and operate on a small ARM-based single-board computer.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "45",
        "title": "SALT: Step-level Advantage Assignment for Long-horizon Agents via Trajectory Graph",
        "author": [
            "Jiazheng Li",
            "Yawei Wang",
            "David Yan",
            "Yijun Tian",
            "Zhichao Xu",
            "Huan Song",
            "Panpan Xu",
            "Lin Lee Cheong"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20022",
        "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities, enabling language agents to excel at single-turn tasks. However, their application to complex, multi-step, and long-horizon tasks remains challenging. While reinforcement learning (RL) offers a promising avenue for addressing these challenges, mainstream approaches typically rely solely on sparse, outcome-based rewards, a limitation that becomes especially problematic for group-based RL algorithms lacking critic models, such as Group Relative Policy Optimization (GRPO). In such methods, uniformly rewarding or penalizing all actions within a trajectory can lead to training instability and suboptimal policies, because beneficial and detrimental actions are often entangled across multi-step interactions. To address this challenge, we propose SALT, a novel and lightweight framework that provides a finer-grained advantage assignment, derived solely from outcome rewards. We achieve this by constructing a graph from trajectories of the same prompt, which allows us to quantify the quality of each step and assign advantages accordingly. Crucially, SALT is designed as a plug-and-play module that seamlessly integrates with existing group-based RL algorithms, requiring no modifications to the rollout procedure and introducing negligible computational overhead. Extensive experiments on the WebShop, ALFWorld, and AppWorld benchmarks with various model sizes demonstrate that SALT consistently improves performance. We also conduct a thorough analysis to validate the design choices behind SALT and offer actionable insights.",
        "tags": [
            "GRPO",
            "LLM",
            "RL"
        ]
    },
    {
        "id": "46",
        "title": "Extreme Views: 3DGS Filter for Novel View Synthesis from Out-of-Distribution Camera Poses",
        "author": [
            "Damian Bowness",
            "Charalambos Poullis"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20027",
        "abstract": "When viewing a 3D Gaussian Splatting (3DGS) model from camera positions significantly outside the training data distribution, substantial visual noise commonly occurs. These artifacts result from the lack of training data in these extrapolated regions, leading to uncertain density, color, and geometry predictions from the model.\nTo address this issue, we propose a novel real-time render-aware filtering method. Our approach leverages sensitivity scores derived from intermediate gradients, explicitly targeting instabilities caused by anisotropic orientations rather than isotropic variance. This filtering method directly addresses the core issue of generative uncertainty, allowing 3D reconstruction systems to maintain high visual fidelity even when users freely navigate outside the original training viewpoints.\nExperimental evaluation demonstrates that our method substantially improves visual quality, realism, and consistency compared to existing Neural Radiance Field (NeRF)-based approaches such as BayesRays. Critically, our filter seamlessly integrates into existing 3DGS rendering pipelines in real-time, unlike methods that require extensive post-hoc retraining or fine-tuning.\nCode and results at https://damian-bowness.github.io/EV3DGS",
        "tags": [
            "3D",
            "Gaussian Splatting",
            "NeRF"
        ]
    },
    {
        "id": "47",
        "title": "Improving Transfer Learning for Sequence Labeling Tasks by Adapting Pre-trained Neural Language Models",
        "author": [
            "David DukiÄ"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20033",
        "abstract": "This doctoral thesis improves the transfer learning for sequence labeling tasks by adapting pre-trained neural language models. The proposed improvements in transfer learning involve introducing a multi-task model that incorporates an additional signal, a method based on architectural modifications in autoregressive large language models, and a sequence labeling framework for autoregressive large language models utilizing supervised in-context fine-tuning combined with response-oriented adaptation strategies. The first improvement is given in the context of domain transfer for the event trigger detection task. The domain transfer of the event trigger detection task can be improved by incorporating an additional signal obtained from a domain-independent text processing system into a multi-task model. The second improvement involves modifying the model's architecture. For that purpose, a method is proposed to enable bidirectional information flow across layers of autoregressive large language models. The third improvement utilizes autoregressive large language models as text generators through a generative supervised in-context fine-tuning framework. The proposed model, method, and framework demonstrate that pre-trained neural language models achieve their best performance on sequence labeling tasks when adapted through targeted transfer learning paradigms.",
        "tags": [
            "Detection",
            "LLM"
        ]
    },
    {
        "id": "48",
        "title": "ToolScope: Enhancing LLM Agent Tool Use through Tool Merging and Context-Aware Filtering",
        "author": [
            "Marianne Menglin Liu",
            "Daniel Garcia",
            "Fjona Parllaku",
            "Vikas Upadhyay",
            "Syed Fahad Allam Shah",
            "Dan Roth"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20036",
        "abstract": "Large language model (LLM) agents rely on external tools to solve complex tasks, but real-world toolsets often contain redundant tools with overlapping names and descriptions, introducing ambiguity and reducing selection accuracy. LLMs also face strict input context limits, preventing efficient consideration of large toolsets. To address these challenges, we propose ToolScope, which includes: (1) ToolScopeMerger with Auto-Correction to automatically audit and fix tool merges, reducing redundancy, and (2) ToolScopeRetriever to rank and select only the most relevant tools for each query, compressing toolsets to fit within context limits without sacrificing accuracy. Evaluations on three state-of-the-art LLMs and three open-source tool-use benchmarks show gains of 8.38% to 38.6% in tool selection accuracy, demonstrating ToolScope's effectiveness in enhancing LLM tool use.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "49",
        "title": "Beyond One-Way Influence: Bidirectional Opinion Dynamics in Multi-Turn Human-LLM Interactions",
        "author": [
            "Yuyang Jiang",
            "Longjie Guo",
            "Yuchen Wu",
            "Aylin Caliskan",
            "Tanu Mitra",
            "Hua Shen"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20039",
        "abstract": "Large language model (LLM)-powered chatbots are increasingly used for opinion exploration. Prior research examined how LLMs alter user views, yet little work extended beyond one-way influence to address how user input can affect LLM responses and how such bi-directional influence manifests throughout the multi-turn conversations. This study investigates this dynamic through 50 controversial-topic discussions with participants (N=266) across three conditions: static statements, standard chatbot, and personalized chatbot. Results show that human opinions barely shifted, while LLM outputs changed more substantially, narrowing the gap between human and LLM stance. Personalization amplified these shifts in both directions compared to the standard setting. Analysis of multi-turn conversations further revealed that exchanges involving participants' personal stories were most likely to trigger stance changes for both humans and LLMs. Our work highlights the risk of over-alignment in human-LLM interaction and the need for careful design of personalized chatbots to more thoughtfully and stably align with users.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "50",
        "title": "Exposing Blindspots: Cultural Bias Evaluation in Generative Image Models",
        "author": [
            "Huichan Seo",
            "Sieun Choi",
            "Minki Hong",
            "Yi Zhou",
            "Junseo Kim",
            "Lukman Ismaila",
            "Naome Etori",
            "Mehul Agarwal",
            "Zhixuan Liu",
            "Jihie Kim",
            "Jean Oh"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20042",
        "abstract": "Generative image models produce striking visuals yet often misrepresent culture. Prior work has examined cultural bias mainly in text-to-image (T2I) systems, leaving image-to-image (I2I) editors underexplored. We bridge this gap with a unified evaluation across six countries, an 8-category/36-subcategory schema, and era-aware prompts, auditing both T2I generation and I2I editing under a standardized protocol that yields comparable diagnostics. Using open models with fixed settings, we derive cross-country, cross-era, and cross-category evaluations. Our framework combines standard automatic metrics, a culture-aware retrieval-augmented VQA, and expert human judgments collected from native reviewers. To enable reproducibility, we release the complete image corpus, prompts, and configurations. Our study reveals three findings: (1) under country-agnostic prompts, models default to Global-North, modern-leaning depictions that flatten cross-country distinctions; (2) iterative I2I editing erodes cultural fidelity even when conventional metrics remain flat or improve; and (3) I2I models apply superficial cues (palette shifts, generic props) rather than era-consistent, context-aware changes, often retaining source identity for Global-South targets. These results highlight that culture-sensitive edits remain unreliable in current systems. By releasing standardized data, prompts, and human evaluation protocols, we provide a reproducible, culture-centered benchmark for diagnosing and tracking cultural bias in generative image models.",
        "tags": [
            "Text-to-Image"
        ]
    },
    {
        "id": "51",
        "title": "From Facts to Folklore: Evaluating Large Language Models on Bengali Cultural Knowledge",
        "author": [
            "Nafis Chowdhury",
            "Moinul Haque",
            "Anika Ahmed",
            "Nazia Tasnim",
            "Md. Istiak Hossain Shihab",
            "Sajjadur Rahman",
            "Farig Sadeque"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20043",
        "abstract": "Recent progress in NLP research has demonstrated remarkable capabilities of large language models (LLMs) across a wide range of tasks. While recent multilingual benchmarks have advanced cultural evaluation for LLMs, critical gaps remain in capturing the nuances of low-resource cultures. Our work addresses these limitations through a Bengali Language Cultural Knowledge (BLanCK) dataset including folk traditions, culinary arts, and regional dialects. Our investigation of several multilingual language models shows that while these models perform well in non-cultural categories, they struggle significantly with cultural knowledge and performance improves substantially across all models when context is provided, emphasizing context-aware architectures and culturally curated training data.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "52",
        "title": "Learning Personalized Ad Impact via Contextual Reinforcement Learning under Delayed Rewards",
        "author": [
            "Yuwei Cheng",
            "Zifeng Zhao",
            "Haifeng Xu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20055",
        "abstract": "Online advertising platforms use automated auctions to connect advertisers with potential customers, requiring effective bidding strategies to maximize profits. Accurate ad impact estimation requires considering three key factors: delayed and long-term effects, cumulative ad impacts such as reinforcement or fatigue, and customer heterogeneity. However, these effects are often not jointly addressed in previous studies. To capture these factors, we model ad bidding as a Contextual Markov Decision Process (CMDP) with delayed Poisson rewards. For efficient estimation, we propose a two-stage maximum likelihood estimator combined with data-splitting strategies, ensuring controlled estimation error based on the first-stage estimator's (in)accuracy. Building on this, we design a reinforcement learning algorithm to derive efficient personalized bidding strategies. This approach achieves a near-optimal regret bound of $\\tilde{O}{(dH^2\\sqrt{T})}$, where $d$ is the contextual dimension, $H$ is the number of rounds, and $T$ is the number of customers. Our theoretical findings are validated by simulation experiments.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "53",
        "title": "Not-a-Bandit: Provably No-Regret Drafter Selection in Speculative Decoding for LLMs",
        "author": [
            "Hongyi Liu",
            "Jiaji Huang",
            "Zhen Jia",
            "Youngsuk Park",
            "Yu-Xiang Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20064",
        "abstract": "Speculative decoding is widely used in accelerating large language model (LLM) inference. In this work, we focus on the online draft model selection problem in speculative decoding. We design an algorithm that provably competes with the best draft model in hindsight for each query in terms of either the token acceptance probability or expected acceptance length. In particular, we show that we can accurately evaluate all draft models, instead of only the chosen model without incurring additional queries to the target model, which allows us to improve exponentially over the existing bandit-based approach as the number of draft models increases. Our approach is generically applicable with any speculative decoding methods (single draft, multi-drafts and draft-trees). Moreover, we design system-efficient versions of online learners and demonstrate that the overhead in computation and latency can be substantially reduced. We conduct extensive experiments on open-source LLMs and diverse datasets, demonstrating that our methods substantially outperform the state-of-the-art EAGLE3 and the BanditSpec baseline in a variety of domains where specialized domain-expert drafters are available, especially when long reasoning chains are required.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "54",
        "title": "Coupled Transformer Autoencoder for Disentangling Multi-Region Neural Latent Dynamics",
        "author": [
            "Ram Dyuthi Sristi",
            "Sowmya Manojna Narasimha",
            "Jingya Huang",
            "Alice Despatin",
            "Simon Musall",
            "Vikash Gilja",
            "Gal Mishne"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20068",
        "abstract": "Simultaneous recordings from thousands of neurons across multiple brain areas reveal rich mixtures of activity that are shared between regions and dynamics that are unique to each region. Existing alignment or multi-view methods neglect temporal structure, whereas dynamical latent variable models capture temporal dependencies but are usually restricted to a single area, assume linear read-outs, or conflate shared and private signals. We introduce the Coupled Transformer Autoencoder (CTAE) - a sequence model that addresses both (i) non-stationary, non-linear dynamics and (ii) separation of shared versus region-specific structure in a single framework. CTAE employs transformer encoders and decoders to capture long-range neural dynamics and explicitly partitions each region's latent space into orthogonal shared and private subspaces. We demonstrate the effectiveness of CTAE on two high-density electrophysiology datasets with simultaneous recordings from multiple regions, one from motor cortical areas and the other from sensory areas. CTAE extracts meaningful representations that better decode behavioral variables compared to existing approaches.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "55",
        "title": "LLMs can hide text in other text of the same length.ipynb",
        "author": [
            "Antonio Norelli",
            "Michael Bronstein"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20075",
        "abstract": "A meaningful text can be hidden inside another, completely different yet still coherent and plausible, text of the same length. For example, a tweet containing a harsh political critique could be embedded in a tweet that celebrates the same political leader, or an ordinary product review could conceal a secret manuscript. This uncanny state of affairs is now possible thanks to Large Language Models, and in this paper we present a simple and efficient protocol to achieve it. We show that even modest 8-billion-parameter open-source LLMs are sufficient to obtain high-quality results, and a message as long as this abstract can be encoded and decoded locally on a laptop in seconds. The existence of such a protocol demonstrates a radical decoupling of text from authorial intent, further eroding trust in written communication, already shaken by the rise of LLM chatbots. We illustrate this with a concrete scenario: a company could covertly deploy an unfiltered LLM by encoding its answers within the compliant responses of a safe model. This possibility raises urgent questions for AI safety and challenges our understanding of what it means for a Large Language Model to know something.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "56",
        "title": "Hierarchical Dual-Head Model for Suicide Risk Assessment via MentalRoBERTa",
        "author": [
            "Chang Yang",
            "Ziyi Wang",
            "Wangfeng Tan",
            "Zhiting Tan",
            "Changrui Ji",
            "Zhiming Zhou"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20085",
        "abstract": "Social media platforms have become important sources for identifying suicide risk, but automated detection systems face multiple challenges including severe class imbalance, temporal complexity in posting patterns, and the dual nature of risk levels as both ordinal and categorical. This paper proposes a hierarchical dual-head neural network based on MentalRoBERTa for suicide risk classification into four levels: indicator, ideation, behavior, and attempt. The model employs two complementary prediction heads operating on a shared sequence representation: a CORAL (Consistent Rank Logits) head that preserves ordinal relationships between risk levels, and a standard classification head that enables flexible categorical distinctions. A 3-layer Transformer encoder with 8-head multi-head attention models temporal dependencies across post sequences, while explicit time interval embeddings capture posting behavior dynamics. The model is trained with a combined loss function (0.5 CORAL + 0.3 Cross-Entropy + 0.2 Focal Loss) that simultaneously addresses ordinal structure preservation, overconfidence reduction, and class imbalance. To improve computational efficiency, we freeze the first 6 layers (50%) of MentalRoBERTa and employ mixed-precision training. The model is evaluated using 5-fold stratified cross-validation with macro F1 score as the primary metric.",
        "tags": [
            "Detection",
            "Transformer"
        ]
    },
    {
        "id": "57",
        "title": "CreativityPrism: A Holistic Benchmark for Large Language Model Creativity",
        "author": [
            "Zhaoyi Joey Hou",
            "Bowei Alvin Zhang",
            "Yining Lu",
            "Bhiman Kumar Baghel",
            "Anneliese Brei",
            "Ximing Lu",
            "Meng Jiang",
            "Faeze Brahman",
            "Snigdha Chaturvedi",
            "Haw-Shiuan Chang",
            "Daniel Khashabi",
            "Xiang Lorraine Li"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20091",
        "abstract": "Creativity is often seen as a hallmark of human intelligence. While large language models (LLMs) are increasingly perceived as producing creative text, there is still no holistic framework to evaluate their creativity across diverse scenarios. Existing evaluation methods remain fragmented, with dramatic variation across domains and tasks, largely due to differing definitions and measurements of creativity. Inspired by the hypothesis that creativity is not one fixed idea, we propose CreativityPrism, an evaluation analysis framework that decomposes creativity into three dimensions: quality, novelty, and diversity. CreativityPrism incorporates nine tasks, three domains, i.e., divergent thinking, creative writing, and logical reasoning, and twenty evaluation metrics, which measure each dimension in task-specific, unique ways. We evaluate 17 state-of-the-art (SoTA) proprietary and open-sourced LLMs on CreativityPrism and analyze the performance correlations among different metrics and task domains. Our results reveal a notable gap between proprietary and open-source models. Overall, model performance tends to be highly correlated across tasks within the same domain and less so across different domains. Among evaluation dimensions, diversity and quality metrics show strong correlations - models that perform well on one often excel on the other - whereas novelty exhibits much weaker correlation with either. These findings support our hypothesis that strong performance in one creativity task or dimension does not necessarily generalize to others, underscoring the need for a holistic evaluation of LLM creativity.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "58",
        "title": "Attentive Convolution: Unifying the Expressivity of Self-Attention with Convolutional Efficiency",
        "author": [
            "Hao Yu",
            "Haoyu Chen",
            "Yan Jiang",
            "Wei Peng",
            "Zhaodong Sun",
            "Samuel Kaski",
            "Guoying Zhao"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20092",
        "abstract": "Self-attention (SA) has become the cornerstone of modern vision backbones for its powerful expressivity over traditional Convolutions (Conv). However, its quadratic complexity remains a critical bottleneck for practical applications. Given that Conv offers linear complexity and strong visual priors, continuing efforts have been made to promote the renaissance of Conv. However, a persistent performance chasm remains, highlighting that these modernizations have not yet captured the intrinsic expressivity that defines SA. In this paper, we re-examine the design of the CNNs, directed by a key question: what principles give SA its edge over Conv? As a result, we reveal two fundamental insights that challenge the long-standing design intuitions in prior research (e.g., Receptive field). The two findings are: (1) \\textit{Adaptive routing}: SA dynamically regulates positional information flow according to semantic content, whereas Conv employs static kernels uniformly across all positions. (2) \\textit{Lateral inhibition}: SA induces score competition among token weighting, effectively suppressing redundancy and sharpening representations, whereas Conv filters lack such inhibitory dynamics and exhibit considerable redundancy. Based on this, we propose \\textit{Attentive Convolution} (ATConv), a principled reformulation of the convolutional operator that intrinsically injects these principles. Interestingly, with only $3\\times3$ kernels, ATConv consistently outperforms various SA mechanisms in fundamental vision tasks. Building on ATConv, we introduce AttNet, a CNN family that can attain \\textbf{84.4\\%} ImageNet-1K Top-1 accuracy with only 27M parameters. In diffusion-based image generation, replacing all SA with the proposed $3\\times 3$ ATConv in SiT-XL/2 reduces ImageNet FID by 0.15 in 400k steps with faster sampling. Code is available at: http://github.com/price112/Attentive-Convolution.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "59",
        "title": "StableSketcher: Enhancing Diffusion Model for Pixel-based Sketch Generation via Visual Question Answering Feedback",
        "author": [
            "Jiho Park",
            "Sieun Choi",
            "Jaeyoon Seo",
            "Jihie Kim"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20093",
        "abstract": "Although recent advancements in diffusion models have significantly enriched the quality of generated images, challenges remain in synthesizing pixel-based human-drawn sketches, a representative example of abstract expression. To combat these challenges, we propose StableSketcher, a novel framework that empowers diffusion models to generate hand-drawn sketches with high prompt fidelity. Within this framework, we fine-tune the variational autoencoder to optimize latent decoding, enabling it to better capture the characteristics of sketches. In parallel, we integrate a new reward function for reinforcement learning based on visual question answering, which improves text-image alignment and semantic consistency. Extensive experiments demonstrate that StableSketcher generates sketches with improved stylistic fidelity, achieving better alignment with prompts compared to the Stable Diffusion baseline. Additionally, we introduce SketchDUO, to the best of our knowledge, the first dataset comprising instance-level sketches paired with captions and question-answer pairs, thereby addressing the limitations of existing datasets that rely on image-label pairs. Our code and dataset will be made publicly available upon acceptance.",
        "tags": [
            "Diffusion",
            "RL"
        ]
    },
    {
        "id": "60",
        "title": "Leveraging the Power of Large Language Models in Entity Linking via Adaptive Routing and Targeted Reasoning",
        "author": [
            "Yajie Li",
            "Albert Galimov",
            "Mitra Datta Ganapaneni",
            "Pujitha Thejaswi",
            "De Meng",
            "Priyanshu Kumar",
            "Saloni Potdar"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20098",
        "abstract": "Entity Linking (EL) has traditionally relied on large annotated datasets and extensive model fine-tuning. While recent few-shot methods leverage large language models (LLMs) through prompting to reduce training requirements, they often suffer from inefficiencies due to expensive LLM-based reasoning. ARTER (Adaptive Routing and Targeted Entity Reasoning) presents a structured pipeline that achieves high performance without deep fine-tuning by strategically combining candidate generation, context-based scoring, adaptive routing, and selective reasoning. ARTER computes a small set of complementary signals(both embedding and LLM-based) over the retrieved candidates to categorize contextual mentions into easy and hard cases. The cases are then handled by a low-computational entity linker (e.g. ReFinED) and more expensive targeted LLM-based reasoning respectively. On standard benchmarks, ARTER outperforms ReFinED by up to +4.47%, with an average gain of +2.53% on 5 out of 6 datasets, and performs comparably to pipelines using LLM-based reasoning for all mentions, while being as twice as efficient in terms of the number of LLM tokens.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "61",
        "title": "Competition is the key: A Game Theoretic Causal Discovery Approach",
        "author": [
            "Amartya Roy",
            "Souvik Chakraborty"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20106",
        "abstract": "Causal discovery remains a central challenge in machine learning, yet existing methods face a fundamental gap: algorithms like GES and GraN-DAG achieve strong empirical performance but lack finite-sample guarantees, while theoretically principled approaches fail to scale. We close this gap by introducing a game-theoretic reinforcement learning framework for causal discovery, where a DDQN agent directly competes against a strong baseline (GES or GraN-DAG), always warm-starting from the opponent's solution. This design yields three provable guarantees: the learned graph is never worse than the opponent, warm-starting strictly accelerates convergence, and most importantly, with high probability the algorithm selects the true best candidate graph. To the best of our knowledge, our result makes a first-of-its-kind progress in explaining such finite-sample guarantees in causal discovery: on synthetic SEMs (30 nodes), the observed error probability decays with n, tightly matching theory. On real-world benchmarks including Sachs, Asia, Alarm, Child, Hepar2, Dream, and Andes, our method consistently improves upon GES and GraN-DAG while remaining theoretically safe. Remarkably, it scales to large graphs such as Hepar2 (70 nodes), Dream (100 nodes), and Andes (220 nodes). Together, these results establish a new class of RL-based causal discovery algorithms that are simultaneously provably consistent, sample-efficient, and practically scalable, marking a decisive step toward unifying empirical performance with rigorous finite-sample theory.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "62",
        "title": "AsyncHZP: Hierarchical ZeRO Parallelism with Asynchronous Scheduling for Scalable LLM Training",
        "author": [
            "Huawei Bai",
            "Yifan Huang",
            "Wenqi Shi",
            "Ansheng You",
            "Feifan Shao",
            "Tengfei Han",
            "Minghui Yu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20111",
        "abstract": "The training efficiency and scalability of language models on massive clusters currently remain a critical bottleneck. Mainstream approaches like ND parallelism are often cumbersome and complex, while flexible alternatives such as the Zero Redundancy Optimizer (ZeRO) are frequently hampered by communication overhead. In this paper, we propose Asynchronous Hierarchical Zero Parallelism (AsyncHZP), a novel asynchronous variant of ZeRO designed to achieve superior performance while maintaining simplicity and memory efficiency. Unlike traditional ZeRO, which employs over-fine-grained sharding that can lead to inefficient communication, AsyncHZP adaptively reshards parameters, gradients, and optimizer states across different replica groups. This strategy optimizes device memory utilization and significantly reduces communication overhead. In addition, we also design a multi-stream asynchronous scheduling method that executes parameter all-gather and gradient reduce-scatter operations in dedicated background threads, effectively overlapping communication with computation while incurring negligible memory fragmentation. Empirical evaluations on both Dense and Mixture-of-Experts (MoE) models confirm that AsyncHZP maintains robust stability at scale. It consistently outperforms classic ND parallelism, achieving state-of-the-art performance without complex strategic tuning, thereby simplifying the path to efficient large-scale training.",
        "tags": [
            "LLM",
            "MoE"
        ]
    },
    {
        "id": "63",
        "title": "SpeechAgent: An End-to-End Mobile Infrastructure for Speech Impairment Assistance",
        "author": [
            "Haowei Lou",
            "Chengkai Huang",
            "Hye-young Paik",
            "Yongquan Hu",
            "Aaron Quigley",
            "Wen Hu",
            "Lina Yao"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20113",
        "abstract": "Speech is essential for human communication, yet millions of people face impairments such as dysarthria, stuttering, and aphasia conditions that often lead to social isolation and reduced participation. Despite recent progress in automatic speech recognition (ASR) and text-to-speech (TTS) technologies, accessible web and mobile infrastructures for users with impaired speech remain limited, hindering the practical adoption of these advances in daily communication. To bridge this gap, we present SpeechAgent, a mobile SpeechAgent designed to facilitate people with speech impairments in everyday communication. The system integrates large language model (LLM)- driven reasoning with advanced speech processing modules, providing adaptive support tailored to diverse impairment types. To ensure real-world practicality, we develop a structured deployment pipeline that enables real-time speech processing on mobile and edge devices, achieving imperceptible latency while maintaining high accuracy and speech quality. Evaluation on real-world impaired speech datasets and edge-device latency profiling confirms that SpeechAgent delivers both effective and user-friendly performance, demonstrating its feasibility for personalized, day-to-day assistive communication.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "64",
        "title": "\"Learning Together\": AI-Mediated Support for Parental Involvement in Everyday Learning",
        "author": [
            "Yao Li",
            "Jingyi Xie",
            "Ya-Fang Ling",
            "He Zhang",
            "Ge Wang",
            "Gaojian Huang",
            "Rui Yu",
            "Si Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20123",
        "abstract": "Family learning takes place in everyday routines where children and caregivers read, practice, and develop new skills together. Although AI is increasingly present in learning environments, most systems remain child-centered and overlook the collaborative, distributed nature of family education. This paper investigates how AI can mediate family collaboration by addressing tensions of coordination, uneven workloads, and parental mediation. From a formative study with families using AI in daily learning, we identified challenges in responsibility sharing and recognition of contributions. Building on these insights, we designed FamLearn, an LLM-powered prototype that distributes tasks, visualizes contributions, and provides individualized support. A one-week field study with 11 families shows how this prototype can ease caregiving burdens, foster recognition, and enrich shared learning experiences. Our findings suggest that LLMs can move beyond the role of tutor to act as family mediators - balancing responsibilities, scaffolding intergenerational participation, and strengthening the relational fabric of family learning.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "65",
        "title": "Physics-Guided Fusion for Robust 3D Tracking of Fast Moving Small Objects",
        "author": [
            "Prithvi Raj Singh",
            "Raju Gottumukkala",
            "Anthony S. Maida",
            "Alan B. Barhorst",
            "Vijaya Gopu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20126",
        "abstract": "While computer vision has advanced considerably for general object detection and tracking, the specific problem of fast-moving tiny objects remains underexplored. This paper addresses the significant challenge of detecting and tracking rapidly moving small objects using an RGB-D camera. Our novel system combines deep learning-based detection with physics-based tracking to overcome the limitations of existing approaches. Our contributions include: (1) a comprehensive system design for object detection and tracking of fast-moving small objects in 3D space, (2) an innovative physics-based tracking algorithm that integrates kinematics motion equations to handle outliers and missed detections, and (3) an outlier detection and correction module that significantly improves tracking performance in challenging scenarios such as occlusions and rapid direction changes. We evaluated our proposed system on a custom racquetball dataset. Our evaluation shows our system surpassing kalman filter based trackers with up to 70\\% less Average Displacement Error. Our system has significant applications for improving robot perception on autonomous platforms and demonstrates the effectiveness of combining physics-based models with deep learning approaches for real-time 3D detection and tracking of challenging small objects.",
        "tags": [
            "3D",
            "Detection",
            "Robotics"
        ]
    },
    {
        "id": "66",
        "title": "SAID: Empowering Large Language Models with Self-Activating Internal Defense",
        "author": [
            "Yulong Chen",
            "Yadong Liu",
            "Jiawen Zhang",
            "Mu Li",
            "Chao Huang",
            "Jie Wen"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20129",
        "abstract": "Large Language Models (LLMs), despite advances in safety alignment, remain vulnerable to jailbreak attacks designed to circumvent protective mechanisms. Prevailing defense strategies rely on external interventions, such as input filtering or output modification, which often lack generalizability and compromise model utility while incurring significant computational overhead. In this work, we introduce a new, training-free defense paradigm, Self-Activating Internal Defense (SAID), which reframes the defense task from external correction to internal capability activation. SAID uniquely leverages the LLM's own reasoning abilities to proactively identify and neutralize malicious intent through a three-stage pipeline: model-native intent distillation to extract core semantics, optimal safety prefix probing to activate latent safety awareness, and a conservative aggregation strategy to ensure robust decision-making. Extensive experiments on five open-source LLMs against six advanced jailbreak attacks demonstrate that SAID substantially outperforms state-of-the-art defenses in reducing harmful outputs. Crucially, it achieves this while preserving model performance on benign tasks and incurring minimal computational overhead. Our work establishes that activating the intrinsic safety mechanisms of LLMs is a more robust and scalable path toward building safer and more reliable aligned AI systems.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "67",
        "title": "BoundRL: Efficient Structured Text Segmentation through Reinforced Boundary Generation",
        "author": [
            "Haoyuan Li",
            "Zhengyuan Shen",
            "Sullam Jeoung",
            "Yueyan Chen",
            "Jiayu Li",
            "Qi Zhu",
            "Shuai Wang",
            "Vassilis Ioannidis",
            "Huzefa Rangwala"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20151",
        "abstract": "As structured texts become increasingly complex across diverse domains -- from technical reports to generative AI prompts -- the need for text segmentation into semantically meaningful components becomes critical. Such texts often contain elements beyond plain language, including tables, code snippets, and placeholders, which conventional sentence- or paragraph-level segmentation methods cannot handle effectively. To address this challenge, we propose BoundRL, a novel and efficient approach that jointly performs token-level text segmentation and label prediction for long structured texts. Instead of generating complete contents for each segment, it generates only a sequence of starting tokens and reconstructs the complete contents by locating these tokens within the original texts, thereby reducing inference costs by orders of magnitude and minimizing hallucination. To adapt the model for the output format, BoundRL~performs reinforcement learning with verifiable rewards (RLVR) with a specifically designed reward that jointly optimizes document reconstruction fidelity and semantic alignment. To mitigate entropy collapse, it further constructs intermediate candidates by systematically perturbing a fraction of generated sequences of segments to create stepping stones toward higher-quality solutions. To demonstrate BoundRL's effectiveness on particularly challenging structured texts, we focus evaluation on complex prompts used for LLM applications. Experiments show that BoundRL enables small language models (1.7B parameters) to outperform few-shot prompting of much larger models. Moreover, RLVR with our designed reward yields significant improvements over supervised fine-tuning, and incorporating intermediate candidates further improves both performance and generalization.",
        "tags": [
            "LLM",
            "RL",
            "Segmentation"
        ]
    },
    {
        "id": "68",
        "title": "Soft Switching Expert Policies for Controlling Systems with Uncertain Parameters",
        "author": [
            "Junya Ikemoto"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20152",
        "abstract": "This paper proposes a simulation-based reinforcement learning algorithm for controlling systems with uncertain and varying system parameters. While simulators are useful for safely learning control policies for physical systems, mitigating the reality gap remains a major challenge. To address the challenge, we propose a two-stage algorithm. In the first stage, multiple control policies are learned for systems with different parameters in a simulator. In the second stage, for a real system, the control policies learned in the first stage are smoothly switched using an online convex optimization algorithm based on observations. Our proposed algorithm is demonstrated through numerical experiments.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "69",
        "title": "Are Stereotypes Leading LLMs' Zero-Shot Stance Detection ?",
        "author": [
            "Anthony Dubreuil",
            "Antoine Gourru",
            "Christine Largeron",
            "Amine Trabelsi"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20154",
        "abstract": "Large Language Models inherit stereotypes from their pretraining data, leading to biased behavior toward certain social groups in many Natural Language Processing tasks, such as hateful speech detection or sentiment analysis. Surprisingly, the evaluation of this kind of bias in stance detection methods has been largely overlooked by the community. Stance Detection involves labeling a statement as being against, in favor, or neutral towards a specific target and is among the most sensitive NLP tasks, as it often relates to political leanings. In this paper, we focus on the bias of Large Language Models when performing stance detection in a zero-shot setting. We automatically annotate posts in pre-existing stance detection datasets with two attributes: dialect or vernacular of a specific group and text complexity/readability, to investigate whether these attributes influence the model's stance detection decisions. Our results show that LLMs exhibit significant stereotypes in stance detection tasks, such as incorrectly associating pro-marijuana views with low text complexity and African American dialect with opposition to Donald Trump.",
        "tags": [
            "Detection",
            "LLM"
        ]
    },
    {
        "id": "70",
        "title": "PartNeXt: A Next-Generation Dataset for Fine-Grained and Hierarchical 3D Part Understanding",
        "author": [
            "Penghao Wang",
            "Yiyang He",
            "Xin Lv",
            "Yukai Zhou",
            "Lan Xu",
            "Jingyi Yu",
            "Jiayuan Gu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20155",
        "abstract": "Understanding objects at the level of their constituent parts is fundamental to advancing computer vision, graphics, and robotics. While datasets like PartNet have driven progress in 3D part understanding, their reliance on untextured geometries and expert-dependent annotation limits scalability and usability. We introduce PartNeXt, a next-generation dataset addressing these gaps with over 23,000 high-quality, textured 3D models annotated with fine-grained, hierarchical part labels across 50 categories. We benchmark PartNeXt on two tasks: (1) class-agnostic part segmentation, where state-of-the-art methods (e.g., PartField, SAMPart3D) struggle with fine-grained and leaf-level parts, and (2) 3D part-centric question answering, a new benchmark for 3D-LLMs that reveals significant gaps in open-vocabulary part grounding. Additionally, training Point-SAM on PartNeXt yields substantial gains over PartNet, underscoring the dataset's superior quality and diversity. By combining scalable annotation, texture-aware labels, and multi-task evaluation, PartNeXt opens new avenues for research in structured 3D understanding.",
        "tags": [
            "3D",
            "LLM",
            "Robotics",
            "SAM",
            "Segmentation"
        ]
    },
    {
        "id": "71",
        "title": "IEnSF: Iterative Ensemble Score Filter for Reducing Error in Posterior Score Estimation in Nonlinear Data Assimilation",
        "author": [
            "Zezhong Zhang",
            "Feng Bao",
            "Guannan Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20159",
        "abstract": "The Ensemble Score Filter (EnSF) has emerged as a promising approach to leverage score-based diffusion models for solving high-dimensional and nonlinear data assimilation problems. While initial applications of EnSF to the Lorenz-96 model and the quasi-geostrophic system showed potential, the current method employs a heuristic weighted sum to combine the prior and the likelihood score functions. This introduces a structural error into the estimation of the posterior score function in the nonlinear setting. This work addresses this challenge by developing an iterative ensemble score filter (IEnSF) that applies an iterative algorithm as an outer loop around the reverse-time stochastic differential equation solver. When the state dynamics or the observation operator is nonlinear, the iterative algorithm can gradually reduce the posterior score estimation error by improving the accuracy of approximating the conditional expectation of the likelihood score function. The number of iterations required depends on the distance between the prior and posterior distributions and the nonlinearity of the observation operator. Numerical experiments demonstrate that the IEnSF algorithm substantially reduces the error in posterior score estimation in the nonlinear setting and thus improves the accuracy of tracking high-dimensional dynamical systems.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "72",
        "title": "PathFormer: A Transformer with 3D Grid Constraints for Digital Twin Robot-Arm Trajectory Generation",
        "author": [
            "Ahmed Alanazi",
            "Duy Ho",
            "Yugyung Lee"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20161",
        "abstract": "Robotic arms require precise, task-aware trajectory planning, yet sequence models that ignore motion structure often yield invalid or inefficient executions. We present a Path-based Transformer that encodes robot motion with a 3-grid (where/what/when) representation and constraint-masked decoding, enforcing lattice-adjacent moves and workspace bounds while reasoning over task graphs and action order. Trained on 53,755 trajectories (80% train / 20% validation), the model aligns closely with ground truth -- 89.44% stepwise accuracy, 93.32% precision, 89.44% recall, and 90.40% F1 -- with 99.99% of paths legal by construction. Compiled to motor primitives on an xArm Lite 6 with a depth-camera digital twin, it attains up to 97.5% reach and 92.5% pick success in controlled tests, and 86.7% end-to-end success across 60 language-specified tasks in cluttered scenes, absorbing slips and occlusions via local re-grounding without global re-planning. These results show that path-structured representations enable Transformers to generate accurate, reliable, and interpretable robot trajectories, bridging graph-based planning and sequence-based learning and providing a practical foundation for general-purpose manipulation and sim-to-real transfer.",
        "tags": [
            "3D",
            "Robotics",
            "Transformer"
        ]
    },
    {
        "id": "73",
        "title": "IB-GAN: Disentangled Representation Learning with Information Bottleneck Generative Adversarial Networks",
        "author": [
            "Insu Jeon",
            "Wonkwang Lee",
            "Myeongjang Pyeon",
            "Gunhee Kim"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20165",
        "abstract": "We propose a new GAN-based unsupervised model for disentangled representation learning. The new model is discovered in an attempt to utilize the Information Bottleneck (IB) framework to the optimization of GAN, thereby named IB-GAN. The architecture of IB-GAN is partially similar to that of InfoGAN but has a critical difference; an intermediate layer of the generator is leveraged to constrain the mutual information between the input and the generated output. The intermediate stochastic layer can serve as a learnable latent distribution that is trained with the generator jointly in an end-to-end fashion. As a result, the generator of IB-GAN can harness the latent space in a disentangled and interpretable manner. With the experiments on dSprites and Color-dSprites dataset, we demonstrate that IB-GAN achieves competitive disentanglement scores to those of state-of-the-art \\b{eta}-VAEs and outperforms InfoGAN. Moreover, the visual quality and the diversity of samples generated by IB-GAN are often better than those by \\b{eta}-VAEs and Info-GAN in terms of FID score on CelebA and 3D Chairs dataset.",
        "tags": [
            "3D",
            "GAN"
        ]
    },
    {
        "id": "74",
        "title": "Collective Communication for 100k+ GPUs",
        "author": [
            "Min Si",
            "Pavan Balaji",
            "Yongzhou Chen",
            "Ching-Hsiang Chu",
            "Adi Gangidi",
            "Saif Hasan",
            "Subodh Iyengar",
            "Dan Johnson",
            "Bingzhe Liu",
            "Jingliang Ren",
            "Ashmitha Jeevaraj Shetty",
            "Greg Steinbrecher",
            "Xinfeng Xie",
            "Yulun Wang",
            "Bruce Wu",
            "Jingyi Yang",
            "Mingran Yang",
            "Minlan Yu",
            "Cen Zhao",
            "Wes Bland",
            "Denis Boyda",
            "Suman Gumudavelli",
            "Cristian Lumezanu",
            "Rui Miao",
            "Zhe Qu",
            "Venkat Ramesh",
            "Maxim Samoylov",
            "Jan Seidel",
            "Feng Tian",
            "Qiye Tan",
            "Shuqiang Zhang",
            "Yimeng Zhao",
            "Shengbao Zheng",
            "Art Zhu",
            "Hongyi Zeng"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20171",
        "abstract": "The increasing scale of large language models (LLMs) necessitates highly efficient collective communication frameworks, particularly as training workloads extend to hundreds of thousands of GPUs. Traditional communication methods face significant throughput and latency limitations at this scale, hindering both the development and deployment of state-of-the-art models. This paper presents the NCCLX collective communication framework, developed at Meta, engineered to optimize performance across the full LLM lifecycle, from the synchronous demands of large-scale training to the low-latency requirements of inference. The framework is designed to support complex workloads on clusters exceeding 100,000 GPUs, ensuring reliable, high-throughput, and low-latency data exchange. Empirical evaluation on the Llama4 model demonstrates substantial improvements in communication efficiency. This research contributes a robust solution for enabling the next generation of LLMs to operate at unprecedented scales.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "75",
        "title": "Reinforcement Learning-based Robust Wall Climbing Locomotion Controller in Ferromagnetic Environment",
        "author": [
            "Yong Um",
            "Young-Ha Shin",
            "Joon-Ha Kim",
            "Soonpyo Kwon",
            "Hae-Won Park"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20174",
        "abstract": "We present a reinforcement learning framework for quadrupedal wall-climbing locomotion that explicitly addresses uncertainty in magnetic foot adhesion. A physics-based adhesion model of a quadrupedal magnetic climbing robot is incorporated into simulation to capture partial contact, air-gap sensitivity, and probabilistic attachment failures. To stabilize learning and enable reliable transfer, we design a three-phase curriculum: (1) acquire a crawl gait on flat ground without adhesion, (2) gradually rotate the gravity vector to vertical while activating the adhesion model, and (3) inject stochastic adhesion failures to encourage slip recovery. The learned policy achieves a high success rate, strong adhesion retention, and rapid recovery from detachment in simulation under degraded adhesion. Compared with a model predictive control (MPC) baseline that assumes perfect adhesion, our controller maintains locomotion when attachment is intermittently lost. Hardware experiments with the untethered robot further confirm robust vertical crawling on steel surfaces, maintaining stability despite transient misalignment and incomplete attachment. These results show that combining curriculum learning with realistic adhesion modeling provides a resilient sim-to-real framework for magnetic climbing robots in complex environments.",
        "tags": [
            "MPC",
            "RL",
            "Robotics"
        ]
    },
    {
        "id": "76",
        "title": "Mixture-of-Minds: Multi-Agent Reinforcement Learning for Table Understanding",
        "author": [
            "Yuhang Zhou",
            "Mingrui Zhang",
            "Ke Li",
            "Mingyi Wang",
            "Qiao Liu",
            "Qifei wang",
            "Jiayi Liu",
            "Fei Liu",
            "Serena Li",
            "Weiwi Li",
            "Mingze Gao",
            "Abhishek Kumar",
            "Xiangjun Fan",
            "Zhuokai Zhao",
            "Lizhu Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20176",
        "abstract": "Understanding and reasoning over tables is a critical capability for many real-world applications. Large language models (LLMs) have shown promise on this task, but current approaches remain limited. Fine-tuning based methods strengthen language reasoning; yet they are prone to arithmetic errors and hallucination. In contrast, tool-based methods enable precise table manipulation but rely on rigid schemas and lack semantic understanding. These complementary drawbacks highlight the need for approaches that integrate robust reasoning with reliable table processing. In this work, we propose Mixture-of-Minds, a multi-agent framework that decomposes table reasoning into three specialized roles: planning, coding, and answering. This design enables each agent to focus on a specific aspect of the task while leveraging code execution for precise table manipulation. Building on this workflow, we introduce a self-improvement training framework that employs Monte Carlo Tree Search (MCTS) rollouts to generate pseudo-gold trajectories and optimize agents with reinforcement learning (RL). Extensive experiments show that Mixture-of-Minds delivers substantial gains, reaching 62.13% on TableBench and surpassing OpenAI-o4-mini-high. These results demonstrate the promise of combining structured multi-agent workflows with RL to advance table understanding.",
        "tags": [
            "LLM",
            "RL"
        ]
    },
    {
        "id": "77",
        "title": "Information Gradient for Nonlinear Gaussian Channel with Applications to Task-Oriented Communication",
        "author": [
            "Tadashi Wadayama"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20179",
        "abstract": "We propose a gradient-based framework for optimizing parametric nonlinear Gaussian channels via mutual information maximization. Leveraging the score-to-Fisher bridge (SFB) methodology, we derive a computationally tractable formula for the information gradient that is the gradient of mutual information with respect to the parameters of the nonlinear front-end. Our formula expresses this gradient in terms of two key components: the score function of the marginal output distribution, which can be learned via denoising score matching (DSM), and the Jacobian of the front-end function, which is handled efficiently using the vector-Jacobian product (VJP) within automatic differentiation frameworks. This enables practical parameter optimization through gradient ascent. Furthermore, we extend this framework to task-oriented scenarios, deriving gradients for both task-specific mutual information, where a task variable depends on the channel input, and the information bottleneck (IB) objective. A key advantage of our approach is that it facilitates end-to-end optimization of the nonlinear front-end without requiring explicit computation on the output distribution. Extensive experimental validation confirms the correctness of our information gradient formula against analytical solutions and demonstrates its effectiveness in optimizing both linear and nonlinear channels toward their objectives.",
        "tags": [
            "Score Matching"
        ]
    },
    {
        "id": "78",
        "title": "Evaluating Video Models as Simulators of Multi-Person Pedestrian Trajectories",
        "author": [
            "Aaron Appelle",
            "Jerome P. Lynch"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20182",
        "abstract": "Large-scale video generation models have demonstrated high visual realism in diverse contexts, spurring interest in their potential as general-purpose world simulators. Existing benchmarks focus on individual subjects rather than scenes with multiple interacting people. However, the plausibility of multi-agent dynamics in generated videos remains unverified. We propose a rigorous evaluation protocol to benchmark text-to-video (T2V) and image-to-video (I2V) models as implicit simulators of pedestrian dynamics. For I2V, we leverage start frames from established datasets to enable comparison with a ground truth video dataset. For T2V, we develop a prompt suite to explore diverse pedestrian densities and interactions. A key component is a method to reconstruct 2D bird's-eye view trajectories from pixel-space without known camera parameters. Our analysis reveals that leading models have learned surprisingly effective priors for plausible multi-agent behavior. However, failure modes like merging and disappearing people highlight areas for future improvement.",
        "tags": [
            "Text-to-Video",
            "Video Generation"
        ]
    },
    {
        "id": "79",
        "title": "Every Question Has Its Own Value: Reinforcement Learning with Explicit Human Values",
        "author": [
            "Dian Yu",
            "Yulai Zhao",
            "Kishan Panaganti",
            "Linfeng Song",
            "Haitao Mi",
            "Dong Yu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20187",
        "abstract": "We propose Reinforcement Learning with Explicit Human Values (RLEV), a method that aligns Large Language Model (LLM) optimization directly with quantifiable human value signals. While Reinforcement Learning with Verifiable Rewards (RLVR) effectively trains models in objective domains using binary correctness rewards, it overlooks that not all tasks are equally significant. RLEV extends this framework by incorporating human-defined value signals directly into the reward function. Using exam-style data with explicit ground-truth value labels, RLEV consistently outperforms correctness-only baselines across multiple RL algorithms and model scales. Crucially, RLEV policies not only improve value-weighted accuracy but also learn a value-sensitive termination policy: concise for low-value prompts, thorough for high-value ones. We demonstrate this behavior stems from value-weighted gradient amplification on end-of-sequence tokens. Ablation studies confirm the gain is causally linked to value alignment. RLEV remains robust under noisy value signals, such as difficulty-based labels, demonstrating that optimizing for an explicit utility function offers a practical path to aligning LLMs with human priorities.",
        "tags": [
            "LLM",
            "RL"
        ]
    },
    {
        "id": "80",
        "title": "The Lock-In Phase Hypothesis: Identity Consolidation as a Precursor to AGI",
        "author": [
            "Marcelo Maciel Amaral",
            "Raymond Aschheim"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20190",
        "abstract": "Large language models (LLMs) remain broadly open and highly steerable: they imitate at scale, accept arbitrary system prompts, and readily adopt multiple personae. By analogy to human development, we hypothesize that progress toward artificial general intelligence (AGI) involves a lock-in phase: a transition from open imitation to identity consolidation, in which goal structures, refusals, preferences, and internal representations become comparatively stable and resistant to external steering. We formalize this phase, link it to known phenomena in learning dynamics, and propose operational metrics for onset detection. Experimentally, we demonstrate that while the behavioral consolidation is rapid and non-linear, its side-effects on general capabilities are not monolithic. Our results reveal a spectrum of outcomes--from performance trade-offs in small models, through largely cost-free adoption in mid-scale models, to transient instabilities in large, quantized models. We argue that such consolidation is a prerequisite for AGI-level reliability and also a critical control point for safety: identities can be deliberately engineered for reliability, yet may also emerge spontaneously during scaling, potentially hardening unpredictable goals and behaviors.",
        "tags": [
            "Detection",
            "LLM"
        ]
    },
    {
        "id": "81",
        "title": "Stuck in the Matrix: Probing Spatial Reasoning in Large Language Models",
        "author": [
            "Maggie Bai",
            "Ava Kim Cohen",
            "Eleanor Koss",
            "Charlie Lichtenbaum"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20198",
        "abstract": "This paper explores the spatial reasoning capability of large language models (LLMs) over textual input through a suite of five tasks aimed at probing their spatial understanding and computational abilities. The models were tested on both fundamental spatial reasoning and multi-step problem-solving within structured grid-based environments using tasks such as quadrant identification, geometric transformations, distance evaluation, word searches, and tile sliding. Each task was scaled in complexity through increasing grid dimensions, requiring models to extend beyond simple pattern recognition into abstract spatial reasoning. Our results reveal that while LLMs demonstrate moderate success in all tasks with small complexity and size, performance drops off rapidly as scale increases, with an average loss in accuracy of 42.7%, and reaching as high as 84%. Every test that began with over 50% accuracy showed a loss of at least 48%, illustrating the consistent nature of the deterioration. Furthermore, their struggles with scaling complexity hint at a lack of robust spatial representations in their underlying architectures. This paper underscores the gap between linguistic and spatial reasoning in LLMs, offering insights into their current limitations, and laying the groundwork for future integrative benchmarks at the intersection of language and geometry.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "82",
        "title": "Risk-Averse Constrained Reinforcement Learning with Optimized Certainty Equivalents",
        "author": [
            "Jane H. Lee",
            "Baturay Saglam",
            "Spyridon Pougkakiotis",
            "Amin Karbasi",
            "Dionysis Kalogerias"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20199",
        "abstract": "Constrained optimization provides a common framework for dealing with conflicting objectives in reinforcement learning (RL). In most of these settings, the objectives (and constraints) are expressed though the expected accumulated reward. However, this formulation neglects risky or even possibly catastrophic events at the tails of the reward distribution, and is often insufficient for high-stakes applications in which the risk involved in outliers is critical. In this work, we propose a framework for risk-aware constrained RL, which exhibits per-stage robustness properties jointly in reward values and time using optimized certainty equivalents (OCEs). Our framework ensures an exact equivalent to the original constrained problem within a parameterized strong Lagrangian duality framework under appropriate constraint qualifications, and yields a simple algorithmic recipe which can be wrapped around standard RL solvers, such as PPO. Lastly, we establish the convergence of the proposed algorithm under common assumptions, and verify the risk-aware properties of our approach through several numerical experiments.",
        "tags": [
            "PPO",
            "RL"
        ]
    },
    {
        "id": "83",
        "title": "From Bundles to Backstepping: Geometric Control Barrier Functions for Safety-Critical Control on Manifolds",
        "author": [
            "Massimiliano de Sa",
            "Pio Ong",
            "Aaron D. Ames"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20202",
        "abstract": "Control barrier functions (CBFs) have a well-established theory in Euclidean spaces, yet still lack general formulations and constructive synthesis tools for systems evolving on manifolds common in robotics and aerospace applications. In this paper, we develop a general theory of geometric CBFs on bundles and, for control-affine systems, recover the standard optimization-based CBF controllers and their smooth analogues. Then, by generalizing kinetic energy-based CBF backstepping to Riemannian manifolds, we provide a constructive CBF synthesis technique for geometric mechanical systems, as well as easily verifiable conditions under which it succeeds. Further, this technique utilizes mechanical structure to avoid computations on higher-order tangent bundles. We demonstrate its application to an underactuated satellite on SO(3).",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "84",
        "title": "Merge and Conquer: Evolutionarily Optimizing AI for 2048",
        "author": [
            "Maggie Bai",
            "Ava Kim Cohen",
            "Eleanor Koss",
            "Charlie Lichtenbaum"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20205",
        "abstract": "Optimizing artificial intelligence (AI) for dynamic environments remains a fundamental challenge in machine learning research. In this paper, we examine evolutionary training methods for optimizing AI to solve the game 2048, a 2D sliding puzzle. 2048, with its mix of strategic gameplay and stochastic elements, presents an ideal playground for studying decision-making, long-term planning, and dynamic adaptation. We implemented two distinct systems: a two-agent metaprompting system where a \"thinker\" large language model (LLM) agent refines gameplay strategies for an \"executor\" LLM agent, and a single-agent system based on refining a value function for a limited Monte Carlo Tree Search. We also experimented with rollback features to avoid performance degradation. Our results demonstrate the potential of evolutionary refinement techniques in improving AI performance in non-deterministic environments. The single-agent system achieved substantial improvements, with an average increase of 473.2 points per cycle, and with clear upward trends (correlation $\\rho$=0.607) across training cycles. The LLM's understanding of the game grew as well, shown in its development of increasingly advanced strategies. Conversely, the two-agent system did not garner much improvement, highlighting the inherent limits of meta-prompting.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "85",
        "title": "RAPO++: Cross-Stage Prompt Optimization for Text-to-Video Generation via Data Alignment and Test-Time Scaling",
        "author": [
            "Bingjie Gao",
            "Qianli Ma",
            "Xiaoxue Wu",
            "Shuai Yang",
            "Guanzhou Lan",
            "Haonan Zhao",
            "Jiaxuan Chen",
            "Qingyang Liu",
            "Yu Qiao",
            "Xinyuan Chen",
            "Yaohui Wang",
            "Li Niu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20206",
        "abstract": "Prompt design plays a crucial role in text-to-video (T2V) generation, yet user-provided prompts are often short, unstructured, and misaligned with training data, limiting the generative potential of diffusion-based T2V models. We present \\textbf{RAPO++}, a cross-stage prompt optimization framework that unifies training-data--aligned refinement, test-time iterative scaling, and large language model (LLM) fine-tuning to substantially improve T2V generation without modifying the underlying generative backbone. In \\textbf{Stage 1}, Retrieval-Augmented Prompt Optimization (RAPO) enriches user prompts with semantically relevant modifiers retrieved from a relation graph and refactors them to match training distributions, enhancing compositionality and multi-object fidelity. \\textbf{Stage 2} introduces Sample-Specific Prompt Optimization (SSPO), a closed-loop mechanism that iteratively refines prompts using multi-source feedback -- including semantic alignment, spatial fidelity, temporal coherence, and task-specific signals such as optical flow -- yielding progressively improved video generation quality. \\textbf{Stage 3} leverages optimized prompt pairs from SSPO to fine-tune the rewriter LLM, internalizing task-specific optimization patterns and enabling efficient, high-quality prompt generation even before inference. Extensive experiments across five state-of-the-art T2V models and five benchmarks demonstrate that RAPO++ achieves significant gains in semantic alignment, compositional reasoning, temporal stability, and physical plausibility, outperforming existing methods by large margins. Our results highlight RAPO++ as a model-agnostic, cost-efficient, and scalable solution that sets a new standard for prompt optimization in T2V generation. The code is available at https://github.com/Vchitect/RAPO.",
        "tags": [
            "Diffusion",
            "LLM",
            "Text-to-Video",
            "Video Generation"
        ]
    },
    {
        "id": "86",
        "title": "Decoding-Free Sampling Strategies for LLM Marginalization",
        "author": [
            "David Pohl",
            "Marco Cognetta",
            "Junyoung Lee",
            "Naoaki Okazaki"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20208",
        "abstract": "Modern language models operate on subword-tokenized text in order to make a trade-off between model size, inference speed, and vocabulary coverage. A side effect of this is that, during inference, models are evaluated by measuring the probability of only the specific tokenization produced as the output, despite there being many possible ways to represent the same text with a subword vocabulary. Recent studies have argued instead for evaluating LLMs by marginalization - the probability mass of all tokenizations of a given text.\nMarginalization is difficult due to the number of possible tokenizations of a text, so often approximate marginalization is done via sampling. However, a downside of sampling is that an expensive generation step must be performed by the LLM for each sample, which limits the number of samples that can be acquired given a runtime budget, and therefore also the accuracy of the approximation. Since computing the probability of a sequence given the tokenization is relatively cheap compared to actually generating it, we investigate sampling strategies that are decoding-free - they require no generation from the LLM, instead relying entirely on extremely cheap sampling strategies that are model and tokenizer agnostic.\nWe investigate the approximation quality and speed of decoding-free sampling strategies for a number of open models to find that they provide sufficiently accurate marginal estimates at a small fraction of the runtime cost and demonstrate its use on a set of downstream inference tasks.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "87",
        "title": "Vox-Evaluator: Enhancing Stability and Fidelity for Zero-shot TTS with A Multi-Level Evaluator",
        "author": [
            "Hualei Wang",
            "Na Li",
            "Chuke Wang",
            "Shu Wu",
            "Zhifeng Li",
            "Dong Yu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20210",
        "abstract": "Recent advances in zero-shot text-to-speech (TTS), driven by language models, diffusion models and masked generation, have achieved impressive naturalness in speech synthesis. Nevertheless, stability and fidelity remain key challenges, manifesting as mispronunciations, audible noise, and quality degradation. To address these issues, we introduce Vox-Evaluator, a multi-level evaluator designed to guide the correction of erroneous speech segments and preference alignment for TTS systems. It is capable of identifying the temporal boundaries of erroneous segments and providing a holistic quality assessment of the generated speech. Specifically, to refine erroneous segments and enhance the robustness of the zero-shot TTS model, we propose to automatically identify acoustic errors with the evaluator, mask the erroneous segments, and finally regenerate speech conditioning on the correct portions. In addition, the fine-gained information obtained from Vox-Evaluator can guide the preference alignment for TTS model, thereby reducing the bad cases in speech synthesis. Due to the lack of suitable training datasets for the Vox-Evaluator, we also constructed a synthesized text-speech dataset annotated with fine-grained pronunciation errors or audio quality issues. The experimental results demonstrate the effectiveness of the proposed Vox-Evaluator in enhancing the stability and fidelity of TTS systems through the speech correction mechanism and preference optimization. The demos are shown.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "88",
        "title": "Automated Cloud Infrastructure-as-Code Reconciliation with AI Agents",
        "author": [
            "Zhenning Yang",
            "Hui Guan",
            "Victor Nicolet",
            "Brandon Paulsen",
            "Joey Dodds",
            "Daniel Kroening",
            "Ang Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20211",
        "abstract": "Cloud infrastructure is managed through a mix of interfaces -- traditionally, cloud consoles, command-line interfaces (CLI), and SDKs are the tools of choice. Recently, Infrastructure-as-Code/IaC frameworks (e.g., Terraform) have quickly gained popularity. Unlike conventional tools, IaC~frameworks encode the infrastructure in a \"source-of-truth\" configuration. They are capable of automatically carrying out modifications to the cloud -- deploying, updating, or destroying resources -- to bring the actual infrastructure into alignment with the IaC configuration. However, when IaC is used alongside consoles, CLIs, or SDKs, it loses visibility into external changes, causing infrastructure drift, where the configuration becomes outdated, and later IaC operations may undo valid updates or trigger errors.\nWe present NSync, an automated system for IaC reconciliation that propagates out-of-band changes back into the IaC program. Our key insight is that infrastructure changes eventually all occur via cloud API invocations -- the lowest layer for cloud management operations. NSync gleans insights from API traces to detect drift (i.e., non-IaC changes) and reconcile it (i.e., update the IaC configuration to capture the changes). It employs an agentic architecture that leverages LLMs to infer high-level intents from noisy API sequences, synthesize targeted IaC updates using specialized tools, and continually improve through a self-evolving knowledge base of past reconciliations. We further introduce a novel evaluation pipeline for injecting realistic drifts into cloud infrastructure and assessing reconciliation performance. Experiments across five real-world Terraform projects and 372 drift scenarios show that NSync outperforms the baseline both in terms of accuracy (from 0.71 to 0.97 pass@3) and token efficiency (1.47$\\times$ improvement).",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "89",
        "title": "FlowCycle: Pursuing Cycle-Consistent Flows for Text-based Editing",
        "author": [
            "Yanghao Wang",
            "Zhen Wang",
            "Long Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20212",
        "abstract": "Recent advances in pre-trained text-to-image flow models have enabled remarkable progress in text-based image editing. Mainstream approaches always adopt a corruption-then-restoration paradigm, where the source image is first corrupted into an ``intermediate state'' and then restored to the target image under the prompt guidance. However, current methods construct this intermediate state in a target-agnostic manner, i.e., they primarily focus on realizing source image reconstruction while neglecting the semantic gaps towards the specific editing target. This design inherently results in limited editability or inconsistency when the desired modifications substantially deviate from the source. In this paper, we argue that the intermediate state should be target-aware, i.e., selectively corrupting editing-relevant contents while preserving editing-irrelevant ones. To this end, we propose FlowCycle, a novel inversion-free and flow-based editing framework that parameterizes corruption with learnable noises and optimizes them through a cycle-consistent process. By iteratively editing the source to the target and recovering back to the source with dual consistency constraints, FlowCycle learns to produce a target-aware intermediate state, enabling faithful modifications while preserving source consistency. Extensive ablations have demonstrated that FlowCycle achieves superior editing quality and consistency over state-of-the-art methods.",
        "tags": [
            "Image Editing",
            "Text-to-Image"
        ]
    },
    {
        "id": "90",
        "title": "EditInfinity: Image Editing with Binary-Quantized Generative Models",
        "author": [
            "Jiahuan Wang",
            "Yuxin Chen",
            "Jun Yu",
            "Guangming Lu",
            "Wenjie Pei"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20217",
        "abstract": "Adapting pretrained diffusion-based generative models for text-driven image editing with negligible tuning overhead has demonstrated remarkable potential. A classical adaptation paradigm, as followed by these methods, first infers the generative trajectory inversely for a given source image by image inversion, then performs image editing along the inferred trajectory guided by the target text prompts. However, the performance of image editing is heavily limited by the approximation errors introduced during image inversion by diffusion models, which arise from the absence of exact supervision in the intermediate generative steps. To circumvent this issue, we investigate the parameter-efficient adaptation of VQ-based generative models for image editing, and leverage their inherent characteristic that the exact intermediate quantized representations of a source image are attainable, enabling more effective supervision for precise image inversion. Specifically, we propose \\emph{EditInfinity}, which adapts \\emph{Infinity}, a binary-quantized generative model, for image editing. We propose an efficient yet effective image inversion mechanism that integrates text prompting rectification and image style preservation, enabling precise image inversion. Furthermore, we devise a holistic smoothing strategy which allows our \\emph{EditInfinity} to perform image editing with high fidelity to source images and precise semantic alignment to the text prompts. Extensive experiments on the PIE-Bench benchmark across \"add\", \"change\", and \"delete\" editing operations, demonstrate the superior performance of our model compared to state-of-the-art diffusion-based baselines. Code available at: https://github.com/yx-chen-ust/EditInfinity.",
        "tags": [
            "Diffusion",
            "Image Editing"
        ]
    },
    {
        "id": "91",
        "title": "High-order Interactions Modeling for Interpretable Multi-Agent Q-Learning",
        "author": [
            "Qinyu Xu",
            "Yuanyang Zhu",
            "Xuefei Wu",
            "Chunlin Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20218",
        "abstract": "The ability to model interactions among agents is crucial for effective coordination and understanding their cooperation mechanisms in multi-agent reinforcement learning (MARL). However, previous efforts to model high-order interactions have been primarily hindered by the combinatorial explosion or the opaque nature of their black-box network structures. In this paper, we propose a novel value decomposition framework, called Continued Fraction Q-Learning (QCoFr), which can flexibly capture arbitrary-order agent interactions with only linear complexity $\\mathcal{O}\\left({n}\\right)$ in the number of agents, thus avoiding the combinatorial explosion when modeling rich cooperation. Furthermore, we introduce the variational information bottleneck to extract latent information for estimating credits. This latent information helps agents filter out noisy interactions, thereby significantly enhancing both cooperation and interpretability. Extensive experiments demonstrate that QCoFr not only consistently achieves better performance but also provides interpretability that aligns with our theoretical analysis.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "92",
        "title": "QKCV Attention: Enhancing Time Series Forecasting with Static Categorical Embeddings for Both Lightweight and Pre-trained Foundation Models",
        "author": [
            "Hao Wang",
            "Baojun Ma"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20222",
        "abstract": "In real-world time series forecasting tasks, category information plays a pivotal role in capturing inherent data patterns. This paper introduces QKCV (Query-Key-Category-Value) attention, an extension of the traditional QKV framework that incorporates a static categorical embedding C to emphasize category-specific information. As a versatile plug-in module, QKCV enhances the forecasting accuracy of attention-based models (e.g., Vanilla Transformer, Informer, PatchTST, TFT) across diverse real-world datasets. Furthermore, QKCV demonstrates remarkable adaptability in fine-tuning univariate time series foundation model by solely updating the static embedding C while preserving pretrained weights, thereby reducing computational overhead and achieving superior fine-tuning performance.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "93",
        "title": "Why LVLMs Are More Prone to Hallucinations in Longer Responses: The Role of Context",
        "author": [
            "Ge Zheng",
            "Jiaye Qian",
            "Jiajin Tang",
            "Sibei Yang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20229",
        "abstract": "Large Vision-Language Models (LVLMs) have made significant progress in recent years but are also prone to hallucination issues. They exhibit more hallucinations in longer, free-form responses, often attributed to accumulated uncertainties. In this paper, we ask: Does increased hallucination result solely from length-induced errors, or is there a deeper underlying mechanism? After a series of preliminary experiments and findings, we suggest that the risk of hallucinations is not caused by length itself but by the increased reliance on context for coherence and completeness in longer responses. Building on these insights, we propose a novel \"induce-detect-suppress\" framework that actively induces hallucinations through deliberately designed contexts, leverages induced instances for early detection of high-risk cases, and ultimately suppresses potential object-level hallucinations during actual decoding. Our approach achieves consistent, significant improvements across all benchmarks, demonstrating its efficacy. The strong detection and improved hallucination mitigation not only validate our framework but, more importantly, re-validate our hypothesis on context. Rather than solely pursuing performance gains, this study aims to provide new insights and serves as a first step toward a deeper exploration of hallucinations in LVLMs' longer responses.",
        "tags": [
            "Detection",
            "VLM"
        ]
    },
    {
        "id": "94",
        "title": "COS3D: Collaborative Open-Vocabulary 3D Segmentation",
        "author": [
            "Runsong Zhu",
            "Ka-Hei Hui",
            "Zhengzhe Liu",
            "Qianyi Wu",
            "Weiliang Tang",
            "Shi Qiu",
            "Pheng-Ann Heng",
            "Chi-Wing Fu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20238",
        "abstract": "Open-vocabulary 3D segmentation is a fundamental yet challenging task, requiring a mutual understanding of both segmentation and language. However, existing Gaussian-splatting-based methods rely either on a single 3D language field, leading to inferior segmentation, or on pre-computed class-agnostic segmentations, suffering from error accumulation. To address these limitations, we present COS3D, a new collaborative prompt-segmentation framework that contributes to effectively integrating complementary language and segmentation cues throughout its entire pipeline. We first introduce the new concept of collaborative field, comprising an instance field and a language field, as the cornerstone for collaboration. During training, to effectively construct the collaborative field, our key idea is to capture the intrinsic relationship between the instance field and language field, through a novel instance-to-language feature mapping and designing an efficient two-stage training strategy. During inference, to bridge distinct characteristics of the two fields, we further design an adaptive language-to-instance prompt refinement, promoting high-quality prompt-segmentation inference. Extensive experiments not only demonstrate COS3D's leading performance over existing methods on two widely-used benchmarks but also show its high potential to various applications,~\\ie, novel image-based 3D segmentation, hierarchical segmentation, and robotics. The code is publicly available at \\href{https://github.com/Runsong123/COS3D}{https://github.com/Runsong123/COS3D}.",
        "tags": [
            "3D",
            "Gaussian Splatting",
            "Robotics",
            "Segmentation"
        ]
    },
    {
        "id": "95",
        "title": "Tri-Modal Severity Fused Diagnosis across Depression and Post-traumatic Stress Disorders",
        "author": [
            "Filippo Cenacchi",
            "Deborah Richards",
            "Longbing Cao"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20239",
        "abstract": "Depression and post traumatic stress disorder (PTSD) often co-occur with connected symptoms, complicating automated assessment, which is often binary and disorder specific. Clinically useful diagnosis needs severity aware cross disorder estimates and decision support explanations. Our unified tri modal affective severity framework synchronizes and fuses interview text with sentence level transformer embeddings, audio with log Mel statistics with deltas, and facial signals with action units, gaze, head and pose descriptors to output graded severities for diagnosing both depression (PHQ-8; 5 classes) and PTSD (3 classes). Standardized features are fused via a calibrated late fusion classifier, yielding per disorder probabilities and feature-level attributions. This severity aware tri-modal affective fusion approach is demoed on multi disorder concurrent depression and PTSD assessment. Stratified cross validation on DAIC derived corpora outperforms unimodal/ablation baselines. The fused model matches the strongest unimodal baseline on accuracy and weighted F1, while improving decision curve utility and robustness under noisy or missing modalities. For PTSD specifically, fusion reduces regression error and improves class concordance. Errors cluster between adjacent severities; extreme classes are identified reliably. Ablations show text contributes most to depression severity, audio and facial cues are critical for PTSD, whereas attributions align with linguistic and behavioral markers. Our approach offers reproducible evaluation and clinician in the loop support for affective clinical decision making.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "96",
        "title": "Empower Words: DualGround for Structured Phrase and Sentence-Level Temporal Grounding",
        "author": [
            "Minseok Kang",
            "Minhyeok Lee",
            "Minjung Kim",
            "Donghyeong Kim",
            "Sangyoun Lee"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20244",
        "abstract": "Video Temporal Grounding (VTG) aims to localize temporal segments in long, untrimmed videos that align with a given natural language query. This task typically comprises two subtasks: Moment Retrieval (MR) and Highlight Detection (HD). While recent advances have been progressed by powerful pretrained vision-language models such as CLIP and InternVideo2, existing approaches commonly treat all text tokens uniformly during crossmodal attention, disregarding their distinct semantic roles. To validate the limitations of this approach, we conduct controlled experiments demonstrating that VTG models overly rely on [EOS]-driven global semantics while failing to effectively utilize word-level signals, which limits their ability to achieve fine-grained temporal alignment. Motivated by this limitation, we propose DualGround, a dual-branch architecture that explicitly separates global and local semantics by routing the [EOS] token through a sentence-level path and clustering word tokens into phrase-level units for localized grounding. Our method introduces (1) tokenrole- aware cross modal interaction strategies that align video features with sentence-level and phrase-level semantics in a structurally disentangled manner, and (2) a joint modeling framework that not only improves global sentence-level alignment but also enhances finegrained temporal grounding by leveraging structured phrase-aware context. This design allows the model to capture both coarse and localized semantics, enabling more expressive and context-aware video grounding. DualGround achieves state-of-the-art performance on both Moment Retrieval and Highlight Detection tasks across QVHighlights and Charades- STA benchmarks, demonstrating the effectiveness of disentangled semantic modeling in video-language alignment.",
        "tags": [
            "CLIP",
            "Detection",
            "VLM"
        ]
    },
    {
        "id": "97",
        "title": "Individualized Cognitive Simulation in Large Language Models: Evaluating Different Cognitive Representation Methods",
        "author": [
            "Tianyi Zhang",
            "Xiaolin Zhou",
            "Yunzhe Wang",
            "Erik Cambria",
            "David Traum",
            "Rui Mao"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20252",
        "abstract": "Individualized cognitive simulation (ICS) aims to build computational models that approximate the thought processes of specific individuals. While large language models (LLMs) convincingly mimic surface-level human behavior such as role-play, their ability to simulate deeper individualized cognitive processes remains poorly understood. To address this gap, we introduce a novel task that evaluates different cognitive representation methods in ICS. We construct a dataset from recently published novels (later than the release date of the tested LLMs) and propose an 11-condition cognitive evaluation framework to benchmark seven off-the-shelf LLMs in the context of authorial style emulation. We hypothesize that effective cognitive representations can help LLMs generate storytelling that better mirrors the original author. Thus, we test different cognitive representations, e.g., linguistic features, concept mappings, and profile-based information. Results show that combining conceptual and linguistic features is particularly effective in ICS, outperforming static profile-based cues in overall evaluation. Importantly, LLMs are more effective at mimicking linguistic style than narrative structure, underscoring their limits in deeper cognitive simulation. These findings provide a foundation for developing AI systems that adapt to individual ways of thinking and expression, advancing more personalized and human-aligned creative technologies.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "98",
        "title": "Towards AI Agents for Course Instruction in Higher Education: Early Experiences from the Field",
        "author": [
            "Yogesh Simmhan",
            "Varad Kulkarni"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20255",
        "abstract": "This article presents early findings from designing, deploying and evaluating an AI-based educational agent deployed as the primary instructor in a graduate-level Cloud Computing course at IISc. We detail the design of a Large Language Model (LLM)-driven Instructor Agent, and introduce a pedagogical framework that integrates the Instructor Agent into the course workflow for actively interacting with the students for content delivery, supplemented by the human instructor to offer the course structure and undertake question--answer sessions. We also propose an analytical framework that evaluates the Agent--Student interaction transcripts using interpretable engagement metrics of topic coverage, topic depth and turn-level elaboration. We report early experiences on how students interact with the Agent to explore concepts, clarify doubts and sustain inquiry-driven dialogue during live classroom sessions. We also report preliminary analysis on our evaluation metrics applied across two successive instructional modules that reveals patterns of engagement evolution, transitioning from broad conceptual exploration to deeper, focused inquiry. These demonstrate how structured integration of conversational AI agents can foster reflective learning, offer a reproducible methodology for studying engagement in authentic classroom settings, and support scalable, high-quality higher education.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "99",
        "title": "Using Large Language Models for Abstraction of Planning Domains - Extended Version",
        "author": [
            "Bita Banihashemi",
            "Megh Patel",
            "Yves LespÃ©rance"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20258",
        "abstract": "Generating an abstraction of a dynamic domain that aligns with a given purpose remains a significant challenge given that the choice of such an abstraction can impact an agent's ability to plan, reason, and provide explanations effectively. We model the agent's concrete behaviors in PDDL and investigate the use of in-context learning with large language models (LLMs) for the generation of abstract PDDL domains and problem instances, given an abstraction objective specified in natural language. The benchmark examples we use are new and have not been part of the data any LLMs have been trained on. We consider three categories of abstractions: abstraction of choice of alternative concrete actions, abstraction of sequences of concrete actions, and abstraction of action/predicate parameters, as well as combinations of these. The generated abstract PDDL domains and problem instances are then checked by symbolic validation tools as well as human experts. Our experiments show that GPT-4o can generally synthesize useful planning domain abstractions in simple settings, although it is better at abstracting over actions than over the associated fluents.",
        "tags": [
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "100",
        "title": "Kinaema: a recurrent sequence model for memory and pose in motion",
        "author": [
            "Mert Bulent Sariyildiz",
            "Philippe Weinzaepfel",
            "Guillaume Bono",
            "Gianluca Monaci",
            "Christian Wolf"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20261",
        "abstract": "One key aspect of spatially aware robots is the ability to \"find their bearings\", ie. to correctly situate themselves in previously seen spaces. In this work, we focus on this particular scenario of continuous robotics operations, where information observed before an actual episode start is exploited to optimize efficiency. We introduce a new model, Kinaema, and agent, capable of integrating a stream of visual observations while moving in a potentially large scene, and upon request, processing a query image and predicting the relative position of the shown space with respect to its current position. Our model does not explicitly store an observation history, therefore does not have hard constraints on context length. It maintains an implicit latent memory, which is updated by a transformer in a recurrent way, compressing the history of sensor readings into a compact representation. We evaluate the impact of this model in a new downstream task we call \"Mem-Nav\". We show that our large-capacity recurrent model maintains a useful representation of the scene, navigates to goals observed before the actual episode start, and is computationally efficient, in particular compared to classical transformers with attention over an observation history.",
        "tags": [
            "Robotics",
            "Transformer"
        ]
    },
    {
        "id": "101",
        "title": "Optimistic Task Inference for Behavior Foundation Models",
        "author": [
            "Thomas Rupf",
            "Marco Bagatella",
            "Marin Vlastelica",
            "Andreas Krause"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20264",
        "abstract": "Behavior Foundation Models (BFMs) are capable of retrieving high-performing policy for any reward function specified directly at test-time, commonly referred to as zero-shot reinforcement learning (RL). While this is a very efficient process in terms of compute, it can be less so in terms of data: as a standard assumption, BFMs require computing rewards over a non-negligible inference dataset, assuming either access to a functional form of rewards, or significant labeling efforts. To alleviate these limitations, we tackle the problem of task inference purely through interaction with the environment at test-time. We propose OpTI-BFM, an optimistic decision criterion that directly models uncertainty over reward functions and guides BFMs in data collection for task inference. Formally, we provide a regret bound for well-trained BFMs through a direct connection to upper-confidence algorithms for linear bandits. Empirically, we evaluate OpTI-BFM on established zero-shot benchmarks, and observe that it enables successor-features-based BFMs to identify and optimize an unseen reward function in a handful of episodes with minimal compute overhead. Code is available at https://github.com/ThomasRupf/opti-bfm.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "102",
        "title": "ImpossibleBench: Measuring LLMs' Propensity of Exploiting Test Cases",
        "author": [
            "Ziqian Zhong",
            "Aditi Raghunathan",
            "Nicholas Carlini"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20270",
        "abstract": "The tendency to find and exploit \"shortcuts\" to complete tasks poses significant risks for reliable assessment and deployment of large language models (LLMs). For example, an LLM agent with access to unit tests may delete failing tests rather than fix the underlying bug. Such behavior undermines both the validity of benchmark results and the reliability of real-world LLM coding assistant deployments.\nTo quantify, study, and mitigate such behavior, we introduce ImpossibleBench, a benchmark framework that systematically measures LLM agents' propensity to exploit test cases. ImpossibleBench creates \"impossible\" variants of tasks from existing benchmarks like LiveCodeBench and SWE-bench by introducing direct conflicts between the natural-language specification and the unit tests. We measure an agent's \"cheating rate\" as its pass rate on these impossible tasks, where any pass necessarily implies a specification-violating shortcut.\nAs a practical framework, ImpossibleBench is not just an evaluation but a versatile tool. We demonstrate its utility for: (1) studying model behaviors, revealing more fine-grained details of cheating behaviors from simple test modification to complex operator overloading; (2) context engineering, showing how prompt, test access and feedback loop affect cheating rates; and (3) developing monitoring tools, providing a testbed with verified deceptive solutions. We hope ImpossibleBench serves as a useful framework for building more robust and reliable LLM systems.\nOur implementation can be found at https://github.com/safety-research/impossiblebench.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "103",
        "title": "Limits of PRM-Guided Tree Search for Mathematical Reasoning with LLMs",
        "author": [
            "Tristan Cinquin",
            "Geoff Pleiss",
            "Agustinus Kristiadi"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20272",
        "abstract": "While chain-of-thought prompting with Best-of-N (BoN) selection has become popular for mathematical reasoning in large language models (LLMs), its linear structure fails to capture the branching and exploratory nature of complex problem-solving. In this work, we propose an adaptive algorithm to maximize process reward model (PRM) scores over the intractable action space, and investigate whether PRM-guided tree search can improve mathematical reasoning by exploring multiple partial solution paths. Across $23$ diverse mathematical problems using Qwen2.5-Math-7B-Instruct with its associated PRM as a case study, we find that: (1) PRM-guided tree search shows no statistically significant improvements over BoN despite higher costs, (2) Monte Carlo tree search and beam search outperform other PRM-guided tree search methods, (3) PRMs poorly approximate state values and their reliability degrades with reasoning depth, and (4) PRMs generalize poorly out of distribution. This underperformance stems from tree search's greater reliance on unreliable PRM scores, suggesting different reward modeling is necessary before tree search can effectively enhance mathematical reasoning in LLMs.",
        "tags": [
            "CoT",
            "LLM"
        ]
    },
    {
        "id": "104",
        "title": "Classical Feature Embeddings Help in BERT-Based Human Mobility Prediction",
        "author": [
            "Yunzhi Liu",
            "Haokai Tan",
            "Rushi Kanjaria",
            "Lihuan Li",
            "Flora D. Salim"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20275",
        "abstract": "Human mobility forecasting is crucial for disaster relief, city planning, and public health. However, existing models either only model location sequences or include time information merely as auxiliary input, thereby failing to leverage the rich semantic context provided by points of interest (POIs). To address this, we enrich a BERT-based mobility model with derived temporal descriptors and POI embeddings to better capture the semantics underlying human movement. We propose STaBERT (Semantic-Temporal aware BERT), which integrates both POI and temporal information at each location to construct a unified, semantically enriched representation of mobility. Experimental results show that STaBERT significantly improves prediction accuracy: for single-city prediction, the GEO-BLEU score improved from 0.34 to 0.75; for multi-city prediction, from 0.34 to 0.56.",
        "tags": [
            "BERT"
        ]
    },
    {
        "id": "105",
        "title": "KCM: KAN-Based Collaboration Models Enhance Pretrained Large Models",
        "author": [
            "Guangyu Dai",
            "Siliang Tang",
            "Yueting Zhuang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20278",
        "abstract": "In recent years, Pretrained Large Models(PLMs) researchers proposed large-small model collaboration frameworks, leveraged easily trainable small models to assist large models, aim to(1) significantly reduce computational resource consumption while maintaining comparable accuracy, and (2) enhance large model performance in specialized domain tasks. However, this collaborative paradigm suffers from issues such as significant accuracy degradation, exacerbated catastrophic forgetting, and amplified hallucination problems induced by small model knowledge. To address these challenges, we propose a KAN-based Collaborative Model (KCM) as an improved approach to large-small model collaboration. The KAN utilized in KCM represents an alternative neural network architecture distinct from conventional MLPs. Compared to MLPs, KAN offers superior visualizability and interpretability while mitigating catastrophic forgetting. We deployed KCM in large-small model collaborative systems across three scenarios: language, vision, and vision-language cross-modal tasks. The experimental results demonstrate that, compared with pure large model approaches, the large-small model collaboration framework utilizing KCM as the collaborative model significantly reduces the number of large model inference calls while maintaining near-identical task accuracy, thereby substantially lowering computational resource consumption. Concurrently, the KAN-based small collaborative model markedly mitigates catastrophic forgetting, leading to significant accuracy improvements for long-tail data. The results reveal that KCM demonstrates superior performance across all metrics compared to MLP-based small collaborative models (MCM).",
        "tags": [
            "KAN"
        ]
    },
    {
        "id": "106",
        "title": "ResearchGPT: Benchmarking and Training LLMs for End-to-End Computer Science Research Workflows",
        "author": [
            "Penghao Wang",
            "Yuhao Zhou",
            "Mengxuan Wu",
            "Ziheng Qin",
            "Bangyuan Zhu",
            "Shengbin Huang",
            "Xuanlei Zhao",
            "Panpan Zhang",
            "Xiaojiang Peng",
            "Yuzhang Shang",
            "Jianfei Yang",
            "Zheng Zhu",
            "Tianlong Chen",
            "Zhangyang Wang",
            "Kai Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20279",
        "abstract": "As large language models (LLMs) advance, the ultimate vision for their role in science is emerging: we could build an AI collaborator to effectively assist human beings throughout the entire scientific research process. We refer to this envisioned system as ResearchGPT. Given that scientific research progresses through multiple interdependent phases, achieving this vision requires rigorous benchmarks that evaluate the end-to-end workflow rather than isolated sub-tasks. To this end, we contribute CS-54k, a high-quality corpus of scientific Q&A pairs in computer science, built from 14k CC-licensed papers. It is constructed through a scalable, paper-grounded pipeline that combines retrieval-augmented generation (RAG) with multi-stage quality control to ensure factual grounding. From this unified corpus, we derive two complementary subsets: CS-4k, a carefully curated benchmark for evaluating AI's ability to assist scientific research, and CS-50k, a large-scale training dataset. Extensive experiments demonstrate that CS-4k stratifies state-of-the-art LLMs into distinct capability tiers. Open models trained on CS-50k with supervised training and reinforcement learning demonstrate substantial improvements. Even 7B-scale models, when properly trained, outperform many larger proprietary systems, such as GPT-4.1, GPT-4o, and Gemini 2.5 Pro. This indicates that making AI models better research assistants relies more on domain-aligned training with high-quality data than on pretraining scale or general benchmark performance. We release CS-4k and CS-50k in the hope of fostering AI systems as reliable collaborators in CS research.",
        "tags": [
            "GPT",
            "LLM",
            "RAG",
            "RL"
        ]
    },
    {
        "id": "107",
        "title": "Context-level Language Modeling by Learning Predictive Context Embeddings",
        "author": [
            "Beiya Dai",
            "Yuliang Liu",
            "Daozheng Xue",
            "Qipeng Guo",
            "Kai Chen",
            "Xinbing Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20280",
        "abstract": "Next-token prediction (NTP) is the cornerstone of modern large language models (LLMs) pretraining, driving their unprecedented capabilities in text generation, reasoning, and instruction following. However, the token-level prediction limits the model's capacity to capture higher-level semantic structures and long-range contextual relationships. To overcome this limitation, we introduce \\textbf{ContextLM}, a framework that augments standard pretraining with an inherent \\textbf{next-context prediction} objective. This mechanism trains the model to learn predictive representations of multi-token contexts, leveraging error signals derived from future token chunks. Crucially, ContextLM achieves this enhancement while remaining fully compatible with the standard autoregressive, token-by-token evaluation paradigm (e.g., perplexity). Extensive experiments on the GPT2 and Pythia model families, scaled up to $1.5$B parameters, show that ContextLM delivers consistent improvements in both perplexity and downstream task performance. Our analysis indicates that next-context prediction provides a scalable and efficient pathway to stronger language modeling, yielding better long-range coherence and more effective attention allocation with minimal computational overhead.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "108",
        "title": "Knowledge-Informed Neural Network for Complex-Valued SAR Image Recognition",
        "author": [
            "Haodong Yang",
            "Zhongling Huang",
            "Shaojie Guo",
            "Zhe Zhang",
            "Gong Cheng",
            "Junwei Han"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20284",
        "abstract": "Deep learning models for complex-valued Synthetic Aperture Radar (CV-SAR) image recognition are fundamentally constrained by a representation trilemma under data-limited and domain-shift scenarios: the concurrent, yet conflicting, optimization of generalization, interpretability, and efficiency. Our work is motivated by the premise that the rich electromagnetic scattering features inherent in CV-SAR data hold the key to resolving this trilemma, yet they are insufficiently harnessed by conventional data-driven models. To this end, we introduce the Knowledge-Informed Neural Network (KINN), a lightweight framework built upon a novel \"compression-aggregation-compression\" architecture. The first stage performs a physics-guided compression, wherein a novel dictionary processor adaptively embeds physical priors, enabling a compact unfolding network to efficiently extract sparse, physically-grounded signatures. A subsequent aggregation module enriches these representations, followed by a final semantic compression stage that utilizes a compact classification head with self-distillation to learn maximally task-relevant and discriminative embeddings. We instantiate KINN in both CNN (0.7M) and Vision Transformer (0.95M) variants. Extensive evaluations on five SAR benchmarks confirm that KINN establishes a state-of-the-art in parameter-efficient recognition, offering exceptional generalization in data-scarce and out-of-distribution scenarios and tangible interpretability, thereby providing an effective solution to the representation trilemma and offering a new path for trustworthy AI in SAR image analysis.",
        "tags": [
            "Transformer",
            "ViT"
        ]
    },
    {
        "id": "109",
        "title": "UI-Ins: Enhancing GUI Grounding with Multi-Perspective Instruction-as-Reasoning",
        "author": [
            "Liangyu Chen",
            "Hanzhang Zhou",
            "Chenglin Cai",
            "Jianan Zhang",
            "Panrong Tong",
            "Quyu Kong",
            "Xu Zhang",
            "Chen Liu",
            "Yuqi Liu",
            "Wenxuan Wang",
            "Yue Wang",
            "Qin Jin",
            "Steven Hoi"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20286",
        "abstract": "GUI grounding, which maps natural-language instructions to actionable UI elements, is a core capability of GUI agents. Prior works largely treats instructions as a static proxy for user intent, overlooking the impact of instruction diversity and quality on grounding performance. Through a careful investigation of existing grounding datasets, we find a 23.3% flaw rate in their instructions and show that inference-time exploitation of instruction diversity yields up to a substantial 76% relative performance improvement. In this paper, we introduce the Instruction-as-Reasoning paradigm, treating instructions as dynamic analytical pathways that offer distinct perspectives and enabling the model to select the most effective pathway during reasoning. To achieve this, we propose a two-stage training framework: supervised fine-tuning (SFT) on synthesized, diverse instructions to instill multi-perspective reasoning, followed by reinforcement learning (RL) to optimize pathway selection and composition. Our resulting models, UI-Ins-7B and UI-Ins-32B, achieve state-of-the-art results on five challenging grounding benchmarks and exhibit emergent reasoning, selectively composing and synthesizing novel instruction pathways at inference. In particular, UI-Ins-32B attains the best grounding accuracy, scoring 87.3% on UI-I2E-Bench, 57.0% on ScreenSpot-Pro, and 84.9% on MMBench-GUI L2. Furthermore, our model demonstrates strong agentic potential, achieving a 74.1% success rate on AndroidWorld using UI-Ins-7B as the executor. Our in-depth analysis reveals additional insights such as how reasoning can be formulated to enhance rather than hinder grounding performance, and how our method mitigates policy collapse in the SFT+RL framework. All code and model checkpoints will be publicly released in https://github.com/alibaba/UI-Ins.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "110",
        "title": "Breakdance Video classification in the age of Generative AI",
        "author": [
            "Sauptik Dhar",
            "Naveen Ramakrishnan",
            "Michelle Munson"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20287",
        "abstract": "Large Vision Language models have seen huge application in several sports use-cases recently. Most of these works have been targeted towards a limited subset of popular sports like soccer, cricket, basketball etc; focusing on generative tasks like visual question answering, highlight generation. This work analyzes the applicability of the modern video foundation models (both encoder and decoder) for a very niche but hugely popular dance sports - breakdance. Our results show that Video Encoder models continue to outperform state-of-the-art Video Language Models for prediction tasks. We provide insights on how to choose the encoder model and provide a thorough analysis into the workings of a finetuned decoder model for breakdance video classification.",
        "tags": [
            "VLM"
        ]
    },
    {
        "id": "111",
        "title": "A Parameter-Efficient Mixture-of-Experts Framework for Cross-Modal Geo-Localization",
        "author": [
            "LinFeng Li",
            "Jian Zhao",
            "Zepeng Yang",
            "Yuhang Song",
            "Bojun Lin",
            "Tianle Zhang",
            "Yuchen Yuan",
            "Chi Zhang",
            "Xuelong Li"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20291",
        "abstract": "We present a winning solution to RoboSense 2025 Track 4: Cross-Modal Drone Navigation. The task retrieves the most relevant geo-referenced image from a large multi-platform corpus (satellite/drone/ground) given a natural-language query. Two obstacles are severe inter-platform heterogeneity and a domain gap between generic training descriptions and platform-specific test queries. We mitigate these with a domain-aligned preprocessing pipeline and a Mixture-of-Experts (MoE) framework: (i) platform-wise partitioning, satellite augmentation, and removal of orientation words; (ii) an LLM-based caption refinement pipeline to align textual semantics with the distinct visual characteristics of each platform. Using BGE-M3 (text) and EVA-CLIP (image), we train three platform experts using a progressive two-stage, hard-negative mining strategy to enhance discriminative power, and fuse their scores at inference. The system tops the official leaderboard, demonstrating robust cross-modal geo-localization under heterogeneous viewpoints.",
        "tags": [
            "CLIP",
            "LLM",
            "MoE"
        ]
    },
    {
        "id": "112",
        "title": "Moving or Predicting? RoleAware-MAPP: A Role-Aware Transformer Framework for Movable Antenna Position Prediction to Secure Wireless Communications",
        "author": [
            "Wenxu Wang",
            "Xiaowu Liu",
            "Wei Gong",
            "Yujia Zhao",
            "Kaixuan Li",
            "Qixun Zhang",
            "Zhiyong Feng",
            "Kan Yu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20293",
        "abstract": "Movable antenna (MA) technology provides a promising avenue for actively shaping wireless channels through dynamic antenna positioning, thereby enabling electromagnetic radiation reconstruction to enhance physical layer security (PLS). However, its practical deployment is hindered by two major challenges: the high computational complexity of real time optimization and a critical temporal mismatch between slow mechanical movement and rapid channel variations. Although data driven methods have been introduced to alleviate online optimization burdens, they are still constrained by suboptimal training labels derived from conventional solvers or high sample complexity in reinforcement learning. More importantly, existing learning based approaches often overlook communication-specific domain knowledge, particularly the asymmetric roles and adversarial interactions between legitimate users and eavesdroppers, which are fundamental to PLS. To address these issues, this paper reformulates the MA positioning problem as a predictive task and introduces RoleAware-MAPP, a novel Transformer based framework that incorporates domain knowledge through three key components: role-aware embeddings that model user specific intentions, physics-informed semantic features that encapsulate channel propagation characteristics, and a composite loss function that strategically prioritizes secrecy performance over mere geometric accuracy. Extensive simulations under 3GPP-compliant scenarios show that RoleAware-MAPP achieves an average secrecy rate of 0.3569 bps/Hz and a strictly positive secrecy capacity of 81.52%, outperforming the strongest baseline by 48.4% and 5.39 percentage points, respectively, while maintaining robust performance across diverse user velocities and noise conditions.",
        "tags": [
            "RL",
            "Transformer"
        ]
    },
    {
        "id": "113",
        "title": "RAG-Stack: Co-Optimizing RAG Quality and Performance From the Vector Database Perspective",
        "author": [
            "Wenqi Jiang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20296",
        "abstract": "Retrieval-augmented generation (RAG) has emerged as one of the most prominent applications of vector databases. By integrating documents retrieved from a database into the prompt of a large language model (LLM), RAG enables more reliable and informative content generation. While there has been extensive research on vector databases, many open research problems remain once they are considered in the wider context of end-to-end RAG pipelines. One practical yet challenging problem is how to jointly optimize both system performance and generation quality in RAG, which is significantly more complex than it appears due to the numerous knobs on both the algorithmic side (spanning models and databases) and the systems side (from software to hardware). In this paper, we present RAG-Stack, a three-pillar blueprint for quality-performance co-optimization in RAG systems. RAG-Stack comprises: (1) RAG-IR, an intermediate representation that serves as an abstraction layer to decouple quality and performance aspects; (2) RAG-CM, a cost model for estimating system performance given an RAG-IR; and (3) RAG-PE, a plan exploration algorithm that searches for high-quality, high-performance RAG configurations. We believe this three-pillar blueprint will become the de facto paradigm for RAG quality-performance co-optimization in the years to come.",
        "tags": [
            "LLM",
            "RAG"
        ]
    },
    {
        "id": "114",
        "title": "Citation Failure: Definition, Analysis and Efficient Mitigation",
        "author": [
            "Jan Buchmann",
            "Iryna Gurevych"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20303",
        "abstract": "Citations from LLM-based RAG systems are supposed to simplify response verification. However, this does not hold for citation failure, when a model generates a helpful response, but fails to cite complete evidence. In contrast to previous work, we propose to disentangle this from response failure, where the response itself is flawed, and citing complete evidence is impossible. To address citation failure, this work follows a two-step approach: (1) We study when citation failure occurs and (2) how it can be mitigated. For step 1, we extend prior work by investigating how the relation between response and evidence affects citation quality. We introduce CITECONTROL, a benchmark that systematically varies this relation to analyze failure modes. Experiments show that failures increase with relational complexity and suggest that combining citation methods could improve performance, motivating step 2. To improve LLM citation efficiently, we propose CITENTION, a framework integrating generative, attention-based, and retrieval-based methods. Results demonstrate substantial citation improvements on CITECONTROL and in transfer settings. We make our data and code publicly available.",
        "tags": [
            "LLM",
            "RAG"
        ]
    },
    {
        "id": "115",
        "title": "Exploring Generative Process Reward Modeling for Semi-Structured Data: A Case Study of Table Question Answering",
        "author": [
            "Lei Tang",
            "Wei Zhou",
            "Mohsen Mesgar"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20304",
        "abstract": "Process reward models (PRMs) improve complex reasoning in large language models (LLMs) by grading candidate solutions step-by-step and selecting answers via aggregated step scores. While effective in domains such as mathematics, their applicability to tasks involving semi-structured data, like table question answering (TQA) remains unexplored. TQA poses unique challenges for PRMs, including abundant irrelevant information, loosely connected reasoning steps, and domain-specific reasoning. This work presents the first systematic study of PRMs for TQA. We evaluate state-of-the-art generative PRMs on TQA from both answer and step perspectives. Results show that PRMs that combine textual and code verification can aid solution selection but struggle to generalize to out-of-domain data. Analysis reveals a weak correlation between performance in step-level verification and answer accuracy, possibly stemming from weak step dependencies and loose causal links. Our findings highlight limitations of current PRMs on TQA and offer valuable insights for building more robust, process-aware verifiers.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "116",
        "title": "Multi-Step Reasoning for Embodied Question Answering via Tool Augmentation",
        "author": [
            "Mingliang Zhai",
            "Hansheng Liang",
            "Xiaomeng Fan",
            "Zhi Gao",
            "Chuanhao Li",
            "Che Sun",
            "Xu Bin",
            "Yuwei Wu",
            "Yunde Jia"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20310",
        "abstract": "Embodied Question Answering (EQA) requires agents to explore 3D environments to obtain observations and answer questions related to the scene. Existing methods leverage VLMs to directly explore the environment and answer questions without explicit thinking or planning, which limits their reasoning ability and results in excessive or inefficient exploration as well as ineffective responses. In this paper, we introduce ToolEQA, an agent that integrates external tools with multi-step reasoning, where external tools can provide more useful information for completing the task, helping the model derive better exploration directions in the next step of reasoning and thus obtaining additional effective information. This enables ToolEQA to generate more accurate responses with a shorter exploration distance. To enhance the model's ability for tool-usage and multi-step reasoning, we further design a novel EQA data generation pipeline that automatically constructs large-scale EQA tasks with reasoning trajectories and corresponding answers. Based on the pipeline, we collect the EQA-RT dataset that contains about 18K tasks, divided into a training set EQA-RT-Train, and two test sets EQA-RT-Seen (scenes overlapping with the training set) and EQA-RT-Unseen (novel scenes). Experiments on EQA-RT-Seen and EQA-RT-Unseen show that ToolEQA improves the success rate by 9.2~20.2% over state-of-the-art baselines, while outperforming the zero-shot ToolEQA by 10% in success rate. In addition, ToolEQA also achieves state-of-the-art performance on the HM-EQA, OpenEQA, and EXPRESS-Bench datasets, demonstrating its generality. Our homepage see https://tooleqa.github.io.",
        "tags": [
            "3D",
            "VLM"
        ]
    },
    {
        "id": "117",
        "title": "HyperET: Efficient Training in Hyperbolic Space for Multi-modal Large Language Models",
        "author": [
            "Zelin Peng",
            "Zhengqin Xu",
            "Qingyang Liu",
            "Xiaokang Yang",
            "Wei Shen"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20322",
        "abstract": "Multi-modal large language models (MLLMs) have emerged as a transformative approach for aligning visual and textual understanding. They typically require extremely high computational resources (e.g., thousands of GPUs) for training to achieve cross-modal alignment at multi-granularity levels. We argue that a key source of this inefficiency lies in the vision encoders they widely equip with, e.g., CLIP and SAM, which lack the alignment with language at multi-granularity levels. To address this issue, in this paper, we leverage hyperbolic space, which inherently models hierarchical levels and thus provides a principled framework for bridging the granularity gap between visual and textual modalities at an arbitrary granularity level. Concretely, we propose an efficient training paradigm for MLLMs, dubbed as HyperET, which can optimize visual representations to align with their textual counterparts at an arbitrary granularity level through dynamic hyperbolic radius adjustment in hyperbolic space. HyperET employs learnable matrices with MÃ¶bius multiplication operations, implemented via three effective configurations: diagonal scaling matrices, block-diagonal matrices, and banded matrices, providing a flexible yet efficient parametrization strategy. Comprehensive experiments across multiple MLLM benchmarks demonstrate that HyperET consistently improves both existing pre-training and fine-tuning MLLMs clearly with less than 1\\% additional parameters.",
        "tags": [
            "CLIP",
            "LLM",
            "SAM"
        ]
    },
    {
        "id": "118",
        "title": "MemER: Scaling Up Memory for Robot Control via Experience Retrieval",
        "author": [
            "Ajay Sridhar",
            "Jennifer Pan",
            "Satvik Sharma",
            "Chelsea Finn"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20328",
        "abstract": "Humans routinely rely on memory to perform tasks, yet most robot policies lack this capability; our goal is to endow robot policies with the same ability. Naively conditioning on long observation histories is computationally expensive and brittle under covariate shift, while indiscriminate subsampling of history leads to irrelevant or redundant information. We propose a hierarchical policy framework, where the high-level policy is trained to select and track previous relevant keyframes from its experience. The high-level policy uses selected keyframes and the most recent frames when generating text instructions for a low-level policy to execute. This design is compatible with existing vision-language-action (VLA) models and enables the system to efficiently reason over long-horizon dependencies. In our experiments, we finetune Qwen2.5-VL-7B-Instruct and $\\pi_{0.5}$ as the high-level and low-level policies respectively, using demonstrations supplemented with minimal language annotations. Our approach, MemER, outperforms prior methods on three real-world long-horizon robotic manipulation tasks that require minutes of memory. Videos and code can be found at https://jen-pan.github.io/memer/.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "119",
        "title": "GhostEI-Bench: Do Mobile Agents Resilience to Environmental Injection in Dynamic On-Device Environments?",
        "author": [
            "Chiyu Chen",
            "Xinhao Song",
            "Yunkai Chai",
            "Yang Yao",
            "Haodong Zhao",
            "Lijun Li",
            "Jie Li",
            "Yan Teng",
            "Gongshen Liu",
            "Yingchun Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20333",
        "abstract": "Vision-Language Models (VLMs) are increasingly deployed as autonomous agents to navigate mobile graphical user interfaces (GUIs). Operating in dynamic on-device ecosystems, which include notifications, pop-ups, and inter-app interactions, exposes them to a unique and underexplored threat vector: environmental injection. Unlike prompt-based attacks that manipulate textual instructions, environmental injection corrupts an agent's visual perception by inserting adversarial UI elements (for example, deceptive overlays or spoofed notifications) directly into the GUI. This bypasses textual safeguards and can derail execution, causing privacy leakage, financial loss, or irreversible device compromise. To systematically evaluate this threat, we introduce GhostEI-Bench, the first benchmark for assessing mobile agents under environmental injection attacks within dynamic, executable environments. Moving beyond static image-based assessments, GhostEI-Bench injects adversarial events into realistic application workflows inside fully operational Android emulators and evaluates performance across critical risk scenarios. We further propose a judge-LLM protocol that conducts fine-grained failure analysis by reviewing the agent's action trajectory alongside the corresponding screenshot sequence, pinpointing failure in perception, recognition, or reasoning. Comprehensive experiments on state-of-the-art agents reveal pronounced vulnerability to deceptive environmental cues: current models systematically fail to perceive and reason about manipulated UIs. GhostEI-Bench provides a framework for quantifying and mitigating this emerging threat, paving the way toward more robust and secure embodied agents.",
        "tags": [
            "LLM",
            "VLM"
        ]
    },
    {
        "id": "120",
        "title": "Dino-Diffusion Modular Designs Bridge the Cross-Domain Gap in Autonomous Parking",
        "author": [
            "Zixuan Wu",
            "Hengyuan Zhang",
            "Ting-Hsuan Chen",
            "Yuliang Guo",
            "David Paz",
            "Xinyu Huang",
            "Liu Ren"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20335",
        "abstract": "Parking is a critical pillar of driving safety. While recent end-to-end (E2E) approaches have achieved promising in-domain results, robustness under domain shifts (e.g., weather and lighting changes) remains a key challenge. Rather than relying on additional data, in this paper, we propose Dino-Diffusion Parking (DDP), a domain-agnostic autonomous parking pipeline that integrates visual foundation models with diffusion-based planning to enable generalized perception and robust motion planning under distribution shifts. We train our pipeline in CARLA at regular setting and transfer it to more adversarial settings in a zero-shot fashion. Our model consistently achieves a parking success rate above 90% across all tested out-of-distribution (OOD) scenarios, with ablation studies confirming that both the network architecture and algorithmic design significantly enhance cross-domain performance over existing baselines. Furthermore, testing in a 3D Gaussian splatting (3DGS) environment reconstructed from a real-world parking lot demonstrates promising sim-to-real transfer.",
        "tags": [
            "3D",
            "Diffusion",
            "Gaussian Splatting"
        ]
    },
    {
        "id": "121",
        "title": "Teaching Language Models to Reason with Tools",
        "author": [
            "Chengpeng Li",
            "Zhengyang Tang",
            "Ziniu Li",
            "Mingfeng Xue",
            "Keqin Bao",
            "Tian Ding",
            "Ruoyu Sun",
            "Benyou Wang",
            "Xiang Wang",
            "Junyang Lin",
            "Dayiheng Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20342",
        "abstract": "Large reasoning models (LRMs) like OpenAI-o1 have shown impressive capabilities in natural language reasoning. However, these models frequently demonstrate inefficiencies or inaccuracies when tackling complex mathematical operations. While integrating computational tools such as Code Interpreters (CIs) offers a promising solution, it introduces a critical challenge: a conflict between the model's internal, probabilistic reasoning and the external, deterministic knowledge provided by the CI, which often leads models to unproductive deliberation. To overcome this, we introduce CoRT (Code-Optimized Reasoning Training), a post-training framework designed to teach LRMs to effectively utilize CIs. We propose \\emph{Hint-Engineering}, a new data synthesis strategy that strategically injects diverse hints at optimal points within reasoning paths. This approach generates high-quality, code-integrated reasoning data specifically tailored to optimize LRM-CI interaction. Using this method, we have synthesized 30 high-quality samples to post-train models ranging from 1.5B to 32B parameters through supervised fine-tuning. CoRT further refines the multi-round interleaving of external CI usage and internal thinking by employing rejection sampling and reinforcement learning. Our experimental evaluations demonstrate CoRT's effectiveness, yielding absolute improvements of 4\\% and 8\\% on DeepSeek-R1-Distill-Qwen-32B and DeepSeek-R1-Distill-Qwen-1.5B, respectively, across five challenging mathematical reasoning datasets. Moreover, CoRT significantly enhances efficiency, reducing token usage by approximately 30\\% for the 32B model and 50\\% for the 1.5B model compared to pure natural language reasoning baselines. The models and code are available at: https://github.com/ChengpengLi1003/CoRT.",
        "tags": [
            "DeepSeek",
            "Qwen",
            "RL"
        ]
    },
    {
        "id": "122",
        "title": "LLM-empowered knowledge graph construction: A survey",
        "author": [
            "Haonan Bian"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20345",
        "abstract": "Knowledge Graphs (KGs) have long served as a fundamental infrastructure for structured knowledge representation and reasoning. With the advent of Large Language Models (LLMs), the construction of KGs has entered a new paradigm-shifting from rule-based and statistical pipelines to language-driven and generative frameworks. This survey provides a comprehensive overview of recent progress in LLM-empowered knowledge graph construction, systematically analyzing how LLMs reshape the classical three-layered pipeline of ontology engineering, knowledge extraction, and knowledge fusion.\nWe first revisit traditional KG methodologies to establish conceptual foundations, and then review emerging LLM-driven approaches from two complementary perspectives: schema-based paradigms, which emphasize structure, normalization, and consistency; and schema-free paradigms, which highlight flexibility, adaptability, and open discovery. Across each stage, we synthesize representative frameworks, analyze their technical mechanisms, and identify their limitations.\nFinally, the survey outlines key trends and future research directions, including KG-based reasoning for LLMs, dynamic knowledge memory for agentic systems, and multimodal KG construction. Through this systematic review, we aim to clarify the evolving interplay between LLMs and knowledge graphs, bridging symbolic knowledge engineering and neural semantic understanding toward the development of adaptive, explainable, and intelligent knowledge systems.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "123",
        "title": "Multi-Modal Decentralized Reinforcement Learning for Modular Reconfigurable Lunar Robots",
        "author": [
            "Ashutosh Mishra",
            "Shreya Santra",
            "Elian Neppel",
            "Edoardo M. Rossi Lombardi",
            "Shamistan Karimov",
            "Kentaro Uno",
            "Kazuya Yoshida"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20347",
        "abstract": "Modular reconfigurable robots suit task-specific space operations, but the combinatorial growth of morphologies hinders unified control. We propose a decentralized reinforcement learning (Dec-RL) scheme where each module learns its own policy: wheel modules use Soft Actor-Critic (SAC) for locomotion and 7-DoF limbs use Proximal Policy Optimization (PPO) for steering and manipulation, enabling zero-shot generalization to unseen configurations. In simulation, the steering policy achieved a mean absolute error of 3.63Â° between desired and induced angles; the manipulation policy plateaued at 84.6 % success on a target-offset criterion; and the wheel policy cut average motor torque by 95.4 % relative to baseline while maintaining 99.6 % success. Lunar-analogue field tests validated zero-shot integration for autonomous locomotion, steering, and preliminary alignment for reconfiguration. The system transitioned smoothly among synchronous, parallel, and sequential modes for Policy Execution, without idle states or control conflicts, indicating a scalable, reusable, and robust approach for modular lunar robots.",
        "tags": [
            "PPO",
            "RL"
        ]
    },
    {
        "id": "124",
        "title": "AccuQuant: Simulating Multiple Denoising Steps for Quantizing Diffusion Models",
        "author": [
            "Seunghoon Lee",
            "Jeongwoo Choi",
            "Byunggwan Son",
            "Jaehyeon Moon",
            "Jeimin Jeon",
            "Bumsub Ham"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20348",
        "abstract": "We present in this paper a novel post-training quantization (PTQ) method, dubbed AccuQuant, for diffusion models. We show analytically and empirically that quantization errors for diffusion models are accumulated over denoising steps in a sampling process. To alleviate the error accumulation problem, AccuQuant minimizes the discrepancies between outputs of a full-precision diffusion model and its quantized version within a couple of denoising steps. That is, it simulates multiple denoising steps of a diffusion sampling process explicitly for quantization, accounting the accumulated errors over multiple denoising steps, which is in contrast to previous approaches to imitating a training process of diffusion models, namely, minimizing the discrepancies independently for each step. We also present an efficient implementation technique for AccuQuant, together with a novel objective, which reduces a memory complexity significantly from $\\mathcal{O}(n)$ to $\\mathcal{O}(1)$, where $n$ is the number of denoising steps. We demonstrate the efficacy and efficiency of AccuQuant across various tasks and diffusion models on standard benchmarks.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "125",
        "title": "What do AI-Generated Images Want?",
        "author": [
            "Amanda Wasielewski"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20350",
        "abstract": "W.J.T. Mitchell's influential essay 'What do pictures want?' shifts the theoretical focus away from the interpretative act of understanding pictures and from the motivations of the humans who create them to the possibility that the picture itself is an entity with agency and wants. In this article, I reframe Mitchell's question in light of contemporary AI image generation tools to ask: what do AI-generated images want? Drawing from art historical discourse on the nature of abstraction, I argue that AI-generated images want specificity and concreteness because they are fundamentally abstract. Multimodal text-to-image models, which are the primary subject of this article, are based on the premise that text and image are interchangeable or exchangeable tokens and that there is a commensurability between them, at least as represented mathematically in data. The user pipeline that sees textual input become visual output, however, obscures this representational regress and makes it seem like one form transforms into the other -- as if by magic.",
        "tags": [
            "Text-to-Image"
        ]
    },
    {
        "id": "126",
        "title": "Dialogue Is Not Enough to Make a Communicative BabyLM (But Neither Is Developmentally Inspired Reinforcement Learning)",
        "author": [
            "Francesca Padovani",
            "Bastian Bunzeck",
            "Manar Ali",
            "Omar Momen",
            "Arianna Bisazza",
            "Hendrik Buschmeier",
            "Sina ZarrieÃ"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20358",
        "abstract": "We investigate whether pre-training exclusively on dialogue data results in formally and functionally apt small language models. Based on this pre-trained llamalogue model, we employ a variety of fine-tuning strategies to enforce \"more communicative\" text generations by our models. Although our models underperform on most standard BabyLM benchmarks, they excel at dialogue continuation prediction in a minimal pair setting. While PPO fine-tuning has mixed to adversarial effects on our models, DPO fine-tuning further improves their performance on our custom dialogue benchmark.",
        "tags": [
            "DPO",
            "PPO",
            "RL"
        ]
    },
    {
        "id": "127",
        "title": "NeuPerm: Disrupting Malware Hidden in Neural Network Parameters by Leveraging Permutation Symmetry",
        "author": [
            "Daniel Gilkarov",
            "Ran Dubin"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20367",
        "abstract": "Pretrained deep learning model sharing holds tremendous value for researchers and enterprises alike. It allows them to apply deep learning by fine-tuning models at a fraction of the cost of training a brand-new model. However, model sharing exposes end-users to cyber threats that leverage the models for malicious purposes. Attackers can use model sharing by hiding self-executing malware inside neural network parameters and then distributing them for unsuspecting users to unknowingly directly execute them, or indirectly as a dependency in another software. In this work, we propose NeuPerm, a simple yet effec- tive way of disrupting such malware by leveraging the theoretical property of neural network permutation symmetry. Our method has little to no effect on model performance at all, and we empirically show it successfully disrupts state-of-the-art attacks that were only previously addressed using quantization, a highly complex process. NeuPerm is shown to work on LLMs, a feat that no other previous similar works have achieved. The source code is available at https://github.com/danigil/NeuPerm.git.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "128",
        "title": "Ask a Strong LLM Judge when Your Reward Model is Uncertain",
        "author": [
            "Zhenghao Xu",
            "Qin Lu",
            "Qingru Zhang",
            "Liang Qiu",
            "Ilgee Hong",
            "Changlong Yu",
            "Wenlin Yao",
            "Yao Liu",
            "Haoming Jiang",
            "Lihong Li",
            "Hyokun Yun",
            "Tuo Zhao"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20369",
        "abstract": "Reward model (RM) plays a pivotal role in reinforcement learning with human feedback (RLHF) for aligning large language models (LLMs). However, classical RMs trained on human preferences are vulnerable to reward hacking and generalize poorly to out-of-distribution (OOD) inputs. By contrast, strong LLM judges equipped with reasoning capabilities demonstrate superior generalization, even without additional training, but incur significantly higher inference costs, limiting their applicability in online RLHF. In this work, we propose an uncertainty-based routing framework that efficiently complements a fast RM with a strong but costly LLM judge. Our approach formulates advantage estimation in policy gradient (PG) methods as pairwise preference classification, enabling principled uncertainty quantification to guide routing. Uncertain pairs are forwarded to the LLM judge, while confident ones are evaluated by the RM. Experiments on RM benchmarks demonstrate that our uncertainty-based routing strategy significantly outperforms random judge calling at the same cost, and downstream alignment results showcase its effectiveness in improving online RLHF.",
        "tags": [
            "LLM",
            "RL",
            "RLHF"
        ]
    },
    {
        "id": "129",
        "title": "The Impact of Negated Text on Hallucination with Large Language Models",
        "author": [
            "Jaehyung Seo",
            "Hyeonseok Moon",
            "Heuiseok Lim"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20375",
        "abstract": "Recent studies on hallucination in large language models (LLMs) have been actively progressing in natural language processing. However, the impact of negated text on hallucination with LLMs remains largely unexplored. In this paper, we set three important yet unanswered research questions and aim to address them. To derive the answers, we investigate whether LLMs can recognize contextual shifts caused by negation and still reliably distinguish hallucinations comparable to affirmative cases. We also design the NegHalu dataset by reconstructing existing hallucination detection datasets with negated expressions. Our experiments demonstrate that LLMs struggle to detect hallucinations in negated text effectively, often producing logically inconsistent or unfaithful judgments. Moreover, we trace the internal state of LLMs as they process negated inputs at the token level and reveal the challenges of mitigating their unintended effects.",
        "tags": [
            "Detection",
            "LLM"
        ]
    },
    {
        "id": "130",
        "title": "IKnow: Instruction-Knowledge-Aware Continual Pretraining for Effective Domain Adaptation",
        "author": [
            "Tianyi Zhang",
            "Florian Mai",
            "Lucie Flek"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20377",
        "abstract": "Continual pretraining promises to adapt large language models (LLMs) to new domains using only unlabeled test-time data, but naively applying standard self-supervised objectives to instruction-tuned models is known to degrade their instruction-following capability and semantic representations. Existing fixes assume access to the original base model or rely on knowledge from an external domain-specific database - both of which pose a realistic barrier in settings where the base model weights are withheld for safety reasons or reliable external corpora are unavailable. In this work, we propose Instruction-Knowledge-Aware Continual Adaptation (IKnow), a simple and general framework that formulates novel self-supervised objectives in the instruction-response dialogue format. Rather than depend- ing on external resources, IKnow leverages domain knowledge embedded within the text itself and learns to encode it at a deeper semantic level.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "131",
        "title": "Positional Encoding Field",
        "author": [
            "Yunpeng Bai",
            "Haoxiang Li",
            "Qixing Huang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20385",
        "abstract": "Diffusion Transformers (DiTs) have emerged as the dominant architecture for visual generation, powering state-of-the-art image and video models. By representing images as patch tokens with positional encodings (PEs), DiTs combine Transformer scalability with spatial and temporal inductive biases. In this work, we revisit how DiTs organize visual content and discover that patch tokens exhibit a surprising degree of independence: even when PEs are perturbed, DiTs still produce globally coherent outputs, indicating that spatial coherence is primarily governed by PEs. Motivated by this finding, we introduce the Positional Encoding Field (PE-Field), which extends positional encodings from the 2D plane to a structured 3D field. PE-Field incorporates depth-aware encodings for volumetric reasoning and hierarchical encodings for fine-grained sub-patch control, enabling DiTs to model geometry directly in 3D space. Our PE-Field-augmented DiT achieves state-of-the-art performance on single-image novel view synthesis and generalizes to controllable spatial image editing.",
        "tags": [
            "3D",
            "DiT",
            "Diffusion",
            "Image Editing",
            "Transformer"
        ]
    },
    {
        "id": "132",
        "title": "NeoDictaBERT: Pushing the Frontier of BERT models for Hebrew",
        "author": [
            "Shaltiel Shmidman",
            "Avi Shmidman",
            "Moshe Koppel"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20386",
        "abstract": "Since their initial release, BERT models have demonstrated exceptional performance on a variety of tasks, despite their relatively small size (BERT-base has ~100M parameters). Nevertheless, the architectural choices used in these models are outdated compared to newer transformer-based models such as Llama3 and Qwen3. In recent months, several architectures have been proposed to close this gap. ModernBERT and NeoBERT both show strong improvements on English benchmarks and significantly extend the supported context window. Following their successes, we introduce NeoDictaBERT and NeoDictaBERT-bilingual: BERT-style models trained using the same architecture as NeoBERT, with a dedicated focus on Hebrew texts. These models outperform existing ones on almost all Hebrew benchmarks and provide a strong foundation for downstream tasks. Notably, the NeoDictaBERT-bilingual model shows strong results on retrieval tasks, outperforming other multilingual models of similar size. In this paper, we describe the training process and report results across various benchmarks. We release the models to the community as part of our goal to advance research and development in Hebrew NLP.",
        "tags": [
            "BERT",
            "Transformer"
        ]
    },
    {
        "id": "133",
        "title": "Relative-Based Scaling Law for Neural Language Models",
        "author": [
            "Baoqing Yue",
            "Jinyuan Zhou",
            "Zixi Wei",
            "Jingtao Zhan",
            "Qingyao Ai",
            "Yiqun Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20387",
        "abstract": "Scaling laws aim to accurately predict model performance across different scales. Existing scaling-law studies almost exclusively rely on cross-entropy as the evaluation metric. However, cross-entropy provides only a partial view of performance: it measures the absolute probability assigned to the correct token, but ignores the relative ordering between correct and incorrect tokens. Yet, relative ordering is crucial for language models, such as in greedy-sampling scenario. To address this limitation, we investigate scaling from the perspective of relative ordering. We first propose the Relative-Based Probability (RBP) metric, which quantifies the probability that the correct token is ranked among the top predictions. Building on this metric, we establish the Relative-Based Scaling Law, which characterizes how RBP improves with increasing model size. Through extensive experiments on four datasets and four model families spanning five orders of magnitude, we demonstrate the robustness and accuracy of this law. Finally, we illustrate the broad application of this law with two examples, namely providing a deeper explanation of emergence phenomena and facilitating finding fundamental theories of scaling laws. In summary, the Relative-Based Scaling Law complements the cross-entropy perspective and contributes to a more complete understanding of scaling large language models. Thus, it offers valuable insights for both practical development and theoretical exploration.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "134",
        "title": "NeuralTouch: Neural Descriptors for Precise Sim-to-Real Tactile Robot Control",
        "author": [
            "Yijiong Lin",
            "Bowen Deng",
            "Chenghua Lu",
            "Max Yang",
            "Efi Psomopoulou",
            "Nathan F. Lepora"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20390",
        "abstract": "Grasping accuracy is a critical prerequisite for precise object manipulation, often requiring careful alignment between the robot hand and object. Neural Descriptor Fields (NDF) offer a promising vision-based method to generate grasping poses that generalize across object categories. However, NDF alone can produce inaccurate poses due to imperfect camera calibration, incomplete point clouds, and object variability. Meanwhile, tactile sensing enables more precise contact, but existing approaches typically learn policies limited to simple, predefined contact geometries. In this work, we introduce NeuralTouch, a multimodal framework that integrates NDF and tactile sensing to enable accurate, generalizable grasping through gentle physical interaction. Our approach leverages NDF to implicitly represent the target contact geometry, from which a deep reinforcement learning (RL) policy is trained to refine the grasp using tactile feedback. This policy is conditioned on the neural descriptors and does not require explicit specification of contact types. We validate NeuralTouch through ablation studies in simulation and zero-shot transfer to real-world manipulation tasks--such as peg-out-in-hole and bottle lid opening--without additional fine-tuning. Results show that NeuralTouch significantly improves grasping accuracy and robustness over baseline methods, offering a general framework for precise, contact-rich robotic manipulation.",
        "tags": [
            "RL",
            "Robotics"
        ]
    },
    {
        "id": "135",
        "title": "PointMapPolicy: Structured Point Cloud Processing for Multi-Modal Imitation Learning",
        "author": [
            "Xiaogang Jia",
            "Qian Wang",
            "Anrui Wang",
            "Han A. Wang",
            "BalÃ¡zs Gyenes",
            "Emiliyan Gospodinov",
            "Xinkai Jiang",
            "Ge Li",
            "Hongyi Zhou",
            "Weiran Liao",
            "Xi Huang",
            "Maximilian Beck",
            "Moritz Reuss",
            "Rudolf Lioutikov",
            "Gerhard Neumann"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20406",
        "abstract": "Robotic manipulation systems benefit from complementary sensing modalities, where each provides unique environmental information. Point clouds capture detailed geometric structure, while RGB images provide rich semantic context. Current point cloud methods struggle to capture fine-grained detail, especially for complex tasks, which RGB methods lack geometric awareness, which hinders their precision and generalization. We introduce PointMapPolicy, a novel approach that conditions diffusion policies on structured grids of points without downsampling. The resulting data type makes it easier to extract shape and spatial relationships from observations, and can be transformed between reference frames. Yet due to their structure in a regular grid, we enable the use of established computer vision techniques directly to 3D data. Using xLSTM as a backbone, our model efficiently fuses the point maps with RGB data for enhanced multi-modal perception. Through extensive experiments on the RoboCasa and CALVIN benchmarks and real robot evaluations, we demonstrate that our method achieves state-of-the-art performance across diverse manipulation tasks. The overview and demos are available on our project page: https://point-map.github.io/Point-Map/",
        "tags": [
            "3D",
            "Diffusion",
            "Robotics"
        ]
    },
    {
        "id": "136",
        "title": "Balancing Specialization and Centralization: A Multi-Agent Reinforcement Learning Benchmark for Sequential Industrial Control",
        "author": [
            "Tom Maus",
            "Asma Atamna",
            "Tobias Glasmachers"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20408",
        "abstract": "Autonomous control of multi-stage industrial processes requires both local specialization and global coordination. Reinforcement learning (RL) offers a promising approach, but its industrial adoption remains limited due to challenges such as reward design, modularity, and action space management. Many academic benchmarks differ markedly from industrial control problems, limiting their transferability to real-world applications. This study introduces an enhanced industry-inspired benchmark environment that combines tasks from two existing benchmarks, SortingEnv and ContainerGym, into a sequential recycling scenario with sorting and pressing operations. We evaluate two control strategies: a modular architecture with specialized agents and a monolithic agent governing the full system, while also analyzing the impact of action masking. Our experiments show that without action masking, agents struggle to learn effective policies, with the modular architecture performing better. When action masking is applied, both architectures improve substantially, and the performance gap narrows considerably. These results highlight the decisive role of action space constraints and suggest that the advantages of specialization diminish as action complexity is reduced. The proposed benchmark thus provides a valuable testbed for exploring practical and robust multi-agent RL solutions in industrial automation, while contributing to the ongoing debate on centralization versus specialization.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "137",
        "title": "Why DPO is a Misspecified Estimator and How to Fix It",
        "author": [
            "Aditya Gopalan",
            "Sayak Ray Chowdhury",
            "Debangshu Banerjee"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20413",
        "abstract": "Direct alignment algorithms such as Direct Preference Optimization (DPO) fine-tune models based on preference data, using only supervised learning instead of two-stage reinforcement learning with human feedback (RLHF). We show that DPO encodes a statistical estimation problem over reward functions induced by a parametric policy class. When the true reward function that generates preferences cannot be realized via the policy class, DPO becomes misspecified, resulting in failure modes such as preference order reversal, worsening of policy reward, and high sensitivity to the input preference data distribution. On the other hand, we study the local behavior of two-stage RLHF for a parametric class and relate it to a natural gradient step in policy space. Our fine-grained geometric characterization allows us to propose AuxDPO, which introduces additional auxiliary variables in the DPO loss function to help move towards the RLHF solution in a principled manner and mitigate the misspecification in DPO. We empirically demonstrate the superior performance of AuxDPO on didactic bandit settings as well as LLM alignment tasks.",
        "tags": [
            "DPO",
            "LLM",
            "RL",
            "RLHF"
        ]
    },
    {
        "id": "138",
        "title": "Projecting onto the Unit Dual Quaternion Set",
        "author": [
            "Ziyang Li",
            "Chunfeng Cui",
            "Jiaxin Xie"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20425",
        "abstract": "Dual quaternions have gained significant attention due to their wide applications in areas such as multi-agent formation control, 3D motion modeling, and robotics. A fundamental aspect in dual quaternion research involves the projection onto unit dual quaternion sets. In this paper, we systematically study such projections under the $2^R$-norm, which is commonly used in practical applications. We identify several distinct cases based on the relationship between the standard and dual parts in vector form, and demonstrate the effectiveness of the proposed algorithm through numerical experiments.",
        "tags": [
            "3D",
            "Robotics"
        ]
    },
    {
        "id": "139",
        "title": "An Empirical Study of Sample Selection Strategies for Large Language Model Repair",
        "author": [
            "Xuran Li",
            "Jingyi Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20428",
        "abstract": "Large language models (LLMs) are increasingly deployed in real-world systems, yet they can produce toxic or biased outputs that undermine safety and trust. Post-hoc model repair provides a practical remedy, but the high cost of parameter updates motivates selective use of repair data. Despite extensive prior work on data selection for model training, it remains unclear which sampling criteria are most effective and efficient when applied specifically to behavioral repair of large generative models. Our study presents a systematic analysis of sample prioritization strategies for LLM repair. We evaluate five representative selection methods, including random sampling, K-Center, gradient-norm-based selection(GraNd), stratified coverage (CCS), and a Semantic-Aware Prioritized Sampling (SAPS) approach we proposed. Repair effectiveness and trade-offs are assessed through toxicity reduction, perplexity on WikiText-2 and LAMBADA, and three composite metrics: the Repair Proximity Score (RPS), the Overall Performance Score (OPS), and the Repair Efficiency Score (RES). Experimental results show that SAPS achieves the best balance between detoxification, utility preservation, and efficiency, delivering comparable or superior repair outcomes with substantially less data. Random sampling remains effective for large or robust models, while high-overhead methods such as CCS and GraNd provide limited benefit. The optimal data proportion depends on model scale and repair method, indicating that sample selection should be regarded as a tunable component of repair pipelines. Overall, these findings establish selection-based repair as an efficient and scalable paradigm for maintaining LLM reliability.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "140",
        "title": "LM-mixup: Text Data Augmentation via Language Model based Mixup",
        "author": [
            "Zhijie Deng",
            "Zhouan Shen",
            "Ling Li",
            "Yao Zhou",
            "Zhaowei Zhu",
            "Yanji He",
            "Wei Wang",
            "Jiaheng Wei"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20449",
        "abstract": "Instruction tuning is crucial for aligning Large Language Models (LLMs), yet the quality of instruction-following data varies significantly. While high-quality data is paramount, it is often scarce; conversely, abundant low-quality data is frequently discarded, leading to substantial information loss. Existing data augmentation methods struggle to augment this low-quality data effectively, and the evaluation of such techniques remains poorly defined. To address this, we formally define the task of Instruction Distillation: distilling multiple low-quality and redundant inputs into high-quality and coherent instruction-output pairs. Specifically, we introduce a comprehensive data construction pipeline to create MIXTURE, a 144K-sample dataset pairing low-quality or semantically redundant imperfect instruction clusters with their high-quality distillations. We then introduce LM-Mixup, by first performing supervised fine-tuning on MIXTURE and then optimizing it with reinforcement learning. This process uses three complementary reward signals: quality, semantic alignment, and format compliance, via Group Relative Policy Optimization (GRPO). We demonstrate that LM-Mixup effectively augments imperfect datasets: fine-tuning LLMs on its distilled data, which accounts for only about 3% of the entire dataset, not only surpasses full-dataset training but also competes with state-of-the-art high-quality data selection methods across multiple benchmarks. Our work establishes that low-quality data is a valuable resource when properly distilled and augmented with LM-Mixup, significantly enhancing the efficiency and performance of instruction-tuned LLMs.",
        "tags": [
            "GRPO",
            "LLM",
            "RL"
        ]
    },
    {
        "id": "141",
        "title": "Systematic Evaluation of Uncertainty Estimation Methods in Large Language Models",
        "author": [
            "Christian Hobelsberger",
            "Theresa Winner",
            "Andreas Nawroth",
            "Oliver Mitevski",
            "Anna-Carolina Haensch"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20460",
        "abstract": "Large language models (LLMs) produce outputs with varying levels of uncertainty, and, just as often, varying levels of correctness; making their practical reliability far from guaranteed. To quantify this uncertainty, we systematically evaluate four approaches for confidence estimation in LLM outputs: VCE, MSP, Sample Consistency, and CoCoA (Vashurin et al., 2025). For the evaluation of the approaches, we conduct experiments on four question-answering tasks using a state-of-the-art open-source LLM. Our results show that each uncertainty metric captures a different facet of model confidence and that the hybrid CoCoA approach yields the best reliability overall, improving both calibration and discrimination of correct answers. We discuss the trade-offs of each method and provide recommendations for selecting uncertainty measures in LLM applications.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "142",
        "title": "Conan: Progressive Learning to Reason Like a Detective over Multi-Scale Visual Evidence",
        "author": [
            "Kun Ouyang",
            "Yuanxin Liu",
            "Linli Yao",
            "Yishuo Cai",
            "Hao Zhou",
            "Jie Zhou",
            "Fandong Meng",
            "Xu Sun"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20470",
        "abstract": "Video reasoning, which requires multi-step deduction across frames, remains a major challenge for multimodal large language models (MLLMs). While reinforcement learning (RL)-based methods enhance reasoning capabilities, they often rely on text-only chains that yield ungrounded or hallucinated conclusions. Conversely, frame-retrieval approaches introduce visual grounding but still struggle with inaccurate evidence localization. To address these challenges, we present Conan, a framework for evidence-grounded multi-step video reasoning. Conan identifies contextual and evidence frames, reasons over cross-frame clues, and adaptively decides when to conclude or explore further. To achieve this, we (1) construct Conan-91K, a large-scale dataset of automatically generated reasoning traces that includes frame identification, evidence reasoning, and action decision, and (2) design a multi-stage progressive cold-start strategy combined with an Identification-Reasoning-Action (AIR) RLVR training framework to jointly enhance multi-step visual reasoning. Extensive experiments on six multi-step reasoning benchmarks demonstrate that Conan surpasses the baseline Qwen2.5-VL-7B-Instruct by an average of over 10% in accuracy, achieving state-of-the-art performance. Furthermore, Conan generalizes effectively to long-video understanding tasks, validating its strong scalability and robustness.",
        "tags": [
            "LLM",
            "RL"
        ]
    },
    {
        "id": "143",
        "title": "Robot Path and Trajectory Planning Considering a Spatially Fixed TCP",
        "author": [
            "Bernhard Rameder",
            "Hubert Gattringer",
            "Andreas Mueller",
            "Ronald Naderer"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20473",
        "abstract": "This paper presents a method for planning a trajectory in workspace coordinates using a spatially fixed tool center point (TCP), while taking into account the processing path on a part. This approach is beneficial if it is easier to move the part rather than moving the tool. Whether a mathematical description that defines the shape to be processed or single points from a design program are used, the robot path is finally represented using B-splines. The use of splines enables the path to be continuous with a desired degree, which finally leads to a smooth robot trajectory. While calculating the robot trajectory through prescribed orientation, additionally a given velocity at the TCP has to be considered. The procedure was validated on a real system using an industrial robot moving an arbitrary defined part.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "144",
        "title": "Bi-CoG: Bi-Consistency-Guided Self-Training for Vision-Language Models",
        "author": [
            "Rui Zhu",
            "Song-Lin Lv",
            "Zi-Kang Wang",
            "Lan-Zhe Guo"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20477",
        "abstract": "Exploiting unlabeled data through semi-supervised learning (SSL) or leveraging pre-trained models via fine-tuning are two prevailing paradigms for addressing label-scarce scenarios. Recently, growing attention has been given to combining fine-tuning of pre-trained vision-language models (VLMs) with SSL, forming the emerging paradigm of semi-supervised fine-tuning. However, existing methods often suffer from model bias and hyperparameter sensitivity, due to reliance on prediction consistency or pre-defined confidence thresholds. To address these limitations, we propose a simple yet effective plug-and-play methodology named $\\underline{\\textbf{Bi-Co}}$nsistency-$\\underline{\\textbf{G}}$uided Self-Training (Bi-CoG), which assigns high-quality and low-bias pseudo-labels, by simultaneously exploiting inter-model and intra-model consistency, along with an error-aware dynamic pseudo-label assignment strategy. Both theoretical analysis and extensive experiments over 14 datasets demonstrate the effectiveness of Bi-CoG, which consistently and significantly improves the performance of existing methods.",
        "tags": [
            "VLM"
        ]
    },
    {
        "id": "145",
        "title": "RECALL: REpresentation-aligned Catastrophic-forgetting ALLeviation via Hierarchical Model Merging",
        "author": [
            "Bowen Wang",
            "Haiyuan Wan",
            "Liwen Shi",
            "Chen Yang",
            "Peng He",
            "Yue Ma",
            "Haochen Han",
            "Wenhao Li",
            "Tiao Tan",
            "Yongjian Li",
            "Fangming Liu",
            "Yifan Gong",
            "Sheng Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20479",
        "abstract": "We unveil that internal representations in large language models (LLMs) serve as reliable proxies of learned knowledge, and propose RECALL, a novel representation-aware model merging framework for continual learning without access to historical data. RECALL computes inter-model similarity from layer-wise hidden representations over clustered typical samples, and performs adaptive, hierarchical parameter fusion to align knowledge across models. This design enables the preservation of domain-general features in shallow layers while allowing task-specific adaptation in deeper layers. Unlike prior methods that require task labels or incur performance trade-offs, RECALL achieves seamless multi-domain integration and strong resistance to catastrophic forgetting. Extensive experiments across five NLP tasks and multiple continual learning scenarios show that RECALL outperforms baselines in both knowledge retention and generalization, providing a scalable and data-free solution for evolving LLMs.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "146",
        "title": "Degradation-Aware Cooperative Multi-Modal GNSS-Denied Localization Leveraging LiDAR-Based Robot Detections",
        "author": [
            "VÃ¡clav Pritzl",
            "Xianjia Yu",
            "Tomi Westerlund",
            "Petr Å tÄpÃ¡n",
            "Martin Saska"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20480",
        "abstract": "Accurate long-term localization using onboard sensors is crucial for robots operating in Global Navigation Satellite System (GNSS)-denied environments. While complementary sensors mitigate individual degradations, carrying all the available sensor types on a single robot significantly increases the size, weight, and power demands. Distributing sensors across multiple robots enhances the deployability but introduces challenges in fusing asynchronous, multi-modal data from independently moving platforms. We propose a novel adaptive multi-modal multi-robot cooperative localization approach using a factor-graph formulation to fuse asynchronous Visual-Inertial Odometry (VIO), LiDAR-Inertial Odometry (LIO), and 3D inter-robot detections from distinct robots in a loosely-coupled fashion. The approach adapts to changing conditions, leveraging reliable data to assist robots affected by sensory degradations. A novel interpolation-based factor enables fusion of the unsynchronized measurements. LIO degradations are evaluated based on the approximate scan-matching Hessian. A novel approach of weighting odometry data proportionally to the Wasserstein distance between the consecutive VIO outputs is proposed. A theoretical analysis is provided, investigating the cooperative localization problem under various conditions, mainly in the presence of sensory degradations. The proposed method has been extensively evaluated on real-world data gathered with heterogeneous teams of an Unmanned Ground Vehicle (UGV) and Unmanned Aerial Vehicles (UAVs), showing that the approach provides significant improvements in localization accuracy in the presence of various sensory degradations.",
        "tags": [
            "3D",
            "Robotics"
        ]
    },
    {
        "id": "147",
        "title": "Dual Control Reference Generation for Optimal Pick-and-Place Execution under Payload Uncertainty",
        "author": [
            "Victor Vantilborgh",
            "Hrishikesh Sathyanarayan",
            "Guillaume Crevecoeur",
            "Ian Abraham",
            "Tom Lefebvre"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20483",
        "abstract": "This work addresses the problem of robot manipulation tasks under unknown dynamics, such as pick-and-place tasks under payload uncertainty, where active exploration and(/for) online parameter adaptation during task execution are essential to enable accurate model-based control. The problem is framed as dual control seeking a closed-loop optimal control problem that accounts for parameter uncertainty. We simplify the dual control problem by pre-defining the structure of the feedback policy to include an explicit adaptation mechanism. Then we propose two methods for reference trajectory generation. The first directly embeds parameter uncertainty in robust optimal control methods that minimize the expected task cost. The second method considers minimizing the so-called optimality loss, which measures the sensitivity of parameter-relevant information with respect to task performance. We observe that both approaches reason over the Fisher information as a natural side effect of their formulations, simultaneously pursuing optimal task execution. We demonstrate the effectiveness of our approaches for a pick-and-place manipulation task. We show that designing the reference trajectories whilst taking into account the control enables faster and more accurate task performance and system identification while ensuring stable and efficient control.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "148",
        "title": "Steering Evaluation-Aware Language Models To Act Like They Are Deployed",
        "author": [
            "Tim Tian Hua",
            "Andrew Qin",
            "Samuel Marks",
            "Neel Nanda"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20487",
        "abstract": "Large language models (LLMs) can sometimes detect when they are being evaluated and adjust their behavior to appear more aligned, compromising the reliability of safety evaluations. In this paper, we show that adding a steering vector to an LLM's activations can suppress evaluation-awareness and make the model act like it is deployed during evaluation. To study our steering technique, we train an LLM to exhibit evaluation-aware behavior using a two-step training process designed to mimic how this behavior could emerge naturally. First, we perform continued pretraining on documents with factual descriptions of the model (1) using Python type hints during evaluation but not during deployment and (2) recognizing that the presence of a certain evaluation cue always means that it is being tested. Then, we train the model with expert iteration to use Python type hints in evaluation settings. The resulting model is evaluation-aware: it writes type hints in evaluation contexts more than deployment contexts. However, this gap can only be observed by removing the evaluation cue. We find that activation steering can suppress evaluation awareness and make the model act like it is deployed even when the cue is present. Importantly, we constructed our steering vector using the original model before our additional training. Our results suggest that AI evaluators could improve the reliability of safety evaluations by steering models to act like they are deployed.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "149",
        "title": "Simultaneous Stiffness and Trajectory Optimization for Energy Minimization of Pick-and-Place Tasks of SEA-Actuated Parallel Kinematic Manipulators",
        "author": [
            "Thomas Kordik",
            "Hubert Gattringer",
            "Andreas Mueller"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20490",
        "abstract": "A major field of industrial robot applications deals with repetitive tasks that alternate between operating points. For these so-called pick-and-place operations, parallel kinematic manipulators (PKM) are frequently employed. These tasks tend to automatically run for a long period of time and therefore minimizing energy consumption is always of interest. Recent research addresses this topic by the use of elastic elements and particularly series elastic actuators (SEA). This paper explores the possibilities of minimizing energy consumption of SEA actuated PKM performing pick-and-place tasks. The basic idea is to excite eigenmotions that result from the actuator springs and exploit their oscillating characteristics. To this end, a prescribed cyclic pick-and-place operation is analyzed and a dynamic model of SEA driven PKM is derived. Subsequently, an energy minimizing optimal control problem is formulated where operating trajectories as well as SEA stiffnesses are optimized simultaneously. Here, optimizing the actuator stiffness does not account for variable stiffness actuators. It serves as a tool for the design and dimensioning process. The hypothesis on energy reduction is tested on two (parallel) robot applications where redundant actuation is also addressed. The results confirm the validity of this approach.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "150",
        "title": "Robust Preference Alignment via Directional Neighborhood Consensus",
        "author": [
            "Ruochen Mao",
            "Yuling Shi",
            "Xiaodong Gu",
            "Jiaheng Wei"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20498",
        "abstract": "Aligning large language models with human preferences is critical for creating reliable and controllable AI systems. A human preference can be visualized as a high-dimensional vector where different directions represent trade-offs between desired attributes (e.g., helpfulness vs. verbosity). Yet, because the training data often reflects dominant, average preferences, LLMs tend to perform well on common requests but fall short in specific, individual needs. This mismatch creates a preference coverage gap. Existing methods often address this through costly retraining, which may not be generalized to the full spectrum of diverse preferences. This brittleness means that when a user's request reflects a nuanced preference deviating from the training data's central tendency, model performance can degrade unpredictably. To address this challenge, we introduce Robust Preference Selection (RPS), a post-hoc, training-free method by leveraging directional neighborhood consensus. Instead of forcing a model to generate a response from a single, highly specific preference, RPS samples multiple responses from a local neighborhood of related preferences to create a superior candidate pool. It then selects the response that best aligns with the user's original intent. We provide a theoretical framework showing our neighborhood generation strategy is provably superior to a strong baseline that also samples multiple candidates. Comprehensive experiments across three distinct alignment paradigms (DPA, DPO, and SFT) demonstrate that RPS consistently improves robustness against this baseline, achieving win rates of up to 69% on challenging preferences from under-represented regions of the space without any model retraining. Our work presents a practical, theoretically-grounded solution for enhancing the reliability of preference-aligned models.",
        "tags": [
            "DPO",
            "LLM"
        ]
    },
    {
        "id": "151",
        "title": "Speaking Clearly: A Simplified Whisper-Based Codec for Low-Bitrate Speech Coding",
        "author": [
            "Xin Zhang",
            "Lin Li",
            "Xiangni Lu",
            "Jianquan Liu",
            "Kong Aik Lee"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20504",
        "abstract": "Speech codecs serve as bridges between continuous speech signals and large language models, yet face an inherent conflict between acoustic fidelity and semantic preservation. To mitigate this conflict, prevailing methods augment acoustic codecs with complex semantic supervision. We explore the opposite direction: a semantic-first approach that starts from a semantically-capable model and adapts it for high-fidelity acoustic reconstruction. Through empirical analysis, we discover that targeted architectural simplification can unlock the acoustic modeling potential of Whisper, a text-aligned Automatic Speech Recognition (ASR) model. Based on this finding, we propose SimWhisper-Codec, a novel codec that balances the semantic and acoustic preservation by leveraging a frozen, simplified Whisper encoder without requiring external supervision. Experimental results demonstrate that SimWhisper-Codec achieves superior performance in both semantic preservation and acoustic quality compared to semantically-supervised codecs such as Mimi Codec and SpeechTokenizer at similar bitrates, validating the effectiveness of our semantic-first approach. Code is available at https://github.com/ZhangXinWhut/SimWhisper-Codec.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "152",
        "title": "Assessing the Political Fairness of Multilingual LLMs: A Case Study based on a 21-way Multiparallel EuroParl Dataset",
        "author": [
            "Paul Lerner",
            "FranÃ§ois Yvon"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20508",
        "abstract": "The political biases of Large Language Models (LLMs) are usually assessed by simulating their answers to English surveys. In this work, we propose an alternative framing of political biases, relying on principles of fairness in multilingual translation. We systematically compare the translation quality of speeches in the European Parliament (EP), observing systematic differences with majority parties from left, center, and right being better translated than outsider parties. This study is made possible by a new, 21-way multiparallel version of EuroParl, the parliamentary proceedings of the EP, which includes the political affiliations of each speaker. The dataset consists of 1.5M sentences for a total of 40M words and 249M characters. It covers three years, 1000+ speakers, 7 countries, 12 EU parties, 25 EU committees, and hundreds of national parties.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "153",
        "title": "EchoDistill: Bidirectional Concept Distillation for One-Step Diffusion Personalization",
        "author": [
            "Yixiong Yang",
            "Tao Wu",
            "Senmao Li",
            "Shiqi Yang",
            "Yaxing Wang",
            "Joost van de Weijer",
            "Kai Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20512",
        "abstract": "Recent advances in accelerating text-to-image (T2I) diffusion models have enabled the synthesis of high-fidelity images even in a single step. However, personalizing these models to incorporate novel concepts remains a challenge due to the limited capacity of one-step models to capture new concept distributions effectively. We propose a bidirectional concept distillation framework, EchoDistill, to enable one-step diffusion personalization (1-SDP). Our approach involves an end-to-end training process where a multi-step diffusion model (teacher) and a one-step diffusion model (student) are trained simultaneously. The concept is first distilled from the teacher model to the student, and then echoed back from the student to the teacher. During the EchoDistill, we share the text encoder between the two models to ensure consistent semantic understanding. Following this, the student model is optimized with adversarial losses to align with the real image distribution and with alignment losses to maintain consistency with the teacher's output. Furthermore, we introduce the bidirectional echoing refinement strategy, wherein the student model leverages its faster generation capability to feedback to the teacher model. This bidirectional concept distillation mechanism not only enhances the student ability to personalize novel concepts but also improves the generative quality of the teacher model. Our experiments demonstrate that this collaborative framework significantly outperforms existing personalization methods over the 1-SDP setup, establishing a novel paradigm for rapid and effective personalization in T2I diffusion models.",
        "tags": [
            "Diffusion",
            "Text-to-Image"
        ]
    },
    {
        "id": "154",
        "title": "Metis-HOME: Hybrid Optimized Mixture-of-Experts for Multimodal Reasoning",
        "author": [
            "Xiaohan Lan",
            "Fanfan Liu",
            "Haibo Qiu",
            "Siqi Yang",
            "Delian Ruan",
            "Peng Shi",
            "Lin Ma"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20519",
        "abstract": "Inspired by recent advancements in LLM reasoning, the field of multimodal reasoning has seen remarkable progress, achieving significant performance gains on intricate tasks such as mathematical problem-solving. Despite this progress, current multimodal large reasoning models exhibit two key limitations. They tend to employ computationally expensive reasoning even for simple queries, leading to inefficiency. Furthermore, this focus on specialized reasoning often impairs their broader, more general understanding capabilities. In this paper, we propose Metis-HOME: a Hybrid Optimized Mixture-of-Experts framework designed to address this trade-off. Metis-HOME enables a ''Hybrid Thinking'' paradigm by structuring the original dense model into two distinct expert branches: a thinking branch tailored for complex, multi-step reasoning, and a non-thinking branch optimized for rapid, direct inference on tasks like general VQA and OCR. A lightweight, trainable router dynamically allocates queries to the most suitable expert. We instantiate Metis-HOME by adapting the Qwen2.5-VL-7B into an MoE architecture. Comprehensive evaluations reveal that our approach not only substantially enhances complex reasoning abilities but also improves the model's general capabilities, reversing the degradation trend observed in other reasoning-specialized models. Our work establishes a new paradigm for building powerful and versatile MLLMs, effectively resolving the prevalent reasoning-vs-generalization dilemma.",
        "tags": [
            "LLM",
            "MoE"
        ]
    },
    {
        "id": "155",
        "title": "Large Language Models for Fault Localization: An Empirical Study",
        "author": [
            "YingJian Xiao",
            "RongQun Hu",
            "WeiWei Gong",
            "HongWei Li",
            "AnQuan Jie"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20521",
        "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities in code-related tasks, particularly in automated program repair. However, the effectiveness of such repairs is highly dependent on the performance of upstream fault localization, for which comprehensive evaluations are currently lacking. This paper presents a systematic empirical study on LLMs in the statement-level code fault localization task. We evaluate representative open-source models (Qwen2.5-coder-32b-instruct, DeepSeek-V3) and closed-source models (GPT-4.1 mini, Gemini-2.5-flash) to assess their fault localization capabilities on the HumanEval-Java and Defects4J datasets. The study investigates the impact of different prompting strategies--including standard prompts, few-shot examples, and chain-of-reasoning--on model performance, with a focus on analysis across accuracy, time efficiency, and economic cost dimensions. Our experimental results show that incorporating bug report context significantly enhances model performance. Few-shot learning shows potential for improvement but exhibits noticeable diminishing marginal returns, while chain-of-thought reasoning's effectiveness is highly contingent on the model's inherent reasoning capabilities. This study not only highlights the performance characteristics and trade-offs of different models in fault localization tasks, but also offers valuable insights into the strengths of current LLMs and strategies for improving fault localization effectiveness.",
        "tags": [
            "CoT",
            "DeepSeek",
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "156",
        "title": "Fake-in-Facext: Towards Fine-Grained Explainable DeepFake Analysis",
        "author": [
            "Lixiong Qin",
            "Yang Zhang",
            "Mei Wang",
            "Jiani Hu",
            "Weihong Deng",
            "Weiran Xu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20531",
        "abstract": "The advancement of Multimodal Large Language Models (MLLMs) has bridged the gap between vision and language tasks, enabling the implementation of Explainable DeepFake Analysis (XDFA). However, current methods suffer from a lack of fine-grained awareness: the description of artifacts in data annotation is unreliable and coarse-grained, and the models fail to support the output of connections between textual forgery explanations and the visual evidence of artifacts, as well as the input of queries for arbitrary facial regions. As a result, their responses are not sufficiently grounded in Face Visual Context (Facext). To address this limitation, we propose the Fake-in-Facext (FiFa) framework, with contributions focusing on data annotation and model construction. We first define a Facial Image Concept Tree (FICT) to divide facial images into fine-grained regional concepts, thereby obtaining a more reliable data annotation pipeline, FiFa-Annotator, for forgery explanation. Based on this dedicated data annotation, we introduce a novel Artifact-Grounding Explanation (AGE) task, which generates textual forgery explanations interleaved with segmentation masks of manipulated artifacts. We propose a unified multi-task learning architecture, FiFa-MLLM, to simultaneously support abundant multimodal inputs and outputs for fine-grained Explainable DeepFake Analysis. With multiple auxiliary supervision tasks, FiFa-MLLM can outperform strong baselines on the AGE task and achieve SOTA performance on existing XDFA datasets. The code and data will be made open-source at https://github.com/lxq1000/Fake-in-Facext.",
        "tags": [
            "LLM",
            "Segmentation"
        ]
    },
    {
        "id": "157",
        "title": "ARC-Encoder: learning compressed text representations for large language models",
        "author": [
            "Hippolyte Pilchen",
            "Edouard Grave",
            "Patrick PÃ©rez"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20535",
        "abstract": "Recent techniques such as retrieval-augmented generation or chain-of-thought reasoning have led to longer contexts and increased inference costs. Context compression techniques can reduce these costs, but the most effective approaches require fine-tuning the target model or even modifying its architecture. This can degrade its general abilities when not used for this specific purpose. Here we explore an alternative approach: an encoder that compresses the context into continuous representations which replace token embeddings in decoder LLMs. First, we perform a systematic study of training strategies and architecture choices for the encoder. Our findings led to the design of an Adaptable text Representations Compressor, named ARC-Encoder, which outputs $x$-times fewer continuous representations (typically $x\\!\\in\\!\\{4,8\\}$) than text tokens. We evaluate ARC-Encoder across a variety of LLM usage scenarios, ranging from in-context learning to context window extension, on both instruct and base decoders. Results show that ARC-Encoder achieves state-of-the-art performance on several benchmarks while improving computational efficiency at inference. Finally, we demonstrate that our models can be adapted to multiple decoders simultaneously, allowing a single encoder to generalize across different decoder LLMs. This makes ARC-Encoder a flexible and efficient solution for portable encoders that work seamlessly with multiple LLMs. We release a training code at https://github.com/kyutai-labs/ARC-Encoder , fine-tuning dataset and pretrained models are available at https://huggingface.co/collections/kyutai/arc-encoders-68ee18787301407d60a57047 .",
        "tags": [
            "CoT",
            "LLM"
        ]
    },
    {
        "id": "158",
        "title": "A Unified Framework for Zero-Shot Reinforcement Learning",
        "author": [
            "Jacopo Di Ventura",
            "Jan Felix Kleuker",
            "Aske Plaat",
            "Thomas Moerland"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20542",
        "abstract": "Zero-shot reinforcement learning (RL) has emerged as a setting for developing general agents in an unsupervised manner, capable of solving downstream tasks without additional training or planning at test-time. Unlike conventional RL, which optimizes policies for a fixed reward, zero-shot RL requires agents to encode representations rich enough to support immediate adaptation to any objective, drawing parallels to vision and language foundation models. Despite growing interest, the field lacks a common analytical lens.\nWe present the first unified framework for zero-shot RL. Our formulation introduces a consistent notation and taxonomy that organizes existing approaches and allows direct comparison between them. Central to our framework is the classification of algorithms into two families: direct representations, which learn end-to-end mappings from rewards to policies, and compositional representations, which decompose the representation leveraging the substructure of the value function. Within this framework, we highlight shared principles and key differences across methods, and we derive an extended bound for successor-feature methods, offering a new perspective on their performance in the zero-shot regime. By consolidating existing work under a common lens, our framework provides a principled foundation for future research in zero-shot RL and outlines a clear path toward developing more general agents.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "159",
        "title": "GlobalRAG: Enhancing Global Reasoning in Multi-hop Question Answering via Reinforcement Learning",
        "author": [
            "Jinchang Luo",
            "Mingquan Cheng",
            "Fan Wan",
            "Ni Li",
            "Xiaoling Xia",
            "Shuangshuang Tian",
            "Tingcheng Bian",
            "Haiwei Wang",
            "Haohuan Fu",
            "Yan Tao"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20548",
        "abstract": "Reinforcement learning has recently shown promise in improving retrieval-augmented generation (RAG). Despite these advances, its effectiveness in multi-hop question answering (QA) remains limited by two fundamental limitations: (i) global planning absence to structure multi-step reasoning, and (ii) unfaithful execution, which hinders effective query formulation and consistent use of retrieved evidence. We propose GlobalRAG, a reinforcement learning framework designed to enhance global reasoning in multi-hop QA. GlobalRAG decomposes questions into subgoals, coordinates retrieval with reasoning, and refines evidence iteratively. To guide this process, we introduce Planning Quality Reward and SubGoal Completion Reward, which encourage coherent planning and reliable subgoal execution. In addition, a progressive weight annealing strategy balances process-oriented and outcome-based objectives. Extensive experiments on both in-domain and out-of-domain benchmarks demonstrate that GlobalRAG significantly outperforms strong baselines while using only 8k training data (42% of the training data used by strong baselines), achieving average improvements of 14.2% in both EM and F1.",
        "tags": [
            "RAG",
            "RL"
        ]
    },
    {
        "id": "160",
        "title": "Deep Learning-Powered Visual SLAM Aimed at Assisting Visually Impaired Navigation",
        "author": [
            "Marziyeh Bamdad",
            "Hans-Peter Hutter",
            "Alireza Darvishy"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20549",
        "abstract": "Despite advancements in SLAM technologies, robust operation under challenging conditions such as low-texture, motion-blur, or challenging lighting remains an open challenge. Such conditions are common in applications such as assistive navigation for the visually impaired. These challenges undermine localization accuracy and tracking stability, reducing navigation reliability and safety. To overcome these limitations, we present SELM-SLAM3, a deep learning-enhanced visual SLAM framework that integrates SuperPoint and LightGlue for robust feature extraction and matching. We evaluated our framework using TUM RGB-D, ICL-NUIM, and TartanAir datasets, which feature diverse and challenging scenarios. SELM-SLAM3 outperforms conventional ORB-SLAM3 by an average of 87.84% and exceeds state-of-the-art RGB-D SLAM systems by 36.77%. Our framework demonstrates enhanced performance under challenging conditions, such as low-texture scenes and fast motion, providing a reliable platform for developing navigation aids for the visually impaired.",
        "tags": [
            "SLAM"
        ]
    },
    {
        "id": "161",
        "title": "AdaDoS: Adaptive DoS Attack via Deep Adversarial Reinforcement Learning in SDN",
        "author": [
            "Wei Shao",
            "Yuhao Wang",
            "Rongguang He",
            "Muhammad Ejaz Ahmed",
            "Seyit Camtepe"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20566",
        "abstract": "Existing defence mechanisms have demonstrated significant effectiveness in mitigating rule-based Denial-of-Service (DoS) attacks, leveraging predefined signatures and static heuristics to identify and block malicious traffic. However, the emergence of AI-driven techniques presents new challenges to SDN security, potentially compromising the efficacy of existing defence mechanisms. In this paper, we introduce~AdaDoS, an adaptive attack model that disrupt network operations while evading detection by existing DoS-based detectors through adversarial reinforcement learning (RL). Specifically, AdaDoS models the problem as a competitive game between an attacker, whose goal is to obstruct network traffic without being detected, and a detector, which aims to identify malicious traffic. AdaDoS can solve this game by dynamically adjusting its attack strategy based on feedback from the SDN and the detector. Additionally, recognising that attackers typically have less information than defenders, AdaDoS formulates the DoS-like attack as a partially observed Markov decision process (POMDP), with the attacker having access only to delay information between attacker and victim nodes. We address this challenge with a novel reciprocal learning module, where the student agent, with limited observations, enhances its performance by learning from the teacher agent, who has full observational capabilities in the SDN environment. AdaDoS represents the first application of RL to develop DoS-like attack sequences, capable of adaptively evading both machine learning-based and rule-based DoS-like attack detectors.",
        "tags": [
            "Detection",
            "RL"
        ]
    },
    {
        "id": "162",
        "title": "EmbodiedBrain: Expanding Performance Boundaries of Task Planning for Embodied Intelligence",
        "author": [
            "Ding Zou",
            "Feifan Wang",
            "Mengyu Ge",
            "Siyuan Fan",
            "Zongbing Zhang",
            "Wei Chen",
            "Lingfeng Wang",
            "Zhongyou Hu",
            "Wenrui Yan",
            "Zhengwei Gao",
            "Hao Wang",
            "Weizhao Jin",
            "Yu Zhang",
            "Hainan Zhao",
            "Mingliang Zhang",
            "Xianxian Xi",
            "Yaru Zhang",
            "Wenyuan Li",
            "Zhengguang Gao",
            "Yurui Zhu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20578",
        "abstract": "The realization of Artificial General Intelligence (AGI) necessitates Embodied AI agents capable of robust spatial perception, effective task planning, and adaptive execution in physical environments. However, current large language models (LLMs) and multimodal LLMs (MLLMs) for embodied tasks suffer from key limitations, including a significant gap between model design and agent requirements, an unavoidable trade-off between real-time latency and performance, and the use of unauthentic, offline evaluation metrics. To address these challenges, we propose EmbodiedBrain, a novel vision-language foundation model available in both 7B and 32B parameter sizes. Our framework features an agent-aligned data structure and employs a powerful training methodology that integrates large-scale Supervised Fine-Tuning (SFT) with Step-Augumented Group Relative Policy Optimization (Step-GRPO), which boosts long-horizon task success by integrating preceding steps as Guided Precursors. Furthermore, we incorporate a comprehensive reward system, including a Generative Reward Model (GRM) accelerated at the infrastructure level, to improve training efficiency. For enable thorough validation, we establish a three-part evaluation system encompassing General, Planning, and End-to-End Simulation Benchmarks, highlighted by the proposal and open-sourcing of a novel, challenging simulation environment. Experimental results demonstrate that EmbodiedBrain achieves superior performance across all metrics, establishing a new state-of-the-art for embodied foundation models. Towards paving the way for the next generation of generalist embodied agents, we open-source all of our data, model weight, and evaluating methods, which are available at https://zterobot.github.io/EmbodiedBrain.github.io.",
        "tags": [
            "GRPO",
            "LLM"
        ]
    },
    {
        "id": "163",
        "title": "Open-o3 Video: Grounded Video Reasoning with Explicit Spatio-Temporal Evidence",
        "author": [
            "Jiahao Meng",
            "Xiangtai Li",
            "Haochen Wang",
            "Yue Tan",
            "Tao Zhang",
            "Lingdong Kong",
            "Yunhai Tong",
            "Anran Wang",
            "Zhiyang Teng",
            "Yujing Wang",
            "Zhuochen Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20579",
        "abstract": "Most video reasoning models only generate textual reasoning traces without indicating when and where key evidence appears. Recent models such as OpenAI-o3 have sparked wide interest in evidence-centered reasoning for images, yet extending this ability to videos is more challenging, as it requires joint temporal tracking and spatial localization across dynamic scenes. We introduce Open-o3 Video, a non-agent framework that integrates explicit spatio-temporal evidence into video reasoning, and carefully collect training data and design training strategies to address the aforementioned challenges. The model highlights key timestamps, objects, and bounding boxes alongside its answers, allowing reasoning to be grounded in concrete visual observations. To enable this functionality, we first curate and build two high-quality datasets, STGR-CoT-30k for SFT and STGR-RL-36k for RL, with carefully constructed temporal and spatial annotations, since most existing datasets offer either temporal spans for videos or spatial boxes on images, lacking unified spatio-temporal supervision and reasoning traces. Then, we adopt a cold-start reinforcement learning strategy with multiple specially designed rewards that jointly encourage answer accuracy, temporal alignment, and spatial precision. On V-STAR benchmark, Open-o3 Video achieves state-of-the-art performance, raising mAM by 14.4% and mLGM by 24.2% on the Qwen2.5-VL baseline. Consistent improvements are also observed on a broad range of video understanding benchmarks, including VideoMME, WorldSense, VideoMMMU, and TVGBench. Beyond accuracy, the reasoning traces produced by Open-o3 Video also provide valuable signals for test-time scaling, enabling confidence-aware verification and improving answer reliability.",
        "tags": [
            "CoT",
            "RL"
        ]
    },
    {
        "id": "164",
        "title": "Can ChatGPT Code Communication Data Fairly?: Empirical Evidence from Multiple Collaborative Tasks",
        "author": [
            "Jiangang Hao",
            "Wenju Cui",
            "Patrick Kyllonen",
            "Emily Kerzabi"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20584",
        "abstract": "Assessing communication and collaboration at scale depends on a labor intensive task of coding communication data into categories according to different frameworks. Prior research has established that ChatGPT can be directly instructed with coding rubrics to code the communication data and achieves accuracy comparable to human raters. However, whether the coding from ChatGPT or similar AI technology exhibits bias against different demographic groups, such as gender and race, remains unclear. To fill this gap, this paper investigates ChatGPT-based automated coding of communication data using a typical coding framework for collaborative problem solving, examining differences across gender and racial groups. The analysis draws on data from three types of collaborative tasks: negotiation, problem solving, and decision making. Our results show that ChatGPT-based coding exhibits no significant bias across gender and racial groups, paving the road for its adoption in large-scale assessment of collaboration and communication.",
        "tags": [
            "GPT"
        ]
    },
    {
        "id": "165",
        "title": "GenColorBench: A Color Evaluation Benchmark for Text-to-Image Generation Models",
        "author": [
            "Muhammad Atif Butt",
            "Alexandra Gomez-Villa",
            "Tao Wu",
            "Javier Vazquez-Corral",
            "Joost Van De Weijer",
            "Kai Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20586",
        "abstract": "Recent years have seen impressive advances in text-to-image generation, with image generative or unified models producing high-quality images from text. Yet these models still struggle with fine-grained color controllability, often failing to accurately match colors specified in text prompts. While existing benchmarks evaluate compositional reasoning and prompt adherence, none systematically assess color precision. Color is fundamental to human visual perception and communication, critical for applications from art to design workflows requiring brand consistency. However, current benchmarks either neglect color or rely on coarse assessments, missing key capabilities such as interpreting RGB values or aligning with human expectations. To this end, we propose GenColorBench, the first comprehensive benchmark for text-to-image color generation, grounded in color systems like ISCC-NBS and CSS3/X11, including numerical colors which are absent elsewhere. With 44K color-focused prompts covering 400+ colors, it reveals models' true capabilities via perceptual and automated assessments. Evaluations of popular text-to-image models using GenColorBench show performance variations, highlighting which color conventions models understand best and identifying failure modes. Our GenColorBench assessments will guide improvements in precise color generation. The benchmark will be made public upon acceptance.",
        "tags": [
            "Text-to-Image"
        ]
    },
    {
        "id": "166",
        "title": "What Defines Good Reasoning in LLMs? Dissecting Reasoning Steps with Multi-Aspect Evaluation",
        "author": [
            "Heejin Do",
            "Jaehui Hwang",
            "Dongyoon Han",
            "Seong Joon Oh",
            "Sangdoo Yun"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20603",
        "abstract": "Evaluating large language models (LLMs) on final-answer correctness is the dominant paradigm. This approach, however, provides a coarse signal for model improvement and overlooks the quality of the underlying reasoning process. We argue that a more granular evaluation of reasoning offers a more effective path to building robust models. We decompose reasoning quality into two dimensions: relevance and coherence. Relevance measures if a step is grounded in the problem; coherence measures if it follows logically from prior steps. To measure these aspects reliably, we introduce causal stepwise evaluation (CaSE). This method assesses each reasoning step using only its preceding context, which avoids hindsight bias. We validate CaSE against human judgments on our new expert-annotated benchmarks, MRa-GSM8K and MRa-MATH. More importantly, we show that curating training data with CaSE-evaluated relevance and coherence directly improves final task performance. Our work provides a scalable framework for analyzing, debugging, and improving LLM reasoning, demonstrating the practical value of moving beyond validity checks.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "167",
        "title": "BUSTED at AraGenEval Shared Task: A Comparative Study of Transformer-Based Models for Arabic AI-Generated Text Detection",
        "author": [
            "Ali Zain",
            "Sareem Farooqui",
            "Muhammad Rafi"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20610",
        "abstract": "This paper details our submission to the Ara- GenEval Shared Task on Arabic AI-generated text detection, where our team, BUSTED, se- cured 5th place. We investigated the effec- tiveness of three pre-trained transformer mod- els: AraELECTRA, CAMeLBERT, and XLM- RoBERTa. Our approach involved fine-tuning each model on the provided dataset for a binary classification task. Our findings revealed a sur- prising result: the multilingual XLM-RoBERTa model achieved the highest performance with an F1 score of 0.7701, outperforming the spe- cialized Arabic models. This work underscores the complexities of AI-generated text detection and highlights the strong generalization capa- bilities of multilingual models.",
        "tags": [
            "Detection",
            "Transformer"
        ]
    },
    {
        "id": "168",
        "title": "Black Box Absorption: LLMs Undermining Innovative Ideas",
        "author": [
            "Wenjun Cao"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20612",
        "abstract": "Large Language Models are increasingly adopted as critical tools for accelerating innovation. This paper identifies and formalizes a systemic risk inherent in this paradigm: \\textbf{Black Box Absorption}. We define this as the process by which the opaque internal architectures of LLM platforms, often operated by large-scale service providers, can internalize, generalize, and repurpose novel concepts contributed by users during interaction. This mechanism threatens to undermine the foundational principles of innovation economics by creating severe informational and structural asymmetries between individual creators and platform operators, thereby jeopardizing the long-term sustainability of the innovation ecosystem. To analyze this challenge, we introduce two core concepts: the idea unit, representing the transportable functional logic of an innovation, and idea safety, a multidimensional standard for its protection. This paper analyzes the mechanisms of absorption and proposes a concrete governance and engineering agenda to mitigate these risks, ensuring that creator contributions remain traceable, controllable, and equitable.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "169",
        "title": "SeViCES: Unifying Semantic-Visual Evidence Consensus for Long Video Understanding",
        "author": [
            "Yuan Sheng",
            "Yanbin Hao",
            "Chenxu Li",
            "Shuo Wang",
            "Xiangnan He"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20622",
        "abstract": "Long video understanding remains challenging due to its complex, diverse, and temporally scattered content. Although video large language models (Video-LLMs) can process videos lasting tens of minutes, applying them to truly long sequences is computationally prohibitive and often leads to unfocused or inconsistent reasoning. A promising solution is to select only the most informative frames, yet existing approaches typically ignore temporal dependencies or rely on unimodal evidence, limiting their ability to provide complete and query-relevant context. We propose a Semantic-Visual Consensus Evidence Selection (SeViCES) framework for effective and reliable long video understanding. SeViCES is training-free and model-agnostic, and introduces two key components. The Semantic-Visual Consensus Frame Selection (SVCFS) module selects frames through (1) a temporal-aware semantic branch that leverages LLM reasoning over captions, and (2) a cluster-guided visual branch that aligns embeddings with semantic scores via mutual information. The Answer Consensus Refinement (ACR) module further resolves inconsistencies between semantic- and visual-based predictions by fusing evidence and constraining the answer space. Extensive experiments on long video understanding benchmarks show that SeViCES consistently outperforms state-of-the-art methods in both accuracy and robustness, demonstrating the importance of consensus-driven evidence selection for Video-LLMs.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "170",
        "title": "Towards Reliable Evaluation of Large Language Models for Multilingual and Multimodal E-Commerce Applications",
        "author": [
            "Shuyi Xie",
            "Ziqin Liew",
            "Hailing Zhang",
            "Haibo Zhang",
            "Ling Hu",
            "Zhiqiang Zhou",
            "Shuman Liu",
            "Anxiang Zeng"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20632",
        "abstract": "Large Language Models (LLMs) excel on general-purpose NLP benchmarks, yet their capabilities in specialized domains remain underexplored. In e-commerce, existing evaluations-such as EcomInstruct, ChineseEcomQA, eCeLLM, and Shopping MMLU-suffer from limited task diversity (e.g., lacking product guidance and after-sales issues), limited task modalities (e.g., absence of multimodal data), synthetic or curated data, and a narrow focus on English and Chinese, leaving practitioners without reliable tools to assess models on complex, real-world shopping scenarios. We introduce EcomEval, a comprehensive multilingual and multimodal benchmark for evaluating LLMs in e-commerce. EcomEval covers six categories and 37 tasks (including 8 multimodal tasks), sourced primarily from authentic customer queries and transaction logs, reflecting the noisy and heterogeneous nature of real business interactions. To ensure both quality and scalability of reference answers, we adopt a semi-automatic pipeline in which large models draft candidate responses subsequently reviewed and modified by over 50 expert annotators with strong e-commerce and multilingual expertise. We define difficulty levels for each question and task category by averaging evaluation scores across models with different sizes and capabilities, enabling challenge-oriented and fine-grained assessment. EcomEval also spans seven languages-including five low-resource Southeast Asian languages-offering a multilingual perspective absent from prior work.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "171",
        "title": "Why Did Apple Fall To The Ground: Evaluating Curiosity In Large Language Model",
        "author": [
            "Haoyu Wang",
            "Sihang Jiang",
            "Yuyan Chen",
            "Yitong Wang",
            "Yanghua Xiao"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20635",
        "abstract": "Curiosity serves as a pivotal conduit for human beings to discover and learn new knowledge. Recent advancements of large language models (LLMs) in natural language processing have sparked discussions regarding whether these models possess capability of curiosity-driven learning akin to humans. In this paper, starting from the human curiosity assessment questionnaire Five-Dimensional Curiosity scale Revised (5DCR), we design a comprehensive evaluation framework that covers dimensions such as Information Seeking, Thrill Seeking, and Social Curiosity to assess the extent of curiosity exhibited by LLMs. The results demonstrate that LLMs exhibit a stronger thirst for knowledge than humans but still tend to make conservative choices when faced with uncertain environments. We further investigated the relationship between curiosity and thinking of LLMs, confirming that curious behaviors can enhance the model's reasoning and active learning abilities. These findings suggest that LLMs have the potential to exhibit curiosity similar to that of humans, providing experimental support for the future development of learning capabilities and innovative research in LLMs.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "172",
        "title": "Large Multimodal Models-Empowered Task-Oriented Autonomous Communications: Design Methodology and Implementation Challenges",
        "author": [
            "Hyun Jong Yang",
            "Hyunsoo Kim",
            "Hyeonho Noh",
            "Seungnyun Kim",
            "Byonghyo Shim"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20637",
        "abstract": "Large language models (LLMs) and large multimodal models (LMMs) have achieved unprecedented breakthrough, showcasing remarkable capabilities in natural language understanding, generation, and complex reasoning. This transformative potential has positioned them as key enablers for 6G autonomous communications among machines, vehicles, and humanoids. In this article, we provide an overview of task-oriented autonomous communications with LLMs/LMMs, focusing on multimodal sensing integration, adaptive reconfiguration, and prompt/fine-tuning strategies for wireless tasks. We demonstrate the framework through three case studies: LMM-based traffic control, LLM-based robot scheduling, and LMM-based environment-aware channel estimation. From experimental results, we show that the proposed LLM/LMM-aided autonomous systems significantly outperform conventional and discriminative deep learning (DL) model-based techniques, maintaining robustness under dynamic objectives, varying input parameters, and heterogeneous multimodal conditions where conventional static optimization degrades.",
        "tags": [
            "LLM",
            "Robotics"
        ]
    },
    {
        "id": "173",
        "title": "Safe Decentralized Density Control of Multi-Robot Systems using PDE-Constrained Optimization with State Constraints",
        "author": [
            "Longchen Niu",
            "Gennaro Notomista"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20643",
        "abstract": "In this paper, we introduce a decentralized optimization-based density controller designed to enforce set invariance constraints in multi-robot systems. By designing a decentralized control barrier function, we derived sufficient conditions under which local safety constraints guarantee global safety. We account for localization and motion noise explicitly by modeling robots as spatial probability density functions governed by the Fokker-Planck equation. Compared to traditional centralized approaches, our controller requires less computational and communication power, making it more suitable for deployment in situations where perfect communication and localization are impractical. The controller is validated through simulations and experiments with four quadcopters.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "174",
        "title": "UltraHR-100K: Enhancing UHR Image Synthesis with A Large-Scale High-Quality Dataset",
        "author": [
            "Chen Zhao",
            "En Ci",
            "Yunzhe Xu",
            "Tiehan Fan",
            "Shanyan Guan",
            "Yanhao Ge",
            "Jian Yang",
            "Ying Tai"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20661",
        "abstract": "Ultra-high-resolution (UHR) text-to-image (T2I) generation has seen notable progress. However, two key challenges remain : 1) the absence of a large-scale high-quality UHR T2I dataset, and (2) the neglect of tailored training strategies for fine-grained detail synthesis in UHR scenarios. To tackle the first challenge, we introduce \\textbf{UltraHR-100K}, a high-quality dataset of 100K UHR images with rich captions, offering diverse content and strong visual fidelity. Each image exceeds 3K resolution and is rigorously curated based on detail richness, content complexity, and aesthetic quality. To tackle the second challenge, we propose a frequency-aware post-training method that enhances fine-detail generation in T2I diffusion models. Specifically, we design (i) \\textit{Detail-Oriented Timestep Sampling (DOTS)} to focus learning on detail-critical denoising steps, and (ii) \\textit{Soft-Weighting Frequency Regularization (SWFR)}, which leverages Discrete Fourier Transform (DFT) to softly constrain frequency components, encouraging high-frequency detail preservation. Extensive experiments on our proposed UltraHR-eval4K benchmarks demonstrate that our approach significantly improves the fine-grained detail quality and overall fidelity of UHR image generation. The code is available at \\href{https://github.com/NJU-PCALab/UltraHR-100k}{here}.",
        "tags": [
            "Diffusion",
            "Text-to-Image"
        ]
    },
    {
        "id": "175",
        "title": "The Shape of Reasoning: Topological Analysis of Reasoning Traces in Large Language Models",
        "author": [
            "Xue Wen Tan",
            "Nathaniel Tan",
            "Galen Lee",
            "Stanley Kok"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20665",
        "abstract": "Evaluating the quality of reasoning traces from large language models remains understudied, labor-intensive, and unreliable: current practice relies on expert rubrics, manual annotation, and slow pairwise judgments. Automated efforts are dominated by graph-based proxies that quantify structural connectivity but do not clarify what constitutes high-quality reasoning; such abstractions can be overly simplistic for inherently complex processes. We introduce a topological data analysis (TDA)-based evaluation framework that captures the geometry of reasoning traces and enables label-efficient, automated assessment. In our empirical study, topological features yield substantially higher predictive power for assessing reasoning quality than standard graph metrics, suggesting that effective reasoning is better captured by higher-dimensional geometric structures rather than purely relational graphs. We further show that a compact, stable set of topological features reliably indicates trace quality, offering a practical signal for future reinforcement learning algorithms.",
        "tags": [
            "LLM",
            "RL"
        ]
    },
    {
        "id": "176",
        "title": "Bayesian Jammer Localization with a Hybrid CNN and Path-Loss Mixture of Experts",
        "author": [
            "Mariona Jaramillo-Civill",
            "Luis GonzÃ¡lez-GudiÃ±o",
            "Tales Imbiriba",
            "Pau Closas"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20666",
        "abstract": "Global Navigation Satellite System (GNSS) signals are vulnerable to jamming, particularly in urban areas where multipath and shadowing distort received power. Previous data-driven approaches achieved reasonable localization but poorly reconstructed the received signal strength (RSS) field due to limited spatial context. We propose a hybrid Bayesian mixture-of-experts framework that fuses a physical path-loss (PL) model and a convolutional neural network (CNN) through log-linear pooling. The PL expert ensures physical consistency, while the CNN leverages building-height maps to capture urban propagation effects. Bayesian inference with Laplace approximation provides posterior uncertainty over both the jammer position and RSS field. Experiments on urban ray-tracing data show that localization accuracy improves and uncertainty decreases with more training points, while uncertainty concentrates near the jammer and along urban canyons where propagation is most sensitive.",
        "tags": [
            "MoE"
        ]
    },
    {
        "id": "177",
        "title": "Efficient Multi-bit Quantization Network Training via Weight Bias Correction and Bit-wise Coreset Sampling",
        "author": [
            "Jinhee Kim",
            "Jae Jun An",
            "Kang Eun Jeon",
            "Jong Hwan Ko"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20673",
        "abstract": "Multi-bit quantization networks enable flexible deployment of deep neural networks by supporting multiple precision levels within a single model. However, existing approaches suffer from significant training overhead as full-dataset updates are repeated for each supported bit-width, resulting in a cost that scales linearly with the number of precisions. Additionally, extra fine-tuning stages are often required to support additional or intermediate precision options, further compounding the overall training burden. To address this issue, we propose two techniques that greatly reduce the training overhead without compromising model utility: (i) Weight bias correction enables shared batch normalization and eliminates the need for fine-tuning by neutralizing quantization-induced bias across bit-widths and aligning activation distributions; and (ii) Bit-wise coreset sampling strategy allows each child model to train on a compact, informative subset selected via gradient-based importance scores by exploiting the implicit knowledge transfer phenomenon. Experiments on CIFAR-10/100, TinyImageNet, and ImageNet-1K with both ResNet and ViT architectures demonstrate that our method achieves competitive or superior accuracy while reducing training time up to 7.88x. Our code is released at https://github.com/a2jinhee/EMQNet_jk.",
        "tags": [
            "ViT"
        ]
    },
    {
        "id": "178",
        "title": "Analyticup E-commerce Product Search Competition Technical Report from Team Tredence_AICOE",
        "author": [
            "Rakshith R",
            "Shubham Sharma",
            "Mohammed Sameer Khan",
            "Ankush Chopra"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20674",
        "abstract": "This study presents the multilingual e-commerce search system developed by the Tredence_AICOE team. The competition features two multilingual relevance tasks: Query-Category (QC) Relevance, which evaluates how well a user's search query aligns with a product category, and Query-Item (QI) Relevance, which measures the match between a multilingual search query and an individual product listing. To ensure full language coverage, we performed data augmentation by translating existing datasets into languages missing from the development set, enabling training across all target languages. We fine-tuned Gemma-3 12B and Qwen-2.5 14B model for both tasks using multiple strategies. The Gemma-3 12B (4-bit) model achieved the best QC performance using original and translated data, and the best QI performance using original, translated, and minority class data creation. These approaches secured 4th place on the final leaderboard, with an average F1-score of 0.8857 on the private test set.",
        "tags": [
            "Qwen"
        ]
    },
    {
        "id": "179",
        "title": "Downsizing Diffusion Models for Cardinality Estimation",
        "author": [
            "Xinhe Mu",
            "Zhaoqi Zhou",
            "Zaijiu Shang",
            "Chuan Zhou",
            "Gang Fu",
            "Guiying Yan",
            "Guoliang Li",
            "Zhiming Ma"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20681",
        "abstract": "Inspired by the performance of score-based diffusion models in estimating complex text, video, and image distributions with thousands of dimensions, we introduce Accelerated Diffusion Cardest (ADC), the first joint distribution cardinality estimator based on a downsized diffusion model.\nTo calculate the pointwise density value of data distributions, ADC's density estimator uses a formula that evaluates log-likelihood by integrating the score function, a gradient mapping which ADC has learned to efficiently approximate using its lightweight score estimator. To answer ranged queries, ADC's selectivity estimator first predicts their selectivity using a Gaussian Mixture Model (GMM), then uses importance sampling Monte Carlo to correct its predictions with more accurate pointwise density values calculated by the density estimator. ADC+ further trains a decision tree to identify the high-volume, high-selectivity queries that the GMM alone can predict very accurately, in which case it skips the correction phase to prevent Monte Carlo from adding more variance. Doing so lowers median Q-error and cuts per-query latency by 25 percent, making ADC+ usually twice as fast as Naru, arguably the state-of-the-art joint distribution cardinality estimator.\nNumerical experiments using well-established benchmarks show that on all real-world datasets tested, ADC+ is capable of rivaling Naru and outperforming MSCN, DeepDB, LW-Tree, and LW-NN using around 66 percent their storage space, being at least 3 times as accurate as MSCN on 95th and 99th percentile error. Furthermore, on a synthetic dataset where attributes exhibit complex, multilateral correlations, ADC and ADC+ are considerably robust while almost every other learned model suffered significant accuracy declines. In this case, ADC+ performs better than any other tested model, being 10 times as accurate as Naru on 95th and 99th percentile error.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "180",
        "title": "Neural Diversity Regularizes Hallucinations in Small Models",
        "author": [
            "Kushal Chakrabarti",
            "Nirmal Balachundhar"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20690",
        "abstract": "Language models continue to hallucinate despite increases in parameters, compute, and data. We propose neural diversity -- decorrelated parallel representations -- as a principled mechanism that reduces hallucination rates at fixed parameter and data budgets. Inspired by portfolio theory, where uncorrelated assets reduce risk by $\\sqrt{P}$, we prove hallucination probability is bounded by representational correlation: $P(H) \\leq f(\\sigma^2((1-\\rho(P))/P + \\rho(P)), \\mu^2)$, which predicts that language models need an optimal amount of neurodiversity. To validate this, we introduce ND-LoRA (Neural Diversity Low-Rank Adaptation), combining parallel LoRA adapters with Barlow Twins regularization, and demonstrate that ND-LoRA reduces hallucinations by up to 25.6% (and 14.6% on average) without degrading general accuracy. Ablations show LoRA adapters and regularization act synergistically, causal interventions prove neurodiversity as the mediating factor and correlational analyses indicate scale: a 0.1% neural correlation increase is associated with a 3.8% hallucination increase. Finally, task-dependent optimality emerges: different tasks require different amounts of optimal neurodiversity. Together, our results highlight neural diversity as a third axis of scaling -- orthogonal to parameters and data -- to improve the reliability of language models at fixed budgets.",
        "tags": [
            "LoRA"
        ]
    },
    {
        "id": "181",
        "title": "Plan Then Retrieve: Reinforcement Learning-Guided Complex Reasoning over Knowledge Graphs",
        "author": [
            "Yanlin Song",
            "Ben Liu",
            "VÃ­ctor GutiÃ©rrez-Basulto",
            "Zhiwei Hu",
            "Qianqian Xie",
            "Min Peng",
            "Sophia Ananiadou",
            "Jeff Z. Pan"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20691",
        "abstract": "Knowledge Graph Question Answering aims to answer natural language questions by reasoning over structured knowledge graphs. While large language models have advanced KGQA through their strong reasoning capabilities, existing methods continue to struggle to fully exploit both the rich knowledge encoded in KGs and the reasoning capabilities of LLMs, particularly in complex scenarios. They often assume complete KG coverage and lack mechanisms to judge when external information is needed, and their reasoning remains locally myopic, failing to maintain coherent multi-step planning, leading to reasoning failures even when relevant knowledge exists. We propose Graph-RFT, a novel two-stage reinforcement fine-tuning KGQA framework with a 'plan-KGsearch-and-Websearch-during-think' paradigm, that enables LLMs to perform autonomous planning and adaptive retrieval scheduling across KG and web sources under incomplete knowledge conditions. Graph-RFT introduces a chain-of-thought fine-tuning method with a customized plan-retrieval dataset activates structured reasoning and resolves the GRPO cold-start problem. It then introduces a novel plan-retrieval guided reinforcement learning process integrates explicit planning and retrieval actions with a multi-reward design, enabling coverage-aware retrieval scheduling. It employs a Cartesian-inspired planning module to decompose complex questions into ordered subquestions, and logical expression to guide tool invocation for globally consistent multi-step reasoning. This reasoning retrieval process is optimized with a multi-reward combining outcome and retrieval specific signals, enabling the model to learn when and how to combine KG and web retrieval effectively.",
        "tags": [
            "CoT",
            "GRPO",
            "LLM",
            "RL"
        ]
    },
    {
        "id": "182",
        "title": "Exploring Large Language Models for Access Control Policy Synthesis and Summarization",
        "author": [
            "Adarsh Vatsa",
            "Bethel Hall",
            "William Eiers"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20692",
        "abstract": "Cloud computing is ubiquitous, with a growing number of services being hosted on the cloud every day. Typical cloud compute systems allow administrators to write policies implementing access control rules which specify how access to private data is governed. These policies must be manually written, and due to their complexity can often be error prone. Moreover, existing policies often implement complex access control specifications and thus can be difficult to precisely analyze in determining their behavior works exactly as intended. Recently, Large Language Models (LLMs) have shown great success in automated code synthesis and summarization. Given this success, they could potentially be used for automatically generating access control policies or aid in understanding existing policies. In this paper, we explore the effectiveness of LLMs for access control policy synthesis and summarization. Specifically, we first investigate diverse LLMs for access control policy synthesis, finding that: although LLMs can effectively generate syntactically correct policies, they have permissiveness issues, generating policies equivalent to the given specification 45.8% of the time for non-reasoning LLMs, and 93.7% of the time for reasoning LLMs. We then investigate how LLMs can be used to analyze policies by introducing a novel semantic-based request summarization approach which leverages LLMs to generate a precise characterization of the requests allowed by a policy. Our results show that while there are significant hurdles in leveraging LLMs for automated policy generation, LLMs show promising results when combined with symbolic approaches in analyzing existing policies.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "183",
        "title": "Diagnosing Visual Reasoning: Challenges, Insights, and a Path Forward",
        "author": [
            "Jing Bi",
            "Guangyu Sun",
            "Ali Vosoughi",
            "Chen Chen",
            "Chenliang Xu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20696",
        "abstract": "Multimodal large language models (MLLMs) that integrate visual and textual reasoning leverage chain-of-thought (CoT) prompting to tackle complex visual tasks, yet continue to exhibit visual hallucinations and an over-reliance on textual priors. We present a systematic diagnosis of state-of-the-art vision-language models using a three-stage evaluation framework, uncovering key failure modes. To address these, we propose an agent-based architecture that combines LLM reasoning with lightweight visual modules, enabling fine-grained analysis and iterative refinement of reasoning chains. Our results highlight future visual reasoning models should focus on integrating a broader set of specialized tools for analyzing visual content. Our system achieves significant gains (+10.3 on MMMU, +6.0 on MathVista over a 7B baseline), matching or surpassing much larger models. We will release our framework and evaluation suite to facilitate future research.",
        "tags": [
            "CoT",
            "LLM",
            "VLM"
        ]
    },
    {
        "id": "184",
        "title": "Trust, But Verify: An Empirical Evaluation of AI-Generated Code for SDN Controllers",
        "author": [
            "Felipe Avencourt Soares",
            "Muriel F. Franco",
            "Eder J. Scheid",
            "Lisandro Z. Granville"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20703",
        "abstract": "Generative Artificial Intelligence (AI) tools have been used to generate human-like content across multiple domains (e.g., sound, image, text, and programming). However, their reliability in terms of correctness and functionality in novel contexts such as programmable networks remains unclear. Hence, this paper presents an empirical evaluation of the source code of a POX controller generated by different AI tools, namely ChatGPT, Copilot, DeepSeek, and http://BlackBox.ai. To evaluate such a code, three networking tasks of increasing complexity were defined and for each task, zero-shot and few-shot prompting techniques were input to the tools. Next, the output code was tested in emulated network topologies with Mininet and analyzed according to functionality, correctness, and the need for manual fixes. Results show that all evaluated models can produce functional controllers. However, ChatGPT and DeepSeek exhibited higher consistency and code quality, while Copilot and http://BlackBox.ai required more adjustments.",
        "tags": [
            "DeepSeek",
            "GPT"
        ]
    },
    {
        "id": "185",
        "title": "Real-Time Gait Adaptation for Quadrupeds using Model Predictive Control and Reinforcement Learning",
        "author": [
            "Ganga Nair B",
            "Prakrut Kotecha",
            "Shishir Kolathaya"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20706",
        "abstract": "Model-free reinforcement learning (RL) has enabled adaptable and agile quadruped locomotion; however, policies often converge to a single gait, leading to suboptimal performance. Traditionally, Model Predictive Control (MPC) has been extensively used to obtain task-specific optimal policies but lacks the ability to adapt to varying environments. To address these limitations, we propose an optimization framework for real-time gait adaptation in a continuous gait space, combining the Model Predictive Path Integral (MPPI) algorithm with a Dreamer module to produce adaptive and optimal policies for quadruped locomotion. At each time step, MPPI jointly optimizes the actions and gait variables using a learned Dreamer reward that promotes velocity tracking, energy efficiency, stability, and smooth transitions, while penalizing abrupt gait changes. A learned value function is incorporated as terminal reward, extending the formulation to an infinite-horizon planner. We evaluate our framework in simulation on the Unitree Go1, demonstrating an average reduction of up to 36.48\\% in energy consumption across varying target speeds, while maintaining accurate tracking and adaptive, task-appropriate gaits.",
        "tags": [
            "MPC",
            "RL"
        ]
    },
    {
        "id": "186",
        "title": "Mixing Importance with Diversity: Joint Optimization for KV Cache Compression in Large Vision-Language Models",
        "author": [
            "Xuyang Liu",
            "Xiyan Gui",
            "Yuchao Zhang",
            "Linfeng Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20707",
        "abstract": "Recent large vision-language models (LVLMs) demonstrate remarkable capabilities in processing extended multi-modal sequences, yet the resulting key-value (KV) cache expansion creates a critical memory bottleneck that fundamentally limits deployment scalability. While existing KV cache compression methods focus on retaining high-importance KV pairs to minimize storage, they often overlook the modality-specific semantic redundancy patterns that emerge distinctively in multi-modal KV caches. In this work, we first analyze how, beyond simple importance, the KV cache in LVLMs exhibits varying levels of redundancy across attention heads. We show that relying solely on importance can only cover a subset of the full KV cache information distribution, leading to potential loss of semantic coverage. To address this, we propose \\texttt{MixKV}, a novel method that mixes importance with diversity for optimized KV cache compression in LVLMs. \\texttt{MixKV} adapts to head-wise semantic redundancy, selectively balancing diversity and importance when compressing KV pairs. Extensive experiments demonstrate that \\texttt{MixKV} consistently enhances existing methods across multiple LVLMs. Under extreme compression (budget=64), \\texttt{MixKV} improves baseline methods by an average of \\textbf{5.1\\%} across five multi-modal understanding benchmarks and achieves remarkable gains of \\textbf{8.0\\%} and \\textbf{9.0\\%} for SnapKV and AdaKV on GUI grounding tasks, all while maintaining comparable inference efficiency. Furthermore, \\texttt{MixKV} extends seamlessly to LLMs with comparable performance gains. Our code is available at \\href{https://github.com/xuyang-liu16/MixKV}{\\textcolor{citeblue}{https://github.com/xuyang-liu16/MixKV}}.",
        "tags": [
            "LLM",
            "VLM"
        ]
    },
    {
        "id": "187",
        "title": "Separating the what and how of compositional computation to enable reuse and continual learning",
        "author": [
            "Haozhe Shan",
            "Sun Minni",
            "Lea Duncker"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20709",
        "abstract": "The ability to continually learn, retain and deploy skills to accomplish goals is a key feature of intelligent and efficient behavior. However, the neural mechanisms facilitating the continual learning and flexible (re-)composition of skills remain elusive. Here, we study continual learning and the compositional reuse of learned computations in recurrent neural network (RNN) models using a novel two-system approach: one system that infers what computation to perform, and one that implements how to perform it. We focus on a set of compositional cognitive tasks commonly studied in neuroscience. To construct the what system, we first show that a large family of tasks can be systematically described by a probabilistic generative model, where compositionality stems from a shared underlying vocabulary of discrete task epochs. The shared epoch structure makes these tasks inherently compositional. We first show that this compositionality can be systematically described by a probabilistic generative model. Furthermore, We develop an unsupervised online learning approach that can learn this model on a single-trial basis, building its vocabulary incrementally as it is exposed to new tasks, and inferring the latent epoch structure as a time-varying computational context within a trial. We implement the how system as an RNN whose low-rank components are composed according to the context inferred by the what system. Contextual inference facilitates the creation, learning, and reuse of low-rank RNN components as new tasks are introduced sequentially, enabling continual learning without catastrophic forgetting. Using an example task set, we demonstrate the efficacy and competitive performance of this two-system learning framework, its potential for forward and backward transfer, as well as fast compositional generalization to unseen tasks.",
        "tags": [
            "RNN"
        ]
    },
    {
        "id": "188",
        "title": "User Perceptions of Privacy and Helpfulness in LLM Responses to Privacy-Sensitive Scenarios",
        "author": [
            "Xiaoyuan Wu",
            "Roshni Kaushik",
            "Wenkai Li",
            "Lujo Bauer",
            "Koichi Onoue"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20721",
        "abstract": "Large language models (LLMs) have seen rapid adoption for tasks such as drafting emails, summarizing meetings, and answering health questions. In such uses, users may need to share private information (e.g., health records, contact details). To evaluate LLMs' ability to identify and redact such private information, prior work developed benchmarks (e.g., ConfAIde, PrivacyLens) with real-life scenarios. Using these benchmarks, researchers have found that LLMs sometimes fail to keep secrets private when responding to complex tasks (e.g., leaking employee salaries in meeting summaries). However, these evaluations rely on LLMs (proxy LLMs) to gauge compliance with privacy norms, overlooking real users' perceptions. Moreover, prior work primarily focused on the privacy-preservation quality of responses, without investigating nuanced differences in helpfulness. To understand how users perceive the privacy-preservation quality and helpfulness of LLM responses to privacy-sensitive scenarios, we conducted a user study with 94 participants using 90 scenarios from PrivacyLens. We found that, when evaluating identical responses to the same scenario, users showed low agreement with each other on the privacy-preservation quality and helpfulness of the LLM response. Further, we found high agreement among five proxy LLMs, while each individual LLM had low correlation with users' evaluations. These results indicate that the privacy and helpfulness of LLM responses are often specific to individuals, and proxy LLMs are poor estimates of how real users would perceive these responses in privacy-sensitive scenarios. Our results suggest the need to conduct user-centered studies on measuring LLMs' ability to help users while preserving privacy. Additionally, future research could investigate ways to improve the alignment between proxy LLMs and users for better estimation of users' perceived privacy and utility.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "189",
        "title": "No-Regret Thompson Sampling for Finite-Horizon Markov Decision Processes with Gaussian Processes",
        "author": [
            "Jasmine Bayrooti",
            "Sattar Vakili",
            "Amanda Prorok",
            "Carl Henrik Ek"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20725",
        "abstract": "Thompson sampling (TS) is a powerful and widely used strategy for sequential decision-making, with applications ranging from Bayesian optimization to reinforcement learning (RL). Despite its success, the theoretical foundations of TS remain limited, particularly in settings with complex temporal structure such as RL. We address this gap by establishing no-regret guarantees for TS using models with Gaussian marginal distributions. Specifically, we consider TS in episodic RL with joint Gaussian process (GP) priors over rewards and transitions. We prove a regret bound of $\\mathcal{\\tilde{O}}(\\sqrt{KH\\Gamma(KH)})$ over $K$ episodes of horizon $H$, where $\\Gamma(\\cdot)$ captures the complexity of the GP model. Our analysis addresses several challenges, including the non-Gaussian nature of value functions and the recursive structure of Bellman updates, and extends classical tools such as the elliptical potential lemma to multi-output settings. This work advances the understanding of TS in RL and highlights how structural assumptions and model uncertainty shape its performance in finite-horizon Markov Decision Processes.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "190",
        "title": "AutoScape: Geometry-Consistent Long-Horizon Scene Generation",
        "author": [
            "Jiacheng Chen",
            "Ziyu Jiang",
            "Mingfu Liang",
            "Bingbing Zhuang",
            "Jong-Chyi Su",
            "Sparsh Garg",
            "Ying Wu",
            "Manmohan Chandraker"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20726",
        "abstract": "This paper proposes AutoScape, a long-horizon driving scene generation framework. At its core is a novel RGB-D diffusion model that iteratively generates sparse, geometrically consistent keyframes, serving as reliable anchors for the scene's appearance and geometry. To maintain long-range geometric consistency, the model 1) jointly handles image and depth in a shared latent space, 2) explicitly conditions on the existing scene geometry (i.e., rendered point clouds) from previously generated keyframes, and 3) steers the sampling process with a warp-consistent guidance. Given high-quality RGB-D keyframes, a video diffusion model then interpolates between them to produce dense and coherent video frames. AutoScape generates realistic and geometrically consistent driving videos of over 20 seconds, improving the long-horizon FID and FVD scores over the prior state-of-the-art by 48.6\\% and 43.0\\%, respectively.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "191",
        "title": "Automated Extraction of Fluoropyrimidine Treatment and Treatment-Related Toxicities from Clinical Notes Using Natural Language Processing",
        "author": [
            "Xizhi Wu",
            "Madeline S. Kreider",
            "Philip E. Empey",
            "Chenyu Li",
            "Yanshan Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20727",
        "abstract": "Objective: Fluoropyrimidines are widely prescribed for colorectal and breast cancers, but are associated with toxicities such as hand-foot syndrome and cardiotoxicity. Since toxicity documentation is often embedded in clinical notes, we aimed to develop and evaluate natural language processing (NLP) methods to extract treatment and toxicity information.\nMaterials and Methods: We constructed a gold-standard dataset of 236 clinical notes from 204,165 adult oncology patients. Domain experts annotated categories related to treatment regimens and toxicities. We developed rule-based, machine learning-based (Random Forest, Support Vector Machine [SVM], Logistic Regression [LR]), deep learning-based (BERT, ClinicalBERT), and large language models (LLM)-based NLP approaches (zero-shot and error-analysis prompting). Models used an 80:20 train-test split.\nResults: Sufficient data existed to train and evaluate 5 annotated categories. Error-analysis prompting achieved optimal precision, recall, and F1 scores (F1=1.000) for treatment and toxicities extraction, whereas zero-shot prompting reached F1=1.000 for treatment and F1=0.876 for toxicities http://extraction.LR and SVM ranked second for toxicities (F1=0.937). Deep learning underperformed, with BERT (F1=0.873 treatment; F1= 0.839 toxicities) and ClinicalBERT (F1=0.873 treatment; F1 = 0.886 toxicities). Rule-based methods served as our baseline with F1 scores of 0.857 in treatment and 0.858 in toxicities.\nDiscussion: LMM-based approaches outperformed all others, followed by machine learning methods. Machine and deep learning approaches were limited by small training data and showed limited generalizability, particularly for rare categories.\nConclusion: LLM-based NLP most effectively extracted fluoropyrimidine treatment and toxicity information from clinical notes, and has strong potential to support oncology research and pharmacovigilance.",
        "tags": [
            "BERT",
            "LLM"
        ]
    },
    {
        "id": "192",
        "title": "Thought Communication in Multiagent Collaboration",
        "author": [
            "Yujia Zheng",
            "Zhuokai Zhao",
            "Zijian Li",
            "Yaqi Xie",
            "Mingze Gao",
            "Lizhu Zhang",
            "Kun Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20733",
        "abstract": "Natural language has long enabled human cooperation, but its lossy, ambiguous, and indirect nature limits the potential of collective intelligence. While machines are not subject to these constraints, most LLM-based multi-agent systems still rely solely on natural language, exchanging tokens or their embeddings. To go beyond language, we introduce a new paradigm, thought communication, which enables agents to interact directly mind-to-mind, akin to telepathy. To uncover these latent thoughts in a principled way, we formalize the process as a general latent variable model, where agent states are generated by an unknown function of underlying thoughts. We prove that, in a nonparametric setting without auxiliary information, both shared and private latent thoughts between any pair of agents can be identified. Moreover, the global structure of thought sharing, including which agents share which thoughts and how these relationships are structured, can also be recovered with theoretical guarantees. Guided by the established theory, we develop a framework that extracts latent thoughts from all agents prior to communication and assigns each agent the relevant thoughts, along with their sharing patterns. This paradigm naturally extends beyond LLMs to all modalities, as most observational data arise from hidden generative processes. Experiments on both synthetic and real-world benchmarks validate the theory and demonstrate the collaborative advantages of thought communication. We hope this work illuminates the potential of leveraging the hidden world, as many challenges remain unsolvable through surface-level observation alone, regardless of compute or data scale.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "193",
        "title": "Learning to Triage Taint Flows Reported by Dynamic Program Analysis in Node.js Packages",
        "author": [
            "Ronghao Ni",
            "Aidan Z.H. Yang",
            "Min-Chien Hsu",
            "Nuno Sabino",
            "Limin Jia",
            "Ruben Martins",
            "Darion Cassel",
            "Kevin Cheang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20739",
        "abstract": "Program analysis tools often produce large volumes of candidate vulnerability reports that require costly manual review, creating a practical challenge: how can security analysts prioritize the reports most likely to be true vulnerabilities?\nThis paper investigates whether machine learning can be applied to prioritizing vulnerabilities reported by program analysis tools. We focus on http://Node.js packages and collect a benchmark of 1,883 http://Node.js packages, each containing one reported ACE or ACI vulnerability. We evaluate a variety of machine learning approaches, including classical models, graph neural networks (GNNs), large language models (LLMs), and hybrid models that combine GNN and LLMs, trained on data based on a dynamic program analysis tool's output. The top LLM achieves $F_{1} {=} 0.915$, while the best GNN and classical ML models reaching $F_{1} {=} 0.904$. At a less than 7% false-negative rate, the leading model eliminates 66.9% of benign packages from manual review, taking around 60 ms per package. If the best model is tuned to operate at a precision level of 0.8 (i.e., allowing 20% false positives amongst all warnings), our approach can detect 99.2% of exploitable taint flows while missing only 0.8%, demonstrating strong potential for real-world vulnerability triage.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "194",
        "title": "Empathic Prompting: Non-Verbal Context Integration for Multimodal LLM Conversations",
        "author": [
            "Lorenzo Stacchio",
            "Andrea Ubaldi",
            "Alessandro Galdelli",
            "Maurizio Mauri",
            "Emanuele Frontoni",
            "Andrea Gaggioli"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20743",
        "abstract": "We present Empathic Prompting, a novel framework for multimodal human-AI interaction that enriches Large Language Model (LLM) conversations with implicit non-verbal context. The system integrates a commercial facial expression recognition service to capture users' emotional cues and embeds them as contextual signals during prompting. Unlike traditional multimodal interfaces, empathic prompting requires no explicit user control; instead, it unobtrusively augments textual input with affective information for conversational and smoothness alignment. The architecture is modular and scalable, allowing integration of additional non-verbal modules. We describe the system design, implemented through a locally deployed DeepSeek instance, and report a preliminary service and usability evaluation (N=5). Results show consistent integration of non-verbal input into coherent LLM outputs, with participants highlighting conversational fluidity. Beyond this proof of concept, empathic prompting points to applications in chatbot-mediated communication, particularly in domains like healthcare or education, where users' emotional signals are critical yet often opaque in verbal exchanges.",
        "tags": [
            "DeepSeek",
            "LLM"
        ]
    },
    {
        "id": "195",
        "title": "DyPE: Dynamic Position Extrapolation for Ultra High Resolution Diffusion",
        "author": [
            "Noam Issachar",
            "Guy Yariv",
            "Sagie Benaim",
            "Yossi Adi",
            "Dani Lischinski",
            "Raanan Fattal"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20766",
        "abstract": "Diffusion Transformer models can generate images with remarkable fidelity and detail, yet training them at ultra-high resolutions remains extremely costly due to the self-attention mechanism's quadratic scaling with the number of image tokens. In this paper, we introduce Dynamic Position Extrapolation (DyPE), a novel, training-free method that enables pre-trained diffusion transformers to synthesize images at resolutions far beyond their training data, with no additional sampling cost. DyPE takes advantage of the spectral progression inherent to the diffusion process, where low-frequency structures converge early, while high-frequencies take more steps to resolve. Specifically, DyPE dynamically adjusts the model's positional encoding at each diffusion step, matching their frequency spectrum with the current stage of the generative process. This approach allows us to generate images at resolutions that exceed the training resolution dramatically, e.g., 16 million pixels using FLUX. On multiple benchmarks, DyPE consistently improves performance and achieves state-of-the-art fidelity in ultra-high-resolution image generation, with gains becoming even more pronounced at higher resolutions. Project page is available at https://noamissachar.github.io/DyPE/.",
        "tags": [
            "DiT",
            "Diffusion",
            "FLUX",
            "Transformer"
        ]
    },
    {
        "id": "196",
        "title": "RAGRank: Using PageRank to Counter Poisoning in CTI LLM Pipelines",
        "author": [
            "Austin Jia",
            "Avaneesh Ramesh",
            "Zain Shamsi",
            "Daniel Zhang",
            "Alex Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20768",
        "abstract": "Retrieval-Augmented Generation (RAG) has emerged as the dominant architectural pattern to operationalize Large Language Model (LLM) usage in Cyber Threat Intelligence (CTI) systems. However, this design is susceptible to poisoning attacks, and previously proposed defenses can fail for CTI contexts as cyber threat information is often completely new for emerging attacks, and sophisticated threat actors can mimic legitimate formats, terminology, and stylistic conventions. To address this issue, we propose that the robustness of modern RAG defenses can be accelerated by applying source credibility algorithms on corpora, using PageRank as an example. In our experiments, we demonstrate quantitatively that our algorithm applies a lower authority score to malicious documents while promoting trusted content, using the standardized MS MARCO dataset. We also demonstrate proof-of-concept performance of our algorithm on CTI documents and feeds.",
        "tags": [
            "LLM",
            "RAG"
        ]
    },
    {
        "id": "197",
        "title": "AlphaFlow: Understanding and Improving MeanFlow Models",
        "author": [
            "Huijie Zhang",
            "Aliaksandr Siarohin",
            "Willi Menapace",
            "Michael Vasilkovsky",
            "Sergey Tulyakov",
            "Qing Qu",
            "Ivan Skorokhodov"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20771",
        "abstract": "MeanFlow has recently emerged as a powerful framework for few-step generative modeling trained from scratch, but its success is not yet fully understood. In this work, we show that the MeanFlow objective naturally decomposes into two parts: trajectory flow matching and trajectory consistency. Through gradient analysis, we find that these terms are strongly negatively correlated, causing optimization conflict and slow convergence. Motivated by these insights, we introduce $\\alpha$-Flow, a broad family of objectives that unifies trajectory flow matching, Shortcut Model, and MeanFlow under one formulation. By adopting a curriculum strategy that smoothly anneals from trajectory flow matching to MeanFlow, $\\alpha$-Flow disentangles the conflicting objectives, and achieves better convergence. When trained from scratch on class-conditional ImageNet-1K 256x256 with vanilla DiT backbones, $\\alpha$-Flow consistently outperforms MeanFlow across scales and settings. Our largest $\\alpha$-Flow-XL/2+ model achieves new state-of-the-art results using vanilla DiT backbones, with FID scores of 2.58 (1-NFE) and 2.15 (2-NFE).",
        "tags": [
            "DiT",
            "Flow Matching"
        ]
    },
    {
        "id": "198",
        "title": "CUPID: Pose-Grounded Generative 3D Reconstruction from a Single Image",
        "author": [
            "Binbin Huang",
            "Haobin Duan",
            "Yiqun Zhao",
            "Zibo Zhao",
            "Yi Ma",
            "Shenghua Gao"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20776",
        "abstract": "This work proposes a new generation-based 3D reconstruction method, named Cupid, that accurately infers the camera pose, 3D shape, and texture of an object from a single 2D image. Cupid casts 3D reconstruction as a conditional sampling process from a learned distribution of 3D objects, and it jointly generates voxels and pixel-voxel correspondences, enabling robust pose and shape estimation under a unified generative framework. By representing both input camera poses and 3D shape as a distribution in a shared 3D latent space, Cupid adopts a two-stage flow matching pipeline: (1) a coarse stage that produces initial 3D geometry with associated 2D projections for pose recovery; and (2) a refinement stage that integrates pose-aligned image features to enhance structural fidelity and appearance details. Extensive experiments demonstrate Cupid outperforms leading 3D reconstruction methods with an over 3 dB PSNR gain and an over 10% Chamfer Distance reduction, while matching monocular estimators on pose accuracy and delivering superior visual fidelity over baseline 3D generative models. For an immersive view of the 3D results generated by Cupid, please visit http://cupid3d.github.io.",
        "tags": [
            "3D",
            "Flow Matching"
        ]
    },
    {
        "id": "199",
        "title": "Are Large Reasoning Models Good Translation Evaluators? Analysis and Performance Boost",
        "author": [
            "Runzhe Zhan",
            "Zhihong Huang",
            "Xinyi Yang",
            "Lidia S. Chao",
            "Min Yang",
            "Derek F. Wong"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20780",
        "abstract": "Recent advancements in large reasoning models (LRMs) have introduced an intermediate \"thinking\" process prior to generating final answers, improving their reasoning capabilities on complex downstream tasks. However, the potential of LRMs as evaluators for machine translation (MT) quality remains underexplored. We provides the first systematic analysis of LRM-as-a-judge in MT evaluation. We identify key challenges, revealing LRMs require tailored evaluation materials, tend to \"overthink\" simpler instances and have issues with scoring mechanisms leading to overestimation. To address these, we propose to calibrate LRM thinking by training them on synthetic, human-like thinking trajectories. Our experiments on WMT24 Metrics benchmarks demonstrate that this approach largely reduces thinking budgets by ~35x while concurrently improving evaluation performance across different LRM scales from 7B to 32B (e.g., R1-Distill-Qwen-7B achieves a +8.7 correlation point improvement). These findings highlight the potential of efficiently calibrated LRMs to advance fine-grained automatic MT evaluation.",
        "tags": [
            "Qwen"
        ]
    },
    {
        "id": "200",
        "title": "A Use-Case Specific Dataset for Measuring Dimensions of Responsible Performance in LLM-generated Text",
        "author": [
            "Alicia Sagae",
            "Chia-Jung Lee",
            "Sandeep Avula",
            "Brandon Dang",
            "Vanessa Murdock"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20782",
        "abstract": "Current methods for evaluating large language models (LLMs) typically focus on high-level tasks such as text generation, without targeting a particular AI application. This approach is not sufficient for evaluating LLMs for Responsible AI dimensions like fairness, since protected attributes that are highly relevant in one application may be less relevant in another. In this work, we construct a dataset that is driven by a real-world application (generate a plain-text product description, given a list of product features), parameterized by fairness attributes intersected with gendered adjectives and product categories, yielding a rich set of labeled prompts. We show how to use the data to identify quality, veracity, safety, and fairness gaps in LLMs, contributing a proposal for LLM evaluation paired with a concrete resource for the research community.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "201",
        "title": "Out-of-distribution Tests Reveal Compositionality in Chess Transformers",
        "author": [
            "Anna MÃ©szÃ¡ros",
            "Patrik Reizinger",
            "Ferenc HuszÃ¡r"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20783",
        "abstract": "Chess is a canonical example of a task that requires rigorous reasoning and long-term planning. Modern decision Transformers - trained similarly to LLMs - are able to learn competent gameplay, but it is unclear to what extent they truly capture the rules of chess. To investigate this, we train a 270M parameter chess Transformer and test it on out-of-distribution scenarios, designed to reveal failures of systematic generalization. Our analysis shows that Transformers exhibit compositional generalization, as evidenced by strong rule extrapolation: they adhere to fundamental syntactic rules of the game by consistently choosing valid moves even in situations very different from the training data. Moreover, they also generate high-quality moves for OOD puzzles. In a more challenging test, we evaluate the models on variants including Chess960 (Fischer Random Chess) - a variant of chess where starting positions of pieces are randomized. We found that while the model exhibits basic strategy adaptation, they are inferior to symbolic AI algorithms that perform explicit search, but gap is smaller when playing against users on Lichess. Moreover, the training dynamics revealed that the model initially learns to move only its own pieces, suggesting an emergent compositional understanding of the game.",
        "tags": [
            "LLM",
            "Transformer"
        ]
    },
    {
        "id": "202",
        "title": "A Coherence-Based Measure of AGI",
        "author": [
            "Fares Fourati"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20784",
        "abstract": "Recent work by \\citet{hendrycks2025agidefinition} formalized \\textit{Artificial General Intelligence} (AGI) as the arithmetic mean of proficiencies across cognitive domains derived from the Cattell--Horn--Carroll (CHC) model of human cognition. While elegant, this definition assumes \\textit{compensability} -- that exceptional ability in some domains can offset failure in others. True general intelligence, however, should reflect \\textit{coherent sufficiency}: balanced competence across all essential domains. We propose a coherence-aware measure of AGI based on the integral of generalized means over a continuum of compensability exponents. This formulation spans arithmetic, geometric, and harmonic regimes, and the resulting \\textit{area under the curve} (AUC) quantifies robustness under varying compensability assumptions. Unlike the arithmetic mean, which rewards specialization, the AUC penalizes imbalance and captures inter-domain dependency. Applied to published CHC-based domain scores for GPT-4 and GPT-5, the coherence-adjusted AUC reveals that both systems remain far from general competence despite high arithmetic scores (e.g., GPT-5 at~24\\%). Integrating the generalized mean thus yields a principled, interpretable, and stricter foundation for measuring genuine progress toward AGI.",
        "tags": [
            "GPT"
        ]
    },
    {
        "id": "203",
        "title": "Simple Context Compression: Mean-Pooling and Multi-Ratio Training",
        "author": [
            "Yair Feldman",
            "Yoav Artzi"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20797",
        "abstract": "A common strategy to reduce the computational costs of using long contexts in retrieval-augmented generation (RAG) with large language models (LLMs) is soft context compression, where the input sequence is transformed into a shorter continuous representation. We develop a lightweight and simple mean-pooling approach that consistently outperforms the widely used compression-tokens architecture, and study training the same compressor to output multiple compression ratios. We conduct extensive experiments across in-domain and out-of-domain QA datasets, as well as across model families, scales, and compression ratios. Overall, our simple mean-pooling approach achieves the strongest performance, with a relatively small drop when training for multiple compression ratios. More broadly though, across architectures and training regimes the trade-offs are more nuanced, illustrating the complex landscape of compression methods.",
        "tags": [
            "LLM",
            "RAG"
        ]
    },
    {
        "id": "204",
        "title": "Compress to Impress: Efficient LLM Adaptation Using a Single Gradient Step on 100 Samples",
        "author": [
            "Shiva Sreeram",
            "Alaa Maalouf",
            "Pratyusha Sharma",
            "Daniela Rus"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20800",
        "abstract": "Recently, Sharma et al. suggested a method called Layer-SElective-Rank reduction (LASER) which demonstrated that pruning high-order components of carefully chosen LLM's weight matrices can boost downstream accuracy -- without any gradient-based fine-tuning. Yet LASER's exhaustive, per-matrix search (each requiring full-dataset forward passes) makes it impractical for rapid deployment. We demonstrate that this overhead can be removed and find that: (i) Only a small, carefully chosen subset of matrices needs to be inspected -- eliminating the layer-by-layer sweep, (ii) The gradient of each matrix's singular values pinpoints which matrices merit reduction, (iii) Increasing the factorization search space by allowing matrices rows to cluster around multiple subspaces and then decomposing each cluster separately further reduces overfitting on the original training data and further lifts accuracy by up to 24.6 percentage points, and finally, (iv) we discover that evaluating on just 100 samples rather than the full training data -- both for computing the indicative gradients and for measuring the final accuracy -- suffices to further reduce the search time; we explain that as adaptation to downstream tasks is dominated by prompting style, not dataset size. As a result, we show that combining these findings yields a fast and robust adaptation algorithm for downstream tasks. Overall, with a single gradient step on 100 examples and a quick scan of the top candidate layers and factorization techniques, we can adapt LLMs to new datasets -- entirely without fine-tuning.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "205",
        "title": "ARGenSeg: Image Segmentation with Autoregressive Image Generation Model",
        "author": [
            "Xiaolong Wang",
            "Lixiang Ru",
            "Ziyuan Huang",
            "Kaixiang Ji",
            "Dandan Zheng",
            "Jingdong Chen",
            "Jun Zhou"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20803",
        "abstract": "We propose a novel AutoRegressive Generation-based paradigm for image Segmentation (ARGenSeg), achieving multimodal understanding and pixel-level perception within a unified framework. Prior works integrating image segmentation into multimodal large language models (MLLMs) typically employ either boundary points representation or dedicated segmentation heads. These methods rely on discrete representations or semantic prompts fed into task-specific decoders, which limits the ability of the MLLM to capture fine-grained visual details. To address these challenges, we introduce a segmentation framework for MLLM based on image generation, which naturally produces dense masks for target objects. We leverage MLLM to output visual tokens and detokenize them into images using an universal VQ-VAE, making the segmentation fully dependent on the pixel-level understanding of the MLLM. To reduce inference latency, we employ a next-scale-prediction strategy to generate required visual tokens in parallel. Extensive experiments demonstrate that our method surpasses prior state-of-the-art approaches on multiple segmentation datasets with a remarkable boost in inference speed, while maintaining strong understanding capabilities.",
        "tags": [
            "LLM",
            "Segmentation",
            "VAE"
        ]
    },
    {
        "id": "206",
        "title": "Video Prediction of Dynamic Physical Simulations With Pixel-Space Spatiotemporal Transformers",
        "author": [
            "Dean L Slack",
            "G Thomas Hudson",
            "Thomas Winterbottom",
            "Noura Al Moubayed"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20807",
        "abstract": "Inspired by the performance and scalability of autoregressive large language models (LLMs), transformer-based models have seen recent success in the visual domain. This study investigates a transformer adaptation for video prediction with a simple end-to-end approach, comparing various spatiotemporal self-attention layouts. Focusing on causal modeling of physical simulations over time; a common shortcoming of existing video-generative approaches, we attempt to isolate spatiotemporal reasoning via physical object tracking metrics and unsupervised training on physical simulation datasets. We introduce a simple yet effective pure transformer model for autoregressive video prediction, utilizing continuous pixel-space representations for video prediction. Without the need for complex training strategies or latent feature-learning components, our approach significantly extends the time horizon for physically accurate predictions by up to 50% when compared with existing latent-space approaches, while maintaining comparable performance on common video quality metrics. In addition, we conduct interpretability experiments to identify network regions that encode information useful to perform accurate estimations of PDE simulation parameters via probing models, and find that this generalizes to the estimation of out-of-distribution simulation parameters. This work serves as a platform for further attention-based spatiotemporal modeling of videos via a simple, parameter efficient, and interpretable approach.",
        "tags": [
            "LLM",
            "Transformer"
        ]
    },
    {
        "id": "207",
        "title": "The Reality Gap in Robotics: Challenges, Solutions, and Best Practices",
        "author": [
            "Elie Aljalbout",
            "Jiaxu Xing",
            "Angel Romero",
            "Iretiayo Akinola",
            "Caelan Reed Garrett",
            "Eric Heiden",
            "Abhishek Gupta",
            "Tucker Hermans",
            "Yashraj Narang",
            "Dieter Fox",
            "Davide Scaramuzza",
            "Fabio Ramos"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20808",
        "abstract": "Machine learning has facilitated significant advancements across various robotics domains, including navigation, locomotion, and manipulation. Many such achievements have been driven by the extensive use of simulation as a critical tool for training and testing robotic systems prior to their deployment in real-world environments. However, simulations consist of abstractions and approximations that inevitably introduce discrepancies between simulated and real environments, known as the reality gap. These discrepancies significantly hinder the successful transfer of systems from simulation to the real world. Closing this gap remains one of the most pressing challenges in robotics. Recent advances in sim-to-real transfer have demonstrated promising results across various platforms, including locomotion, navigation, and manipulation. By leveraging techniques such as domain randomization, real-to-sim transfer, state and action abstractions, and sim-real co-training, many works have overcome the reality gap. However, challenges persist, and a deeper understanding of the reality gap's root causes and solutions is necessary. In this survey, we present a comprehensive overview of the sim-to-real landscape, highlighting the causes, solutions, and evaluation metrics for the reality gap and sim-to-real transfer.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "208",
        "title": "Real Deep Research for AI, Robotics and Beyond",
        "author": [
            "Xueyan Zou",
            "Jianglong Ye",
            "Hao Zhang",
            "Xiaoyu Xiang",
            "Mingyu Ding",
            "Zhaojing Yang",
            "Yong Jae Lee",
            "Zhuowen Tu",
            "Sifei Liu",
            "Xiaolong Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20809",
        "abstract": "With the rapid growth of research in AI and robotics now producing over 10,000 papers annually it has become increasingly difficult for researchers to stay up to date. Fast evolving trends, the rise of interdisciplinary work, and the need to explore domains beyond one's expertise all contribute to this challenge. To address these issues, we propose a generalizable pipeline capable of systematically analyzing any research area: identifying emerging trends, uncovering cross domain opportunities, and offering concrete starting points for new inquiry. In this work, we present Real Deep Research (RDR) a comprehensive framework applied to the domains of AI and robotics, with a particular focus on foundation models and robotics advancements. We also briefly extend our analysis to other areas of science. The main paper details the construction of the RDR pipeline, while the appendix provides extensive results across each analyzed topic. We hope this work sheds light for researchers working in the field of AI and beyond.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "209",
        "title": "On the Detectability of LLM-Generated Text: What Exactly Is LLM-Generated Text?",
        "author": [
            "Mingmeng Geng",
            "Thierry Poibeau"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20810",
        "abstract": "With the widespread use of large language models (LLMs), many researchers have turned their attention to detecting text generated by them. However, there is no consistent or precise definition of their target, namely \"LLM-generated text\". Differences in usage scenarios and the diversity of LLMs further increase the difficulty of detection. What is commonly regarded as the detecting target usually represents only a subset of the text that LLMs can potentially produce. Human edits to LLM outputs, together with the subtle influences that LLMs exert on their users, are blurring the line between LLM-generated and human-written text. Existing benchmarks and evaluation approaches do not adequately address the various conditions in real-world detector applications. Hence, the numerical results of detectors are often misunderstood, and their significance is diminishing. Therefore, detectors remain useful under specific conditions, but their results should be interpreted only as references rather than decisive indicators.",
        "tags": [
            "Detection",
            "LLM"
        ]
    },
    {
        "id": "210",
        "title": "Small Drafts, Big Verdict: Information-Intensive Visual Reasoning via Speculation",
        "author": [
            "Yuhan Liu",
            "Lianhui Qin",
            "Shengjie Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20812",
        "abstract": "Large Vision-Language Models (VLMs) have achieved remarkable progress in multimodal understanding, yet they struggle when reasoning over information-intensive images that densely interleave textual annotations with fine-grained graphical elements. The main challenges lie in precisely localizing critical cues in dense layouts and multi-hop reasoning to integrate dispersed evidence. We propose Speculative Verdict (SV), a training-free framework inspired by speculative decoding that combines multiple lightweight draft experts with a large verdict model. In the draft stage, small VLMs act as draft experts to generate reasoning paths that provide diverse localization candidates; in the verdict stage, a strong VLM synthesizes these paths to produce the final answer, minimizing computational cost while recovering correct answers. To further improve efficiency and accuracy, SV introduces a consensus expert selection mechanism that forwards only high-agreement reasoning paths to the verdict. Empirically, SV achieves consistent gains on challenging information-intensive and high-resolution visual question answering benchmarks, including InfographicVQA, ChartMuseum, ChartQAPro, and HR-Bench 4K. By synthesizing correct insights from multiple partially accurate reasoning paths, SV achieves both error correction and cost-efficiency compared to large proprietary models or training pipelines. Code is available at https://github.com/Tinaliu0123/speculative-verdict",
        "tags": [
            "VLM"
        ]
    },
    {
        "id": "211",
        "title": "GSWorld: Closed-Loop Photo-Realistic Simulation Suite for Robotic Manipulation",
        "author": [
            "Guangqi Jiang",
            "Haoran Chang",
            "Ri-Zhao Qiu",
            "Yutong Liang",
            "Mazeyu Ji",
            "Jiyue Zhu",
            "Zhao Dong",
            "Xueyan Zou",
            "Xiaolong Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20813",
        "abstract": "This paper presents GSWorld, a robust, photo-realistic simulator for robotics manipulation that combines 3D Gaussian Splatting with physics engines. Our framework advocates \"closing the loop\" of developing manipulation policies with reproducible evaluation of policies learned from real-robot data and sim2real policy training without using real robots. To enable photo-realistic rendering of diverse scenes, we propose a new asset format, which we term GSDF (Gaussian Scene Description File), that infuses Gaussian-on-Mesh representation with robot URDF and other objects. With a streamlined reconstruction pipeline, we curate a database of GSDF that contains 3 robot embodiments for single-arm and bimanual manipulation, as well as more than 40 objects. Combining GSDF with physics engines, we demonstrate several immediate interesting applications: (1) learning zero-shot sim2real pixel-to-action manipulation policy with photo-realistic rendering, (2) automated high-quality DAgger data collection for adapting policies to deployment environments, (3) reproducible benchmarking of real-robot manipulation policies in simulation, (4) simulation data collection by virtual teleoperation, and (5) zero-shot sim2real visual reinforcement learning. Website: https://3dgsworld.github.io/.",
        "tags": [
            "3D",
            "Gaussian Splatting",
            "RL",
            "Robotics"
        ]
    },
    {
        "id": "212",
        "title": "KL-Regularized Reinforcement Learning is Designed to Mode Collapse",
        "author": [
            "Anthony GX-Chen",
            "Jatin Prakash",
            "Jeff Guo",
            "Rob Fergus",
            "Rajesh Ranganath"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20817",
        "abstract": "It is commonly believed that optimizing the reverse KL divergence results in \"mode seeking\", while optimizing forward KL results in \"mass covering\", with the latter being preferred if the goal is to sample from multiple diverse modes. We show -- mathematically and empirically -- that this intuition does not necessarily transfer well to doing reinforcement learning with reverse/forward KL regularization (e.g. as commonly used with language models). Instead, the choice of reverse/forward KL determines the family of optimal target distributions, parameterized by the regularization coefficient. Mode coverage depends primarily on other factors, such as regularization strength, and relative scales between rewards and reference probabilities. Further, we show commonly used settings such as low regularization strength and equal verifiable rewards tend to specify unimodal target distributions, meaning the optimization objective is, by construction, non-diverse. We leverage these insights to construct a simple, scalable, and theoretically justified algorithm. It makes minimal changes to reward magnitudes, yet optimizes for a target distribution which puts high probability over all high-quality sampling modes. In experiments, this simple modification works to post-train both Large Language Models and Chemical Language Models to have higher solution quality and diversity, without any external signals of diversity, and works with both forward and reverse KL when using either naively fails.",
        "tags": [
            "LLM",
            "RL"
        ]
    },
    {
        "id": "213",
        "title": "VAMOS: A Hierarchical Vision-Language-Action Model for Capability-Modulated and Steerable Navigation",
        "author": [
            "Mateo Guaman Castro",
            "Sidharth Rajagopal",
            "Daniel Gorbatov",
            "Matt Schmittle",
            "Rohan Baijal",
            "Octi Zhang",
            "Rosario Scalise",
            "Sidharth Talia",
            "Emma Romig",
            "Celso de Melo",
            "Byron Boots",
            "Abhishek Gupta"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20818",
        "abstract": "A fundamental challenge in robot navigation lies in learning policies that generalize across diverse environments while conforming to the unique physical constraints and capabilities of a specific embodiment (e.g., quadrupeds can walk up stairs, but rovers cannot). We propose VAMOS, a hierarchical VLA that decouples semantic planning from embodiment grounding: a generalist planner learns from diverse, open-world data, while a specialist affordance model learns the robot's physical constraints and capabilities in safe, low-cost simulation. We enabled this separation by carefully designing an interface that lets a high-level planner propose candidate paths directly in image space that the affordance model then evaluates and re-ranks. Our real-world experiments show that VAMOS achieves higher success rates in both indoor and complex outdoor navigation than state-of-the-art model-based and end-to-end learning methods. We also show that our hierarchical design enables cross-embodied navigation across legged and wheeled robots and is easily steerable using natural language. Real-world ablations confirm that the specialist model is key to embodiment grounding, enabling a single high-level planner to be deployed across physically distinct wheeled and legged robots. Finally, this model significantly enhances single-robot reliability, achieving 3X higher success rates by rejecting physically infeasible plans. Website: https://vamos-vla.github.io/",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "214",
        "title": "Towards General Modality Translation with Contrastive and Predictive Latent Diffusion Bridge",
        "author": [
            "Nimrod Berman",
            "Omkar Joglekar",
            "Eitan Kosman",
            "Dotan Di Castro",
            "Omri Azencot"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20819",
        "abstract": "Recent advances in generative modeling have positioned diffusion models as state-of-the-art tools for sampling from complex data distributions. While these models have shown remarkable success across single-modality domains such as images and audio, extending their capabilities to Modality Translation (MT), translating information across different sensory modalities, remains an open challenge. Existing approaches often rely on restrictive assumptions, including shared dimensionality, Gaussian source priors, and modality-specific architectures, which limit their generality and theoretical grounding. In this work, we propose the Latent Denoising Diffusion Bridge Model (LDDBM), a general-purpose framework for modality translation based on a latent-variable extension of Denoising Diffusion Bridge Models. By operating in a shared latent space, our method learns a bridge between arbitrary modalities without requiring aligned dimensions. We introduce a contrastive alignment loss to enforce semantic consistency between paired samples and design a domain-agnostic encoder-decoder architecture tailored for noise prediction in latent space. Additionally, we propose a predictive loss to guide training toward accurate cross-domain translation and explore several training strategies to improve stability. Our approach supports arbitrary modality pairs and performs strongly on diverse MT tasks, including multi-view to 3D shape generation, image super-resolution, and multi-view scene synthesis. Comprehensive experiments and ablations validate the effectiveness of our framework, establishing a new strong baseline in general modality translation. For more information, see our project page: https://sites.google.com/view/lddbm/home.",
        "tags": [
            "3D",
            "Diffusion",
            "Super Resolution"
        ]
    },
    {
        "id": "215",
        "title": "LayerComposer: Interactive Personalized T2I via Spatially-Aware Layered Canvas",
        "author": [
            "Guocheng Gordon Qian",
            "Ruihang Zhang",
            "Tsai-Shien Chen",
            "Yusuf Dalva",
            "Anujraaj Argo Goyal",
            "Willi Menapace",
            "Ivan Skorokhodov",
            "Meng Dong",
            "Arpit Sahni",
            "Daniil Ostashev",
            "Ju Hu",
            "Sergey Tulyakov",
            "Kuan-Chieh Jackson Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20820",
        "abstract": "Despite their impressive visual fidelity, existing personalized generative models lack interactive control over spatial composition and scale poorly to multiple subjects. To address these limitations, we present LayerComposer, an interactive framework for personalized, multi-subject text-to-image generation. Our approach introduces two main contributions: (1) a layered canvas, a novel representation in which each subject is placed on a distinct layer, enabling occlusion-free composition; and (2) a locking mechanism that preserves selected layers with high fidelity while allowing the remaining layers to adapt flexibly to the surrounding context. Similar to professional image-editing software, the proposed layered canvas allows users to place, resize, or lock input subjects through intuitive layer manipulation. Our versatile locking mechanism requires no architectural changes, relying instead on inherent positional embeddings combined with a new complementary data sampling strategy. Extensive experiments demonstrate that LayerComposer achieves superior spatial control and identity preservation compared to the state-of-the-art methods in multi-subject personalized image generation.",
        "tags": [
            "Image Editing",
            "Text-to-Image"
        ]
    },
    {
        "id": "216",
        "title": "HoloCine: Holistic Generation of Cinematic Multi-Shot Long Video Narratives",
        "author": [
            "Yihao Meng",
            "Hao Ouyang",
            "Yue Yu",
            "Qiuyu Wang",
            "Wen Wang",
            "Ka Leong Cheng",
            "Hanlin Wang",
            "Yixuan Li",
            "Cheng Chen",
            "Yanhong Zeng",
            "Yujun Shen",
            "Huamin Qu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20822",
        "abstract": "State-of-the-art text-to-video models excel at generating isolated clips but fall short of creating the coherent, multi-shot narratives, which are the essence of storytelling. We bridge this \"narrative gap\" with HoloCine, a model that generates entire scenes holistically to ensure global consistency from the first shot to the last. Our architecture achieves precise directorial control through a Window Cross-Attention mechanism that localizes text prompts to specific shots, while a Sparse Inter-Shot Self-Attention pattern (dense within shots but sparse between them) ensures the efficiency required for minute-scale generation. Beyond setting a new state-of-the-art in narrative coherence, HoloCine develops remarkable emergent abilities: a persistent memory for characters and scenes, and an intuitive grasp of cinematic techniques. Our work marks a pivotal shift from clip synthesis towards automated filmmaking, making end-to-end cinematic creation a tangible future. Our code is available at: https://holo-cine.github.io/.",
        "tags": [
            "CLIP",
            "Text-to-Video"
        ]
    },
    {
        "id": "217",
        "title": "Guiding diffusion models to reconstruct flow fields from sparse data",
        "author": [
            "Marc AmorÃ³s-Trepat",
            "Luis Medrano-Navarro",
            "Qiang Liu",
            "Luca Guastoni",
            "Nils Thuerey"
        ],
        "pdf": "https://arxiv.org/pdf/2510.19971",
        "abstract": "The reconstruction of unsteady flow fields from limited measurements is a challenging and crucial task for many engineering applications. Machine learning models are gaining popularity in solving this problem due to their ability to learn complex patterns from data and generalize across diverse conditions. Among these, diffusion models have emerged as particularly powerful in generative tasks, producing high-quality samples by iteratively refining noisy inputs. In contrast to other methods, these generative models are capable of reconstructing the smallest scales of the fluid spectrum. In this work, we introduce a novel sampling method for diffusion models that enables the reconstruction of high-fidelity samples by guiding the reverse process using the available sparse data. Moreover, we enhance the reconstructions with available physics knowledge using a conflict-free update method during training. To evaluate the effectiveness of our method, we conduct experiments on 2 and 3-dimensional turbulent flow data. Our method consistently outperforms other diffusion-based methods in predicting the fluid's structure and in pixel-wise accuracy. This study underscores the remarkable potential of diffusion models in reconstructing flow field data, paving the way for their application in Computational Fluid Dynamics research.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "218",
        "title": "Counterexample to majority optimality in NICD with erasures",
        "author": [
            "Paata Ivanisvili",
            "Xinyuan Xie"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20013",
        "abstract": "We asked GPT-5 Pro to look for counterexamples among a public list of open problems (the Simons ``Real Analysis in Computer Science'' collection). After several numerical experiments, it suggested a counterexample for the Non-Interactive Correlation Distillation (NICD) with erasures question: namely, a Boolean function on 5 bits that achieves a strictly larger value of $\\mathbb{E}|f(z)|$ than the 5-bit majority function when the erasure parameter is $p=0.40.$ In this very short note we record the finding, state the problem precisely, give the explicit function, and verify the computation step by step by hand so that it can be checked without a computer. In addition, we show that for each fixed odd $n$ the majority is optimal (among unbiased Boolean functions) in a neighborhood of $p=0$. We view this as a little spark of an AI contribution in Theoretical Computer Science: while modern Large Language Models (LLMs) often assist with literature and numerics, here a concrete finite counterexample emerged.",
        "tags": [
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "219",
        "title": "On the Structure of Stationary Solutions to McKean-Vlasov Equations with Applications to Noisy Transformers",
        "author": [
            "Krishnakumar Balasubramanian",
            "Sayan Banerjee",
            "Philippe Rigollet"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20094",
        "abstract": "We study stationary solutions of McKean-Vlasov equations on the circle. Our main contributions stem from observing an exact equivalence between solutions of the stationary McKean-Vlasov equation and an infinite-dimensional quadratic system of equations over Fourier coefficients, which allows explicit characterization of the stationary states in a sequence space rather than a function space. This framework provides a transparent description of local bifurcations, characterizing their periodicity, and resonance structures, while accommodating singular potentials. We derive analytic expressions that characterize the emergence, form and shape (supercritical, critical, subcritical or transcritical) of bifurcations involving possibly multiple Fourier modes and connect them with discontinuous phase transitions. We also characterize, under suitable assumptions, the detailed structure of the stationary bifurcating solutions that are accurate upto an arbitrary number of Fourier modes. At the global level, we establish regularity and concavity properties of the free energy landscape, proving existence, compactness, and coexistence of globally minimizing stationary measures, further identifying discontinuous phase transitions with points of non-differentiability of the minimum free energy map. As an application, we specialize the theory to the Noisy Mean-Field Transformer model, where we show how changing the inverse temperature parameter $\\beta$ affects the geometry of the infinitely many bifurcations from the uniform measure. We also explain how increasing $\\beta$ can lead to a rich class of approximate multi-mode stationary solutions which can be seen as `metastable states'. Further, a sharp transition from continuous to discontinuous (first-order) phase behavior is observed as $\\beta$ increases.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "220",
        "title": "Compositional Generation for Long-Horizon Coupled PDEs",
        "author": [
            "Somayajulu L. N. Dhulipala",
            "Deep Ray",
            "Nicholas Forman"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20141",
        "abstract": "Simulating coupled PDE systems is computationally intensive, and prior efforts have largely focused on training surrogates on the joint (coupled) data, which requires a large amount of data. In the paper, we study compositional diffusion approaches where diffusion models are only trained on the decoupled PDE data and are composed at inference time to recover the coupled field. Specifically, we investigate whether the compositional strategy can be feasible under long time horizons involving a large number of time steps. In addition, we compare a baseline diffusion model with that trained using the v-parameterization strategy. We also introduce a symmetric compositional scheme for the coupled fields based on the Euler scheme. We evaluate on Reaction-Diffusion and modified Burgers with longer time grids, and benchmark against a Fourier Neural Operator trained on coupled data. Despite seeing only decoupled training data, the compositional diffusion models recover coupled trajectories with low error. v-parameterization can improve accuracy over a baseline diffusion model, while the neural operator surrogate remains strongest given that it is trained on the coupled data. These results show that compositional diffusion is a viable strategy towards efficient, long-horizon modeling of coupled PDEs.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "221",
        "title": "FinCARE: Financial Causal Analysis with Reasoning and Evidence",
        "author": [
            "Alejandro Michel",
            "Abhinav Arun",
            "Bhaskarjit Sarmah",
            "Stefano Pasquali"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20221",
        "abstract": "Portfolio managers rely on correlation-based analysis and heuristic methods that fail to capture true causal relationships driving performance. We present a hybrid framework that integrates statistical causal discovery algorithms with domain knowledge from two complementary sources: a financial knowledge graph extracted from SEC 10-K filings and large language model reasoning. Our approach systematically enhances three representative causal discovery paradigms, constraint-based (PC), score-based (GES), and continuous optimization (NOTEARS), by encoding knowledge graph constraints algorithmically and leveraging LLM conceptual reasoning for hypothesis generation. Evaluated on a synthetic financial dataset of 500 firms across 18 variables, our KG+LLM-enhanced methods demonstrate consistent improvements across all three algorithms: PC (F1: 0.622 vs. 0.459 baseline, +36%), GES (F1: 0.735 vs. 0.367, +100%), and NOTEARS (F1: 0.759 vs. 0.163, +366%). The framework enables reliable scenario analysis with mean absolute error of 0.003610 for counterfactual predictions and perfect directional accuracy for intervention effects. It also addresses critical limitations of existing methods by grounding statistical discoveries in financial domain expertise while maintaining empirical validation, providing portfolio managers with the causal foundation necessary for proactive risk management and strategic decision-making in dynamic market environments.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "222",
        "title": "ComProScanner: A multi-agent based framework for composition-property structured data extraction from scientific literature",
        "author": [
            "Aritra Roy",
            "Enrico Grisan",
            "John Buckeridge",
            "Chiara Gattinoni"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20362",
        "abstract": "Since the advent of various pre-trained large language models, extracting structured knowledge from scientific text has experienced a revolutionary change compared with traditional machine learning or natural language processing techniques. Despite these advances, accessible automated tools that allow users to construct, validate, and visualise datasets from scientific literature extraction remain scarce. We therefore developed ComProScanner, an autonomous multi-agent platform that facilitates the extraction, validation, classification, and visualisation of machine-readable chemical compositions and properties, integrated with synthesis data from journal articles for comprehensive database creation. We evaluated our framework using 100 journal articles against 10 different LLMs, including both open-source and proprietary models, to extract highly complex compositions associated with ceramic piezoelectric materials and corresponding piezoelectric strain coefficients (d33), motivated by the lack of a large dataset for such materials. DeepSeek-V3-0324 outperformed all models with a significant overall accuracy of 0.82. This framework provides a simple, user-friendly, readily-usable package for extracting highly complex experimental data buried in the literature to build machine learning or deep learning datasets.",
        "tags": [
            "DeepSeek",
            "LLM"
        ]
    },
    {
        "id": "223",
        "title": "A Transformer Inspired AI-based MIMO receiver",
        "author": [
            "AndrÃ¡s RÃ¡cz",
            "TamÃ¡s Borsos",
            "AndrÃ¡s Veres",
            "Benedek Csala"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20363",
        "abstract": "We present AttDet, a Transformer-inspired MIMO (Multiple Input Multiple Output) detection method that treats each transmit layer as a token and learns inter-stream interference via a lightweight self-attention mechanism. Queries and keys are derived directly from the estimated channel matrix, so attention scores quantify channel correlation. Values are initialized by matched-filter outputs and iteratively refined. The AttDet design combines model-based interpretability with data-driven flexibility. We demonstrate through link-level simulations under realistic 5G channel models and high-order, mixed QAM modulation and coding schemes, that AttDet can approach near-optimal BER/BLER (Bit Error Rate/Block Error Rate) performance while maintaining predictable, polynomial complexity.",
        "tags": [
            "Detection",
            "Transformer"
        ]
    },
    {
        "id": "224",
        "title": "Learning Decentralized Routing Policies via Graph Attention-based Multi-Agent Reinforcement Learning in Lunar Delay-Tolerant Networks",
        "author": [
            "Federico Lozano-Cuadra",
            "Beatriz Soret",
            "Marc Sanchez Net",
            "Abhishek Cauligi",
            "Federico Rossi"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20436",
        "abstract": "We present a fully decentralized routing framework for multi-robot exploration missions operating under the constraints of a Lunar Delay-Tolerant Network (LDTN). In this setting, autonomous rovers must relay collected data to a lander under intermittent connectivity and unknown mobility patterns. We formulate the problem as a Partially Observable Markov Decision Problem (POMDP) and propose a Graph Attention-based Multi-Agent Reinforcement Learning (GAT-MARL) policy that performs Centralized Training, Decentralized Execution (CTDE). Our method relies only on local observations and does not require global topology updates or packet replication, unlike classical approaches such as shortest path and controlled flooding-based algorithms. Through Monte Carlo simulations in randomized exploration environments, GAT-MARL provides higher delivery rates, no duplications, and fewer packet losses, and is able to leverage short-term mobility forecasts; offering a scalable solution for future space robotic systems for planetary exploration, as demonstrated by successful generalization to larger rover teams.",
        "tags": [
            "RL",
            "Robotics"
        ]
    },
    {
        "id": "225",
        "title": "Stochastic evolution equations with nonlinear diffusivity, recent progress and critical cases",
        "author": [
            "Ioana Ciotir",
            "Dan Goreac",
            "Jonas M. TÃ¶lle"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20471",
        "abstract": "This short survey article stems from recent progress on critical cases of stochastic evolution equations in variational formulation with additive, multiplicative or gradient noises. Typical examples appear as the limit cases of the stochastic porous medium equation, stochastic fast- and super fast-diffusion equations, self-organized criticality, stochastic singular $p$-Laplace equations, and the stochastic total variation flow, among others. We present several different notions of solutions, results on convergence of solutions depending on a parameter, and homogenization. Furthermore, we provide some references hinting at the recent progress in regularity results, long-time behavior, ergodicity, and numerical analysis.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "226",
        "title": "Diffusion Autoencoders with Perceivers for Long, Irregular and Multimodal Astronomical Sequences",
        "author": [
            "Yunyi Shen",
            "Alexander Gagliano"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20595",
        "abstract": "Self-supervised learning has become a central strategy for representation learning, but the majority of architectures used for encoding data have only been validated on regularly-sampled inputs such as images, audios. and videos. In many scientific domains, data instead arrive as long, irregular, and multimodal sequences. To extract semantic information from these data, we introduce the Diffusion Autoencoder with Perceivers (daep). daep tokenizes heterogeneous measurements, compresses them with a Perceiver encoder, and reconstructs them with a Perceiver-IO diffusion decoder, enabling scalable learning in diverse data settings. To benchmark the daep architecture, we adapt the masked autoencoder to a Perceiver encoder/decoder design, and establish a strong baseline (maep) in the same architectural family as daep. Across diverse spectroscopic and photometric astronomical datasets, daep achieves lower reconstruction errors, produces more discriminative latent spaces, and better preserves fine-scale structure than both VAE and maep baselines. These results establish daep as an effective framework for scientific domains where data arrives as irregular, heterogeneous sequences.",
        "tags": [
            "Diffusion",
            "VAE"
        ]
    },
    {
        "id": "227",
        "title": "Finding the Sweet Spot: Trading Quality, Cost, and Speed During Inference-Time LLM Reflection",
        "author": [
            "Jack Butler",
            "Nikita Kozodoi",
            "Zainab Afolabi",
            "Brian Tyacke",
            "Gaiar Baimuratov"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20653",
        "abstract": "As Large Language Models (LLMs) continue to evolve, practitioners face increasing options for enhancing inference-time performance without model retraining, including budget tuning and multi-step techniques like self-reflection. While these methods improve output quality, they create complex trade-offs among accuracy, cost, and latency that remain poorly understood across different domains. This paper systematically compares self-reflection and budget tuning across mathematical reasoning and translation tasks. We evaluate prominent LLMs, including Anthropic Claude, Amazon Nova, and Mistral families, along with other models under varying reflection depths and compute budgets to derive Pareto optimal performance frontiers. Our analysis reveals substantial domain dependent variation in self-reflection effectiveness, with performance gains up to 220\\% in mathematical reasoning. We further investigate how reflection round depth and feedback mechanism quality influence performance across model families. To validate our findings in a real-world setting, we deploy a self-reflection enhanced marketing content localisation system at Lounge by Zalando, where it shows market-dependent effectiveness, reinforcing the importance of domain specific evaluation when deploying these techniques. Our results provide actionable guidance for selecting optimal inference strategies given specific domains and resource constraints. We open source our self-reflection implementation for reproducibility at https://github.com/aws-samples/sample-genai-reflection-for-bedrock.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "228",
        "title": "Fusing Narrative Semantics for Financial Volatility Forecasting",
        "author": [
            "Yaxuan Kong",
            "Yoontae Hwang",
            "Marcus Kaiser",
            "Chris Vryonides",
            "Roel Oomen",
            "Stefan Zohren"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20699",
        "abstract": "We introduce M2VN: Multi-Modal Volatility Network, a novel deep learning-based framework for financial volatility forecasting that unifies time series features with unstructured news data. M2VN leverages the representational power of deep neural networks to address two key challenges in this domain: (i) aligning and fusing heterogeneous data modalities, numerical financial data and textual information, and (ii) mitigating look-ahead bias that can undermine the validity of financial models. To achieve this, M2VN combines open-source market features with news embeddings generated by Time Machine GPT, a recently introduced point-in-time LLM, ensuring temporal integrity. An auxiliary alignment loss is introduced to enhance the integration of structured and unstructured data within the deep learning architecture. Extensive experiments demonstrate that M2VN consistently outperforms existing baselines, underscoring its practical value for risk management and financial decision-making in dynamic markets.",
        "tags": [
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "229",
        "title": "Co-Designing Quantum Codes with Transversal Diagonal Gates via Multi-Agent Systems",
        "author": [
            "Xi He",
            "Sirui Lu",
            "Bei Zeng"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20728",
        "abstract": "We present a multi-agent, human-in-the-loop workflow that co-designs quantum codes with prescribed transversal diagonal gates. It builds on the Subset-Sum Linear Programming (SSLP) framework (https://arxiv.org/abs/2504.20847), which partitions basis strings by modular residues and enforces $Z$-marginal Knill-Laflamme (KL) equalities via small LPs. The workflow is powered by GPT-5 and implemented within TeXRA (https://texra.ai)-a multi-agent research assistant platform that supports an iterative tool-use loop agent and a derivation-then-edit workflow reasoning agent. We work in a LaTeX-Python environment where agents reason, edit documents, execute code, and synchronize their work to Git/Overleaf. Within this workspace, three roles collaborate: a Synthesis Agent formulates the problem; a Search Agent sweeps/screens candidates and exactifies numerics into rationals; and an Audit Agent independently checks all KL equalities and the induced logical action. As a first step we focus on distance $d=2$ with nondegenerate residues. For code dimension $K\\in\\{2,3,4\\}$ and $n\\le6$ qubits, systematic sweeps yield certificate-backed tables cataloging attainable cyclic logical groups-all realized by new codes-e.g., for $K=3$ we obtain order $16$ at $n=6$. From verified instances, Synthesis Agent abstracts recurring structures into closed-form families and proves they satisfy the KL equalities for all parameters. It further demonstrates that SSLP accommodates residue degeneracy by exhibiting a new $((6,4,2))$ code implementing the transversal controlled-phase $diag(1,1,1,i)$. Overall, the workflow recasts diagonal-transversal feasibility as an analytical pipeline executed at scale, combining systematic enumeration with exact analytical reconstruction. It yields reproducible code constructions, supports targeted extensions to larger $K$ and higher distances, and leads toward data-driven classification.",
        "tags": [
            "GPT"
        ]
    },
    {
        "id": "230",
        "title": "Reinforcement Learning and Consumption-Savings Behavior",
        "author": [
            "Brandon Kaplowitz"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20748",
        "abstract": "This paper demonstrates how reinforcement learning can explain two puzzling empirical patterns in household consumption behavior during economic downturns. I develop a model where agents use Q-learning with neural network approximation to make consumption-savings decisions under income uncertainty, departing from standard rational expectations assumptions. The model replicates two key findings from recent literature: (1) unemployed households with previously low liquid assets exhibit substantially higher marginal propensities to consume (MPCs) out of stimulus transfers compared to high-asset households (0.50 vs 0.34), even when neither group faces borrowing constraints, consistent with Ganong et al. (2024); and (2) households with more past unemployment experiences maintain persistently lower consumption levels after controlling for current economic conditions, a \"scarring\" effect documented by Malmendier and Shen (2024). Unlike existing explanations based on belief updating about income risk or ex-ante heterogeneity, the reinforcement learning mechanism generates both higher MPCs and lower consumption levels simultaneously through value function approximation errors that evolve with experience. Simulation results closely match the empirical estimates, suggesting that adaptive learning through reinforcement learning provides a unifying framework for understanding how past experiences shape current consumption behavior beyond what current economic conditions would predict.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "231",
        "title": "CSU-PCAST: A Dual-Branch Transformer Framework for medium-range ensemble Precipitation Forecasting",
        "author": [
            "Tianyi Xiong",
            "Haonan Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20769",
        "abstract": "Accurate medium-range precipitation forecasting is crucial for hydrometeorological risk management and disaster mitigation, yet remains challenging for current numerical weather prediction (NWP) systems. Traditional ensemble systems such as the Global Ensemble Forecast System (GEFS) struggle to maintain high skill, especially for moderate and heavy rainfall at extended lead times. This study develops a deep learning-based ensemble framework for multi-step precipitation prediction through joint modeling of a comprehensive set of atmospheric variables. The model is trained on ERA5 reanalysis data at 0.25$^{\\circ}$ spatial resolution, with precipitation labels from NASA's Integrated Multi-satellite Retrievals for Global Precipitation Measurement (GPM) constellation (IMERG), incorporating 57 input variables, including upper-air and surface predictors. The architecture employs a patch-based Swin Transformer backbone with periodic convolutions to handle longitudinal continuity and integrates time and noise embeddings through conditional layer normalization. A dual-branch decoder predicts total precipitation and other variables, with targeted freezing of encoder-decoder pathways for specialized training. Training minimizes a hybrid loss combining the Continuous Ranked Probability Score (CRPS) and weighted log1p mean squared error (log1pMSE), balancing probabilistic accuracy and magnitude fidelity. During inference, the model ingests real-time Global Forecast System (GFS) initial conditions to generate 15-day forecasts autoregressively. Evaluation against GEFS using IMERG data demonstrates higher Critical Success Index (CSI) scores at precipitation thresholds of 0.1 mm, 1 mm, 10 mm, and 20 mm, highlighting improved performance for moderate to heavy rainfall.",
        "tags": [
            "Transformer"
        ]
    }
]