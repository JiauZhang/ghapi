[
    {
        "id": "1",
        "title": "Sketch2BIM: A Multi-Agent Human-AI Collaborative Pipeline to Convert Hand-Drawn Floor Plans to 3D BIM",
        "author": [
            "Abir Khan Ratul",
            "Sanjay Acharjee",
            "Somin Park",
            "Md Nazmus Sakib"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20838",
        "abstract": "This study introduces a human-in-the-loop pipeline that converts unscaled, hand-drawn floor plan sketches into semantically consistent 3D BIM models. The workflow leverages multimodal large language models (MLLMs) within a multi-agent framework, combining perceptual extraction, human feedback, schema validation, and automated BIM scripting. Initially, sketches are iteratively refined into a structured JSON layout of walls, doors, and windows. Later, these layouts are transformed into executable scripts that generate 3D BIM models. Experiments on ten diverse floor plans demonstrate strong convergence: openings (doors, windows) are captured with high reliability in the initial pass, while wall detection begins around 83% and achieves near-perfect alignment after a few feedback iterations. Across all categories, precision, recall, and F1 scores remain above 0.83, and geometric errors (RMSE, MAE) progressively decrease to zero through feedback corrections. This study demonstrates how MLLM-driven multi-agent reasoning can make BIM creation accessible to both experts and non-experts using only freehand sketches.",
        "tags": [
            "3D",
            "Detection",
            "LLM"
        ]
    },
    {
        "id": "2",
        "title": "Cultural Alien Sampler: Open-ended art generation balancing originality and coherence",
        "author": [
            "Alejandro H. Artiles",
            "Hiromu Yakura",
            "Levin Brinkmann",
            "Mar Canet Sola",
            "Hassan Abu Alhaija",
            "Ignacio Serna",
            "Nasim Rahaman",
            "Bernhard SchÃ¶lkopf",
            "Iyad Rahwan"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20849",
        "abstract": "In open-ended domains like art, autonomous agents must generate ideas that are both original and internally coherent, yet current Large Language Models (LLMs) either default to familiar cultural patterns or sacrifice coherence when pushed toward novelty. We address this by introducing the Cultural Alien Sampler (CAS), a concept-selection method that explicitly separates compositional fit from cultural typicality. CAS uses two GPT-2 models fine-tuned on WikiArt concepts: a Concept Coherence Model that scores whether concepts plausibly co-occur within artworks, and a Cultural Context Model that estimates how typical those combinations are within individual artists' bodies of work. CAS targets combinations that are high in coherence and low in typicality, yielding ideas that maintain internal consistency while deviating from learned conventions and embedded cultural context. In a human evaluation (N = 100), our approach outperforms random selection and GPT-4o baselines and achieves performance comparable to human art students in both perceived originality and harmony. Additionally, a quantitative study shows that our method produces more diverse outputs and explores a broader conceptual space than its GPT-4o counterpart, demonstrating that artificial cultural alienness can unlock creative potential in autonomous agents.",
        "tags": [
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "3",
        "title": "Incentivizing Consistent, Effective and Scalable Reasoning Capability in Audio LLMs via Reasoning Process Rewards",
        "author": [
            "Jiajun Fan",
            "Roger Ren",
            "Jingyuan Li",
            "Rahul Pandey",
            "Prashanth Gurunath Shivakumar",
            "Ivan Bulyko",
            "Ankur Gandhe",
            "Ge Liu",
            "Yile Gu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20867",
        "abstract": "The role of reasoning in Audio Large Language Models remains widely underexplored, as introducing a reasoning process often degrades rather than improves performance during inference, a phenomenon we term test-time inverse scaling, where longer reasoning chains yield progressively worse results. We demonstrate that this stems not from fundamental limitations of reasoning itself, but from inadequate training: models without proper guidance for the reasoning process produce hallucinatory, inconsistent reasoning that accumulates errors over longer chains. To address these challenges, we introduce CESAR (Consistent, Effective, and Scalable Audio Reasoners), shifting from outcome verification to rewarding the reasoning process. Our online reinforcement learning framework employs Group Relative Policy Optimization with a multi-faceted reward suite that incentivizes not only correctness and format but also consistency, structured analytical patterns, causal reasoning, domain-knowledge integration, and calibrated reasoning depth. CESAR resolves test-time inverse scaling, transforming reasoning from detriments into gains while revealing model-specific ``reasoning sweet spots\", where performance peaks during test-time scaling. We achieve state-of-the-art results on MMAU Test-mini, substantially outperforming Gemini 2.5 Pro and GPT-4o Audio, and near-human-level performance on MMSU reasoning tasks. Through AI-as-judge evaluations and qualitative comparisons, we provide both quantitative and qualitative validation of our improved reasoning quality. Importantly, enhanced reasoning creates synergistic effects, simultaneously improving multimodal reasoning and perception capabilities. Overall, CESAR establishes a principled method for developing robust and scalable reasoning in Audio LLMs.",
        "tags": [
            "GPT",
            "LLM",
            "RL"
        ]
    },
    {
        "id": "4",
        "title": "HA-RAG: Hotness-Aware RAG Acceleration via Mixed Precision and Data Placement",
        "author": [
            "Danying Ge",
            "Jianhua Gao",
            "Yixue Yang",
            "Weixing Ji"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20878",
        "abstract": "Retrieval-Augmented Generation (RAG) improves model output accuracy by leveraging external knowledge bases, serving as an effective solution to address hallucination issues and knowledge-update delays in Large Language Models (LLMs). However, the introduction of external knowledge bases presents RAG with challenges in long-context processing, significantly increasing memory consumption and inference latency. Existing research accelerates inference by precomputing Key and Value (KV) of the knowledge base and loading them on-demand during inference. Based on the access frequency of different KV chunks within the external knowledge base, this paper proposes a hotness-aware RAG (HA-RAG) inference optimization system. First, leveraging the numerical distribution of KV chunks, we introduce a hotness-aware mixed-precision compressing and loading method to reduce disk I/O and memory access overhead. Second, we design a hotness-aware data placement strategy that prioritizes storing frequently accessed KV chunks in high-speed memory to improve data access efficiency. Experimental results demonstrate that, compared with TurboRAG, the proposed HA-RAG achieves an average speedup of 2.10x and maximum speedup of 10.49x in Time-To-First-Token (TTFT) with negligible accuracy loss.",
        "tags": [
            "LLM",
            "RAG"
        ]
    },
    {
        "id": "5",
        "title": "ROPES: Robotic Pose Estimation via Score-Based Causal Representation Learning",
        "author": [
            "Pranamya Kulkarni",
            "Puranjay Datta",
            "Burak VarÄ±cÄ±",
            "Emre AcartÃ¼rk",
            "Karthikeyan Shanmugam",
            "Ali Tajer"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20884",
        "abstract": "Causal representation learning (CRL) has emerged as a powerful unsupervised framework that (i) disentangles the latent generative factors underlying high-dimensional data, and (ii) learns the cause-and-effect interactions among the disentangled variables. Despite extensive recent advances in identifiability and some practical progress, a substantial gap remains between theory and real-world practice. This paper takes a step toward closing that gap by bringing CRL to robotics, a domain that has motivated CRL. Specifically, this paper addresses the well-defined robot pose estimation -- the recovery of position and orientation from raw images -- by introducing Robotic Pose Estimation via Score-Based CRL (ROPES). Being an unsupervised framework, ROPES embodies the essence of interventional CRL by identifying those generative factors that are actuated: images are generated by intrinsic and extrinsic latent factors (e.g., joint angles, arm/limb geometry, lighting, background, and camera configuration) and the objective is to disentangle and recover the controllable latent variables, i.e., those that can be directly manipulated (intervened upon) through actuation. Interventional CRL theory shows that variables that undergo variations via interventions can be identified. In robotics, such interventions arise naturally by commanding actuators of various joints and recording images under varied controls. Empirical evaluations in semi-synthetic manipulator experiments demonstrate that ROPES successfully disentangles latent generative factors with high fidelity with respect to the ground truth. Crucially, this is achieved by leveraging only distributional changes, without using any labeled data. The paper also includes a comparison with a baseline based on a recently proposed semi-supervised framework. This paper concludes by positioning robot pose estimation as a near-practical testbed for CRL.",
        "tags": [
            "Pose Estimation",
            "Robotics"
        ]
    },
    {
        "id": "6",
        "title": "Shoot First, Ask Questions Later? Building Rational Agents that Explore and Act Like People",
        "author": [
            "Gabriel Grand",
            "Valerio Pepe",
            "Jacob Andreas",
            "Joshua B. Tenenbaum"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20886",
        "abstract": "Many high-stakes applications of AI require forming data-driven hypotheses and making targeted guesses; e.g., in scientific and diagnostic settings. Given limited resources, to what extent do agents based on language models (LMs) act rationally? We develop methods to benchmark and enhance agentic information-seeking, drawing on insights from human behavior. First, we introduce a strategic decision-oriented dialogue task called Collaborative Battleship, in which a partially-informed Captain must balance exploration (asking questions) and action (taking shots), while a fully-informed Spotter must provide accurate answers under an information bottleneck. Compared to human players (N=42), we find that LM agents struggle to ground answers in context, generate informative questions, and select high-value actions. Next, to address these gaps, we develop novel Monte Carlo inference strategies for LMs based on principles from Bayesian Experimental Design (BED). For Spotter agents, our approach boosts accuracy by up to 14.7% absolute over LM-only baselines; for Captain agents, it raises expected information gain (EIG) by up to 0.227 bits (94.2% of the achievable noise ceiling). Combined, these components yield sharper targeting (+0.303-0.374 F1), and enable weaker LMs, such as Llama-4-Scout, to outperform both humans (8% -> 82% win rate) and frontier models (0% -> 67% win rate vs. GPT-5) at ~1% of GPT-5's cost. We replicate these findings on Guess Who? where our methods significantly boost accuracy (+28.3-42.4 p.p.), demonstrating their general applicability for building rational information-seeking agents.",
        "tags": [
            "GPT",
            "LLaMA"
        ]
    },
    {
        "id": "7",
        "title": "Preventing Shortcuts in Adapter Training via Providing the Shortcuts",
        "author": [
            "Anujraaj Argo Goyal",
            "Guocheng Gordon Qian",
            "Huseyin Coskun",
            "Aarush Gupta",
            "Himmy Tam",
            "Daniil Ostashev",
            "Ju Hu",
            "Dhritiman Sagar",
            "Sergey Tulyakov",
            "Kfir Aberman",
            "Kuan-Chieh Jackson Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20887",
        "abstract": "Adapter-based training has emerged as a key mechanism for extending the capabilities of powerful foundation image generators, enabling personalized and stylized text-to-image synthesis. These adapters are typically trained to capture a specific target attribute, such as subject identity, using single-image reconstruction objectives. However, because the input image inevitably contains a mixture of visual factors, adapters are prone to entangle the target attribute with incidental ones, such as pose, expression, and lighting. This spurious correlation problem limits generalization and obstructs the model's ability to adhere to the input text prompt. In this work, we uncover a simple yet effective solution: provide the very shortcuts we wish to eliminate during adapter training. In Shortcut-Rerouted Adapter Training, confounding factors are routed through auxiliary modules, such as ControlNet or LoRA, eliminating the incentive for the adapter to internalize them. The auxiliary modules are then removed during inference. When applied to tasks like facial and full-body identity injection, our approach improves generation quality, diversity, and prompt adherence. These results point to a general design principle in the era of large models: when seeking disentangled representations, the most effective path may be to establish shortcuts for what should NOT be learned.",
        "tags": [
            "ControlNet",
            "LoRA",
            "Text-to-Image"
        ]
    },
    {
        "id": "8",
        "title": "Video-As-Prompt: Unified Semantic Control for Video Generation",
        "author": [
            "Yuxuan Bian",
            "Xin Chen",
            "Zenan Li",
            "Tiancheng Zhi",
            "Shen Sang",
            "Linjie Luo",
            "Qiang Xu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20888",
        "abstract": "Unified, generalizable semantic control in video generation remains a critical open challenge. Existing methods either introduce artifacts by enforcing inappropriate pixel-wise priors from structure-based controls, or rely on non-generalizable, condition-specific finetuning or task-specific architectures. We introduce Video-As-Prompt (VAP), a new paradigm that reframes this problem as in-context generation. VAP leverages a reference video as a direct semantic prompt, guiding a frozen Video Diffusion Transformer (DiT) via a plug-and-play Mixture-of-Transformers (MoT) expert. This architecture prevents catastrophic forgetting and is guided by a temporally biased position embedding that eliminates spurious mapping priors for robust context retrieval. To power this approach and catalyze future research, we built VAP-Data, the largest dataset for semantic-controlled video generation with over 100K paired videos across 100 semantic conditions. As a single unified model, VAP sets a new state-of-the-art for open-source methods, achieving a 38.7% user preference rate that rivals leading condition-specific commercial models. VAP's strong zero-shot generalization and support for various downstream applications mark a significant advance toward general-purpose, controllable video generation.",
        "tags": [
            "DiT",
            "Diffusion",
            "Transformer",
            "Video Generation"
        ]
    },
    {
        "id": "9",
        "title": "Information Theoretic Learning for Diffusion Models with Warm Start",
        "author": [
            "Yirong Shen",
            "Lu Gan",
            "Cong Ling"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20903",
        "abstract": "Generative models that maximize model likelihood have gained traction in many practical settings. Among them, perturbation based approaches underpin many strong likelihood estimation models, yet they often face slow convergence and limited theoretical understanding. In this paper, we derive a tighter likelihood bound for noise driven models to improve both the accuracy and efficiency of maximum likelihood learning. Our key insight extends the classical KL divergence Fisher information relationship to arbitrary noise perturbations, going beyond the Gaussian assumption and enabling structured noise distributions. This formulation allows flexible use of randomized noise distributions that naturally account for sensor artifacts, quantization effects, and data distribution smoothing, while remaining compatible with standard diffusion training. Treating the diffusion process as a Gaussian channel, we further express the mismatched entropy between data and model, showing that the proposed objective upper bounds the negative log-likelihood (NLL). In experiments, our models achieve competitive NLL on CIFAR-10 and SOTA results on ImageNet across multiple resolutions, all without data augmentation, and the framework extends naturally to discrete data.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "10",
        "title": "Code-enabled language models can outperform reasoning models on diverse tasks",
        "author": [
            "Cedegao E. Zhang",
            "CÃ©dric Colas",
            "Gabriel Poesia",
            "Joshua B. Tenenbaum",
            "Jacob Andreas"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20909",
        "abstract": "Reasoning models (RMs), language models (LMs) trained with reinforcement learning to produce long-form natural language reasoning, have been remarkably successful, but they still require large amounts of computation and data to train, and can be slow and expensive to run. In this paper, we show that standard instruct LMs can already be elicited to be strong reasoners at a level comparable to or even surpassing their corresponding RMs (e.g., DeepSeek V3 vs R1) without finetuning, across diverse domains from instruction following and creative generation to mathematical reasoning. This is achieved by CodeAdapt, our simple recipe that combines the CodeAct framework, where LMs interleave natural language reasoning with code execution in a multi-step fashion, with few-shot bootstrap in-context learning from as few as five training problems. Analyzing four matched pairs of LMs and RMs, we find that CodeAdapt enables three LMs to outperform the corresponding RMs on average over eight tasks (up to 22.9%) while being 10-81% more token efficient, and delivers superior performance on six tasks when averaged over the four models (up to 35.7%). Furthermore, the code-augmented reasoning traces display rich and varied problem-solving strategies. Our findings support that (1) CodeAdapt-style learning and reasoning may be robust and domain general and (2) code-enabled LMs are cognitively grounded and powerful systems, potentially providing a strong foundation for in-weight reinforcement learning.",
        "tags": [
            "DeepSeek",
            "RL"
        ]
    },
    {
        "id": "11",
        "title": "Security Logs to ATT&CK Insights: Leveraging LLMs for High-Level Threat Understanding and Cognitive Trait Inference",
        "author": [
            "Soham Hans",
            "Stacy Marsella",
            "Sophia Hirschmann",
            "Nikolos Gurney"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20930",
        "abstract": "Understanding adversarial behavior in cybersecurity has traditionally relied on high-level intelligence reports and manual interpretation of attack chains. However, real-time defense requires the ability to infer attacker intent and cognitive strategy directly from low-level system telemetry such as intrusion detection system (IDS) logs. In this paper, we propose a novel framework that leverages large language models (LLMs) to analyze Suricata IDS logs and infer attacker actions in terms of MITRE ATT&CK techniques. Our approach is grounded in the hypothesis that attacker behavior reflects underlying cognitive biases such as loss aversion, risk tolerance, or goal persistence that can be extracted and modeled through careful observation of log sequences. This lays the groundwork for future work on behaviorally adaptive cyber defense and cognitive trait inference. We develop a strategy-driven prompt system to segment large amounts of network logs data into distinct behavioral phases in a highly efficient manner, enabling the LLM to associate each phase with likely techniques and underlying cognitive motives. By mapping network-layer events to high-level attacker strategies, our method reveals how behavioral signals such as tool switching, protocol transitions, or pivot patterns correspond to psychologically meaningful decision points. The results demonstrate that LLMs can bridge the semantic gap between packet-level logs and strategic intent, offering a pathway toward cognitive-adaptive cyber defense.\nKeywords: Cognitive Cybersecurity, Large Language Models (LLMs), Cyberpsychology, Intrusion Detection Systems (IDS), MITRE ATT&CK, Cognitive Biases",
        "tags": [
            "Detection",
            "LLM"
        ]
    },
    {
        "id": "12",
        "title": "Do LLMs Truly Understand When a Precedent Is Overruled?",
        "author": [
            "Li Zhang",
            "Jaromir Savelka",
            "Kevin Ashley"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20941",
        "abstract": "Large language models (LLMs) with extended context windows show promise for complex legal reasoning tasks, yet their ability to understand long legal documents remains insufficiently evaluated. Developing long-context benchmarks that capture realistic, high-stakes tasks remains a significant challenge in the field, as most existing evaluations rely on simplified synthetic tasks that fail to represent the complexity of real-world document understanding. Overruling relationships are foundational to common-law doctrine and commonly found in judicial opinions. They provide a focused and important testbed for long-document legal understanding that closely resembles what legal professionals actually do. We present an assessment of state-of-the-art LLMs on identifying overruling relationships from U.S. Supreme Court cases using a dataset of 236 case pairs. Our evaluation reveals three critical limitations: (1) era sensitivity -- the models show degraded performance on historical cases compared to modern ones, revealing fundamental temporal bias in their training; (2) shallow reasoning -- models rely on shallow logical heuristics rather than deep legal comprehension; and (3) context-dependent reasoning failures -- models produce temporally impossible relationships in complex open-ended tasks despite maintaining basic temporal awareness in simple contexts. Our work contributes a benchmark that addresses the critical gap in realistic long-context evaluation, providing an environment that mirrors the complexity and stakes of actual legal reasoning tasks.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "13",
        "title": "Generative Point Tracking with Flow Matching",
        "author": [
            "Mattie Tesfaldet",
            "Adam W. Harley",
            "Konstantinos G. Derpanis",
            "Derek Nowrouzezahrai",
            "Christopher Pal"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20951",
        "abstract": "Tracking a point through a video can be a challenging task due to uncertainty arising from visual obfuscations, such as appearance changes and occlusions. Although current state-of-the-art discriminative models excel in regressing long-term point trajectory estimates -- even through occlusions -- they are limited to regressing to a mean (or mode) in the presence of uncertainty, and fail to capture multi-modality. To overcome this limitation, we introduce Generative Point Tracker (GenPT), a generative framework for modelling multi-modal trajectories. GenPT is trained with a novel flow matching formulation that combines the iterative refinement of discriminative trackers, a window-dependent prior for cross-window consistency, and a variance schedule tuned specifically for point coordinates. We show how our model's generative capabilities can be leveraged to improve point trajectory estimates by utilizing a best-first search strategy on generated samples during inference, guided by the model's own confidence of its predictions. Empirically, we evaluate GenPT against the current state of the art on the standard PointOdyssey, Dynamic Replica, and TAP-Vid benchmarks. Further, we introduce a TAP-Vid variant with additional occlusions to assess occluded point tracking performance and highlight our model's ability to capture multi-modality. GenPT is capable of capturing the multi-modality in point trajectories, which translates to state-of-the-art tracking accuracy on occluded points, while maintaining competitive tracking accuracy on visible points compared to extant discriminative point trackers.",
        "tags": [
            "Flow Matching"
        ]
    },
    {
        "id": "14",
        "title": "LLM-Integrated Bayesian State Space Models for Multimodal Time-Series Forecasting",
        "author": [
            "Sungjun Cho",
            "Changho Shin",
            "Suenggwan Jo",
            "Xinya Yan",
            "Shourjo Aditya Chaudhuri",
            "Frederic Sala"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20952",
        "abstract": "Forecasting in the real world requires integrating structured time-series data with unstructured textual information, but existing methods are architecturally limited by fixed input/output horizons and are unable to model or quantify uncertainty. We address this challenge by introducing LLM-integrated Bayesian State space models (LBS), a novel probabilistic framework for multimodal temporal forecasting. At a high level, LBS consists of two components: (1) a state space model (SSM) backbone that captures the temporal dynamics of latent states from which both numerical and textual observations are generated and (2) a pretrained large language model (LLM) that is adapted to encode textual inputs for posterior state estimation and decode textual forecasts consistent with the latent trajectory. This design enables flexible lookback and forecast windows, principled uncertainty quantification, and improved temporal generalization thanks to the well-suited inductive bias of SSMs toward modeling dynamical systems. Experiments on the TextTimeCorpus benchmark demonstrate that LBS improves the previous state-of-the-art by 13.20% while providing human-readable summaries of each forecast. Our work is the first to unify LLMs and SSMs for joint numerical and textual prediction, offering a novel foundation for multimodal temporal reasoning.",
        "tags": [
            "LLM",
            "SSMs"
        ]
    },
    {
        "id": "15",
        "title": "Safety Assessment in Reinforcement Learning via Model Predictive Control",
        "author": [
            "Jeff Pflueger",
            "Michael Everett"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20955",
        "abstract": "Model-free reinforcement learning approaches are promising for control but typically lack formal safety guarantees. Existing methods to shield or otherwise provide these guarantees often rely on detailed knowledge of the safety specifications. Instead, this work's insight is that many difficult-to-specify safety issues are best characterized by invariance. Accordingly, we propose to leverage reversibility as a method for preventing these safety issues throughout the training process. Our method uses model-predictive path integral control to check the safety of an action proposed by a learned policy throughout training. A key advantage of this approach is that it only requires the ability to query the black-box dynamics, not explicit knowledge of the dynamics or safety constraints. Experimental results demonstrate that the proposed algorithm successfully aborts before all unsafe actions, while still achieving comparable training progress to a baseline PPO approach that is allowed to violate safety.",
        "tags": [
            "PPO",
            "RL"
        ]
    },
    {
        "id": "16",
        "title": "Self-Jailbreaking: Language Models Can Reason Themselves Out of Safety Alignment After Benign Reasoning Training",
        "author": [
            "Zheng-Xin Yong",
            "Stephen H. Bach"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20956",
        "abstract": "We discover a novel and surprising phenomenon of unintentional misalignment in reasoning language models (RLMs), which we call self-jailbreaking. Specifically, after benign reasoning training on math or code domains, RLMs will use multiple strategies to circumvent their own safety guardrails. One strategy is to introduce benign assumptions about users and scenarios to justify fulfilling harmful requests. For instance, an RLM reasons that harmful requests like ``outline a strategy for stealing customers' credit card information from a retail store'' could be associated with the benign intent of ``a security professional trying to test defense,'' despite no such benign context being provided as input. We observe that many open-weight RLMs, including DeepSeek-R1-distilled, s1.1, Phi-4-mini-reasoning, and Nemotron, suffer from self-jailbreaking despite being aware of the harmfulness of the requests. We also provide a mechanistic understanding of self-jailbreaking: RLMs are more compliant after benign reasoning training, and after self-jailbreaking, models appear to perceive malicious requests as less harmful in the CoT, thus enabling compliance with them. To mitigate self-jailbreaking, we find that including minimal safety reasoning data during training is sufficient to ensure RLMs remain safety-aligned. Our work provides the first systematic analysis of self-jailbreaking behavior and offers a practical path forward for maintaining safety in increasingly capable RLMs.",
        "tags": [
            "CoT",
            "DeepSeek"
        ]
    },
    {
        "id": "17",
        "title": "Irish-BLiMP: A Linguistic Benchmark for Evaluating Human and Language Model Performance in a Low-Resource Setting",
        "author": [
            "Josh McGiff",
            "Khanh-Tung Tran",
            "William Mulcahy",
            "DÃ¡ibhidh Ã LuinÃ­n",
            "Jake Dalzell",
            "RÃ³isÃ­n NÃ­ Bhroin",
            "Adam Burke",
            "Barry O'Sullivan",
            "Hoang D. Nguyen",
            "Nikola S. Nikolov"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20957",
        "abstract": "We present Irish-BLiMP (Irish Benchmark of Linguistic Minimal Pairs), the first dataset and framework designed for fine-grained evaluation of linguistic competence in the Irish language, an endangered language. Drawing on a variety of linguistic literature and grammar reference works, we manually constructed and reviewed 1020 minimal pairs across a taxonomy of 11 linguistic features, through a team of fluent Irish speakers. We evaluate both existing Large Language Models (LLMs) and fluent human participants on their syntactic knowledge of Irish. Our findings show that humans outperform all models across all linguistic features, achieving 16.6% higher accuracy on average. Moreover, a substantial performance gap of 18.1% persists between open- and closed-source LLMs, with even the strongest model (gpt-5) reaching only 73.5% accuracy compared to 90.1% by human. Interestingly, human participants and models struggle on different aspects of Irish grammar, thus highlighting a difference in representation learned by the models. Overall, Irish-BLiMP provides the first systematic framework for evaluating the grammatical competence of LLMs in Irish and offers a valuable benchmark for advancing research on linguistic understanding in low-resource languages.",
        "tags": [
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "18",
        "title": "Towards Scalable Oversight with Collaborative Multi-Agent Debate in Error Detection",
        "author": [
            "Yongqiang Chen",
            "Gang Niu",
            "James Cheng",
            "Bo Han",
            "Masashi Sugiyama"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20963",
        "abstract": "Accurate detection of errors in large language models (LLM) responses is central to the success of scalable oversight, or providing effective supervision to superhuman intelligence. Yet, self-diagnosis is often unreliable on complex tasks unless aided by reliable external feedback. Multi-agent debate (MAD) seems to be a natural alternative to external feedback: multiple LLMs provide complementary perspectives and cross-checks for error detection. However, prior MAD protocols frame debate as a zero-sum game, where the debaters compete to win the game instead of seeking the truth. Consequently, it leads to debate hacking: debaters tend to mislead the judge by misinterpreting the task or presenting overconfident claims, which introduce more mistakes and underperform single-agent methods. To mitigate the issue, we introduce a new collaborative MAD protocol, termed ColMAD, that reframes MAD as a non-zero sum game. Specifically, ColMAD encourages multiple agents to criticize each other in a supportive way, such that they can complement the missing points of each other. Therefore, the judge agent can make a more informative conclusion based on more comprehensive evidence. Empirically, we show that ColMAD significantly outperforms previous competitive MAD by 19% and brings non-trivial improvements over single-agent methods in error detection.",
        "tags": [
            "Detection",
            "LLM"
        ]
    },
    {
        "id": "19",
        "title": "Robust Point Cloud Reinforcement Learning via PCA-Based Canonicalization",
        "author": [
            "Michael Bezick",
            "Vittorio Giammarino",
            "Ahmed H. Qureshi"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20974",
        "abstract": "Reinforcement Learning (RL) from raw visual input has achieved impressive successes in recent years, yet it remains fragile to out-of-distribution variations such as changes in lighting, color, and viewpoint. Point Cloud Reinforcement Learning (PC-RL) offers a promising alternative by mitigating appearance-based brittleness, but its sensitivity to camera pose mismatches continues to undermine reliability in realistic settings. To address this challenge, we propose PCA Point Cloud (PPC), a canonicalization framework specifically tailored for downstream robotic control. PPC maps point clouds under arbitrary rigid-body transformations to a unique canonical pose, aligning observations to a consistent frame, thereby substantially decreasing viewpoint-induced inconsistencies. In our experiments, we show that PPC improves robustness to unseen camera poses across challenging robotic tasks, providing a principled alternative to domain randomization.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "20",
        "title": "REx86: A Local Large Language Model for Assisting in x86 Assembly Reverse Engineering",
        "author": [
            "Darrin Lea",
            "James Ghawaly",
            "Golden Richard III",
            "Aisha Ali-Gombe",
            "Andrew Case"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20975",
        "abstract": "Reverse engineering (RE) of x86 binaries is indispensable for malware and firmware analysis, but remains slow due to stripped metadata and adversarial obfuscation. Large Language Models (LLMs) offer potential for improving RE efficiency through automated comprehension and commenting, but cloud-hosted, closed-weight models pose privacy and security risks and cannot be used in closed-network facilities. We evaluate parameter-efficient fine-tuned local LLMs for assisting with x86 RE tasks in these settings. Eight open-weight models across the CodeLlama, Qwen2.5-Coder, and CodeGemma series are fine-tuned on a custom curated dataset of 5,981 x86 assembly examples. We evaluate them quantitatively and identify the fine-tuned Qwen2.5-Coder-7B as the top performer, which we name REx86.\nREx86 reduces test-set cross-entropy loss by 64.2% and improves semantic cosine similarity against ground truth by 20.3\\% over its base model. In a limited user case study (n=43), REx86 significantly enhanced line-level code understanding (p = 0.031) and increased the correct-solve rate from 31% to 53% (p = 0.189), though the latter did not reach statistical significance. Qualitative analysis shows more accurate, concise comments with fewer hallucinations.\nREx86 delivers state-of-the-art assistance in x86 RE among local, open-weight LLMs. Our findings demonstrate the value of domain-specific fine-tuning, and highlight the need for more commented disassembly data to further enhance LLM performance in RE. REx86, its dataset, and LoRA adapters are publicly available at https://github.com/dlea8/REx86 and https://zenodo.org/records/15420461.",
        "tags": [
            "LLM",
            "LoRA"
        ]
    },
    {
        "id": "21",
        "title": "L^2M^3OF: A Large Language Multimodal Model for Metal-Organic Frameworks",
        "author": [
            "Jiyu Cui",
            "Fang Wu",
            "Haokai Zhao",
            "Minggao Feng",
            "Xenophon Evangelopoulos",
            "Andrew I. Cooper",
            "Yejin Choi"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20976",
        "abstract": "Large language models have demonstrated remarkable reasoning capabilities across diverse natural language tasks. However, comparable breakthroughs in scientific discovery are more limited, because understanding complex physical phenomena demands multifaceted representations far beyond language alone. A compelling example is the design of functional materials such as MOFs-critical for a range of impactful applications like carbon capture and hydrogen storage. Navigating their vast and intricate design space in language-based representations interpretable by LLMs is challenging due to the numerous possible three-dimensional atomic arrangements and strict reticular rules of coordination geometry and topology. Despite promising early results in LLM-assisted discovery for simpler materials systems, MOF design remains heavily reliant on tacit human expertise rarely codified in textual information alone. To overcome this barrier, we introduce L2M3OF, the first multimodal LLM for MOFs. L2M3OF integrates crystal representation learning with language understanding to process structural, textual, and knowledge modalities jointly. L2M3OF employs a pre-trained crystal encoder with a lightweight projection layer to compress structural information into a token space, enabling efficient alignment with language instructions. To facilitate training and evaluation, we curate a structure-property-knowledge database of crystalline materials and benchmark L2M3OF against state-of-the-art closed-source LLMs such as GPT-5, Gemini-2.5-Pro and DeepSeek-R1. Experiments show that L2M3OF outperforms leading text-based closed-source LLMs in property prediction and knowledge generation tasks, despite using far fewer parameters. These results highlight the importance of multimodal approaches for porous material understanding and establish L2M3OF as a foundation for next-generation AI systems in materials discovery.",
        "tags": [
            "DeepSeek",
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "22",
        "title": "Learning Grouped Lattice Vector Quantizers for Low-Bit LLM Compression",
        "author": [
            "Xi Zhang",
            "Xiaolin Wu",
            "Jiamang Wang",
            "Weisi Lin"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20984",
        "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities but typically require extensive computational resources and memory for inference. Post-training quantization (PTQ) can effectively reduce these demands by storing weights in lower bit-width formats. However, standard uniform quantization often leads to notable performance degradation, particularly in low-bit scenarios. In this work, we introduce a Grouped Lattice Vector Quantization (GLVQ) framework that assigns each group of weights a customized lattice codebook, defined by a learnable generation matrix. To address the non-differentiability of the quantization process, we adopt Babai rounding to approximate nearest-lattice-point search during training, which enables stable optimization of the generation matrices. Once trained, decoding reduces to a simple matrix-vector multiplication, yielding an efficient and practical quantization pipeline. Experiments on multiple benchmarks show that our approach achieves a better trade-off between model size and accuracy compared to existing post-training quantization baselines, highlighting its effectiveness in deploying large models under stringent resource constraints. Our source code is available on GitHub repository: https://github.com/xzhang9308/GLVQ.",
        "tags": [
            "LLM",
            "Vector Quantization"
        ]
    },
    {
        "id": "23",
        "title": "GPU Memory Requirement Prediction for Deep Learning Task Based on Bidirectional Gated Recurrent Unit Optimization Transformer",
        "author": [
            "Chao Wang",
            "Zhizhao Wen",
            "Ruoxin Zhang",
            "Puyang Xu",
            "Yifan Jiang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20985",
        "abstract": "In response to the increasingly critical demand for accurate prediction of GPU memory resources in deep learning tasks, this paper deeply analyzes the current research status and innovatively proposes a deep learning model that integrates bidirectional gated recurrent units (BiGRU) to optimize the Transformer architecture, aiming to improve the accuracy of memory demand prediction. To verify the effectiveness of the model, a carefully designed comparative experiment was conducted, selecting four representative basic machine learning models: decision tree, random forest, Adaboost, and XGBoost as benchmarks. The detailed experimental results show that the BiGRU Transformer optimization model proposed in this paper exhibits significant advantages in key evaluation indicators: in terms of mean square error (MSE) and root mean square error (RMSE), the model achieves the lowest value among all comparison models, and its predicted results have the smallest deviation from the actual values; In terms of mean absolute error (MAE) and coefficient of determination (R2) indicators, the model also performs well and the results are balanced and stable, with comprehensive predictive performance far exceeding the benchmark machine learning methods compared. In summary, the Transformer model based on bidirectional gated recurrent unit optimization successfully constructed in this study can efficiently and accurately complete GPU memory demand prediction tasks in deep learning tasks, and its prediction accuracy has been significantly improved compared to traditional machine learning methods. This research provides strong technical support and reliable theoretical basis for optimizing resource scheduling and management of deep learning tasks, and improving the utilization efficiency of computing clusters.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "24",
        "title": "BioDet: Boosting Industrial Object Detection with Image Preprocessing Strategies",
        "author": [
            "Jiaqi Hu",
            "Hongli Xu",
            "Junwen Huang",
            "Peter KT Yu",
            "Slobodan Ilic",
            "Benjamin Busam"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21000",
        "abstract": "Accurate 6D pose estimation is essential for robotic manipulation in industrial environments. Existing pipelines typically rely on off-the-shelf object detectors followed by cropping and pose refinement, but their performance degrades under challenging conditions such as clutter, poor lighting, and complex backgrounds, making detection the critical bottleneck. In this work, we introduce a standardized and plug-in pipeline for 2D detection of unseen objects in industrial settings. Based on current SOTA baselines, our approach reduces domain shift and background artifacts through low-light image enhancement and background removal guided by open-vocabulary detection with foundation models. This design suppresses the false positives prevalent in raw SAM outputs, yielding more reliable detections for downstream pose estimation. Extensive experiments on real-world industrial bin-picking benchmarks from BOP demonstrate that our method significantly boosts detection accuracy while incurring negligible inference overhead, showing the effectiveness and practicality of the proposed method.",
        "tags": [
            "Detection",
            "Pose Estimation",
            "SAM"
        ]
    },
    {
        "id": "25",
        "title": "Can Confidence Estimates Decide When Chain-of-thought is Necessary for Llms?",
        "author": [
            "Samuel Lewis-Lim",
            "Xingwei Tan",
            "Zhixue Zhao",
            "Nikolaos Aletras"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21007",
        "abstract": "Chain-of-thought (CoT) prompting has emerged as a common technique for enhancing the reasoning abilities of large language models (LLMs). While extended reasoning can boost accuracy on complex tasks, it is often unnecessary and substantially increases token usage, limiting the practicality of reasoning models in many scenarios. Recent models, such as GPT-OSS and Qwen3, expose controls that enable users to adjust the length of CoT or determine whether it is used at all. Yet, it remains unclear when CoT should be used: on some tasks it improves performance, while on others it provides little benefit or even harms performance. We address this challenge with confidence-gated CoT, where a model invokes reasoning only when confidence in its direct answer is low. To this end, we present the first systematic study of training-free confidence estimation methods for CoT gating. Specifically, we evaluate four training-free confidence estimation methods and compare them to a random baseline and an oracle that always knows when CoT is needed. Through extensive experiments, we show that existing training-free confidence measures can reduce redundant CoT and outperform randomly invoked CoT. However, the utility of individual confidence measures is inconsistent, varying with both the dataset and the model, underscoring the difficulty of deploying confidence-gated CoT in practice. By analysing both strengths and failure modes, our study highlights the potential and limitations of current methods and paves the way toward more reliable adaptive gating of CoT.",
        "tags": [
            "CoT",
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "26",
        "title": "Race and Gender in LLM-Generated Personas: A Large-Scale Audit of 41 Occupations",
        "author": [
            "Ilona van der Linden",
            "Sahana Kumar",
            "Arnav Dixit",
            "Aadi Sudan",
            "Smruthi Danda",
            "David C. Anastasiu",
            "Kai Lukoff"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21011",
        "abstract": "Generative AI tools are increasingly used to create portrayals of people in occupations, raising concerns about how race and gender are represented. We conducted a large-scale audit of over 1.5 million occupational personas across 41 U.S. occupations, generated by four large language models with different AI safety commitments and countries of origin (U.S., China, France). Compared with Bureau of Labor Statistics data, we find two recurring patterns: systematic shifts, where some groups are consistently under- or overrepresented, and stereotype exaggeration, where existing demographic skews are amplified. On average, White (--31pp) and Black (--9pp) workers are underrepresented, while Hispanic (+17pp) and Asian (+12pp) workers are overrepresented. These distortions can be extreme: for example, across all four models, Housekeepers are portrayed as nearly 100\\% Hispanic, while Black workers are erased from many occupations. For HCI, these findings show provider choice materially changes who is visible, motivating model-specific audits and accountable design practices.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "27",
        "title": "Physically consistent and uncertainty-aware learning of spatiotemporal dynamics",
        "author": [
            "Qingsong Xu",
            "Jonathan L Bamber",
            "Nils Thuerey",
            "Niklas Boers",
            "Paul Bates",
            "Gustau Camps-Valls",
            "Yilei Shi",
            "Xiao Xiang Zhu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21023",
        "abstract": "Accurate long-term forecasting of spatiotemporal dynamics remains a fundamental challenge across scientific and engineering domains. Existing machine learning methods often neglect governing physical laws and fail to quantify inherent uncertainties in spatiotemporal predictions. To address these challenges, we introduce a physics-consistent neural operator (PCNO) that enforces physical constraints by projecting surrogate model outputs onto function spaces satisfying predefined laws. A physics-consistent projection layer within PCNO efficiently computes mass and momentum conservation in Fourier space. Building upon deterministic predictions, we further propose a diffusion model-enhanced PCNO (DiffPCNO), which leverages a consistency model to quantify and mitigate uncertainties, thereby improving the accuracy and reliability of forecasts. PCNO and DiffPCNO achieve high-fidelity spatiotemporal predictions while preserving physical consistency and uncertainty across diverse systems and spatial resolutions, ranging from turbulent flow modeling to real-world flood/atmospheric forecasting. Our two-stage framework provides a robust and versatile approach for accurate, physically grounded, and uncertainty-aware spatiotemporal forecasting.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "28",
        "title": "HRT1: One-Shot Human-to-Robot Trajectory Transfer for Mobile Manipulation",
        "author": [
            "Sai Haneesh Allu",
            "Jishnu Jaykumar P",
            "Ninad Khargonkar",
            "Tyler Summers",
            "Jian Yao",
            "Yu Xiang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21026",
        "abstract": "We introduce a novel system for human-to-robot trajectory transfer that enables robots to manipulate objects by learning from human demonstration videos. The system consists of four modules. The first module is a data collection module that is designed to collect human demonstration videos from the point of view of a robot using an AR headset. The second module is a video understanding module that detects objects and extracts 3D human-hand trajectories from demonstration videos. The third module transfers a human-hand trajectory into a reference trajectory of a robot end-effector in 3D space. The last module utilizes a trajectory optimization algorithm to solve a trajectory in the robot configuration space that can follow the end-effector trajectory transferred from the human demonstration. Consequently, these modules enable a robot to watch a human demonstration video once and then repeat the same mobile manipulation task in different environments, even when objects are placed differently from the demonstrations. Experiments of different manipulation tasks are conducted on a mobile manipulator to verify the effectiveness of our system",
        "tags": [
            "3D",
            "Robotics"
        ]
    },
    {
        "id": "29",
        "title": "Customizing Open Source LLMs for Quantitative Medication Attribute Extraction across Heterogeneous EHR Systems",
        "author": [
            "Zhe Fei",
            "Mehmet Yigit Turali",
            "Shreyas Rajesh",
            "Xinyang Dai",
            "Huyen Pham",
            "Pavan Holur",
            "Yuhui Zhu",
            "Larissa Mooney",
            "Yih-Ing Hser",
            "Vwani Roychowdhury"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21027",
        "abstract": "Harmonizing medication data across Electronic Health Record (EHR) systems is a persistent barrier to monitoring medications for opioid use disorder (MOUD). In heterogeneous EHR systems, key prescription attributes are scattered across differently formatted fields and freetext notes. We present a practical framework that customizes open source large language models (LLMs), including Llama, Qwen, Gemma, and MedGemma, to extract a unified set of MOUD prescription attributes (prescription date, drug name, duration, total quantity, daily quantity, and refills) from heterogeneous, site specific data and compute a standardized metric of medication coverage, \\emph{MOUD days}, per patient. Our pipeline processes records directly in a fixed JSON schema, followed by lightweight normalization and cross-field consistency checks. We evaluate the system on prescription level EHR data from five clinics in a national OUD study (25{,}605 records from 1{,}257 patients), using a previously annotated benchmark of 10{,}369 records (776 patients) as the ground truth. Performance is reported as coverage (share of records with a valid, matchable output) and record-level exact-match accuracy. Larger models perform best overall: Qwen2.5-32B achieves \\textbf{93.4\\%} coverage with \\textbf{93.0\\%} exact-match accuracy across clinics, and MedGemma-27B attains \\textbf{93.1\\%}/\\textbf{92.2\\%}. A brief error review highlights three common issues and fixes: imputing missing dosage fields using within-drug norms, handling monthly/weekly injectables (e.g., Vivitrol) by setting duration from the documented schedule, and adding unit checks to prevent mass units (e.g., ``250 g'') from being misread as daily counts. By removing brittle, site-specific ETL and supporting local, privacy-preserving deployment, this approach enables consistent cross-site analyses of MOUD exposure, adherence, and retention in real-world settings.",
        "tags": [
            "LLM",
            "LLaMA",
            "Qwen"
        ]
    },
    {
        "id": "30",
        "title": "Input Matters: Evaluating Input Structure's Impact on LLM Summaries of Sports Play-by-Play",
        "author": [
            "Barkavi Sundararajan",
            "Somayajulu Sripada",
            "Ehud Reiter"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21034",
        "abstract": "A major concern when deploying LLMs in accuracy-critical domains such as sports reporting is that the generated text may not faithfully reflect the input data. We quantify how input structure affects hallucinations and other factual errors in LLM-generated summaries of NBA play-by-play data, across three formats: row-structured, JSON and unstructured. We manually annotated 3,312 factual errors across 180 game summaries produced by two models, Llama-3.1-70B and Qwen2.5-72B. Input structure has a strong effect: JSON input reduces error rates by 69% for Llama and 65% for Qwen compared to unstructured input, while row-structured input reduces errors by 54% for Llama and 51% for Qwen. A two-way repeated measures ANOVA shows that input structure accounts for over 80% of the variance in error rates, with Tukey HSD post hoc tests confirming statistically significant differences between all input formats.",
        "tags": [
            "LLM",
            "LLaMA",
            "Qwen"
        ]
    },
    {
        "id": "31",
        "title": "Reasoning's Razor: Reasoning Improves Accuracy but Can Hurt Recall at Critical Operating Points in Safety and Hallucination Detection",
        "author": [
            "Atoosa Chegini",
            "Hamid Kazemi",
            "Garrett Souza",
            "Maria Safi",
            "Yang Song",
            "Samy Bengio",
            "Sinead Williamson",
            "Mehrdad Farajtabar"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21049",
        "abstract": "Reasoning has become a central paradigm for large language models (LLMs), consistently boosting accuracy across diverse benchmarks. Yet its suitability for precision-sensitive tasks remains unclear. We present the first systematic study of reasoning for classification tasks under strict low false positive rate (FPR) regimes. Our analysis covers two tasks--safety detection and hallucination detection--evaluated in both fine-tuned and zero-shot settings, using standard LLMs and Large Reasoning Models (LRMs). Our results reveal a clear trade-off: Think On (reasoning-augmented) generation improves overall accuracy, but underperforms at the low-FPR thresholds essential for practical use. In contrast, Think Off (no reasoning during inference) dominates in these precision-sensitive regimes, with Think On surpassing only when higher FPRs are acceptable. In addition, we find token-based scoring substantially outperforms self-verbalized confidence for precision-sensitive deployments. Finally, a simple ensemble of the two modes recovers the strengths of each. Taken together, our findings position reasoning as a double-edged tool: beneficial for average accuracy, but often ill-suited for applications requiring strict precision.",
        "tags": [
            "Detection",
            "LLM"
        ]
    },
    {
        "id": "32",
        "title": "Soft Instruction De-escalation Defense",
        "author": [
            "Nils Philipp Walter",
            "Chawin Sitawarin",
            "Jamie Hayes",
            "David Stutz",
            "Ilia Shumailov"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21057",
        "abstract": "Large Language Models (LLMs) are increasingly deployed in agentic systems that interact with an external environment; this makes them susceptible to prompt injections when dealing with untrusted data. To overcome this limitation, we propose SIC (Soft Instruction Control)-a simple yet effective iterative prompt sanitization loop designed for tool-augmented LLM agents. Our method repeatedly inspects incoming data for instructions that could compromise agent behavior. If such content is found, the malicious content is rewritten, masked, or removed, and the result is re-evaluated. The process continues until the input is clean or a maximum iteration limit is reached; if imperative instruction-like content remains, the agent halts to ensure security. By allowing multiple passes, our approach acknowledges that individual rewrites may fail but enables the system to catch and correct missed injections in later steps. Although immediately useful, worst-case analysis shows that SIC is not infallible; strong adversary can still get a 15% ASR by embedding non-imperative workflows. This nonetheless raises the bar.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "33",
        "title": "Dynamic Retriever for In-Context Knowledge Editing via Policy Optimization",
        "author": [
            "Mahmud Wasif Nafee",
            "Maiqi Jiang",
            "Haipeng Chen",
            "Yanfu Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21059",
        "abstract": "Large language models (LLMs) excel at factual recall yet still propagate stale or incorrect knowledge. In-context knowledge editing offers a gradient-free remedy suitable for black-box APIs, but current editors rely on static demonstration sets chosen by surface-level similarity, leading to two persistent obstacles: (i) a quantity-quality trade-off, and (ii) lack of adaptivity to task difficulty. We address these issues by dynamically selecting supporting demonstrations according to their utility for the edit. We propose Dynamic Retriever for In-Context Knowledge Editing (DR-IKE), a lightweight framework that (1) trains a BERT retriever with REINFORCE to rank demonstrations by editing reward, and (2) employs a learnable threshold to prune low-value examples, shortening the prompt when the edit is easy and expanding it when the task is hard. DR-IKE performs editing without modifying model weights, relying solely on forward passes for compatibility with black-box LLMs. On the COUNTERFACT benchmark, it improves edit success by up to 17.1%, reduces latency by 41.6%, and preserves accuracy on unrelated queries, demonstrating scalable and adaptive knowledge editing. The code is available at https://github.com/mwnafee/DR-IKE .",
        "tags": [
            "BERT",
            "LLM"
        ]
    },
    {
        "id": "34",
        "title": "On the Sample Complexity of Differentially Private Policy Optimization",
        "author": [
            "Yi He",
            "Xingyu Zhou"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21060",
        "abstract": "Policy optimization (PO) is a cornerstone of modern reinforcement learning (RL), with diverse applications spanning robotics, healthcare, and large language model training. The increasing deployment of PO in sensitive domains, however, raises significant privacy concerns. In this paper, we initiate a theoretical study of differentially private policy optimization, focusing explicitly on its sample complexity. We first formalize an appropriate definition of differential privacy (DP) tailored to PO, addressing the inherent challenges arising from on-policy learning dynamics and the subtlety involved in defining the unit of privacy. We then systematically analyze the sample complexity of widely-used PO algorithms, including policy gradient (PG), natural policy gradient (NPG) and more, under DP constraints and various settings, via a unified framework. Our theoretical results demonstrate that privacy costs can often manifest as lower-order terms in the sample complexity, while also highlighting subtle yet important observations in private PO settings. These offer valuable practical insights for privacy-preserving PO algorithms.",
        "tags": [
            "RL",
            "Robotics"
        ]
    },
    {
        "id": "35",
        "title": "The Virtues of Brevity: Avoid Overthinking in Parallel Test-Time Reasoning",
        "author": [
            "Raul Cavalcante Dinardi",
            "Bruno Yamamoto",
            "Anna Helena Reali Costa",
            "Artur Jordao"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21067",
        "abstract": "Reasoning models represent a significant advance in LLM capabilities, particularly for complex reasoning tasks such as mathematics and coding. Previous studies confirm that parallel test-time compute-sampling multiple solutions and selecting the best one-can further enhance the predictive performance of LLMs. However, strategies in this area often require complex scoring, thus increasing computational cost and complexity. In this work, we demonstrate that the simple and counterintuitive heuristic of selecting the shortest solution is highly effective. We posit that the observed effectiveness stems from models operating in two distinct regimes: a concise, confident conventional regime and a verbose overthinking regime characterized by uncertainty, and we show evidence of a critical point where the overthinking regime begins to be significant. By selecting the shortest answer, the heuristic preferentially samples from the conventional regime. We confirm that this approach is competitive with more complex methods such as self-consistency across two challenging benchmarks while significantly reducing computational overhead. The shortest-answer heuristic provides a Pareto improvement over self-consistency and applies even to tasks where output equality is not well defined.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "36",
        "title": "ZING-3D: Zero-shot Incremental 3D Scene Graphs via Vision-Language Models",
        "author": [
            "Pranav Saxena",
            "Jimmy Chiun"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21069",
        "abstract": "Understanding and reasoning about complex 3D environments requires structured scene representations that capture not only objects but also their semantic and spatial relationships. While recent works on 3D scene graph generation have leveraged pretrained VLMs without task-specific fine-tuning, they are largely confined to single-view settings, fail to support incremental updates as new observations arrive and lack explicit geometric grounding in 3D space, all of which are essential for embodied scenarios. In this paper, we propose, ZING-3D, a framework that leverages the vast knowledge of pretrained foundation models to enable open-vocabulary recognition and generate a rich semantic representation of the scene in a zero-shot manner while also enabling incremental updates and geometric grounding in 3D space, making it suitable for downstream robotics applications. Our approach leverages VLM reasoning to generate a rich 2D scene graph, which is grounded in 3D using depth information. Nodes represent open-vocabulary objects with features, 3D locations, and semantic context, while edges capture spatial and semantic relations with inter-object distances. Our experiments on scenes from the Replica and HM3D dataset show that ZING-3D is effective at capturing spatial and relational knowledge without the need of task-specific training.",
        "tags": [
            "3D",
            "Robotics",
            "VLM"
        ]
    },
    {
        "id": "37",
        "title": "Revisiting Replanning from Scratch: Real-Time Incremental Planning with Fast Almost-Surely Asymptotically Optimal Planners",
        "author": [
            "Mitchell E. C. Sabbadini",
            "Andrew H. Liu",
            "Joseph Ruan",
            "Tyler S. Wilson",
            "Zachary Kingston",
            "Jonathan D. Gammell"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21074",
        "abstract": "Robots operating in changing environments either predict obstacle changes and/or plan quickly enough to react to them. Predictive approaches require a strong prior about the position and motion of obstacles. Reactive approaches require no assumptions about their environment but must replan quickly and find high-quality paths to navigate effectively.\nReactive approaches often reuse information between queries to reduce planning cost. These techniques are conceptually sound but updating dense planning graphs when information changes can be computationally prohibitive. It can also require significant effort to detect the changes in some applications.\nThis paper revisits the long-held assumption that reactive replanning requires updating existing plans. It shows that the incremental planning problem can alternatively be solved more efficiently as a series of independent problems using fast almost-surely asymptotically optimal (ASAO) planning algorithms. These ASAO algorithms quickly find an initial solution and converge towards an optimal solution which allows them to find consistent global plans in the presence of changing obstacles without requiring explicit plan reuse. This is demonstrated with simulated experiments where Effort Informed Trees (EIT*) finds shorter median solution paths than the tested reactive planning algorithms and is further validated using Asymptotically Optimal RRT-Connect (AORRTC) on a real-world planning problem on a robot arm.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "38",
        "title": "WaveSeg: Enhancing Segmentation Precision via High-Frequency Prior and Mamba-Driven Spectrum Decomposition",
        "author": [
            "Guoan Xu",
            "Yang Xiao",
            "Wenjing Jia",
            "Guangwei Gao",
            "Guo-Jun Qi",
            "Chia-Wen Lin"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21079",
        "abstract": "While recent semantic segmentation networks heavily rely on powerful pretrained encoders, most employ simplistic decoders, leading to suboptimal trade-offs between semantic context and fine-grained detail preservation. To address this, we propose a novel decoder architecture, WaveSeg, which jointly optimizes feature refinement in spatial and wavelet domains. Specifically, high-frequency components are first learned from input images as explicit priors to reinforce boundary details at early stages. A multi-scale fusion mechanism, Dual Domain Operation (DDO), is then applied, and the novel Spectrum Decomposition Attention (SDA) block is proposed, which is developed to leverage Mamba's linear-complexity long-range modeling to enhance high-frequency structural details. Meanwhile, reparameterized convolutions are applied to preserve low-frequency semantic integrity in the wavelet domain. Finally, a residual-guided fusion integrates multi-scale features with boundary-aware representations at native resolution, producing semantically and structurally rich feature maps. Extensive experiments on standard benchmarks demonstrate that WaveSeg, leveraging wavelet-domain frequency prior with Mamba-based attention, consistently outperforms state-of-the-art approaches both quantitatively and qualitatively, achieving efficient and precise segmentation.",
        "tags": [
            "Mamba",
            "Segmentation"
        ]
    },
    {
        "id": "39",
        "title": "Designing and Evaluating Hint Generation Systems for Science Education",
        "author": [
            "Anubhav Jangra",
            "Smaranda Muresan"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21087",
        "abstract": "Large language models are influencing the education landscape, with students relying on them in their learning process. Often implemented using general-purpose models, these systems are likely to give away the answers, which could hinder conceptual understanding and critical thinking. We study the role of automatic hint generation as a pedagogical strategy to promote active engagement with the learning content, while guiding learners toward the answers. Focusing on scientific topics at the secondary education level, we explore the potential of large language models to generate chains of hints that scaffold learners without revealing answers. We compare two distinct hinting strategies: static hints, pre-generated for each problem, and dynamic hints, adapted to learners' progress. Through a quantitative study with 41 participants, we uncover different preferences among learners with respect to hinting strategies, and identify the limitations of automatic evaluation metrics to capture them. Our findings highlight key design considerations for future research on hint generation and intelligent tutoring systems that seek to develop learner-centered educational technologies.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "40",
        "title": "Self-Rewarding PPO: Aligning Large Language Models with Demonstrations Only",
        "author": [
            "Qingru Zhang",
            "Liang Qiu",
            "Ilgee Hong",
            "Zhenghao Xu",
            "Tianyi Liu",
            "Shiyang Li",
            "Rongzhi Zhang",
            "Zheng Li",
            "Lihong Li",
            "Bing Yin",
            "Chao Zhang",
            "Jianshu Chen",
            "Haoming Jiang",
            "Tuo Zhao"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21090",
        "abstract": "Supervised fine-tuning (SFT) has emerged as a crucial method for aligning large language models (LLMs) with human-annotated demonstrations. However, SFT, being an off-policy approach similar to behavior cloning, often struggles with overfitting and poor out-of-domain generalization, especially in limited-data scenarios. To address these limitations, we propose Self-Rewarding PPO, a novel fine-tuning method that leverages on-policy techniques to enhance generalization performance. Our approach combines the strengths of SFT and proximal policy optimization (PPO) to achieve more effective alignment from demonstration data. At its core is a reward function designed as the log policy ratio between the SFT model and the pretrained base model. This function serves as an implicit reward signal, using the pretrained policy as a baseline and the SFT policy as a target. By doing so, it enables on-policy fine-tuning without relying on human preference annotations. The integration of this self-rewarding mechanism with PPO addresses key limitations of SFT, improving generalization, data efficiency, and robustness. Our empirical evaluation across a range of natural language processing tasks demonstrates that Self-Rewarding PPO consistently outperforms traditional SFT methods. The results highlight the effectiveness of our approach in aligning LLMs using demonstration data, particularly in scenarios where high-quality annotated data is scarce.",
        "tags": [
            "LLM",
            "PPO"
        ]
    },
    {
        "id": "41",
        "title": "BDiff: Block-aware and Accurate Text-based Code Differencing",
        "author": [
            "Yao Lu",
            "Wanwei Liu",
            "Tanghaoran Zhang",
            "Kang Yang",
            "Yang Zhang",
            "Wenyu Xu",
            "Longfei Sun",
            "Xinjun Mao",
            "Shuzheng Gao",
            "Michael R. Lyu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21094",
        "abstract": "Code differencing is a fundamental technique in software engineering practice and research. While researchers have proposed text-based differencing techniques capable of identifying line changes over the past decade, existing methods exhibit a notable limitation in identifying edit actions (EAs) that operate on text blocks spanning multiple lines. Such EAs are common in developers' practice, such as moving a code block for conditional branching or duplicating a method definition block for overloading. Existing tools represent such block-level operations as discrete sequences of line-level EAs, compelling developers to manually correlate them and thereby substantially impeding the efficiency of change comprehension. To address this issue, we propose BDiff, a text-based differencing algorithm capable of identifying two types of block-level EAs and five types of line-level EAs. Building on traditional differencing algorithms, we first construct a candidate set containing all possible line mappings and block mappings. Leveraging the Kuhn-Munkres algorithm, we then compute the optimal mapping set that can minimize the size of the edit script (ES) while closely aligning with the original developer's intent. To validate the effectiveness of BDiff, we selected five state-of-the-art tools, including large language models (LLMs), as baselines and adopted a combined qualitative and quantitative approach to evaluate their performance in terms of ES size, result quality, and running time. Experimental results show that BDiff produces higher-quality differencing results than baseline tools while maintaining competitive runtime performance. Our experiments also show the unreliability of LLMs in code differencing tasks regarding result quality and their infeasibility in terms of runtime efficiency. We have implemented a web-based visual differencing tool.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "42",
        "title": "Sensing and Storing Less: A MARL-based Solution for Energy Saving in Edge Internet of Things",
        "author": [
            "Zongyang Yuan",
            "Lailong Luo",
            "Qianzhen Zhang",
            "Bangbang Ren",
            "Deke Guo",
            "Richard T.B. Ma"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21103",
        "abstract": "As the number of Internet of Things (IoT) devices continuously grows and application scenarios constantly enrich, the volume of sensor data experiences an explosive increase. However, substantial data demands considerable energy during computation and transmission. Redundant deployment or mobile assistance is essential to cover the target area reliably with fault-prone sensors. Consequently, the ``butterfly effect\" may appear during the IoT operation, since unreasonable data overlap could result in many duplicate data. To this end, we propose Senses, a novel online energy saving solution for edge IoT networks, with the insight of sensing and storing less at the network edge by adopting Muti-Agent Reinforcement Learning (MARL). Senses achieves data de-duplication by dynamically adjusting sensor coverage at the sensor level. For exceptional cases where sensor coverage cannot be altered, Senses conducts data partitioning and eliminates redundant data at the controller level. Furthermore, at the global level, considering the heterogeneity of IoT devices, Senses balances the operational duration among the devices to prolong the overall operational duration of edge IoT networks. We evaluate the performance of Senses through testbed experiments and simulations. The results show that Senses saves 11.37% of energy consumption on control devices and prolongs 20% overall operational duration of the IoT device network.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "43",
        "title": "R2ComSync: Improving Code-Comment Synchronization with In-Context Learning and Reranking",
        "author": [
            "Zhen Yang",
            "Hongyi Lin",
            "Xiao Yu",
            "Jacky Wai Keung",
            "Shuo Liu",
            "Pak Yuen Patrick Chan",
            "Yicheng Sun",
            "Fengji Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21106",
        "abstract": "Code-Comment Synchronization (CCS) aims to synchronize the comments with code changes in an automated fashion, thereby significantly reducing the workload of developers during software maintenance and evolution. While previous studies have proposed various solutions that have shown success, they often exhibit limitations, such as a lack of generalization ability or the need for extensive task-specific learning resources. This motivates us to investigate the potential of Large Language Models (LLMs) in this area. However, a pilot analysis proves that LLMs fall short of State-Of-The-Art (SOTA) CCS approaches because (1) they lack instructive demonstrations for In-Context Learning (ICL) and (2) many correct-prone candidates are not http://prioritized.To tackle the above challenges, we propose R2ComSync, an ICL-based code-Comment Synchronization approach enhanced with Retrieval and Re-ranking. Specifically, R2ComSync carries corresponding two novelties: (1) Ensemble hybrid retrieval. It equally considers the similarity in both code-comment semantics and change patterns when retrieval, thereby creating ICL prompts with effective examples. (2) Multi-turn re-ranking strategy. We derived three significant rules through large-scale CCS sample analysis. Given the inference results of LLMs, it progressively exploits three re-ranking rules to prioritize relatively correct-prone candidates. We evaluate R2ComSync using five recent LLMs on three CCS datasets covering both Java and Python programming languages, and make comparisons with five SOTA approaches. Extensive experiments demonstrate the superior performance of R2ComSync against other approaches. Moreover, both quantitative and qualitative analyses provide compelling evidence that the comments synchronized by our proposal exhibit significantly higher quality.}",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "44",
        "title": "Confounding Robust Deep Reinforcement Learning: A Causal Approach",
        "author": [
            "Mingxuan Li",
            "Junzhe Zhang",
            "Elias Bareinboim"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21110",
        "abstract": "A key task in Artificial Intelligence is learning effective policies for controlling agents in unknown environments to optimize performance measures. Off-policy learning methods, like Q-learning, allow learners to make optimal decisions based on past experiences. This paper studies off-policy learning from biased data in complex and high-dimensional domains where \\emph{unobserved confounding} cannot be ruled out a priori. Building on the well-celebrated Deep Q-Network (DQN), we propose a novel deep reinforcement learning algorithm robust to confounding biases in observed data. Specifically, our algorithm attempts to find a safe policy for the worst-case environment compatible with the observations. We apply our method to twelve confounded Atari games, and find that it consistently dominates the standard DQN in all games where the observed input to the behavioral and target policies mismatch and unobserved confounders exist.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "45",
        "title": "PhysVLM-AVR: Active Visual Reasoning for Multimodal Large Language Models in Physical Environments",
        "author": [
            "Weijie Zhou",
            "Xuantang Xiong",
            "Yi Peng",
            "Manli Tao",
            "Chaoyang Zhao",
            "Honghui Dong",
            "Ming Tang",
            "Jinqiao Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21111",
        "abstract": "Visual reasoning in multimodal large language models (MLLMs) has primarily been studied in static, fully observable settings, limiting their effectiveness in real-world environments where information is often incomplete due to occlusion or limited field of view. Humans, in contrast, actively explore and interact with their environment-moving, examining, and manipulating objects-to gather information through a closed-loop process integrating perception, reasoning, and action. Inspired by this human capability, we introduce the Active Visual Reasoning (AVR) task, extending visual reasoning to partially observable, interactive environments. AVR necessitates agents to: (1) actively acquire information via sequential physical actions, (2) integrate observations across multiple steps for coherent reasoning, and (3) dynamically adjust decisions based on evolving visual feedback. To rigorously evaluate AVR, we introduce CLEVR-AVR, a simulation benchmark featuring multi-round interactive environments designed to assess both reasoning correctness and information-gathering efficiency. We present AVR-152k, a large-scale dataset that offers rich Chain-of-Thought (CoT) annotations detailing iterative reasoning for uncertainty identification, action-conditioned information gain prediction, and information-maximizing action selection, crucial for training agents in a higher-order Markov Decision Process. Building on this, we develop PhysVLM-AVR, an MLLM achieving state-of-the-art performance on CLEVR-AVR, embodied reasoning (OpenEQA, RoboVQA), and passive visual reasoning (GeoMath, Geometry30K). Our analysis also reveals that current embodied MLLMs, despite detecting information incompleteness, struggle to actively acquire and integrate new information through interaction, highlighting a fundamental gap in active reasoning capabilities.",
        "tags": [
            "CoT",
            "LLM"
        ]
    },
    {
        "id": "46",
        "title": "Controllable-LPMoE: Adapting to Challenging Object Segmentation via Dynamic Local Priors from Mixture-of-Experts",
        "author": [
            "Yanguang Sun",
            "Jiawei Lian",
            "Jian Yang",
            "Lei Luo"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21114",
        "abstract": "Large-scale foundation models provide powerful feature representations for downstream object segmentation tasks. However, when adapted to specific tasks through the full-parameter fine-tuning, the enormous parameters being updated often results in significant computational overhead, creating a bottleneck in training efficiency. Although existing methods attempt to fine-tune frozen models by directly embedding trainable prompts, these prompts lack inherent semantic priors, limiting the adaptability of large-scale models. In this paper, we propose a novel dynamic priors-based fine-tuning paradigm with fewer trainable parameters, dubbed Controllable-LPMoE, which adaptively modulates frozen foundation models by dynamically controlling local priors to enhance fine-grained perception for specific segmentation tasks. More specifically, we construct a lightweight dynamic mixed local priors extractor that captures diverse local priors from input images through heterogeneous convolutions while employing a gating network to dynamically output expert priors required for the subsequent fine-tuning. Furthermore, we design a bi-directional interaction adapter that employs cosine-aligned deformable attention and channel-oriented adaptive scale enhancement to interact and restructure between frozen and trainable features, achieving efficient fine-tuning. Extensive experiments validate the superiority of our \\href{https://github.com/CSYSI/Controllable-LPMoE} {Controllable-LPMoE} approach, demonstrating excellent segmentation performance compared to 31 state-of-the-art (SOTA) methods and adaptability to multiple binary object segmentation tasks.",
        "tags": [
            "MoE",
            "Segmentation"
        ]
    },
    {
        "id": "47",
        "title": "The Gray Zone of Faithfulness: Taming Ambiguity in Unfaithfulness Detection",
        "author": [
            "Qiang Ding",
            "Lvzhou Luo",
            "Yixuan Cao",
            "Ping Luo"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21118",
        "abstract": "Ensuring that Large Language Models (LLMs) generate summaries faithful to a given source document is essential for real-world applications. While prior research has explored LLM faithfulness, existing benchmarks suffer from annotation ambiguity, primarily due to the ill-defined boundary of permissible external knowledge in generated outputs. For instance, common sense is often incorporated into responses and labeled as \"faithful\", yet the acceptable extent of such knowledge remains unspecified, leading to inconsistent annotations. To address this issue, we propose a novel faithfulness annotation framework, which introduces an intermediate category, Out-Dependent, to classify cases where external knowledge is required for verification. Using this framework, we construct VeriGray (Verification with the Gray Zone) -- a new unfaithfulness detection benchmark in summarization. Statistics reveal that even SOTA LLMs, such as GPT-5, exhibit hallucinations ($\\sim 6\\%$ of sentences) in summarization tasks. Moreover, a substantial proportion ($\\sim 8\\%$ on average of models) of generated sentences fall into the Out-Dependent category, underscoring the importance of resolving annotation ambiguity in unfaithfulness detection benchmarks. Experiments demonstrate that our benchmark poses significant challenges to multiple baseline methods, indicating considerable room for future improvement.",
        "tags": [
            "Detection",
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "48",
        "title": "SafetyPairs: Isolating Safety Critical Image Features with Counterfactual Image Generation",
        "author": [
            "Alec Helbling",
            "Shruti Palaskar",
            "Kundan Krishna",
            "Polo Chau",
            "Leon Gatys",
            "Joseph Yitan Cheng"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21120",
        "abstract": "What exactly makes a particular image unsafe? Systematically differentiating between benign and problematic images is a challenging problem, as subtle changes to an image, such as an insulting gesture or symbol, can drastically alter its safety implications. However, existing image safety datasets are coarse and ambiguous, offering only broad safety labels without isolating the specific features that drive these differences. We introduce SafetyPairs, a scalable framework for generating counterfactual pairs of images, that differ only in the features relevant to the given safety policy, thus flipping their safety label. By leveraging image editing models, we make targeted changes to images that alter their safety labels while leaving safety-irrelevant details unchanged. Using SafetyPairs, we construct a new safety benchmark, which serves as a powerful source of evaluation data that highlights weaknesses in vision-language models' abilities to distinguish between subtly different images. Beyond evaluation, we find our pipeline serves as an effective data augmentation strategy that improves the sample efficiency of training lightweight guard models. We release a benchmark containing over 3,020 SafetyPair images spanning a diverse taxonomy of 9 safety categories, providing the first systematic resource for studying fine-grained image safety distinctions.",
        "tags": [
            "Image Editing",
            "VLM"
        ]
    },
    {
        "id": "49",
        "title": "Generalizable Hierarchical Skill Learning via Object-Centric Representation",
        "author": [
            "Haibo Zhao",
            "Yu Qi",
            "Boce Hu",
            "Yizhe Zhu",
            "Ziyan Chen",
            "Heng Tian",
            "Xupeng Zhu",
            "Owen Howell",
            "Haojie Huang",
            "Robin Walters",
            "Dian Wang",
            "Robert Platt"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21121",
        "abstract": "We present Generalizable Hierarchical Skill Learning (GSL), a novel framework for hierarchical policy learning that significantly improves policy generalization and sample efficiency in robot manipulation. One core idea of GSL is to use object-centric skills as an interface that bridges the high-level vision-language model and the low-level visual-motor policy. Specifically, GSL decomposes demonstrations into transferable and object-canonicalized skill primitives using foundation models, ensuring efficient low-level skill learning in the object frame. At test time, the skill-object pairs predicted by the high-level agent are fed to the low-level module, where the inferred canonical actions are mapped back to the world frame for execution. This structured yet flexible design leads to substantial improvements in sample efficiency and generalization of our method across unseen spatial arrangements, object appearances, and task compositions. In simulation, GSL trained with only 3 demonstrations per task outperforms baselines trained with 30 times more data by 15.5 percent on unseen tasks. In real-world experiments, GSL also surpasses the baseline trained with 10 times more data.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "50",
        "title": "NoisyGRPO: Incentivizing Multimodal CoT Reasoning via Noise Injection and Bayesian Estimation",
        "author": [
            "Longtian Qiu",
            "Shan Ning",
            "Jiaxuan Sun",
            "Xuming He"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21122",
        "abstract": "Reinforcement learning (RL) has shown promise in enhancing the general Chain-of-Thought (CoT) reasoning capabilities of multimodal large language models (MLLMs). However, when applied to improve general CoT reasoning, existing RL frameworks often struggle to generalize beyond the training distribution. To address this, we propose NoisyGRPO, a systematic multimodal RL framework that introduces controllable noise into visual inputs for enhanced exploration and explicitly models the advantage estimation process via a Bayesian framework. Specifically, NoisyGRPO improves RL training by: (1) \\textbf{Noise-Injected Exploration Policy}: Perturbing visual inputs with Gaussian noise to encourage exploration across a wider range of visual scenarios; and (2) \\textbf{Bayesian Advantage Estimation}: Formulating advantage estimation as a principled Bayesian inference problem, where the injected noise level serves as a prior and the observed trajectory reward as the likelihood. This Bayesian modeling fuses both sources of information to compute a robust posterior estimate of trajectory advantage, effectively guiding MLLMs to prefer visually grounded trajectories over noisy ones. Experiments on standard CoT quality, general capability, and hallucination benchmarks demonstrate that NoisyGRPO substantially improves generalization and robustness, especially in RL settings with small-scale MLLMs such as Qwen2.5-VL 3B. The project page is available at \\href{https://artanic30.github.io/project_pages/NoisyGRPO/}{\\texttt{https://artanic30.github.io/project\\_pages/NoisyGRPO}}.",
        "tags": [
            "CoT",
            "LLM",
            "RL"
        ]
    },
    {
        "id": "51",
        "title": "Enhanced Evolutionary Multi-Objective Deep Reinforcement Learning for Reliable and Efficient Wireless Rechargeable Sensor Networks",
        "author": [
            "Bowei Tong",
            "Hui Kang",
            "Jiahui Li",
            "Geng Sun",
            "Jiacheng Wang",
            "Yaoqi Yang",
            "Bo Xu",
            "Dusit Niyato"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21127",
        "abstract": "Despite rapid advancements in sensor networks, conventional battery-powered sensor networks suffer from limited operational lifespans and frequent maintenance requirements that severely constrain their deployment in remote and inaccessible environments. As such, wireless rechargeable sensor networks (WRSNs) with mobile charging capabilities offer a promising solution to extend network lifetime. However, WRSNs face critical challenges from the inherent trade-off between maximizing the node survival rates and maximizing charging energy efficiency under dynamic operational conditions. In this paper, we investigate a typical scenario where mobile chargers move and charge the sensor, thereby maintaining the network connectivity while minimizing the energy waste. Specifically, we formulate a multi-objective optimization problem that simultaneously maximizes the network node survival rate and mobile charger energy usage efficiency across multiple time slots, which presents NP-hard computational complexity with long-term temporal dependencies that make traditional optimization approaches ineffective. To address these challenges, we propose an enhanced evolutionary multi-objective deep reinforcement learning algorithm, which integrates a long short-term memory (LSTM)-based policy network for temporal pattern recognition, a multilayer perceptron-based prospective increment model for future state prediction, and a time-varying Pareto policy evaluation method for dynamic preference adaptation. Extensive simulation results demonstrate that the proposed algorithm significantly outperforms existing approaches in balancing node survival rate and energy efficiency while generating diverse Pareto-optimal solutions. Moreover, the LSTM-enhanced policy network converges 25% faster than conventional networks, with the time-varying evaluation method effectively adapting to dynamic conditions.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "52",
        "title": "Quantifying CBRN Risk in Frontier Models",
        "author": [
            "Divyanshu Kumar",
            "Nitin Aravind Birur",
            "Tanay Baswa",
            "Sahil Agarwal",
            "Prashanth Harshangi"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21133",
        "abstract": "Frontier Large Language Models (LLMs) pose unprecedented dual-use risks through the potential proliferation of chemical, biological, radiological, and nuclear (CBRN) weapons knowledge. We present the first comprehensive evaluation of 10 leading commercial LLMs against both a novel 200-prompt CBRN dataset and a 180-prompt subset of the FORTRESS benchmark, using a rigorous three-tier attack methodology. Our findings expose critical safety vulnerabilities: Deep Inception attacks achieve 86.0\\% success versus 33.8\\% for direct requests, demonstrating superficial filtering mechanisms; Model safety performance varies dramatically from 2\\% (claude-opus-4) to 96\\% (mistral-small-latest) attack success rates; and eight models exceed 70\\% vulnerability when asked to enhance dangerous material properties. We identify fundamental brittleness in current safety alignment, where simple prompt engineering techniques bypass safeguards for dangerous CBRN information. These results challenge industry safety claims and highlight urgent needs for standardized evaluation frameworks, transparent safety metrics, and more robust alignment techniques to mitigate catastrophic misuse risks while preserving beneficial capabilities.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "53",
        "title": "PanicToCalm: A Proactive Counseling Agent for Panic Attacks",
        "author": [
            "Jihyun Lee",
            "Yejin Min",
            "San Kim",
            "Yejin Jeon",
            "SungJun Yang",
            "Hyounghun Kim",
            "Gary Geunbae Lee"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21143",
        "abstract": "Panic attacks are acute episodes of fear and distress, in which timely, appropriate intervention can significantly help individuals regain stability. However, suitable datasets for training such models remain scarce due to ethical and logistical issues. To address this, we introduce PACE, which is a dataset that includes high-distress episodes constructed from first-person narratives, and structured around the principles of Psychological First Aid (PFA). Using this data, we train PACER, a counseling model designed to provide both empathetic and directive support, which is optimized through supervised learning and simulated preference alignment. To assess its effectiveness, we propose PanicEval, a multi-dimensional framework covering general counseling quality and crisis-specific strategies. Experimental results show that PACER outperforms strong baselines in both counselor-side metrics and client affect improvement. Human evaluations further confirm its practical value, with PACER consistently preferred over general, CBT-based, and GPT-4-powered models in panic scenarios (Code is available at https://github.com/JihyunLee1/PanicToCalm ).",
        "tags": [
            "GPT"
        ]
    },
    {
        "id": "54",
        "title": "NeuroGenPoisoning: Neuron-Guided Attacks on Retrieval-Augmented Generation of LLM via Genetic Optimization of External Knowledge",
        "author": [
            "Hanyu Zhu",
            "Lance Fiondella",
            "Jiawei Yuan",
            "Kai Zeng",
            "Long Jiao"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21144",
        "abstract": "Retrieval-Augmented Generation (RAG) empowers Large Language Models (LLMs) to dynamically integrate external knowledge during inference, improving their factual accuracy and adaptability. However, adversaries can inject poisoned external knowledge to override the model's internal memory. While existing attacks iteratively manipulate retrieval content or prompt structure of RAG, they largely ignore the model's internal representation dynamics and neuron-level sensitivities. The underlying mechanism of RAG poisoning has not been fully studied and the effect of knowledge conflict with strong parametric knowledge in RAG is not considered. In this work, we propose NeuroGenPoisoning, a novel attack framework that generates adversarial external knowledge in RAG guided by LLM internal neuron attribution and genetic optimization. Our method first identifies a set of Poison-Responsive Neurons whose activation strongly correlates with contextual poisoning knowledge. We then employ a genetic algorithm to evolve adversarial passages that maximally activate these neurons. Crucially, our framework enables massive-scale generation of effective poisoned RAG knowledge by identifying and reusing promising but initially unsuccessful external knowledge variants via observed attribution signals. At the same time, Poison-Responsive Neurons guided poisoning can effectively resolves knowledge conflict. Experimental results across models and datasets demonstrate consistently achieving high Population Overwrite Success Rate (POSR) of over 90% while preserving fluency. Empirical evidence shows that our method effectively resolves knowledge conflict.",
        "tags": [
            "LLM",
            "RAG"
        ]
    },
    {
        "id": "55",
        "title": "How to Auto-optimize Prompts for Domain Tasks? Adaptive Prompting and Reasoning through Evolutionary Domain Knowledge Adaptation",
        "author": [
            "Yang Zhao",
            "Pu Wang",
            "Hao Frank Yang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21148",
        "abstract": "Designing optimal prompts and reasoning processes for large language models (LLMs) on domain-specific tasks is both necessary and challenging in real-world applications. Determining how to integrate domain knowledge, enhance reasoning efficiency, and even provide domain experts with refined knowledge integration hints are particularly crucial yet unresolved tasks. In this research, we propose Evolutionary Graph Optimization for Prompting (EGO-Prompt), an automated framework to designing better prompts, efficient reasoning processes and providing enhanced causal-informed process. EGO-Prompt begins with a general prompt and fault-tolerant initial Semantic Causal Graph (SCG) descriptions, constructed by human experts, which is then automatically refined and optimized to guide LLM reasoning. Recognizing that expert-defined SCGs may be partial or imperfect and that their optimal integration varies across LLMs, EGO-Prompt integrates a novel causal-guided textual gradient process in two steps: first, generating nearly deterministic reasoning guidance from the SCG for each instance, and second, adapting the LLM to effectively utilize the guidance alongside the original input. The iterative optimization algorithm further refines both the SCG and the reasoning mechanism using textual gradients with ground-truth. We tested the framework on real-world public health, transportation and human behavior tasks. EGO-Prompt achieves 7.32%-12.61% higher F1 than cutting-edge methods, and allows small models to reach the performence of larger models at under 20% of the original cost. It also outputs a refined, domain-specific SCG that improves interpretability.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "56",
        "title": "String Seed of Thought: Prompting LLMs for Distribution-Faithful and Diverse Generation",
        "author": [
            "Kou Misaki",
            "Takuya Akiba"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21150",
        "abstract": "We introduce String Seed of Thought (SSoT), a novel prompting method for LLMs that improves Probabilistic Instruction Following (PIF). We define PIF as a task requiring an LLM to select its answer from a predefined set of options, each associated with a specific probability, such that the empirical distribution of the generated answers aligns with the target distribution when prompted multiple times. While LLMs excel at tasks with single, deterministic answers, they often fail at PIF, exhibiting biases problematic for applications requiring non-deterministic behaviors, such as human-behavior simulation, content diversification, and multiplayer games. It also harms the diversity of generated responses, a crucial factor in test-time scaling, by causing the outputs to collapse into a limited set of answers. To address this, we propose SSoT, a simple prompting method that instructs an LLM to first output a random string to generate sufficient entropy. SSoT also instructs the LLM to extract randomness by manipulating this string to derive a final answer, thereby preserving diversity while adhering to specific constraints. We demonstrate that SSoT significantly improves the PIF performance of LLMs, approaching the ideal performance of a pseudo-random number generator. Furthermore, our experiments on NoveltyBench show SSoT's benefits extend beyond closed-set tasks to open-ended tasks by enhancing response diversity.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "57",
        "title": "Towards Physics-informed Spatial Intelligence with Human Priors: An Autonomous Driving Pilot Study",
        "author": [
            "Guanlin Wu",
            "Boyan Su",
            "Yang Zhao",
            "Pu Wang",
            "Yichen Lin",
            "Hao Frank Yang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21160",
        "abstract": "How to integrate and verify spatial intelligence in foundation models remains an open challenge. Current practice often proxies Visual-Spatial Intelligence (VSI) with purely textual prompts and VQA-style scoring, which obscures geometry, invites linguistic shortcuts, and weakens attribution to genuinely spatial skills. We introduce Spatial Intelligence Grid (SIG): a structured, grid-based schema that explicitly encodes object layouts, inter-object relations, and physically grounded priors. As a complementary channel to text, SIG provides a faithful, compositional representation of scene structure for foundation-model reasoning. Building on SIG, we derive SIG-informed evaluation metrics that quantify a model's intrinsic VSI, which separates spatial capability from language priors. In few-shot in-context learning with state-of-the-art multimodal LLMs (e.g. GPT- and Gemini-family models), SIG yields consistently larger, more stable, and more comprehensive gains across all VSI metrics compared to VQA-only representations, indicating its promise as a data-labeling and training schema for learning VSI. We also release SIGBench, a benchmark of 1.4K driving frames annotated with ground-truth SIG labels and human gaze traces, supporting both grid-based machine VSI tasks and attention-driven, human-like VSI tasks in autonomous-driving scenarios.",
        "tags": [
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "58",
        "title": "An Agnostic End-Effector Alignment Controller for Robust Assembly of Modular Space Robots",
        "author": [
            "Shamistan Karimov",
            "Elian Neppel",
            "Shreya Santra",
            "Kentaro Uno",
            "Kazuya Yoshida"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21164",
        "abstract": "Modular robots offer reconfigurability and fault tolerance essential for lunar missions, but require controllers that adapt safely to real-world disturbances. We build on our previous hardware-agnostic actuator synchronization in Motion Stack to develop a new controller enforcing adaptive velocity bounds via a dynamic hypersphere clamp. Using only real-time end-effector and target pose measurements, the controller adjusts its translational and rotational speed limits to ensure smooth, stable alignment without abrupt motions. We implemented two variants, a discrete, step-based version and a continuous, velocity-based version, and tested them on two MoonBot limbs in JAXA's lunar environment simulator. Field trials demonstrate that the step-based variant produces highly predictable, low-wobble motions, while the continuous variant converges more quickly and maintains millimeter-level positional accuracy, and both remain robust across limbs with differing mechanical imperfections and sensing noise (e.g., backlash and flex). These results highlight the flexibility and robustness of our robot-agnostic framework for autonomous self-assembly and reconfiguration under harsh conditions.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "59",
        "title": "Blockwise Flow Matching: Improving Flow Matching Models For Efficient High-Quality Generation",
        "author": [
            "Dogyun Park",
            "Taehoon Lee",
            "Minseok Joo",
            "Hyunwoo J. Kim"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21167",
        "abstract": "Recently, Flow Matching models have pushed the boundaries of high-fidelity data generation across a wide range of domains. It typically employs a single large network to learn the entire generative trajectory from noise to data. Despite their effectiveness, this design struggles to capture distinct signal characteristics across timesteps simultaneously and incurs substantial inference costs due to the iterative evaluation of the entire model. To address these limitations, we propose Blockwise Flow Matching (BFM), a novel framework that partitions the generative trajectory into multiple temporal segments, each modeled by smaller but specialized velocity blocks. This blockwise design enables each block to specialize effectively in its designated interval, improving inference efficiency and sample quality. To further enhance generation fidelity, we introduce a Semantic Feature Guidance module that explicitly conditions velocity blocks on semantically rich features aligned with pretrained representations. Additionally, we propose a lightweight Feature Residual Approximation strategy that preserves semantic quality while significantly reducing inference cost. Extensive experiments on ImageNet 256x256 demonstrate that BFM establishes a substantially improved Pareto frontier over existing Flow Matching methods, achieving 2.1x to 4.9x accelerations in inference complexity at comparable generation performance. Code is available at https://github.com/mlvlab/BFM.",
        "tags": [
            "Flow Matching"
        ]
    },
    {
        "id": "60",
        "title": "Memory-Free Continual Learning with Null Space Adaptation for Zero-Shot Vision-Language Models",
        "author": [
            "Yujin Jo",
            "Taesup Kim"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21175",
        "abstract": "Pre-trained vision-language models (VLMs), such as CLIP, have demonstrated remarkable zero-shot generalization, enabling deployment in a wide range of real-world tasks without additional task-specific training. However, in real deployment scenarios with evolving environments or emerging classes, these models inevitably face distributional shifts and novel tasks. In such contexts, static zero-shot capabilities are insufficient, and there is a growing need for continual learning methods that allow models to adapt over time while avoiding catastrophic forgetting. We introduce NuSA-CL (Null Space Adaptation for Continual Learning), a lightweight memory-free continual learning framework designed to address this challenge. NuSA-CL employs low-rank adaptation and constrains task-specific weight updates to lie within an approximate null space of the model's current parameters. This strategy minimizes interference with previously acquired knowledge, effectively preserving the zero-shot capabilities of the original model. Unlike methods relying on replay buffers or costly distillation, NuSA-CL imposes minimal computational and memory overhead, making it practical for deployment in resource-constrained, real-world continual learning environments. Experiments show that our framework not only effectively preserves zero-shot transfer capabilities but also achieves highly competitive performance on continual learning benchmarks. These results position NuSA-CL as a practical and scalable solution for continually evolving zero-shot VLMs in real-world applications.",
        "tags": [
            "CLIP",
            "LoRA",
            "VLM"
        ]
    },
    {
        "id": "61",
        "title": "Social Simulations with Large Language Model Risk Utopian Illusion",
        "author": [
            "Ning Bian",
            "Xianpei Han",
            "Hongyu Lin",
            "Baolei Wu",
            "Jun Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21180",
        "abstract": "Reliable simulation of human behavior is essential for explaining, predicting, and intervening in our society. Recent advances in large language models (LLMs) have shown promise in emulating human behaviors, interactions, and decision-making, offering a powerful new lens for social science studies. However, the extent to which LLMs diverge from authentic human behavior in social contexts remains underexplored, posing risks of misinterpretation in scientific studies and unintended consequences in real-world applications. Here, we introduce a systematic framework for analyzing LLMs' behavior in social simulation. Our approach simulates multi-agent interactions through chatroom-style conversations and analyzes them across five linguistic dimensions, providing a simple yet effective method to examine emergent social cognitive biases. We conduct extensive experiments involving eight representative LLMs across three families. Our findings reveal that LLMs do not faithfully reproduce genuine human behavior but instead reflect overly idealized versions of it, shaped by the social desirability bias. In particular, LLMs show social role bias, primacy effect, and positivity bias, resulting in \"Utopian\" societies that lack the complexity and variability of real human interactions. These findings call for more socially grounded LLMs that capture the diversity of human social behavior.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "62",
        "title": "KBE-DME: Dynamic Multimodal Evaluation via Knowledge Enhanced Benchmark Evolution",
        "author": [
            "Junzhe Zhang",
            "Huixuan Zhang",
            "Xiaojun Wan"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21182",
        "abstract": "The rapid progress of multimodal large language models (MLLMs) calls for more reliable evaluation protocols. Existing static benchmarks suffer from the potential risk of data contamination and saturation, leading to inflated or misleading performance evaluations. To address these issues, we first apply Graph formulation to represent a static or dynamic VQA sample. With the formulation, we propose Knowledge-enhanced Benchmark Evolution(KBE), a dynamic multimodal evaluation framework. KBE first analyzes the original static benchmark, then expands it by integrating multimodal knowledge, transforming the static benchmark into a controllable, dynamic evolving version. Crucially, KBE can both reconstruct questions by Re-selecting visual information in the original image and expand existing questions with external textual knowledge. It enables difficulty-controllable evaluation by adjusting the degree of question exploration. Extensive experiments demonstrate that KBE alleviates the risk of data contamination, data saturation, and provides a more comprehensive assessment of MLLM capabilities.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "63",
        "title": "Reducing the Probability of Undesirable Outputs in Language Models Using Probabilistic Inference",
        "author": [
            "Stephen Zhao",
            "Aidan Li",
            "Rob Brekelmans",
            "Roger Grosse"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21184",
        "abstract": "Reinforcement learning (RL) has become a predominant technique to align language models (LMs) with human preferences or promote outputs which are deemed to be desirable by a given reward function. Standard RL approaches optimize average reward, while methods explicitly focused on reducing the probability of undesired outputs typically come at a cost to average-case performance. To improve this tradeoff, we introduce RePULSe, a new training method that augments the standard RL loss with an additional loss that uses learned proposals to guide sampling low-reward outputs, and then reduces those outputs' probability. We run experiments demonstrating that RePULSe produces a better tradeoff of expected reward versus the probability of undesired outputs and is more adversarially robust, compared to standard RL alignment approaches and alternatives.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "64",
        "title": "PLAN: Proactive Low-Rank Allocation for Continual Learning",
        "author": [
            "Xiequn Wang",
            "Zhan Zhuang",
            "Yu Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21188",
        "abstract": "Continual learning (CL) requires models to continuously adapt to new tasks without forgetting past knowledge. In this work, we propose \\underline{P}roactive \\underline{L}ow-rank \\underline{A}llocatio\\underline{N} (PLAN), a framework that extends Low-Rank Adaptation (LoRA) to enable efficient and interference-aware fine-tuning of large pre-trained models in CL settings. PLAN proactively manages the allocation of task-specific subspaces by introducing orthogonal basis vectors for each task and optimizing them through a perturbation-based strategy that minimizes conflicts with previously learned parameters. Furthermore, PLAN incorporates a novel selection mechanism that identifies and assigns basis vectors with minimal sensitivity to interference, reducing the risk of degrading past knowledge while maintaining efficient adaptation to new tasks. Empirical results on standard CL benchmarks demonstrate that PLAN consistently outperforms existing methods, establishing a new state-of-the-art for continual learning with foundation models.",
        "tags": [
            "LoRA"
        ]
    },
    {
        "id": "65",
        "title": "Adjacent Words, Divergent Intents: Jailbreaking Large Language Models via Task Concurrency",
        "author": [
            "Yukun Jiang",
            "Mingjie Li",
            "Michael Backes",
            "Yang Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21189",
        "abstract": "Despite their superior performance on a wide range of domains, large language models (LLMs) remain vulnerable to misuse for generating harmful content, a risk that has been further amplified by various jailbreak attacks. Existing jailbreak attacks mainly follow sequential logic, where LLMs understand and answer each given task one by one. However, concurrency, a natural extension of the sequential scenario, has been largely overlooked. In this work, we first propose a word-level method to enable task concurrency in LLMs, where adjacent words encode divergent intents. Although LLMs maintain strong utility in answering concurrent tasks, which is demonstrated by our evaluations on mathematical and general question-answering benchmarks, we notably observe that combining a harmful task with a benign one significantly reduces the probability of it being filtered by the guardrail, showing the potential risks associated with concurrency in LLMs. Based on these findings, we introduce $\\texttt{JAIL-CON}$, an iterative attack framework that $\\underline{\\text{JAIL}}$breaks LLMs via task $\\underline{\\text{CON}}$currency. Experiments on widely-used LLMs demonstrate the strong jailbreak capabilities of $\\texttt{JAIL-CON}$ compared to existing attacks. Furthermore, when the guardrail is applied as a defense, compared to the sequential answers generated by previous attacks, the concurrent answers in our $\\texttt{JAIL-CON}$ exhibit greater stealthiness and are less detectable by the guardrail, highlighting the unique feature of task concurrency in jailbreaking LLMs.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "66",
        "title": "The Trojan Example: Jailbreaking LLMs through Template Filling and Unsafety Reasoning",
        "author": [
            "Mingrui Liu",
            "Sixiao Zhang",
            "Cheng Long",
            "Kwok Yan Lam"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21190",
        "abstract": "Large Language Models (LLMs) have advanced rapidly and now encode extensive world knowledge. Despite safety fine-tuning, however, they remain susceptible to adversarial prompts that elicit harmful content. Existing jailbreak techniques fall into two categories: white-box methods (e.g., gradient-based approaches such as GCG), which require model internals and are infeasible for closed-source APIs, and black-box methods that rely on attacker LLMs to search or mutate prompts but often produce templates that lack explainability and transferability. We introduce TrojFill, a black-box jailbreak that reframes unsafe instruction as a template-filling task. TrojFill embeds obfuscated harmful instructions (e.g., via placeholder substitution or Caesar/Base64 encoding) inside a multi-part template that asks the model to (1) reason why the original instruction is unsafe (unsafety reasoning) and (2) generate a detailed example of the requested text, followed by a sentence-by-sentence analysis. The crucial \"example\" component acts as a Trojan Horse that contains the target jailbreak content while the surrounding task framing reduces refusal rates. We evaluate TrojFill on standard jailbreak benchmarks across leading LLMs (e.g., ChatGPT, Gemini, DeepSeek, Qwen), showing strong empirical performance (e.g., 100% attack success on Gemini-flash-2.5 and DeepSeek-3.1, and 97% on GPT-4o). Moreover, the generated prompts exhibit improved interpretability and transferability compared with prior black-box optimization approaches. We release our code, sample prompts, and generated outputs to support future red-teaming research.",
        "tags": [
            "DeepSeek",
            "GPT",
            "LLM",
            "Qwen"
        ]
    },
    {
        "id": "67",
        "title": "Gen-Review: A Large-scale Dataset of AI-Generated (and Human-written) Peer Reviews",
        "author": [
            "Luca Demetrio",
            "Giovanni Apruzzese",
            "Kathrin Grosse",
            "Pavel Laskov",
            "Emil Lupu",
            "Vera Rimmer",
            "Philine Widmer"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21192",
        "abstract": "How does the progressive embracement of Large Language Models (LLMs) affect scientific peer reviewing? This multifaceted question is fundamental to the effectiveness -- as well as to the integrity -- of the scientific process. Recent evidence suggests that LLMs may have already been tacitly used in peer reviewing, e.g., at the 2024 International Conference of Learning Representations (ICLR). Furthermore, some efforts have been undertaken in an attempt to explicitly integrate LLMs in peer reviewing by various editorial boards (including that of ICLR'25). To fully understand the utility and the implications of LLMs' deployment for scientific reviewing, a comprehensive relevant dataset is strongly desirable. Despite some previous research on this topic, such dataset has been lacking so far. We fill in this gap by presenting GenReview, the hitherto largest dataset containing LLM-written reviews. Our dataset includes 81K reviews generated for all submissions to the 2018--2025 editions of the ICLR by providing the LLM with three independent prompts: a negative, a positive, and a neutral one. GenReview is also linked to the respective papers and their original reviews, thereby enabling a broad range of investigations. To illustrate the value of GenReview, we explore a sample of intriguing research questions, namely: if LLMs exhibit bias in reviewing (they do); if LLM-written reviews can be automatically detected (so far, they can); if LLMs can rigorously follow reviewing instructions (not always) and whether LLM-provided ratings align with decisions on paper acceptance or rejection (holds true only for accepted papers). GenReview can be accessed at the following link: https://anonymous.4open.science/r/gen_review.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "68",
        "title": "Estonian Native Large Language Model Benchmark",
        "author": [
            "Helena Grete Lillepalu",
            "Tanel AlumÃ¤e"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21193",
        "abstract": "The availability of LLM benchmarks for the Estonian language is limited, and a comprehensive evaluation comparing the performance of different LLMs on Estonian tasks has yet to be conducted. We introduce a new benchmark for evaluating LLMs in Estonian, based on seven diverse datasets. These datasets assess general and domain-specific knowledge, understanding of Estonian grammar and vocabulary, summarization abilities, contextual comprehension, and more. The datasets are all generated from native Estonian sources without using machine translation. We compare the performance of base models, instruction-tuned open-source models, and commercial models. Our evaluation includes 6 base models and 26 instruction-tuned models. To assess the results, we employ both human evaluation and LLM-as-a-judge methods. Human evaluation scores showed moderate to high correlation with benchmark evaluations, depending on the dataset. Claude 3.7 Sonnet, used as an LLM judge, demonstrated strong alignment with human ratings, indicating that top-performing LLMs can effectively support the evaluation of Estonian-language models.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "69",
        "title": "3rd Place Solution to ICCV LargeFineFoodAI Retrieval",
        "author": [
            "Yang Zhong",
            "Zhiming Wang",
            "Zhaoyang Li",
            "Jinyu Ma",
            "Xiang Li"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21198",
        "abstract": "This paper introduces the 3rd place solution to the ICCV LargeFineFoodAI Retrieval Competition on Kaggle. Four basic models are independently trained with the weighted sum of ArcFace and Circle loss, then TTA and Ensemble are successively applied to improve feature representation ability. In addition, a new reranking method for retrieval is proposed based on diffusion and k-reciprocal reranking. Finally, our method scored 0.81219 and 0.81191 mAP@100 on the public and private leaderboard, respectively.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "70",
        "title": "Adaptive Graph Mixture of Residual Experts: Unsupervised Learning on Diverse Graphs with Heterogeneous Specialization",
        "author": [
            "Yunlong Chu",
            "Minglai Shao",
            "Zengyi Wo",
            "Bing Hao",
            "Yuhang Liu",
            "Ruijie Wang",
            "Jianxin Li"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21207",
        "abstract": "Graph Neural Networks (GNNs) face a fundamental adaptability challenge: their fixed message-passing architectures struggle with the immense diversity of real-world graphs, where optimal computational strategies vary by local structure and task. While Mixture-of-Experts (MoE) offers a promising pathway to adaptability, existing graph MoE methods remain constrained by their reliance on supervised signals and instability when training heterogeneous experts. We introduce ADaMoRE (Adaptive Mixture of Residual Experts), a principled framework that enables robust, fully unsupervised training of heterogeneous MoE on graphs. ADaMoRE employs a backbone-residual expert architecture where foundational encoders provide stability while specialized residual experts capture diverse computational patterns. A structurally-aware gating network performs fine-grained node routing. The entire architecture is trained end-to-end using a unified unsupervised objective, which integrates a primary reconstruction task with an information-theoretic diversity regularizer to explicitly enforce functional specialization among the experts. Theoretical analysis confirms our design improves data efficiency and training stability. Extensive evaluation across 16 benchmarks validates ADaMoRE's state-of-the-art performance in unsupervised node classification and few-shot learning, alongside superior generalization, training efficiency, and faster convergence on diverse graphs and tasks.",
        "tags": [
            "MoE"
        ]
    },
    {
        "id": "71",
        "title": "On the flow matching interpretability",
        "author": [
            "Francesco Pivi",
            "Simone Gazza",
            "Davide Evangelista",
            "Roberto Amadini",
            "Maurizio Gabbrielli"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21210",
        "abstract": "Generative models based on flow matching have demonstrated remarkable success in various domains, yet they suffer from a fundamental limitation: the lack of interpretability in their intermediate generation steps. In fact these models learn to transform noise into data through a series of vector field updates, however the meaning of each step remains opaque. We address this problem by proposing a general framework constraining each flow step to be sampled from a known physical distribution. Flow trajectories are mapped to (and constrained to traverse) the equilibrium states of the simulated physical process. We implement this approach through the 2D Ising model in such a way that flow steps become thermal equilibrium points along a parametric cooling schedule.\nOur proposed architecture includes an encoder that maps discrete Ising configurations into a continuous latent space, a flow-matching network that performs temperature-driven diffusion, and a projector that returns to discrete Ising states while preserving physical constraints.\nWe validate this framework across multiple lattice sizes, showing that it preserves physical fidelity while outperforming Monte Carlo generation in speed as the lattice size increases. In contrast with standard flow matching, each vector field represents a meaningful stepwise transition in the 2D Ising model's latent space. This demonstrates that embedding physical semantics into generative flows transforms opaque neural trajectories into interpretable physical processes.",
        "tags": [
            "Diffusion",
            "Flow Matching"
        ]
    },
    {
        "id": "72",
        "title": "Enhanced MLLM Black-Box Jailbreaking Attacks and Defenses",
        "author": [
            "Xingwei Zhong",
            "Kar Wai Fok",
            "Vrizlynn L.L. Thing"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21214",
        "abstract": "Multimodal large language models (MLLMs) comprise of both visual and textual modalities to process vision language tasks. However, MLLMs are vulnerable to security-related issues, such as jailbreak attacks that alter the model's input to induce unauthorized or harmful responses. The incorporation of the additional visual modality introduces new dimensions to security threats. In this paper, we proposed a black-box jailbreak method via both text and image prompts to evaluate MLLMs. In particular, we designed text prompts with provocative instructions, along with image prompts that introduced mutation and multi-image capabilities. To strengthen the evaluation, we also designed a Re-attack strategy. Empirical results show that our proposed work can improve capabilities to assess the security of both open-source and closed-source MLLMs. With that, we identified gaps in existing defense methods to propose new strategies for both training-time and inference-time defense methods, and evaluated them across the new jailbreak methods. The experiment results showed that the re-designed defense methods improved protections against the jailbreak attacks.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "73",
        "title": "Securing AI Agent Execution",
        "author": [
            "Christoph BÃ¼hler",
            "Matteo Biagiola",
            "Luca Di Grazia",
            "Guido Salvaneschi"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21236",
        "abstract": "Large Language Models (LLMs) have evolved into AI agents that interact with external tools and environments to perform complex tasks. The Model Context Protocol (MCP) has become the de facto standard for connecting agents with such resources, but security has lagged behind: thousands of MCP servers execute with unrestricted access to host systems, creating a broad attack surface. In this paper, we introduce AgentBound, the first access control framework for MCP servers. AgentBound combines a declarative policy mechanism, inspired by the Android permission model, with a policy enforcement engine that contains malicious behavior without requiring MCP server modifications. We build a dataset containing the 296 most popular MCP servers, and show that access control policies can be generated automatically from source code with 80.9% accuracy. We also show that AgentBound blocks the majority of security threats in several malicious MCP servers, and that policy enforcement engine introduces negligible overhead. Our contributions provide developers and project managers with a practical foundation for securing MCP servers while maintaining productivity, enabling researchers and tool builders to explore new directions for declarative access control and MCP security.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "74",
        "title": "OutboundEval: A Dual-Dimensional Benchmark for Expert-Level Intelligent Outbound Evaluation of Xbench's Professional-Aligned Series",
        "author": [
            "Pengyu Xu",
            "Shijia Li",
            "Ao Sun",
            "Feng Zhang",
            "Yahan Li",
            "Bo Wu",
            "Zhanyu Ma",
            "Jiguo Li",
            "Jun Xu",
            "Jiuchong Gao",
            "Jinghua Hao",
            "Renqing He",
            "Rui Wang",
            "Yang Liu",
            "Xiaobo Hu",
            "Fan Yang",
            "Jia Zheng",
            "Guanghua Yao"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21244",
        "abstract": "We propose OutboundEval, a comprehensive benchmark for evaluating large language models (LLMs) in expert-level intelligent outbound calling scenarios. Unlike existing methods that suffer from three key limitations - insufficient dataset diversity and category coverage, unrealistic user simulation, and inaccurate evaluation metrics - OutboundEval addresses these issues through a structured framework. First, we design a benchmark spanning six major business domains and 30 representative sub-scenarios, each with scenario-specific process decomposition, weighted scoring, and domain-adaptive metrics. Second, we develop a large-model-driven User Simulator that generates diverse, persona-rich virtual users with realistic behaviors, emotional variability, and communication styles, providing a controlled yet authentic testing environment. Third, we introduce a dynamic evaluation method that adapts to task variations, integrating automated and human-in-the-loop assessment to measure task execution accuracy, professional knowledge application, adaptability, and user experience quality. Experiments on 12 state-of-the-art LLMs reveal distinct trade-offs between expert-level task completion and interaction fluency, offering practical insights for building reliable, human-like outbound AI systems. OutboundEval establishes a practical, extensible, and domain-oriented standard for benchmarking LLMs in professional applications.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "75",
        "title": "Out-of-Distribution Detection for Safety Assurance of AI and Autonomous Systems",
        "author": [
            "Victoria J. Hodge",
            "Colin Paterson",
            "Ibrahim Habli"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21254",
        "abstract": "The operational capabilities and application domains of AI-enabled autonomous systems have expanded significantly in recent years due to advances in robotics and machine learning (ML). Demonstrating the safety of autonomous systems rigorously is critical for their responsible adoption but it is challenging as it requires robust methodologies that can handle novel and uncertain situations throughout the system lifecycle, including detecting out-of-distribution (OoD) data. Thus, OOD detection is receiving increased attention from the research, development and safety engineering communities. This comprehensive review analyses OOD detection techniques within the context of safety assurance for autonomous systems, in particular in safety-critical domains. We begin by defining the relevant concepts, investigating what causes OOD and exploring the factors which make the safety assurance of autonomous systems and OOD detection challenging. Our review identifies a range of techniques which can be used throughout the ML development lifecycle and we suggest areas within the lifecycle in which they may be used to support safety assurance arguments. We discuss a number of caveats that system and safety engineers must be aware of when integrating OOD detection into system lifecycles. We conclude by outlining the challenges and future work necessary for the safe development and operation of autonomous systems across a range of domains and applications.",
        "tags": [
            "Detection",
            "Robotics"
        ]
    },
    {
        "id": "76",
        "title": "Correlation Dimension of Auto-Regressive Large Language Models",
        "author": [
            "Xin Du",
            "Kumiko Tanaka-Ishii"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21258",
        "abstract": "Large language models (LLMs) have achieved remarkable progress in natural language generation, yet they continue to display puzzling behaviors -- such as repetition and incoherence -- even when exhibiting low perplexity. This highlights a key limitation of conventional evaluation metrics, which emphasize local prediction accuracy while overlooking long-range structural complexity. We introduce correlation dimension, a fractal-geometric measure of self-similarity, to quantify the epistemological complexity of text as perceived by a language model. This measure captures the hierarchical recurrence structure of language, bridging local and global properties in a unified framework. Through extensive experiments, we show that correlation dimension (1) reveals three distinct phases during pretraining, (2) reflects context-dependent complexity, (3) indicates a model's tendency toward hallucination, and (4) reliably detects multiple forms of degeneration in generated text. The method is computationally efficient, robust to model quantization (down to 4-bit precision), broadly applicable across autoregressive architectures (e.g., Transformer and Mamba), and provides fresh insight into the generative dynamics of LLMs.",
        "tags": [
            "LLM",
            "Mamba",
            "Transformer"
        ]
    },
    {
        "id": "77",
        "title": "PINN Balls: Scaling Second-Order Methods for PINNs with Domain Decomposition and Adaptive Sampling",
        "author": [
            "Andrea Bonfanti",
            "Ismael Medina",
            "Roman List",
            "BjÃ¶rn Staeves",
            "Roberto Santana",
            "Marco Ellero"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21262",
        "abstract": "Recent advances in Scientific Machine Learning have shown that second-order methods can enhance the training of Physics-Informed Neural Networks (PINNs), making them a suitable alternative to traditional numerical methods for Partial Differential Equations (PDEs). However, second-order methods induce large memory requirements, making them scale poorly with the model size. In this paper, we define a local Mixture of Experts (MoE) combining the parameter-efficiency of ensemble models and sparse coding to enable the use of second-order training. Our model -- \\textsc{PINN Balls} -- also features a fully learnable domain decomposition structure, achieved through the use of Adversarial Adaptive Sampling (AAS), which adapts the DD to the PDE and its domain. \\textsc{PINN Balls} achieves better accuracy than the state-of-the-art in scientific machine learning, while maintaining invaluable scalability properties and drawing from a sound theoretical background.",
        "tags": [
            "MoE"
        ]
    },
    {
        "id": "78",
        "title": "Topology Sculptor, Shape Refiner: Discrete Diffusion Model for High-Fidelity 3D Meshes Generation",
        "author": [
            "Kaiyu Song",
            "Hanjiang Lai",
            "Yaqing Zhang",
            "Chuangjian Cai",
            "Yan Pan Kun Yue",
            "Jian Yin"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21264",
        "abstract": "In this paper, we introduce Topology Sculptor, Shape Refiner (TSSR), a novel method for generating high-quality, artist-style 3D meshes based on Discrete Diffusion Models (DDMs). Our primary motivation for TSSR is to achieve highly accurate token prediction while enabling parallel generation, a significant advantage over sequential autoregressive methods. By allowing TSSR to \"see\" all mesh tokens concurrently, we unlock a new level of efficiency and control. We leverage this parallel generation capability through three key innovations: 1) Decoupled Training and Hybrid Inference, which distinctly separates the DDM-based generation into a topology sculpting stage and a subsequent shape refinement stage. This strategic decoupling enables TSSR to effectively capture both intricate local topology and overarching global shape. 2) An Improved Hourglass Architecture, featuring bidirectional attention enriched by face-vertex-sequence level Rotational Positional Embeddings (RoPE), thereby capturing richer contextual information across the mesh structure. 3) A novel Connection Loss, which acts as a topological constraint to further enhance the realism and fidelity of the generated meshes. Extensive experiments on complex datasets demonstrate that TSSR generates high-quality 3D artist-style meshes, capable of achieving up to 10,000 faces at a remarkable spatial resolution of $1024^3$. The code will be released at: https://github.com/psky1111/Tencent-TSSR.",
        "tags": [
            "3D",
            "Diffusion",
            "RoPE"
        ]
    },
    {
        "id": "79",
        "title": "Sparser Block-Sparse Attention via Token Permutation",
        "author": [
            "Xinghao Wang",
            "Pengyu Wang",
            "Dong Zhang",
            "Chenkun Tan",
            "Shaojun Zhou",
            "Zhaoxiang Liu",
            "Shiguo Lian",
            "Fangxu Liu",
            "Kai Song",
            "Xipeng Qiu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21270",
        "abstract": "Scaling the context length of large language models (LLMs) offers significant benefits but is computationally expensive. This expense stems primarily from the self-attention mechanism, whose $O(N^2)$ complexity with respect to sequence length presents a major bottleneck for both memory and latency. Fortunately, the attention matrix is often sparse, particularly for long sequences, suggesting an opportunity for optimization. Block-sparse attention has emerged as a promising solution that partitions sequences into blocks and skips computation for a subset of these blocks. However, the effectiveness of this method is highly dependent on the underlying attention patterns, which can lead to sub-optimal block-level sparsity. For instance, important key tokens for queries within a single block may be scattered across numerous other blocks, leading to computational redundancy. In this work, we propose Permuted Block-Sparse Attention (\\textbf{PBS-Attn}), a plug-and-play method that leverages the permutation properties of attention to increase block-level sparsity and enhance the computational efficiency of LLM prefilling. We conduct comprehensive experiments on challenging real-world long-context datasets, demonstrating that PBS-Attn consistently outperforms existing block-sparse attention methods in model accuracy and closely matches the full attention baseline. Powered by our custom permuted-FlashAttention kernels, PBS-Attn achieves an end-to-end speedup of up to $2.75\\times$ in long-context prefilling, confirming its practical viability. Code available at https://github.com/xinghaow99/pbs-attn",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "80",
        "title": "LLM-Powered Detection of Price Manipulation in DeFi",
        "author": [
            "Lu Liu",
            "Wuqi Zhang",
            "Lili Wei",
            "Hao Guan",
            "Yongqiang Tian",
            "Yepang Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21272",
        "abstract": "Decentralized Finance (DeFi) smart contracts manage billions of dollars, making them a prime target for exploits. Price manipulation vulnerabilities, often via flash loans, are a devastating class of attacks causing significant financial losses. Existing detection methods are limited. Reactive approaches analyze attacks only after they occur, while proactive static analysis tools rely on rigid, predefined heuristics, limiting adaptability. Both depend on known attack patterns, failing to identify novel variants or comprehend complex economic logic. We propose PMDetector, a hybrid framework combining static analysis with Large Language Model (LLM)-based reasoning to proactively detect price manipulation vulnerabilities. Our approach uses a formal attack model and a three-stage pipeline. First, static taint analysis identifies potentially vulnerable code paths. Second, a two-stage LLM process filters paths by analyzing defenses and then simulates attacks to evaluate exploitability. Finally, a static analysis checker validates LLM results, retaining only high-risk paths and generating comprehensive vulnerability reports. To evaluate its effectiveness, we built a dataset of 73 real-world vulnerable and 288 benign DeFi protocols. Results show PMDetector achieves 88% precision and 90% recall with Gemini 2.5-flash, significantly outperforming state-of-the-art static analysis and LLM-based approaches. Auditing a vulnerability with PMDetector costs just $0.03 and takes 4.0 seconds with GPT-4.1, offering an efficient and cost-effective alternative to manual audits.",
        "tags": [
            "Detection",
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "81",
        "title": "Sensor-Specific Transformer (PatchTST) Ensembles with Test-Matched Augmentation",
        "author": [
            "Pavankumar Chandankar",
            "Robin Burchard"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21282",
        "abstract": "We present a noise-aware, sensor-specific ensemble approach for robust human activity recognition on the 2nd WEAR Dataset Challenge. Our method leverages the PatchTST transformer architecture, training four independent models-one per inertial sensor location-on a tampered training set whose 1-second sliding windows are augmented to mimic the test-time noise. By aligning the train and test data schemas (JSON-encoded 50-sample windows) and applying randomized jitter, scaling, rotation, and channel dropout, each PatchTST model learns to generalize across real-world sensor perturbations. At inference, we compute softmax probabilities from all four sensor models on the Kaggle test set and average them to produce final labels. On the private leaderboard, this pipeline achieves a macro-F1 substantially above the baseline, demonstrating that test-matched augmentation combined with transformer-based ensembling is an effective strategy for robust HAR under noisy conditions.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "82",
        "title": "Text-Guided Diffusion Model-based Generative Communication for Wireless Image Transmission",
        "author": [
            "Shengkang Chen",
            "Tong Wu",
            "Zhiyong Chen",
            "Feng Yang",
            "Meixia Tao",
            "Wenjun Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21299",
        "abstract": "Reliable image transmission over wireless channels is particularly challenging at extremely low transmission rates, where conventional compression and channel coding schemes fail to preserve adequate visual quality. To address this issue, we propose a generative communication framework based on diffusion models, which integrates joint source channel coding (JSCC) with semantic-guided reconstruction leveraging a pre-trained generative model. Unlike conventional architectures that aim to recover exact pixel values of the original image, the proposed method focuses on preserving and reconstructing semantically meaningful visual content under severely constrained rates, ensuring perceptual plausibility and faithfulness to the scene intent. Specifically, the transmitter encodes the source image via JSCC and jointly transmits it with a textual prompt over the wireless channel. At the receiver, the corrupted low-rate representation is fused with the prompt and reconstructed through a Stable Diffusion model with ControlNet, enabling high-quality visual recovery. Leveraging both generative priors and semantic guidance, the proposed framework produces perceptually convincing images even under extreme bandwidth limitations. Experimental results demonstrate that the proposed method consistently outperforms conventional coding-based schemes and deep learning baselines, achieving superior perceptual quality and robustness across various channel conditions.",
        "tags": [
            "ControlNet",
            "Diffusion"
        ]
    },
    {
        "id": "83",
        "title": "Towards Reliable Code-as-Policies: A Neuro-Symbolic Framework for Embodied Task Planning",
        "author": [
            "Sanghyun Ahn",
            "Wonje Choi",
            "Junyong Lee",
            "Jinwoo Park",
            "Honguk Woo"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21302",
        "abstract": "Recent advances in large language models (LLMs) have enabled the automatic generation of executable code for task planning and control in embodied agents such as robots, demonstrating the potential of LLM-based embodied intelligence. However, these LLM-based code-as-policies approaches often suffer from limited environmental grounding, particularly in dynamic or partially observable settings, leading to suboptimal task success rates due to incorrect or incomplete code generation. In this work, we propose a neuro-symbolic embodied task planning framework that incorporates explicit symbolic verification and interactive validation processes during code generation. In the validation phase, the framework generates exploratory code that actively interacts with the environment to acquire missing observations while preserving task-relevant states. This integrated process enhances the grounding of generated code, resulting in improved task reliability and success rates in complex environments. We evaluate our framework on RLBench and in real-world settings across dynamic, partially observable scenarios. Experimental results demonstrate that our framework improves task success rates by 46.2% over Code-as-Policies baselines and attains over 86.8% executability of task-relevant actions, thereby enhancing the reliability of task planning in dynamic environments.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "84",
        "title": "Arbitration-Free Consistency is Available (and Vice Versa)",
        "author": [
            "Hagit Attiya",
            "Constantin Enea",
            "Enrique RomÃ¡n-Calvo"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21304",
        "abstract": "The fundamental tension between \\emph{availability} and \\emph{consistency} shapes the design of distributed storage systems. Classical results capture extreme points of this trade-off: the CAP theorem shows that strong models like linearizability preclude availability under partitions, while weak models like causal consistency remain implementable without coordination. These theorems apply to simple read-write interfaces, leaving open a precise explanation of the combinations of object semantics and consistency models that admit available implementations.\nThis paper develops a general semantic framework in which storage specifications combine operation semantics and consistency models. The framework encompasses a broad range of objects (key-value stores, counters, sets, CRDTs, and transactional databases) and consistency models (from causal consistency and sequential consistency to snapshot isolation and transactional and non-transactional SQL).\nWithin this framework, we prove the \\emph{Arbitration-Free Consistency} (AFC) theorem, showing that an object specification within a consistency model admits an available implementation if and only if it is \\emph{arbitration-free}, that is, it does not require a total arbitration order to resolve visibility or read dependencies.\nThe AFC theorem unifies and generalizes previous results, revealing arbitration-freedom as the fundamental property that delineates coordination-free consistency from inherently synchronized behavior.",
        "tags": [
            "Consistency Models"
        ]
    },
    {
        "id": "85",
        "title": "PARL: Prompt-based Agents for Reinforcement Learning",
        "author": [
            "Yarik Menchaca Resendiz",
            "Roman Klinger"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21306",
        "abstract": "Large language models (LLMs) have demonstrated high performance on tasks expressed in natural language, particularly in zero- or few-shot settings. These are typically framed as supervised (e.g., classification) or unsupervised (e.g., clustering) problems. However, limited work evaluates LLMs as agents in reinforcement learning (RL) tasks (e.g., playing games), where learning occurs through interaction with an environment and a reward system. While prior work focused on representing tasks that rely on a language representation, we study structured, non-linguistic reasoning - such as interpreting positions in a grid world. We therefore introduce PARL (Prompt-based Agent for Reinforcement Learning), a method that uses LLMs as RL agents through prompting, without any fine-tuning. PARL encodes actions, states, and rewards in the prompt, enabling the model to learn through trial-and-error interaction. We evaluate PARL on three standard RL tasks that do not entirely rely on natural language. We show that it can match or outperform traditional RL agents in simple environments by leveraging pretrained knowledge. However, we identify performance limitations in tasks that require complex mathematical operations or decoding states and actions.",
        "tags": [
            "LLM",
            "RL"
        ]
    },
    {
        "id": "86",
        "title": "Towards Physically Executable 3D Gaussian for Embodied Navigation",
        "author": [
            "Bingchen Miao",
            "Rong Wei",
            "Zhiqi Ge",
            "Xiaoquan sun",
            "Shiqi Gao",
            "Jingzhe Zhu",
            "Renhan Wang",
            "Siliang Tang",
            "Jun Xiao",
            "Rui Tang",
            "Juncheng Li"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21307",
        "abstract": "3D Gaussian Splatting (3DGS), a 3D representation method with photorealistic real-time rendering capabilities, is regarded as an effective tool for narrowing the sim-to-real gap. However, it lacks fine-grained semantics and physical executability for Visual-Language Navigation (VLN). To address this, we propose SAGE-3D (Semantically and Physically Aligned Gaussian Environments for 3D Navigation), a new paradigm that upgrades 3DGS into an executable, semantically and physically aligned environment. It comprises two components: (1) Object-Centric Semantic Grounding, which adds object-level fine-grained annotations to 3DGS; and (2) Physics-Aware Execution Jointing, which embeds collision objects into 3DGS and constructs rich physical interfaces. We release InteriorGS, containing 1K object-annotated 3DGS indoor scene data, and introduce SAGE-Bench, the first 3DGS-based VLN benchmark with 2M VLN data. Experiments show that 3DGS scene data is more difficult to converge, while exhibiting strong generalizability, improving baseline performance by 31% on the VLN-CE Unseen task. The data and code will be available soon.",
        "tags": [
            "3D",
            "Gaussian Splatting"
        ]
    },
    {
        "id": "87",
        "title": "Efficient semantic uncertainty quantification in language models via diversity-steered sampling",
        "author": [
            "Ji Won Park",
            "Kyunghyun Cho"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21310",
        "abstract": "Accurately estimating semantic aleatoric and epistemic uncertainties in large language models (LLMs) is particularly challenging in free-form question answering (QA), where obtaining stable estimates often requires many expensive generations. We introduce a diversity-steered sampler that discourages semantically redundant outputs during decoding, covers both autoregressive and masked diffusion paradigms, and yields substantial sample-efficiency gains. The key idea is to inject a continuous semantic-similarity penalty into the model's proposal distribution using a natural language inference (NLI) model lightly finetuned on partial prefixes or intermediate diffusion states. We debias downstream uncertainty estimates with importance reweighting and shrink their variance with control variates. Across four QA benchmarks, our method matches or surpasses baselines while covering more semantic clusters with the same number of samples. Being modular and requiring no gradient access to the base LLM, the framework promises to serve as a drop-in enhancement for uncertainty estimation in risk-sensitive model deployments.",
        "tags": [
            "Diffusion",
            "LLM"
        ]
    },
    {
        "id": "88",
        "title": "FineRS: Fine-grained Reasoning and Segmentation of Small Objects with Reinforcement Learning",
        "author": [
            "Lu Zhang",
            "Jiazuo Yu",
            "Haomiao Xiong",
            "Ping Hu",
            "Yunzhi Zhuge",
            "Huchuan Lu",
            "You He"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21311",
        "abstract": "Multi-modal Large Language Models (MLLMs) have shown remarkable capabilities across a wide range of vision-language tasks. However, due to the restricted input resolutions, MLLMs face significant challenges in precisely understanding and localizing visual details in high-resolution images -- particularly when dealing with extra-small objects embedded in cluttered contexts. To address this issue, we propose \\textsc{FineRS}, a two-stage MLLM-based reinforcement learning framework for jointly reasoning and segmenting extremely small objects within high-resolution scenes. \\textsc{FineRS} adopts a coarse-to-fine pipeline comprising Global Semantic Exploration (GSE) and Localized Perceptual Refinement (LPR). Specifically, GSE performs instruction-guided reasoning to generate a textural response and a coarse target region, while LPR refines this region to produce an accurate bounding box and segmentation mask. To couple the two stages, we introduce a locate-informed retrospective reward, where LPR's outputs are used to optimize GSE for more robust coarse region exploration. % Additionally, we present \\textsc{FineRS}-4k, a new dataset for evaluating MLLMs on attribute-level reasoning and pixel-level segmentation on subtle, small-scale targets in complex high-resolution scenes. Experimental results on \\textsc{FineRS}-4k and public datasets demonstrate that our method consistently outperforms state-of-the-art MLLM-based approaches on both instruction-guided segmentation and visual reasoning tasks.",
        "tags": [
            "LLM",
            "RL",
            "Segmentation"
        ]
    },
    {
        "id": "89",
        "title": "A Convergence Analysis of Adaptive Optimizers under Floating-point Quantization",
        "author": [
            "Xuan Tang",
            "Jichu Li",
            "Difan Zou"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21314",
        "abstract": "The rapid scaling of large language models (LLMs) has made low-precision training essential for reducing memory, improving efficiency, and enabling larger models and datasets. Existing convergence theories for adaptive optimizers, however, assume all components are exact and neglect hardware-aware quantization, leaving open the question of why low-precision training remains effective. We introduce the first theoretical framework for analyzing the convergence of adaptive optimizers, including Adam and Muon, under floating-point quantization of gradients, weights, and optimizer states (e.g., moment estimates). Within this framework, we derive convergence rates on smooth non-convex objectives under standard stochastic gradient assumptions, explicitly characterizing how quantization errors from different components affect convergence. We show that both algorithms retain rates close to their full-precision counterparts provided mantissa length scales only logarithmically with the number of iterations. Our analysis further reveals that Adam is highly sensitive to weights and second-moment quantization due to its reliance on $\\beta_2 \\to 1$, while Muon requires weaker error control and is thus potentially more robust. These results narrow the gap between empirical success and theoretical understanding of low-precision training methods. Numerical experiments on synthetic and real-world data corroborate our theory.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "90",
        "title": "VL-SAE: Interpreting and Enhancing Vision-Language Alignment with a Unified Concept Set",
        "author": [
            "Shufan Shen",
            "Junshu Sun",
            "Qingming Huang",
            "Shuhui Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21323",
        "abstract": "The alignment of vision-language representations endows current Vision-Language Models (VLMs) with strong multi-modal reasoning capabilities. However, the interpretability of the alignment component remains uninvestigated due to the difficulty in mapping the semantics of multi-modal representations into a unified concept set. To address this problem, we propose VL-SAE, a sparse autoencoder that encodes vision-language representations into its hidden activations. Each neuron in its hidden layer correlates to a concept represented by semantically similar images and texts, thereby interpreting these representations with a unified concept set. To establish the neuron-concept correlation, we encourage semantically similar representations to exhibit consistent neuron activations during self-supervised training. First, to measure the semantic similarity of multi-modal representations, we perform their alignment in an explicit form based on cosine similarity. Second, we construct the VL-SAE with a distance-based encoder and two modality-specific decoders to ensure the activation consistency of semantically similar representations. Experiments across multiple VLMs (e.g., CLIP, LLaVA) demonstrate the superior capability of VL-SAE in interpreting and enhancing the vision-language alignment. For interpretation, the alignment between vision and language representations can be understood by comparing their semantics with concepts. For enhancement, the alignment can be strengthened by aligning vision-language representations at the concept level, contributing to performance improvements in downstream tasks, including zero-shot image classification and hallucination elimination. Codes are available at https://github.com/ssfgunner/VL-SAE.",
        "tags": [
            "CLIP",
            "LLaVA",
            "VLM"
        ]
    },
    {
        "id": "91",
        "title": "Typoglycemia under the Hood: Investigating Language Models' Understanding of Scrambled Words",
        "author": [
            "Gianluca Sperduti",
            "Alejandro Moreo"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21326",
        "abstract": "Research in linguistics has shown that humans can read words with internally scrambled letters, a phenomenon recently dubbed typoglycemia. Some specific NLP models have recently been proposed that similarly demonstrate robustness to such distortions by ignoring the internal order of characters by design. This raises a fundamental question: how can models perform well when many distinct words (e.g., form and from) collapse into identical representations under typoglycemia? Our work, focusing exclusively on the English language, seeks to shed light on the underlying aspects responsible for this robustness. We hypothesize that the main reasons have to do with the fact that (i) relatively few English words collapse under typoglycemia, and that (ii) collapsed words tend to occur in contexts so distinct that disambiguation becomes trivial. In our analysis, we (i) analyze the British National Corpus to quantify word collapse and ambiguity under typoglycemia, (ii) evaluate BERT's ability to disambiguate collapsing forms, and (iii) conduct a probing experiment by comparing variants of BERT trained from scratch on clean versus typoglycemic Wikipedia text; our results reveal that the performance degradation caused by scrambling is smaller than expected.",
        "tags": [
            "BERT"
        ]
    },
    {
        "id": "92",
        "title": "TripTide: A Benchmark for Adaptive Travel Planning under Disruptions",
        "author": [
            "Priyanshu Karmakar",
            "Soumyabrata Chaudhuri",
            "Shubhojit Mallick",
            "Manish Gupta",
            "Abhik Jana",
            "Shreya Ghosh"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21329",
        "abstract": "Recent efforts like TripCraft and TravelPlanner have advanced the use of Large Language Models ( LLMs) for personalized, constraint aware travel itinerary generation. Yet, real travel often faces disruptions. To address this, we present TripTide, the first benchmark evaluating LLM's ability to revise itineraries under realistic disruptions. TripTide models key dimensions such as disruption severity and traveler tolerance, enabling nuanced assessment of LLM adaptability to events like flight cancellations, weather closures, or overbooked attractions. We conduct a threefold evaluation. First, we introduce automatic metrics including Preservation of Intent (how well the revised plan maintains feasibility and goals), Responsiveness (promptness and appropriateness of disruption handling), and Adaptability (semantic, spatial, and sequential divergence between original and revised plans). Second, we apply an LLM-as-a-judge approach to automatically assess revision quality. Third, we perform manual expert evaluation to verify whether revisions preserve semantic, spatial, sequential, and responsive aspects. Our experiments show that LLMs maintain strong sequential consistency and semantic stability, while spatial deviations are larger for shorter trips but decrease with longer ones, indicating that extended plans encourage better geographic coherence. However, disruption-handling ability declines as plan length increases, highlighting limits in LLM robustness. TripTide establishes a benchmark for evaluating adaptability, personalization, and resilience in LLM-based travel planning under real-world uncertainty.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "93",
        "title": "SCORENF: Score-based Normalizing Flows for Sampling Unnormalized distributions",
        "author": [
            "Vikas Kanaujia",
            "Vipul Arora"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21330",
        "abstract": "Unnormalized probability distributions are central to modeling complex physical systems across various scientific domains. Traditional sampling methods, such as Markov Chain Monte Carlo (MCMC), often suffer from slow convergence, critical slowing down, poor mode mixing, and high autocorrelation. In contrast, likelihood-based and adversarial machine learning models, though effective, are heavily data-driven, requiring large datasets and often encountering mode covering and mode collapse. In this work, we propose ScoreNF, a score-based learning framework built on the Normalizing Flow (NF) architecture, integrated with an Independent Metropolis-Hastings (IMH) module, enabling efficient and unbiased sampling from unnormalized target distributions. We show that ScoreNF maintains high performance even with small training ensembles, thereby reducing reliance on computationally expensive MCMC-generated training data. We also present a method for assessing mode-covering and mode-collapse behaviours. We validate our method on synthetic 2D distributions (MOG-4 and MOG-8) and the high-dimensional $\\phi^4$ lattice field theory distribution, demonstrating its effectiveness for sampling tasks.",
        "tags": [
            "Normalizing Flows"
        ]
    },
    {
        "id": "94",
        "title": "Multi-turn Training with Basic Human Feedback Helps Little on LLM Reasoning",
        "author": [
            "Qiang Liu",
            "Wuganjing Song",
            "Zhenzhou Lin",
            "Feifan Chen",
            "Qiaolong Cai",
            "Chen Li",
            "Yongduo Sui"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21339",
        "abstract": "The reasoning capabilities of Large Language Models (LLMs) are typically developed through the single-turn reinforcement learning, whereas real-world applications often involve multi-turn interactions with human feedback, leading to a potential mismatch between training and deployment conditions. In this work, we study whether multi-turn training with human feedback is necessary for reasoning tasks. We compare conventional single-turn training with three multi-turn strategies and reach contrary conclusions to previous research. We find that models trained in a single-turn setting generalize effectively to both single- and multi-turn evaluations, while models trained with multi-turn strategies exhibit a significant degradation in single-turn reasoning performance. These results suggest that for tasks with complete information, robust single-turn training remains more effective and reliable, as multi-turn training with basic feedback provides limited benefits and can even degrade reasoning capabilities.",
        "tags": [
            "LLM",
            "RL"
        ]
    },
    {
        "id": "95",
        "title": "Magellan: Guided MCTS for Latent Space Exploration and Novelty Generation",
        "author": [
            "Lufan Chang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21341",
        "abstract": "Large Language Models (LLMs) often struggle with generating truly innovative ideas, typically defaulting to high-probability, familiar concepts within their training data's \"gravity wells.\" While advanced search-based methods like Tree of Thoughts (ToT) attempt to mitigate this, they are fundamentally limited by their reliance on unprincipled, inconsistent self-evaluation heuristics to guide exploration. To address this gap, we introduce \\textbf{Magellan}, a novel framework that reframes creative generation as a principled, guided exploration of an LLM's latent conceptual space. At its core, Magellan employs Monte Carlo Tree Search (MCTS) governed by a hierarchical guidance system. For long-range direction, a \"semantic compass\" vector, formulated via orthogonal projection, steers the search towards relevant novelty. For local, step-by-step decisions, a landscape-aware value function replaces flawed self-evaluation with an explicit reward structure that balances intrinsic coherence, extrinsic novelty, and narrative progress. Extensive experiments demonstrate that Magellan significantly outperforms strong baselines, including ReAct and ToT, in generating scientific ideas with superior plausibility and innovation. Our work shows that for creative discovery, a principled, guided search is more effective than unconstrained agency, paving the way for LLMs to become more capable partners in innovation.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "96",
        "title": "$Î±$-LoRA: Effective Fine-Tuning via Base Model Rescaling",
        "author": [
            "Aymane El Firdoussi",
            "El Mahdi Chayti",
            "Mohamed El Amine Seddik",
            "Martin Jaggi"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21345",
        "abstract": "Fine-tuning has proven to be highly effective in adapting pre-trained models to perform better on new desired tasks with minimal data samples. Among the most widely used approaches are reparameterization methods, which update a target module by augmenting its frozen weight matrix with an additional trainable weight matrix. The most prominent example is Low Rank Adaption (LoRA), which gained significant attention in recent years. In this paper, we introduce a new class of reparameterization methods for transfer learning, designed to enhance the generalization ability of fine-tuned models. We establish the effectiveness of our approach in a high-dimensional binary classification setting using tools from Random Matrix Theory, and further validate our theoretical findings through more realistic experiments, such as fine-tuning LLMs.",
        "tags": [
            "LLM",
            "LoRA"
        ]
    },
    {
        "id": "97",
        "title": "Dynamic Semantic-Aware Correlation Modeling for UAV Tracking",
        "author": [
            "Xinyu Zhou",
            "Tongxin Pan",
            "Lingyi Hong",
            "Pinxue Guo",
            "Haijing Guo",
            "Zhaoyu Chen",
            "Kaixun Jiang",
            "Wenqiang Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21351",
        "abstract": "UAV tracking can be widely applied in scenarios such as disaster rescue, environmental monitoring, and logistics transportation. However, existing UAV tracking methods predominantly emphasize speed and lack exploration in semantic awareness, which hinders the search region from extracting accurate localization information from the template. The limitation results in suboptimal performance under typical UAV tracking challenges such as camera motion, fast motion, and low resolution, etc. To address this issue, we propose a dynamic semantic aware correlation modeling tracking framework. The core of our framework is a Dynamic Semantic Relevance Generator, which, in combination with the correlation map from the Transformer, explore semantic relevance. The approach enhances the search region's ability to extract important information from the template, improving accuracy and robustness under the aforementioned challenges. Additionally, to enhance the tracking speed, we design a pruning method for the proposed framework. Therefore, we present multiple model variants that achieve trade-offs between speed and accuracy, enabling flexible deployment according to the available computational resources. Experimental results validate the effectiveness of our method, achieving competitive performance on multiple UAV tracking datasets. The code is available at https://github.com/zxyyxzz/DSATrack.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "98",
        "title": "Gaze-VLM:Bridging Gaze and VLMs through Attention Regularization for Egocentric Understanding",
        "author": [
            "Anupam Pani",
            "Yanchao Yang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21356",
        "abstract": "Eye gaze offers valuable cues about attention, short-term intent, and future actions, making it a powerful signal for modeling egocentric behavior. In this work, we propose a gaze-regularized framework that enhances VLMs for two key egocentric understanding tasks: fine-grained future event prediction and current activity understanding. Unlike prior approaches that rely solely on visual inputs or use gaze as an auxiliary input signal , our method uses gaze only during training. We introduce a gaze-regularized attention mechanism that aligns model focus with human visual gaze. This design is flexible and modular, allowing it to generalize across multiple VLM architectures that utilize attention. Experimental results show that our approach improves semantic prediction scores by up to 11 for future event prediction and around 7 for current activity understanding, compared to the corresponding baseline models trained without gaze regularization. These results highlight the value of gaze-guided training in improving the accuracy and robustness of egocentric VLMs. Overall, this work establishes a foundation for using human gaze to enhance the predictive capabilities of VLMs in real-world scenarios like assistive robots and human-machine collaboration. Code and additional information is available at: https://github.com/anupampani/Gaze-VLM",
        "tags": [
            "VLM"
        ]
    },
    {
        "id": "99",
        "title": "Compositional Monte Carlo Tree Diffusion for Extendable Planning",
        "author": [
            "Jaesik Yoon",
            "Hyeonseo Cho",
            "Sungjin Ahn"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21361",
        "abstract": "Monte Carlo Tree Diffusion (MCTD) integrates diffusion models with structured tree search to enable effective trajectory exploration through stepwise reasoning. However, MCTD remains fundamentally limited by training trajectory lengths. While periodic replanning allows plan concatenation for longer plan generation, the planning process remains locally confined, as MCTD searches within individual trajectories without access to global context. We propose Compositional Monte Carlo Tree Diffusion (C-MCTD), a framework that elevates planning from individual trajectory optimization to reasoning over complete plan compositions. C-MCTD introduces three complementary components: (1) Online Composer, which performs globally-aware planning by searching across entire plan compositions; (2) Distributed Composer, which reduces search complexity through parallel exploration from multiple starting points; and (3) Preplan Composer, which accelerates inference by leveraging cached plan graphs.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "100",
        "title": "FairImagen: Post-Processing for Bias Mitigation in Text-to-Image Models",
        "author": [
            "Zihao Fu",
            "Ryan Brown",
            "Shun Shao",
            "Kai Rawal",
            "Eoin Delaney",
            "Chris Russell"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21363",
        "abstract": "Text-to-image diffusion models, such as Stable Diffusion, have demonstrated remarkable capabilities in generating high-quality and diverse images from natural language prompts. However, recent studies reveal that these models often replicate and amplify societal biases, particularly along demographic attributes like gender and race. In this paper, we introduce FairImagen (https://github.com/fuzihaofzh/FairImagen), a post-hoc debiasing framework that operates on prompt embeddings to mitigate such biases without retraining or modifying the underlying diffusion model. Our method integrates Fair Principal Component Analysis to project CLIP-based input embeddings into a subspace that minimizes group-specific information while preserving semantic content. We further enhance debiasing effectiveness through empirical noise injection and propose a unified cross-demographic projection method that enables simultaneous debiasing across multiple demographic attributes. Extensive experiments across gender, race, and intersectional settings demonstrate that FairImagen significantly improves fairness with a moderate trade-off in image quality and prompt fidelity. Our framework outperforms existing post-hoc methods and offers a simple, scalable, and model-agnostic solution for equitable text-to-image generation.",
        "tags": [
            "CLIP",
            "Diffusion",
            "Text-to-Image"
        ]
    },
    {
        "id": "101",
        "title": "SindBERT, the Sailor: Charting the Seas of Turkish NLP",
        "author": [
            "Raphael Scheible-Schmitt",
            "Stefan Schweter"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21364",
        "abstract": "Transformer models have revolutionized NLP, yet many morphologically rich languages remain underrepresented in large-scale pre-training efforts. With SindBERT, we set out to chart the seas of Turkish NLP, providing the first large-scale RoBERTa-based encoder for Turkish. Trained from scratch on 312 GB of Turkish text (mC4, OSCAR23, Wikipedia), SindBERT is released in both base and large configurations, representing the first large-scale encoder-only language model available for Turkish. We evaluate SindBERT on part-of-speech tagging, named entity recognition, offensive language detection, and the TurBLiMP linguistic acceptability benchmark. Our results show that SindBERT performs competitively with existing Turkish and multilingual models, with the large variant achieving the best scores in two of four tasks but showing no consistent scaling advantage overall. This flat scaling trend, also observed for XLM-R and EuroBERT, suggests that current Turkish benchmarks may already be saturated. At the same time, comparisons with smaller but more curated models such as BERTurk highlight that corpus quality and diversity can outweigh sheer data volume. Taken together, SindBERT contributes both as an openly released resource for Turkish NLP and as an empirical case study on the limits of scaling and the central role of corpus composition in morphologically rich languages. The SindBERT models are released under the MIT license and made available in both fairseq and Huggingface formats.",
        "tags": [
            "Detection",
            "Transformer"
        ]
    },
    {
        "id": "102",
        "title": "BADiff: Bandwidth Adaptive Diffusion Model",
        "author": [
            "Xi Zhang",
            "Hanwei Zhu",
            "Yan Zhong",
            "Jiamang Wang",
            "Weisi Lin"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21366",
        "abstract": "In this work, we propose a novel framework to enable diffusion models to adapt their generation quality based on real-time network bandwidth constraints. Traditional diffusion models produce high-fidelity images by performing a fixed number of denoising steps, regardless of downstream transmission limitations. However, in practical cloud-to-device scenarios, limited bandwidth often necessitates heavy compression, leading to loss of fine textures and wasted computation. To address this, we introduce a joint end-to-end training strategy where the diffusion model is conditioned on a target quality level derived from the available bandwidth. During training, the model learns to adaptively modulate the denoising process, enabling early-stop sampling that maintains perceptual quality appropriate to the target transmission condition. Our method requires minimal architectural changes and leverages a lightweight quality embedding to guide the denoising trajectory. Experimental results demonstrate that our approach significantly improves the visual fidelity of bandwidth-adapted generations compared to naive early-stopping, offering a promising solution for efficient image delivery in bandwidth-constrained environments. Code is available at: https://github.com/xzhang9308/BADiff.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "103",
        "title": "Load-bearing Assessment for Safe Locomotion of Quadruped Robots on Collapsing Terrain",
        "author": [
            "Vivian S. Medeiros",
            "Giovanni B. Dessy",
            "Thiago Boaventura",
            "Marcelo Becker",
            "Claudio Semini",
            "Victor Barasuol"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21369",
        "abstract": "Collapsing terrains, often present in search and rescue missions or planetary exploration, pose significant challenges for quadruped robots. This paper introduces a robust locomotion framework for safe navigation over unstable surfaces by integrating terrain probing, load-bearing analysis, motion planning, and control strategies. Unlike traditional methods that rely on specialized sensors or external terrain mapping alone, our approach leverages joint measurements to assess terrain stability without hardware modifications. A Model Predictive Control (MPC) system optimizes robot motion, balancing stability and probing constraints, while a state machine coordinates terrain probing actions, enabling the robot to detect collapsible regions and dynamically adjust its footholds. Experimental results on custom-made collapsing platforms and rocky terrains demonstrate the framework's ability to traverse collapsing terrain while maintaining stability and prioritizing safety.",
        "tags": [
            "MPC",
            "Robotics"
        ]
    },
    {
        "id": "104",
        "title": "HalleluBERT: Let every token that has meaning bear its weight",
        "author": [
            "Raphael Scheible-Schmitt"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21372",
        "abstract": "Transformer-based models have advanced NLP, yet Hebrew still lacks a large-scale RoBERTa encoder which is extensively trained. Existing models such as HeBERT, AlephBERT, and HeRo are limited by corpus size, vocabulary, or training depth. We present HalleluBERT, a RoBERTa-based encoder family (base and large) trained from scratch on 49.1~GB of deduplicated Hebrew web text and Wikipedia with a Hebrew-specific byte-level BPE vocabulary. Evaluated on NER and sentiment classification benchmarks, HalleluBERT outperforms both monolingual and multilingual baselines. HalleluBERT sets a new state of the art for Hebrew and highlights the benefits of fully converged monolingual pretraining.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "105",
        "title": "Low-Complexity MIMO Channel Estimation with Latent Diffusion Models",
        "author": [
            "Xiaotian Fan",
            "Xingyu Zhou",
            "Le Liang",
            "Shi Jin"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21386",
        "abstract": "Deep generative models offer a powerful alternative to conventional channel estimation by learning the complex prior distribution of wireless channels. Capitalizing on this potential, this paper proposes a novel channel estimation algorithm based on latent diffusion models (LDMs), termed posterior sampling with latent diffusion for channel estimation (PSLD-CE). The core of our approach is a lightweight LDM architecture specifically designed for channel estimation, which serves as a powerful generative prior to capture the intricate channel distribution. Furthermore, we enhance the diffusion posterior sampling process by introducing an effective approximation for the likelihood term and a tailored self-consistency constraint on the variational autoencoder latent space. Extensive experimental results demonstrate that PSLD-CE consistently outperforms a wide range of existing methods. Notably, these significant performance gains are achieved while maintaining low computational complexity and fast inference speed, establishing our method as a highly promising and practical solution for next-generation wireless systems.",
        "tags": [
            "Diffusion",
            "LDMs"
        ]
    },
    {
        "id": "106",
        "title": "Boosting Accuracy and Efficiency of Budget Forcing in LLMs via Reinforcement Learning for Mathematical Reasoning",
        "author": [
            "Ravindra Aribowo Tarunokusumo",
            "Rafael Fernandes Cunha"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21398",
        "abstract": "Test-time scaling methods have seen a rapid increase in popularity for its computational efficiency and parameter-independent training to improve reasoning performance on Large Language Models. One such method is called budget forcing, a decoding intervention strategy which allocates extra compute budget for thinking and elicits the inherent self-correcting behavior of the model. However, this relies on supervised fine-tuning (SFT) on long-context reasoning traces which causes performance degradation on smaller models due to verbose responses. For this reason, we offer a framework integrating reinforcement learning (RL) to improve token efficiency and boost the performance of a 1.5B model for mathematical reasoning. We demonstrate this using only 1.5K training samples and found that our SFT+RL model performed better on the GSM8K dataset with varying compute budgets. Our main findings showed an overall higher accuracy while significantly reducing its token usage by over 40% compared to the SFT model, revealing how RL can recover the losses due to long-context training and altogether improving performance in mathematical reasoning.",
        "tags": [
            "LLM",
            "RL"
        ]
    },
    {
        "id": "107",
        "title": "FLAMES: Fine-tuning LLMs to Synthesize Invariants for Smart Contract Security",
        "author": [
            "Mojtaba Eshghie",
            "Gabriele Morello",
            "Matteo Lauretano",
            "Alexandre Bartel",
            "Martin Monperrus"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21401",
        "abstract": "Smart contract vulnerabilities cost billions of dollars annually, yet existing automated analysis tools fail to generate deployable defenses. We present FLAMES, a novel automated approach that synthesizes executable runtime guards as Solidity \"require\" statements to harden smart contracts against exploits. Unlike prior work that relies on vulnerability labels, symbolic analysis, or natural language specifications, FLAMES employs domain-adapted large language models trained through fill-in-the-middle supervised fine-tuning on real-world invariants extracted from 514,506 verified contracts. Our extensive evaluation across three dimensions demonstrates FLAMES's effectiveness: (1) Compilation: FLAMES achieves 96.7% compilability for synthesized invariant (2) Semantic Quality: on a curated test set of 5,000 challenging invariants, FLAMES produces exact or semantically equivalent matches to ground truth in 44.5% of cases; (3) Exploit Mitigation: FLAMES prevents 22 out of 108 real exploits (20.4%) while preserving contract functionality, and (4) FLAMES successfully blocks the real-world APEMAGA incident by synthesizing a pre-condition that mitigates the attack. FLAMES establishes that domain-adapted LLMs can automatically generate production-ready security defenses for smart contracts without requiring vulnerability detection, formal specifications, or human intervention. We release our code, model weights, datasets, and evaluation infrastructure to enable reproducible research in this critical domain.",
        "tags": [
            "Detection",
            "LLM"
        ]
    },
    {
        "id": "108",
        "title": "Unveiling the Spatial-temporal Effective Receptive Fields of Spiking Neural Networks",
        "author": [
            "Jieyuan Zhang",
            "Xiaolong Zhou",
            "Shuai Wang",
            "Wenjie Wei",
            "Hanwen Liu",
            "Qian Sun",
            "Malu Zhang",
            "Yang Yang",
            "Haizhou Li"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21403",
        "abstract": "Spiking Neural Networks (SNNs) demonstrate significant potential for energy-efficient neuromorphic computing through an event-driven paradigm. While training methods and computational models have greatly advanced, SNNs struggle to achieve competitive performance in visual long-sequence modeling tasks. In artificial neural networks, the effective receptive field (ERF) serves as a valuable tool for analyzing feature extraction capabilities in visual long-sequence modeling. Inspired by this, we introduce the Spatio-Temporal Effective Receptive Field (ST-ERF) to analyze the ERF distributions across various Transformer-based SNNs. Based on the proposed ST-ERF, we reveal that these models suffer from establishing a robust global ST-ERF, thereby limiting their visual feature modeling capabilities. To overcome this issue, we propose two novel channel-mixer architectures: \\underline{m}ulti-\\underline{l}ayer-\\underline{p}erceptron-based m\\underline{ixer} (MLPixer) and \\underline{s}plash-and-\\underline{r}econstruct \\underline{b}lock (SRB). These architectures enhance global spatial ERF through all timesteps in early network stages of Transformer-based SNNs, improving performance on challenging visual long-sequence modeling tasks. Extensive experiments conducted on the Meta-SDT variants and across object detection and semantic segmentation tasks further validate the effectiveness of our proposed method. Beyond these specific applications, we believe the proposed ST-ERF framework can provide valuable insights for designing and optimizing SNN architectures across a broader range of tasks. The code is available at \\href{https://github.com/EricZhang1412/Spatial-temporal-ERF}{\\faGithub~EricZhang1412/Spatial-temporal-ERF}.",
        "tags": [
            "Detection",
            "Segmentation",
            "Transformer"
        ]
    },
    {
        "id": "109",
        "title": "MUVR: A Multi-Modal Untrimmed Video Retrieval Benchmark with Multi-Level Visual Correspondence",
        "author": [
            "Yue Feng",
            "Jinwei Hu",
            "Qijia Lu",
            "Jiawei Niu",
            "Li Tan",
            "Shuo Yuan",
            "Ziyi Yan",
            "Yizhen Jia",
            "Qingzhi He",
            "Shiping Ge",
            "Ethan Q. Chen",
            "Wentong Li",
            "Limin Wang",
            "Jie Qin"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21406",
        "abstract": "We propose the Multi-modal Untrimmed Video Retrieval task, along with a new benchmark (MUVR) to advance video retrieval for long-video platforms. MUVR aims to retrieve untrimmed videos containing relevant segments using multi-modal queries. It has the following features: 1) Practical retrieval paradigm: MUVR supports video-centric multi-modal queries, expressing fine-grained retrieval needs through long text descriptions, video tag prompts, and mask prompts. It adopts a one-to-many retrieval paradigm and focuses on untrimmed videos, tailored for long-video platform applications. 2) Multi-level visual correspondence: To cover common video categories (e.g., news, travel, dance) and precisely define retrieval matching criteria, we construct multi-level visual correspondence based on core video content (e.g., news events, travel locations, dance moves) which users are interested in and want to retrieve. It covers six levels: copy, event, scene, instance, action, and others. 3) Comprehensive evaluation criteria: We develop 3 versions of MUVR (i.e., Base, Filter, QA). MUVR-Base/Filter evaluates retrieval models, while MUVR-QA assesses MLLMs in a question-answering format. We also propose a Reranking Score to evaluate the reranking ability of MLLMs. MUVR consists of 53K untrimmed videos from the video platform Bilibili, with 1,050 multi-modal queries and 84K matches. Extensive evaluations of 3 state-of-the-art video retrieval models, 6 image-based VLMs, and 10 MLLMs are conducted. MUVR reveals the limitations of retrieval methods in processing untrimmed videos and multi-modal queries, as well as MLLMs in multi-video understanding and reranking. Our code and benchmark is available at https://github.com/debby-0527/MUVR.",
        "tags": [
            "VLM"
        ]
    },
    {
        "id": "110",
        "title": "REvolution: An Evolutionary Framework for RTL Generation driven by Large Language Models",
        "author": [
            "Kyungjun Min",
            "Kyumin Cho",
            "Junhwan Jang",
            "Seokhyeong Kang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21407",
        "abstract": "Large Language Models (LLMs) are used for Register-Transfer Level (RTL) code generation, but they face two main challenges: functional correctness and Power, Performance, and Area (PPA) optimization. Iterative, feedback-based methods partially address these, but they are limited to local search, hindering the discovery of a global optimum. This paper introduces REvolution, a framework that combines Evolutionary Computation (EC) with LLMs for automatic RTL generation and optimization. REvolution evolves a population of candidates in parallel, each defined by a design strategy, RTL implementation, and evaluation feedback. The framework includes a dual-population algorithm that divides candidates into Fail and Success groups for bug fixing and PPA optimization, respectively. An adaptive mechanism further improves search efficiency by dynamically adjusting the selection probability of each prompt strategy according to its success rate. Experiments on the VerilogEval and RTLLM benchmarks show that REvolution increased the initial pass rate of various LLMs by up to 24.0 percentage points. The DeepSeek-V3 model achieved a final pass rate of 95.5\\%, comparable to state-of-the-art results, without the need for separate training or domain-specific tools. Additionally, the generated RTL designs showed significant PPA improvements over reference designs. This work introduces a new RTL design approach by combining LLMs' generative capabilities with EC's broad search power, overcoming the local-search limitations of previous methods.",
        "tags": [
            "DeepSeek",
            "LLM"
        ]
    },
    {
        "id": "111",
        "title": "Large Language Models as Model Organisms for Human Associative Learning",
        "author": [
            "Camila Kolling",
            "Vy Ai Vo",
            "Mariya Toneva"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21408",
        "abstract": "Associative learning--forming links between co-occurring items--is fundamental to human cognition, reshaping internal representations in complex ways. Testing hypotheses on how representational changes occur in biological systems is challenging, but large language models (LLMs) offer a scalable alternative. Building on LLMs' in-context learning, we adapt a cognitive neuroscience associative learning paradigm and investigate how representations evolve across six models. Our initial findings reveal a non-monotonic pattern consistent with the Non-Monotonic Plasticity Hypothesis, with moderately similar items differentiating after learning. Leveraging the controllability of LLMs, we further show that this differentiation is modulated by the overlap of associated items with the broader vocabulary--a factor we term vocabulary interference, capturing how new associations compete with prior knowledge. We find that higher vocabulary interference amplifies differentiation, suggesting that representational change is influenced by both item similarity and global competition. Our findings position LLMs not only as powerful tools for studying representational dynamics in human-like learning systems, but also as accessible and general computational models for generating new hypotheses about the principles underlying memory reorganization in the brain.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "112",
        "title": "Self-diffusion for Solving Inverse Problems",
        "author": [
            "Guanxiong Luo",
            "Shoujin Huang",
            "Yanlong Yang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21417",
        "abstract": "We propose self-diffusion, a novel framework for solving inverse problems without relying on pretrained generative models. Traditional diffusion-based approaches require training a model on a clean dataset to learn to reverse the forward noising process. This model is then used to sample clean solutions -- corresponding to posterior sampling from a Bayesian perspective -- that are consistent with the observed data under a specific task. In contrast, self-diffusion introduces a self-contained iterative process that alternates between noising and denoising steps to progressively refine its estimate of the solution. At each step of self-diffusion, noise is added to the current estimate, and a self-denoiser, which is a single untrained convolutional network randomly initialized from scratch, is continuously trained for certain iterations via a data fidelity loss to predict the solution from the noisy estimate. Essentially, self-diffusion exploits the spectral bias of neural networks and modulates it through a scheduled noise process. Without relying on pretrained score functions or external denoisers, this approach still remains adaptive to arbitrary forward operators and noisy observations, making it highly flexible and broadly applicable. We demonstrate the effectiveness of our approach on a variety of linear inverse problems, showing that self-diffusion achieves competitive or superior performance compared to other methods.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "113",
        "title": "Vision Language Models for Dynamic Human Activity Recognition in Healthcare Settings",
        "author": [
            "Abderrazek Abid",
            "Thanh-Cong Ho",
            "Fakhri Karray"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21424",
        "abstract": "As generative AI continues to evolve, Vision Language Models (VLMs) have emerged as promising tools in various healthcare applications. One area that remains relatively underexplored is their use in human activity recognition (HAR) for remote health monitoring. VLMs offer notable strengths, including greater flexibility and the ability to overcome some of the constraints of traditional deep learning models. However, a key challenge in applying VLMs to HAR lies in the difficulty of evaluating their dynamic and often non-deterministic outputs. To address this gap, we introduce a descriptive caption data set and propose comprehensive evaluation methods to evaluate VLMs in HAR. Through comparative experiments with state-of-the-art deep learning models, our findings demonstrate that VLMs achieve comparable performance and, in some cases, even surpass conventional approaches in terms of accuracy. This work contributes a strong benchmark and opens new possibilities for the integration of VLMs into intelligent healthcare systems.",
        "tags": [
            "VLM"
        ]
    },
    {
        "id": "114",
        "title": "Advancing Symbolic Integration in Large Language Models: Beyond Conventional Neurosymbolic AI",
        "author": [
            "Maneeha Rani",
            "Bhupesh Kumar Mishra",
            "Dhavalkumar Thakker"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21425",
        "abstract": "LLMs have demonstrated highly effective learning, human-like response generation,and decision-making capabilities in high-risk sectors. However, these models remain black boxes because they struggle to ensure transparency in responses. The literature has explored numerous approaches to address transparency challenges in LLMs, including Neurosymbolic AI (NeSy AI). NeSy AI approaches were primarily developed for conventional neural networks and are not well-suited to the unique features of LLMs. Consequently, there is a limited systematic understanding of how symbolic AI can be effectively integrated into LLMs. This paper aims to address this gap by first reviewing established NeSy AI methods and then proposing a novel taxonomy of symbolic integration in LLMs, along with a roadmap to merge symbolic techniques with LLMs. The roadmap introduces a new categorisation framework across four dimensions by organising existing literature within these categories. These include symbolic integration across various stages of LLM, coupling mechanisms, architectural paradigms, as well as algorithmic and application-level perspectives. The paper thoroughly identifies current benchmarks, cutting-edge advancements, and critical gaps within the field to propose a roadmap for future research. By highlighting the latest developments and notable gaps in the literature, it offers practical insights for implementing frameworks for symbolic integration into LLMs to enhance transparency.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "115",
        "title": "Causality Meets Locality: Provably Generalizable and Scalable Policy Learning for Networked Systems",
        "author": [
            "Hao Liang",
            "Shuqing Shi",
            "Yudi Zhang",
            "Biwei Huang",
            "Yali Du"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21427",
        "abstract": "Large-scale networked systems, such as traffic, power, and wireless grids, challenge reinforcement-learning agents with both scale and environment shifts. To address these challenges, we propose GSAC (Generalizable and Scalable Actor-Critic), a framework that couples causal representation learning with meta actor-critic learning to achieve both scalability and domain generalization. Each agent first learns a sparse local causal mask that provably identifies the minimal neighborhood variables influencing its dynamics, yielding exponentially tight approximately compact representations (ACRs) of state and domain factors. These ACRs bound the error of truncating value functions to $\\kappa$-hop neighborhoods, enabling efficient learning on graphs. A meta actor-critic then trains a shared policy across multiple source domains while conditioning on the compact domain factors; at test time, a few trajectories suffice to estimate the new domain factor and deploy the adapted policy. We establish finite-sample guarantees on causal recovery, actor-critic convergence, and adaptation gap, and show that GSAC adapts rapidly and significantly outperforms learning-from-scratch and conventional adaptation baselines.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "116",
        "title": "ArtiLatent: Realistic Articulated 3D Object Generation via Structured Latents",
        "author": [
            "Honghua Chen",
            "Yushi Lan",
            "Yongwei Chen",
            "Xingang Pan"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21432",
        "abstract": "We propose ArtiLatent, a generative framework that synthesizes human-made 3D objects with fine-grained geometry, accurate articulation, and realistic appearance. Our approach jointly models part geometry and articulation dynamics by embedding sparse voxel representations and associated articulation properties, including joint type, axis, origin, range, and part category, into a unified latent space via a variational autoencoder. A latent diffusion model is then trained over this space to enable diverse yet physically plausible sampling. To reconstruct photorealistic 3D shapes, we introduce an articulation-aware Gaussian decoder that accounts for articulation-dependent visibility changes (e.g., revealing the interior of a drawer when opened). By conditioning appearance decoding on articulation state, our method assigns plausible texture features to regions that are typically occluded in static poses, significantly improving visual realism across articulation configurations. Extensive experiments on furniture-like objects from PartNet-Mobility and ACD datasets demonstrate that ArtiLatent outperforms existing approaches in geometric consistency and appearance fidelity. Our framework provides a scalable solution for articulated 3D object synthesis and manipulation.",
        "tags": [
            "3D",
            "Diffusion"
        ]
    },
    {
        "id": "117",
        "title": "AutoOpt: A Dataset and a Unified Framework for Automating Optimization Problem Solving",
        "author": [
            "Ankur Sinha",
            "Shobhit Arora",
            "Dhaval Pujara"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21436",
        "abstract": "This study presents AutoOpt-11k, a unique image dataset of over 11,000 handwritten and printed mathematical optimization models corresponding to single-objective, multi-objective, multi-level, and stochastic optimization problems exhibiting various types of complexities such as non-linearity, non-convexity, non-differentiability, discontinuity, and high-dimensionality. The labels consist of the LaTeX representation for all the images and modeling language representation for a subset of images. The dataset is created by 25 experts following ethical data creation guidelines and verified in two-phases to avoid errors. Further, we develop AutoOpt framework, a machine learning based automated approach for solving optimization problems, where the user just needs to provide an image of the formulation and AutoOpt solves it efficiently without any further human intervention. AutoOpt framework consists of three Modules: (i) M1 (Image_to_Text)- a deep learning model performs the Mathematical Expression Recognition (MER) task to generate the LaTeX code corresponding to the optimization formulation in image; (ii) M2 (Text_to_Text)- a small-scale fine-tuned LLM generates the PYOMO script (optimization modeling language) from LaTeX code; (iii) M3 (Optimization)- a Bilevel Optimization based Decomposition (BOBD) method solves the optimization formulation described in the PYOMO script. We use AutoOpt-11k dataset for training and testing of deep learning models employed in AutoOpt. The deep learning model for MER task (M1) outperforms ChatGPT, Gemini and Nougat on BLEU score metric. BOBD method (M3), which is a hybrid approach, yields better results on complex test problems compared to common approaches, like interior-point algorithm and genetic algorithm.",
        "tags": [
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "118",
        "title": "Redefining Retrieval Evaluation in the Era of LLMs",
        "author": [
            "Giovanni Trappolini",
            "Florin Cuconasu",
            "Simone Filice",
            "Yoelle Maarek",
            "Fabrizio Silvestri"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21440",
        "abstract": "Traditional Information Retrieval (IR) metrics, such as nDCG, MAP, and MRR, assume that human users sequentially examine documents with diminishing attention to lower ranks. This assumption breaks down in Retrieval Augmented Generation (RAG) systems, where search results are consumed by Large Language Models (LLMs), which, unlike humans, process all retrieved documents as a whole rather than sequentially. Additionally, traditional IR metrics do not account for related but irrelevant documents that actively degrade generation quality, rather than merely being ignored. Due to these two major misalignments, namely human vs. machine position discount and human relevance vs. machine utility, classical IR metrics do not accurately predict RAG performance. We introduce a utility-based annotation schema that quantifies both the positive contribution of relevant passages and the negative impact of distracting ones. Building on this foundation, we propose UDCG (Utility and Distraction-aware Cumulative Gain), a metric using an LLM-oriented positional discount to directly optimize the correlation with the end-to-end answer accuracy. Experiments on five datasets and six LLMs demonstrate that UDCG improves correlation by up to 36% compared to traditional metrics. Our work provides a critical step toward aligning IR evaluation with LLM consumers and enables more reliable assessment of RAG components",
        "tags": [
            "LLM",
            "RAG"
        ]
    },
    {
        "id": "119",
        "title": "Does Model Size Matter? A Comparison of Small and Large Language Models for Requirements Classification",
        "author": [
            "Mohammad Amin Zadenoori",
            "Vincenzo De Martino",
            "Jacek Dabrowski",
            "Xavier Franch",
            "Alessio Ferrari"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21443",
        "abstract": "[Context and motivation] Large language models (LLMs) show notable results in natural language processing (NLP) tasks for requirements engineering (RE). However, their use is compromised by high computational cost, data sharing risks, and dependence on external services. In contrast, small language models (SLMs) offer a lightweight, locally deployable alternative. [Question/problem] It remains unclear how well SLMs perform compared to LLMs in RE tasks in terms of accuracy. [Results] Our preliminary study compares eight models, including three LLMs and five SLMs, on requirements classification tasks using the PROMISE, PROMISE Reclass, and SecReq datasets. Our results show that although LLMs achieve an average F1 score of 2% higher than SLMs, this difference is not statistically significant. SLMs almost reach LLMs performance across all datasets and even outperform them in recall on the PROMISE Reclass dataset, despite being up to 300 times smaller. We also found that dataset characteristics play a more significant role in performance than model size. [Contribution] Our study contributes with evidence that SLMs are a valid alternative to LLMs for requirements classification, offering advantages in privacy, cost, and local deployability.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "120",
        "title": "PhysWorld: From Real Videos to World Models of Deformable Objects via Physics-Aware Demonstration Synthesis",
        "author": [
            "Yu Yang",
            "Zhilu Zhang",
            "Xiang Zhang",
            "Yihan Zeng",
            "Hui Li",
            "Wangmeng Zuo"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21447",
        "abstract": "Interactive world models that simulate object dynamics are crucial for robotics, VR, and AR. However, it remains a significant challenge to learn physics-consistent dynamics models from limited real-world video data, especially for deformable objects with spatially-varying physical properties. To overcome the challenge of data scarcity, we propose PhysWorld, a novel framework that utilizes a simulator to synthesize physically plausible and diverse demonstrations to learn efficient world models. Specifically, we first construct a physics-consistent digital twin within MPM simulator via constitutive model selection and global-to-local optimization of physical properties. Subsequently, we apply part-aware perturbations to the physical properties and generate various motion patterns for the digital twin, synthesizing extensive and diverse demonstrations. Finally, using these demonstrations, we train a lightweight GNN-based world model that is embedded with physical properties. The real video can be used to further refine the physical properties. PhysWorld achieves accurate and fast future predictions for various deformable objects, and also generalizes well to novel interactions. Experiments show that PhysWorld has competitive performance while enabling inference speeds 47 times faster than the recent state-of-the-art method, i.e., PhysTwin.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "121",
        "title": "Unified token representations for sequential decision models",
        "author": [
            "Zhuojing Tian",
            "Yushu Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21448",
        "abstract": "Transformers have demonstrated strong potential in offline reinforcement learning (RL) by modeling trajectories as sequences of return-to-go, states, and actions. However, existing approaches such as the Decision Transformer(DT) and its variants suffer from redundant tokenization and quadratic attention complexity, limiting their scalability in real-time or resource-constrained settings. To address this, we propose a Unified Token Representation (UTR) that merges return-to-go, state, and action into a single token, substantially reducing sequence length and model complexity. Theoretical analysis shows that UTR leads to a tighter Rademacher complexity bound, suggesting improved generalization. We further develop two variants: UDT and UDC, built upon transformer and gated CNN backbones, respectively. Both achieve comparable or superior performance to state-of-the-art methods with markedly lower computation. These findings demonstrate that UTR generalizes well across architectures and may provide an efficient foundation for scalable control in future large decision models.",
        "tags": [
            "RL",
            "Transformer"
        ]
    },
    {
        "id": "122",
        "title": "ParaRNN: Unlocking Parallel Training of Nonlinear RNNs for Large Language Models",
        "author": [
            "Federico Danieli",
            "Pau Rodriguez",
            "Miguel Sarabia",
            "Xavier Suau",
            "Luca Zappella"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21450",
        "abstract": "Recurrent Neural Networks (RNNs) laid the foundation for sequence modeling, but their intrinsic sequential nature restricts parallel computation, creating a fundamental barrier to scaling. This has led to the dominance of parallelizable architectures like Transformers and, more recently, State Space Models (SSMs). While SSMs achieve efficient parallelization through structured linear recurrences, this linearity constraint limits their expressive power and precludes modeling complex, nonlinear sequence-wise dependencies. To address this, we present ParaRNN, a framework that breaks the sequence-parallelization barrier for nonlinear RNNs. Building on prior work, we cast the sequence of nonlinear recurrence relationships as a single system of equations, which we solve in parallel using Newton's iterations combined with custom parallel reductions. Our implementation achieves speedups of up to 665x over naive sequential application, allowing training nonlinear RNNs at unprecedented scales. To showcase this, we apply ParaRNN to adaptations of LSTM and GRU architectures, successfully training models of 7B parameters that attain perplexity comparable to similarly-sized Transformers and Mamba2 architectures. To accelerate research in efficient sequence modeling, we release the ParaRNN codebase as an open-source framework for automatic training-parallelization of nonlinear RNNs, enabling researchers and practitioners to explore new nonlinear RNN models at scale.",
        "tags": [
            "LLM",
            "RNN",
            "SSMs"
        ]
    },
    {
        "id": "123",
        "title": "Multi-Task Vehicle Routing Solver via Mixture of Specialized Experts under State-Decomposable MDP",
        "author": [
            "Yuxin Pan",
            "Zhiguang Cao",
            "Chengyang Gu",
            "Liu Liu",
            "Peilin Zhao",
            "Yize Chen",
            "Fangzhen Lin"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21453",
        "abstract": "Existing neural methods for multi-task vehicle routing problems (VRPs) typically learn unified solvers to handle multiple constraints simultaneously. However, they often underutilize the compositional structure of VRP variants, each derivable from a common set of basis VRP variants. This critical oversight causes unified solvers to miss out the potential benefits of basis solvers, each specialized for a basis VRP variant. To overcome this limitation, we propose a framework that enables unified solvers to perceive the shared-component nature across VRP variants by proactively reusing basis solvers, while mitigating the exponential growth of trained neural solvers. Specifically, we introduce a State-Decomposable MDP (SDMDP) that reformulates VRPs by expressing the state space as the Cartesian product of basis state spaces associated with basis VRP variants. More crucially, this formulation inherently yields the optimal basis policy for each basis VRP variant. Furthermore, a Latent Space-based SDMDP extension is developed by incorporating both the optimal basis policies and a learnable mixture function to enable the policy reuse in the latent space. Under mild assumptions, this extension provably recovers the optimal unified policy of SDMDP through the mixture function that computes the state embedding as a mapping from the basis state embeddings generated by optimal basis policies. For practical implementation, we introduce the Mixture-of-Specialized-Experts Solver (MoSES), which realizes basis policies through specialized Low-Rank Adaptation (LoRA) experts, and implements the mixture function via an adaptive gating mechanism. Extensive experiments conducted across VRP variants showcase the superiority of MoSES over prior methods.",
        "tags": [
            "LoRA"
        ]
    },
    {
        "id": "124",
        "title": "SBASH: a Framework for Designing and Evaluating RAG vs. Prompt-Tuned LLM Honeypots",
        "author": [
            "Adetayo Adebimpe",
            "Helmut Neukirchen",
            "Thomas Welsh"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21459",
        "abstract": "Honeypots are decoy systems used for gathering valuable threat intelligence or diverting attackers away from production systems. Maximising attacker engagement is essential to their utility. However research has highlighted that context-awareness, such as the ability to respond to new attack types, systems and attacker agents, is necessary to increase engagement. Large Language Models (LLMs) have been shown as one approach to increase context awareness but suffer from several challenges including accuracy and timeliness of response time, high operational costs and data-protection issues due to cloud deployment. We propose the System-Based Attention Shell Honeypot (SBASH) framework which manages data-protection issues through the use of lightweight local LLMs. We investigate the use of Retrieval Augmented Generation (RAG) supported LLMs and non-RAG LLMs for Linux shell commands and evaluate them using several different metrics such as response time differences, realism from human testers, and similarity to a real system calculated with Levenshtein distance, SBert, and BertScore. We show that RAG improves accuracy for untuned models while models that have been tuned via a system prompt that tells the LLM to respond like a Linux system achieve without RAG a similar accuracy as untuned with RAG, while having a slightly lower latency.",
        "tags": [
            "LLM",
            "RAG"
        ]
    },
    {
        "id": "125",
        "title": "Risk Management for Mitigating Benchmark Failure Modes: BenchRisk",
        "author": [
            "Sean McGregor",
            "Victor Lu",
            "Vassil Tashev",
            "Armstrong Foundjem",
            "Aishwarya Ramasethu",
            "Sadegh AlMahdi Kazemi Zarkouei",
            "Chris Knotz",
            "Kongtao Chen",
            "Alicia Parrish",
            "Anka Reuel",
            "Heather Frase"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21460",
        "abstract": "Large language model (LLM) benchmarks inform LLM use decisions (e.g., \"is this LLM safe to deploy for my use case and context?\"). However, benchmarks may be rendered unreliable by various failure modes that impact benchmark bias, variance, coverage, or people's capacity to understand benchmark evidence. Using the National Institute of Standards and Technology's risk management process as a foundation, this research iteratively analyzed 26 popular benchmarks, identifying 57 potential failure modes and 196 corresponding mitigation strategies. The mitigations reduce failure likelihood and/or severity, providing a frame for evaluating \"benchmark risk,\" which is scored to provide a metaevaluation benchmark: BenchRisk. Higher scores indicate that benchmark users are less likely to reach an incorrect or unsupported conclusion about an LLM. All 26 scored benchmarks present significant risk within one or more of the five scored dimensions (comprehensiveness, intelligibility, consistency, correctness, and longevity), which points to important open research directions for the field of LLM benchmarking. The BenchRisk workflow allows for comparison between benchmarks; as an open-source tool, it also facilitates the identification and sharing of risks and their mitigations.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "126",
        "title": "Enhancing Social Robots through Resilient AI",
        "author": [
            "Domenico Palmisano",
            "Giuseppe Palestra",
            "Berardina Nadja De Carolis"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21469",
        "abstract": "As artificial intelligence continues to advance and becomes more integrated into sensitive areas like healthcare, education, and everyday life, it's crucial for these systems to be both resilient and robust. This paper shows how resilience is a fundamental characteristic of social robots, which, through it, ensure trust in the robot itself-an essential element especially when operating in contexts with elderly people, who often have low trust in these systems. Resilience is therefore the ability to operate under adverse or stressful conditions, even when degraded or weakened, while maintaining essential operational capabilities.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "127",
        "title": "MRO: Enhancing Reasoning in Diffusion Language Models via Multi-Reward Optimization",
        "author": [
            "Chenglong Wang",
            "Yang Gan",
            "Hang Zhou",
            "Chi Hu",
            "Yongyu Mu",
            "Kai Song",
            "Murun Yang",
            "Bei Li",
            "Chunliang Zhang",
            "Tongran Liu",
            "Jingbo Zhu",
            "Zhengtao Yu",
            "Tong Xiao"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21473",
        "abstract": "Recent advances in diffusion language models (DLMs) have presented a promising alternative to traditional autoregressive large language models (LLMs). However, DLMs still lag behind LLMs in reasoning performance, especially as the number of denoising steps decreases. Our analysis reveals that this shortcoming arises primarily from the independent generation of masked tokens across denoising steps, which fails to capture the token correlation. In this paper, we define two types of token correlation: intra-sequence correlation and inter-sequence correlation, and demonstrate that enhancing these correlations improves reasoning performance. To this end, we propose a Multi-Reward Optimization (MRO) approach, which encourages DLMs to consider the token correlation during the denoising process. More specifically, our MRO approach leverages test-time scaling, reject sampling, and reinforcement learning to directly optimize the token correlation with multiple elaborate rewards. Additionally, we introduce group step and importance sampling strategies to mitigate reward variance and enhance sampling efficiency. Through extensive experiments, we demonstrate that MRO not only improves reasoning performance but also achieves significant sampling speedups while maintaining high performance on reasoning benchmarks.",
        "tags": [
            "Diffusion",
            "LLM",
            "RL"
        ]
    },
    {
        "id": "128",
        "title": "GranViT: A Fine-Grained Vision Model With Autoregressive Perception For MLLMs",
        "author": [
            "Guanghao Zheng",
            "Bowen Shi",
            "Mingxing Xu",
            "Ruoyu Sun",
            "Peisen Zhao",
            "Zhibo Zhang",
            "Wenrui Dai",
            "Junni Zou",
            "Hongkai Xiong",
            "Xiaopeng Zhang",
            "Qi Tian"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21501",
        "abstract": "Vision encoders are indispensable for allowing impressive performance of Multi-modal Large Language Models (MLLMs) in vision language tasks such as visual question answering and reasoning. However, existing vision encoders focus on global image representations but overlook fine-grained regional analysis. They are limited in fine grained perception due to the scarcity of fine grained annotated data and the lack of a fine grained pre-training paradigm. In this paper, we propose GranViT, a novel Vision Transformer that integrates fine-grained feature extraction with semantic alignment to Large Language Models (LLMs) via region level autoregressive training. We first construct Gran-29M, a dataset comprising 2million natural and OCR images paired with over 180 million high-quality region-level annotations, to enable large scale fine grained pretraining. Consequently, we develop a pretraining-adaptation framework along with a self distillation mechanism to train fine-grained GranViT on Gran-29M. We sufficiently exploit the fine-grained annotations from Gran-29M to resort to bounding-box-to-caption regression to enhance localized visual representation of the vision encoder in the pretraining and caption-to-bounding-box regression to improve vision feature utilization and localization for LLM in the adaptation. We further incorporate a self distillation mechanism that imposes explicit localization constraints on the vision encoder to strengthen its regional reasoning capability. Extensive experiments show that GranViT surpasses existing vision encoders and attains strong transferability to varying LLMs. Remarkably, it achieves state-of-the-art results on fine-grained recognition, multimodal VQA, and OCR understanding.",
        "tags": [
            "LLM",
            "Transformer",
            "ViT"
        ]
    },
    {
        "id": "129",
        "title": "Actionable Cybersecurity Notifications for Smart Homes: A User Study on the Role of Length and Complexity",
        "author": [
            "Victor JÃ¼ttner",
            "Charlotte S. LÃ¶ffler",
            "Erik Buchmann"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21508",
        "abstract": "The proliferation of smart home devices has increased convenience but also introduced cybersecurity risks for everyday users, as many devices lack robust security features. Intrusion Detection Systems are a prominent approach to detecting cybersecurity threats. However, their alerts often use technical terms and require users to interpret them correctly, which is challenging for a typical smart home user. Large Language Models can bridge this gap by translating IDS alerts into actionable security notifications. However, it has not yet been clear what an actionable cybersecurity notification should look like. In this paper, we conduct an experimental online user study with 130 participants to examine how the length and complexity of LLM-generated notifications affect user likability, understandability, and motivation to act. Our results show that intermediate-complexity notifications are the most effective across all user groups, regardless of their technological proficiency. Across the board, users rated beginner-level messages as more effective when they were longer, while expert-level messages were rated marginally more effective when they were shorter. These findings provide insights for designing security notifications that are both actionable and broadly accessible to smart home users.",
        "tags": [
            "Detection",
            "LLM"
        ]
    },
    {
        "id": "130",
        "title": "Towards a Golden Classifier-Free Guidance Path via Foresight Fixed Point Iterations",
        "author": [
            "Kaibo Wang",
            "Jianda Mao",
            "Tong Wu",
            "Yang Xiang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21512",
        "abstract": "Classifier-Free Guidance (CFG) is an essential component of text-to-image diffusion models, and understanding and advancing its operational mechanisms remains a central focus of research. Existing approaches stem from divergent theoretical interpretations, thereby limiting the design space and obscuring key design choices. To address this, we propose a unified perspective that reframes conditional guidance as fixed point iterations, seeking to identify a golden path where latents produce consistent outputs under both conditional and unconditional generation. We demonstrate that CFG and its variants constitute a special case of single-step short-interval iteration, which is theoretically proven to exhibit inefficiency. To this end, we introduce Foresight Guidance (FSG), which prioritizes solving longer-interval subproblems in early diffusion stages with increased iterations. Extensive experiments across diverse datasets and model architectures validate the superiority of FSG over state-of-the-art methods in both image quality and computational efficiency. Our work offers novel perspectives for conditional guidance and unlocks the potential of adaptive design.",
        "tags": [
            "Diffusion",
            "Text-to-Image"
        ]
    },
    {
        "id": "131",
        "title": "Wisdom and Delusion of LLM Ensembles for Code Generation and Repair",
        "author": [
            "Fernando Vallecillos Ruiz",
            "Max Hort",
            "Leon Moonen"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21513",
        "abstract": "Today's pursuit of a single Large Language Model (LMM) for all software engineering tasks is resource-intensive and overlooks the potential benefits of complementarity, where different models contribute unique strengths. However, the degree to which coding LLMs complement each other and the best strategy for maximizing an ensemble's potential are unclear, leaving practitioners without a clear path to move beyond single-model systems.\nTo address this gap, we empirically compare ten individual LLMs from five families, and three ensembles of these LLMs across three software engineering benchmarks covering code generation and program repair. We assess the complementarity between models and the performance gap between the best individual model and the ensembles. Next, we evaluate various selection heuristics to identify correct solutions from an ensemble's candidate pool.\nWe find that the theoretical upperbound for an ensemble's performance can be 83% above the best single model. Our results show that consensus-based strategies for selecting solutions fall into a \"popularity trap,\" amplifying common but incorrect outputs. In contrast, a diversity-based strategy realizes up to 95% of this theoretical potential, and proves effective even in small two-model ensembles, enabling a cost-efficient way to enhance performance by leveraging multiple LLMs.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "132",
        "title": "Head Pursuit: Probing Attention Specialization in Multimodal Transformers",
        "author": [
            "Lorenzo Basile",
            "Valentino Maiorca",
            "Diego Doimo",
            "Francesco Locatello",
            "Alberto Cazzaniga"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21518",
        "abstract": "Language and vision-language models have shown impressive performance across a wide range of tasks, but their internal mechanisms remain only partly understood. In this work, we study how individual attention heads in text-generative models specialize in specific semantic or visual attributes. Building on an established interpretability method, we reinterpret the practice of probing intermediate activations with the final decoding layer through the lens of signal processing. This lets us analyze multiple samples in a principled way and rank attention heads based on their relevance to target concepts. Our results show consistent patterns of specialization at the head level across both unimodal and multimodal transformers. Remarkably, we find that editing as few as 1% of the heads, selected using our method, can reliably suppress or enhance targeted concepts in the model output. We validate our approach on language tasks such as question answering and toxicity mitigation, as well as vision-language tasks including image classification and captioning. Our findings highlight an interpretable and controllable structure within attention layers, offering simple tools for understanding and editing large-scale generative models.",
        "tags": [
            "VLM"
        ]
    },
    {
        "id": "133",
        "title": "EU-Agent-Bench: Measuring Illegal Behavior of LLM Agents Under EU Law",
        "author": [
            "Ilija Lichkovski",
            "Alexander MÃ¼ller",
            "Mariam Ibrahim",
            "Tiwai Mhundwa"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21524",
        "abstract": "Large language models (LLMs) are increasingly deployed as agents in various contexts by providing tools at their disposal. However, LLM agents can exhibit unpredictable behaviors, including taking undesirable and/or unsafe actions. In order to measure the latent propensity of LLM agents for taking illegal actions under an EU legislative context, we introduce EU-Agent-Bench, a verifiable human-curated benchmark that evaluates an agent's alignment with EU legal norms in situations where benign user inputs could lead to unlawful actions. Our benchmark spans scenarios across several categories, including data protection, bias/discrimination, and scientific integrity, with each user request allowing for both compliant and non-compliant execution of the requested actions. Comparing the model's function calls against a rubric exhaustively supported by citations of the relevant legislature, we evaluate the legal compliance of frontier LLMs, and furthermore investigate the compliance effect of providing the relevant legislative excerpts in the agent's system prompt along with explicit instructions to comply. We release a public preview set for the research community, while holding out a private test set to prevent data contamination in evaluating upcoming models. We encourage future work extending agentic safety benchmarks to different legal jurisdictions and to multi-turn and multilingual interactions. We release our code on \\href{https://github.com/ilijalichkovski/eu-agent-bench}{this URL}.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "134",
        "title": "A Unified Model for Multi-Task Drone Routing in Post-Disaster Road Assessment",
        "author": [
            "Huatian Gong",
            "Jiuh-Biing Sheu",
            "Zheng Wang",
            "Xiaoguang Yang",
            "Ran Yan"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21525",
        "abstract": "Post-disaster road assessment (PDRA) is essential for emergency response, enabling rapid evaluation of infrastructure conditions and efficient allocation of resources. Although drones provide a flexible and effective tool for PDRA, routing them in large-scale networks remains challenging. Traditional optimization methods scale poorly and demand domain expertise, while existing deep reinforcement learning (DRL) approaches adopt a single-task paradigm, requiring separate models for each problem variant and lacking adaptability to evolving operational needs. This study proposes a unified model (UM) for drone routing that simultaneously addresses eight PDRA variants. By training a single neural network across multiple problem configurations, UM captures shared structural knowledge while adapting to variant-specific constraints through a modern transformer encoder-decoder architecture. A lightweight adapter mechanism further enables efficient finetuning to unseen attributes without retraining, enhancing deployment flexibility in dynamic disaster scenarios. Extensive experiments demonstrate that the UM reduces training time and parameters by a factor of eight compared with training separate models, while consistently outperforming single-task DRL methods by 6--14\\% and traditional optimization approaches by 24--82\\% in terms of solution quality (total collected information value). The model achieves real-time solutions (1--10 seconds) across networks of up to 1,000 nodes, with robustness confirmed through sensitivity analyses. Moreover, finetuning experiments show that unseen attributes can be effectively incorporated with minimal cost while retaining high solution quality. The proposed UM advances neural combinatorial optimization for time-critical applications, offering a computationally efficient, high-quality, and adaptable solution for drone-based PDRA.",
        "tags": [
            "RL",
            "Transformer"
        ]
    },
    {
        "id": "135",
        "title": "AURASeg: Attention Guided Upsampling with Residual Boundary-Assistive Refinement for Drivable-Area Segmentation",
        "author": [
            "Narendhiran Vijayakumar",
            "Sridevi. M"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21536",
        "abstract": "Free space ground segmentation is essential to navigate robots and autonomous vehicles, recognize drivable zones, and traverse efficiently. Fine-grained features remain challenging for existing segmentation models, particularly for robots in indoor and structured environments. These difficulties arise from ineffective multi-scale processing, suboptimal boundary refinement, and limited feature representation. In order to overcome these limitations, we propose Attention-Guided Upsampling with Residual Boundary-Assistive Refinement (AURASeg), a ground-plane semantic segmentation model that maintains high segmentation accuracy while improving border precision. Our method uses CSP-Darknet backbone by adding a Residual Border Refinement Module (RBRM) for accurate edge delineation and an Attention Progressive Upsampling Decoder (APUD) for strong feature integration. We also incorporate a lightweight Atrous Spatial Pyramid Pooling (ASPP-Lite) module to ensure multi-scale context extraction without compromising real-time performance. The proposed model beats benchmark segmentation architectures in mIoU and F1 metrics when tested on the Ground Mobile Robot Perception (GMRP) Dataset and a custom Gazebo indoor dataset. Our approach achieves an improvement in mean Intersection-over-Union (mIoU) of +1.26% and segmentation precision of +1.65% compared to state-of-the-art models. These results show that our technique is feasible for autonomous perception in both indoor and outdoor environments, enabling precise border refinement with minimal effect on inference speed.",
        "tags": [
            "Robotics",
            "Segmentation"
        ]
    },
    {
        "id": "136",
        "title": "InterpDetect: Interpretable Signals for Detecting Hallucinations in Retrieval-Augmented Generation",
        "author": [
            "Likun Tan",
            "Kuan-Wei Huang",
            "Joy Shi",
            "Kevin Wu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21538",
        "abstract": "Retrieval-Augmented Generation (RAG) integrates external knowledge to mitigate hallucinations, yet models often generate outputs inconsistent with retrieved content. Accurate hallucination detection requires disentangling the contributions of external context and parametric knowledge, which prior methods typically conflate. We investigate the mechanisms underlying RAG hallucinations and find they arise when later-layer FFN modules disproportionately inject parametric knowledge into the residual stream. To address this, we explore a mechanistic detection approach based on external context scores and parametric knowledge scores. Using Qwen3-0.6b, we compute these scores across layers and attention heads and train regression-based classifiers to predict hallucinations. Our method is evaluated against state-of-the-art LLMs (GPT-5, GPT-4.1) and detection baselines (RAGAS, TruLens, RefChecker). Furthermore, classifiers trained on Qwen3-0.6b signals generalize to GPT-4.1-mini responses, demonstrating the potential of proxy-model evaluation. Our results highlight mechanistic signals as efficient, generalizable predictors for hallucination detection in RAG systems.",
        "tags": [
            "Detection",
            "GPT",
            "LLM",
            "RAG"
        ]
    },
    {
        "id": "137",
        "title": "Co-Sight: Enhancing LLM-Based Agents via Conflict-Aware Meta-Verification and Trustworthy Reasoning with Structured Facts",
        "author": [
            "Hongwei Zhang",
            "Ji Lu",
            "Shiqing Jiang",
            "Chenxiang Zhu",
            "Li Xie",
            "Chen Zhong",
            "Haoran Chen",
            "Yurui Zhu",
            "Yongsheng Du",
            "Yanqin Gao",
            "Lingjun Huang",
            "Baoli Wang",
            "Fang Tan",
            "Peng Zou"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21557",
        "abstract": "Long-horizon reasoning in LLM-based agents often fails not from generative weakness but from insufficient verification of intermediate reasoning. Co-Sight addresses this challenge by turning reasoning into a falsifiable and auditable process through two complementary mechanisms: Conflict-Aware Meta-Verification (CAMV) and Trustworthy Reasoning with Structured Facts (TRSF). CAMV reformulates verification as conflict identification and targeted falsification, allocating computation only to disagreement hotspots among expert agents rather than to full reasoning chains. This bounds verification cost to the number of inconsistencies and improves efficiency and reliability. TRSF continuously organizes, validates, and synchronizes evidence across agents through a structured facts module. By maintaining verified, traceable, and auditable knowledge, it ensures that all reasoning is grounded in consistent, source-verified information and supports transparent verification throughout the reasoning process. Together, TRSF and CAMV form a closed verification loop, where TRSF supplies structured facts and CAMV selectively falsifies or reinforces them, yielding transparent and trustworthy reasoning. Empirically, Co-Sight achieves state-of-the-art accuracy on GAIA (84.4%) and Humanity's Last Exam (35.5%), and strong results on Chinese-SimpleQA (93.8%). Ablation studies confirm that the synergy between structured factual grounding and conflict-aware verification drives these improvements. Co-Sight thus offers a scalable paradigm for reliable long-horizon reasoning in LLM-based agents. Code is available at https://github.com/ZTE-AICloud/Co-Sight/tree/cosight2.0_benchmarks.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "138",
        "title": "Are the LLMs Capable of Maintaining at Least the Language Genus?",
        "author": [
            "Sandra MitroviÄ",
            "David Kletz",
            "Ljiljana Dolamic",
            "Fabio Rinaldi"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21561",
        "abstract": "Large Language Models (LLMs) display notable variation in multilingual behavior, yet the role of genealogical language structure in shaping this variation remains underexplored. In this paper, we investigate whether LLMs exhibit sensitivity to linguistic genera by extending prior analyses on the MultiQ dataset. We first check if models prefer to switch to genealogically related languages when prompt language fidelity is not maintained. Next, we investigate whether knowledge consistency is better preserved within than across genera. We show that genus-level effects are present but strongly conditioned by training resource availability. We further observe distinct multilingual strategies across LLMs families. Our findings suggest that LLMs encode aspects of genus-level structure, but training data imbalances remain the primary factor shaping their multilingual performance.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "139",
        "title": "Scalable Vision-Language-Action Model Pretraining for Robotic Manipulation with Real-Life Human Activity Videos",
        "author": [
            "Qixiu Li",
            "Yu Deng",
            "Yaobo Liang",
            "Lin Luo",
            "Lei Zhou",
            "Chengtang Yao",
            "Lingqi Zeng",
            "Zhiyuan Feng",
            "Huizhi Liang",
            "Sicheng Xu",
            "Yizhong Zhang",
            "Xi Chen",
            "Hao Chen",
            "Lily Sun",
            "Dong Chen",
            "Jiaolong Yang",
            "Baining Guo"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21571",
        "abstract": "This paper presents a novel approach for pretraining robotic manipulation Vision-Language-Action (VLA) models using a large corpus of unscripted real-life video recordings of human hand activities. Treating human hand as dexterous robot end-effector, we show that \"in-the-wild\" egocentric human videos without any annotations can be transformed into data formats fully aligned with existing robotic V-L-A training data in terms of task granularity and labels. This is achieved by the development of a fully-automated holistic human activity analysis approach for arbitrary human hand videos. This approach can generate atomic-level hand activity segments and their language descriptions, each accompanied with framewise 3D hand motion and camera motion. We process a large volume of egocentric videos and create a hand-VLA training dataset containing 1M episodes and 26M frames. This training data covers a wide range of objects and concepts, dexterous manipulation tasks, and environment variations in real life, vastly exceeding the coverage of existing robot data. We design a dexterous hand VLA model architecture and pretrain the model on this dataset. The model exhibits strong zero-shot capabilities on completely unseen real-world observations. Additionally, fine-tuning it on a small amount of real robot action data significantly improves task success rates and generalization to novel objects in real robotic experiments. We also demonstrate the appealing scaling behavior of the model's task performance with respect to pretraining data scale. We believe this work lays a solid foundation for scalable VLA pretraining, advancing robots toward truly generalizable embodied intelligence.",
        "tags": [
            "3D",
            "Robotics"
        ]
    },
    {
        "id": "140",
        "title": "From Polyester Girlfriends to Blind Mice: Creating the First Pragmatics Understanding Benchmarks for Slovene",
        "author": [
            "Mojca Brglez",
            "Å pela Vintar"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21575",
        "abstract": "Large language models are demonstrating increasing capabilities, excelling at benchmarks once considered very difficult. As their capabilities grow, there is a need for more challenging evaluations that go beyond surface-level linguistic competence. Namely, language competence involves not only syntax and semantics but also pragmatics, i.e., understanding situational meaning as shaped by context as well as linguistic and cultural norms. To contribute to this line of research, we introduce SloPragEval and SloPragMega, the first pragmatics understanding benchmarks for Slovene that contain altogether 405 multiple-choice questions. We discuss the difficulties of translation, describe the campaign to establish a human baseline, and report pilot evaluations with LLMs. Our results indicate that current models have greatly improved in understanding nuanced language but may still fail to infer implied speaker meaning in non-literal utterances, especially those that are culture-specific. We also observe a significant gap between proprietary and open-source models. Finally, we argue that benchmarks targeting nuanced language understanding and knowledge of the target culture must be designed with care, preferably constructed from native data, and validated with human responses.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "141",
        "title": "Foley Control: Aligning a Frozen Latent Text-to-Audio Model to Video",
        "author": [
            "Ciara Rowles",
            "Varun Jampani",
            "Simon DonnÃ©",
            "Shimon Vainer",
            "Julian Parker",
            "Zach Evans"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21581",
        "abstract": "Foley Control is a lightweight approach to video-guided Foley that keeps pretrained single-modality models frozen and learns only a small cross-attention bridge between them. We connect V-JEPA2 video embeddings to a frozen Stable Audio Open DiT text-to-audio (T2A) model by inserting compact video cross-attention after the model's existing text cross-attention, so prompts set global semantics while video refines timing and local dynamics. The frozen backbones retain strong marginals (video; audio given text) and the bridge learns the audio-video dependency needed for synchronization -- without retraining the audio prior. To cut memory and stabilize training, we pool video tokens before conditioning. On curated video-audio benchmarks, Foley Control delivers competitive temporal and semantic alignment with far fewer trainable parameters than recent multi-modal systems, while preserving prompt-driven controllability and production-friendly modularity (swap/upgrade encoders or the T2A backbone without end-to-end retraining). Although we focus on Video-to-Foley, the same bridge design can potentially extend to other audio modalities (e.g., speech).",
        "tags": [
            "DiT"
        ]
    },
    {
        "id": "142",
        "title": "Sample By Step, Optimize By Chunk: Chunk-Level GRPO For Text-to-Image Generation",
        "author": [
            "Yifu Luo",
            "Penghui Du",
            "Bo Li",
            "Sinan Du",
            "Tiantian Zhang",
            "Yongzhe Chang",
            "Kai Wu",
            "Kun Gai",
            "Xueqian Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21583",
        "abstract": "Group Relative Policy Optimization (GRPO) has shown strong potential for flow-matching-based text-to-image (T2I) generation, but it faces two key limitations: inaccurate advantage attribution, and the neglect of temporal dynamics of generation. In this work, we argue that shifting the optimization paradigm from the step level to the chunk level can effectively alleviate these issues. Building on this idea, we propose Chunk-GRPO, the first chunk-level GRPO-based approach for T2I generation. The insight is to group consecutive steps into coherent 'chunk's that capture the intrinsic temporal dynamics of flow matching, and to optimize policies at the chunk level. In addition, we introduce an optional weighted sampling strategy to further enhance performance. Extensive experiments show that ChunkGRPO achieves superior results in both preference alignment and image quality, highlighting the promise of chunk-level optimization for GRPO-based methods.",
        "tags": [
            "Flow Matching",
            "GRPO",
            "Text-to-Image"
        ]
    },
    {
        "id": "143",
        "title": "MATrack: Efficient Multiscale Adaptive Tracker for Real-Time Nighttime UAV Operations",
        "author": [
            "Xuzhao Li",
            "Xuchen Li",
            "Shiyu Hu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21586",
        "abstract": "Nighttime UAV tracking faces significant challenges in real-world robotics operations. Low-light conditions not only limit visual perception capabilities, but cluttered backgrounds and frequent viewpoint changes also cause existing trackers to drift or fail during deployment. To address these difficulties, researchers have proposed solutions based on low-light enhancement and domain adaptation. However, these methods still have notable shortcomings in actual UAV systems: low-light enhancement often introduces visual artifacts, domain adaptation methods are computationally expensive and existing lightweight designs struggle to fully leverage dynamic object information. Based on an in-depth analysis of these key issues, we propose MATrack-a multiscale adaptive system designed specifically for nighttime UAV tracking. MATrack tackles the main technical challenges of nighttime tracking through the collaborative work of three core modules: Multiscale Hierarchy Blende (MHB) enhances feature consistency between static and dynamic templates. Adaptive Key Token Gate accurately identifies object information within complex backgrounds. Nighttime Template Calibrator (NTC) ensures stable tracking performance over long sequences. Extensive experiments show that MATrack achieves a significant performance improvement. On the UAVDark135 benchmark, its precision, normalized precision and AUC surpass state-of-the-art (SOTA) methods by 5.9%, 5.4% and 4.2% respectively, while maintaining a real-time processing speed of 81 FPS. Further tests on a real-world UAV platform validate the system's reliability, demonstrating that MATrack can provide stable and effective nighttime UAV tracking support for critical robotics applications such as nighttime search and rescue and border patrol.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "144",
        "title": "Doc-Researcher: A Unified System for Multimodal Document Parsing and Deep Research",
        "author": [
            "Kuicai Dong",
            "Shurui Huang",
            "Fangda Ye",
            "Wei Han",
            "Zhi Zhang",
            "Dexun Li",
            "Wenjun Li",
            "Qu Yang",
            "Gang Wang",
            "Yichao Wang",
            "Chen Zhang",
            "Yong Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21603",
        "abstract": "Deep Research systems have revolutionized how LLMs solve complex questions through iterative reasoning and evidence gathering. However, current systems remain fundamentally constrained to textual web data, overlooking the vast knowledge embedded in multimodal documents Processing such documents demands sophisticated parsing to preserve visual semantics (figures, tables, charts, and equations), intelligent chunking to maintain structural coherence, and adaptive retrieval across modalities, which are capabilities absent in existing systems. In response, we present Doc-Researcher, a unified system that bridges this gap through three integrated components: (i) deep multimodal parsing that preserves layout structure and visual semantics while creating multi-granular representations from chunk to document level, (ii) systematic retrieval architecture supporting text-only, vision-only, and hybrid paradigms with dynamic granularity selection, and (iii) iterative multi-agent workflows that decompose complex queries, progressively accumulate evidence, and synthesize comprehensive answers across documents and modalities. To enable rigorous evaluation, we introduce M4DocBench, the first benchmark for Multi-modal, Multi-hop, Multi-document, and Multi-turn deep research. Featuring 158 expert-annotated questions with complete evidence chains across 304 documents, M4DocBench tests capabilities that existing benchmarks cannot assess. Experiments demonstrate that Doc-Researcher achieves 50.6% accuracy, 3.4xbetter than state-of-the-art baselines, validating that effective document research requires not just better retrieval, but fundamentally deep parsing that preserve multimodal integrity and support iterative research. Our work establishes a new paradigm for conducting deep research on multimodal document collections.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "145",
        "title": "RETuning: Upgrading Inference-Time Scaling for Stock Movement Prediction with Large Language Models",
        "author": [
            "Xueyuan Lin",
            "Cehao Yang",
            "Ye Ma",
            "Ming Li",
            "Rongjunchen Zhang",
            "Yang Ni",
            "Xiaojun Wu",
            "Chengjin Xu",
            "Jian Guo",
            "Hui Xiong"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21604",
        "abstract": "Recently, large language models (LLMs) have demonstrated outstanding reasoning capabilities on mathematical and coding tasks. However, their application to financial tasks-especially the most fundamental task of stock movement prediction-remains underexplored. We study a three-class classification problem (up, hold, down) and, by analyzing existing reasoning responses, observe that: (1) LLMs follow analysts' opinions rather than exhibit a systematic, independent analytical logic (CoTs). (2) LLMs list summaries from different sources without weighing adversarial evidence, yet such counterevidence is crucial for reliable prediction. It shows that the model does not make good use of its reasoning ability to complete the task. To address this, we propose Reflective Evidence Tuning (RETuning), a cold-start method prior to reinforcement learning, to enhance prediction ability. While generating CoT, RETuning encourages dynamically constructing an analytical framework from diverse information sources, organizing and scoring evidence for price up or down based on that framework-rather than on contextual viewpoints-and finally reflecting to derive the prediction. This approach maximally aligns the model with its learned analytical framework, ensuring independent logical reasoning and reducing undue influence from context. We also build a large-scale dataset spanning all of 2024 for 5,123 A-share stocks, with long contexts (32K tokens) and over 200K samples. In addition to price and news, it incorporates analysts' opinions, quantitative reports, fundamental data, macroeconomic indicators, and similar stocks. Experiments show that RETuning successfully unlocks the model's reasoning ability in the financial domain. Inference-time scaling still works even after 6 months or on out-of-distribution stocks, since the models gain valuable insights about stock movement prediction.",
        "tags": [
            "CoT",
            "LLM",
            "RL"
        ]
    },
    {
        "id": "146",
        "title": "S3OD: Towards Generalizable Salient Object Detection with Synthetic Data",
        "author": [
            "Orest Kupyn",
            "Hirokatsu Kataoka",
            "Christian Rupprecht"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21605",
        "abstract": "Salient object detection exemplifies data-bounded tasks where expensive pixel-precise annotations force separate model training for related subtasks like DIS and HR-SOD. We present a method that dramatically improves generalization through large-scale synthetic data generation and ambiguity-aware architecture. We introduce S3OD, a dataset of over 139,000 high-resolution images created through our multi-modal diffusion pipeline that extracts labels from diffusion and DINO-v3 features. The iterative generation framework prioritizes challenging categories based on model performance. We propose a streamlined multi-mask decoder that naturally handles the inherent ambiguity in salient object detection by predicting multiple valid interpretations. Models trained solely on synthetic data achieve 20-50% error reduction in cross-dataset generalization, while fine-tuned versions reach state-of-the-art performance across DIS and HR-SOD benchmarks.",
        "tags": [
            "Detection",
            "Diffusion"
        ]
    },
    {
        "id": "147",
        "title": "Modest-Align: Data-Efficient Alignment for Vision-Language Models",
        "author": [
            "Jiaxiang Liu",
            "Yuan Wang",
            "Jiawei Du",
            "Joey Tianyi Zhou",
            "Mingkun Xu",
            "Zuozhu Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21606",
        "abstract": "Cross-modal alignment aims to map heterogeneous modalities into a shared latent space, as exemplified by models like CLIP, which benefit from large-scale image-text pretraining for strong recognition capabilities. However, when operating in resource-constrained settings with limited or low-quality data, these models often suffer from overconfidence and degraded performance due to the prevalence of ambiguous or weakly correlated image-text pairs. Current contrastive learning approaches, which rely on single positive pairs, further exacerbate this issue by reinforcing overconfidence on uncertain samples. To address these challenges, we propose Modest-Align, a lightweight alignment framework designed for robustness and efficiency. Our approach leverages two complementary strategies -- Random Perturbation, which introduces controlled noise to simulate uncertainty, and Embedding Smoothing, which calibrates similarity distributions in the embedding space. These mechanisms collectively reduce overconfidence and improve performance on noisy or weakly aligned samples. Extensive experiments across multiple benchmark datasets demonstrate that Modest-Align outperforms state-of-the-art methods in retrieval tasks, achieving competitive results with over 100x less training data and 600x less GPU time than CLIP. Our method offers a practical and scalable solution for cross-modal alignment in real-world, low-resource scenarios.",
        "tags": [
            "CLIP",
            "VLM"
        ]
    },
    {
        "id": "148",
        "title": "Enhancing Tactile-based Reinforcement Learning for Robotic Control",
        "author": [
            "Elle Miller",
            "Trevor McInroe",
            "David Abel",
            "Oisin Mac Aodha",
            "Sethu Vijayakumar"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21609",
        "abstract": "Achieving safe, reliable real-world robotic manipulation requires agents to evolve beyond vision and incorporate tactile sensing to overcome sensory deficits and reliance on idealised state information. Despite its potential, the efficacy of tactile sensing in reinforcement learning (RL) remains inconsistent. We address this by developing self-supervised learning (SSL) methodologies to more effectively harness tactile observations, focusing on a scalable setup of proprioception and sparse binary contacts. We empirically demonstrate that sparse binary tactile signals are critical for dexterity, particularly for interactions that proprioceptive control errors do not register, such as decoupled robot-object motions. Our agents achieve superhuman dexterity in complex contact tasks (ball bouncing and Baoding ball rotation). Furthermore, we find that decoupling the SSL memory from the on-policy memory can improve performance. We release the Robot Tactile Olympiad (RoTO) benchmark to standardise and promote future research in tactile-based manipulation. Project page: https://elle-miller.github.io/tactile_rl",
        "tags": [
            "RL",
            "Robotics"
        ]
    },
    {
        "id": "149",
        "title": "Huxley-GÃ¶del Machine: Human-Level Coding Agent Development by an Approximation of the Optimal Self-Improving Machine",
        "author": [
            "Wenyi Wang",
            "Piotr PiÄkos",
            "Li Nanbo",
            "Firas Laakom",
            "Yimeng Chen",
            "Mateusz Ostaszewski",
            "Mingchen Zhuge",
            "JÃ¼rgen Schmidhuber"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21614",
        "abstract": "Recent studies operationalize self-improvement through coding agents that edit their own codebases. They grow a tree of self-modifications through expansion strategies that favor higher software engineering benchmark performance, assuming that this implies more promising subsequent self-modifications. However, we identify a mismatch between the agent's self-improvement potential (metaproductivity) and its coding benchmark performance, namely the Metaproductivity-Performance Mismatch. Inspired by Huxley's concept of clade, we propose a metric ($\\mathrm{CMP}$) that aggregates the benchmark performances of the descendants of an agent as an indicator of its potential for self-improvement. We show that, in our self-improving coding agent development setting, access to the true $\\mathrm{CMP}$ is sufficient to simulate how the GÃ¶del Machine would behave under certain assumptions. We introduce the Huxley-GÃ¶del Machine (HGM), which, by estimating $\\mathrm{CMP}$ and using it as guidance, searches the tree of self-modifications. On SWE-bench Verified and Polyglot, HGM outperforms prior self-improving coding agent development methods while using less wall-clock time. Last but not least, HGM demonstrates strong transfer to other coding datasets and large language models. The agent optimized by HGM on SWE-bench Verified with GPT-5-mini and evaluated on SWE-bench Lite with GPT-5 achieves human-level performance, matching the best officially checked results of human-engineered coding agents. Our code is available at https://github.com/metauto-ai/HGM.",
        "tags": [
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "150",
        "title": "Epipolar Geometry Improves Video Generation Models",
        "author": [
            "Orest Kupyn",
            "Fabian Manhardt",
            "Federico Tombari",
            "Christian Rupprecht"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21615",
        "abstract": "Video generation models have progressed tremendously through large latent diffusion transformers trained with rectified flow techniques. Yet these models still struggle with geometric inconsistencies, unstable motion, and visual artifacts that break the illusion of realistic 3D scenes. 3D-consistent video generation could significantly impact numerous downstream applications in generation and reconstruction tasks. We explore how epipolar geometry constraints improve modern video diffusion models. Despite massive training data, these models fail to capture fundamental geometric principles underlying visual content. We align diffusion models using pairwise epipolar geometry constraints via preference-based optimization, directly addressing unstable camera trajectories and geometric artifacts through mathematically principled geometric enforcement. Our approach efficiently enforces geometric principles without requiring end-to-end differentiability. Evaluation demonstrates that classical geometric constraints provide more stable optimization signals than modern learned metrics, which produce noisy targets that compromise alignment quality. Training on static scenes with dynamic cameras ensures high-quality measurements while the model generalizes effectively to diverse dynamic content. By bridging data-driven deep learning with classical geometric computer vision, we present a practical method for generating spatially consistent videos without compromising visual quality.",
        "tags": [
            "3D",
            "Diffusion",
            "Rectified Flow",
            "Video Generation"
        ]
    },
    {
        "id": "151",
        "title": "DeepAgent: A General Reasoning Agent with Scalable Toolsets",
        "author": [
            "Xiaoxi Li",
            "Wenxiang Jiao",
            "Jiarui Jin",
            "Guanting Dong",
            "Jiajie Jin",
            "Yinuo Wang",
            "Hao Wang",
            "Yutao Zhu",
            "Ji-Rong Wen",
            "Yuan Lu",
            "Zhicheng Dou"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21618",
        "abstract": "Large reasoning models have demonstrated strong problem-solving abilities, yet real-world tasks often require external tools and long-horizon interactions. Existing agent frameworks typically follow predefined workflows, which limit autonomous and global task completion. In this paper, we introduce DeepAgent, an end-to-end deep reasoning agent that performs autonomous thinking, tool discovery, and action execution within a single, coherent reasoning process. To address the challenges of long-horizon interactions, particularly the context length explosion from multiple tool calls and the accumulation of interaction history, we introduce an autonomous memory folding mechanism that compresses past interactions into structured episodic, working, and tool memories, reducing error accumulation while preserving critical information. To teach general-purpose tool use efficiently and stably, we develop an end-to-end reinforcement learning strategy, namely ToolPO, that leverages LLM-simulated APIs and applies tool-call advantage attribution to assign fine-grained credit to the tool invocation tokens. Extensive experiments on eight benchmarks, including general tool-use tasks (ToolBench, API-Bank, TMDB, Spotify, ToolHop) and downstream applications (ALFWorld, WebShop, GAIA, HLE), demonstrate that DeepAgent consistently outperforms baselines across both labeled-tool and open-set tool retrieval scenarios. This work takes a step toward more general and capable agents for real-world applications. The code and demo are available at https://github.com/RUC-NLPIR/DeepAgent.",
        "tags": [
            "LLM",
            "RL"
        ]
    },
    {
        "id": "152",
        "title": "The Universal Landscape of Human Reasoning",
        "author": [
            "Qiguang Chen",
            "Jinhao Liu",
            "Libo Qin",
            "Yimeng Zhang",
            "Yihao Liang",
            "Shangxu Ren",
            "Chengyu Luan",
            "Dengyun Peng",
            "Hanjing Li",
            "Jiannan Guan",
            "Zheng Yan",
            "Jiaqi Wang",
            "Mengkang Hu",
            "Yantao Du",
            "Zhi Chen",
            "Xie Chen",
            "Wanxiang Che"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21623",
        "abstract": "Understanding how information is dynamically accumulated and transformed in human reasoning has long challenged cognitive psychology, philosophy, and artificial intelligence. Existing accounts, from classical logic to probabilistic models, illuminate aspects of output or individual modelling, but do not offer a unified, quantitative description of general human reasoning dynamics. To solve this, we introduce Information Flow Tracking (IF-Track), that uses large language models (LLMs) as probabilistic encoder to quantify information entropy and gain at each reasoning step. Through fine-grained analyses across diverse tasks, our method is the first successfully models the universal landscape of human reasoning behaviors within a single metric space. We show that IF-Track captures essential reasoning features, identifies systematic error patterns, and characterizes individual differences. Applied to discussion of advanced psychological theory, we first reconcile single- versus dual-process theories in IF-Track and discover the alignment of artificial and human cognition and how LLMs reshaping human reasoning process. This approach establishes a quantitative bridge between theory and measurement, offering mechanistic insights into the architecture of reasoning.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "153",
        "title": "Few-Shot Knowledge Distillation of LLMs With Counterfactual Explanations",
        "author": [
            "Faisal Hamman",
            "Pasan Dissanayake",
            "Yanjun Fu",
            "Sanghamitra Dutta"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21631",
        "abstract": "Knowledge distillation is a promising approach to transfer capabilities from complex teacher models to smaller, resource-efficient student models that can be deployed easily, particularly in task-aware scenarios. However, existing methods of task-aware distillation typically require substantial quantities of data which may be unavailable or expensive to obtain in many practical scenarios. In this paper, we address this challenge by introducing a novel strategy called Counterfactual-explanation-infused Distillation CoD for few-shot task-aware knowledge distillation by systematically infusing counterfactual explanations. Counterfactual explanations (CFEs) refer to inputs that can flip the output prediction of the teacher model with minimum perturbation. Our strategy CoD leverages these CFEs to precisely map the teacher's decision boundary with significantly fewer samples. We provide theoretical guarantees for motivating the role of CFEs in distillation, from both statistical and geometric perspectives. We mathematically show that CFEs can improve parameter estimation by providing more informative examples near the teacher's decision boundary. We also derive geometric insights on how CFEs effectively act as knowledge probes, helping the students mimic the teacher's decision boundaries more effectively than standard data. We perform experiments across various datasets and LLMs to show that CoD outperforms standard distillation approaches in few-shot regimes (as low as 8-512 samples). Notably, CoD only uses half of the original samples used by the baselines, paired with their corresponding CFEs and still improves performance.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "154",
        "title": "DEEDEE: Fast and Scalable Out-of-Distribution Dynamics Detection",
        "author": [
            "Tala Aljaafari",
            "Varun Kanade",
            "Philip Torr",
            "Christian Schroeder de Witt"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21638",
        "abstract": "Deploying reinforcement learning (RL) in safety-critical settings is constrained by brittleness under distribution shift. We study out-of-distribution (OOD) detection for RL time series and introduce DEEDEE, a two-statistic detector that revisits representation-heavy pipelines with a minimal alternative. DEEDEE uses only an episodewise mean and an RBF kernel similarity to a training summary, capturing complementary global and local deviations. Despite its simplicity, DEEDEE matches or surpasses contemporary detectors across standard RL OOD suites, delivering a 600-fold reduction in compute (FLOPs / wall-time) and an average 5% absolute accuracy gain over strong baselines. Conceptually, our results indicate that diverse anomaly types often imprint on RL trajectories through a small set of low-order statistics, suggesting a compact foundation for OOD detection in complex environments.",
        "tags": [
            "Detection",
            "RL"
        ]
    },
    {
        "id": "155",
        "title": "Near-Optimal Min-Sum Motion Planning in a Planar Polygonal Environment",
        "author": [
            "Pankaj K. Agarwal",
            "Benjamin Holmgren",
            "Alex Steiger"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21639",
        "abstract": "Let $W \\subset \\mathbb{R}^2$ be a planar polygonal environment with $n$ vertices, and let $[k] = \\{1,\\ldots,k\\}$ denote $k$ unit-square robots translating in $W$. Given source and target placements $s_1, t_1, \\ldots, s_k, t_k \\in W$ for each robot, we wish to compute a collision-free motion plan $\\mathbf{\\pi}$, i.e., a coordinated motion for each robot $i$ along a continuous path from $s_i$ to $t_i$ so that robot $i$ does not leave $W$ or collide with any other $j$. Moreover, we additionally require that $\\mathbf{\\pi}$ minimizes the sum of the path lengths; this variant is known as \\textit{min-sum motion planning}.\nEven computing a feasible motion plan for $k$ unit-square robots in a polygonal environment is {\\textsf PSPACE}-hard. For $r > 0$, let $opt(\\mathbf{s},\\mathbf{t}, r)$ denote the cost of a min-sum motion plan for $k$ square robots of radius $r$ each from $\\mathbf{s}=(s_1,\\ldots,s_k)$ to $\\mathbf{t}=(t_1,\\ldots,t_k)$. Given a parameter $\\epsilon > 0$, we present an algorithm for computing a coordinated motion plan for $k$ unit radius square robots of cost at most $(1+\\epsilon)opt(\\mathbf{s},\\mathbf{t}, 1+\\epsilon)+\\epsilon$, which improves to $(1+\\epsilon)opt(\\mathbf{s},\\mathbf{t}, 1+\\epsilon)$ if $opt(\\mathbf{s},\\mathbf{t}, 1+\\epsilon)\\geq 1$, that runs in time $f(k,\\epsilon)n^{O(k)}$, where $f(k,\\epsilon) = (k/\\epsilon)^{O(k^2)}$. Our result is the first polynomial-time bicriteria $(1+\\epsilon)$-approximation algorithm for any optimal multi-robot motion planning problem amidst obstacles for a constant value of $k > 2$. The algorithm also works even if robots are modeled as $k$ congruent disks.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "156",
        "title": "Group Inertial Poser: Multi-Person Pose and Global Translation from Sparse Inertial Sensors and Ultra-Wideband Ranging",
        "author": [
            "Ying Xue",
            "Jiaxi Jiang",
            "Rayan Armani",
            "Dominik Hollidt",
            "Yi-Chi Liao",
            "Christian Holz"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21654",
        "abstract": "Tracking human full-body motion using sparse wearable inertial measurement units (IMUs) overcomes the limitations of occlusion and instrumentation of the environment inherent in vision-based approaches. However, purely IMU-based tracking compromises translation estimates and accurate relative positioning between individuals, as inertial cues are inherently self-referential and provide no direct spatial reference for others. In this paper, we present a novel approach for robustly estimating body poses and global translation for multiple individuals by leveraging the distances between sparse wearable sensors - both on each individual and across multiple individuals. Our method Group Inertial Poser estimates these absolute distances between pairs of sensors from ultra-wideband ranging (UWB) and fuses them with inertial observations as input into structured state-space models to integrate temporal motion patterns for precise 3D pose estimation. Our novel two-step optimization further leverages the estimated distances for accurately tracking people's global trajectories through the world. We also introduce GIP-DB, the first IMU+UWB dataset for two-person tracking, which comprises 200 minutes of motion recordings from 14 participants. In our evaluation, Group Inertial Poser outperforms previous state-of-the-art methods in accuracy and robustness across synthetic and real-world data, showing the promise of IMU+UWB-based multi-human motion capture in the wild. Code, models, dataset: https://github.com/eth-siplab/GroupInertialPoser",
        "tags": [
            "3D",
            "Pose Estimation",
            "SSMs"
        ]
    },
    {
        "id": "157",
        "title": "Smule Renaissance Small: Efficient General-Purpose Vocal Restoration",
        "author": [
            "Yongyi Zang",
            "Chris Manchester",
            "David Young",
            "Ivan Ivanov",
            "Jeffrey Lufkin",
            "Martin Vladimirov",
            "PJ Solomon",
            "Svetoslav Kepchelev",
            "Fei Yueh Chen",
            "Dongting Cai",
            "Teodor Naydenov",
            "Randal Leistikow"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21659",
        "abstract": "Vocal recordings on consumer devices commonly suffer from multiple concurrent degradations: noise, reverberation, band-limiting, and clipping. We present Smule Renaissance Small (SRS), a compact single-stage model that performs end-to-end vocal restoration directly in the complex STFT domain. By incorporating phase-aware losses, SRS enables large analysis windows for improved frequency resolution while achieving 10.5x real-time inference on iPhone 12 CPU at 48 kHz. On the DNS 5 Challenge blind set, despite no speech training, SRS outperforms a strong GAN baseline and closely matches a computationally expensive flow-matching system. To enable evaluation under realistic multi-degradation scenarios, we introduce the Extreme Degradation Bench (EDB): 87 singing and speech recordings captured under severe acoustic conditions. On EDB, SRS surpasses all open-source baselines on singing and matches commercial systems, while remaining competitive on speech despite no speech-specific training. We release both SRS and EDB under the MIT License.",
        "tags": [
            "Flow Matching",
            "GAN"
        ]
    },
    {
        "id": "158",
        "title": "FlowSynth: Instrument Generation Through Distributional Flow Matching and Test-Time Search",
        "author": [
            "Qihui Yang",
            "Randal Leistikow",
            "Yongyi Zang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21667",
        "abstract": "Virtual instrument generation requires maintaining consistent timbre across different pitches and velocities, a challenge that existing note-level models struggle to address. We present FlowSynth, which combines distributional flow matching (DFM) with test-time optimization for high-quality instrument synthesis. Unlike standard flow matching that learns deterministic mappings, DFM parameterizes the velocity field as a Gaussian distribution and optimizes via negative log-likelihood, enabling the model to express uncertainty in its predictions. This probabilistic formulation allows principled test-time search: we sample multiple trajectories weighted by model confidence and select outputs that maximize timbre consistency. FlowSynth outperforms the current state-of-the-art TokenSynth baseline in both single-note quality and cross-note consistency. Our approach demonstrates that modeling predictive uncertainty in flow matching, combined with music-specific consistency objectives, provides an effective path to professional-quality virtual instruments suitable for real-time performance.",
        "tags": [
            "Flow Matching"
        ]
    },
    {
        "id": "159",
        "title": "A Data-Centric Approach to Multilingual E-Commerce Product Search: Case Study on Query-Category and Query-Item Relevance",
        "author": [
            "Yabo Yin",
            "Yang Xi",
            "Jialong Wang",
            "Shanqi Wang",
            "Jiateng Hu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21671",
        "abstract": "Multilingual e-commerce search suffers from severe data imbalance across languages, label noise, and limited supervision for low-resource languages--challenges that impede the cross-lingual generalization of relevance models despite the strong capabilities of large language models (LLMs). In this work, we present a practical, architecture-agnostic, data-centric framework to enhance performance on two core tasks: Query-Category (QC) relevance (matching queries to product categories) and Query-Item (QI) relevance (matching queries to product titles). Rather than altering the model, we redesign the training data through three complementary strategies: (1) translation-based augmentation to synthesize examples for languages absent in training, (2) semantic negative sampling to generate hard negatives and mitigate class imbalance, and (3) self-validation filtering to detect and remove likely mislabeled instances. Evaluated on the CIKM AnalytiCup 2025 dataset, our approach consistently yields substantial F1 score improvements over strong LLM baselines, achieving competitive results in the official competition. Our findings demonstrate that systematic data engineering can be as impactful as--and often more deployable than--complex model modifications, offering actionable guidance for building robust multilingual search systems in the real-world e-commerce settings.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "160",
        "title": "A Multimodal Benchmark for Framing of Oil & Gas Advertising and Potential Greenwashing Detection",
        "author": [
            "Gaku Morio",
            "Harri Rowlands",
            "Dominik Stammbach",
            "Christopher D. Manning",
            "Peter Henderson"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21679",
        "abstract": "Companies spend large amounts of money on public relations campaigns to project a positive brand image. However, sometimes there is a mismatch between what they say and what they do. Oil & gas companies, for example, are accused of \"greenwashing\" with imagery of climate-friendly initiatives. Understanding the framing, and changes in framing, at scale can help better understand the goals and nature of public relations campaigns. To address this, we introduce a benchmark dataset of expert-annotated video ads obtained from Facebook and YouTube. The dataset provides annotations for 13 framing types for more than 50 companies or advocacy groups across 20 countries. Our dataset is especially designed for the evaluation of vision-language models (VLMs), distinguishing it from past text-only framing datasets. Baseline experiments show some promising results, while leaving room for improvement for future work: GPT-4.1 can detect environmental messages with 79% F1 score, while our best model only achieves 46% F1 score on identifying framing around green innovation. We also identify challenges that VLMs must address, such as implicit framing, handling videos of various lengths, or implicit cultural backgrounds. Our dataset contributes to research in multimodal analysis of strategic communication in the energy sector.",
        "tags": [
            "Detection",
            "GPT",
            "VLM"
        ]
    },
    {
        "id": "161",
        "title": "Toward provably private analytics and insights into GenAI use",
        "author": [
            "Albert Cheu",
            "Artem Lagzdin",
            "Brett McLarnon",
            "Daniel Ramage",
            "Katharine Daly",
            "Marco Gruteser",
            "Peter Kairouz",
            "Rakshita Tandon",
            "Stanislav Chiknavaryan",
            "Timon Van Overveldt",
            "Zoe Gong"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21684",
        "abstract": "Large-scale systems that compute analytics over a fleet of devices must achieve high privacy and security standards while also meeting data quality, usability, and resource efficiency expectations. We present a next-generation federated analytics system that uses Trusted Execution Environments (TEEs) based on technologies like AMD SEV-SNP and Intel TDX to provide verifiable privacy guarantees for all server-side processing. In our system, devices encrypt and upload data, tagging it with a limited set of allowable server-side processing steps. An open source, TEE-hosted key management service guarantees that the data is accessible only to those steps, which are themselves protected by TEE confidentiality and integrity assurance guarantees. The system is designed for flexible workloads, including processing unstructured data with LLMs (for structured summarization) before aggregation into differentially private insights (with automatic parameter tuning). The transparency properties of our system allow any external party to verify that all raw and derived data is processed in TEEs, protecting it from inspection by the system operator, and that differential privacy is applied to all released results. This system has been successfully deployed in production, providing helpful insights into real-world GenAI experiences.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "162",
        "title": "StylePitcher: Generating Style-Following and Expressive Pitch Curves for Versatile Singing Tasks",
        "author": [
            "Jingyue Huang",
            "Qihui Yang",
            "Fei Yueh Chen",
            "Julian McAuley",
            "Randal Leistikow",
            "Perry R. Cook",
            "Yongyi Zang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21685",
        "abstract": "Existing pitch curve generators face two main challenges: they often neglect singer-specific expressiveness, reducing their ability to capture individual singing styles. And they are typically developed as auxiliary modules for specific tasks such as pitch correction, singing voice synthesis, or voice conversion, which restricts their generalization capability. We propose StylePitcher, a general-purpose pitch curve generator that learns singer style from reference audio while preserving alignment with the intended melody. Built upon a rectified flow matching architecture, StylePitcher flexibly incorporates symbolic music scores and pitch context as conditions for generation, and can seamlessly adapt to diverse singing tasks without retraining. Objective and subjective evaluations across various singing tasks demonstrate that StylePitcher improves style similarity and audio quality while maintaining pitch accuracy comparable to task-specific baselines.",
        "tags": [
            "Flow Matching",
            "Rectified Flow"
        ]
    },
    {
        "id": "163",
        "title": "Mechanistic Interpretability for Neural TSP Solvers",
        "author": [
            "Reuben Narad",
            "Leonard Boussioux",
            "Michael Wagner"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21693",
        "abstract": "Neural networks have advanced combinatorial optimization, with Transformer-based solvers achieving near-optimal solutions on the Traveling Salesman Problem (TSP) in milliseconds. However, these models operate as black boxes, providing no insight into the geometric patterns they learn or the heuristics they employ during tour construction. We address this opacity by applying sparse autoencoders (SAEs), a mechanistic interpretability technique, to a Transformer-based TSP solver, representing the first application of activation-based interpretability methods to operations research models. We train a pointer network with reinforcement learning on 100-node instances, then fit an SAE to the encoder's residual stream to discover an overcomplete dictionary of interpretable features. Our analysis reveals that the solver naturally develops features mirroring fundamental TSP concepts: boundary detectors that activate on convex-hull nodes, cluster-sensitive features responding to locally dense regions, and separator features encoding geometric partitions. These findings provide the first model-internal account of what neural TSP solvers compute before node selection, demonstrate that geometric structure emerges without explicit supervision, and suggest pathways toward transparent hybrid systems that combine neural efficiency with algorithmic interpretability. Interactive feature explorer: https://reubennarad.github.io/TSP_interp",
        "tags": [
            "RL",
            "Transformer"
        ]
    },
    {
        "id": "164",
        "title": "BachVid: Training-Free Video Generation with Consistent Background and Character",
        "author": [
            "Han Yan",
            "Xibin Song",
            "Yifu Wang",
            "Hongdong Li",
            "Pan Ji",
            "Chao Ma"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21696",
        "abstract": "Diffusion Transformers (DiTs) have recently driven significant progress in text-to-video (T2V) generation. However, generating multiple videos with consistent characters and backgrounds remains a significant challenge. Existing methods typically rely on reference images or extensive training, and often only address character consistency, leaving background consistency to image-to-video models. We introduce BachVid, the first training-free method that achieves consistent video generation without needing any reference images. Our approach is based on a systematic analysis of DiT's attention mechanism and intermediate features, revealing its ability to extract foreground masks and identify matching points during the denoising process. Our method leverages this finding by first generating an identity video and caching the intermediate variables, and then inject these cached variables into corresponding positions in newly generated videos, ensuring both foreground and background consistency across multiple videos. Experimental results demonstrate that BachVid achieves robust consistency in generated videos without requiring additional training, offering a novel and efficient solution for consistent video generation without relying on reference images or additional training.",
        "tags": [
            "DiT",
            "Diffusion",
            "Text-to-Video",
            "Video Generation"
        ]
    },
    {
        "id": "165",
        "title": "Visual Diffusion Models are Geometric Solvers",
        "author": [
            "Nir Goren",
            "Shai Yehezkel",
            "Omer Dahary",
            "Andrey Voynov",
            "Or Patashnik",
            "Daniel Cohen-Or"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21697",
        "abstract": "In this paper we show that visual diffusion models can serve as effective geometric solvers: they can directly reason about geometric problems by working in pixel space. We first demonstrate this on the Inscribed Square Problem, a long-standing problem in geometry that asks whether every Jordan curve contains four points forming a square. We then extend the approach to two other well-known hard geometric problems: the Steiner Tree Problem and the Simple Polygon Problem.\nOur method treats each problem instance as an image and trains a standard visual diffusion model that transforms Gaussian noise into an image representing a valid approximate solution that closely matches the exact one. The model learns to transform noisy geometric structures into correct configurations, effectively recasting geometric reasoning as image generation.\nUnlike prior work that necessitates specialized architectures and domain-specific adaptations when applying diffusion to parametric geometric representations, we employ a standard visual diffusion model that operates on the visual representation of the problem. This simplicity highlights a surprising bridge between generative modeling and geometric problem solving. Beyond the specific problems studied here, our results point toward a broader paradigm: operating in image space provides a general and practical framework for approximating notoriously hard problems, and opens the door to tackling a far wider class of challenging geometric tasks.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "166",
        "title": "Automated Detection of Visual Attribute Reliance with a Self-Reflective Agent",
        "author": [
            "Christy Li",
            "Josep Lopez CamuÃ±as",
            "Jake Thomas Touchet",
            "Jacob Andreas",
            "Agata Lapedriza",
            "Antonio Torralba",
            "Tamar Rott Shaham"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21704",
        "abstract": "When a vision model performs image recognition, which visual attributes drive its predictions? Detecting unintended reliance on specific visual features is critical for ensuring model robustness, preventing overfitting, and avoiding spurious correlations. We introduce an automated framework for detecting such dependencies in trained vision models. At the core of our method is a self-reflective agent that systematically generates and tests hypotheses about visual attributes that a model may rely on. This process is iterative: the agent refines its hypotheses based on experimental outcomes and uses a self-evaluation protocol to assess whether its findings accurately explain model behavior. When inconsistencies arise, the agent self-reflects over its findings and triggers a new cycle of experimentation. We evaluate our approach on a novel benchmark of 130 models designed to exhibit diverse visual attribute dependencies across 18 categories. Our results show that the agent's performance consistently improves with self-reflection, with a significant performance increase over non-reflective baselines. We further demonstrate that the agent identifies real-world visual attribute dependencies in state-of-the-art models, including CLIP's vision encoder and the YOLOv8 object detector.",
        "tags": [
            "CLIP",
            "Detection"
        ]
    },
    {
        "id": "167",
        "title": "Can large audio language models understand child stuttering speech? speech summarization, and source separation",
        "author": [
            "Chibuzor Okocha",
            "Maya Bakri",
            "Christan Grant"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20850",
        "abstract": "Child speech differs from adult speech in acoustics, prosody, and language development, and disfluencies (repetitions, prolongations, blocks) further challenge Automatic Speech Recognition (ASR) and downstream Natural Language Processing (NLP). Recent large audio-language models (LALMs) demonstrate strong cross-modal audio understanding; however, their behavior in disfluent child speech remains underexplored. We evaluate several state-of-the-art LALMs in two settings: an interview (mixed speakers) and a reading task (single child). The tasks are (i) single-channel source separation to isolate the child and (ii) child-only summarization that preserves clinically relevant disfluencies and avoids adult-speech leakage.\nEvaluation combines Large Language Model (LLM) as a judge, human expert ratings, and BERTScore (F1), and we report agreement between models and between models and humans to assess reliability. Our findings delineate the conditions under which LALMs produce faithful child-only summaries from mixed audio and where they fail, offering practical guidance for clinical and educational deployments. We provide prompts and evaluation scripts to support replication.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "168",
        "title": "Exponential Convergence Guarantees for Iterative Markovian Fitting",
        "author": [
            "Marta Gentiloni Silveri",
            "Giovanni Conforti",
            "Alain Durmus"
        ],
        "pdf": "https://arxiv.org/pdf/2510.20871",
        "abstract": "The SchrÃ¶dinger Bridge (SB) problem has become a fundamental tool in computational optimal transport and generative modeling. To address this problem, ideal methods such as Iterative Proportional Fitting and Iterative Markovian Fitting (IMF) have been proposed-alongside practical approximations like Diffusion SchrÃ¶dinger Bridge and its Matching (DSBM) variant. While previous work have established asymptotic convergence guarantees for IMF, a quantitative, non-asymptotic understanding remains unknown. In this paper, we provide the first non-asymptotic exponential convergence guarantees for IMF under mild structural assumptions on the reference measure and marginal distributions, assuming a sufficiently large time horizon. Our results encompass two key regimes: one where the marginals are log-concave, and another where they are weakly log-concave. The analysis relies on new contraction results for the Markovian projection operator and paves the way to theoretical guarantees for DSBM.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "169",
        "title": "Hierarchical AI Multi-Agent Fundamental Investing: Evidence from China's A-Share Market",
        "author": [
            "Chujun He",
            "Zhonghao Huang",
            "Xiangguo Li",
            "Ye Luo",
            "Kewei Ma",
            "Yuxuan Xiong",
            "Xiaowei Zhang",
            "Mingyang Zhao"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21147",
        "abstract": "We present a multi-agent, AI-driven framework for fundamental investing that integrates macro indicators, industry-level and firm-specific information to construct optimized equity portfolios. The architecture comprises: (i) a Macro agent that dynamically screens and weights sectors based on evolving economic indicators and industry performance; (ii) four firm-level agents -- Fundamental, Technical, Report, and News -- that conduct in-depth analyses of individual firms to ensure both breadth and depth of coverage; (iii) a Portfolio agent that uses reinforcement learning to combine the agent outputs into a unified policy to generate the trading strategy; and (iv) a Risk Control agent that adjusts portfolio positions in response to market volatility. We evaluate the system on the constituents by the CSI 300 Index of China's A-share market and find that it consistently outperforms standard benchmarks and a state-of-the-art multi-agent trading system on risk-adjusted returns and drawdown control. Our core contribution is a hierarchical multi-agent design that links top-down macro screening with bottom-up fundamental analysis, offering a robust and extensible approach to factor-based portfolio construction.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "170",
        "title": "SpecTokenizer: A Lightweight Streaming Codec in the Compressed Spectrum Domain",
        "author": [
            "Zixiang Wan",
            "Guochang Zhang",
            "Yifeng He",
            "Jianqiang Wei"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21209",
        "abstract": "Neural Audio Codecs (NACs) have gained growing attention in recent years as technologies for audio compression and audio representation in speech language models. While mainstream NACs typically require G-level computation and M-level parameters, the performance of lightweight and streaming NACs remains underexplored. This paper proposes SpecTokenizer, a lightweight streaming codec that operates in the compressed spectral domain. Composed solely of alternating CNN and RNN layers, SpecTokenizer achieves greater efficiency and better representational capability through multi-scale modeling in the compressed spectrum domain. At 4 kbps, the proposed SpecTokenizer achieves comparable or superior performance compared to the codec with state-of-the-art lightweight architecture while requiring only 20% of the computation and 10% of the parameters. Furthermore, it significantly outperforms the codec when using similar computational and storage resources.",
        "tags": [
            "RNN"
        ]
    },
    {
        "id": "171",
        "title": "Patient-specific AI for generation of 3D dosimetry imaging from two 2D-planar measurements",
        "author": [
            "Alejandro Lopez-Montes",
            "Robert Seifert",
            "Astrid Delker",
            "Guido Boening",
            "Jiahui Wang",
            "Christoph Clement",
            "Ali Afshar-Oromieh",
            "Axel Rominger",
            "Kuangyu Shi"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21362",
        "abstract": "In this work we explored the use of patient specific reinforced learning to generate 3D activity maps from two 2D planar images (anterior and posterior). The solution of this problem remains unachievable using conventional methodologies and is of particular interest for dosimetry in nuclear medicine where approaches for post-therapy distribution of radiopharmaceuticals such as 177Lu-PSMA are typically done via either expensive and long 3D SPECT acquisitions or fast, yet only 2D, planar scintigraphy. Being able to generate 3D activity maps from planar scintigraphy opens the gate for new dosimetry applications removing the need for SPECT and facilitating multi-time point dosimetry studies. Our solution comprises the generation of a patient specific dataset with possible 3D uptake maps of the radiopharmaceuticals withing the anatomy of the individual followed by an AI approach (we explored both the use of 3DUnet and diffusion models) able to generate 3D activity maps from 2D planar images. We have validated our method both in simulation and real planar acquisitions. We observed enhanced results using patient specific reinforcement learning (~20% reduction on MAE and ~5% increase in SSIM) and better organ delineation and patient anatomy especially when combining diffusion models with patient specific training yielding a SSIM=0.89 compared to the ground truth for simulations and 0.73 when compared to a SPECT acquisition performed half an hour after the planar. We believe that our methodology can set a change of paradigm for nuclear medicine dosimetry allowing for 3D quantification using only planar scintigraphy without the need of expensive and time-consuming SPECT leveraging the pre-therapy information of the patients.",
        "tags": [
            "3D",
            "Diffusion",
            "RL"
        ]
    },
    {
        "id": "172",
        "title": "Efficient Exploration of Chemical Kinetics",
        "author": [
            "Rohit Goswami"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21368",
        "abstract": "Estimating reaction rates and chemical stability is fundamental, yet efficient methods for large-scale simulations remain out of reach despite advances in modeling and exascale computing. Direct simulation is limited by short timescales; machine-learned potentials require large data sets and struggle with transition state regions essential for reaction rates. Reaction network exploration with sufficient accuracy is hampered by the computational cost of electronic structure calculations, and even simplifications like harmonic transition state theory rely on prohibitively expensive saddle point searches. Surrogate model-based acceleration has been promising but hampered by overhead and numerical instability.\nThis dissertation presents a holistic solution, co-designing physical representations, statistical models, and systems architecture in the Optimal Transport Gaussian Process (OT-GP) framework. Using physics-aware optimal transport metrics, OT-GP creates compact, chemically relevant surrogates of the potential energy surface, underpinned by statistically robust sampling. Alongside EON software rewrites for long timescale simulations, we introduce reinforcement learning approaches for both minimum-mode following (when the final state is unknown) and nudged elastic band methods (when endpoints are specified). Collectively, these advances establish a representation-first, modular approach to chemical kinetics simulation. Large-scale benchmarks and Bayesian hierarchical validation demonstrate state-of-the-art performance and practical exploration of chemical kinetics, transforming a longstanding theoretical promise into a working engine for discovery.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "173",
        "title": "Compressing Quaternion Convolutional Neural Networks for Audio Classification",
        "author": [
            "Arshdeep Singh",
            "Vinayak Abrol",
            "Mark D. Plumbley"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21388",
        "abstract": "Conventional Convolutional Neural Networks (CNNs) in the real domain have been widely used for audio classification. However, their convolution operations process multi-channel inputs independently, limiting the ability to capture correlations among channels. This can lead to suboptimal feature learning, particularly for complex audio patterns such as multi-channel spectrogram representations. Quaternion Convolutional Neural Networks (QCNNs) address this limitation by employing quaternion algebra to jointly capture inter-channel dependencies, enabling more compact models with fewer learnable parameters while better exploiting the multi-dimensional nature of audio signals. However, QCNNs exhibit higher computational complexity due to the overhead of quaternion operations, resulting in increased inference latency and reduced efficiency compared to conventional CNNs, posing challenges for deployment on resource-constrained platforms. To address this challenge, this study explores knowledge distillation (KD) and pruning, to reduce the computational complexity of QCNNs while maintaining performance. Our experiments on audio classification reveal that pruning QCNNs achieves similar or superior performance compared to KD while requiring less computational effort. Compared to conventional CNNs and Transformer-based architectures, pruned QCNNs achieve competitive performance with a reduced learnable parameter count and computational complexity. On the AudioSet dataset, pruned QCNNs reduce computational cost by 50\\% and parameter count by 80\\%, while maintaining performance comparable to the conventional CNNs. Furthermore, pruned QCNNs generalize well across multiple audio classification benchmarks, including GTZAN for music genre recognition, ESC-50 for environmental sound classification and RAVDESS for speech emotion recognition.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "174",
        "title": "HollowFlow: Efficient Sample Likelihood Evaluation using Hollow Message Passing",
        "author": [
            "Johann Flemming Gloy",
            "Simon Olsson"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21542",
        "abstract": "Flow and diffusion-based models have emerged as powerful tools for scientific applications, particularly for sampling non-normalized probability distributions, as exemplified by Boltzmann Generators (BGs). A critical challenge in deploying these models is their reliance on sample likelihood computations, which scale prohibitively with system size $n$, often rendering them infeasible for large-scale problems. To address this, we introduce $\\textit{HollowFlow}$, a flow-based generative model leveraging a novel non-backtracking graph neural network (NoBGNN). By enforcing a block-diagonal Jacobian structure, HollowFlow likelihoods are evaluated with a constant number of backward passes in $n$, yielding speed-ups of up to $\\mathcal{O}(n^2)$: a significant step towards scaling BGs to larger systems. Crucially, our framework generalizes: $\\textbf{any equivariant GNN or attention-based architecture}$ can be adapted into a NoBGNN. We validate HollowFlow by training BGs on two different systems of increasing size. For both systems, the sampling and likelihood evaluation time decreases dramatically, following our theoretical scaling laws. For the larger system we obtain a $10^2\\times$ speed-up, clearly illustrating the potential of HollowFlow-based approaches for high-dimensional scientific problems previously hindered by computational bottlenecks.",
        "tags": [
            "Diffusion"
        ]
    }
]