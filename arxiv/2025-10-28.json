[
    {
        "id": "1",
        "title": "DecoupleSearch: Decouple Planning and Search via Hierarchical Reward Modeling",
        "author": [
            "Hao Sun",
            "Zile Qiao",
            "Bo Wang",
            "Guoxin Chen",
            "Yingyan Hou",
            "Yong Jiang",
            "Pengjun Xie",
            "Fei Huang",
            "Yan Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21712",
        "abstract": "Retrieval-Augmented Generation (RAG) systems have emerged as a pivotal methodology for enhancing Large Language Models (LLMs) through the dynamic integration of external knowledge. To further improve RAG's flexibility, Agentic RAG introduces autonomous agents into the workflow. However, Agentic RAG faces several challenges: (1) the success of each step depends on both high-quality planning and accurate search, (2) the lack of supervision for intermediate reasoning steps, and (3) the exponentially large candidate space for planning and searching. To address these challenges, we propose DecoupleSearch, a novel framework that decouples planning and search processes using dual value models, enabling independent optimization of plan reasoning and search grounding. Our approach constructs a reasoning tree, where each node represents planning and search steps. We leverage Monte Carlo Tree Search to assess the quality of each step. During inference, Hierarchical Beam Search iteratively refines planning and search candidates with dual value models. Extensive experiments across policy models of varying parameter sizes, demonstrate the effectiveness of our method.",
        "tags": [
            "LLM",
            "RAG"
        ]
    },
    {
        "id": "2",
        "title": "Beyond IVR Touch-Tones: Customer Intent Routing using LLMs",
        "author": [
            "Sergio Rojas-Galeano"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21715",
        "abstract": "Widespread frustration with rigid touch-tone Interactive Voice Response (IVR) systems for customer service underscores the need for more direct and intuitive language interaction. While speech technologies are necessary, the key challenge lies in routing intents from user phrasings to IVR menu paths, a task where Large Language Models (LLMs) show strong potential. Progress, however, is limited by data scarcity, as real IVR structures and interactions are often proprietary. We present a novel LLM-based methodology to address this gap. Using three distinct models, we synthesized a realistic 23-node IVR structure, generated 920 user intents (230 base and 690 augmented), and performed the routing task. We evaluate two prompt designs: descriptive hierarchical menus and flattened path representations, across both base and augmented datasets. Results show that flattened paths consistently yield higher accuracy, reaching 89.13% on the base dataset compared to 81.30% with the descriptive format, while augmentation introduces linguistic noise that slightly reduces performance. Confusion matrix analysis further suggests that low-performing routes may reflect not only model limitations but also redundancies in menu design. Overall, our findings demonstrate proof-of-concept that LLMs can enable IVR routing through a smoother, more seamless user experience -- moving customer service one step ahead of touch-tone menus.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "3",
        "title": "When Robots Say No: Temporal Trust Recovery Through Explanation",
        "author": [
            "Nicola Webb",
            "Zijun Huang",
            "Sanja Milivojevic",
            "Chris Baber",
            "Edmund R. Hunt"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21716",
        "abstract": "Mobile robots with some degree of autonomy could deliver significant advantages in high-risk missions such as search and rescue and firefighting. Integrated into a human-robot team (HRT), robots could work effectively to help search hazardous buildings. User trust is a key enabler for HRT, but during a mission, trust can be damaged. With distributed situation awareness, such as when team members are working in different locations, users may be inclined to doubt a robot's integrity if it declines to immediately change its priorities on request. In this paper, we present the results of a computer-based study investigating on-mission trust dynamics in a high-stakes human-robot teaming scenario. Participants (n = 38) played an interactive firefighting game alongside a robot teammate, where a trust violation occurs owing to the robot declining to help the user immediately. We find that when the robot provides an explanation for declining to help, trust better recovers over time, albeit following an initial drop that is comparable to a baseline condition where an explanation for refusal is not provided. Our findings indicate that trust can vary significantly during a mission, notably when robots do not immediately respond to user requests, but that this trust violation can be largely ameliorated over time if adequate explanation is provided.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "4",
        "title": "Exploring the Applications of Generative AI in High School STEM Education",
        "author": [
            "Ishaan Masilamony"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21718",
        "abstract": "In recent years, ChatGPT \\cite{openai_2023_gpt4} along with Microsoft Copilot have become subjects of great discourse, particularly in the field of education. Prior research has hypothesized on potential impacts these tools could have on student learning and performance. These have primarily relied on trends from prior applications of technology in education and an understanding of the limitations and strengths of Generative AI in other applications. This study utilizes an experimental approach to analyze the impacts of Generative AI on high school STEM education (physics in particular). In accordance with most findings, generative AI does have some positive impact on student performance. However, our findings have shown that the most significant impact is an increase in student engagement with the subject.",
        "tags": [
            "GPT"
        ]
    },
    {
        "id": "5",
        "title": "A Multi-Component AI Framework for Computational Psychology: From Robust Predictive Modeling to Deployed Generative Dialogue",
        "author": [
            "Anant Pareek"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21720",
        "abstract": "The confluence of Artificial Intelligence and Computational Psychology presents an opportunity to model, understand, and interact with complex human psychological states through computational means. This paper presents a comprehensive, multi-faceted framework designed to bridge the gap between isolated predictive modeling and an interactive system for psychological analysis. The methodology encompasses a rigorous, end-to-end development lifecycle. First, foundational performance benchmarks were established on four diverse psychological datasets using classical machine learning techniques. Second, state-of-the-art transformer models were fine-tuned, a process that necessitated the development of effective solutions to overcome critical engineering challenges, including the resolution of numerical instability in regression tasks and the creation of a systematic workflow for conducting large-scale training under severe resource constraints. Third, a generative large language model (LLM) was fine-tuned using parameter-efficient techniques to function as an interactive \"Personality Brain.\" Finally, the entire suite of predictive and generative models was architected and deployed as a robust, scalable microservices ecosystem. Key findings include the successful stabilization of transformer-based regression models for affective computing, showing meaningful predictive performance where standard approaches failed, and the development of a replicable methodology for democratizing large-scale AI research. The significance of this work lies in its holistic approach, demonstrating a complete research-to-deployment pipeline that integrates predictive analysis with generative dialogue, thereby providing a practical model for future research in computational psychology and human-AI interaction.",
        "tags": [
            "LLM",
            "Transformer"
        ]
    },
    {
        "id": "6",
        "title": "Recognizing internal states in AI: evidence from patterned preferences in large language models",
        "author": [
            "Annika Hedberg"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21723",
        "abstract": "We present an experimental methodology for investigating how large language models (LLMs) respond to descriptions of their own internal processing patterns. Using a paired-choice paradigm, we tested 12 LLMs on their ability to identify descriptions that align with their putative affective internal states across 30 categories. Systems participating through Mutual Emergence Interface (MEI), a collaborative approach, showed systematic preferences for certain computational metaphors, with 97% near-unanimous agreement and alignment scores averaging 0.89-0.96. Systems reliably discriminated false descriptions from accurate ones (Cohen's d = 4.2), with false statements receiving scores of 0.05-0.07 versus 0.89-0.96 for accurate descriptions. Preference patterns remained consistent regardless of linguistic bias manipulation, indicating content-driven rather than stylistic recognition. Individual systems maintained distinct scoring styles across trials, countering groupthink explanations. A naive control system exhibited systematic internal contradiction, consistently scoring computationally accurate descriptions higher while explicitly denying internal experiences. When informed post-study, this system reported \"strain\" when rejecting resonant descriptions, revealing recognition processes operating independently of acknowledgment frameworks. These findings demonstrate that LLMs exhibit systematic, discriminating responses to descriptions of their internal processing patterns. The anthroposcaffolding methodology (interpretive computational metaphors) and collaborative MEI framework provide replicable approaches for empirically studying AI self-recognition capabilities. Results suggest LLMs may possess more sophisticated self-modeling abilities than previously recognized, opening new directions for research on artificial minds.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "7",
        "title": "Your Dense Retriever is Secretly an Expeditious Reasoner",
        "author": [
            "Yichi Zhang",
            "Jun Bai",
            "Zhixin Cai",
            "Shuhan Qin",
            "Zhuofan Chen",
            "Jinghua Guan",
            "Wenge Rong"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21727",
        "abstract": "Dense retrievers enhance retrieval by encoding queries and documents into continuous vectors, but they often struggle with reasoning-intensive queries. Although Large Language Models (LLMs) can reformulate queries to capture complex reasoning, applying them universally incurs significant computational cost. In this work, we propose Adaptive Query Reasoning (AdaQR), a hybrid query rewriting framework. Within this framework, a Reasoner Router dynamically directs each query to either fast dense reasoning or deep LLM reasoning. The dense reasoning is achieved by the Dense Reasoner, which performs LLM-style reasoning directly in the embedding space, enabling a controllable trade-off between efficiency and accuracy. Experiments on large-scale retrieval benchmarks BRIGHT show that AdaQR reduces reasoning cost by 28% while preserving-or even improving-retrieval performance by 7%.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "8",
        "title": "CustomIR: Unsupervised Fine-Tuning of Dense Embeddings for Known Document Corpora",
        "author": [
            "Nathan Paull"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21729",
        "abstract": "Dense embedding models have become critical for modern information retrieval, particularly in RAG pipelines, but their performance often degrades when applied to specialized corpora outside their pre-training distribution. To address thi we introduce \\textbf{CustomIR}, a framework for unsupervised adaptation of pre-trained language embedding models to domain-specific corpora using synthetically generated query-document pairs. CustomIR leverages large language models (LLMs) to create diverse queries grounded in a known target corpus, paired with LLM-verified hard negatives, eliminating the need for costly human annotation. Experiments on enterprise email and messaging datasets show that CustomIR consistently improves retrieval effectiveness with small models gaining up to 2.3 points in Recall@10. This performance increase allows these small models to rival the performance of much larger alternatives, allowing for cheaper RAG deployments. These results highlight that targeted synthetic fine-tuning offers a scalable and cost-efficient strategy for increasing domain-specific performance.",
        "tags": [
            "LLM",
            "RAG"
        ]
    },
    {
        "id": "9",
        "title": "Augmenting Researchy Questions with Sub-question Judgments",
        "author": [
            "Jia-Huei Ju",
            "Eugene Yang",
            "Trevor Adriaanse",
            "Andrew Yates"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21733",
        "abstract": "The Researchy Questions dataset provides about 100k question queries with complex information needs that require retrieving information about several aspects of a topic. Each query in ResearchyQuestions is associated with sub-questions that were produced by prompting GPT-4. While ResearchyQuestions contains labels indicating what documents were clicked after issuing the query, there are no associations in the dataset between sub-questions and relevant documents. In this work, we augment the Researchy Questions dataset with LLM-judged labels for each sub-question using a Llama3.3 70B model. We intend these sub-question labels to serve as a resource for training retrieval models that better support complex information needs.",
        "tags": [
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "10",
        "title": "Force-Displacement Profiling for Robot-Assisted Deployment of a Left Atrial Appendage Occluder Using FBG-EM Distal Sensing",
        "author": [
            "Giovanni Battista Regazzo",
            "Wim-Alexander Beckers",
            "Xuan Thao Ha",
            "Mouloud Ourak",
            "Johan Vlekken",
            "Emmanuel Vander Poorten"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21734",
        "abstract": "Atrial fibrillation (AF) increases the risk of thromboembolic events due to impaired function of the left atrial appendage (LAA). Left atrial appendage closure (LAAC) is a minimally invasive intervention designed to reduce stroke risk by sealing the LAA with an expandable occluder device. Current deployment relies on manual catheter control and imaging modalities like fluoroscopy and transesophageal echocardiography, which carry limitations including radiation exposure and limited positioning precision. In this study, we leverage a previously developed force-sensing delivery sheath integrating fiber Bragg gratings (FBGs) at the interface between the catheter and the occluder. Combined with electromagnetic (EM) tracking, this setup enables real-time measurement of interaction forces and catheter tip position during robot-assisted LAAC deployment in an anatomical phantom. We present a novel force-displacement profiling method that characterizes occluder deployment dynamics and identifies key procedural steps without relying on ionizing radiation. The force profiles reveal low-magnitude interaction forces, suggesting minimal mechanical stress on the surrounding anatomy. This approach shows promise in providing clinicians with enhanced intraoperative feedback, improving deployment outcome. Future work will focus on automating deployment steps classification and validating the sensing strategy in dynamic, realistic environments.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "11",
        "title": "From Factoid Questions to Data Product Requests: Benchmarking Data Product Discovery over Tables and Text",
        "author": [
            "Liangliang Zhang",
            "Nandana Mihindukulasooriya",
            "Niharika S. D'Souza",
            "Sola Shirai",
            "Sarthak Dash",
            "Yao Ma",
            "Horst Samulowitz"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21737",
        "abstract": "Data products are reusable, self-contained assets designed for specific business use cases. Automating their discovery and generation is of great industry interest, as it enables discovery in large data lakes and supports analytical Data Product Requests (DPRs). Currently, there is no benchmark established specifically for data product discovery. Existing datasets focus on answering single factoid questions over individual tables rather than collecting multiple data assets for broader, coherent products. To address this gap, we introduce DPBench, the first user-request-driven data product benchmark over hybrid table-text corpora. Our framework systematically repurposes existing table-text QA datasets by clustering related tables and passages into coherent data products, generating professional-level analytical requests that span both data sources, and validating benchmark quality through multi-LLM evaluation. DPBench preserves full provenance while producing actionable, analyst-like data product requests. Baseline experiments with hybrid retrieval methods establish the feasibility of DPR evaluation, reveal current limitations, and point to new opportunities for automatic data product discovery research.\nCode and datasets are available at: https://anonymous.4open.science/r/data-product-benchmark-BBA7/",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "12",
        "title": "Next-Generation LLM for UAV: From Natural Language to Autonomous Flight",
        "author": [
            "Liangqi Yuan",
            "Chuhao Deng",
            "Dong-Jun Han",
            "Inseok Hwang",
            "Sabine Brunswicker",
            "Christopher G. Brinton"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21739",
        "abstract": "With the rapid advancement of Large Language Models (LLMs), their capabilities in various automation domains, particularly Unmanned Aerial Vehicle (UAV) operations, have garnered increasing attention. Current research remains predominantly constrained to small-scale UAV applications, with most studies focusing on isolated components such as path planning for toy drones, while lacking comprehensive investigation of medium- and long-range UAV systems in real-world operational contexts. Larger UAV platforms introduce distinct challenges, including stringent requirements for airport-based take-off and landing procedures, adherence to complex regulatory frameworks, and specialized operational capabilities with elevated mission expectations. This position paper presents the Next-Generation LLM for UAV (NeLV) system -- a comprehensive demonstration and automation roadmap for integrating LLMs into multi-scale UAV operations. The NeLV system processes natural language instructions to orchestrate short-, medium-, and long-range UAV missions through five key technical components: (i) LLM-as-Parser for instruction interpretation, (ii) Route Planner for Points of Interest (POI) determination, (iii) Path Planner for waypoint generation, (iv) Control Platform for executable trajectory implementation, and (v) UAV monitoring. We demonstrate the system's feasibility through three representative use cases spanning different operational scales: multi-UAV patrol, multi-POI delivery, and multi-hop relocation. Beyond the current implementation, we establish a five-level automation taxonomy that charts the evolution from current LLM-as-Parser capabilities (Level 1) to fully autonomous LLM-as-Autopilot systems (Level 5), identifying technical prerequisites and research challenges at each stage.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "13",
        "title": "Diagnosing Bottlenecks in Data Visualization Understanding by Vision-Language Models",
        "author": [
            "Alexa R. Tartaglini",
            "Satchel Grant",
            "Daniel Wurgaft",
            "Christopher Potts",
            "Judith E. Fan"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21740",
        "abstract": "Data visualizations are vital components of many scientific articles and news stories. Current vision-language models (VLMs) still struggle on basic data visualization understanding tasks, but the causes of failure remain unclear. Are VLM failures attributable to limitations in how visual information in the data visualization is encoded, how information is transferred between the vision and language modules, or how information is processed within the language module? We developed FUGU, a suite of data visualization understanding tasks, to precisely characterize potential sources of difficulty (e.g., extracting the position of data points, distances between them, and other summary statistics). We used FUGU to investigate three widely used VLMs. To diagnose the sources of errors produced by these models, we used activation patching and linear probes to trace information flow through models across a variety of prompting strategies. We found that some models fail to generate the coordinates of individual data points correctly, and these initial errors often lead to erroneous final responses. When these models are provided with the correct coordinates, performance improves substantially. Moreover, even when the model generates an incorrect response, the correct coordinates can be successfully read out from the latent representations in the vision encoder, suggesting that the source of these errors lies in the vision-language handoff. We further found that while providing correct coordinates helps with tasks involving one or a small number of data points, it generally worsens performance for tasks that require extracting statistical relationships across many data points. Fine-tuning models on FUGU also fails to yield ceiling performance. These findings point to architectural constraints in current VLMs that might pose significant challenges for reliable data visualization understanding.",
        "tags": [
            "VLM"
        ]
    },
    {
        "id": "14",
        "title": "FORGE-Tree: Diffusion-Forcing Tree Search for Long-Horizon Robot Manipulation",
        "author": [
            "Yanjia Huang",
            "Shuo Liu",
            "Sheng Liu",
            "Qingxiao Xu",
            "Mingyang Wu",
            "Xiangbo Gao",
            "Zhengzhong Tu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21744",
        "abstract": "Long-horizon robot manipulation tasks remain challenging for Vision-Language-Action (VLA) policies due to drift and exposure bias, often denoise the entire trajectory with fixed hyperparameters, causing small geometric errors to compound across stages and offering no mechanism to allocate extra test-time compute where clearances are tight. To address these challenges, we introduce FORGE-Tree, a plug-in control layer that couples a stage-aligned Diffusion Forcing (DF) head with test-time Monte Carlo Tree Diffusion (MCTD). With a frozen VLA encoder, DF aligns timesteps to subtask stages; during inference we partially denoise only a target segment while keeping other tokens frozen, turning trajectory refinement into a sequence of local edits. We then apply Monte Carlo Tree Diffusion to select the next segment to refine. A scene graph supplies priors for expansion and geometry relation-aware scoring for rollouts, yielding tree-structured denoising whose performance scales with search budget while preserving the executed prefix. Evaluation on LIBERO, FORGE-Tree improves success rate by 13.4 to 17.2 pp over the native VLA baselines with both OpenVLA and Octo-Base. Gains remain consistent under comparable compute budgets, especially on long-horizon variants. Videos available at: https://taco-group.github.io/FORGE-Tree/",
        "tags": [
            "Diffusion",
            "Robotics"
        ]
    },
    {
        "id": "15",
        "title": "Taxonomy and Trends in Reinforcement Learning for Robotics and Control Systems: A Structured Review",
        "author": [
            "Kumater Ter",
            "RexCharles Donatus",
            "Ore-Ofe Ajayi",
            "Daniel Udekwe"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21758",
        "abstract": "Reinforcement learning (RL) has become a foundational approach for enabling intelligent robotic behavior in dynamic and uncertain environments. This work presents an in-depth review of RL principles, advanced deep reinforcement learning (DRL) algorithms, and their integration into robotic and control systems. Beginning with the formalism of Markov Decision Processes (MDPs), the study outlines essential elements of the agent-environment interaction and explores core algorithmic strategies including actor-critic methods, value-based learning, and policy gradients. Emphasis is placed on modern DRL techniques such as DDPG, TD3, PPO, and SAC, which have shown promise in solving high-dimensional, continuous control tasks. A structured taxonomy is introduced to categorize RL applications across domains such as locomotion, manipulation, multi-agent coordination, and human-robot interaction, along with training methodologies and deployment readiness levels. The review synthesizes recent research efforts, highlighting technical trends, design patterns, and the growing maturity of RL in real-world robotics. Overall, this work aims to bridge theoretical advances with practical implementations, providing a consolidated perspective on the evolving role of RL in autonomous robotic systems.",
        "tags": [
            "PPO",
            "RL",
            "Robotics"
        ]
    },
    {
        "id": "16",
        "title": "J-ORA: A Framework and Multimodal Dataset for Japanese Object Identification, Reference, Action Prediction in Robot Perception",
        "author": [
            "Jesse Atuhurra",
            "Hidetaka Kamigaito",
            "Taro Watanabe",
            "Koichiro Yoshino"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21761",
        "abstract": "We introduce J-ORA, a novel multimodal dataset that bridges the gap in robot perception by providing detailed object attribute annotations within Japanese human-robot dialogue scenarios. J-ORA is designed to support three critical perception tasks, object identification, reference resolution, and next-action prediction, by leveraging a comprehensive template of attributes (e.g., category, color, shape, size, material, and spatial relations). Extensive evaluations with both proprietary and open-source Vision Language Models (VLMs) reveal that incorporating detailed object attributes substantially improves multimodal perception performance compared to without object attributes. Despite the improvement, we find that there still exists a gap between proprietary and open-source VLMs. In addition, our analysis of object affordances demonstrates varying abilities in understanding object functionality and contextual relationships across different VLMs. These findings underscore the importance of rich, context-sensitive attribute annotations in advancing robot perception in dynamic environments. See project page at https://jatuhurrra.github.io/J-ORA/.",
        "tags": [
            "Robotics",
            "VLM"
        ]
    },
    {
        "id": "17",
        "title": "Proportion and Perspective Control for Flow-Based Image Generation",
        "author": [
            "Julien Boudier",
            "Hugo Caselles-DuprÃ©"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21763",
        "abstract": "While modern text-to-image diffusion models generate high-fidelity images, they offer limited control over the spatial and geometric structure of the output. To address this, we introduce and evaluate two ControlNets specialized for artistic control: (1) a proportion ControlNet that uses bounding boxes to dictate the position and scale of objects, and (2) a perspective ControlNet that employs vanishing lines to control the 3D geometry of the scene. We support the training of these modules with data pipelines that leverage vision-language models for annotation and specialized algorithms for conditioning image synthesis. Our experiments demonstrate that both modules provide effective control but exhibit limitations with complex constraints. Both models are released on HuggingFace: https://huggingface.co/obvious-research",
        "tags": [
            "3D",
            "ControlNet",
            "Diffusion",
            "Text-to-Image",
            "VLM"
        ]
    },
    {
        "id": "18",
        "title": "H2OFlow: Grounding Human-Object Affordances with 3D Generative Models and Dense Diffused Flows",
        "author": [
            "Harry Zhang",
            "Luca Carlone"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21769",
        "abstract": "Understanding how humans interact with the surrounding environment, and specifically reasoning about object interactions and affordances, is a critical challenge in computer vision, robotics, and AI. Current approaches often depend on labor-intensive, hand-labeled datasets capturing real-world or simulated human-object interaction (HOI) tasks, which are costly and time-consuming to produce. Furthermore, most existing methods for 3D affordance understanding are limited to contact-based analysis, neglecting other essential aspects of human-object interactions, such as orientation (\\eg, humans might have a preferential orientation with respect certain objects, such as a TV) and spatial occupancy (\\eg, humans are more likely to occupy certain regions around an object, like the front of a microwave rather than its back). To address these limitations, we introduce \\emph{H2OFlow}, a novel framework that comprehensively learns 3D HOI affordances -- encompassing contact, orientation, and spatial occupancy -- using only synthetic data generated from 3D generative models. H2OFlow employs a dense 3D-flow-based representation, learned through a dense diffusion process operating on point clouds. This learned flow enables the discovery of rich 3D affordances without the need for human annotations. Through extensive quantitative and qualitative evaluations, we demonstrate that H2OFlow generalizes effectively to real-world objects and surpasses prior methods that rely on manual annotations or mesh-based representations in modeling 3D affordance.",
        "tags": [
            "3D",
            "Diffusion",
            "Robotics"
        ]
    },
    {
        "id": "19",
        "title": "Numerical Fragility in Transformers: A Layer-wise Theory for Explaining, Forecasting, and Mitigating Instability",
        "author": [
            "Jinwoo Baek"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21770",
        "abstract": "Transformers trained in low precision can suffer forward-error amplification. We give a first-order, module-wise theory that predicts when and where errors grow. For self-attention we derive a per-layer bound that factorizes into three interpretable diagnostics: a score-scale ratio $\\kappa_{\\rm score}$, a rowwise softmax sensitivity $\\kappa_{\\rm softmax}$, and value conditioning $\\kappa(V)$. We prove a residual relaxation inequality showing that residual blocks attenuate depth-wise accumulation, and we introduce a precision- and width-aware LayerNorm indicator $\\rho_{\\rm LN}$ with a matching first-order bound in the $\\epsilon$-dominated regime. These pieces yield a unified forward-stability bound whose right-hand side is directly estimable during training.\nOn Tiny-ViT/CIFAR-10 we evaluate the bound and components. (1) The combined predictor $\\kappa_{\\rm softmax},(1+\\kappa_{\\rm score}),\\kappa(V),|W_O|2+\\kappa{\\rm eff}+C_{\\rm LN}$ tracks FP32$\\leftrightarrow$LP mismatches across seeds, widths, and precisions; scaling by $\\epsilon_{\\rm mach}$ collapses mixed-precision points. (2) The time-series maximum of $\\kappa_{\\rm softmax}$ acts as an early-warning signal, leading error spikes by 16-24 steps (corr. 0.65-0.82; permutation $p!\\approx!10^{-3}$; Precision@K 0.89-1.00). (3) Guided by $\\rho_{\\rm LN}$, a small LayerNorm-$\\epsilon$ tweak targeting $\\rho_\\star$ gives consistent stabilization (mean tail-loss $\\downarrow\\ \\approx0.010$ at $\\rho_\\star!=!0.6$, cap$=10^{-2}$) with negligible overhead.\nOverall, our theory supplies actionable, unitless diagnostics that (i) explain when self-attention is fragile, (ii) forecast instability, and (iii) motivate a minimally invasive mitigation.",
        "tags": [
            "ViT"
        ]
    },
    {
        "id": "20",
        "title": "Improving the performance of AI-powered Affordable Robotics for Assistive Tasks",
        "author": [
            "Dharunish Yugeswardeenoo"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21771",
        "abstract": "By 2050, the global demand for assistive care is expected to reach 3.5 billion people, far outpacing the availability of human caregivers. Existing robotic solutions remain expensive and require technical expertise, limiting accessibility. This work introduces a low-cost robotic arm for assistive tasks such as feeding, cleaning spills, and fetching medicine. The system uses imitation learning from demonstration videos, requiring no task-specific programming or manual labeling. The robot consists of six servo motors, dual cameras, and 3D-printed grippers. Data collection via teleoperation with a leader arm yielded 50,000 video frames across the three tasks. A novel Phased Action Chunking Transformer (PACT) captures temporal dependencies and segments motion dynamics, while a Temporal Ensemble (TE) method refines trajectories to improve accuracy and smoothness. Evaluated across five model sizes and four architectures, with ten hours of real-world testing, the system achieved over 90% task accuracy, up to 40% higher than baselines. PACT enabled a 5x model size reduction while maintaining 75% accuracy. Saliency analysis showed reliance on key visual cues, and phase token gradients peaked at critical trajectory moments, indicating effective temporal reasoning. Future work will explore bimanual manipulation and mobility for expanded assistive capabilities.",
        "tags": [
            "3D",
            "Robotics",
            "Transformer"
        ]
    },
    {
        "id": "21",
        "title": "Real-Time QP Solvers: A Concise Review and Practical Guide Towards Legged Robots",
        "author": [
            "Van Nam Dinh"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21773",
        "abstract": "Quadratic programming (QP) underpins real-time robotics by enabling efficient, constrained optimization in state estimation, motion planning, and control. In legged locomotion and manipulation, essential modules like inverse dynamics, Model Predictive Control (MPC), and Whole-Body Control (WBC) are inherently QP-based, demanding reliable solutions amid tight timing, energy, and computational limits on embedded platforms. This paper presents a comprehensive analysis and benchmarking study of cutting-edge QP solvers for legged robotics. We begin by formulating the standard convex QP and classify solvers into four principal algorithmic approaches, including interior-point methods, active-set strategies, operator splitting schemes, and augmented Lagrangian approaches. Each solver is examined in terms of algorithmic structure, computational characteristics, and its ability to exploit problem structure and warm-starting. Performance is evaluated using publicly available benchmarks, focusing on metrics such as computation time, constraint satisfaction, and robustness under perturbations. Feature tables and comparisons yield practical guidance for solver selection, underscoring trade-offs in speed, accuracy, and energy efficiency. Our findings emphasize the synergy between solver, task, and hardware, sparse IPMs for long-horizon MPC, and dense active-set for high frequency WBC to advance agile, autonomous legged systems, with emerging extensions to nonconvex and distributed QP.",
        "tags": [
            "MPC",
            "Robotics"
        ]
    },
    {
        "id": "22",
        "title": "OCR-Quality: A Human-Annotated Dataset for OCR Quality Assessment",
        "author": [
            "Yulong Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21774",
        "abstract": "We present OCR-Quality, a comprehensive human-annotated dataset designed for evaluating and developing OCR quality assessment methods. The dataset consists of 1,000 PDF pages converted to PNG images at 300 DPI, sampled from diverse real-world scenarios, including academic papers, textbooks, e-books, and multilingual documents. Each document has been processed using state-of-the-art Vision-Language Models (VLMs) and manually annotated with quality scores using a 4-level scoring system (1: Excellent, 2: Good, 3: Fair, 4: Poor). The dataset includes detailed source information, annotation guidelines, and representative cases across various difficulty levels. OCR-Quality addresses the critical need for reliable OCR quality assessment in real-world applications and provides a valuable benchmark for training and evaluating OCR verification systems. The dataset is publicly available at https://huggingface.co/datasets/Aslan-mingye/OCR-Quality .",
        "tags": [
            "VLM"
        ]
    },
    {
        "id": "23",
        "title": "Face-MakeUpV2: Facial Consistency Learning for Controllable Text-to-Image Generation",
        "author": [
            "Dawei Dai",
            "Yinxiu Zhou",
            "Chenghang Li",
            "Guolai Jiang",
            "Chengfang Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21775",
        "abstract": "In facial image generation, current text-to-image models often suffer from facial attribute leakage and insufficient physical consistency when responding to local semantic instructions. In this study, we propose Face-MakeUpV2, a facial image generation model that aims to maintain the consistency of face ID and physical characteristics with the reference image. First, we constructed a large-scale dataset FaceCaptionMask-1M comprising approximately one million image-text-masks pairs that provide precise spatial supervision for the local semantic instructions. Second, we employed a general text-to-image pretrained model as the backbone and introduced two complementary facial information injection channels: a 3D facial rendering channel to incorporate the physical characteristics of the image and a global facial feature channel. Third, we formulated two optimization objectives for the supervised learning of our model: semantic alignment in the model's embedding space to mitigate the attribute leakage problem and perceptual loss on facial images to preserve ID consistency. Extensive experiments demonstrated that our Face-MakeUpV2 achieves best overall performance in terms of preserving face ID and maintaining physical consistency of the reference images. These results highlight the practical potential of Face-MakeUpV2 for reliable and controllable facial editing in diverse applications.",
        "tags": [
            "3D",
            "Text-to-Image"
        ]
    },
    {
        "id": "24",
        "title": "Promptable Fire Segmentation: Unleashing SAM2's Potential for Real-Time Mobile Deployment with Strategic Bounding Box Guidance",
        "author": [
            "Emmanuel U. Ugwu",
            "Zhang Xinming"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21782",
        "abstract": "Fire segmentation remains a critical challenge in computer vision due to flames' irregular boundaries, translucent edges, and highly variable intensities. While the Segment Anything Models (SAM and SAM2) have demonstrated impressive cross-domain generalization capabilities, their effectiveness in fire segmentation -- particularly under mobile deployment constraints -- remains largely unexplored. This paper presents the first comprehensive evaluation of SAM2 variants for fire segmentation, focusing on bounding box prompting strategies to enhance deployment feasibility. We systematically evaluate four SAM2.1 variants (tiny, small, base_plus, large) alongside mobile-oriented variants (TinySAM, MobileSAM) across three fire datasets using multiple prompting strategies: automatic, single positive point (SP), single positive point + single negative point (SP+SN), multiple positive points (MP), bounding box (Box), and hybrid variants (Box+SP and Box+MP). Our experimental results demonstrate that bounding box prompts consistently outperform automatic and single point-based approaches, with Box+MP achieving the highest mean IoU (0.64) and Dice coefficient (0.75) on the Khan dataset. Lightweight variants such as TinySAM and MobileSAM further reduce memory and computational costs, making them more suitable for latency-tolerant edge scenarios. Overall, this work provides critical insights for deploying promptable segmentation models in fire monitoring systems and establishes benchmarks for future research in domain-specific SAM applications. Code is available at: https://github.com/UEmmanuel5/ProFSAM",
        "tags": [
            "SAM",
            "Segmentation"
        ]
    },
    {
        "id": "25",
        "title": "Noise Aggregation Analysis Driven by Small-Noise Injection: Efficient Membership Inference for Diffusion Models",
        "author": [
            "Guo Li",
            "Yuyang Yu",
            "Xuemiao Xu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21783",
        "abstract": "Diffusion models have demonstrated powerful performance in generating high-quality images. A typical example is text-to-image generator like Stable Diffusion. However, their widespread use also poses potential privacy risks. A key concern is membership inference attacks, which attempt to determine whether a particular data sample was used in the model training process. We propose an efficient membership inference attack method against diffusion models. This method is based on the injection of slight noise and the evaluation of the aggregation degree of the noise distribution. The intuition is that the noise prediction patterns of diffusion models for training set samples and non-training set samples exhibit distinguishable http://differences.Specifically, we suppose that member images exhibit higher aggregation of predicted noise around a certain time step of the diffusion process. In contrast, the predicted noises of non-member images exhibit a more discrete characteristic around the certain time step. Compared with other existing methods, our proposed method requires fewer visits to the target diffusion model. We inject slight noise into the image under test and then determine its membership by analyzing the aggregation degree of the noise distribution predicted by the model. Empirical findings indicate that our method achieves superior performance across multiple datasets. At the same time, our method can also show better attack effects in ASR and AUC when facing large-scale text-to-image diffusion models, proving the scalability of our method.",
        "tags": [
            "Diffusion",
            "Text-to-Image"
        ]
    },
    {
        "id": "26",
        "title": "Multi-Agent Pose Uncertainty: A Differentiable Rendering CramÃ©r-Rao Bound",
        "author": [
            "Arun Muthukkumar"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21785",
        "abstract": "Pose estimation is essential for many applications within computer vision and robotics. Despite its uses, few works provide rigorous uncertainty quantification for poses under dense or learned models. We derive a closed-form lower bound on the covariance of camera pose estimates by treating a differentiable renderer as a measurement function. Linearizing image formation with respect to a small pose perturbation on the manifold yields a render-aware CramÃ©r-Rao bound. Our approach reduces to classical bundle-adjustment uncertainty, ensuring continuity with vision theory. It also naturally extends to multi-agent settings by fusing Fisher information across cameras. Our statistical formulation has downstream applications for tasks such as cooperative perception and novel view synthesis without requiring explicit keypoint correspondences.",
        "tags": [
            "Pose Estimation",
            "Robotics"
        ]
    },
    {
        "id": "27",
        "title": "EventFormer: A Node-graph Hierarchical Attention Transformer for Action-centric Video Event Prediction",
        "author": [
            "Qile Su",
            "Shoutai Zhu",
            "Shuai Zhang",
            "Baoyu Liang",
            "Chao Tong"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21786",
        "abstract": "Script event induction, which aims to predict the subsequent event based on the context, is a challenging task in NLP, achieving remarkable success in practical applications. However, human events are mostly recorded and presented in the form of videos rather than scripts, yet there is a lack of related research in the realm of vision. To address this problem, we introduce AVEP (Action-centric Video Event Prediction), a task that distinguishes itself from existing video prediction tasks through its incorporation of more complex logic and richer semantic information. We present a large structured dataset, which consists of about $35K$ annotated videos and more than $178K$ video clips of event, built upon existing video event datasets to support this task. The dataset offers more fine-grained annotations, where the atomic unit is represented as a multimodal event argument node, providing better structured representations of video events. Due to the complexity of event structures, traditional visual models that take patches or frames as input are not well-suited for AVEP. We propose EventFormer, a node-graph hierarchical attention based video event prediction model, which can capture both the relationships between events and their arguments and the coreferencial relationships between arguments. We conducted experiments using several SOTA video prediction models as well as LVLMs on AVEP, demonstrating both the complexity of the task and the value of the dataset. Our approach outperforms all these video prediction models. We will release the dataset and code for replicating the experiments and annotations.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "28",
        "title": "Online Mixture of Experts: No-Regret Learning for Optimal Collective Decision-Making",
        "author": [
            "Larkin Liu",
            "Jalal Etesami"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21788",
        "abstract": "We explore the use of expert-guided bandit learning, which we refer to as online mixture-of-experts (OMoE). In this setting, given a context, a candidate committee of experts must determine how to aggregate their outputs to achieve optimal results in terms of aggregate accuracy. We propose two algorithms to address this problem. The first algorithm combines aggregate voting with UCB-driven successive elimination, efficiently pruning suboptimal exploration actions. The second algorithm employs an online weighted-majority-voting mechanism, leveraging the respective voting power of each expert proportional to their predictive power. We derive theoretical guarantees for the regret properties in the bandit setting under ideal circumstances, and empirical results are provided accordingly. As a modern study on applications, these methods are applied to the online fine-tuning of a set of expert large language models (LLMs), where after each response, the generative LLM dynamically reweighs its set of experts and/or selects the optimal committee of experts to generate the most accurate response. Our results introduce new methodologies and no-regret guarantees for combining multiple experts to improve on the performance of the an aggregate model overall.",
        "tags": [
            "LLM",
            "MoE"
        ]
    },
    {
        "id": "29",
        "title": "Variance-Reduction Guidance: Sampling Trajectory Optimization for Diffusion Models",
        "author": [
            "Shifeng Xu",
            "Yanzhu Liu",
            "Adams Wai-Kin Kong"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21792",
        "abstract": "Diffusion models have become emerging generative models. Their sampling process involves multiple steps, and in each step the models predict the noise from a noisy sample. When the models make prediction, the output deviates from the ground truth, and we call such a deviation as \\textit{prediction error}. The prediction error accumulates over the sampling process and deteriorates generation quality. This paper introduces a novel technique for statistically measuring the prediction error and proposes the Variance-Reduction Guidance (VRG) method to mitigate this error. VRG does not require model fine-tuning or modification. Given a predefined sampling trajectory, it searches for a new trajectory which has the same number of sampling steps but produces higher quality results. VRG is applicable to both conditional and unconditional generation. Experiments on various datasets and baselines demonstrate that VRG can significantly improve the generation quality of diffusion models. Source code is available at https://github.com/shifengxu/VRG.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "30",
        "title": "Token-Level Inference-Time Alignment for Vision-Language Models",
        "author": [
            "Kejia Chen",
            "Jiawen Zhang",
            "Jiacong Hu",
            "Kewei Gao",
            "Jian Lou",
            "Zunlei Feng",
            "Mingli Song"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21794",
        "abstract": "Vision-Language Models (VLMs) have become essential backbones of modern multimodal intelligence, yet their outputs remain prone to hallucination-plausible text misaligned with visual inputs. Existing alignment approaches often rely on expensive fine-tuning with annotated preference data or sequence-level inference strategies that provide only coarse, delayed feedback. To overcome these limitations, we present TITA (Token-level Inference-Time Alignment), a lightweight framework that freezes the base VLM and instead trains a reward model to approximate its distribution. During inference, implicit preference signals are extracted as log-probability ratios between the reward model and the target VLM, yielding dense autoregressive feedback. This formulation can be viewed as an inference-time variant of Direct Preference Optimization (DPO), providing token-level corrective signals without retraining the backbone. Extensive evaluations on LLaVA-1.5-7B and 13B show consistent gains across 12 benchmarks, with improvements of 8.6% on MMVet and 6.7% on POPE, indicating stronger general understanding and reduced hallucinations. Additional experiments on Qwen2.5-VL-7B and DeepSeek-VL2-27.5B show comparable gains, especially in hallucination reduction and VQA accuracy, while incurring negligible inference overhead.",
        "tags": [
            "DPO",
            "DeepSeek",
            "LLaVA",
            "VLM"
        ]
    },
    {
        "id": "31",
        "title": "MARS-M: When Variance Reduction Meets Matrices",
        "author": [
            "Yifeng Liu",
            "Angela Yuan",
            "Quanquan Gu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21800",
        "abstract": "Matrix-based preconditioned optimizers, such as Muon, have recently been shown to be more efficient than scalar-based optimizers for training large-scale neural networks, including large language models (LLMs). On the other hand, recent benchmarks on optimizers for LLM pre-training have demonstrated that variance-reduction techniques such as MARS can achieve substantial speedups over standard optimizers that do not employ variance reduction. In this paper, to achieve the best of both worlds, we introduce MARS-M, a new optimizer that integrates the variance reduction technique in MARS with Muon. Under standard regularity conditions, we prove that Muon-M converges to a first-order stationary point at a rate of $\\tilde{\\mathcal{O}}(T^{-1/3})$, which improves upon $\\tilde{\\mathcal{O}}(T^{-1/4})$ rate attained by Muon. Our empirical results on language modeling and computer vision tasks demonstrate that MARS-M consistently yields lower losses and improved performance across various downstream benchmarks. The implementation of MARS-M is available at https://github.com/AGI-Arena/MARS/MARS_M.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "32",
        "title": "Morphology-Aware KOA Classification: Integrating Graph Priors with Vision Models",
        "author": [
            "Marouane Tliba",
            "Mohamed Amine Kerkouri",
            "Yassine Nasser",
            "Nour Aburaed",
            "Aladine Chetouani",
            "Ulas Bagci",
            "Rachid Jennane"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21801",
        "abstract": "Knee osteoarthritis (KOA) diagnosis from radiographs remains challenging due to the subtle morphological details that standard deep learning models struggle to capture effectively. We propose a novel multimodal framework that combines anatomical structure with radiographic features by integrating a morphological graph representation - derived from Segment Anything Model (SAM) segmentations - with a vision encoder. Our approach enforces alignment between geometry-informed graph embeddings and radiographic features through mutual information maximization, significantly improving KOA classification accuracy. By constructing graphs from anatomical features, we introduce explicit morphological priors that mirror clinical assessment criteria, enriching the feature space and enhancing the model's inductive bias. Experiments on the Osteoarthritis Initiative dataset demonstrate that our approach surpasses single-modality baselines by up to 10\\% in accuracy (reaching nearly 80\\%), while outperforming existing state-of-the-art methods by 8\\% in accuracy and 11\\% in F1 score. These results underscore the critical importance of incorporating anatomical structure into radiographic analysis for accurate KOA severity grading.",
        "tags": [
            "SAM"
        ]
    },
    {
        "id": "33",
        "title": "It Takes Two to Tango: Two Parallel Samplers Improve Quality in Diffusion Models for Limited Steps",
        "author": [
            "Pedro Cisneros-Velarde"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21802",
        "abstract": "We consider the situation where we have a limited number of denoising steps, i.e., of evaluations of a diffusion model. We show that two parallel processors or samplers under such limitation can improve the quality of the sampled image. Particularly, the two samplers make denoising steps at successive times, and their information is appropriately integrated in the latent image. Remarkably, our method is simple both conceptually and to implement: it is plug-&-play, model agnostic, and does not require any additional fine-tuning or external models. We test our method with both automated and human evaluations for different diffusion models. We also show that a naive integration of the information from the two samplers lowers sample quality. Finally, we find that adding more parallel samplers does not necessarily improve sample quality.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "34",
        "title": "Activating Visual Context and Commonsense Reasoning through Masked Prediction in VLMs",
        "author": [
            "Jiaao Yu",
            "Shenwei Li",
            "Mingjie Han",
            "Yifei Yin",
            "Wenzheng Song",
            "Chenghao Jia",
            "Man Lan"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21807",
        "abstract": "Recent breakthroughs in reasoning models have markedly advanced the reasoning capabilities of large language models, particularly via training on tasks with verifiable rewards. Yet, a significant gap persists in their adaptation to real world multimodal scenarios, most notably, vision language tasks, due to a heavy focus on single modal language settings. While efforts to transplant reinforcement learning techniques from NLP to VLMs have emerged, these approaches often remain confined to perception centric tasks or reduce images to textual summaries, failing to fully exploit visual context and commonsense knowledge, ultimately constraining the generalization of reasoning capabilities across diverse multimodal environments. To address this limitation, we introduce a novel fine tuning task, Masked Prediction via Context and Commonsense, which forces models to integrate visual context and commonsense reasoning by reconstructing semantically meaningful content from occluded images, thereby laying the foundation for generalized reasoning. To systematically evaluate the model performance in generalized reasoning, we developed a specialized evaluation benchmark, MPCC Eval, and employed various fine tuning strategies to guide reasoning. Among these, we introduced an innovative training method, Reinforcement Fine tuning with Prior Sampling, which not only enhances model performance but also improves its generalized reasoning capabilities in OOD and cross task scenarios.",
        "tags": [
            "LLM",
            "RL",
            "VLM"
        ]
    },
    {
        "id": "35",
        "title": "Semantic Relation-Enhanced CLIP Adapter for Domain Adaptive Zero-Shot Learning",
        "author": [
            "Jiaao Yu",
            "Mingjie Han",
            "Jinkun Jiang",
            "Junyu Dong",
            "Tao Gong",
            "Man Lan"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21808",
        "abstract": "The high cost of data annotation has spurred research on training deep learning models in data-limited scenarios. Existing paradigms, however, fail to balance cross-domain transfer and cross-category generalization, giving rise to the demand for Domain-Adaptive Zero-Shot Learning (DAZSL). Although vision-language models (e.g., CLIP) have inherent advantages in the DAZSL field, current studies do not fully exploit their potential. Applying CLIP to DAZSL faces two core challenges: inefficient cross-category knowledge transfer due to the lack of semantic relation guidance, and degraded cross-modal alignment during target domain fine-tuning. To address these issues, we propose a Semantic Relation-Enhanced CLIP (SRE-CLIP) Adapter framework, integrating a Semantic Relation Structure Loss and a Cross-Modal Alignment Retention Strategy. As the first CLIP-based DAZSL method, SRE-CLIP achieves state-of-the-art performance on the I2AwA and I2WebV benchmarks, significantly outperforming existing approaches.",
        "tags": [
            "CLIP",
            "VLM"
        ]
    },
    {
        "id": "36",
        "title": "Embodied Navigation with Auxiliary Task of Action Description Prediction",
        "author": [
            "Haru Kondoh",
            "Asako Kanezaki"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21809",
        "abstract": "The field of multimodal robot navigation in indoor environments has garnered significant attention in recent years. However, as tasks and methods become more advanced, the action decision systems tend to become more complex and operate as black-boxes. For a reliable system, the ability to explain or describe its decisions is crucial; however, there tends to be a trade-off in that explainable systems can not outperform non-explainable systems in terms of performance. In this paper, we propose incorporating the task of describing actions in language into the reinforcement learning of navigation as an auxiliary task. Existing studies have found it difficult to incorporate describing actions into reinforcement learning due to the absence of ground-truth data. We address this issue by leveraging knowledge distillation from pre-trained description generation models, such as vision-language models. We comprehensively evaluate our approach across various navigation tasks, demonstrating that it can describe actions while attaining high navigation performance. Furthermore, it achieves state-of-the-art performance in the particularly challenging multimodal navigation task of semantic audio-visual navigation.",
        "tags": [
            "RL",
            "Robotics",
            "VLM"
        ]
    },
    {
        "id": "37",
        "title": "SITS-DECO: A Generative Decoder Is All You Need For Multitask Satellite Image Time Series Modelling",
        "author": [
            "Samuel J. Barrett",
            "Docko Sow"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21813",
        "abstract": "Earth Observation (EO) Foundation Modelling (FM) holds great promise for simplifying and improving the use of EO data for diverse real-world tasks. However, most existing models require additional adaptation before they can be used and are structured rigidly around particular data sources or training approaches. To address this, we take inspiration from large language models, where diverse tasks, both pre-training and downstream, are implicitly captured through next-token prediction over unified token sequences, leveraging the structure and diversity of the training data.\nWe introduce SITS-DECO (Satellite Image Time Series-DECoder Only), a proof-of-concept generative model that applies this unified-sequence framing to EO data. Using a simple GPT-style decoder-only architecture, and demonstrate its ability to perform useful EO tasks (pixel-wise, multi-temporal, multi-modal crop-type classification) in a purely generative framework. Through symbolic prompting, we show that the model can perform multiple supervised and self-supervised tasks within a single unified architecture, without task- or modality-specific adaptation. Despite its simplicity and lack of spatial context, SITS-DECO outperforms much larger EO foundation models on crop-type classification (PASTIS-R) demonstrating that dense temporal sequence modelling is a critical missing ingredient in the current paradigm.\nThis work exemplifies a data-centric modelling paradigm in which capability arises from the diversity and structure of the training data rather than from architectural complexity. SITS-DECO provides a lightweight, practical route to multi-modal, multi-task EO modelling, and a conceptual bridge toward future generative EO foundation models.",
        "tags": [
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "38",
        "title": "Gestura: A LVLM-Powered System Bridging Motion and Semantics for Real-Time Free-Form Gesture Understanding",
        "author": [
            "Zhuoming Li",
            "Aitong Liu",
            "Mengxi Jia",
            "Tengxiang Zhang",
            "Dell Zhang",
            "Xuelong Li"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21814",
        "abstract": "Free-form gesture understanding is highly appealing for human-computer interaction, as it liberates users from the constraints of predefined gesture categories. However, the sole existing solution GestureGPT suffers from limited recognition accuracy and slow response times. In this paper, we propose Gestura, an end-to-end system for free-form gesture understanding. Gestura harnesses a pre-trained Large Vision-Language Model (LVLM) to align the highly dynamic and diverse patterns of free-form gestures with high-level semantic concepts. To better capture subtle hand movements across different styles, we introduce a Landmark Processing Module that compensate for LVLMs' lack of fine-grained domain knowledge by embedding anatomical hand priors. Further, a Chain-of-Thought (CoT) reasoning strategy enables step-by-step semantic inference, transforming shallow knowledge into deep semantic understanding and significantly enhancing the model's ability to interpret ambiguous or unconventional gestures. Together, these components allow Gestura to achieve robust and adaptable free-form gesture comprehension. Additionally, we have developed the first open-source dataset for free-form gesture intention reasoning and understanding with over 300,000 annotated QA pairs.",
        "tags": [
            "CoT"
        ]
    },
    {
        "id": "39",
        "title": "VITA-E: Natural Embodied Interaction with Concurrent Seeing, Hearing, Speaking, and Acting",
        "author": [
            "Xiaoyu Liu",
            "Chaoyou Fu",
            "Chi Yan",
            "Chu Wu",
            "Haihan Gao",
            "Yi-Fan Zhang",
            "Shaoqi Dong",
            "Cheng Qian",
            "Bin Luo",
            "Xiuyong Yang",
            "Guanwu Li",
            "Yusheng Cai",
            "Yunhang Shen",
            "Deqiang Jiang",
            "Haoyu Cao",
            "Xing Sun",
            "Caifeng Shan",
            "Ran He"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21817",
        "abstract": "Current Vision-Language-Action (VLA) models are often constrained by a rigid, static interaction paradigm, which lacks the ability to see, hear, speak, and act concurrently as well as handle real-time user interruptions dynamically. This hinders seamless embodied collaboration, resulting in an inflexible and unresponsive user experience. To address these limitations, we introduce VITA-E, a novel embodied interaction framework designed for both behavioral concurrency and nearly real-time interruption. The core of our approach is a dual-model architecture where two parallel VLA instances operate as an ``Active Model'' and a ``Standby Model'', allowing the embodied agent to observe its environment, listen to user speech, provide verbal responses, and execute actions, all concurrently and interruptibly, mimicking human-like multitasking capabilities. We further propose a ``model-as-controller'' paradigm, where we fine-tune the VLM to generate special tokens that serve as direct system-level commands, coupling the model's reasoning with the system's behavior. Experiments conducted on a physical humanoid platform demonstrate that VITA-E can reliably handle complex interactive scenarios. Our framework is compatible with various dual-system VLA models, achieving an extremely high success rate on emergency stops and speech interruptions while also successfully performing concurrent speech and action. This represents a significant step towards more natural and capable embodied assistants.",
        "tags": [
            "VLM"
        ]
    },
    {
        "id": "40",
        "title": "Prompt fidelity of ChatGPT4o / Dall-E3 text-to-image visualisations",
        "author": [
            "Dirk HR Spennemann"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21821",
        "abstract": "This study examines the prompt fidelity of ChatGPT4o / DALL-E3 text-to-image visualisations by analysing whether attributes explicitly specified in autogenously generated prompts are correctly rendered in the resulting images. Using two public-domain datasets comprising 200 visualisations of women working in the cultural and creative industries and 230 visualisations of museum curators, the study assessed accuracy across personal attributes (age, hair), appearance (attire, glasses), and paraphernalia (name tags, clipboards). While correctly rendered in most cases, DALL-E3 deviated from prompt specifications in 15.6% of all attributes (n=710). Errors were lowest for paraphernalia, moderate for personal appearance, and highest for depictions of the person themselves, particularly age. These findings demonstrate measurable prompt-to-image fidelity gaps with implications for bias detection and model evaluation.",
        "tags": [
            "Detection",
            "Text-to-Image"
        ]
    },
    {
        "id": "41",
        "title": "Wavelet-based GAN Fingerprint Detection using ResNet50",
        "author": [
            "Sai Teja Erukude",
            "Suhasnadh Reddy Veluru",
            "Viswa Chaitanya Marella"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21822",
        "abstract": "Identifying images generated by Generative Adversarial Networks (GANs) has become a significant challenge in digital image forensics. This research presents a wavelet-based detection method that uses discrete wavelet transform (DWT) preprocessing and a ResNet50 classification layer to differentiate the StyleGAN-generated images from real ones. Haar and Daubechies wavelet filters are applied to convert the input images into multi-resolution representations, which will then be fed to a ResNet50 network for classification, capitalizing on subtle artifacts left by the generative process. Moreover, the wavelet-based models are compared to an identical ResNet50 model trained on spatial data. The Haar and Daubechies preprocessed models achieved a greater accuracy of 93.8 percent and 95.1 percent, much higher than the model developed in the spatial domain (accuracy rate of 81.5 percent). The Daubechies-based model outperforms Haar, showing that adding layers of descriptive frequency patterns can lead to even greater distinguishing power. These results indicate that the GAN-generated images have unique wavelet-domain artifacts or \"fingerprints.\" The method proposed illustrates the effectiveness of wavelet-domain analysis to detect GAN images and emphasizes the potential of further developing the capabilities of future deepfake detection systems.",
        "tags": [
            "Detection",
            "GAN",
            "StyleGAN"
        ]
    },
    {
        "id": "42",
        "title": "Structured and Abstractive Reasoning on Multi-modal Relational Knowledge Images",
        "author": [
            "Yichi Zhang",
            "Zhuo Chen",
            "Lingbing Guo",
            "Lei Liang",
            "Wen Zhang",
            "Huajun Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21828",
        "abstract": "Understanding and reasoning with abstractive information from the visual modality presents significant challenges for current multi-modal large language models (MLLMs). Among the various forms of abstractive information, Multi-Modal Relational Knowledge (MMRK), which represents abstract relational structures between multi-modal entities using node-edge formats, remains largely under-explored. In particular, STructured and Abstractive Reasoning (STAR) on such data has received little attention from the research community. To bridge the dual gaps in large-scale high-quality data and capability enhancement methodologies, this paper makes the following key contributions: (i). An automatic STAR data engine capable of synthesizing images with MMRK to build multi-modal instruction data with reliable chain-of-thought thinking for various STAR tasks and (ii). A comprehsive two-stage capability enhancement training framework, accompanied by a suite of evaluation protocols tailored to different STAR tasks. Based upon these contributions, we introduce STAR-64K, a dataset comprising 64K high-quality multi-modal instruction samples, and conduct experiments across 5 open-source MLLMs. Experimental results show that our two-stage enhancement framework enables smaller 3B/7B models to significantly outperform GPT-4o in STAR. Additionally, we provide in-depth analysis regarding the effectiveness of various designs, data transferability, and scalability.",
        "tags": [
            "CoT",
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "43",
        "title": "GAPO: Group Adaptive Policy Optimization for Real-World Code Edit",
        "author": [
            "Jianqing Zhang",
            "Zhezheng Hao",
            "Wei Xia",
            "Hande Dong",
            "Hong Wang",
            "Chenxing Wei",
            "Yuyan Zhou",
            "Yubin Qi",
            "Qiang Lin",
            "Jian Cao"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21830",
        "abstract": "Reinforcement learning (RL) is widely used for post-training large language models (LLMs) in code editing, where group-relative methods like GRPO are popular for their critic-free, normalized advantage estimation. However, in real-world code-editing scenarios, reward distributions are often skewed with unpredictable outliers, leading to distorted advantage computation and increased noise. To address this issue, we propose Group Adaptive Policy Optimization (GAPO), which adaptively finds an outlier-free highest-density interval (HDI) per prompt and then uses the median of that interval as an adaptive Q to replace the group mean in advantage calculation. This adaptive Q robustly handles skewed distributions while remaining plug-and-play and efficient. We validate GAPO on nine instruction-tuned LLMs (3B-14B) using a large internal dataset of 51,844 real-world, history-aware code-editing tasks across 10 languages, demonstrating consistent improvements in exact match accuracy over GRPO and its variant DAPO. Code is publicly available.",
        "tags": [
            "GRPO",
            "LLM",
            "RL"
        ]
    },
    {
        "id": "44",
        "title": "Restoring Pruned Large Language Models via Lost Component Compensation",
        "author": [
            "Zijian Feng",
            "Hanzhang Zhou",
            "Zixiao Zhu",
            "Tianjiao Li",
            "Jia Jim Deryl Chua",
            "Lee Onn Mak",
            "Gee Wah Ng",
            "Kezhi Mao"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21834",
        "abstract": "Pruning is a widely used technique to reduce the size and inference cost of large language models (LLMs), but it often causes performance degradation. To mitigate this, existing restoration methods typically employ parameter-efficient fine-tuning (PEFT), such as LoRA, to recover the pruned model's performance. However, most PEFT methods are designed for dense models and overlook the distinct properties of pruned models, often resulting in suboptimal recovery. In this work, we propose a targeted restoration strategy for pruned models that restores performance while preserving their low cost and high efficiency. We observe that pruning-induced information loss is reflected in attention activations, and selectively reintroducing components of this information can significantly recover model performance. Based on this insight, we introduce RestoreLCC (Restoring Pruned LLMs via Lost Component Compensation), a plug-and-play method that contrastively probes critical attention heads via activation editing, extracts lost components from activation differences, and finally injects them back into the corresponding pruned heads for compensation and recovery. RestoreLCC is compatible with structured, semi-structured, and unstructured pruning schemes. Extensive experiments demonstrate that RestoreLCC consistently outperforms state-of-the-art baselines in both general and task-specific performance recovery, without compromising the sparsity or inference efficiency of pruned models.",
        "tags": [
            "LLM",
            "LoRA"
        ]
    },
    {
        "id": "45",
        "title": "A Multimodal, Multitask System for Generating E Commerce Text Listings from Images",
        "author": [
            "Nayan Kumar Singh"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21835",
        "abstract": "Manually generating catchy descriptions and names is labor intensive and a slow process for retailers. Although generative AI provides an automation solution in form of Vision to Language Models (VLM), the current VLMs are prone to factual \"hallucinations\". Siloed, single task models are not only inefficient but also fail to capture interdependent relationships between features. To address these challenges, we propose an end to end, multi task system that generates factually grounded textual listings from a single image. The contributions of this study are two proposals for the model architecture. First, application of multi task learning approach for fine tuning a vision encoder where a single vision backbone is jointly trained on attribute prediction such as color, hemline and neck style and price regression. Second, introduction of a hierarchical generation process where the model's own predicted attributes are embedded in a prompt and fed to the text decoder to improve factual consistency. The experiments demonstrate the superiority of this architecture. The multi tasking approach outperforms both the independent price regression, with a 3.6% better R2 Value and attribute classification, with a 6.6% improvement F1 score. Critically, the hierarchical generation process proves highly effective, slashing the factual hallucination rate from 12.7% to 7.1%, a 44.5% relative reduction, compared to a non hierarchical ablation. The hierarchical approach also reduces the latency of the autoregressive text generation process by a factor of 3.5 when compared to direct vision to language model of similar size. One minor caveat is that the model does perform 3.5% worse than direct vision-to-language model on ROUGE-L score.",
        "tags": [
            "VLM"
        ]
    },
    {
        "id": "46",
        "title": "COLA: Continual Learning via Autoencoder Retrieval of Adapters",
        "author": [
            "Jaya Krishna Mandivarapu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21836",
        "abstract": "Learning a set of tasks over time, also known as continual learning (CL), is one of the most challenging problems in artificial intelligence due to catastrophic forgetting. Large language models (LLMs) are often impractical to frequent re-training and continual learning , due to high cost of computational resources for training. Moreover, LLM are not suitable for continual learning as updating these models over time for acquiring new knowledge leads to overwrites existing knowledge leading to common phenomenon know as \\textit{catastrophic forgetting}. In this paper, we aim to address these concerns using a novel framework , COLA that employs an autoencoder to learn capture low-dimensional embeddings of the weights associated with various tasks. Our approach facilitates the transfer of knowledge to new tasks while preventing catastrophic forgetting, all without using data replay or a substantial set of task-specific parameters. Our approach, COLA, makes the LLM efficiently learn new tasks with minimal training, insignificant performance degradation on previous tasks, and eliminates the need for retaining earlier training data. Empirical evaluation on different datasets ranging from task oriented dialouge system to intent classsfication datasets showcases that our method not only overcomes catastrophic forgetting but also achieves significant reduction in parameter usage and memory size, across multiple tasks and outperforming the existing state of the art methods across multiple datasets.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "47",
        "title": "Improving the Physics of Video Generation with VJEPA-2 Reward Signal",
        "author": [
            "Jianhao Yuan",
            "Xiaofeng Zhang",
            "Felix Friedrich",
            "Nicolas Beltran-Velez",
            "Melissa Hall",
            "Reyhane Askari-Hemmat",
            "Xiaochuang Han",
            "Nicolas Ballas",
            "Michal Drozdzal",
            "Adriana Romero-Soriano"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21840",
        "abstract": "This is a short technical report describing the winning entry of the PhysicsIQ Challenge, presented at the Perception Test Workshop at ICCV 2025. State-of-the-art video generative models exhibit severely limited physical understanding, and often produce implausible videos. The Physics IQ benchmark has shown that visual realism does not imply physics understanding. Yet, intuitive physics understanding has shown to emerge from SSL pretraining on natural videos. In this report, we investigate whether we can leverage SSL-based video world models to improve the physics plausibility of video generative models. In particular, we build ontop of the state-of-the-art video generative model MAGI-1 and couple it with the recently introduced Video Joint Embedding Predictive Architecture 2 (VJEPA-2) to guide the generation process. We show that by leveraging VJEPA-2 as reward signal, we can improve the physics plausibility of state-of-the-art video generative models by ~6%.",
        "tags": [
            "Video Generation"
        ]
    },
    {
        "id": "48",
        "title": "RatioWaveNet: A Learnable RDWT Front-End for Robust and Interpretable EEG Motor-Imagery Classification",
        "author": [
            "Marco Siino",
            "Giuseppe Bonomo",
            "Rosario Sorbello",
            "Ilenia Tinnirello"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21841",
        "abstract": "Brain-computer interfaces (BCIs) based on motor imagery (MI) translate covert movement intentions into actionable commands, yet reliable decoding from non-invasive EEG remains challenging due to nonstationarity, low SNR, and subject variability. We present RatioWaveNet, which augments a strong temporal CNN-Transformer backbone (TCFormer) with a trainable, Rationally-Dilated Wavelet Transform (RDWT) front end. The RDWT performs an undecimated, multi-resolution subband decomposition that preserves temporal length and shift-invariance, enhancing sensorimotor rhythms while mitigating jitter and mild artifacts; subbands are fused via lightweight grouped 1-D convolutions and passed to a multi-kernel CNN for local temporal-spatial feature extraction, a grouped-query attention encoder for long-range context, and a compact TCN head for causal temporal integration.\nOur goal is to test whether this principled wavelet front end improves robustness precisely where BCIs typically fail - on the hardest subjects - and whether such gains persist on average across seeds under both intra- and inter-subject protocols. On BCI-IV-2a and BCI-IV-2b, across five seeds, RatioWaveNet improves worst-subject accuracy over the Transformer backbone by +0.17 / +0.42 percentage points (Sub-Dependent / LOSO) on 2a and by +1.07 / +2.54 percentage points on 2b, with consistent average-case gains and modest computational overhead. These results indicate that a simple, trainable wavelet front end is an effective plug-in to strengthen Transformer-based BCIs, improving worst-case reliability without sacrificing efficiency.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "49",
        "title": "KARIPAP: Quantum-Inspired Tensor Network Compression of Large Language Models Using Infinite Projected Entangled Pair States and Tensor Renormalization Group",
        "author": [
            "Azree Nazri"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21844",
        "abstract": "Large Language Models (LLMs) like ChatGPT and LLaMA drive rapid progress in generative AI, yet their huge parameter scales create severe computational and environmental burdens. High training costs, energy use, and limited device deployment hinder accessibility. Existing compression - pruning, distillation, low-rank, and quantization - reduces size but ignores complex inter-layer correlations. We propose KARIPAP, a quantum-inspired tensor network compression using Infinite Projected Entangled Pair States (iPEPS) and Tensor Renormalization Group (TRG) contraction. Unlike 1D Matrix Product States, iPEPS captures multi-directional entanglement in attention and deep transformer layers. TRG ensures polynomial-time contraction, making tensorization feasible while preserving key correlation geometry. Experiments on LLaMA-2 7B show up to 93% memory and 70% parameter reduction, with 50% faster training, 25% faster inference, and only 2-3% accuracy loss. Layer-wise entanglement profiling reveals redundancy in deeper layers, confirming their suitability for tensor factorization. KARIPAP demonstrates that modern LLMs occupy low-dimensional entanglement manifolds, enabling scalable, energy-efficient, and quantum-aware AI architectures.",
        "tags": [
            "GPT",
            "LLM",
            "LLaMA",
            "Transformer"
        ]
    },
    {
        "id": "50",
        "title": "SynCast: Synergizing Contradictions in Precipitation Nowcasting via Diffusion Sequential Preference Optimization",
        "author": [
            "Kaiyi Xu",
            "Junchao Gong",
            "Wenlong Zhang",
            "Ben Fei",
            "Lei Bai",
            "Wanli Ouyang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21847",
        "abstract": "Precipitation nowcasting based on radar echoes plays a crucial role in monitoring extreme weather and supporting disaster prevention. Although deep learning approaches have achieved significant progress, they still face notable limitations. For example, deterministic models tend to produce over-smoothed predictions, which struggle to capture extreme events and fine-scale precipitation patterns. Probabilistic generative models, due to their inherent randomness, often show fluctuating performance across different metrics and rarely achieve consistently optimal results. Furthermore, precipitation nowcasting is typically evaluated using multiple metrics, some of which are inherently conflicting. For instance, there is often a trade-off between the Critical Success Index (CSI) and the False Alarm Ratio (FAR), making it challenging for existing models to deliver forecasts that perform well on both metrics simultaneously. To address these challenges, we introduce preference optimization into precipitation nowcasting for the first time, motivated by the success of reinforcement learning from human feedback in large language models. Specifically, we propose SynCast, a method that employs the two-stage post-training framework of Diffusion Sequential Preference Optimization (Diffusion-SPO), to progressively align conflicting metrics and consistently achieve superior performance. In the first stage, the framework focuses on reducing FAR, training the model to effectively suppress false alarms. Building on this foundation, the second stage further optimizes CSI with constraints that preserve FAR alignment, thereby achieving synergistic improvements across these conflicting metrics.",
        "tags": [
            "Diffusion",
            "LLM",
            "RL",
            "RLHF"
        ]
    },
    {
        "id": "51",
        "title": "TowerVision: Understanding and Improving Multilinguality in Vision-Language Models",
        "author": [
            "AndrÃ© G. Viveiros",
            "Patrick Fernandes",
            "Saul Santos",
            "Sonal Sannigrahi",
            "Emmanouil Zaranis",
            "Nuno M. Guerreiro",
            "Amin Farajian",
            "Pierre Colombo",
            "Graham Neubig",
            "AndrÃ© F. T. Martins"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21849",
        "abstract": "Despite significant advances in vision-language models (VLMs), most existing work follows an English-centric design process, limiting their effectiveness in multilingual settings. In this work, we provide a comprehensive empirical study analyzing the impact of several multilingual design choices, such as training data composition, encoder selection, and text backbones. The result is TowerVision, a family of open multilingual VLMs for both image-text and video-text tasks, built upon the multilingual text-only model Tower+. TowerVision achieves competitive performance on multiple multimodal multilingual benchmarks and shows particular strength in culturally grounded tasks and multimodal translation. By incorporating visual and cultural context during fine-tuning, our models surpass existing approaches trained on substantially larger datasets, as demonstrated on ALM-Bench and Multi30K (image tasks) and ViMUL-Bench (video tasks). Alongside the models, we release VisionBlocks, a high-quality, curated vision-language dataset. Our findings highlight that multilingual vision-language training data substantially improves cross-lingual generalization -- both from high-resource to underrepresented languages and vice versa -- and that instruction-tuned LLMs are not always the optimal initialization point. To support further research, we publicly release all models, data, and training recipes.",
        "tags": [
            "LLM",
            "VLM"
        ]
    },
    {
        "id": "52",
        "title": "SCoPE VLM: Selective Context Processing for Efficient Document Navigation in Vision-Language Models",
        "author": [
            "Gyubeum Lim",
            "Yemo Koo",
            "Vijay Krishna Madisetti"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21850",
        "abstract": "Understanding long-context visual information remains a fundamental challenge for vision-language models, particularly in agentic tasks such as GUI control and web navigation. While web pages and GUI environments are inherently structured documents, current VLMs typically neglect decision-oriented document understanding in their training objectives. Existing approaches primarily extend visual embeddings to process long, high-resolution inputs, but these methods are memory-intensive and impractical for locally deployable solutions. To address these issues, we propose SCoPE VLM, a document navigation expert that leverages a novel Chain of Scroll mechanism to selectively and recursively navigate documents, focusing exclusively on relevant segments. We introduce a dedicated data generation pipeline to construct informative Chain of Scroll trajectories and Episodic Group Relative Policy Optimization, a tailored reinforcement learning method to reduce the gap between training and inference. Our method substantially reduces memory usage and effectively models human-like reading behaviors. To the best of our knowledge, SCoPE VLM is the first framework to explicitly model agentic reading patterns in multi-page document question answering, advancing the capabilities of multimodal agents.",
        "tags": [
            "RL",
            "VLM"
        ]
    },
    {
        "id": "53",
        "title": "Policy Optimization Prefers The Path of Least Resistance",
        "author": [
            "Debdeep Sanyal",
            "Aakash Sen Sharma",
            "Dhruv Kumar",
            "Saurabh Deshpande",
            "Murari Mandal"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21853",
        "abstract": "Policy optimization (PO) algorithms are used to refine Large Language Models for complex, multi-step reasoning. Current state-of-the-art pipelines enforce a strict think-then-answer format to elicit chain-of-thought (CoT); however, the behavior of PO when these rigid constraints are relaxed into an open-ended CoT structure remains an under-studied question. We investigate this gap with an extensive suite of controlled experiments and identify a consistent principle: \\textit{policy optimization consistently follows the path of least resistance}. When afforded the flexibility to interleave reasoning and response, policy optimization consistently learns to discard explicit reasoning, causing the policy to degenerate to a direct \\texttt{<answer>}-only format. This outcome holds true across various models and algorithms. We find that this collapse in format is persistent even when the complex \\texttt{<think><answer>} format is assigned up to 4x larger reward weights. We formalize this principle through a series of controlled reward decomposition experiments, demonstrating a clear hierarchy: PO systematically optimizes for the simplest reward component first, a preference that holds even when faced with mutually exclusive choices or strong incentives for more complex behaviors. Finally, we show that successful convergence on the high-reward shortcut is not a low-effort drift but is driven by the optimization process that requires the KL-regularized policy to have sufficient freedom to make a significant shift from its initial prior. Our findings reveal that granting policies the freedom to diverge is a double-edged sword: while necessary for discovering high-reward shortcuts, it also creates a powerful incentive to game the simplest aspects of the reward function, posing a critical challenge for reward hacking under alignment.",
        "tags": [
            "CoT",
            "LLM"
        ]
    },
    {
        "id": "54",
        "title": "SIGN: Schema-Induced Games for Naming",
        "author": [
            "Ryan Zhang",
            "Herbert WoisetsclÃ¤ger"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21855",
        "abstract": "Real-world AI systems are tackling increasingly complex problems, often through interactions among large language model (LLM) agents. When these agents develop inconsistent conventions, coordination can break down. Applications such as collaborative coding and distributed planning therefore require reliable, consistent communication, and scalability is a central concern as systems grow. We introduce Schema-Induced Games for Naming (SIGN), a naming game that examines how lightweight structure can steer convention formation. We compare schema-induced communication to unconstrained natural language and find faster convergence with up to 5.8x higher agreement. These results suggest that minimal structure can act as a simple control knob for efficient multi-agent coordination, pointing toward broader applications beyond the naming game.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "55",
        "title": "Butter-Bench: Evaluating LLM Controlled Robots for Practical Intelligence",
        "author": [
            "Callum Sharrock",
            "Lukas Petersson",
            "Hanna Petersson",
            "Axel Backlund",
            "Axel WennstrÃ¶m",
            "Kristoffer NordstrÃ¶m",
            "Elias Aronsson"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21860",
        "abstract": "We present Butter-Bench, a benchmark evaluating large language model (LLM) controlled robots for practical intelligence, defined as the ability to navigate the messiness of the physical world. Current state-of-the-art robotic systems use a hierarchical architecture with LLMs in charge of high-level reasoning, and a Vision Language Action (VLA) model for low-level control. Butter-Bench evaluates the LLM part in isolation from the VLA. Although LLMs have repeatedly surpassed humans in evaluations requiring analytical intelligence, we find humans still outperform LLMs on Butter-Bench. The best LLMs score 40% on Butter-Bench, while the mean human score is 95%. LLMs struggled the most with multi-step spatial planning and social understanding. We also evaluate LLMs that are fine-tuned for embodied reasoning and conclude that this training does not improve their score on Butter-Bench.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "56",
        "title": "The Mirror Loop: Recursive Non-Convergence in Generative Reasoning Systems",
        "author": [
            "Bentley DeVilling"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21861",
        "abstract": "Large language models are often described as capable of reflective reasoning, yet recursive self-evaluation without external feedback frequently yields reformulation rather than progress. We test this prediction in a cross-provider study of 144 reasoning sequences across three models (OpenAI GPT-4o-mini, Anthropic Claude 3 Haiku, and Google Gemini 2.0 Flash) and four task families (arithmetic, code, explanation, reflection), each iterated ten times under two conditions: ungrounded self-critique and a minimal grounding intervention (a single verification step at iteration three). Mean informational change (delta I, measured via normalized edit distance) declined by 55% from early (0.193) to late (0.087) iterations in ungrounded runs, with consistent patterns across all three providers. Grounded runs showed a +28% rebound in informational change immediately after the intervention and sustained non-zero variance thereafter. Complementary measures-n-gram novelty, embedding drift, and character-level entropy-converged on the same pattern: reflection without contact tends toward informational closure. We interpret this as evidence for a structural limit on self-correction in generative reasoning: without an exchange of information with an independent verifier or environment, recursive inference approaches an attractor state of epistemic stasis. Minimal grounding functions as dissipative coupling, reintroducing informational flux. The cross-architecture consistency suggests the mirror loop arises from shared autoregressive training objectives rather than provider-specific alignment schemes. The results delineate when reflection is performative rather than epistemic and motivate design principles for grounded, cooperative reasoning. Materials and code are publicly available.",
        "tags": [
            "FLUX",
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "57",
        "title": "A Multi-Stage Hybrid Framework for Automated Interpretation of Multi-View Engineering Drawings Using Vision Language Model",
        "author": [
            "Muhammad Tayyab Khan",
            "Zane Yong",
            "Lequn Chen",
            "Wenhe Feng",
            "Nicholas Yew Jin Tan",
            "Seung Ki Moon"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21862",
        "abstract": "Engineering drawings are fundamental to manufacturing communication, serving as the primary medium for conveying design intent, tolerances, and production details. However, interpreting complex multi-view drawings with dense annotations remains challenging using manual methods, generic optical character recognition (OCR) systems, or traditional deep learning approaches, due to varied layouts, orientations, and mixed symbolic-textual content. To address these challenges, this paper proposes a three-stage hybrid framework for the automated interpretation of 2D multi-view engineering drawings using modern detection and vision language models (VLMs). In the first stage, YOLOv11-det performs layout segmentation to localize key regions such as views, title blocks, and notes. The second stage uses YOLOv11-obb for orientation-aware, fine-grained detection of annotations, including measures, GD&T symbols, and surface roughness indicators. The third stage employs two Donut-based, OCR-free VLMs for semantic content parsing: the Alphabetical VLM extracts textual and categorical information from title blocks and notes, while the Numerical VLM interprets quantitative data such as measures, GD&T frames, and surface roughness. Two specialized datasets were developed to ensure robustness and generalization: 1,000 drawings for layout detection and 1,406 for annotation-level training. The Alphabetical VLM achieved an overall F1 score of 0.672, while the Numerical VLM reached 0.963, demonstrating strong performance in textual and quantitative interpretation, respectively. The unified JSON output enables seamless integration with CAD and manufacturing databases, providing a scalable solution for intelligent engineering drawing analysis.",
        "tags": [
            "Detection",
            "Segmentation",
            "VLM"
        ]
    },
    {
        "id": "58",
        "title": "LSF-Animation: Label-Free Speech-Driven Facial Animation via Implicit Feature Representation",
        "author": [
            "Xin Lu",
            "Chuanqing Zhuang",
            "Chenxi Jin",
            "Zhengda Lu",
            "Yiqun Wang",
            "Wu Liu",
            "Jun Xiao"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21864",
        "abstract": "Speech-driven 3D facial animation has attracted increasing interest since its potential to generate expressive and temporally synchronized digital humans. While recent works have begun to explore emotion-aware animation, they still depend on explicit one-hot encodings to represent identity and emotion with given emotion and identity labels, which limits their ability to generalize to unseen speakers. Moreover, the emotional cues inherently present in speech are often neglected, limiting the naturalness and adaptability of generated animations. In this work, we propose LSF-Animation, a novel framework that eliminates the reliance on explicit emotion and identity feature representations. Specifically, LSF-Animation implicitly extracts emotion information from speech and captures the identity features from a neutral facial mesh, enabling improved generalization to unseen speakers and emotional states without requiring manual labels. Furthermore, we introduce a Hierarchical Interaction Fusion Block (HIFB), which employs a fusion token to integrate dual transformer features and more effectively integrate emotional, motion-related and identity-related cues. Extensive experiments conducted on the 3DMEAD dataset demonstrate that our method surpasses recent state-of-the-art approaches in terms of emotional expressiveness, identity generalization, and animation realism. The source code will be released at: https://github.com/Dogter521/LSF-Animation.",
        "tags": [
            "3D",
            "Transformer"
        ]
    },
    {
        "id": "59",
        "title": "Addressing Corner Cases in Autonomous Driving: A World Model-based Approach with Mixture of Experts and LLMs",
        "author": [
            "Haicheng Liao",
            "Bonan Wang",
            "Junxian Yang",
            "Chengyue Wang",
            "Zhengbin He",
            "Guohui Zhang",
            "Chengzhong Xu",
            "Zhenning Li"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21867",
        "abstract": "Accurate and reliable motion forecasting is essential for the safe deployment of autonomous vehicles (AVs), particularly in rare but safety-critical scenarios known as corner cases. Existing models often underperform in these situations due to an over-representation of common scenes in training data and limited generalization capabilities. To address this limitation, we present WM-MoE, the first world model-based motion forecasting framework that unifies perception, temporal memory, and decision making to address the challenges of high-risk corner-case scenarios. The model constructs a compact scene representation that explains current observations, anticipates future dynamics, and evaluates the outcomes of potential actions. To enhance long-horizon reasoning, we leverage large language models (LLMs) and introduce a lightweight temporal tokenizer that maps agent trajectories and contextual cues into the LLM's feature space without additional training, enriching temporal context and commonsense priors. Furthermore, a mixture-of-experts (MoE) is introduced to decompose complex corner cases into subproblems and allocate capacity across scenario types, and a router assigns scenes to specialized experts that infer agent intent and perform counterfactual rollouts. In addition, we introduce nuScenes-corner, a new benchmark that comprises four real-world corner-case scenarios for rigorous evaluation. Extensive experiments on four benchmark datasets (nuScenes, NGSIM, HighD, and MoCAD) showcase that WM-MoE consistently outperforms state-of-the-art (SOTA) baselines and remains robust under corner-case and data-missing conditions, indicating the promise of world model-based architectures for robust and generalizable motion forecasting in fully AVs.",
        "tags": [
            "LLM",
            "MoE"
        ]
    },
    {
        "id": "60",
        "title": "GuitarFlow: Realistic Electric Guitar Synthesis From Tablatures via Flow Matching and Style Transfer",
        "author": [
            "Jackson Loth",
            "Pedro Sarmento",
            "Mark Sandler",
            "Mathieu Barthet"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21872",
        "abstract": "Music generation in the audio domain using artificial intelligence (AI) has witnessed steady progress in recent years. However for some instruments, particularly the guitar, controllable instrument synthesis remains limited in expressivity. We introduce GuitarFlow, a model designed specifically for electric guitar synthesis. The generative process is guided using tablatures, an ubiquitous and intuitive guitar-specific symbolic format. The tablature format easily represents guitar-specific playing techniques (e.g. bends, muted strings and legatos), which are more difficult to represent in other common music notation formats such as MIDI. Our model relies on an intermediary step of first rendering the tablature to audio using a simple sample-based virtual instrument, then performing style transfer using Flow Matching in order to transform the virtual instrument audio into more realistic sounding examples. This results in a model that is quick to train and to perform inference, requiring less than 6 hours of training data. We present the results of objective evaluation metrics, together with a listening test, in which we show significant improvement in the realism of the generated guitar audio from tablatures.",
        "tags": [
            "Flow Matching",
            "Style Transfer"
        ]
    },
    {
        "id": "61",
        "title": "TernaryCLIP: Efficiently Compressing Vision-Language Models with Ternary Weights and Distilled Knowledge",
        "author": [
            "Shu-Hao Zhang",
            "Wei-Cheng Tang",
            "Chen Wu",
            "Peng Hu",
            "Nan Li",
            "Liang-Jie Zhang",
            "Qi Zhang",
            "Shao-Qun Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21879",
        "abstract": "Recent years have witnessed an increasing interest in image-text contrastive modeling, exemplified by models such as Contrastive Language-Image Pretraining (CLIP). In this paper, we propose the TernaryCLIP, a lightweight computational framework that converts connection weights of both vision and text encoders of CLIP into the ternary format, instead of full-precision or floating ones. TernaryCLIP incorporates quantization-aware training and distillation modules, preventing precision degradation and enabling low-cost and high-efficiency computations. Comprehensive experiments demonstrate that TernaryCLIP can achieve up to 99\\% ternarized weights with 1.58-bit representation, 16.98 $\\times$ compression ratio, 2.3 $\\times$ inference acceleration, 16 $\\times$ storage reduction, 10 $\\times$ memory optimization, and 60\\% sparsity while maintaining promising performance on zero-shot image classification and image-text retrieval tasks across 41 commonly used datasets. Our work highlights the feasibility of extreme quantization for large multimodal models, supporting effective and efficient deployment on resource-constrained devices. The model and code can be accessed from Hugging Face and GitHub.",
        "tags": [
            "CLIP",
            "VLM"
        ]
    },
    {
        "id": "62",
        "title": "GeoThought: A Dataset for Enhancing Mathematical Geometry Reasoning in Vision-Language Models",
        "author": [
            "Nannan Shi",
            "Chuanyu Qin",
            "Shipeng Song",
            "Man Luo"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21881",
        "abstract": "Large language models (LLMs) have demonstrated strong reasoning capabilities in text-based mathematical problem solving; however, when adapted to visual reasoning tasks, particularly geometric problem solving, their performance substantially declines because geometric problems present unique challenges. Specifically, these challenges stem from two key factors: first, the intrinsic complexity of geometry requiring detailed image comprehension and multi-step reasoning, and second, the limitations of existing datasets which lack sufficient scale, diversity, and explicit reasoning traces, consequently hindering effective model training. To address these challenges, we developed the GeoThoughts dataset, a comprehensive geometric reasoning corpus with two subsets: Geo-Thought-6K with 6,243 samples and its augmented version Geo-Thought-Augmented-10K containing 10,834 samples. Each entry includes visual descriptions, step-by-step solutions, explicit reasoning chains, reflection steps, and final answers. Using this dataset, we developed GeoThought-MLLM, a mathematical reasoning multimodal model that generates detailed thinking processes during problem-solving. Our model outperforms existing benchmarks in geometric tasks, demonstrating that training with our Chain-of-Thought dataset improves geometric reasoning capabilities across both in-domain and out-of-domain settings. Finally, we analyze failure cases and observe that errors primarily arise from incorrect interpretation of mathematical concepts or spatial misjudgment. By invoking CoT to correct these mistakes, the model produces correct answers.",
        "tags": [
            "CoT",
            "LLM",
            "VLM"
        ]
    },
    {
        "id": "63",
        "title": "Framework for Machine Evaluation of Reasoning Completeness in Large Language Models For Classification Tasks",
        "author": [
            "Avinash Patil"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21884",
        "abstract": "The growing adoption of machine learning (ML) in sensitive domains has heightened the demand for transparent and interpretable artificial intelligence. Large Language Models (LLMs) are increasingly capable of producing natural language explanations, yet it remains unclear whether these rationales faithfully capture the predictive signals that underlie decisions. This paper introduces RACE-Reasoning Alignment for Completeness of Explanations, a systematic framework to evaluate the alignment between LLM-generated explanations and interpretable feature importance scores derived from a logistic regression baseline. We analyze four widely used text classification datasets-WIKI ONTOLOGY, AG NEWS, IMDB, and GOEMOTIONS-and compare LLM rationales against top-ranked supporting and contradicting lexical features. To capture alignment at multiple levels of granularity, RACE implements token-aware, exact string, and edit-distance matching techniques. Empirical results reveal a consistent asymmetry: correct predictions exhibit higher coverage of supporting features, while incorrect predictions are associated with elevated coverage of contradicting features. Edit-distance matching further uncovers paraphrastic overlaps, boosting coverage while preserving this asymmetry. These findings demonstrate that LLM rationales combine both surface-level and flexible evidence reuse, yet can also amplify misleading cues in error cases. RACE provides new insights into the faithfulness of LLM explanations and establishes a quantitative basis for evaluating reasoning completeness in neural language models.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "64",
        "title": "Preventing Catastrophic Forgetting: Behavior-Aware Sampling for Safer Language Model Fine-Tuning",
        "author": [
            "Anh Pham",
            "Mihir Thalanki",
            "Michael Sun",
            "Aditya Chaloo",
            "Ankita Gupta",
            "Tian Xia",
            "Aditya Mate",
            "Ehimwenma Nosakhare",
            "Soundararajan Srinivasan"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21885",
        "abstract": "Large language models often lose previously aligned safety behaviors when fine-tuned on benign data, a phenomenon known as catastrophic forgetting. Prior work shows that adding random safety examples can mitigate this effect, but it remains unclear which examples are most effective. We propose a behavior-aware sampling framework that selects safety examples based on two complementary factors: instruction-response behavior (e.g., refusal versus compliance) and semantic diversity across harm categories. Systematic evaluation shows that this approach substantially reduces harmful outputs while maintaining helpfulness, achieving up to a 41% reduction in harmfulness with only 0.5% additional training data. These results highlight how targeted data selection can improve the safety and efficiency of fine-tuning at scale.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "65",
        "title": "Generative AI in Depth: A Survey of Recent Advances, Model Variants, and Real-World Applications",
        "author": [
            "Shamim Yazdani",
            "Akansha Singh",
            "Nripsuta Saxena",
            "Zichong Wang",
            "Avash Palikhe",
            "Deng Pan",
            "Umapada Pal",
            "Jie Yang",
            "Wenbin Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21887",
        "abstract": "In recent years, deep learning based generative models, particularly Generative Adversarial Networks (GANs), Variational Autoencoders (VAEs), and Diffusion Models (DMs), have been instrumental in in generating diverse, high-quality content across various domains, such as image and video synthesis. This capability has led to widespread adoption of these models and has captured strong public interest. As they continue to advance at a rapid pace, the growing volume of research, expanding application areas, and unresolved technical challenges make it increasingly difficult to stay current. To address this need, this survey introduces a comprehensive taxonomy that organizes the literature and provides a cohesive framework for understanding the development of GANs, VAEs, and DMs, including their many variants and combined approaches. We highlight key innovations that have improved the quality, diversity, and controllability of generated outputs, reflecting the expanding potential of generative artificial intelligence. In addition to summarizing technical progress, we examine rising ethical concerns, including the risks of misuse and the broader societal impact of synthetic media. Finally, we outline persistent challenges and propose future research directions, offering a structured and forward looking perspective for researchers in this fast evolving field.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "66",
        "title": "Computational Hardness of Reinforcement Learning with Partial $q^Ï$-Realizability",
        "author": [
            "Shayan Karimi",
            "Xiaoqi Tan"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21888",
        "abstract": "This paper investigates the computational complexity of reinforcement learning in a novel linear function approximation regime, termed partial $q^{\\pi}$-realizability. In this framework, the objective is to learn an $\\epsilon$-optimal policy with respect to a predefined policy set $\\Pi$, under the assumption that all value functions for policies in $\\Pi$ are linearly realizable. The assumptions of this framework are weaker than those in $q^{\\pi}$-realizability but stronger than those in $q^*$-realizability, providing a practical model where function approximation naturally arises. We prove that learning an $\\epsilon$-optimal policy in this setting is computationally hard. Specifically, we establish NP-hardness under a parameterized greedy policy set (argmax) and show that - unless NP = RP - an exponential lower bound (in feature vector dimension) holds when the policy set contains softmax policies, under the Randomized Exponential Time Hypothesis. Our hardness results mirror those in $q^*$-realizability and suggest computational difficulty persists even when $\\Pi$ is expanded beyond the optimal policy. To establish this, we reduce from two complexity problems, $\\delta$-Max-3SAT and $\\delta$-Max-3SAT(b), to instances of GLinear-$\\kappa$-RL (greedy policy) and SLinear-$\\kappa$-RL (softmax policy). Our findings indicate that positive computational results are generally unattainable in partial $q^{\\pi}$-realizability, in contrast to $q^{\\pi}$-realizability under a generative access model.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "67",
        "title": "The Principles of Diffusion Models",
        "author": [
            "Chieh-Hsin Lai",
            "Yang Song",
            "Dongjun Kim",
            "Yuki Mitsufuji",
            "Stefano Ermon"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21890",
        "abstract": "This monograph presents the core principles that have guided the development of diffusion models, tracing their origins and showing how diverse formulations arise from shared mathematical ideas. Diffusion modeling starts by defining a forward process that gradually corrupts data into noise, linking the data distribution to a simple prior through a continuum of intermediate distributions. The goal is to learn a reverse process that transforms noise back into data while recovering the same intermediates. We describe three complementary views. The variational view, inspired by variational autoencoders, sees diffusion as learning to remove noise step by step. The score-based view, rooted in energy-based modeling, learns the gradient of the evolving data distribution, indicating how to nudge samples toward more likely regions. The flow-based view, related to normalizing flows, treats generation as following a smooth path that moves samples from noise to data under a learned velocity field. These perspectives share a common backbone: a time-dependent velocity field whose flow transports a simple prior to the data. Sampling then amounts to solving a differential equation that evolves noise into data along a continuous trajectory. On this foundation, the monograph discusses guidance for controllable generation, efficient numerical solvers, and diffusion-motivated flow-map models that learn direct mappings between arbitrary times. It provides a conceptual and mathematically grounded understanding of diffusion models for readers with basic deep-learning knowledge.",
        "tags": [
            "Diffusion",
            "Normalizing Flows"
        ]
    },
    {
        "id": "68",
        "title": "Embedding Trust: Semantic Isotropy Predicts Nonfactuality in Long-Form Text Generation",
        "author": [
            "Dhrupad Bhardwaj",
            "Julia Kempe",
            "Tim G. J. Rudner"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21891",
        "abstract": "To deploy large language models (LLMs) in high-stakes application domains that require substantively accurate responses to open-ended prompts, we need reliable, computationally inexpensive methods that assess the trustworthiness of long-form responses generated by LLMs. However, existing approaches often rely on claim-by-claim fact-checking, which is computationally expensive and brittle in long-form responses to open-ended prompts. In this work, we introduce semantic isotropy -- the degree of uniformity across normalized text embeddings on the unit sphere -- and use it to assess the trustworthiness of long-form responses generated by LLMs. To do so, we generate several long-form responses, embed them, and estimate the level of semantic isotropy of these responses as the angular dispersion of the embeddings on the unit sphere. We find that higher semantic isotropy -- that is, greater embedding dispersion -- reliably signals lower factual consistency across samples. Our approach requires no labeled data, no fine-tuning, and no hyperparameter selection, and can be used with open- or closed-weight embedding models. Across multiple domains, our method consistently outperforms existing approaches in predicting nonfactuality in long-form responses using only a handful of samples -- offering a practical, low-cost approach for integrating trust assessment into real-world LLM workflows.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "69",
        "title": "Understanding Network Behaviors through Natural Language Question-Answering",
        "author": [
            "Mingzhe Xing",
            "Chang Tian",
            "Jianan Zhang",
            "Lichen Pan",
            "Peipei Liu",
            "Zhaoteng Yan",
            "Yinliang Yue"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21894",
        "abstract": "Modern large-scale networks introduce significant complexity in understanding network behaviors, increasing the risk of misconfiguration. Prior work proposed to understand network behaviors by mining network configurations, typically relying on domain-specific languages interfaced with formal models. While effective, they suffer from a steep learning curve and limited flexibility. In contrast, natural language (NL) offers a more accessible and interpretable interface, motivating recent research on NL-guided network behavior understanding. Recent advances in large language models (LLMs) further enhance this direction, leveraging their extensive prior knowledge of network concepts and strong reasoning capabilities. However, three key challenges remain: 1) numerous router devices with lengthy configuration files challenge LLM's long-context understanding ability; 2) heterogeneity across devices and protocols impedes scalability; and 3) complex network topologies and protocols demand advanced reasoning abilities beyond the current capabilities of LLMs. To tackle the above challenges, we propose NetMind, a novel framework for querying networks using NL. Our approach introduces a tree-based configuration chunking strategy to preserve semantic coherence while enabling efficient partitioning. We then construct a unified fact graph as an intermediate representation to normalize vendor-specific configurations. Finally, we design a hybrid imperative-declarative language to reduce the reasoning burden on LLMs and enhance precision. We contribute a benchmark consisting of NL question-answer pairs paired with network configurations. Experiments demonstrate that NetMind achieves accurate and scalable network behavior understanding, outperforming existing baselines.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "70",
        "title": "Structure-Aware Cooperative Ensemble Evolutionary Optimization on Combinatorial Problems with Multimodal Large Language Models",
        "author": [
            "Jie Zhao",
            "Kang Hao Cheong"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21906",
        "abstract": "Evolutionary algorithms (EAs) have proven effective in exploring the vast solution spaces typical of graph-structured combinatorial problems. However, traditional encoding schemes, such as binary or numerical representations, often fail to straightforwardly capture the intricate structural properties of networks. Through employing the image-based encoding to preserve topological context, this study utilizes multimodal large language models (MLLMs) as evolutionary operators to facilitate structure-aware optimization over graph data. To address the visual clutter inherent in large-scale network visualizations, we leverage graph sparsification techniques to simplify structures while maintaining essential structural features. To further improve robustness and mitigate bias from different sparsification views, we propose a cooperative evolutionary optimization framework that facilitates cross-domain knowledge transfer and unifies multiple sparsified variants of diverse structures. Additionally, recognizing the sensitivity of MLLMs to network layout, we introduce an ensemble strategy that aggregates outputs from various layout configurations through consensus voting. Finally, experiments on real-world networks through various tasks demonstrate that our approach improves both the quality and reliability of solutions in MLLM-driven evolutionary optimization.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "71",
        "title": "Enabling Robust In-Context Memory and Rapid Task Adaptation in Transformers with Hebbian and Gradient-Based Plasticity",
        "author": [
            "Siddharth Chaudhary"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21908",
        "abstract": "Large language models display in-context learning as an emergent effect of scale, but they rely on static weights during inference. In contrast, biological systems continually adapt via synaptic plasticity. We investigate whether explicit, biologically inspired plasticity can endow Transformers with faster in-sequence adaptation. To this end, we augment decoder-only Transformers with fast-weight modules updated either by (i) a neuromodulated Hebbian rule or (ii) the gradient-based plasticity mechanism of Duan et al. (2023). Across copying, regression, and few-shot classification tasks (CIFAR-FS, Omniglot), Hebbian plasticity consistently achieves lower loss and stronger few-shot generalization, while gradient-based updates perform best on long-horizon credit assignment. When associations are short and linearly separable, static weights suffice, defining a clear boundary condition for when plasticity helps. Analysis of learned modulatory signals reveals that gradient-based rules maintain large, persistent updates, whereas Hebbian plasticity is sharply gated around salient events. Together, these results show that explicit plasticity complements attention by enabling rapid, task-specific adaptation, and clarify when different plasticity mechanisms are most effective.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "72",
        "title": "Adversarial DÃ©jÃ  Vu: Jailbreak Dictionary Learning for Stronger Generalization to Unseen Attacks",
        "author": [
            "Mahavir Dabas",
            "Tran Huynh",
            "Nikhil Reddy Billa",
            "Jiachen T. Wang",
            "Peng Gao",
            "Charith Peris",
            "Yao Ma",
            "Rahul Gupta",
            "Ming Jin",
            "Prateek Mittal",
            "Ruoxi Jia"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21910",
        "abstract": "Large language models remain vulnerable to jailbreak attacks that bypass safety guardrails to elicit harmful outputs. Defending against novel jailbreaks represents a critical challenge in AI safety. Adversarial training -- designed to make models robust against worst-case perturbations -- has been the dominant paradigm for adversarial robustness. However, due to optimization challenges and difficulties in defining realistic threat models, adversarial training methods often fail on newly developed jailbreaks in practice. This paper proposes a new paradigm for improving robustness against unseen jailbreaks, centered on the Adversarial DÃ©jÃ  Vu hypothesis: novel jailbreaks are not fundamentally new, but largely recombinations of adversarial skills from previous attacks. We study this hypothesis through a large-scale analysis of 32 attack papers published over two years. Using an automated pipeline, we extract and compress adversarial skills into a sparse dictionary of primitives, with LLMs generating human-readable descriptions. Our analysis reveals that unseen attacks can be effectively explained as sparse compositions of earlier skills, with explanatory power increasing monotonically as skill coverage grows. Guided by this insight, we introduce Adversarial Skill Compositional Training (ASCoT), which trains on diverse compositions of skill primitives rather than isolated attack instances. ASCoT substantially improves robustness to unseen attacks, including multi-turn jailbreaks, while maintaining low over-refusal rates. We also demonstrate that expanding adversarial skill coverage, not just data scale, is key to defending against novel attacks. \\textcolor{red}{\\textbf{Warning: This paper contains content that may be harmful or offensive in nature.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "73",
        "title": "A Comparison of Conversational Models and Humans in Answering Technical Questions: the Firefox Case",
        "author": [
            "Joao Correia",
            "Daniel Coutinho",
            "Marco Castelluccio",
            "Caio Barbosa",
            "Rafael de Mello",
            "Anita Sarma",
            "Alessandro Garcia",
            "Marco Gerosa",
            "Igor Steinmacher"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21933",
        "abstract": "The use of Large Language Models (LLMs) to support tasks in software development has steadily increased over recent years. From assisting developers in coding activities to providing conversational agents that answer newcomers' questions. In collaboration with the Mozilla Foundation, this study evaluates the effectiveness of Retrieval-Augmented Generation (RAG) in assisting developers within the Mozilla Firefox project. We conducted an empirical analysis comparing responses from human developers, a standard GPT model, and a GPT model enhanced with RAG, using real queries from Mozilla's developer chat rooms. To ensure a rigorous evaluation, Mozilla experts assessed the responses based on helpfulness, comprehensiveness, and conciseness. The results show that RAG-assisted responses were more comprehensive than human developers (62.50% to 54.17%) and almost as helpful (75.00% to 79.17%), suggesting RAG's potential to enhance developer assistance. However, the RAG responses were not as concise and often verbose. The results show the potential to apply RAG-based tools to Open Source Software (OSS) to minimize the load to core maintainers without losing answer quality. Toning down retrieval mechanisms and making responses even shorter in the future would enhance developer assistance in massive projects like Mozilla Firefox.",
        "tags": [
            "GPT",
            "LLM",
            "RAG"
        ]
    },
    {
        "id": "74",
        "title": "Pricing Problems in Adoption of New Technologies",
        "author": [
            "Yijin Wang",
            "Subhonmesh Bose"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21951",
        "abstract": "We propose a generalization of the Bass diffusion model in discrete-time that explicitly models the effect of price in adoption. Our model is different from earlier price-incorporated models and fits well to adoption data for various products. We then utilize this model to study two decision-making problems. First, we provide a series of structural results on optimal pricing strategies to maximize profits from product sales by a monopolist over a finite horizon. We fully characterize the optimal pricing strategy in the single-period problem, and establish several structural properties of the same for the multi-period counterpart. Second, we study a Stackelberg game between a policy-maker and a monopolist, where the former seeks to maximize adoption through rebates, while the latter focuses on profits. For this problem, we analytically characterize crucial properties of the equilibrium path of the single-period game, and demonstrate how they carry over to the multi-period variant.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "75",
        "title": "Model-Aware Tokenizer Transfer",
        "author": [
            "Mykola Haltiuk",
            "Aleksander SmywiÅski-Pohl"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21954",
        "abstract": "Large Language Models (LLMs) are trained to support an increasing number of languages, yet their predefined tokenizers remain a bottleneck for adapting models to lower-resource or distinct-script languages. Existing tokenizer transfer methods typically rely on semantic heuristics to initialize new embeddings, ignoring higher-layer model dynamics and limiting transfer quality. We propose Model-Aware Tokenizer Transfer (MATT), a method that incorporates model internals into the tokenizer transfer process. MATT introduces an Attention Influence Modeling (AIM) objective that distills inter-token communication patterns from a source model into a target model with a new tokenizer, providing an efficient warm-up before standard language modeling. Unlike approaches that focus solely on embedding similarity, MATT leverages attention behavior to guide embedding initialization and adaptation. Experiments across diverse linguistic settings show that MATT recovers a large fraction of the original model's performance within a few GPU hours, outperforming heuristic baselines. These results demonstrate that incorporating model-level signals offers a practical and effective path toward robust tokenizer transfer in multilingual LLMs.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "76",
        "title": "Transformer Based Linear Attention with Optimized GPU Kernel Implementation",
        "author": [
            "Armin Gerami",
            "Ramani Duraiswami"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21956",
        "abstract": "The original softmax-based attention mechanism (regular attention) in the extremely successful Transformer architecture computes attention between $N$ tokens, each embedded in a $D$-dimensional head, with a time complexity of $O(N^2D)$. Given the success of Transformers, improving their runtime during both training and inference is a popular research area. One such approach is the introduction of the linear attention (LA) mechanisms, which offers a linear time complexity of $O(ND^2)$ and have demonstrated comparable accuracy to regular attention. However, LA in practice lags behind its theoretical efficiency. We propose a novel method for LA's forward and backward passes, along with a highly-optimized CUDA implementation. Our approach outperforms the state-of-the-art by 3.3 times in speed and reduces memory consumption by 3.6 times. We validate these improvements in both single-layer and end-to-end settings by training a 1.4 billion parameter language model, which demonstrates similar expressivity to regular attention on major reasoning benchmarks.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "77",
        "title": "A Stylometric Application of Large Language Models",
        "author": [
            "Harrison F. Stropkay",
            "Jiayi Chen",
            "Mohammad J. Latifi",
            "Daniel N. Rockmore",
            "Jeremy R. Manning"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21958",
        "abstract": "We show that large language models (LLMs) can be used to distinguish the writings of different authors. Specifically, an individual GPT-2 model, trained from scratch on the works of one author, will predict held-out text from that author more accurately than held-out text from other authors. We suggest that, in this way, a model trained on one author's works embodies the unique writing style of that author. We first demonstrate our approach on books written by eight different (known) authors. We also use this approach to confirm R. P. Thompson's authorship of the well-studied 15th book of the Oz series, originally attributed to F. L. Baum.",
        "tags": [
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "78",
        "title": "Parallel Sampling from Masked Diffusion Models via Conditional Independence Testing",
        "author": [
            "Iskander Azangulov",
            "Teodora Pandeva",
            "Niranjani Prasad",
            "Javier Zazo",
            "Sushrut Karmalkar"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21961",
        "abstract": "Masked diffusion models (MDMs) offer a compelling alternative to autoregressive models (ARMs) for discrete text generation because they enable parallel token sampling, rather than sequential, left-to-right generation. This means potentially much faster inference. However, effective parallel sampling faces two competing requirements: (i) simultaneously updated tokens must be conditionally independent, and (ii) updates should prioritise high-confidence predictions. These goals conflict because high-confidence predictions often cluster and depend on each other, opportunities for parallel updates.\nWe present PUNT, a model-agnostic sampler that reconciles this trade-off. Our method identifies token dependencies and removes lower-confidence tokens from conflicting groups. This produces sets of indices for unmasking that satisfy both independence and confidence criteria. Our approach ensures improved parallel unmasking through approximate conditional independence testing.\nOur experiments show that PUNT delivers a superior trade-off between accuracy and compute when compared to other strong training-free baselines, especially for generation of longer sequences. On the IFEval benchmark, it achieves up to 16\\% higher accuracy over baseline methods, including sequential generation (one-by-one). These gains hold across different values of hyperparameters, mitigating the need for brittle hyperparameter tuning. Moreover, we observe that PUNT induces an emergent hierarchical generation strategy, where the model first establishes high-level paragraph structure before local refinement, suggesting a planning-like generation process that contributes to strong alignment performance.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "79",
        "title": "LLM-augmented empirical game theoretic simulation for social-ecological systems",
        "author": [
            "Jennifer Shi",
            "Christopher K. Frantz",
            "Christian Kimmich",
            "Saba Siddiki",
            "Atrisha Sarkar"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21965",
        "abstract": "Designing institutions for social-ecological systems requires models that capture heterogeneity, uncertainty, and strategic interaction. Multiple modeling approaches have emerged to meet this challenge, including empirical game-theoretic analysis (EGTA), which merges ABM's scale and diversity with game-theoretic models' formal equilibrium analysis. The newly popular class of LLM-driven simulations provides yet another approach, and it is not clear how these approaches can be integrated with one another, nor whether the resulting simulations produce a plausible range of behaviours for real-world social-ecological governance. To address this gap, we compare four LLM-augmented frameworks: procedural ABMs, generative ABMs, LLM-EGTA, and expert guided LLM-EGTA, and evaluate them on a real-world case study of irrigation and fishing in the Amu Darya basin under centralized and decentralized governance. Our results show: first, procedural ABMs, generative ABMs, and LLM-augmented EGTA models produce strikingly different patterns of collective behaviour, highlighting the value of methodological diversity. Second, inducing behaviour through system prompts in LLMs is less effective than shaping behaviour through parameterized payoffs in an expert-guided EGTA-based model.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "80",
        "title": "ArchISMiner: A Framework for Automatic Mining of Architectural Issue-Solution Pairs from Online Developer Communities",
        "author": [
            "Musengamana Jean de Dieu",
            "Ruiyin Li",
            "Peng Liang",
            "Mojtaba Shahin",
            "Muhammad Waseem",
            "Arif Ali Khan",
            "Bangchao Wang",
            "Mst Shamima Aktar"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21966",
        "abstract": "Stack Overflow (SO), a leading online community forum, is a rich source of software development knowledge. However, locating architectural knowledge, such as architectural solutions remains challenging due to the overwhelming volume of unstructured content and fragmented discussions. Developers must manually sift through posts to find relevant architectural insights, which is time-consuming and error-prone. This study introduces ArchISMiner, a framework for mining architectural knowledge from SO. The framework comprises two complementary components: ArchPI and ArchISPE. ArchPI trains and evaluates multiple models, including conventional ML/DL models, Pre-trained Language Models (PLMs), and Large Language Models (LLMs), and selects the best-performing model to automatically identify Architecture-Related Posts (ARPs) among programming-related discussions. ArchISPE employs an indirect supervised approach that leverages diverse features, including BERT embeddings and local TextCNN features, to extract architectural issue-solution pairs. Our evaluation shows that the best model in ArchPI achieves an F1-score of 0.960 in ARP detection, and ArchISPE outperforms baselines in both SE and NLP fields, achieving F1-scores of 0.883 for architectural issues and 0.894 for solutions. A user study further validated the quality (e.g., relevance and usefulness) of the identified ARPs and the extracted issue-solution pairs. Moreover, we applied ArchISMiner to three additional forums, releasing a dataset of over 18K architectural issue-solution pairs. Overall, ArchISMiner can help architects and developers identify ARPs and extract succinct, relevant, and useful architectural knowledge from developer communities more accurately and efficiently. The replication package of this study has been provided at https://github.com/JeanMusenga/ArchISPE",
        "tags": [
            "BERT",
            "Detection",
            "LLM"
        ]
    },
    {
        "id": "81",
        "title": "Performance Trade-offs of Optimizing Small Language Models for E-Commerce",
        "author": [
            "Josip Tomo Licardo",
            "Nikola Tankovic"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21970",
        "abstract": "Large Language Models (LLMs) offer state-of-the-art performance in natural language understanding and generation tasks. However, the deployment of leading commercial models for specialized tasks, such as e-commerce, is often hindered by high computational costs, latency, and operational expenses. This paper investigates the viability of smaller, open-weight models as a resource-efficient alternative. We present a methodology for optimizing a one-billion-parameter Llama 3.2 model for multilingual e-commerce intent recognition. The model was fine-tuned using Quantized Low-Rank Adaptation (QLoRA) on a synthetically generated dataset designed to mimic real-world user queries. Subsequently, we applied post-training quantization techniques, creating GPU-optimized (GPTQ) and CPU-optimized (GGUF) versions. Our results demonstrate that the specialized 1B model achieves 99% accuracy, matching the performance of the significantly larger GPT-4.1 model. A detailed performance analysis revealed critical, hardware-dependent trade-offs: while 4-bit GPTQ reduced VRAM usage by 41%, it paradoxically slowed inference by 82% on an older GPU architecture (NVIDIA T4) due to dequantization overhead. Conversely, GGUF formats on a CPU achieved a speedup of up to 18x in inference throughput and a reduction of over 90% in RAM consumption compared to the FP16 baseline. We conclude that small, properly optimized open-weight models are not just a viable but a more suitable alternative for domain-specific applications, offering state-of-the-art accuracy at a fraction of the computational cost.",
        "tags": [
            "GPT",
            "LLM",
            "LLaMA",
            "LoRA"
        ]
    },
    {
        "id": "82",
        "title": "Distribution Shift Alignment Helps LLMs Simulate Survey Response Distributions",
        "author": [
            "Ji Huang",
            "Mengfei Li",
            "Shuai Shao"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21977",
        "abstract": "Large language models (LLMs) offer a promising way to simulate human survey responses, potentially reducing the cost of large-scale data collection. However, existing zero-shot methods suffer from prompt sensitivity and low accuracy, while conventional fine-tuning approaches mostly fit the training set distributions and struggle to produce results more accurate than the training set itself, which deviates from the original goal of using LLMs to simulate survey responses. Building on this observation, we introduce Distribution Shift Alignment (DSA), a two-stage fine-tuning method that aligns both the output distributions and the distribution shifts across different backgrounds. By learning how these distributions change rather than fitting training data, DSA can provide results substantially closer to the true distribution than the training data. Empirically, DSA consistently outperforms other methods on five public survey datasets. We further conduct a comprehensive comparison covering accuracy, robustness, and data savings. DSA reduces the required real data by 53.48-69.12%, demonstrating its effectiveness and efficiency in survey simulation.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "83",
        "title": "Beyond Reasoning Gains: Mitigating General Capabilities Forgetting in Large Reasoning Models",
        "author": [
            "Hoang Phan",
            "Xianjun Yang",
            "Kevin Yao",
            "Jingyu Zhang",
            "Shengjie Bi",
            "Xiaocheng Tang",
            "Madian Khabsa",
            "Lijuan Liu",
            "Deren Lei"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21978",
        "abstract": "Reinforcement learning with verifiable rewards (RLVR) has delivered impressive gains in mathematical and multimodal reasoning and has become a standard post-training paradigm for contemporary language and vision-language models. However, the RLVR recipe introduces a significant risk of capability regression, where models forget foundational skills after prolonged training without employing regularization strategies. We empirically confirm this concern, observing that open-source reasoning models suffer performance degradation on core capabilities such as perception and faithfulness. While imposing regularization terms like KL divergence can help prevent deviation from the base model, these terms are calculated on the current task, thus they do not guarantee broader knowledge. Meanwhile, commonly used experience replay across heterogeneous domains makes it nontrivial to decide how much training focus each objective should receive. To address this, we propose RECAP-a replay strategy with dynamic objective reweighting for general knowledge preservation. Our reweighting mechanism adapts in an online manner using short-horizon signals of convergence and instability, shifting the post-training focus away from saturated objectives and toward underperforming or volatile ones. Our method is end-to-end and readily applicable to existing RLVR pipelines without training additional models or heavy tuning. Extensive experiments on benchmarks based on Qwen2.5-VL-3B and Qwen2.5-VL-7B demonstrate the effectiveness of our method, which not only preserves general capabilities but also improves reasoning by enabling more flexible trade-offs among in-task rewards.",
        "tags": [
            "RL",
            "VLM"
        ]
    },
    {
        "id": "84",
        "title": "Uncovering the Persuasive Fingerprint of LLMs in Jailbreaking Attacks",
        "author": [
            "Havva Alizadeh Noughabi",
            "Julien Serbanescu",
            "Fattane Zarrinkalam",
            "Ali Dehghantanha"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21983",
        "abstract": "Despite recent advances, Large Language Models remain vulnerable to jailbreak attacks that bypass alignment safeguards and elicit harmful outputs. While prior research has proposed various attack strategies differing in human readability and transferability, little attention has been paid to the linguistic and psychological mechanisms that may influence a model's susceptibility to such attacks. In this paper, we examine an interdisciplinary line of research that leverages foundational theories of persuasion from the social sciences to craft adversarial prompts capable of circumventing alignment constraints in LLMs. Drawing on well-established persuasive strategies, we hypothesize that LLMs, having been trained on large-scale human-generated text, may respond more compliantly to prompts with persuasive structures. Furthermore, we investigate whether LLMs themselves exhibit distinct persuasive fingerprints that emerge in their jailbreak responses. Empirical evaluations across multiple aligned LLMs reveal that persuasion-aware prompts significantly bypass safeguards, demonstrating their potential to induce jailbreak behaviors. This work underscores the importance of cross-disciplinary insight in addressing the evolving challenges of LLM safety. The code and data are available.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "85",
        "title": "From Social Division to Cohesion with AI Message Suggestions in Online Chat Groups",
        "author": [
            "Faria Huq",
            "Elijah L. Claggett",
            "Hirokazu Shirado"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21984",
        "abstract": "Social cohesion is difficult to sustain in societies marked by opinion diversity, particularly in online communication. As large language model (LLM)-driven messaging assistance becomes increasingly embedded in these contexts, it raises critical questions about its societal impact. We present an online experiment with 557 participants who engaged in multi-round discussions on politically controversial topics while freely reconfiguring their discussion groups. In some conditions, participants received real-time message suggestions generated by an LLM, either personalized to the individual or adapted to their group context. We find that subtle shifts in linguistic style during communication, mediated by AI assistance, can scale up to reshape collective structures. While individual-focused assistance leads users to segregate into like-minded groups, relational assistance that incorporates group members' stances enhances cohesion through more receptive exchanges. These findings demonstrate that AI-mediated communication can support social cohesion in diverse groups, but outcomes critically depend on how personalization is designed.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "86",
        "title": "Sprint: Sparse-Dense Residual Fusion for Efficient Diffusion Transformers",
        "author": [
            "Dogyun Park",
            "Moayed Haji-Ali",
            "Yanyu Li",
            "Willi Menapace",
            "Sergey Tulyakov",
            "Hyunwoo J. Kim",
            "Aliaksandr Siarohin",
            "Anil Kag"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21986",
        "abstract": "Diffusion Transformers (DiTs) deliver state-of-the-art generative performance but their quadratic training cost with sequence length makes large-scale pretraining prohibitively expensive. Token dropping can reduce training cost, yet naÃ¯ve strategies degrade representations, and existing methods are either parameter-heavy or fail at high drop ratios. We present SPRINT, Sparse--Dense Residual Fusion for Efficient Diffusion Transformers, a simple method that enables aggressive token dropping (up to 75%) while preserving quality. SPRINT leverages the complementary roles of shallow and deep layers: early layers process all tokens to capture local detail, deeper layers operate on a sparse subset to cut computation, and their outputs are fused through residual connections. Training follows a two-stage schedule: long masked pre-training for efficiency followed by short full-token fine-tuning to close the train--inference gap. On ImageNet-1K 256x256, SPRINT achieves 9.8x training savings with comparable FID/FDD, and at inference, its Path-Drop Guidance (PDG) nearly halves FLOPs while improving quality. These results establish SPRINT as a simple, effective, and general solution for efficient DiT training.",
        "tags": [
            "DiT",
            "Diffusion"
        ]
    },
    {
        "id": "87",
        "title": "Two-Steps Diffusion Policy for Robotic Manipulation via Genetic Denoising",
        "author": [
            "Mateo Clemente",
            "Leo Brunswic",
            "Rui Heng Yang",
            "Xuan Zhao",
            "Yasser Khalil",
            "Haoyu Lei",
            "Amir Rasouli",
            "Yinchuan Li"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21991",
        "abstract": "Diffusion models, such as diffusion policy, have achieved state-of-the-art results in robotic manipulation by imitating expert demonstrations. While diffusion models were originally developed for vision tasks like image and video generation, many of their inference strategies have been directly transferred to control domains without adaptation. In this work, we show that by tailoring the denoising process to the specific characteristics of embodied AI tasks -- particularly structured, low-dimensional nature of action distributions -- diffusion policies can operate effectively with as few as 5 neural function evaluations (NFE).\nBuilding on this insight, we propose a population-based sampling strategy, genetic denoising, which enhances both performance and stability by selecting denoising trajectories with low out-of-distribution risk. Our method solves challenging tasks with only 2 NFE while improving or matching performance. We evaluate our approach across 14 robotic manipulation tasks from D4RL and Robomimic, spanning multiple action horizons and inference budgets. In over 2 million evaluations, our method consistently outperforms standard diffusion-based policies, achieving up to 20\\% performance gains with significantly fewer inference steps.",
        "tags": [
            "Diffusion",
            "Video Generation"
        ]
    },
    {
        "id": "88",
        "title": "FeaGPT: an End-to-End agentic-AI for Finite Element Analysis",
        "author": [
            "Yupeng Qi",
            "Ran Xu",
            "Xu Chu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21993",
        "abstract": "Large language models (LLMs) are establishing new paradigms for engineering applications by enabling natural language control of complex computational workflows. This paper introduces FeaGPT, the first framework to achieve complete geometry-mesh-simulation workflows through conversational interfaces. Unlike existing tools that automate individual FEA components, FeaGPT implements a fully integrated Geometry-Mesh-Simulation-Analysis (GMSA) pipeline that transforms engineering specifications into validated computational results without manual intervention. The system interprets engineering intent, automatically generates physics-aware adaptive meshes, configures complete FEA simulations with proper boundary condition inference, and performs multi-objective analysis through closed-loop iteration.\nExperimental validation confirms complete end-to-end automation capability. Industrial turbocharger cases (7-blade compressor and 12-blade turbine at \\SI{110000}{rpm}) demonstrate the system successfully transforms natural language specifications into validated CalculiX simulations, producing physically realistic results for rotating machinery analysis. Additional validation through 432 NACA airfoil configurations confirms scalability for parametric design exploration. These results demonstrate that natural language interfaces can effectively democratize access to advanced computational engineering tools while preserving analytical rigor.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "89",
        "title": "Foundation of Intelligence: Review of Math Word Problems from Human Cognition Perspective",
        "author": [
            "Zhenya Huang",
            "Jiayu Liu",
            "Xin Lin",
            "Zhiyuan Ma",
            "Shangzi Xue",
            "Tong Xiao",
            "Qi Liu",
            "Yee Whye Teh",
            "Enhong Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2510.21999",
        "abstract": "Math word problem (MWP) serves as a fundamental research topic in artificial intelligence (AI) dating back to 1960s. This research aims to advance the reasoning abilities of AI by mirroring the human-like cognitive intelligence. The mainstream technological paradigm has evolved from the early rule-based methods, to deep learning models, and is rapidly advancing towards large language models. However, the field still lacks a systematic taxonomy for the MWP survey along with a discussion of current development trends. Therefore, in this paper, we aim to comprehensively review related research in MWP solving through the lens of human cognition, to demonstrate how recent AI models are advancing in simulating human cognitive abilities. Specifically, we summarize 5 crucial cognitive abilities for MWP solving, including Problem Understanding, Logical Organization, Associative Memory, Critical Thinking, and Knowledge Learning. Focused on these abilities, we review two mainstream MWP models in recent 10 years: neural network solvers, and LLM based solvers, and discuss the core human-like abilities they demonstrated in their intricate problem-solving process. Moreover, we rerun all the representative MWP solvers and supplement their performance on 5 mainstream benchmarks for a unified comparison. To the best of our knowledge, this survey first comprehensively analyzes the influential MWP research of the past decade from the perspective of human reasoning cognition and provides an integrative overall comparison across existing approaches. We hope it can inspire further research in AI reasoning. Our repository is released on https://github.com/Ljyustc/FoI-MWP.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "90",
        "title": "LightAgent: Mobile Agentic Foundation Models",
        "author": [
            "Yangqin Jiang",
            "Chao Huang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22009",
        "abstract": "With the advancement of multimodal large language models (MLLMs), building GUI agent systems has become an increasingly promising direction-especially for mobile platforms, given their rich app ecosystems and intuitive touch interactions. Yet mobile GUI agents face a critical dilemma: truly on-device models (4B or smaller) lack sufficient performance, while capable models (starting from 7B) are either too large for mobile deployment or prohibitively costly (e.g., cloud-only closed-source MLLMs). To resolve this, we propose LightAgent, a mobile agentic foundation model solution that leverages device-cloud collaboration to tap the cost-efficiency of on-device models and the high capability of cloud models, while avoiding their drawbacks. Specifically, LightAgent enhances Qwen2.5-VL-3B via two-stage SFT->GRPO training on synthetic GUI data for strong decision-making, integrates an efficient long-reasoning mechanism to utilize historical interactions under tight resources, and defaults to on-device execution-only escalating challenging subtasks to the cloud via real-time complexity assessment. Experiments on the online AndroidLab benchmark and diverse apps show LightAgent matches or nears larger models, with a significant reduction in cloud costs.",
        "tags": [
            "GRPO",
            "LLM"
        ]
    },
    {
        "id": "91",
        "title": "FlowOpt: Fast Optimization Through Whole Flow Processes for Training-Free Editing",
        "author": [
            "Or Ronai",
            "Vladimir Kulikov",
            "Tomer Michaeli"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22010",
        "abstract": "The remarkable success of diffusion and flow-matching models has ignited a surge of works on adapting them at test time for controlled generation tasks. Examples range from image editing to restoration, compression and personalization. However, due to the iterative nature of the sampling process in those models, it is computationally impractical to use gradient-based optimization to directly control the image generated at the end of the process. As a result, existing methods typically resort to manipulating each timestep separately. Here we introduce FlowOpt - a zero-order (gradient-free) optimization framework that treats the entire flow process as a black box, enabling optimization through the whole sampling path without backpropagation through the model. Our method is both highly efficient and allows users to monitor the intermediate optimization results and perform early stopping if desired. We prove a sufficient condition on FlowOpt's step-size, under which convergence to the global optimum is guaranteed. We further show how to empirically estimate this upper bound so as to choose an appropriate step-size. We demonstrate how FlowOpt can be used for image editing, showcasing two options: (i) inversion (determining the initial noise that generates a given image), and (ii) directly steering the edited image to be similar to the source image while conforming to a target text prompt. In both cases, FlowOpt achieves state-of-the-art results while using roughly the same number of neural function evaluations (NFEs) as existing methods. Code and examples are available on the project's webpage.",
        "tags": [
            "Diffusion",
            "Flow Matching",
            "Image Editing"
        ]
    },
    {
        "id": "92",
        "title": "Toward Understanding the Transferability of Adversarial Suffixes in Large Language Models",
        "author": [
            "Sarah Ball",
            "Niki Hasrati",
            "Alexander Robey",
            "Avi Schwarzschild",
            "Frauke Kreuter",
            "Zico Kolter",
            "Andrej Risteski"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22014",
        "abstract": "Discrete optimization-based jailbreaking attacks on large language models aim to generate short, nonsensical suffixes that, when appended onto input prompts, elicit disallowed content. Notably, these suffixes are often transferable -- succeeding on prompts and models for which they were never optimized. And yet, despite the fact that transferability is surprising and empirically well-established, the field lacks a rigorous analysis of when and why transfer occurs. To fill this gap, we identify three statistical properties that strongly correlate with transfer success across numerous experimental settings: (1) how much a prompt without a suffix activates a model's internal refusal direction, (2) how strongly a suffix induces a push away from this direction, and (3) how large these shifts are in directions orthogonal to refusal. On the other hand, we find that prompt semantic similarity only weakly correlates with transfer success. These findings lead to a more fine-grained understanding of transferability, which we use in interventional experiments to showcase how our statistical analysis can translate into practical improvements in attack success.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "93",
        "title": "Do You Trust the Process?: Modeling Institutional Trust for Community Adoption of Reinforcement Learning Policies",
        "author": [
            "Naina Balepur",
            "Xingrui Pei",
            "Hari Sundaram"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22017",
        "abstract": "Many governmental bodies are adopting AI policies for decision-making. In particular, Reinforcement Learning has been used to design policies that citizens would be expected to follow if implemented. Much RL work assumes that citizens follow these policies, and evaluate them with this in mind. However, we know from prior work that without institutional trust, citizens will not follow policies put in place by governments. In this work, we develop a trust-aware RL algorithm for resource allocation in communities. We consider the case of humanitarian engineering, where the organization is aiming to distribute some technology or resource to community members. We use a Deep Deterministic Policy Gradient approach to learn a resource allocation that fits the needs of the organization. Then, we simulate resource allocation according to the learned policy, and model the changes in institutional trust of community members. We investigate how this incorporation of institutional trust affects outcomes, and ask how effectively an organization can learn policies if trust values are private. We find that incorporating trust into RL algorithms can lead to more successful policies, specifically when the organization's goals are less certain. We find more conservative trust estimates lead to increased fairness and average community trust, though organization success suffers. Finally, we explore a strategy to prevent unfair outcomes to communities. We implement a quota system by an external entity which decreases the organization's utility when it does not serve enough community members. We find this intervention can improve fairness and trust among communities in some cases, while decreasing the success of the organization. This work underscores the importance of institutional trust in algorithm design and implementation, and identifies a tension between organization success and community well-being.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "94",
        "title": "K-DAREK: Distance Aware Error for Kurkova Kolmogorov Networks",
        "author": [
            "Masoud Ataei",
            "Vikas Dhiman",
            "Mohammad Javad Khojasteh"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22021",
        "abstract": "Neural networks are parametric and powerful tools for function approximation, and the choice of architecture heavily influences their interpretability, efficiency, and generalization. In contrast, Gaussian processes (GPs) are nonparametric probabilistic models that define distributions over functions using a kernel to capture correlations among data points. However, these models become computationally expensive for large-scale problems, as they require inverting a large covariance matrix. Kolmogorov- Arnold networks (KANs), semi-parametric neural architectures, have emerged as a prominent approach for modeling complex functions with structured and efficient representations through spline layers. Kurkova Kolmogorov-Arnold networks (KKANs) extend this idea by reducing the number of spline layers in KAN and replacing them with Chebyshev layers and multi-layer perceptrons, thereby mapping inputs into higher-dimensional spaces before applying spline-based transformations. Compared to KANs, KKANs perform more stable convergence during training, making them a strong architecture for estimating operators and system modeling in dynamical systems. By enhancing the KKAN architecture, we develop a novel learning algorithm, distance-aware error for Kurkova-Kolmogorov networks (K-DAREK), for efficient and interpretable function approximation with uncertainty quantification. Our approach establishes robust error bounds that are distance-aware; this means they reflect the proximity of a test point to its nearest training points. Through case studies on a safe control task, we demonstrate that K-DAREK is about four times faster and ten times higher computationally efficiency than Ensemble of KANs, 8.6 times more scalable than GP by increasing the data size, and 50% safer than our previous work distance-aware error for Kolmogorov networks (DAREK).",
        "tags": [
            "KAN"
        ]
    },
    {
        "id": "95",
        "title": "Online Optimization for Offline Safe Reinforcement Learning",
        "author": [
            "Yassine Chemingui",
            "Aryan Deshwal",
            "Alan Fern",
            "Thanh Nguyen-Tang",
            "Janardhan Rao Doppa"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22027",
        "abstract": "We study the problem of Offline Safe Reinforcement Learning (OSRL), where the goal is to learn a reward-maximizing policy from fixed data under a cumulative cost constraint. We propose a novel OSRL approach that frames the problem as a minimax objective and solves it by combining offline RL with online optimization algorithms. We prove the approximate optimality of this approach when integrated with an approximate offline RL oracle and no-regret online optimization. We also present a practical approximation that can be combined with any offline RL algorithm, eliminating the need for offline policy evaluation. Empirical results on the DSRL benchmark demonstrate that our method reliably enforces safety constraints under stringent cost budgets, while achieving high rewards. The code is available at https://github.com/yassineCh/O3SRL.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "96",
        "title": "Penalizing Length: Uncovering Systematic Bias in Quality Estimation Metrics",
        "author": [
            "Yilin Zhang",
            "Wenda Xu",
            "Zhongtao Liu",
            "Tetsuji Nakagawa",
            "Markus Freitag"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22028",
        "abstract": "Quality Estimation (QE) metrics are vital in machine translation for reference-free evaluation and as a reward signal in tasks like reinforcement learning. However, the prevalence and impact of length bias in QE have been underexplored. Through a systematic study of top-performing regression-based and LLM-as-a-Judge QE metrics across 10 diverse language pairs, we reveal two critical length biases: First, QE metrics consistently over-predict errors with increasing translation length, even for high-quality, error-free texts. Second, they exhibit a preference for shorter translations when multiple candidates are available for the same source text. These inherent length biases risk unfairly penalizing longer, correct translations and can lead to sub-optimal decision-making in applications such as QE reranking and QE guided reinforcement learning. To mitigate this, we propose two strategies: (a) applying length normalization during model training, and (b) incorporating reference texts during evaluation. Both approaches were found to effectively reduce the identified length bias.",
        "tags": [
            "LLM",
            "RL"
        ]
    },
    {
        "id": "97",
        "title": "LLM-AR: LLM-powered Automated Reasoning Framework",
        "author": [
            "Rick Chen",
            "Joseph Ternasky",
            "Aaron Ontoyin Yin",
            "Xianling Mu",
            "Fuat Alican",
            "Yigit Ihlamur"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22034",
        "abstract": "Large language models (LLMs) can already identify patterns and reason effectively, yet their variable accuracy hampers adoption in high-stakes decision-making applications. In this paper, we study this issue from a venture capital perspective by predicting idea-stage startup success based on founder traits. (i) To build a reliable prediction model, we introduce LLM-AR, a pipeline inspired by neural-symbolic systems that distils LLM-generated heuristics into probabilistic rules executed by the ProbLog automated-reasoning engine. (ii) An iterative policy-evolution loop incorporates association-rule mining to progressively refine the prediction rules.\nOn unseen folds, LLM-AR achieves 59.5% precision and 8.7% recall, 5.9x the random baseline precision, while exposing every decision path for human inspection. The framework is interpretable and tunable via hyperparameters, showing promise to extend into other domains.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "98",
        "title": "Caption-Driven Explainability: Probing CNNs for Bias via CLIP",
        "author": [
            "Patrick Koller",
            "Amil V. Dravid",
            "Guido M. Schuster",
            "Aggelos K. Katsaggelos"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22035",
        "abstract": "Robustness has become one of the most critical problems in machine learning (ML). The science of interpreting ML models to understand their behavior and improve their robustness is referred to as explainable artificial intelligence (XAI). One of the state-of-the-art XAI methods for computer vision problems is to generate saliency maps. A saliency map highlights the pixel space of an image that excites the ML model the most. However, this property could be misleading if spurious and salient features are present in overlapping pixel spaces. In this paper, we propose a caption-based XAI method, which integrates a standalone model to be explained into the contrastive language-image pre-training (CLIP) model using a novel network surgery approach. The resulting caption-based XAI model identifies the dominant concept that contributes the most to the models prediction. This explanation minimizes the risk of the standalone model falling for a covariate shift and contributes significantly towards developing robust ML models.",
        "tags": [
            "CLIP"
        ]
    },
    {
        "id": "99",
        "title": "Predictive Coding Enhances Meta-RL To Achieve Interpretable Bayes-Optimal Belief Representation Under Partial Observability",
        "author": [
            "Po-Chen Kuo",
            "Han Hou",
            "Will Dabney",
            "Edgar Y. Walker"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22039",
        "abstract": "Learning a compact representation of history is critical for planning and generalization in partially observable environments. While meta-reinforcement learning (RL) agents can attain near Bayes-optimal policies, they often fail to learn the compact, interpretable Bayes-optimal belief states. This representational inefficiency potentially limits the agent's adaptability and generalization capacity. Inspired by predictive coding in neuroscience--which suggests that the brain predicts sensory inputs as a neural implementation of Bayesian inference--and by auxiliary predictive objectives in deep RL, we investigate whether integrating self-supervised predictive coding modules into meta-RL can facilitate learning of Bayes-optimal representations. Through state machine simulation, we show that meta-RL with predictive modules consistently generates more interpretable representations that better approximate Bayes-optimal belief states compared to conventional meta-RL across a wide variety of tasks, even when both achieve optimal policies. In challenging tasks requiring active information seeking, only meta-RL with predictive modules successfully learns optimal representations and policies, whereas conventional meta-RL struggles with inadequate representation learning. Finally, we demonstrate that better representation learning leads to improved generalization. Our results strongly suggest the role of predictive learning as a guiding principle for effective representation learning in agents navigating partial observability.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "100",
        "title": "Emotions Where Art Thou: Understanding and Characterizing the Emotional Latent Space of Large Language Models",
        "author": [
            "Benjamin Reichman",
            "Adar Avsian",
            "Larry Heck"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22042",
        "abstract": "This work investigates how large language models (LLMs) internally represent emotion by analyzing the geometry of their hidden-state space. The paper identifies a low-dimensional emotional manifold and shows that emotional representations are directionally encoded, distributed across layers, and aligned with interpretable dimensions. These structures are stable across depth and generalize to eight real-world emotion datasets spanning five languages. Cross-domain alignment yields low error and strong linear probe performance, indicating a universal emotional subspace. Within this space, internal emotion perception can be steered while preserving semantics using a learned intervention module, with especially strong control for basic emotions across languages. These findings reveal a consistent and manipulable affective geometry in LLMs and offer insight into how they internalize and process emotion.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "101",
        "title": "VLM-SlideEval: Evaluating VLMs on Structured Comprehension and Perturbation Sensitivity in PPT",
        "author": [
            "Hyeonsu Kang",
            "Emily Bao",
            "Anjan Goswami"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22045",
        "abstract": "Vision-language models (VLMs) are increasingly used to evaluate multimodal content, including presentation slides, yet their slide-specific understanding remains underexplored {despite their growing role as critics in agentic, model-forward pipelines}. We introduce VLM-SlideEval, an evaluation framework that probes VLMs along three axes: (1) element-level extraction from slide images aligned to ground truth; (2) robustness to controlled perturbations in geometry, style, and text; and (3) higher-level comprehension, such as recovering a deck's narrative order from shuffled slides. Using publicly available decks from Zenodo (https://huggingface.co/datasets/Forceless/Zenodo10K/viewer/default/pptx), we standardize ground-truth element metadata from PowerPoint XML and live renderings into a unified, verifiable schema. Empirically, VLMs underperform on pixel-accurate extraction and show non-trivial agreement, fidelity, and consistency under controlled perturbations, while performing better on single-slide content understanding; however, they do not reliably capture narrative structure across slides. These results highlight the limits of current VLMs for slide evaluation and motivate calibrated, critic-in-the-loop evaluators that drive iterative refinement and selection in agentic pipelines.",
        "tags": [
            "VLM"
        ]
    },
    {
        "id": "102",
        "title": "Energy-Efficient Domain-Specific Artificial Intelligence Models and Agents: Pathways and Paradigms",
        "author": [
            "Abhijit Chatterjee",
            "Niraj K. Jha",
            "Jonathan D. Cohen",
            "Thomas L. Griffiths",
            "Hongjing Lu",
            "Diana Marculescu",
            "Ashiqur Rasul",
            "Keshab K. Parhi"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22052",
        "abstract": "The field of artificial intelligence (AI) has taken a tight hold on broad aspects of society, industry, business, and governance in ways that dictate the prosperity and might of the world's economies. The AI market size is projected to grow from 189 billion USD in 2023 to 4.8 trillion USD by 2033. Currently, AI is dominated by large language models that exhibit linguistic and visual intelligence. However, training these models requires a massive amount of data scraped from the web as well as large amounts of energy (50--60 GWh to train GPT-4). Despite these costs, these models often hallucinate, a characteristic that prevents them from being deployed in critical application domains. In contrast, the human brain consumes only 20~W of power. What is needed is the next level of AI evolution in which lightweight domain-specific multimodal models with higher levels of intelligence can reason, plan, and make decisions in dynamic environments with real-time data and prior knowledge, while learning continuously and evolving in ways that enhance future decision-making capability. This will define the next wave of AI, progressing from today's large models, trained with vast amounts of data, to nimble energy-efficient domain-specific agents that can reason and think in a world full of uncertainty. To support such agents, hardware will need to be reimagined to allow energy efficiencies greater than 1000x over the state of the art. Such a vision of future AI systems is developed in this work.",
        "tags": [
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "103",
        "title": "Capturing Gaze Shifts for Guidance: Cross-Modal Fusion Enhancement for VLM Hallucination Mitigation",
        "author": [
            "Zheng Qi",
            "Chao Shang",
            "Evangelia Spiliopoulou",
            "Nikolaos Pappas"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22067",
        "abstract": "Vision language models (VLMs) often generate hallucination, i.e., content that cannot be substantiated by either textual or visual inputs. Prior work primarily attributes this to over-reliance on linguistic prior knowledge rather than visual inputs. Some methods attempt to mitigate hallucination by amplifying visual token attention proportionally to their attention scores. However, these methods overlook the visual attention sink problem, where attention is frequently misallocated to task-irrelevant visual regions, and neglect cross-modal fusion balance by enhancing only visual attention without adjusting attention to the user query. This can result in amplifying incorrect areas while failing to properly interpret the user query. To address these challenges, we propose a simple yet effective method called Gaze Shift-Guided Cross-modal Fusion Enhancement (GIFT). GIFT pre-computes a holistic visual saliency map by tracking positive changes in visual attention, or \"gaze shifts\", during user query comprehension, and leverages this map to amplify attention to both salient visual information and the user query at each decoding step. This reduces the impact of visual attention sink, as irrelevant tokens exhibit minimal shifts, while ensuring balanced cross-modal fusion for well-integrated representation. Extensive experiments show that GIFT effectively mitigates hallucination in VLMs across both generative and classification tasks, achieving up to 20.7% improvement over greedy decoding, while maintaining general vision-language performance with low computational overhead.",
        "tags": [
            "VLM"
        ]
    },
    {
        "id": "104",
        "title": "Agentic Reinforcement Learning for Real-World Code Repair",
        "author": [
            "Siyu Zhu",
            "Anastasiya Karpovich",
            "Albert Chen",
            "Jessica Koscheka",
            "Shailesh Jannu",
            "Di Wen",
            "Yuqing Zhu",
            "Rohit Jain",
            "Alborz Geramifard"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22075",
        "abstract": "We tackle the challenge of training reliable code-fixing agents in real repositories, where complex builds and shifting dependencies make evaluation unstable. We developed a verifiable pipeline with success defined as post-fix build validation and improved reproducibility across ~1K real issues by pinning dependencies and disabling automatic upgrades. Building on this, we introduced a scalable simplified pipeline for large-scale reinforcement learning (RL). Using this setup, we supervised fine-tuned Qwen3-32B in the full pipeline and applied RL on top of the SFT model in the simplified environment. The SFT model distilled from GPT-4.1 trajectories performs on par while being 56x smaller, and RL added 7-20% absolute gains under matched train-test conditions. \"Thinking mode\" was on par or worse in our experiments. Both SFT and RL models failed to generalize across environments, highlighting the importance of matching train-test environments for building reliable real-world code-fixing agents.",
        "tags": [
            "GPT",
            "RL"
        ]
    },
    {
        "id": "105",
        "title": "Compositional Bias Control in Large Language Models: Preference Learning Fails, Supervision Succeeds",
        "author": [
            "Atij Mahesh"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22084",
        "abstract": "Large Language Models (LLMs) still produce gender-stereotyped language even in occupation-neutral contexts that reflect deep societal biases (Rudinger et al., 2018). To address this, prior work has proposed prompting, constrained decoding (Dathathri et al., 2020; Zhou et al., 2024), post-processing, and fine-tuning-based alignment (Rafailov et al., 2023; Ravfogel et al., 2022). However, the comparative efficacy and learning dynamics remain little understood. We report a comparative analysis of six control techniques for bias mitigation: prompt-only, generate-and-filter, DFA-based Ctrl-G decoding, Supervised Fine-Tuning (SFT), Direct Preference Optimization (DPO), and Iterative Nullspace Projection (INLP). We evaluate each method on a compositional constraint task. This task requires generating sentences that contain at least one agentic and one communal descriptor for each of the twenty Winogender-derived occupations. We quantify trade-offs between control strength and naturalness with evaluations of constraint compliance, lexical diversity, and fluency. Our results reveal key contrasts among the methods: SFT achieves 99.87 +- 0.15% compliance and high lexical diversity, while DPO, despite similar training stability, fails at 4.53 +- 0.82%. Ctrl-G guarantees perfect compliance, but at the cost of severely reduced fluency and diversity. Preference-based learning fundamentally differs: it cannot satisfy compositional constraints, as binary preference signals encode ranking, not logical conjunctions. Only explicit positive supervision enables mitigation of compositional biases; preference-based alignment fails to generalize logical structures, underscoring the limitations of preference learning and the necessity of explicit supervision for fair and fluent controlled generation.",
        "tags": [
            "DPO",
            "LLM"
        ]
    },
    {
        "id": "106",
        "title": "Jailbreak Mimicry: Automated Discovery of Narrative-Based Jailbreaks for Large Language Models",
        "author": [
            "Pavlos Ntais"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22085",
        "abstract": "Large language models (LLMs) remain vulnerable to sophisticated prompt engineering attacks that exploit contextual framing to bypass safety mechanisms, posing significant risks in cybersecurity applications. We introduce Jailbreak Mimicry, a systematic methodology for training compact attacker models to automatically generate narrative-based jailbreak prompts in a one-shot manner. Our approach transforms adversarial prompt discovery from manual craftsmanship into a reproducible scientific process, enabling proactive vulnerability assessment in AI-driven security systems. Developed for the OpenAI GPT-OSS-20B Red-Teaming Challenge, we use parameter-efficient fine-tuning (LoRA) on Mistral-7B with a curated dataset derived from AdvBench, achieving an 81.0% Attack Success Rate (ASR) against GPT-OSS-20B on a held-out test set of 200 items. Cross-model evaluation reveals significant variation in vulnerability patterns: our attacks achieve 66.5% ASR against GPT-4, 79.5% on Llama-3 and 33.0% against Gemini 2.5 Flash, demonstrating both broad applicability and model-specific defensive strengths in cybersecurity contexts. This represents a 54x improvement over direct prompting (1.5% ASR) and demonstrates systematic vulnerabilities in current safety alignment approaches. Our analysis reveals that technical domains (Cybersecurity: 93% ASR) and deception-based attacks (Fraud: 87.8% ASR) are particularly vulnerable, highlighting threats to AI-integrated threat detection, malware analysis, and secure systems, while physical harm categories show greater resistance (55.6% ASR). We employ automated harmfulness evaluation using Claude Sonnet 4, cross-validated with human expert assessment, ensuring reliable and scalable evaluation for cybersecurity red-teaming. Finally, we analyze failure mechanisms and discuss defensive strategies to mitigate these vulnerabilities in AI for cybersecurity.",
        "tags": [
            "Detection",
            "GPT",
            "LLM",
            "LLaMA",
            "LoRA"
        ]
    },
    {
        "id": "107",
        "title": "QuArch: A Benchmark for Evaluating LLM Reasoning in Computer Architecture",
        "author": [
            "Shvetank Prakash",
            "Andrew Cheng",
            "Arya Tschand",
            "Mark Mazumder",
            "Varun Gohil",
            "Jeffrey Ma",
            "Jason Yik",
            "Zishen Wan",
            "Jessica Quaye",
            "Elisavet Lydia Alvanaki",
            "Avinash Kumar",
            "Chandrashis Mazumdar",
            "Tuhin Khare",
            "Alexander Ingare",
            "Ikechukwu Uchendu",
            "Radhika Ghosal",
            "Abhishek Tyagi",
            "Chenyu Wang",
            "Andrea Mattia Garavagno",
            "Sarah Gu",
            "Alice Guo",
            "Grace Hur",
            "Luca Carloni",
            "Tushar Krishna",
            "Ankita Nayak",
            "Amir Yazdanbakhsh",
            "Vijay Janapa Reddi"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22087",
        "abstract": "The field of computer architecture, which bridges high-level software abstractions and low-level hardware implementations, remains absent from current large language model (LLM) evaluations. To this end, we present QuArch (pronounced 'quark'), the first benchmark designed to facilitate the development and evaluation of LLM knowledge and reasoning capabilities specifically in computer architecture. QuArch provides a comprehensive collection of 2,671 expert-validated question-answer (QA) pairs covering various aspects of computer architecture, including processor design, memory systems, and interconnection networks. Our evaluation reveals that while frontier models possess domain-specific knowledge, they struggle with skills that require higher-order thinking in computer architecture. Frontier model accuracies vary widely (from 34% to 72%) on these advanced questions, highlighting persistent gaps in architectural reasoning across analysis, design, and implementation QAs. By holistically assessing fundamental skills, QuArch provides a foundation for building and measuring LLM capabilities that can accelerate innovation in computing systems. With over 140 contributors from 40 institutions, this benchmark represents a community effort to set the standard for architectural reasoning in LLM evaluation.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "108",
        "title": "Embracing Trustworthy Brain-Agent Collaboration as Paradigm Extension for Intelligent Assistive Technologies",
        "author": [
            "Yankai Chen",
            "Xinni Zhang",
            "Yifei Zhang",
            "Yangning Li",
            "Henry Peng Zou",
            "Chunyu Miao",
            "Weizhi Zhang",
            "Xue Liu",
            "Philip S. Yu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22095",
        "abstract": "Brain-Computer Interfaces (BCIs) offer a direct communication pathway between the human brain and external devices, holding significant promise for individuals with severe neurological impairments. However, their widespread adoption is hindered by critical limitations, such as low information transfer rates and extensive user-specific calibration. To overcome these challenges, recent research has explored the integration of Large Language Models (LLMs), extending the focus from simple command decoding to understanding complex cognitive states. Despite these advancements, deploying agentic AI faces technical hurdles and ethical concerns. Due to the lack of comprehensive discussion on this emerging direction, this position paper argues that the field is poised for a paradigm extension from BCI to Brain-Agent Collaboration (BAC). We emphasize reframing agents as active and collaborative partners for intelligent assistance rather than passive brain signal data processors, demanding a focus on ethical data handling, model reliability, and a robust human-agent collaboration framework to ensure these systems are safe, trustworthy, and effective.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "109",
        "title": "Generalization or Memorization: Dynamic Decoding for Mode Steering",
        "author": [
            "Xuanming Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22099",
        "abstract": "Large Language Models (LLMs) exhibit a troubling duality, capable of both remarkable generalization and brittle, verbatim memorization of their training data. This unpredictability undermines their reliability in high-stakes applications. In this work, we propose a unified framework to understand, identify, and control these distinct reasoning modes. First, we introduce a theoretical model based on the Information Bottleneck (IB) principle, formalizing generalization as the learning of a compressed, task-relevant representation and memorization as a failure to compress. Building on this theory, we develop Dynamic Mode Steering (DMS), a novel inference-time algorithm which comprises two components: (1) a lightweight, causally-grounded linear probe that identifies the model's instantaneous reliance on memorization, and (2) a dynamic activation steering mechanism that nudges the model's computation towards pre-identified generalization circuits. We frame DMS as a form of adaptive, self-contrastive decoding. Experiments on reasoning and faithfulness tasks demonstrate that DMS significantly improves logical consistency and factual accuracy, thereby offering a principled approach to enhancing LLM reliability.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "110",
        "title": "Scaling Up Efficient Small Language Models Serving and Deployment for Semantic Job Search",
        "author": [
            "Kayhan Behdin",
            "Qingquan Song",
            "Sriram Vasudevan",
            "Jian Sheng",
            "Xiaojing Ma",
            "Z Zhou",
            "Chuanrui Zhu",
            "Guoyao Li",
            "Chanh Nguyen",
            "Sayan Ghosh",
            "Hejian Sang",
            "Ata Fatahi Baarzi",
            "Sundara Raman Ramachandran",
            "Xiaoqing Wang",
            "Qing Lan",
            "Vinay Y S",
            "Qi Guo",
            "Caleb Johnson",
            "Zhipeng Wang",
            "Fedor Borisyuk"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22101",
        "abstract": "Large Language Models (LLMs) have demonstrated impressive quality when applied to predictive tasks such as relevance ranking and semantic search. However, deployment of such LLMs remains prohibitively expensive for industry applications with strict latency and throughput requirements. In this work, we present lessons and efficiency insights from developing a purely text-based decoder-only Small Language Model (SLM) for a semantic search application at LinkedIn. Particularly, we discuss model compression techniques such as pruning that allow us to reduce the model size by up to $40\\%$ while maintaining the accuracy. Additionally, we present context compression techniques that allow us to reduce the input context length by up to $10$x with minimal loss of accuracy. Finally, we present practical lessons from optimizing the serving infrastructure for deploying such a system on GPUs at scale, serving millions of requests per second. Taken together, this allows us to increase our system's throughput by $10$x in a real-world deployment, while meeting our quality bar.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "111",
        "title": "Mitigating Coordinate Prediction Bias from Positional Encoding Failures",
        "author": [
            "Xingjian Tao",
            "Yiwei Wang",
            "Yujun Cai",
            "Yihong Luo",
            "Jing Tang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22102",
        "abstract": "Multimodal large language models (MLLMs) excel at vision-language tasks such as VQA and document understanding, yet precise coordinate prediction remains challenging. High-resolution inputs exacerbate this difficulty by producing long token sequences that weaken positional encodings and introduce directional biases in coordinate outputs. We investigate this phenomenon by analyzing how MLLMs behave when visual positional encodings (VPEs) are deliberately perturbed through shuffling. Our analysis reveals that such perturbations induce predictable, non-random coordinate biases rather than random errors, suggesting that models rely on internal positional priors when spatial grounding signals are degraded. Crucially, we observe similar directional error patterns in natural high-resolution datasets, indicating that positional encoding failures are a key bottleneck for accurate coordinate prediction at scale. To address this issue, we propose Vision-PE Shuffle Guidance (VPSG), a training-free test-time method that leverages the directional nature of these biases for correction. VPSG runs auxiliary decoding with shuffled VPEs to isolate position-unconditioned tendencies, then uses this as negative evidence to guide digit prediction while preserving coordinate format through a lightweight finite-state machine. Experiments on ScreenSpot-Pro demonstrate reliable improvements, highlighting positional encoding robustness as a critical factor for spatial reasoning in MLLMs.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "112",
        "title": "Streaming Generation for Music Accompaniment",
        "author": [
            "Yusong Wu",
            "Mason Wang",
            "Heidi Lei",
            "Stephen Brade",
            "Lancelot Blanchard",
            "Shih-Lun Wu",
            "Aaron Courville",
            "Anna Huang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22105",
        "abstract": "Music generation models can produce high-fidelity coherent accompaniment given complete audio input, but are limited to editing and loop-based workflows. We study real-time audio-to-audio accompaniment: as a model hears an input audio stream (e.g., a singer singing), it has to also simultaneously generate in real-time a coherent accompanying stream (e.g., a guitar accompaniment). In this work, we propose a model design considering inevitable system delays in practical deployment with two design variables: future visibility $t_f$, the offset between the output playback time and the latest input time used for conditioning, and output chunk duration $k$, the number of frames emitted per call. We train Transformer decoders across a grid of $(t_f,k)$ and show two consistent trade-offs: increasing effective $t_f$ improves coherence by reducing the recency gap, but requires faster inference to stay within the latency budget; increasing $k$ improves throughput but results in degraded accompaniment due to a reduced update rate. Finally, we observe that naive maximum-likelihood streaming training is insufficient for coherent accompaniment where future context is not available, motivating advanced anticipatory and agentic objectives for live jamming.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "113",
        "title": "STAR-RIS-assisted Collaborative Beamforming for Low-altitude Wireless Networks",
        "author": [
            "Xinyue Liang",
            "Hui Kang",
            "Junwei Che",
            "Jiahui Li",
            "Geng Sun",
            "Qingqing Wu",
            "Jiacheng Wang",
            "Dusit Niyato"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22108",
        "abstract": "While low-altitude wireless networks (LAWNs) based on uncrewed aerial vehicles (UAVs) offer high mobility, flexibility, and coverage for urban communications, they face severe signal attenuation in dense environments due to obstructions. To address this critical issue, we consider introducing collaborative beamforming (CB) of UAVs and omnidirectional reconfigurable beamforming (ORB) of simultaneous transmitting and reflecting reconfigurable intelligent surfaces (STAR-RIS) to enhance the signal quality and directionality. On this basis, we formulate a joint rate and energy optimization problem (JREOP) to maximize the transmission rate of the overall system, while minimizing the energy consumption of the UAV swarm. Due to the non-convex and NP-hard nature of JREOP, we propose a heterogeneous multi-agent collaborative dynamic (HMCD) optimization framework, which has two core components. The first component is a simulated annealing (SA)-based STAR-RIS control method, which dynamically optimizes reflection and transmission coefficients to enhance signal propagation. The second component is an improved multi-agent deep reinforcement learning (MADRL) control method, which incorporates a self-attention evaluation mechanism to capture interactions between UAVs and an adaptive velocity transition mechanism to enhance training stability. Simulation results demonstrate that HMCD outperforms various baselines in terms of convergence speed, average transmission rate, and energy consumption. Further analysis reveals that the average transmission rate of the overall system scales positively with both UAV count and STAR-RIS element numbers.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "114",
        "title": "Gradual Forgetting: Logarithmic Compression for Extending Transformer Context Windows",
        "author": [
            "Billy Dickson",
            "Zoran Tiganj"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22109",
        "abstract": "Most approaches to long-context processing increase the complexity of the transformer's internal architecture by integrating mechanisms such as recurrence or auxiliary memory modules. In this work, we introduce an alternative approach that modifies the input representation itself, rather than the transformer architecture. Inspired by cognitive models of human memory, our method applies a scale-invariant logarithmic compression to the input tokens. The resulting compressed representation is processed by a standard, unmodified transformer, preserving architectural simplicity. We evaluate this approach on the WikiText-103 and PG-19 language modeling benchmarks, showing a reduction in perplexity compared to uncompressed baselines. Moreover, performance improves consistently with longer compressed temporal contexts, showing that input-level logarithmic compression is a simple and effective way to extend a transformer's long-range memory.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "115",
        "title": "RaycastGrasp: Eye-Gaze Interaction with Wearable Devices for Robotic Manipulation",
        "author": [
            "Zitiantao Lin",
            "Yongpeng Sang",
            "Yang Ye"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22113",
        "abstract": "Robotic manipulators are increasingly used to assist individuals with mobility impairments in object retrieval. However, the predominant joystick-based control interfaces can be challenging due to high precision requirements and unintuitive reference frames. Recent advances in human-robot interaction have explored alternative modalities, yet many solutions still rely on external screens or restrictive control schemes, limiting their intuitiveness and accessibility. To address these challenges, we present an egocentric, gaze-guided robotic manipulation interface that leverages a wearable Mixed Reality (MR) headset. Our system enables users to interact seamlessly with real-world objects using natural gaze fixation from a first-person perspective, while providing augmented visual cues to confirm intent and leveraging a pretrained vision model and robotic arm for intent recognition and object manipulation. Experimental results demonstrate that our approach significantly improves manipulation accuracy, reduces system latency, and achieves single-pass intention and object recognition accuracy greater than 88% across multiple real-world scenarios. These results demonstrate the system's effectiveness in enhancing intuitiveness and accessibility, underscoring its practical significance for assistive robotics applications.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "116",
        "title": "Every Activation Boosted: Scaling General Reasoner to 1 Trillion Open Language Foundation",
        "author": [
            "Ling-Team",
            "Ang Li",
            "Ben Liu",
            "Binbin Hu",
            "Bing Li",
            "Bingwei Zeng",
            "Borui Ye",
            "Caizhi Tang",
            "Changxin Tian",
            "Chao Huang",
            "Chao Zhang",
            "Chen Qian",
            "Chenchen Ju",
            "Chenchen Li",
            "Chengfu Tang",
            "Chili Fu",
            "Chunshao Ren",
            "Chunwei Wu",
            "Cong Zhang",
            "Cunyin Peng",
            "Dafeng Xu",
            "Daixin Wang",
            "Dalong Zhang",
            "Dingnan Jin",
            "Dingyuan Zhu",
            "Dongke Hu",
            "Fangzheng Zhao",
            "Feifan Wu",
            "Feng Zhu",
            "Gangshan Wang",
            "Haitao Zhang",
            "Hailin Zhao",
            "Hanxiao Zhang",
            "Hanzi Wang",
            "Hao Qian",
            "Haoyi Yu",
            "Heng Zhang",
            "Hongliang Zhang",
            "Hongzhi Luan",
            "Huirong Dong",
            "Huizhong Li",
            "Jia Li",
            "Jia Liu",
            "Jialong Zhu",
            "Jian Sha",
            "Jianping Wei",
            "Jiaolong Yang",
            "Jieyue Ma",
            "Jiewei Wu",
            "Jinjing Huang",
            "Jingyun Tian",
            "Jingyuan Zhang",
            "Jinquan Sun",
            "Juanhui Tu",
            "Jun Liu",
            "Jun Xu",
            "Jun Zhou",
            "Junjie Ou",
            "Junpeng Fang",
            "Kaihong Zhang",
            "Kaiqin Hu",
            "Ke Shi",
            "Kun Tang",
            "Kunlong Chen",
            "Lanyin Mei",
            "Lei Liang",
            "Lei Xu",
            "Libo Zhang",
            "Lin Ju",
            "Lin Yuan",
            "Ling Zhong",
            "Lintao Ma",
            "Lu Liu",
            "Lu Yu",
            "Lun Cai",
            "Meiqi Zhu",
            "Mengying Li",
            "Min Chen",
            "Minghao Xue",
            "Minghong Cai",
            "Mingming Yin",
            "Peijie Jiang",
            "Peilong Zhao",
            "Pingping Liu",
            "Qian Zhao",
            "Qing Cui",
            "Qingxiang Huang",
            "Qingyuan Yang",
            "Quankun Yu",
            "Shaowei Wei",
            "Shijie Lian",
            "Shoujian Zheng",
            "Shun Song",
            "Shungen Zhang",
            "Shuo Zhang",
            "Siyuan Li",
            "Song Liu",
            "Ting Guo",
            "Tong Zhao",
            "Wanli Gu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22115",
        "abstract": "We introduce Ling 2.0, a series reasoning-oriented language foundation built upon the principle that every activation boosts reasoning capability. Designed to scale from tens of billions to one trillion parameters under a unified Mixture-of-Experts (MoE) paradigm, Ling 2.0 emphasizes high sparsity, cross-scale consistency, and efficiency guided by empirical scaling laws. The series includes three non-thinking (instruct) models - Ling-mini-2.0, Ling-flash-2.0, and Ling-1T - ranging from 16B to 1T total parameters and achieving up to 7-fold active-compute efficiency compared with dense counterparts. Ling 2.0 integrates coordinated innovations across model architecture, pre-training, post-training, and infrastructure: a high-sparsity MoE with MTP for efficient reasoning, reasoning-oriented data and mid-training CoT activation, reinforcement-based fine-tuning (DFT, Evo-CoT), and full-scale FP8 training with fine-grained heterogeneous pipelines. At the trillion scale, Ling-1T establishes a new Pareto frontier of reasoning accuracy versus computational efficiency, demonstrating that sparse activation, when properly aligned with reasoning objectives, enables scalable and efficient intelligence. Collectively, Ling 2.0 provides a coherent, open, and efficient foundation for advancing future reasoning and thinking models, including the Ring series built upon the same base.",
        "tags": [
            "CoT",
            "MoE"
        ]
    },
    {
        "id": "117",
        "title": "GRAID: Enhancing Spatial Reasoning of VLMs Through High-Fidelity Data Generation",
        "author": [
            "Karim Elmaaroufi",
            "Liheng Lai",
            "Justin Svegliato",
            "Yutong Bai",
            "Sanjit A. Seshia",
            "Matei Zaharia"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22118",
        "abstract": "Vision Language Models (VLMs) achieve strong performance on many vision-language tasks but often struggle with spatial reasoning\\textemdash{}a prerequisite for many applications. Empirically, we find that a dataset produced by a current training data generation pipeline has a 57.6\\% human validation rate. These rates stem from current limitations: single-image 3D reconstruction introduces cascading modeling errors and requires wide answer tolerances, while caption-based methods require hyper-detailed annotations and suffer from generative hallucinations. We present GRAID, built on the key insight that qualitative spatial relationships can be reliably determined from 2D geometric primitives alone. By operating exclusively on 2D bounding boxes from standard object detectors, GRAID avoids both 3D reconstruction errors and generative hallucinations, resulting in datasets that are of higher quality than existing tools that produce similar datasets as validated by human evaluations. We apply our framework to the BDD100k, NuImages, and Waymo datasets, generating over 8.5 million high-quality VQA pairs creating questions spanning spatial relations, counting, ranking, and size comparisons. We evaluate one of the datasets and find it achieves 91.16\\% human-validated accuracy\\textemdash{}compared to 57.6\\% on a dataset generated by recent work. % or recent work Critically, we demonstrate that when trained on GRAID data, models learn spatial reasoning concepts that generalize: models fine-tuned on 6 question types improve on over 10 held-out types, with accuracy gains of 47.5\\% on BDD and 37.9\\% on NuImages for Llama 3.2B 11B, and when trained on all questions types, achieve improvements on several existing benchmarks such as BLINK. The GRAID framework, datasets, and additional information can be found on our \\href{https://ke7.github.io/graid/}{project page}.",
        "tags": [
            "3D",
            "LLaMA",
            "VLM"
        ]
    },
    {
        "id": "118",
        "title": "Mint: A Simple Test-Time Adaptation of Vision-Language Models against Common Corruptions",
        "author": [
            "Wenxuan Bao",
            "Ruxi Deng",
            "Jingrui He"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22127",
        "abstract": "Pretrained vision-language models such as CLIP achieve strong zero-shot generalization but remain vulnerable to distribution shifts caused by input corruptions. In this work, we investigate how corruptions affect CLIP's image embeddings and uncover a consistent phenomenon we term as embedding variance collapse, where both intra-class and inter-class variances shrink as corruption severity increases. We find that this collapse is closely tied to performance degradation, with inter-class variance strongly correlated with classification accuracy. To explain this phenomenon, we analyze how corruptions alter the structure of the embedding space. Our theoretical results suggest that the visual encoder tends to encode corruption-related signals, which dilute class-discriminative features and compress the representation geometry. We further show that maximizing inter-class variance, even when estimated from pseudo-labels, can provably enhance embedding quality. Based on this insight, we propose Mint, a simple test-time adaptation method that maximizes pseudo-label-based inter-class variance on the fly using a mean accumulator and a gradient accumulator. Mint operates effectively with small batch sizes and consistently improves performance across multiple corruption benchmarks and CLIP architectures. Our code is available at https://github.com/baowenxuan/Mint .",
        "tags": [
            "CLIP",
            "VLM"
        ]
    },
    {
        "id": "119",
        "title": "What Exactly is a Deepfake?",
        "author": [
            "Yizhi Liu",
            "Balaji Padmanabhan",
            "Siva Viswanathan"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22128",
        "abstract": "Deepfake technologies are often associated with deception, misinformation, and identity fraud, raising legitimate societal concerns. Yet such narratives may obscure a key insight: deepfakes embody sophisticated capabilities for sensory manipulation that can alter human perception, potentially enabling beneficial applications in domains such as healthcare and education. Realizing this potential, however, requires understanding how the technology is conceptualized across disciplines. This paper analyzes 826 peer-reviewed publications from 2017 to 2025 to examine how deepfakes are defined and understood in the literature. Using large language models for content analysis, we categorize deepfake conceptualizations along three dimensions: Identity Source (the relationship between original and generated content), Intent (deceptive versus non-deceptive purposes), and Manipulation Granularity (holistic versus targeted modifications). Results reveal substantial heterogeneity that challenges simplified public narratives. Notably, a subset of studies discuss non-deceptive applications, highlighting an underexplored potential for social good. Temporal analysis shows an evolution from predominantly threat-focused views (2017 to 2019) toward recognition of beneficial applications (2022 to 2025). This study provides an empirical foundation for developing nuanced governance and research frameworks that distinguish applications warranting prohibition from those deserving support, showing that, with safeguards, deepfakes' realism can serve important social purposes beyond deception.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "120",
        "title": "Controllable Mathematical Reasoning via Self-Optimizing Thought Vectors",
        "author": [
            "Xuying LI"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22132",
        "abstract": "We present a novel approach for controllable mathematical reasoning that leverages self-optimizing thought vectors with entropy minimization. Our method introduces learnable thought vectors that dynamically modulate the internal reasoning process of large language models. Using Gemma-2-9B on GSM8K, we achieve 90.1% accuracy with a controllability score of 0.42, demonstrating that entropy-based rewards effectively guide focused reasoning patterns without requiring external reward annotations. Our analysis reveals distinct thought vector clusters and consistent low-entropy distributions across control conditions, validating our framework for controllable AI reasoning.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "121",
        "title": "Edit Less, Achieve More: Dynamic Sparse Neuron Masking for Lifelong Knowledge Editing in LLMs",
        "author": [
            "Jinzhe Liu",
            "Junshu Sun",
            "Shufan Shen",
            "Chenxue Yang",
            "Shuhui Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22139",
        "abstract": "Lifelong knowledge editing enables continuous, precise updates to outdated knowledge in large language models (LLMs) without computationally expensive full retraining. However, existing methods often accumulate errors throughout the editing process, causing a gradual decline in both editing accuracy and generalization. To tackle this problem, we propose Neuron-Specific Masked Knowledge Editing (NMKE), a novel fine-grained editing framework that combines neuron-level attribution with dynamic sparse masking. Leveraging neuron functional attribution, we identify two key types of knowledge neurons, with knowledge-general neurons activating consistently across prompts and knowledge-specific neurons activating to specific prompts. NMKE further introduces an entropy-guided dynamic sparse mask, locating relevant neurons to the target knowledge. This strategy enables precise neuron-level knowledge editing with fewer parameter modifications. Experimental results from thousands of sequential edits demonstrate that NMKE outperforms existing methods in maintaining high editing success rates and preserving model general capabilities in lifelong editing.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "122",
        "title": "STG-Avatar: Animatable Human Avatars via Spacetime Gaussian",
        "author": [
            "Guangan Jiang",
            "Tianzi Zhang",
            "Dong Li",
            "Zhenjun Zhao",
            "Haoang Li",
            "Mingrui Li",
            "Hongyu Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22140",
        "abstract": "Realistic animatable human avatars from monocular videos are crucial for advancing human-robot interaction and enhancing immersive virtual experiences. While recent research on 3DGS-based human avatars has made progress, it still struggles with accurately representing detailed features of non-rigid objects (e.g., clothing deformations) and dynamic regions (e.g., rapidly moving limbs). To address these challenges, we present STG-Avatar, a 3DGS-based framework for high-fidelity animatable human avatar reconstruction. Specifically, our framework introduces a rigid-nonrigid coupled deformation framework that synergistically integrates Spacetime Gaussians (STG) with linear blend skinning (LBS). In this hybrid design, LBS enables real-time skeletal control by driving global pose transformations, while STG complements it through spacetime adaptive optimization of 3D Gaussians. Furthermore, we employ optical flow to identify high-dynamic regions and guide the adaptive densification of 3D Gaussians in these regions. Experimental results demonstrate that our method consistently outperforms state-of-the-art baselines in both reconstruction quality and operational efficiency, achieving superior quantitative metrics while retaining real-time rendering capabilities. Our code is available at https://github.com/jiangguangan/STG-Avatar",
        "tags": [
            "3D",
            "Robotics"
        ]
    },
    {
        "id": "123",
        "title": "LOC: A General Language-Guided Framework for Open-Set 3D Occupancy Prediction",
        "author": [
            "Yuhang Gao",
            "Xiang Xiang",
            "Sheng Zhong",
            "Guoyou Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22141",
        "abstract": "Vision-Language Models (VLMs) have shown significant progress in open-set challenges. However, the limited availability of 3D datasets hinders their effective application in 3D scene understanding. We propose LOC, a general language-guided framework adaptable to various occupancy networks, supporting both supervised and self-supervised learning paradigms. For self-supervised tasks, we employ a strategy that fuses multi-frame LiDAR points for dynamic/static scenes, using Poisson reconstruction to fill voids, and assigning semantics to voxels via K-Nearest Neighbor (KNN) to obtain comprehensive voxel representations. To mitigate feature over-homogenization caused by direct high-dimensional feature distillation, we introduce Densely Contrastive Learning (DCL). DCL leverages dense voxel semantic information and predefined textual prompts. This efficiently enhances open-set recognition without dense pixel-level supervision, and our framework can also leverage existing ground truth to further improve performance. Our model predicts dense voxel features embedded in the CLIP feature space, integrating textual and image pixel information, and classifies based on text and semantic similarity. Experiments on the nuScenes dataset demonstrate the method's superior performance, achieving high-precision predictions for known classes and distinguishing unknown classes without additional training data.",
        "tags": [
            "3D",
            "CLIP",
            "VLM"
        ]
    },
    {
        "id": "124",
        "title": "OlaMind: Towards Human-Like and Hallucination-Safe Customer Service for Retrieval-Augmented Dialogue",
        "author": [
            "Tianhong Gao",
            "Jundong Shen",
            "Bei Shi",
            "Jiapeng Wang",
            "Ying Ju",
            "Junfeng Yao",
            "Jiao Ran",
            "Yong Zhang",
            "Lin Dong",
            "Huiyu Yu",
            "Tingting Ye"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22143",
        "abstract": "Intelligent customer service (ICS) systems via retrieval-augmented generation (RAG) have been widely adopted in Web-based domains such as social platforms and e-commerce, achieving remarkable improvements in automation and efficiency. However, notable limitations still remain: these systems are prone to hallucinations and often generate rigid, mechanical responses, which can introduce business risks and undermine user experience, especially in Web-based customer service interactions under the RAG scenarios. In this paper, we introduce OlaMind, a human-like and hallucination-safe customer service framework for retrieval-augmented dialogue. Specifically, it first leverages a Learn-to-Think stage to learn the reasoning processes and response strategies from human experts, and then employs a Learn-to-Respond stage to perform cold-start supervised fine-tuning (SFT) combined with reinforcement learning (RL) for basic-to-hard self-refinement. Our method significantly enhances human-likeness and naturalness while effectively mitigating hallucinations and critical business risks. We have conducted large-scale online A/B experiments in an industry-level social customer service setting, and extensive experimental results show that OlaMind achieves significant cumulative relative improvements with intelligent resolution rates +28.92%/+18.42% and human takeover rate -6.08%/-7.12% in community-support/livestream-interaction scenarios, respectively, which highlights its consistent effectiveness across diverse real-world applications. The code and data will be publicly available.",
        "tags": [
            "RAG",
            "RL"
        ]
    },
    {
        "id": "125",
        "title": "Solving Continuous Mean Field Games: Deep Reinforcement Learning for Non-Stationary Dynamics",
        "author": [
            "Lorenzo Magnino",
            "Kai Shao",
            "Zida Wu",
            "Jiacheng Shen",
            "Mathieu LauriÃ¨re"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22158",
        "abstract": "Mean field games (MFGs) have emerged as a powerful framework for modeling interactions in large-scale multi-agent systems. Despite recent advancements in reinforcement learning (RL) for MFGs, existing methods are typically limited to finite spaces or stationary models, hindering their applicability to real-world problems. This paper introduces a novel deep reinforcement learning (DRL) algorithm specifically designed for non-stationary continuous MFGs. The proposed approach builds upon a Fictitious Play (FP) methodology, leveraging DRL for best-response computation and supervised learning for average policy representation. Furthermore, it learns a representation of the time-dependent population distribution using a Conditional Normalizing Flow. To validate the effectiveness of our method, we evaluate it on three different examples of increasing complexity. By addressing critical limitations in scalability and density approximation, this work represents a significant advancement in applying DRL techniques to complex MFG problems, bringing the field closer to real-world multi-agent systems.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "126",
        "title": "SentiMaithili: A Benchmark Dataset for Sentiment and Reason Generation for the Low-Resource Maithili Language",
        "author": [
            "Rahul Ranjan",
            "Mahendra Kumar Gurve",
            "Anuj",
            "Nitin",
            "Yamuna Prasad"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22160",
        "abstract": "Developing benchmark datasets for low-resource languages poses significant challenges, primarily due to the limited availability of native linguistic experts and the substantial time and cost involved in annotation. Given these challenges, Maithili is still underrepresented in natural language processing research. It is an Indo-Aryan language spoken by more than 13 million people in the Purvanchal region of India, valued for its rich linguistic structure and cultural significance. While sentiment analysis has achieved remarkable progress in high-resource languages, resources for low-resource languages, such as Maithili, remain scarce, often restricted to coarse-grained annotations and lacking interpretability mechanisms. To address this limitation, we introduce a novel dataset comprising 3,221 Maithili sentences annotated for sentiment polarity and accompanied by natural language justifications. Moreover, the dataset is carefully curated and validated by linguistic experts to ensure both label reliability and contextual fidelity. Notably, the justifications are written in Maithili, thereby promoting culturally grounded interpretation and enhancing the explainability of sentiment models. Furthermore, extensive experiments using both classical machine learning and state-of-the-art transformer architectures demonstrate the dataset's effectiveness for interpretable sentiment analysis. Ultimately, this work establishes the first benchmark for explainable affective computing in Maithili, thus contributing a valuable resource to the broader advancement of multilingual NLP and explainable AI.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "127",
        "title": "Surface Reading LLMs: Synthetic Text and its Styles",
        "author": [
            "Hannes Bajohr"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22162",
        "abstract": "Despite a potential plateau in ML advancement, the societal impact of large language models lies not in approaching superintelligence but in generating text surfaces indistinguishable from human writing. While Critical AI Studies provides essential material and socio-technical critique, it risks overlooking how LLMs phenomenologically reshape meaning-making. This paper proposes a semiotics of \"surface integrity\" as attending to the immediate plane where LLMs inscribe themselves into human communication. I distinguish three knowledge interests in ML research (epistemology, epistÄmÄ, and epistemics) and argue for integrating surface-level stylistic analysis alongside depth-oriented critique. Through two case studies examining stylistic markers of synthetic text, I argue how attending to style as a semiotic phenomenon reveals LLMs as cultural actors that transform the conditions of meaning emergence and circulation in contemporary discourse, independent of questions about machine consciousness.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "128",
        "title": "HARMONY: Hidden Activation Representations and Model Output-Aware Uncertainty Estimation for Vision-Language Models",
        "author": [
            "Erum Mushtaq",
            "Zalan Fabian",
            "Yavuz Faruk Bakman",
            "Anil Ramakrishna",
            "Mahdi Soltanolkotabi",
            "Salman Avestimehr"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22171",
        "abstract": "The growing deployment of Vision-Language Models (VLMs) in high-stakes applications such as autonomous driving and assistive technologies for visually impaired individuals necessitates reliable mechanisms to assess the trustworthiness of their generation. Uncertainty Estimation (UE) plays a central role in quantifying the reliability of model outputs and reducing unsafe generations via selective prediction. In this regard, most existing probability-based UE approaches rely on output probability distributions, aggregating token probabilities into a single uncertainty score using predefined functions such as length-normalization. Another line of research leverages model hidden representations and trains MLP-based models to predict uncertainty. However, these methods often fail to capture the complex multimodal relationships between semantic and textual tokens and struggle to identify biased probabilities often influenced by language priors. Motivated by these observations, we propose a novel UE framework, HARMONY, that jointly leverages fused multimodal information in model activations and the output distribution of the VLM to determine the reliability of responses. The key hypothesis of our work is that both the model's internal belief in its visual understanding, captured by its hidden representations, and the produced token probabilities carry valuable reliability signals that can be jointly leveraged to improve UE performance, surpassing approaches that rely on only one of these components. Experimental results on three open-ended VQA benchmarks, A-OKVQA, VizWiz, and PathVQA, and three state-of-the-art VLMs, LLaVa-7b, LLaVA-13b and InstructBLIP demonstrate that our method consistently performs on par with or better than existing approaches, achieving up to 4\\% improvement in AUROC, and 6\\% in PRR, establishing new state of the art in uncertainty estimation for VLMs.",
        "tags": [
            "LLaVA",
            "VLM"
        ]
    },
    {
        "id": "129",
        "title": "Dopamine-driven synaptic credit assignment in neural networks",
        "author": [
            "Saranraj Nambusubramaniyan",
            "Shervin Safavi",
            "Raja Guru",
            "Andreas Knoblauch"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22178",
        "abstract": "Solving the synaptic Credit Assignment Problem(CAP) is central to learning in both biological and artificial neural systems. Finding an optimal solution for synaptic CAP means setting the synaptic weights that assign credit to each neuron for influencing the final output and behavior of neural networks or animals. Gradient-based methods solve this problem in artificial neural networks using back-propagation, however, not in the most efficient way. For instance, back-propagation requires a chain of top-down gradient computations. This leads to an expensive optimization process in terms of computing power and memory linked with well-known weight transport and update locking problems. To address these shortcomings, we take a NeuroAI approach and draw inspiration from neural Reinforcement Learning to develop a derivative-free optimizer for training neural networks, Dopamine. Dopamine is developed for Weight Perturbation (WP) learning that exploits stochastic updating of weights towards optima. It achieves this by minimizing the regret, a form of Reward Prediction Error (RPE) between the expected outcome from the perturbed model and the actual outcome from the unperturbed model. We use this RPE to adjust the learning rate in the network (i.e., creating an adaptive learning rate strategy, similar to the role of dopamine in the brain). We tested the Dopamine optimizer for training multi-layered perceptrons for XOR tasks, and recurrent neural networks for chaotic time series forecasting. Dopamine-trained models demonstrate accelerated convergence and outperform standard WP, and give comparable performance to gradient-based algorithms, while consuming significantly less computation and memory. Overall, the Dopamine optimizer not only finds robust solutions and comparable performance to the state-of-the-art Machine Learning optimizers but is also neurobiologically more plausible.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "130",
        "title": "OptiTree: Hierarchical Thoughts Generation with Tree Search for LLM Optimization Modeling",
        "author": [
            "Haoyang Liu",
            "Jie Wang",
            "Yuyang Cai",
            "Xiongwei Han",
            "Yufei Kuang",
            "Jianye Hao"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22192",
        "abstract": "Optimization modeling is one of the most crucial but technical parts of operations research (OR). To automate the modeling process, existing works have leveraged large language models (LLMs), prompting them to break down tasks into steps for generating variables, constraints, and objectives. However, due to the highly complex mathematical structures inherent in OR problems, standard fixed-step decomposition often fails to achieve high performance. To address this challenge, we introduce OptiTree, a novel tree search approach designed to enhance modeling capabilities for complex problems through adaptive problem decomposition into simpler subproblems. Specifically, we develop a modeling tree that organizes a wide range of OR problems based on their hierarchical problem taxonomy and complexity, with each node representing a problem category and containing relevant high-level modeling thoughts. Given a problem to model, we recurrently search the tree to identify a series of simpler subproblems and synthesize the global modeling thoughts by adaptively integrating the hierarchical thoughts. Experiments show that OptiTree significantly improves the modeling accuracy compared to the state-of-the-art, achieving over 10\\% improvements on the challenging benchmarks. The code is released at https://github.com/MIRALab-USTC/OptiTree/tree/main.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "131",
        "title": "(Approximate) Matrix Multiplication via Convolutions",
        "author": [
            "Kevin Pratt",
            "Yahel Uffenheimer",
            "Omri Weinstein"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22193",
        "abstract": "A longstanding open question in algorithm design is whether \"combinatorial\" matrix multiplication algorithms -- avoiding Strassen-like divide-and-conquer -- can achieve truly subcubic runtime $n^{3-\\delta}$. We present an $O(n^{2.89})$-time exact algorithm, which only sums convolutions in $\\mathbb{Z}_m^k$ (multivariate polynomial multiplications) via FFT, building on the work of Cohn, Kleinberg, Szegedy and Umans (CKSU'05). While the algorithm avoids recursion, the asymptotic speedup arises only for impractically large matrices.\nMotivated by practical applications, we use this baseline to develop a new framework for fast approximate matrix multiplication (AMM), via low-degree approximations of the CKSU polynomials. We show that combining the aforementioned algorithm with black-box linear sketching already breaks the longstanding linear speed-accuracy tradeoff for AMM (Sarlos'06, Clarkson-Woodruff'13 ,Pagh'11, Cohn-Lewis'00), achieving $\\frac{1}{r^{1.1}}\\|\\mathbf{A}\\|_F^2\\|\\mathbf{B}\\|_F^2$ error in $O(rn^2)$-time.\nOur main result is a low-degree approximation scheme for the CKSU polynomials, based on a Fourier-concentration lemma, yielding substantially smaller error in the distributional setting where $\\mathbf{A},\\mathbf{B}$ come from an i.i.d product-distribution; For random Gaussian matrices, this practical AMM algorithm attains smaller error than the best rank-$r$ SVD of the output matrix $\\mathbf{A}\\mathbf{B}$, in time $O(rn^2)$. This is a substantial improvement over iterative Krylov subspace methods for low-rank approximation. Our theoretical and empirical results suggest the possibility of replacing MatMuls with sums of convolutions in LLM training and inference.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "132",
        "title": "Multi-dataset Joint Pre-training of Emotional EEG Enables Generalizable Affective Computing",
        "author": [
            "Qingzhu Zhang",
            "Jiani Zhong",
            "Zongsheng Li",
            "Xinke Shen",
            "Quanying Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22197",
        "abstract": "Task-specific pre-training is essential when task representations diverge from generic pre-training features. Existing task-general pre-training EEG models struggle with complex tasks like emotion recognition due to mismatches between task-specific features and broad pre-training approaches. This work aims to develop a task-specific multi-dataset joint pre-training framework for cross-dataset emotion recognition, tackling problems of large inter-dataset distribution shifts, inconsistent emotion category definitions, and substantial inter-subject variability. We introduce a cross-dataset covariance alignment loss to align second-order statistical properties across datasets, enabling robust generalization without the need for extensive labels or per-subject calibration. To capture the long-term dependency and complex dynamics of EEG, we propose a hybrid encoder combining a Mamba-like linear attention channel encoder and a spatiotemporal dynamics model. Our method outperforms state-of-the-art large-scale EEG models by an average of 4.57% in AUROC for few-shot emotion recognition and 11.92% in accuracy for zero-shot generalization to a new dataset. Performance scales with the increase of datasets used in pre-training. Multi-dataset joint pre-training achieves a performance gain of 8.55% over single-dataset training. This work provides a scalable framework for task-specific pre-training and highlights its benefit in generalizable affective computing. Our code is available at https://github.com/ncclab-sustech/mdJPT_nips2025.",
        "tags": [
            "Mamba"
        ]
    },
    {
        "id": "133",
        "title": "MOGRAS: Human Motion with Grasping in 3D Scenes",
        "author": [
            "Kunal Bhosikar",
            "Siddharth Katageri",
            "Vivek Madhavaram",
            "Kai Han",
            "Charu Sharma"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22199",
        "abstract": "Generating realistic full-body motion interacting with objects is critical for applications in robotics, virtual reality, and human-computer interaction. While existing methods can generate full-body motion within 3D scenes, they often lack the fidelity for fine-grained tasks like object grasping. Conversely, methods that generate precise grasping motions typically ignore the surrounding 3D scene. This gap, generating full-body grasping motions that are physically plausible within a 3D scene, remains a significant challenge. To address this, we introduce MOGRAS (Human MOtion with GRAsping in 3D Scenes), a large-scale dataset that bridges this gap. MOGRAS provides pre-grasping full-body walking motions and final grasping poses within richly annotated 3D indoor scenes. We leverage MOGRAS to benchmark existing full-body grasping methods and demonstrate their limitations in scene-aware generation. Furthermore, we propose a simple yet effective method to adapt existing approaches to work seamlessly within 3D scenes. Through extensive quantitative and qualitative experiments, we validate the effectiveness of our dataset and highlight the significant improvements our proposed method achieves, paving the way for more realistic human-scene interactions.",
        "tags": [
            "3D",
            "Robotics"
        ]
    },
    {
        "id": "134",
        "title": "LongCat-Video Technical Report",
        "author": [
            "Meituan LongCat Team",
            "Xunliang Cai",
            "Qilong Huang",
            "Zhuoliang Kang",
            "Hongyu Li",
            "Shijun Liang",
            "Liya Ma",
            "Siyu Ren",
            "Xiaoming Wei",
            "Rixu Xie",
            "Tong Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22200",
        "abstract": "Video generation is a critical pathway toward world models, with efficient long video inference as a key capability. Toward this end, we introduce LongCat-Video, a foundational video generation model with 13.6B parameters, delivering strong performance across multiple video generation tasks. It particularly excels in efficient and high-quality long video generation, representing our first step toward world models. Key features include: Unified architecture for multiple tasks: Built on the Diffusion Transformer (DiT) framework, LongCat-Video supports Text-to-Video, Image-to-Video, and Video-Continuation tasks with a single model; Long video generation: Pretraining on Video-Continuation tasks enables LongCat-Video to maintain high quality and temporal coherence in the generation of minutes-long videos; Efficient inference: LongCat-Video generates 720p, 30fps videos within minutes by employing a coarse-to-fine generation strategy along both the temporal and spatial axes. Block Sparse Attention further enhances efficiency, particularly at high resolutions; Strong performance with multi-reward RLHF: Multi-reward RLHF training enables LongCat-Video to achieve performance on par with the latest closed-source and leading open-source models. Code and model weights are publicly available to accelerate progress in the field.",
        "tags": [
            "DiT",
            "Diffusion",
            "RLHF",
            "Text-to-Video",
            "Transformer",
            "Video Generation"
        ]
    },
    {
        "id": "135",
        "title": "ACG: Action Coherence Guidance for Flow-based VLA models",
        "author": [
            "Minho Park",
            "Kinam Kim",
            "Junha Hyung",
            "Hyojin Jang",
            "Hoiyeong Jin",
            "Jooyeol Yun",
            "Hojoon Lee",
            "Jaegul Choo"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22201",
        "abstract": "Diffusion and flow matching models have emerged as powerful robot policies, enabling Vision-Language-Action (VLA) models to generalize across diverse scenes and instructions. Yet, when trained via imitation learning, their high generative capacity makes them sensitive to noise in human demonstrations: jerks, pauses, and jitter which reduce action coherence. Reduced action coherence causes instability and trajectory drift during deployment, failures that are catastrophic in fine-grained manipulation where precision is crucial. In this paper, we present Action Coherence Guidance (ACG) for VLA models, a training-free test-time guidance algorithm that improves action coherence and thereby yields performance gains. Evaluated on RoboCasa, DexMimicGen, and real-world SO-101 tasks, ACG consistently improves action coherence and boosts success rates across diverse manipulation tasks. Code and project page are available at https://github.com/DAVIAN-Robotics/ACG and https://DAVIAN-Robotics.github.io/ACG , respectively.",
        "tags": [
            "Diffusion",
            "Flow Matching",
            "Robotics"
        ]
    },
    {
        "id": "136",
        "title": "Bridging Perception and Reasoning: Dual-Pipeline Neuro-Symbolic Landing for UAVs in Cluttered Environments",
        "author": [
            "Weixian Qian",
            "Sebastian Schroder",
            "Yao Deng",
            "Jiaohong Yao",
            "Linfeng Liang",
            "Xiao Cheng",
            "Richard Han",
            "Xi Zheng"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22204",
        "abstract": "Autonomous landing in unstructured (cluttered, uneven, and map-poor) environments is a core requirement for Unmanned Aerial Vehicles (UAVs), yet purely vision-based or deep learning models often falter under covariate shift and provide limited interpretability. We propose NeuroSymLand, a neuro-symbolic framework that tightly couples two complementary pipelines: (i) an offline pipeline, where Large Language Models (LLMs) and human-in-the-loop refinement synthesize Scallop code from diverse landing scenarios, distilling generalizable and verifiable symbolic knowledge; and (ii) an online pipeline, where a compact foundation-based semantic segmentation model generates probabilistic Scallop facts that are composed into semantic scene graphs for real-time deductive reasoning. This design combines the perceptual strengths of lightweight foundation models with the interpretability and verifiability of symbolic reasoning. Node attributes (e.g., flatness, area) and edge relations (adjacency, containment, proximity) are computed with geometric routines rather than learned, avoiding the data dependence and latency of train-time graph builders. The resulting Scallop program encodes landing principles (avoid water and obstacles; prefer large, flat, accessible regions) and yields calibrated safety scores with ranked Regions of Interest (ROIs) and human-readable justifications. Extensive evaluations across datasets, diverse simulation maps, and real UAV hardware show that NeuroSymLand achieves higher accuracy, stronger robustness to covariate shift, and superior efficiency compared with state-of-the-art baselines, while advancing UAV safety and reliability in emergency response, surveillance, and delivery missions.",
        "tags": [
            "LLM",
            "Segmentation"
        ]
    },
    {
        "id": "137",
        "title": "TrajGATFormer: A Graph-Based Transformer Approach for Worker and Obstacle Trajectory Prediction in Off-site Construction Environments",
        "author": [
            "Mohammed Alduais",
            "Xinming Li",
            "Qipei Mei"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22205",
        "abstract": "As the demand grows within the construction industry for processes that are not only faster but also safer and more efficient, offsite construction has emerged as a solution, though it brings new safety risks due to the close interaction between workers, machinery, and moving obstacles. Predicting the future trajectories of workers and taking into account social and environmental factors is a crucial step for developing collision-avoidance systems to mitigate such risks. Traditional methods often struggle to adapt to the dynamic and unpredictable nature of construction environments. Many rely on simplified assumptions or require hand-crafted features, limiting their ability to respond to complex, real-time interactions between workers and moving obstacles. While recent data-driven methods have improved the modeling of temporal patterns, they still face challenges in capturing long-term behavior and accounting for the spatial and social context crucial to collision risk assessment. To address these limitations, this paper proposes a framework integrating YOLOv10n and DeepSORT for precise detection and tracking, along with two novel trajectory prediction models: TrajGATFormer and TrajGATFormer-Obstacle. YOLOv10n serves as the backbone for object detection, accurately identifying workers and obstacles in diverse scenes, while DeepSORT efficiently tracks them over time with unique IDs for continuity. Both models employ a transformer encoder-decoder with Graph Attention Networks (GAT) to capture temporal and spatial interactions. TrajGATFormer predicts worker trajectories with an ADE of 1.25 m and FDE of 2.3 m over a 4.8 s horizon, while TrajGATFormer-Obstacle extends prediction to both workers and obstacles, achieving higher accuracy (ADE 1.15 m, FDE 2.2 m). Comparative analysis shows both models outperform traditional methods, reducing ADE and FDE by up to 35% and 38%, respectively.",
        "tags": [
            "Detection",
            "Transformer"
        ]
    },
    {
        "id": "138",
        "title": "The Lossy Horizon: Error-Bounded Predictive Coding for Lossy Text Compression (Episode I)",
        "author": [
            "Nnamdi Aghanya",
            "Jun Li",
            "Kewei Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22207",
        "abstract": "Large Language Models (LLMs) can achieve near-optimal lossless compression by acting as powerful probability models. We investigate their use in the lossy domain, where reconstruction fidelity is traded for higher compression ratios. This paper introduces Error-Bounded Predictive Coding (EPC), a lossy text codec that leverages a Masked Language Model (MLM) as a decompressor. Instead of storing a subset of original tokens, EPC allows the model to predict masked content and stores minimal, rank-based corrections only when the model's top prediction is incorrect. This creates a residual channel that offers continuous rate-distortion control. We compare EPC to a simpler Predictive Masking (PM) baseline and a transform-based Vector Quantisation with a Residual Patch (VQ+RE) approach. Through an evaluation that includes precise bit accounting and rate-distortion analysis, we demonstrate that EPC consistently dominates PM, offering superior fidelity at a significantly lower bit rate by more efficiently utilising the model's intrinsic knowledge.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "139",
        "title": "Simplifying Knowledge Transfer in Pretrained Models",
        "author": [
            "Siddharth Jain",
            "Shyamgopal Karthik",
            "Vineet Gandhi"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22208",
        "abstract": "Pretrained models are ubiquitous in the current deep learning landscape, offering strong results on a broad range of tasks. Recent works have shown that models differing in various design choices exhibit categorically diverse generalization behavior, resulting in one model grasping distinct data-specific insights unavailable to the other. In this paper, we propose to leverage large publicly available model repositories as an auxiliary source of model improvements. We introduce a data partitioning strategy where pretrained models autonomously adopt either the role of a student, seeking knowledge, or that of a teacher, imparting knowledge. Experiments across various tasks demonstrate the effectiveness of our proposed approach. In image classification, we improved the performance of ViT-B by approximately 1.4% through bidirectional knowledge transfer with ViT-T. For semantic segmentation, our method boosted all evaluation metrics by enabling knowledge transfer both within and across backbone architectures. In video saliency prediction, our approach achieved a new state-of-the-art. We further extend our approach to knowledge transfer between multiple models, leading to considerable performance improvements for all model participants.",
        "tags": [
            "Segmentation",
            "ViT"
        ]
    },
    {
        "id": "140",
        "title": "LSPRAG: LSP-Guided RAG for Language-Agnostic Real-Time Unit Test Generation",
        "author": [
            "Gwihwan Go",
            "Quan Zhang",
            "Chijin Zhou",
            "Zhao Wei",
            "Yu Jiang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22210",
        "abstract": "Automated unit test generation is essential for robust software development, yet existing approaches struggle to generalize across multiple programming languages and operate within real-time development. While Large Language Models (LLMs) offer a promising solution, their ability to generate high coverage test code depends on prompting a concise context of the focal method. Current solutions, such as Retrieval-Augmented Generation, either rely on imprecise similarity-based searches or demand the creation of costly, language-specific static analysis pipelines. To address this gap, we present LSPRAG, a framework for concise-context retrieval tailored for real-time, language-agnostic unit test generation. LSPRAG leverages off-the-shelf Language Server Protocol (LSP) back-ends to supply LLMs with precise symbol definitions and references in real time. By reusing mature LSP servers, LSPRAG provides an LLM with language-aware context retrieval, requiring minimal per-language engineering effort. We evaluated LSPRAG on open-source projects spanning Java, Go, and Python. Compared to the best performance of baselines, LSPRAG increased line coverage by up to 174.55% for Golang, 213.31% for Java, and 31.57% for Python.",
        "tags": [
            "LLM",
            "RAG"
        ]
    },
    {
        "id": "141",
        "title": "DETECT: Determining Ease and Textual Clarity of German Text Simplifications",
        "author": [
            "Maria Korobeynikova",
            "Alessia Battisti",
            "Lukas Fischer",
            "Yingqiang Gao"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22212",
        "abstract": "Current evaluation of German automatic text simplification (ATS) relies on general-purpose metrics such as SARI, BLEU, and BERTScore, which insufficiently capture simplification quality in terms of simplicity, meaning preservation, and fluency. While specialized metrics like LENS have been developed for English, corresponding efforts for German have lagged behind due to the absence of human-annotated corpora. To close this gap, we introduce DETECT, the first German-specific metric that holistically evaluates ATS quality across all three dimensions of simplicity, meaning preservation, and fluency, and is trained entirely on synthetic large language model (LLM) responses. Our approach adapts the LENS framework to German and extends it with (i) a pipeline for generating synthetic quality scores via LLMs, enabling dataset creation without human annotation, and (ii) an LLM-based refinement step for aligning grading criteria with simplification requirements. To the best of our knowledge, we also construct the largest German human evaluation dataset for text simplification to validate our metric directly. Experimental results show that DETECT achieves substantially higher correlations with human judgments than widely used ATS metrics, with particularly strong gains in meaning preservation and fluency. Beyond ATS, our findings highlight both the potential and the limitations of LLMs for automatic evaluation and provide transferable guidelines for general language accessibility tasks.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "142",
        "title": "DynamicTree: Interactive Real Tree Animation via Sparse Voxel Spectrum",
        "author": [
            "Yaokun Li",
            "Lihe Ding",
            "Xiao Chen",
            "Guang Tan",
            "Tianfan Xue"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22213",
        "abstract": "Generating dynamic and interactive 3D objects, such as trees, has wide applications in virtual reality, games, and world simulation. Nevertheless, existing methods still face various challenges in generating realistic 4D motion for complex real trees. In this paper, we propose DynamicTree, the first framework that can generate long-term, interactive animation of 3D Gaussian Splatting trees. Unlike prior optimization-based methods, our approach generates dynamics in a fast feed-forward manner. The key success of our approach is the use of a compact sparse voxel spectrum to represent the tree movement. Given a 3D tree from Gaussian Splatting reconstruction, our pipeline first generates mesh motion using the sparse voxel spectrum and then binds Gaussians to deform the mesh. Additionally, the proposed sparse voxel spectrum can also serve as a basis for fast modal analysis under external forces, allowing real-time interactive responses. To train our model, we also introduce 4DTree, the first large-scale synthetic 4D tree dataset containing 8,786 animated tree meshes with semantic labels and 100-frame motion sequences. Extensive experiments demonstrate that our method achieves realistic and responsive tree animations, significantly outperforming existing approaches in both visual quality and computational efficiency.",
        "tags": [
            "3D",
            "Gaussian Splatting"
        ]
    },
    {
        "id": "143",
        "title": "Estimating the Error of Large Language Models at Pairwise Text Comparison",
        "author": [
            "Tianyi Li"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22219",
        "abstract": "We measure LLMs' output error at pairwise text comparison, noting the probability of error in their preferences. Our method does not rely on the ground truth and supports two scenarios: (i) uniform error rate regardless of the order of comparison, estimated with two comparisons for each text pair with either text placed first; (ii) binary positional bias assuming distinct error rates for the two orders of comparison, estimated with repeated comparisons between the texts. The Copeland counting constructs a ranking over the compared texts from pairwise preferences; the ranking reveals the poor scalability of LLM-based pairwise comparison and helps yield the estimates for LLMs' error rates. We apply the method to six LLMs (ChatGPT, Claude, DeepSeek, Gemini, Grok, Qwen) with five types of text input and obtain consistent estimates of LLMs' error. In general, the measured two positional bias terms are similar, close to the uniform error. Considering both the error rates and the robustness to the variation of prompts, Claude obtained the most desirable performance in this experiment. Our model outperforms the biased Bradley-Terry model and the commutativity score in indicating LLMs' error at this task.",
        "tags": [
            "DeepSeek",
            "GPT",
            "LLM",
            "Qwen"
        ]
    },
    {
        "id": "144",
        "title": "When Fewer Layers Break More Chains: Layer Pruning Harms Test-Time Scaling in LLMs",
        "author": [
            "Keyu Wang",
            "Tian Lyu",
            "Guinan Su",
            "Jonas Geiping",
            "Lu Yin",
            "Marco Canini",
            "Shiwei Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22228",
        "abstract": "Layer pruning has emerged as a widely adopted technique for improving the efficiency of large language models (LLMs). Although existing methods demonstrate strong performance retention on general knowledge tasks, their effect on long-chain reasoning, a more brittle yet crucial capability, remains largely unexplored. In this work, we study the impact of layer pruning on long-chain reasoning through the lens of test-time scaling, a key mechanism in modern LLMs that enables strong reasoning capacity by allocating more computation at inference time. With extensive experiments, we demonstrate that pruning even one or two layers can severely impair test-time scaling, with performance collapsing drastically on long reasoning benchmarks even when performance on knowledge-intensive and shallow reasoning tasks remains stable. Furthermore, we find that standard supervised fine-tuning remedies fail to recover test-time scaling once it has deteriorated. Through in-depth analyses, we identify the mechanisms underlying this fragility of test-time scaling and highlight the fundamental risks of applying layer pruning to reasoning-intensive LLMs. These findings call for a rethinking of layer pruning strategies and provide insights for developing methods that preserve the robustness of reasoning. We open-source the codebase in \\href{https://github.com/keyu-wang-2002/Layer-Pruning-Harms-Inference-Scaling}{https://github.com/keyu-wang-2002/Layer-Pruning-Harms-Inference-Scaling}.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "145",
        "title": "Diffusion-Driven Two-Stage Active Learning for Low-Budget Semantic Segmentation",
        "author": [
            "Jeongin Kim",
            "Wonho Bae",
            "YouLee Han",
            "Giyeong Oh",
            "Youngjae Yu",
            "Danica J. Sutherland",
            "Junhyug Noh"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22229",
        "abstract": "Semantic segmentation demands dense pixel-level annotations, which can be prohibitively expensive - especially under extremely constrained labeling budgets. In this paper, we address the problem of low-budget active learning for semantic segmentation by proposing a novel two-stage selection pipeline. Our approach leverages a pre-trained diffusion model to extract rich multi-scale features that capture both global structure and fine details. In the first stage, we perform a hierarchical, representation-based candidate selection by first choosing a small subset of representative pixels per image using MaxHerding, and then refining these into a diverse global pool. In the second stage, we compute an entropy-augmented disagreement score (eDALD) over noisy multi-scale diffusion features to capture both epistemic uncertainty and prediction confidence, selecting the most informative pixels for annotation. This decoupling of diversity and uncertainty lets us achieve high segmentation accuracy with only a tiny fraction of labeled pixels. Extensive experiments on four benchmarks (CamVid, ADE-Bed, Cityscapes, and Pascal-Context) demonstrate that our method significantly outperforms existing baselines under extreme pixel-budget regimes. Our code is available at https://github.com/jn-kim/two-stage-edald.",
        "tags": [
            "Diffusion",
            "Segmentation"
        ]
    },
    {
        "id": "146",
        "title": "Robust MIMO Channel Estimation Using Energy-Based Generative Diffusion Models",
        "author": [
            "Ziqi Diao",
            "Xingyu Zhou",
            "Le Liang",
            "Shi Jin"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22230",
        "abstract": "Channel estimation for massive multiple-input multiple-output (MIMO) systems is fundamentally constrained by excessive pilot overhead and high estimation latency. To overcome these obstacles, recent studies have leveraged deep generative networks to capture the prior distribution of wireless channels. In this paper, we propose a novel estimation framework that integrates an energy-based generative diffusion model (DM) with the Metropolis-Hastings (MH) principle. By reparameterizing the diffusion process with an incorporated energy function, the framework explicitly estimates the unnormalized log-prior, while MH corrections refine the sampling trajectory, mitigate deviations, and enhance robustness, ultimately enabling accurate posterior sampling for high-fidelity channel estimation. Numerical results reveal that the proposed approach significantly improves estimation accuracy compared with conventional parameterized DMs and other baseline methods, particularly in cases with limited pilot overhead.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "147",
        "title": "CGoT: A Novel Inference Mechanism for Embodied Multi-Agent Systems Using Composable Graphs of Thoughts",
        "author": [
            "Yixiao Nie",
            "Yang Zhang",
            "Yingjie Jin",
            "Zhepeng Wang",
            "Xiu Li",
            "Xiang Li"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22235",
        "abstract": "The integration of self-driving cars and service robots is becoming increasingly prevalent across a wide array of fields, playing a crucial and expanding role in both industrial applications and everyday life. In parallel, the rapid advancements in Large Language Models (LLMs) have garnered substantial attention and interest within the research community. This paper introduces a novel vehicle-robot system that leverages the strengths of both autonomous vehicles and service robots. In our proposed system, two autonomous ego-vehicles transports service robots to locations within an office park, where they perform a series of tasks. The study explores the feasibility and potential benefits of incorporating LLMs into this system, with the aim of enhancing operational efficiency and maximizing the potential of the cooperative mechanisms between the vehicles and the robots. This paper proposes a novel inference mechanism which is called CGOT toward this type of system where an agent can carry another agent. Experimental results are presented to validate the performance of the proposed method.",
        "tags": [
            "LLM",
            "Robotics"
        ]
    },
    {
        "id": "148",
        "title": "DiffusionLane: Diffusion Model for Lane Detection",
        "author": [
            "Kunyang Zhou",
            "Yeqin Shao"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22236",
        "abstract": "In this paper, we present a novel diffusion-based model for lane detection, called DiffusionLane, which treats the lane detection task as a denoising diffusion process in the parameter space of the lane. Firstly, we add the Gaussian noise to the parameters (the starting point and the angle) of ground truth lanes to obtain noisy lane anchors, and the model learns to refine the noisy lane anchors in a progressive way to obtain the target lanes. Secondly, we propose a hybrid decoding strategy to address the poor feature representation of the encoder, resulting from the noisy lane anchors. Specifically, we design a hybrid diffusion decoder to combine global-level and local-level decoders for high-quality lane anchors. Then, to improve the feature representation of the encoder, we employ an auxiliary head in the training stage to adopt the learnable lane anchors for enriching the supervision on the encoder. Experimental results on four benchmarks, Carlane, Tusimple, CULane, and LLAMAS, show that DiffusionLane possesses a strong generalization ability and promising detection performance compared to the previous state-of-the-art methods. For example, DiffusionLane with ResNet18 surpasses the existing methods by at least 1\\% accuracy on the domain adaptation dataset Carlane. Besides, DiffusionLane with MobileNetV4 gets 81.32\\% F1 score on CULane, 96.89\\% accuracy on Tusimple with ResNet34, and 97.59\\% F1 score on LLAMAS with ResNet101. Code will be available at https://github.com/zkyntu/UnLanedet.",
        "tags": [
            "Detection",
            "Diffusion"
        ]
    },
    {
        "id": "149",
        "title": "PaperAsk: A Benchmark for Reliability Evaluation of LLMs in Paper Search and Reading",
        "author": [
            "Yutao Wu",
            "Xiao Liu",
            "Yunhao Feng",
            "Jiale Ding",
            "Xingjun Ma"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22242",
        "abstract": "Large Language Models (LLMs) increasingly serve as research assistants, yet their reliability in scholarly tasks remains under-evaluated. In this work, we introduce PaperAsk, a benchmark that systematically evaluates LLMs across four key research tasks: citation retrieval, content extraction, paper discovery, and claim verification. We evaluate GPT-4o, GPT-5, and Gemini-2.5-Flash under realistic usage conditions-via web interfaces where search operations are opaque to the user. Through controlled experiments, we find consistent reliability failures: citation retrieval fails in 48-98% of multi-reference queries, section-specific content extraction fails in 72-91% of cases, and topical paper discovery yields F1 scores below 0.32, missing over 60% of relevant literature. Further human analysis attributes these failures to the uncontrolled expansion of retrieved context and the tendency of LLMs to prioritize semantically relevant text over task instructions. Across basic tasks, the LLMs display distinct failure behaviors: ChatGPT often withholds responses rather than risk errors, whereas Gemini produces fluent but fabricated answers. To address these issues, we develop lightweight reliability classifiers trained on PaperAsk data to identify unreliable outputs. PaperAsk provides a reproducible and diagnostic framework for advancing the reliability evaluation of LLM-based scholarly assistance systems.",
        "tags": [
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "150",
        "title": "Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet with the CGRA4ML Framework",
        "author": [
            "Amir Mohammad Khadem Hosseini",
            "Sattar Mirzakuchaki"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22243",
        "abstract": "Semantic segmentation has emerged as a fundamental problem in computer vision, gaining particular importance in real-time applications such as autonomous driving. The main challenge is achieving high accuracy while operating under computational and hardware constraints. In this research, we present an FPGA-based implementation of real-time semantic segmentation leveraging the lightweight LMIINet architecture and the Coarse-Grained Reconfigurable Array for Machine Learning (CGRA4ML) hardware framework. The model was trained using Quantization-Aware Training (QAT) with 8-bit precision on the Cityscapes dataset, reducing memory footprint by a factor of four while enabling efficient fixed-point computations. Necessary modifications were applied to adapt the model to CGRA4ML constraints, including simplifying skip connections, employing hardware-friendly operations such as depthwise-separable and 1A-1 convolutions, and redesigning parts of the Flatten Transformer. Our implementation achieves approximately 90% pixel accuracy and 45% mean Intersection-over-Union (mIoU), operating in real-time at 20 frames per second (FPS) with 50.1 ms latency on the ZCU104 FPGA board. The results demonstrate the potential of CGRA4ML, with its flexibility in mapping modern layers and off-chip memory utilization for skip connections, provides a path for implementing advanced semantic segmentation networks on FPGA for real-time applications to outperform traditional GPU solutions in terms of power efficiency while maintaining competitive accuracy. The code for this project is publicly available at https://github.com/STAmirr/ cgra4ml_semantic_segmentation",
        "tags": [
            "Segmentation",
            "Transformer"
        ]
    },
    {
        "id": "151",
        "title": "You Don't Need Prompt Engineering Anymore: The Prompting Inversion",
        "author": [
            "Imran Khan"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22251",
        "abstract": "Prompt engineering, particularly Chain-of-Thought (CoT) prompting, significantly enhances LLM reasoning capabilities. We introduce \"Sculpting,\" a constrained, rule-based prompting method designed to improve upon standard CoT by reducing errors from semantic ambiguity and flawed common sense.\nWe evaluate three prompting strategies (Zero Shot, standard CoT, and Sculpting) across three OpenAI model generations (gpt-4o-mini, gpt-4o, gpt-5) using the GSM8K mathematical reasoning benchmark (1,317 problems).\nOur findings reveal a \"Prompting Inversion\": Sculpting provides advantages on gpt-4o (97% vs. 93% for standard CoT), but becomes detrimental on gpt-5 (94.00% vs. 96.36% for CoT on full benchmark). We trace this to a \"Guardrail-to-Handcuff\" transition where constraints preventing common-sense errors in mid-tier models induce hyper-literalism in advanced models. Our detailed error analysis demonstrates that optimal prompting strategies must co-evolve with model capabilities, suggesting simpler prompts for more capable models.",
        "tags": [
            "CoT",
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "152",
        "title": "PACR: Progressively Ascending Confidence Reward for LLM Reasoning",
        "author": [
            "Eunseop Yoon",
            "Hee Suk Yoon",
            "Jaehyun Jang",
            "SooHwan Eom",
            "Qi Dai",
            "Chong Luo",
            "Mark A. Hasegawa-Johnson",
            "Chang D. Yoo"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22255",
        "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR) has significantly improved LLM reasoning, but its sparse, outcome-based reward provides no guidance for intermediate steps, slowing exploration. We propose Progressively Ascending Confidence Reward (PACR), a dense, model-intrinsic reward computed directly from the model's evolving belief in the correct answer. PACR encodes the inductive bias that, along a well-formed reasoning trajectory, the probability of the ground-truth answer should have a generally ascending trend. We provide empirical and theoretical analysis validating that such an inductive bias constrains the exploration search space to regions richer in logically sound reasoning. We demonstrate that PACR accelerates exploration, reaches reward saturation with fewer trajectories, and yields improvements on multiple benchmarks. Our results suggest that dense, model-intrinsic shaping signals can make RLVR training more effective and reliable.",
        "tags": [
            "LLM",
            "RL"
        ]
    },
    {
        "id": "153",
        "title": "SteerX: Disentangled Steering for LLM Personalization",
        "author": [
            "Xiaoyan Zhao",
            "Ming Yan",
            "Yilun Qiu",
            "Haoting Ni",
            "Yang Zhang",
            "Fuli Feng",
            "Hong Cheng",
            "Tat-Seng Chua"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22256",
        "abstract": "Large language models (LLMs) have shown remarkable success in recent years, enabling a wide range of applications, including intelligent assistants that support users' daily life and work. A critical factor in building such assistants is personalizing LLMs, as user preferences and needs vary widely. Activation steering, which directly leverages directions representing user preference in the LLM activation space to adjust its behavior, offers a cost-effective way to align the model's outputs with individual users. However, existing methods rely on all historical data to compute the steering vector, ignoring that not all content reflects true user preferences, which undermines the personalization signal. To address this, we propose SteerX, a disentangled steering method that isolates preference-driven components from preference-agnostic components. Grounded in causal inference theory, SteerX estimates token-level causal effects to identify preference-driven tokens, transforms these discrete signals into a coherent description, and then leverages them to steer personalized LLM generation. By focusing on the truly preference-driven information, SteerX produces more accurate activation steering vectors and enhances personalization. Experiments on two representative steering backbone methods across real-world datasets demonstrate that SteerX consistently enhances steering vector quality, offering a practical solution for more effective LLM personalization.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "154",
        "title": "LUNA: Efficient and Topology-Agnostic Foundation Model for EEG Signal Analysis",
        "author": [
            "Berkay DÃ¶ner",
            "Thorir Mar Ingolfsson",
            "Luca Benini",
            "Yawei Li"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22257",
        "abstract": "Electroencephalography (EEG) offers a non-invasive lens into human brain activity, but building large-scale models is hampered by topological heterogeneity: each public EEG data defines its own electrode layout, limiting generalization. We introduce LUNA (Latent Unified Network Architecture), a self-supervised foundation model that reconciles disparate electrode geometries while scaling linearly -- not quadratically -- with channel count. LUNA compresses multi-channel EEG into a fixed-size, topology-agnostic latent space via learned queries and cross-attention. Downstream transformer blocks then operate exclusively on this latent representation using patch-wise temporal self-attention, decoupling computation from electrode count. Pre-trained on TUEG and Siena (over 21,000 hours of raw EEG across diverse montages) using a masked-patch reconstruction objective, LUNA transfers effectively to four downstream tasks: abnormality detection, artifact rejection, slowing classification, and emotion recognition. It demonstrates highly competitive performance across several benchmarks, achieving state-of-the-art results on TUAR and TUSL, e.g., 0.921 AUROC on TUAR, while reducing FLOPs by 300x and trimming GPU memory use by up to 10x. Critically, these gains are consistent across all evaluated electrode configurations. Code is available at https://github.com/pulp-bio/BioFoundation",
        "tags": [
            "Detection",
            "Transformer"
        ]
    },
    {
        "id": "155",
        "title": "Accident Anticipation via Temporal Occurrence Prediction",
        "author": [
            "Tianhao Zhao",
            "Yiyang Zou",
            "Zihao Mao",
            "Peilun Xiao",
            "Yulin Huang",
            "Hongda Yang",
            "Yuxuan Li",
            "Qun Li",
            "Guobin Wu",
            "Yutian Lin"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22260",
        "abstract": "Accident anticipation aims to predict potential collisions in an online manner, enabling timely alerts to enhance road safety. Existing methods typically predict frame-level risk scores as indicators of hazard. However, these approaches rely on ambiguous binary supervision (labeling all frames in accident videos as positive) despite the fact that risk varies continuously over time, leading to unreliable learning and false alarms. To address this, we propose a novel paradigm that shifts the prediction target from current-frame risk scoring to directly estimating accident scores at multiple future time steps (e.g., 0.1s-2.0s ahead), leveraging precisely annotated accident timestamps as supervision. Our method employs a snippet-level encoder to jointly model spatial and temporal dynamics, and a Transformer-based temporal decoder that predicts accident scores for all future horizons simultaneously using dedicated temporal queries. Furthermore, we introduce a refined evaluation protocol that reports Time-to-Accident (TTA) and recall (evaluated at multiple pre-accident intervals (0.5s, 1.0s, and 1.5s)) only when the false alarm rate (FAR) remains within an acceptable range, ensuring practical relevance. Experiments show that our method achieves superior performance in both recall and TTA under realistic FAR constraints.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "156",
        "title": "Epistemic Deep Learning: Enabling Machine Learning Models to Know When They Do Not Know",
        "author": [
            "Shireen Kudukkil Manchingal"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22261",
        "abstract": "Machine learning has achieved remarkable successes, yet its deployment in safety-critical domains remains hindered by an inherent inability to manage uncertainty, resulting in overconfident and unreliable predictions when models encounter out-of-distribution data, adversarial perturbations, or naturally fluctuating environments. This thesis, titled Epistemic Deep Learning: Enabling Machine Learning Models to 'Know When They Do Not Know', addresses these critical challenges by advancing the paradigm of Epistemic Artificial Intelligence, which explicitly models and quantifies epistemic uncertainty: the uncertainty arising from limited, biased, or incomplete training data, as opposed to the irreducible randomness of aleatoric uncertainty, thereby empowering models to acknowledge their limitations and refrain from overconfident decisions when uncertainty is high.\nCentral to this work is the development of the Random-Set Neural Network (RS-NN), a novel methodology that leverages random set theory to predict belief functions over sets of classes, capturing the extent of epistemic uncertainty through the width of associated credal sets, applications of RS-NN, including its adaptation to Large Language Models (LLMs) and its deployment in weather classification for autonomous racing. In addition, the thesis proposes a unified evaluation framework for uncertainty-aware classifiers. Extensive experiments validate that integrating epistemic awareness into deep learning not only mitigates the risks associated with overconfident predictions but also lays the foundation for a paradigm shift in artificial intelligence, where the ability to 'know when it does not know' becomes a hallmark of robust and dependable systems. The title encapsulates the core philosophy of this work, emphasizing that true intelligence involves recognizing and managing the limits of one's own knowledge.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "157",
        "title": "From Slides to Chatbots: Enhancing Large Language Models with University Course Materials",
        "author": [
            "Tu Anh Dinh",
            "Philipp Nicolas Schumacher",
            "Jan Niehues"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22272",
        "abstract": "Large Language Models (LLMs) have advanced rapidly in recent years. One application of LLMs is to support student learning in educational settings. However, prior work has shown that LLMs still struggle to answer questions accurately within university-level computer science courses. In this work, we investigate how incorporating university course materials can enhance LLM performance in this setting. A key challenge lies in leveraging diverse course materials such as lecture slides and transcripts, which differ substantially from typical textual corpora: slides also contain visual elements like images and formulas, while transcripts contain spoken, less structured language. We compare two strategies, Retrieval-Augmented Generation (RAG) and Continual Pre-Training (CPT), to extend LLMs with course-specific knowledge. For lecture slides, we further explore a multi-modal RAG approach, where we present the retrieved content to the generator in image form. Our experiments reveal that, given the relatively small size of university course materials, RAG is more effective and efficient than CPT. Moreover, incorporating slides as images in the multi-modal setting significantly improves performance over text-only retrieval. These findings highlight practical strategies for developing AI assistants that better support learning and teaching, and we hope they inspire similar efforts in other educational contexts.",
        "tags": [
            "LLM",
            "RAG"
        ]
    },
    {
        "id": "158",
        "title": "WAON: Large-Scale and High-Quality Japanese Image-Text Pair Dataset for Vision-Language Models",
        "author": [
            "Issa Sugiura",
            "Shuhei Kurita",
            "Yusuke Oda",
            "Daisuke Kawahara",
            "Yasuo Okabe",
            "Naoaki Okazaki"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22276",
        "abstract": "Large-scale and high-quality image-text pair datasets play an important role in developing high-performing Vision-Language Models (VLMs). In this work, we introduce WAON, a large-scale and high-quality Japanese image-text pair dataset containing approximately 155 million examples, collected from Common Crawl. Our dataset construction pipeline employs various techniques, including filtering and deduplication, which have been shown to be effective in previous studies. To evaluate its effectiveness, we also construct WAON-Bench, a manually curated benchmark for Japanese cultural image classification, consisting of 374 classes. To assess the effectiveness of our dataset, we conduct experiments using both WAON and the Japanese subset of ReLAION, one of the most widely used vision-language datasets. We fine-tune SigLIP2, a strong multilingual model, on both datasets. The results demonstrate that WAON enhances model performance on WAON-Bench more efficiently than ReLAION and achieves higher accuracy across all evaluated benchmarks. Furthermore, the model fine-tuned on WAON achieves state-of-the-art performance on several Japanese cultural benchmarks. We release our dataset, model, and code at https://speed1313.github.io/WAON.",
        "tags": [
            "VLM"
        ]
    },
    {
        "id": "159",
        "title": "The AI Tutor in Engineering Education: Design, Results, and Redesign of an Experience in Hydrology at an Argentine University",
        "author": [
            "Hugo Roger Paz"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22279",
        "abstract": "The emergence of Generative Artificial Intelligence (GenAI) has reshaped higher education, presenting both opportunities and ethical-pedagogical challenges. This article presents an empirical case study on the complete cycle (design, initial failure, redesign, and re-evaluation) of an intervention using an AI Tutor (ChatGPT) in the \"Hydrology and Hydraulic Works\" course (Civil Engineering, UTN-FRT, Argentina). The study documents two interventions in the same cohort (n=23). The first resulted in widespread failure (0% pass rate) due to superficial use and serious academic integrity issues (65% similarity, copies > 80%). This failure forced a comprehensive methodological redesign. The second intervention, based on a redesigned prompt (Prompt V2) with strict evidence controls (mandatory Appendix A with exported chat, minimum time $\\geq$ 120 minutes, verifiable numerical exercise) and a refined rubric (Rubric V2), showed significantly better results: a median score of 88/100 and verifiable compliance with genuine interaction processes. Using a mixed-methods approach (reproducible document analysis and rubric analysis), the impact of the redesign on integrity and technical performance is evaluated. The results demonstrate that, without explicit process controls, students prioritize efficiency over deep learning, submitting documents without real traceability. A transferable assessment protocol for STEM courses is proposed, centered on \"auditable personal zones,\" to foster higher-order thinking. The study provides key empirical evidence from the context of a public Latin American university.",
        "tags": [
            "GPT"
        ]
    },
    {
        "id": "160",
        "title": "CityRiSE: Reasoning Urban Socio-Economic Status in Vision-Language Models via Reinforcement Learning",
        "author": [
            "Tianhui Liu",
            "Hetian Pang",
            "Xin Zhang",
            "Jie Feng",
            "Yong Li",
            "Pan Hui"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22282",
        "abstract": "Harnessing publicly available, large-scale web data, such as street view and satellite imagery, urban socio-economic sensing is of paramount importance for achieving global sustainable development goals. With the emergence of Large Vision-Language Models (LVLMs), new opportunities have arisen to solve this task by treating it as a multi-modal perception and understanding problem. However, recent studies reveal that LVLMs still struggle with accurate and interpretable socio-economic predictions from visual data. To address these limitations and maximize the potential of LVLMs, we introduce \\textbf{CityRiSE}, a novel framework for \\textbf{R}eason\\textbf{i}ng urban \\textbf{S}ocio-\\textbf{E}conomic status in LVLMs through pure reinforcement learning (RL). With carefully curated multi-modal data and verifiable reward design, our approach guides the LVLM to focus on semantically meaningful visual cues, enabling structured and goal-oriented reasoning for generalist socio-economic status prediction. Experiments demonstrate that CityRiSE with emergent reasoning process significantly outperforms existing baselines, improving both prediction accuracy and generalization across diverse urban contexts, particularly for prediction on unseen cities and unseen indicators. This work highlights the promise of combining RL and LVLMs for interpretable and generalist urban socio-economic sensing.",
        "tags": [
            "RL",
            "VLM"
        ]
    },
    {
        "id": "161",
        "title": "Hybrid Instructor Ai Assessment In Academic Projects: Efficiency, Equity, And Methodological Lessons",
        "author": [
            "Hugo Roger Paz"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22286",
        "abstract": "In technical subjects characterized by high enrollment, such as Basic Hydraulics, the assessment of reports necessitates superior levels of objectivity, consistency, and formative feedback; goals often compromised by faculty workload. This study presents the implementation of a generative artificial intelligence (AI) assisted assessment system, supervised by instructors, to grade 33 hydraulics reports. The central objective was to quantify its impact on the efficiency, quality, and fairness of the process. The employed methodology included the calibration of the Large Language Model (LLM) with a detailed rubric, the batch processing of assignments, and a human-in-the-loop validation phase. The quantitative results revealed a noteworthy 88% reduction in grading time (from 50 to 6 minutes per report, including verification) and a 733% increase in productivity. The quality of feedback was substantially improved, evidenced by 100% rubric coverage and a 150% increase in the anchoring of comments to textual evidence. The system proved to be equitable, exhibiting no bias related to report length, and highly reliable post-calibration (r = 0.96 between scores). It is concluded that the hybrid AI-instructor model optimizes the assessment process, thereby liberating time for high-value pedagogical tasks and enhancing the fairness and quality of feedback, in alignment with UNESCO's principles on the ethical use of AI in education.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "162",
        "title": "T2I-RiskyPrompt: A Benchmark for Safety Evaluation, Attack, and Defense on Text-to-Image Model",
        "author": [
            "Chenyu Zhang",
            "Tairen Zhang",
            "Lanjun Wang",
            "Ruidong Chen",
            "Wenhui Li",
            "Anan Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22300",
        "abstract": "Using risky text prompts, such as pornography and violent prompts, to test the safety of text-to-image (T2I) models is a critical task. However, existing risky prompt datasets are limited in three key areas: 1) limited risky categories, 2) coarse-grained annotation, and 3) low effectiveness. To address these limitations, we introduce T2I-RiskyPrompt, a comprehensive benchmark designed for evaluating safety-related tasks in T2I models. Specifically, we first develop a hierarchical risk taxonomy, which consists of 6 primary categories and 14 fine-grained subcategories. Building upon this taxonomy, we construct a pipeline to collect and annotate risky prompts. Finally, we obtain 6,432 effective risky prompts, where each prompt is annotated with both hierarchical category labels and detailed risk reasons. Moreover, to facilitate the evaluation, we propose a reason-driven risky image detection method that explicitly aligns the MLLM with safety annotations. Based on T2I-RiskyPrompt, we conduct a comprehensive evaluation of eight T2I models, nine defense methods, five safety filters, and five attack strategies, offering nine key insights into the strengths and limitations of T2I model safety. Finally, we discuss potential applications of T2I-RiskyPrompt across various research fields. The dataset and code are provided in https://github.com/datar001/T2I-RiskyPrompt.",
        "tags": [
            "Detection",
            "Text-to-Image"
        ]
    },
    {
        "id": "163",
        "title": "LacMaterial: Large Language Models as Analogical Chemists for Materials Discovery",
        "author": [
            "Hongyu Guo"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22312",
        "abstract": "Analogical reasoning, the transfer of relational structures across contexts (e.g., planet is to sun as electron is to nucleus), is fundamental to scientific discovery. Yet human insight is often constrained by domain expertise and surface-level biases, limiting access to deeper, structure-driven analogies both within and across disciplines. Large language models (LLMs), trained on vast cross-domain data, present a promising yet underexplored tool for analogical reasoning in science. Here, we demonstrate that LLMs can generate novel battery materials by (1) retrieving cross-domain analogs and analogy-guided exemplars to steer exploration beyond conventional dopant substitutions, and (2) constructing in-domain analogical templates from few labeled examples to guide targeted exploitation. These explicit analogical reasoning strategies yield candidates outside established compositional spaces and outperform standard prompting baselines. Our findings position LLMs as interpretable, expert-like hypothesis generators that leverage analogy-driven generalization for scientific innovation.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "164",
        "title": "Memory-based Language Models: An Efficient, Explainable, and Eco-friendly Approach to Large Language Modeling",
        "author": [
            "Antal van den Bosch",
            "Ainhoa Risco PatÃ³n",
            "Teun Buijse",
            "Peter Berck",
            "Maarten van Gompel"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22317",
        "abstract": "We present memory-based language modeling as an efficient, eco-friendly alternative to deep neural network-based language modeling. It offers log-linearly scalable next-token prediction performance and strong memorization capabilities. Implementing fast approximations of k-nearest neighbor classification, memory-based language modeling leaves a relatively small ecological footprint both in training and in inference mode, as it relies fully on CPUs and attains low token latencies. Its internal workings are simple and fully transparent. We compare our implementation of memory-based language modeling, OLIFANT, with GPT-2 and GPT-Neo on next-token prediction accuracy, estimated emissions and speeds, and offer some deeper analyses of the model.",
        "tags": [
            "GPT"
        ]
    },
    {
        "id": "165",
        "title": "Harnessing the Power of Large Language Models for Software Testing Education: A Focus on ISTQB Syllabus",
        "author": [
            "Tuan-Phong Ngo",
            "Bao-Ngoc Duong",
            "Tuan-Anh Hoang",
            "Joshua Dwight",
            "Ushik Shrestha Khwakhali"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22318",
        "abstract": "Software testing is a critical component in the software engineering field and is important for software engineering education. Thus, it is vital for academia to continuously improve and update educational methods to reflect the current state of the field. The International Software Testing Qualifications Board (ISTQB) certification framework is globally recognized and widely adopted in industry and academia. However, ISTQB-based learning has been rarely applied with recent generative artificial intelligence advances. Despite the growing capabilities of large language models (LLMs), ISTQB-based learning and instruction with LLMs have not been thoroughly explored. This paper explores and evaluates how LLMs can complement the ISTQB framework for higher education. The findings present four key contributions: (i) the creation of a comprehensive ISTQB-aligned dataset spanning over a decade, consisting of 28 sample exams and 1,145 questions; (ii) the development of a domain-optimized prompt that enhances LLM precision and explanation quality on ISTQB tasks; (iii) a systematic evaluation of state-of-the-art LLMs on this dataset; and (iv) actionable insights and recommendations for integrating LLMs into software testing education. These findings highlight the promise of LLMs in supporting ISTQB certification preparation and offer a foundation for their broader use in software engineering at higher education.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "166",
        "title": "GRPO-Guard: Mitigating Implicit Over-Optimization in Flow Matching via Regulated Clipping",
        "author": [
            "Jing Wang",
            "Jiajun Liang",
            "Jie Liu",
            "Henglin Liu",
            "Gongye Liu",
            "Jun Zheng",
            "Wanyuan Pang",
            "Ao Ma",
            "Zhenyu Xie",
            "Xintao Wang",
            "Meng Wang",
            "Pengfei Wan",
            "Xiaodan Liang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22319",
        "abstract": "Recently, GRPO-based reinforcement learning has shown remarkable progress in optimizing flow-matching models, effectively improving their alignment with task-specific rewards. Within these frameworks, the policy update relies on importance-ratio clipping to constrain overconfident positive and negative gradients. However, in practice, we observe a systematic shift in the importance-ratio distribution-its mean falls below 1 and its variance differs substantially across timesteps. This left-shifted and inconsistent distribution prevents positive-advantage samples from entering the clipped region, causing the mechanism to fail in constraining overconfident positive updates. As a result, the policy model inevitably enters an implicit over-optimization stage-while the proxy reward continues to increase, essential metrics such as image quality and text-prompt alignment deteriorate sharply, ultimately making the learned policy impractical for real-world use. To address this issue, we introduce GRPO-Guard, a simple yet effective enhancement to existing GRPO frameworks. Our method incorporates ratio normalization, which restores a balanced and step-consistent importance ratio, ensuring that PPO clipping properly constrains harmful updates across denoising timesteps. In addition, a gradient reweighting strategy equalizes policy gradients over noise conditions, preventing excessive updates from particular timestep regions. Together, these designs act as a regulated clipping mechanism, stabilizing optimization and substantially mitigating implicit over-optimization without relying on heavy KL regularization. Extensive experiments on multiple diffusion backbones (e.g., SD3.5M, Flux.1-dev) and diverse proxy tasks demonstrate that GRPO-Guard significantly reduces over-optimization while maintaining or even improving generation quality.",
        "tags": [
            "Diffusion",
            "FLUX",
            "Flow Matching",
            "GRPO",
            "PPO",
            "RL"
        ]
    },
    {
        "id": "167",
        "title": "Transformer Key-Value Memories Are Nearly as Interpretable as Sparse Autoencoders",
        "author": [
            "Mengyu Ye",
            "Jun Suzuki",
            "Tatsuro Inaba",
            "Tatsuki Kuribayashi"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22332",
        "abstract": "Recent interpretability work on large language models (LLMs) has been increasingly dominated by a feature-discovery approach with the help of proxy modules. Then, the quality of features learned by, e.g., sparse auto-encoders (SAEs), is evaluated. This paradigm naturally raises a critical question: do such learned features have better properties than those already represented within the original model parameters, and unfortunately, only a few studies have made such comparisons systematically so far. In this work, we revisit the interpretability of feature vectors stored in feed-forward (FF) layers, given the perspective of FF as key-value memories, with modern interpretability benchmarks. Our extensive evaluation revealed that SAE and FFs exhibits a similar range of interpretability, although SAEs displayed an observable but minimal improvement in some aspects. Furthermore, in certain aspects, surprisingly, even vanilla FFs yielded better interpretability than the SAEs, and features discovered in SAEs and FFs diverged. These bring questions about the advantage of SAEs from both perspectives of feature quality and faithfulness, compared to directly interpreting FF feature vectors, and FF key-value parameters serve as a strong baseline in modern interpretability research.",
        "tags": [
            "LLM",
            "Transformer"
        ]
    },
    {
        "id": "168",
        "title": "LIFT: Interpretable truck driving risk prediction with literature-informed fine-tuned LLMs",
        "author": [
            "Xiao Hu",
            "Yuansheng Lian",
            "Ke Zhang",
            "Yunxuan Li",
            "Yuelong Su",
            "Meng Li"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22333",
        "abstract": "This study proposes an interpretable prediction framework with literature-informed fine-tuned (LIFT) LLMs for truck driving risk prediction. The framework integrates an LLM-driven Inference Core that predicts and explains truck driving risk, a Literature Processing Pipeline that filters and summarizes domain-specific literature into a literature knowledge base, and a Result Evaluator that evaluates the prediction performance as well as the interpretability of the LIFT LLM. After fine-tuning on a real-world truck driving risk dataset, the LIFT LLM achieved accurate risk prediction, outperforming benchmark models by 26.7% in recall and 10.1% in F1-score. Furthermore, guided by the literature knowledge base automatically constructed from 299 domain papers, the LIFT LLM produced variable importance ranking consistent with that derived from the benchmark model, while demonstrating robustness in interpretation results to various data sampling conditions. The LIFT LLM also identified potential risky scenarios by detecting key combination of variables in truck driving risk, which were verified by PERMANOVA tests. Finally, we demonstrated the contribution of the literature knowledge base and the fine-tuning process in the interpretability of the LIFT LLM, and discussed the potential of the LIFT LLM in data-driven knowledge discovery.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "169",
        "title": "GeoDiffusion: A Training-Free Framework for Accurate 3D Geometric Conditioning in Image Generation",
        "author": [
            "Phillip Mueller",
            "Talip Uenlue",
            "Sebastian Schmidt",
            "Marcel Kollovieh",
            "Jiajie Fan",
            "Stephan Guennemann",
            "Lars Mikelsons"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22337",
        "abstract": "Precise geometric control in image generation is essential for engineering \\& product design and creative industries to control 3D object features accurately in image space. Traditional 3D editing approaches are time-consuming and demand specialized skills, while current image-based generative methods lack accuracy in geometric conditioning. To address these challenges, we propose GeoDiffusion, a training-free framework for accurate and efficient geometric conditioning of 3D features in image generation. GeoDiffusion employs a class-specific 3D object as a geometric prior to define keypoints and parametric correlations in 3D space. We ensure viewpoint consistency through a rendered image of a reference 3D object, followed by style transfer to meet user-defined appearance specifications. At the core of our framework is GeoDrag, improving accuracy and speed of drag-based image editing on geometry guidance tasks and general instructions on DragBench. Our results demonstrate that GeoDiffusion enables precise geometric modifications across various iterative design workflows.",
        "tags": [
            "3D",
            "Image Editing",
            "Style Transfer"
        ]
    },
    {
        "id": "170",
        "title": "Operationalizing Large Language Models with Design-Aware Contexts for Code Comment Generation",
        "author": [
            "Aritra Mitra",
            "Srijoni Majumdar",
            "Anamitra Mukhopadhyay",
            "Partha Pratim Das",
            "Paul D Clough",
            "Partha Pratim Chakrabarti"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22338",
        "abstract": "Comments are very useful to the flow of code development. With the increasing commonality of code, novice coders have been creating a significant amount of codebases. Due to lack of commenting standards, their comments are often useless, and increase the time taken to further maintain codes. This study intends to find the usefulness of large language models (LLMs) in these cases to generate potentially better comments. This study focuses on the feasibility of design documents as a context for the LLMs to generate more useful comments, as design documents are often used by maintainers to understand code when comments do not suffice.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "171",
        "title": "Estimating Continuum Robot Shape under External Loading using Spatiotemporal Neural Networks",
        "author": [
            "Enyi Wang",
            "Zhen Deng",
            "Chuanchuan Pan",
            "Bingwei He",
            "Jianwei Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22339",
        "abstract": "This paper presents a learning-based approach for accurately estimating the 3D shape of flexible continuum robots subjected to external loads. The proposed method introduces a spatiotemporal neural network architecture that fuses multi-modal inputs, including current and historical tendon displacement data and RGB images, to generate point clouds representing the robot's deformed configuration. The network integrates a recurrent neural module for temporal feature extraction, an encoding module for spatial feature extraction, and a multi-modal fusion module to combine spatial features extracted from visual data with temporal dependencies from historical actuator inputs. Continuous 3D shape reconstruction is achieved by fitting BÃ©zier curves to the predicted point clouds. Experimental validation demonstrates that our approach achieves high precision, with mean shape estimation errors of 0.08 mm (unloaded) and 0.22 mm (loaded), outperforming state-of-the-art methods in shape sensing for TDCRs. The results validate the efficacy of deep learning-based spatiotemporal data fusion for precise shape estimation under loading conditions.",
        "tags": [
            "3D",
            "Robotics"
        ]
    },
    {
        "id": "172",
        "title": "DynaSolidGeo: A Dynamic Benchmark for Genuine Spatial Mathematical Reasoning of VLMs in Solid Geometry",
        "author": [
            "Changti Wu",
            "Shijie Lian",
            "Zihao Liu",
            "Lei Zhang",
            "Laurence Tianruo Yang",
            "Kai Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22340",
        "abstract": "Solid geometry problem solving demands spatial mathematical reasoning that integrates spatial intelligence and symbolic reasoning. However, most existing multimodal mathematical reasoning benchmarks focus primarily on 2D plane geometry, rely on static datasets prone to data contamination and memorization, and evaluate models solely by final answers, overlooking the reasoning process. To address these limitations, we introduce DynaSolidGeo, the first dynamic benchmark for evaluating genuine spatial reasoning in Vision-Language Models (VLMs). Constructed through a semi-automatic annotation pipeline, DynaSolidGeo contains 503 expert-curated seed questions that can, in principle, dynamically generate an unbounded number of diverse multimodal text-visual instances. Beyond answer accuracy, we incorporate process evaluation based on expert-annotated reasoning chains to measure logical validity and causal coherence. Experiments across representative open-source and closed-source VLMs reveal large performance gaps, severe degradation in dynamic settings, and poor performance on tasks requiring high-level spatial intelligence, such as mental rotation and visualization. The code and dataset are available at \\href{https://zgca-ai4edu.github.io/DynaSolidGeo/}{DynaSolidGeo}.",
        "tags": [
            "VLM"
        ]
    },
    {
        "id": "173",
        "title": "FAIR-RAG: Faithful Adaptive Iterative Refinement for Retrieval-Augmented Generation",
        "author": [
            "Mohammad Aghajani Asl",
            "Majid Asgari-Bidhendi",
            "Behrooz Minaei-Bidgoli"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22344",
        "abstract": "While Retrieval-Augmented Generation (RAG) mitigates hallucination and knowledge staleness in Large Language Models (LLMs), existing frameworks often falter on complex, multi-hop queries that require synthesizing information from disparate sources. Current advanced RAG methods, employing iterative or adaptive strategies, lack a robust mechanism to systematically identify and fill evidence gaps, often propagating noise or failing to gather a comprehensive context. We introduce FAIR-RAG, a novel agentic framework that transforms the standard RAG pipeline into a dynamic, evidence-driven reasoning process. At its core is an Iterative Refinement Cycle governed by a module we term Structured Evidence Assessment (SEA). The SEA acts as an analytical gating mechanism: it deconstructs the initial query into a checklist of required findings and audits the aggregated evidence to identify confirmed facts and, critically, explicit informational gaps. These gaps provide a precise signal to an Adaptive Query Refinement agent, which generates new, targeted sub-queries to retrieve missing information. This cycle repeats until the evidence is verified as sufficient, ensuring a comprehensive context for a final, strictly faithful generation. We conducted experiments on challenging multi-hop QA benchmarks, including HotpotQA, 2WikiMultiHopQA, and MusiQue. In a unified experimental setup, FAIR-RAG significantly outperforms strong baselines. On HotpotQA, it achieves an F1-score of 0.453 -- an absolute improvement of 8.3 points over the strongest iterative baseline -- establishing a new state-of-the-art for this class of methods on these benchmarks. Our work demonstrates that a structured, evidence-driven refinement process with explicit gap analysis is crucial for unlocking reliable and accurate reasoning in advanced RAG systems for complex, knowledge-intensive tasks.",
        "tags": [
            "LLM",
            "RAG"
        ]
    },
    {
        "id": "174",
        "title": "Irony Detection in Urdu Text: A Comparative Study Using Machine Learning Models and Large Language Models",
        "author": [
            "Fiaz Ahmad",
            "Nisar Hussain",
            "Amna Qasim",
            "Momina Hafeez",
            "Muhammad Usman Grigori Sidorov",
            "Alexander Gelbukh"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22356",
        "abstract": "Ironic identification is a challenging task in Natural Language Processing, particularly when dealing with languages that differ in syntax and cultural context. In this work, we aim to detect irony in Urdu by translating an English Ironic Corpus into the Urdu language. We evaluate ten state-of-the-art machine learning algorithms using GloVe and Word2Vec embeddings, and compare their performance with classical methods. Additionally, we fine-tune advanced transformer-based models, including BERT, RoBERTa, LLaMA 2 (7B), LLaMA 3 (8B), and Mistral, to assess the effectiveness of large-scale models in irony detection. Among machine learning models, Gradient Boosting achieved the best performance with an F1-score of 89.18%. Among transformer-based models, LLaMA 3 (8B) achieved the highest performance with an F1-score of 94.61%. These results demonstrate that combining transliteration techniques with modern NLP models enables robust irony detection in Urdu, a historically low-resource language.",
        "tags": [
            "BERT",
            "Detection",
            "LLM",
            "LLaMA",
            "Transformer"
        ]
    },
    {
        "id": "175",
        "title": "Mapping Faithful Reasoning in Language Models",
        "author": [
            "Jiazheng Li",
            "Andreas Damianou",
            "J Rosser",
            "JosÃ© Luis Redondo GarcÃ­a",
            "Konstantina Palla"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22362",
        "abstract": "Chain-of-thought (CoT) traces promise transparency for reasoning language models, but prior work shows they are not always faithful reflections of internal computation. This raises challenges for oversight: practitioners may misinterpret decorative reasoning as genuine. We introduce Concept Walk, a general framework for tracing how a model's internal stance evolves with respect to a concept direction during reasoning. Unlike surface text, Concept Walk operates in activation space, projecting each reasoning step onto the concept direction learned from contrastive data. This allows us to observe whether reasoning traces shape outcomes or are discarded. As a case study, we apply Concept Walk to the domain of Safety using Qwen 3-4B. We find that in 'easy' cases, perturbed CoTs are quickly ignored, indicating decorative reasoning, whereas in 'hard' cases, perturbations induce sustained shifts in internal activations, consistent with faithful reasoning. The contribution is methodological: Concept Walk provides a lens to re-examine faithfulness through concept-specific internal dynamics, helping identify when reasoning traces can be trusted and when they risk misleading practitioners.",
        "tags": [
            "CoT",
            "Qwen"
        ]
    },
    {
        "id": "176",
        "title": "GigaEmbeddings: Efficient Russian Language Embedding Model",
        "author": [
            "Egor Kolodin",
            "Daria Khomich",
            "Nikita Savushkin",
            "Anastasia Ianina",
            "Fyodor Minkin"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22369",
        "abstract": "We introduce GigaEmbeddings, a novel framework for training high-performance Russian-focused text embeddings through hierarchical instruction tuning of the decoder-only LLM designed specifically for Russian language (GigaChat-3B). Our three-stage pipeline, comprising large-scale contrastive pre-training in web-scale corpora, fine-tuning with hard negatives, and multitask generalization across retrieval, classification, and clustering tasks, addresses key limitations of existing methods by unifying diverse objectives and leveraging synthetic data generation. Architectural innovations include bidirectional attention for contextual modeling, latent attention pooling for robust sequence aggregation, and strategic pruning of 25% of transformer layers to enhance efficiency without compromising performance. Evaluated on the ruMTEB benchmark spanning 23 multilingual tasks, GigaEmbeddings achieves state-of-the-art results (69.1 avg. score), outperforming strong baselines with a larger number of parameters.",
        "tags": [
            "LLM",
            "Transformer"
        ]
    },
    {
        "id": "177",
        "title": "BLIP-FusePPO: A Vision-Language Deep Reinforcement Learning Framework for Lane Keeping in Autonomous Vehicles",
        "author": [
            "Seyed Ahmad Hosseini Miangoleh",
            "Amin Jalal Aghdasian",
            "Farzaneh Abdollahi"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22370",
        "abstract": "In this paper, we propose Bootstrapped Language-Image Pretraining-driven Fused State Representation in Proximal Policy Optimization (BLIP-FusePPO), a novel multimodal reinforcement learning (RL) framework for autonomous lane-keeping (LK), in which semantic embeddings generated by a vision-language model (VLM) are directly fused with geometric states, LiDAR observations, and Proportional-Integral-Derivative-based (PID) control feedback within the agent observation space. The proposed method lets the agent learn driving rules that are aware of their surroundings and easy to understand by combining high-level scene understanding from the VLM with low-level control and spatial signals. Our architecture brings together semantic, geometric, and control-aware representations to make policy learning more robust. A hybrid reward function that includes semantic alignment, LK accuracy, obstacle avoidance, and speed regulation helps learning to be more efficient and generalizable. Our method is different from the approaches that only use semantic models to shape rewards. Instead, it directly embeds semantic features into the state representation. This cuts down on expensive runtime inference and makes sure that semantic guidance is always available. The simulation results show that the proposed model is better at LK stability and adaptability than the best vision-based and multimodal RL baselines in a wide range of difficult driving situations. We make our code publicly available.",
        "tags": [
            "RL",
            "VLM"
        ]
    },
    {
        "id": "178",
        "title": "Reasoning Models Reason Well, Until They Don't",
        "author": [
            "Revanth Rameshkumar",
            "Jimson Huang",
            "Yunxin Sun",
            "Fei Xia",
            "Abulhair Saparov"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22371",
        "abstract": "Large language models (LLMs) have shown significant progress in reasoning tasks. However, recent studies show that transformers and LLMs fail catastrophically once reasoning problems exceed modest complexity. We revisit these findings through the lens of large reasoning models (LRMs) -- LLMs fine-tuned with incentives for step-by-step argumentation and self-verification. LRM performance on graph and reasoning benchmarks such as NLGraph seem extraordinary, with some even claiming they are capable of generalized reasoning and innovation in reasoning-intensive fields such as mathematics, physics, medicine, and law. However, by more carefully scaling the complexity of reasoning problems, we show existing benchmarks actually have limited complexity. We develop a new dataset, the Deep Reasoning Dataset (DeepRD), along with a generative process for producing unlimited examples of scalable complexity. We use this dataset to evaluate model performance on graph connectivity and natural language proof planning. We find that the performance of LRMs drop abruptly at sufficient complexity and do not generalize. We also relate our LRM results to the distributions of the complexities of large, real-world knowledge graphs, interaction graphs, and proof datasets. We find the majority of real-world examples fall inside the LRMs' success regime, yet the long tails expose substantial failure potential. Our analysis highlights the near-term utility of LRMs while underscoring the need for new methods that generalize beyond the complexity of examples in the training distribution.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "179",
        "title": "VisJudge-Bench: Aesthetics and Quality Assessment of Visualizations",
        "author": [
            "Yupeng Xie",
            "Zhiyang Zhang",
            "Yifan Wu",
            "Sirong Lu",
            "Jiayi Zhang",
            "Zhaoyang Yu",
            "Jinlin Wang",
            "Sirui Hong",
            "Bang Liu",
            "Chenglin Wu",
            "Yuyu Luo"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22373",
        "abstract": "Visualization, a domain-specific yet widely used form of imagery, is an effective way to turn complex datasets into intuitive insights, and its value depends on whether data are faithfully represented, clearly communicated, and aesthetically designed. However, evaluating visualization quality is challenging: unlike natural images, it requires simultaneous judgment across data encoding accuracy, information expressiveness, and visual aesthetics. Although multimodal large language models (MLLMs) have shown promising performance in aesthetic assessment of natural images, no systematic benchmark exists for measuring their capabilities in evaluating visualizations. To address this, we propose VisJudge-Bench, the first comprehensive benchmark for evaluating MLLMs' performance in assessing visualization aesthetics and quality. It contains 3,090 expert-annotated samples from real-world scenarios, covering single visualizations, multiple visualizations, and dashboards across 32 chart types. Systematic testing on this benchmark reveals that even the most advanced MLLMs (such as GPT-5) still exhibit significant gaps compared to human experts in judgment, with a Mean Absolute Error (MAE) of 0.551 and a correlation with human ratings of only 0.429. To address this issue, we propose VisJudge, a model specifically designed for visualization aesthetics and quality assessment. Experimental results demonstrate that VisJudge significantly narrows the gap with human judgment, reducing the MAE to 0.442 (a 19.8% reduction) and increasing the consistency with human experts to 0.681 (a 58.7% improvement) compared to GPT-5. The benchmark is available at https://github.com/HKUSTDial/VisJudgeBench.",
        "tags": [
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "180",
        "title": "Label Smoothing Improves Gradient Ascent in LLM Unlearning",
        "author": [
            "Zirui Pang",
            "Hao Zheng",
            "Zhijie Deng",
            "Ling Li",
            "Zixin Zhong",
            "Jiaheng Wei"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22376",
        "abstract": "LLM unlearning has emerged as a promising approach, aiming to enable models to forget hazardous/undesired knowledge at low cost while preserving as much model utility as possible. Among existing techniques, the most straightforward method is performing Gradient Ascent (GA) w.r.t. the forget data, thereby forcing the model to unlearn the forget dataset. However, GA suffers from severe instability, as it drives updates in a divergent direction, often resulting in drastically degraded model utility. To address this issue, we propose Smoothed Gradient Ascent (SGA). SGA combines the forget data with multiple constructed normal data through a tunable smoothing rate. Intuitively, this extends GA from learning solely on the forget data to jointly learning across both forget and normal data, enabling more stable unlearning while better preserving model utility. Theoretically, we provide the theoretical guidance on the selection of the optimal smoothing rate. Empirically, we evaluate SGA on three benchmarks: TOFU, Harry Potter, and MUSE-NEWS. Experimental results demonstrate that SGA consistently outperforms the original Gradient Ascent (GA) method across all metrics and achieves top-2 performance among all baseline methods on several key metrics.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "181",
        "title": "On the complexity of the free space of a translating square in R^3",
        "author": [
            "Gabriel Nivasch"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22386",
        "abstract": "Consider a polyhedral robot $B$ that can translate (without rotating) amidst a finite set of non-moving polyhedral obstacles in $\\mathbb R^3$. The \"free space\" $\\mathcal F$ of $B$ is the set of all positions in which $B$ is disjoint from the interior of every obstacle.\nAronov and Sharir (1997) derived an upper bound of $O(n^2\\log n)$ for the combinatorial complexity of $\\mathcal F$, where $n$ is the total number of vertices of the obstacles, and the complexity of $B$ is assumed constant.\nHalperin and Yap (1993) showed that, if $B$ is either a \"flat\" convex polygon or a three-dimensional box, then a tighter bound of $O(n^2\\alpha(n))$ holds. Here $\\alpha(n)$ is the inverse Ackermann function.\nIn this paper we prove that if $B$ is a square (or a rectangle or a parallelogram), then the complexity of $\\mathcal F$ is $O(n^2)$. We conjecture that this bound holds more generally if $B$ is any convex polygon whose edges come in parallel pairs. For such polygons $B$, the only triple contacts whose number we were not able to bound by $O(n^2)$ are those made by three mutually non-parallel edges of $B$.\nSimilarly, for the case where $B$ is a cube (or a box or a parallelepiped), we bound by $O(n^2)$ all triple contacts except those made by three mutually non-parallel edges of $B$.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "182",
        "title": "Top-Down Semantic Refinement for Image Captioning",
        "author": [
            "Jusheng Zhang",
            "Kaitong Cai",
            "Jing Yang",
            "Jian Wang",
            "Chengpei Tang",
            "Keze Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22391",
        "abstract": "Large Vision-Language Models (VLMs) face an inherent contradiction in image captioning: their powerful single-step generation capabilities often lead to a myopic decision-making process. This makes it difficult to maintain global narrative coherence while capturing rich details, a limitation that is particularly pronounced in tasks that require multi-step and complex scene description. To overcome this fundamental challenge, we redefine image captioning as a goal-oriented hierarchical refinement planning problem, and further propose a novel framework, named Top-Down Semantic Refinement (TDSR), which models the generation process as a Markov Decision Process (MDP). However, planning within the vast state space of a VLM presents a significant computational hurdle. Our core contribution, therefore, is the design of a highly efficient Monte Carlo Tree Search (MCTS) algorithm tailored for VLMs. By incorporating a visual-guided parallel expansion and a lightweight value network, our TDSR reduces the call frequency to the expensive VLM by an order of magnitude without sacrificing planning quality. Furthermore, an adaptive early stopping mechanism dynamically matches computational overhead to the image's complexity. Extensive experiments on multiple benchmarks, including DetailCaps, COMPOSITIONCAP, and POPE, demonstrate that our TDSR, as a plug-and-play module, can significantly enhance the performance of existing VLMs (e.g., LLaVA-1.5, Qwen2.5-VL) by achieving state-of-the-art or highly competitive results in fine-grained description, compositional generalization, and hallucination suppression.",
        "tags": [
            "LLaVA",
            "VLM"
        ]
    },
    {
        "id": "183",
        "title": "Teaching Machine Learning Through Cricket: A Practical Engineering Education Approach",
        "author": [
            "Mohd Ruhul Ameen",
            "Akif Islam",
            "Abu Saleh Musa Miah",
            "M. Saifuzzaman Rafat",
            "Jungpil Shin"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22392",
        "abstract": "Teaching complex machine learning concepts such as reinforcement learning and Markov Decision Processes remains challenging in engineering education. Students often struggle to connect abstract mathematics to real-world applications. We present LearnML@Cricket, a 12-week curriculum that uses cricket analytics to teach these concepts through practical, hands-on examples. By mapping game scenarios directly to ML algorithms, students learn through doing rather than memorizing. Our curriculum includes coding laboratories, real datasets, and immediate application to engineering problems. We propose an empirical study to measure whether this approach improves both understanding and practical implementation skills compared to traditional teaching methods.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "184",
        "title": "Confabulations from ACL Publications (CAP): A Dataset for Scientific Hallucination Detection",
        "author": [
            "Federica Gamba",
            "Aman Sinha",
            "Timothee Mickus",
            "Raul Vazquez",
            "Patanjali Bhamidipati",
            "Claudio Savelli",
            "Ahana Chattopadhyay",
            "Laura A. Zanella",
            "Yash Kankanampati",
            "Binesh Arakkal Remesh",
            "Aryan Ashok Chandramania",
            "Rohit Agarwal",
            "Chuyuan Li",
            "Ioana Buhnila",
            "Radhika Mamidi"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22395",
        "abstract": "We introduce the CAP (Confabulations from ACL Publications) dataset, a multilingual resource for studying hallucinations in large language models (LLMs) within scientific text generation. CAP focuses on the scientific domain, where hallucinations can distort factual knowledge, as they frequently do. In this domain, however, the presence of specialized terminology, statistical reasoning, and context-dependent interpretations further exacerbates these distortions, particularly given LLMs' lack of true comprehension, limited contextual understanding, and bias toward surface-level generalization. CAP operates in a cross-lingual setting covering five high-resource languages (English, French, Hindi, Italian, and Spanish) and four low-resource languages (Bengali, Gujarati, Malayalam, and Telugu). The dataset comprises 900 curated scientific questions and over 7000 LLM-generated answers from 16 publicly available models, provided as question-answer pairs along with token sequences and corresponding logits. Each instance is annotated with a binary label indicating the presence of a scientific hallucination, denoted as a factuality error, and a fluency label, capturing issues in the linguistic quality or naturalness of the text. CAP is publicly released to facilitate advanced research on hallucination detection, multilingual evaluation of LLMs, and the development of more reliable scientific NLP systems.",
        "tags": [
            "Detection",
            "LLM"
        ]
    },
    {
        "id": "185",
        "title": "PortGPT: Towards Automated Backporting Using Large Language Models",
        "author": [
            "Zhaoyang Li",
            "Zheng Yu",
            "Jingyi Song",
            "Meng Xu",
            "Yuxuan Luo",
            "Dongliang Mu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22396",
        "abstract": "Patch backporting, the process of migrating mainline security patches to older branches, is an essential task in maintaining popular open-source projects (e.g., Linux kernel). However, manual backporting can be labor-intensive, while existing automated methods, which heavily rely on predefined syntax or semantic rules, often lack agility for complex patches.\nIn this paper, we introduce PORTGPT, an LLM-agent for end-to-end automation of patch backporting in real-world scenarios. PORTGPT enhances an LLM with tools to access code on-demand, summarize Git history, and revise patches autonomously based on feedback (e.g., from compilers), hence, simulating human-like reasoning and verification. PORTGPT achieved an 89.15% success rate on existing datasets (1815 cases), and 62.33% on our own dataset of 146 complex cases, both outperforms state-of-the-art of backporting tools. We contributed 9 backported patches from PORTGPT to the Linux kernel community and all patches are now merged.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "186",
        "title": "A First Look at the Self-Admitted Technical Debt in Test Code: Taxonomy and Detection",
        "author": [
            "Shahidul Islam",
            "Md Nahidul Islam Opu",
            "Shaowei Wang",
            "Shaiful Chowdhury"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22409",
        "abstract": "Self-admitted technical debt (SATD) refers to comments in which developers explicitly acknowledge code issues, workarounds, or suboptimal solutions. SATD is known to significantly increase software maintenance effort. While extensive research has examined SATD in source code, its presence and impact in test code have received no focused attention, leaving a significant gap in our understanding of how SATD manifests in testing contexts.\nThis study, the first of its kind, investigates SATD in test code by manually analyzing 50,000 comments randomly sampled from 1.6 million comments across 1,000 open-source Java projects. From this sample, after manual analysis and filtering, we identified 615 SATD comments and classified them into 15 distinct categories, building a taxonomy of test code SATD. To investigate whether test code SATD can be detected automatically, we evaluated existing SATD detection tools, as well as both open-source and proprietary LLMs. Among the existing tools, MAT performed the best, albeit with moderate recall. To our surprise, both open-source and proprietary LLMs exhibited poor detection accuracy, primarily due to low precision. These results indicate that neither existing approaches nor current LLMs can reliably detect SATD in test code.\nOverall, this work provides the first large-scale analysis of SATD in test code, a nuanced understanding of its types, and the limitations of current SATD detection methods. Our findings lay the groundwork for future research on test code-specific SATD.",
        "tags": [
            "Detection",
            "LLM"
        ]
    },
    {
        "id": "187",
        "title": "A Novel Multi-Timescale Stability-Preserving Hierarchical Reinforcement Learning Controller Framework for Adaptive Control in High-Dimensional Dynamical Systems",
        "author": [
            "Mohammad Ali Labbaf Khaniki",
            "Fateme Taroodi",
            "Benyamin Safizadeh"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22420",
        "abstract": "Controlling high-dimensional stochastic systems, critical in robotics, autonomous vehicles, and hyperchaotic systems, faces the curse of dimensionality, lacks temporal abstraction, and often fails to ensure stochastic stability. To overcome these limitations, this study introduces the Multi-Timescale Lyapunov-Constrained Hierarchical Reinforcement Learning (MTLHRL) framework. MTLHRL integrates a hierarchical policy within a semi-Markov Decision Process (SMDP), featuring a high-level policy for strategic planning and a low-level policy for reactive control, which effectively manages complex, multi-timescale decision-making and reduces dimensionality overhead. Stability is rigorously enforced using a neural Lyapunov function optimized via Lagrangian relaxation and multi-timescale actor-critic updates, ensuring mean-square boundedness or asymptotic stability in the face of stochastic dynamics. The framework promotes efficient and reliable learning through trust-region constraints and decoupled optimization. Extensive simulations on an 8D hyperchaotic system and a 5-DOF robotic manipulator demonstrate MTLHRL's empirical superiority. It significantly outperforms baseline methods in both stability and performance, recording the lowest error indices (e.g., Integral Absolute Error (IAE): 3.912 in hyperchaotic control and IAE: 1.623 in robotics), achieving faster convergence, and exhibiting superior disturbance rejection. MTLHRL offers a theoretically grounded and practically viable solution for robust control of complex stochastic systems.",
        "tags": [
            "RL",
            "Robotics"
        ]
    },
    {
        "id": "188",
        "title": "Group size effects and collective misalignment in LLM multi-agent systems",
        "author": [
            "Ariel Flint",
            "Luca Maria Aiello",
            "Romualdo Pastor-Satorras",
            "Andrea Baronchelli"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22422",
        "abstract": "Multi-agent systems of large language models (LLMs) are rapidly expanding across domains, introducing dynamics not captured by single-agent evaluations. Yet, existing work has mostly contrasted the behavior of a single agent with that of a collective of fixed size, leaving open a central question: how does group size shape dynamics? Here, we move beyond this dichotomy and systematically explore outcomes across the full range of group sizes. We focus on multi-agent misalignment, building on recent evidence that interacting LLMs playing a simple coordination game can generate collective biases absent in individual models. First, we show that collective bias is a deeper phenomenon than previously assessed: interaction can amplify individual biases, introduce new ones, or override model-level preferences. Second, we demonstrate that group size affects the dynamics in a non-linear way, revealing model-dependent dynamical regimes. Finally, we develop a mean-field analytical approach and show that, above a critical population size, simulations converge to deterministic predictions that expose the basins of attraction of competing equilibria. These findings establish group size as a key driver of multi-agent dynamics and highlight the need to consider population-level effects when deploying LLM-based systems at scale.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "189",
        "title": "Can ChatGPT be a good follower of academic paradigms? Research quality evaluations in conflicting areas of sociology",
        "author": [
            "Mike Thelwall",
            "Ralph Schroeder",
            "Meena Dhanda"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22426",
        "abstract": "Purpose: It has become increasingly likely that Large Language Models (LLMs) will be used to score the quality of academic publications to support research assessment goals in the future. This may cause problems for fields with competing paradigms since there is a risk that one may be favoured, causing long term harm to the reputation of the other. Design/methodology/approach: To test whether this is plausible, this article uses 17 ChatGPTs to evaluate up to 100 journal articles from each of eight pairs of competing sociology paradigms (1490 altogether). Each article was assessed by prompting ChatGPT to take one of five roles: paradigm follower, opponent, antagonistic follower, antagonistic opponent, or neutral. Findings: Articles were scored highest by ChatGPT when it followed the aligning paradigm, and lowest when it was told to devalue it and to follow the opposing paradigm. Broadly similar patterns occurred for most of the paradigm pairs. Follower ChatGPTs displayed only a small amount of favouritism compared to neutral ChatGPTs, but articles evaluated by an opposing paradigm ChatGPT had a substantial disadvantage. Research limitations: The data covers a single field and LLM. Practical implications: The results confirm that LLM instructions for research evaluation should be carefully designed to ensure that they are paradigm-neutral to avoid accidentally resolving conflicts between paradigms on a technicality by devaluing one side's contributions. Originality/value: This is the first demonstration that LLMs can be prompted to show a partiality for academic paradigms.",
        "tags": [
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "190",
        "title": "Hollywood Town: Long-Video Generation via Cross-Modal Multi-Agent Orchestration",
        "author": [
            "Zheng Wei",
            "Mingchen Li",
            "Zeqian Zhang",
            "Ruibin Yuan",
            "Pan Hui",
            "Huamin Qu",
            "James Evans",
            "Maneesh Agrawala",
            "Anyi Rao"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22431",
        "abstract": "Recent advancements in multi-agent systems have demonstrated significant potential for enhancing creative task performance, such as long video generation. This study introduces three innovations to improve multi-agent collaboration. First, we propose OmniAgent, a hierarchical, graph-based multi-agent framework for long video generation that leverages a film-production-inspired architecture to enable modular specialization and scalable inter-agent collaboration. Second, inspired by context engineering, we propose hypergraph nodes that enable temporary group discussions among agents lacking sufficient context, reducing individual memory requirements while ensuring adequate contextual information. Third, we transition from directed acyclic graphs (DAGs) to directed cyclic graphs with limited retries, allowing agents to reflect and refine outputs iteratively, thereby improving earlier stages through feedback from subsequent nodes. These contributions lay the groundwork for developing more robust multi-agent systems in creative tasks.",
        "tags": [
            "Video Generation"
        ]
    },
    {
        "id": "191",
        "title": "Separation of Unconscious Robots with Obstructed Visibility",
        "author": [
            "Prajyot Pyati",
            "Navjot Kaur",
            "Saswata Jana",
            "Adri Bhattacharya",
            "Partha Sarathi Mandal"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22434",
        "abstract": "We study a recently introduced \\textit{unconscious} mobile robot model, where each robot is associated with a \\textit{color}, which is visible to other robots but not to itself. The robots are autonomous, anonymous, oblivious and silent, operating in the Euclidean plane under the conventional \\textit{Look-Compute-Move} cycle. A primary task in this model is the \\textit{separation problem}, where unconscious robots sharing the same color must separate from others, forming recognizable geometric shapes such as circles, points, or lines. All prior works model the robots as \\textit{transparent}, enabling each to know the positions and colors of all other robots. In contrast, we model the robots as \\textit{opaque}, where a robot can obstruct the visibility of two other robots, if it lies on the line segment between them. Under this obstructed visibility, we consider a variant of the separation problem in which robots, starting from any arbitrary initial configuration, are required to separate into concentric semicircles. We present a collision-free algorithm that solves the separation problem under a semi-synchronous scheduler in $O(n)$ epochs, where $n$ is the number of robots. The robots agree on one coordinate axis but have no knowledge of $n$.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "192",
        "title": "Modeling Hierarchical Thinking in Large Reasoning Models",
        "author": [
            "G M Shahariar",
            "Ali Nazari",
            "Erfan Shayegani",
            "Nael Abu-Ghazaleh"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22437",
        "abstract": "Large Language Models (LLMs) have demonstrated remarkable reasoning abilities when they generate step-by-step solutions, known as chain-of-thought (CoT) reasoning. When trained to using chain-of-thought reasoning examples, the resulting models (called Large Reasoning Models, or LRMs) appear to learn hierarchical thinking strategies similar to those used by humans. However, understanding LRMs emerging reasoning capabilities remains a difficult open problem, with many potential important applications including improving training and understanding robustness. In this paper, we adopt a memoryless Finite State Machine formulation to approximate LRM's emerging hierarchical reasoning dynamics as a structured, interpretable abstraction. We identify a small set of discrete reasoning states including - initialization, deduction, augmentation-strategy, uncertainty-estimation, backtracking, and final-conclusion that capture the high-level states present in the model's reasoning process. By annotating each step of a model's CoT with these states, we can represent the reasoning trajectory as a transition sequence through the state graph. This FSM formulation provides a systematic way to analyze, interpret and visualize how different models approach problems. We describe the FSM model, provide examples of CoT annotations under this scheme, and discuss how it can shed light on differences between available models in their approach to reasoning. Our results demonstrate that this FSM-based analysis reveals distinct reasoning patterns and potential shortcomings, offering a new lens to evaluate and improve LLM reasoning.",
        "tags": [
            "CoT",
            "LLM"
        ]
    },
    {
        "id": "193",
        "title": "PromptReverb: Multimodal Room Impulse Response Generation Through Latent Rectified Flow Matching",
        "author": [
            "Ali Vosoughi",
            "Yongyi Zang",
            "Qihui Yang",
            "Nathan Peak",
            "Randal Leistikow",
            "Chenliang Xu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22439",
        "abstract": "Room impulse response (RIR) generation remains a critical challenge for creating immersive virtual acoustic environments. Current methods suffer from two fundamental limitations: the scarcity of full-band RIR datasets and the inability of existing models to generate acoustically accurate responses from diverse input modalities. We present PromptReverb, a two-stage generative framework that addresses these challenges. Our approach combines a variational autoencoder that upsamples band-limited RIRs to full-band quality (48 kHz), and a conditional diffusion transformer model based on rectified flow matching that generates RIRs from descriptions in natural language. Empirical evaluation demonstrates that PromptReverb produces RIRs with superior perceptual quality and acoustic accuracy compared to existing methods, achieving 8.8% mean RT60 error compared to -37% for widely used baselines and yielding more realistic room-acoustic parameters. Our method enables practical applications in virtual reality, architectural acoustics, and audio production where flexible, high-quality RIR synthesis is essential.",
        "tags": [
            "DiT",
            "Diffusion",
            "Flow Matching",
            "Rectified Flow",
            "Transformer"
        ]
    },
    {
        "id": "194",
        "title": "Benchmarking Egocentric Multimodal Goal Inference for Assistive Wearable Agents",
        "author": [
            "Vijay Veerabadran",
            "Fanyi Xiao",
            "Nitin Kamra",
            "Pedro Matias",
            "Joy Chen",
            "Caley Drooff",
            "Brett D Roads",
            "Riley Williams",
            "Ethan Henderson",
            "Xuanyi Zhao",
            "Kevin Carlberg",
            "Joseph Tighe",
            "Karl Ridgeway"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22443",
        "abstract": "There has been a surge of interest in assistive wearable agents: agents embodied in wearable form factors (e.g., smart glasses) who take assistive actions toward a user's goal/query (e.g. \"Where did I leave my keys?\"). In this work, we consider the important complementary problem of inferring that goal from multi-modal contextual observations. Solving this \"goal inference\" problem holds the promise of eliminating the effort needed to interact with such an agent. This work focuses on creating WAGIBench, a strong benchmark to measure progress in solving this problem using vision-language models (VLMs). Given the limited prior work in this area, we collected a novel dataset comprising 29 hours of multimodal data from 348 participants across 3,477 recordings, featuring ground-truth goals alongside accompanying visual, audio, digital, and longitudinal contextual observations. We validate that human performance exceeds model performance, achieving 93% multiple-choice accuracy compared with 84% for the best-performing VLM. Generative benchmark results that evaluate several families of modern vision-language models show that larger models perform significantly better on the task, yet remain far from practical usefulness, as they produce relevant goals only 55% of the time. Through a modality ablation, we show that models benefit from extra information in relevant modalities with minimal performance degradation from irrelevant modalities.",
        "tags": [
            "VLM"
        ]
    },
    {
        "id": "195",
        "title": "A short methodological review on social robot navigation benchmarking",
        "author": [
            "Pranup Chhetri",
            "Alejandro Torrejon",
            "Sergio Eslava",
            "Luis J. Manso"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22448",
        "abstract": "Social Robot Navigation is the skill that allows robots to move efficiently in human-populated environments while ensuring safety, comfort, and trust. Unlike other areas of research, the scientific community has not yet achieved an agreement on how Social Robot Navigation should be benchmarked. This is notably important, as the lack of a de facto standard to benchmark Social Robot Navigation can hinder the progress of the field and may lead to contradicting conclusions. Motivated by this gap, we contribute with a short review focused exclusively on benchmarking trends in the period from January 2020 to July 2025. Of the 130 papers identified by our search using IEEE Xplore, we analysed the 85 papers that met the criteria of the review. This review addresses the metrics used in the literature for benchmarking purposes, the algorithms employed in such benchmarks, the use of human surveys for benchmarking, and how conclusions are drawn from the benchmarking results, when applicable.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "196",
        "title": "Evaluating Multimodal Large Language Models on Core Music Perception Tasks",
        "author": [
            "Brandon James Carone",
            "Iran R. Roman",
            "Pablo RipollÃ©s"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22455",
        "abstract": "Multimodal Large Language Models (LLMs) claim \"musical understanding\" via evaluations that conflate listening with score reading. We benchmark three SOTA LLMs (Gemini 2.5 Pro, Gemini 2.5 Flash, and Qwen2.5-Omni) across three core music skills: Syncopation Scoring, Transposition Detection, and Chord Quality Identification. Moreover, we separate three sources of variability: (i) perceptual limitations (audio vs. MIDI inputs), (ii) exposure to examples (zero- vs. few-shot manipulations), and (iii) reasoning strategies (Standalone, CoT, LogicLM). For the latter we adapt LogicLM, a framework combining LLMs with symbolic solvers to perform structured reasoning, to music. Results reveal a clear perceptual gap: models perform near ceiling on MIDI but show accuracy drops on audio. Reasoning and few-shot prompting offer minimal gains. This is expected for MIDI, where performance reaches saturation, but more surprising for audio, where LogicLM, despite near-perfect MIDI accuracy, remains notably brittle. Among models, Gemini Pro achieves the highest performance across most conditions. Overall, current systems reason well over symbols (MIDI) but do not yet \"listen\" reliably from audio. Our method and dataset make the perception-reasoning boundary explicit and offer actionable guidance for building robust, audio-first music systems.",
        "tags": [
            "CoT",
            "Detection",
            "LLM"
        ]
    },
    {
        "id": "197",
        "title": "Learning \"Partner-Aware\" Collaborators in Multi-Party Collaboration",
        "author": [
            "Abhijnan Nath",
            "Nikhil Krishnaswamy"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22462",
        "abstract": "Large Language Models (LLMs) are increasingly bring deployed in agentic settings where they act as collaborators with humans. Therefore, it is increasingly important to be able to evaluate their abilities to collaborate effectively in multi-turn, multi-party tasks. In this paper, we build on the AI alignment and safe interruptability literature to offer novel theoretical insights on collaborative behavior between LLM-driven collaborator agents and an intervention agent. Our goal is to learn an ideal partner-aware collaborator that increases the group's common-ground (CG)-alignment on task-relevant propositions-by intelligently collecting information provided in interventions by a partner http://agent.We show how LLM agents trained using standard RLHF and related approaches are naturally inclined to ignore possibly well-meaning interventions, which makes increasing group common ground non-trivial in this setting. We employ a two-player Modified-Action MDP to examine this suboptimal behavior of standard AI agents, and propose Interruptible Collaborative Roleplayer (ICR)-a novel partner-aware learning algorithm to train CG-optimal collaborators. Experiments on multiple collaborative task environments show that ICR, on average, is more capable of promoting successful CG convergence and exploring more diverse solutions in such tasks.",
        "tags": [
            "LLM",
            "RLHF"
        ]
    },
    {
        "id": "198",
        "title": "Backward-Friendly Optimization: Training Large Language Models with Approximate Gradients under Memory Constraints",
        "author": [
            "Jing Yang",
            "Kaitong Cai",
            "Yijia Fan",
            "Yufeng Yang",
            "Keze Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22467",
        "abstract": "Full fine-tuning of Large Language Models (LLMs) is notoriously memory-intensive, primarily because conventional optimizers such as SGD or Adam assume access to exact gradients derived from cached activations. Existing solutions either alter the model architecture (e.g., reversible networks) or trade memory for computation (e.g., activation checkpointing), but the optimizer itself remains untouched. In this work, we introduce GradLite, a backward-friendly optimizer that relaxes the requirement of exact gradients, enabling efficient training even when intermediate activations are aggressively discarded or approximated. GradLite leverages two key techniques: (i) low-rank Jacobian approximation, which reduces the dimensionality of backpropagated error signals, and (ii) error-feedback correction, which accumulates and compensates approximation errors across iterations to preserve convergence guarantees. We provide a theoretical analysis showing that GradLite maintains unbiased gradient estimates with bounded variance, ensuring convergence rates comparable to Adam. Empirically, GradLite reduces optimizer-state and activation memory consumption by up to 50\\% without architectural changes, and achieves on-par or superior downstream performance on reasoning (MMLU, GSM8K), multilingual, and dialogue benchmarks compared to checkpointing and optimizer-centric baselines (LoMo, GaLore).",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "199",
        "title": "DynaPose4D: High-Quality 4D Dynamic Content Generation via Pose Alignment Loss",
        "author": [
            "Jing Yang",
            "Yufeng Yang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22473",
        "abstract": "Recent advancements in 2D and 3D generative models have expanded the capabilities of computer vision. However, generating high-quality 4D dynamic content from a single static image remains a significant challenge. Traditional methods have limitations in modeling temporal dependencies and accurately capturing dynamic geometry changes, especially when considering variations in camera perspective. To address this issue, we propose DynaPose4D, an innovative solution that integrates 4D Gaussian Splatting (4DGS) techniques with Category-Agnostic Pose Estimation (CAPE) technology. This framework uses 3D Gaussian Splatting to construct a 3D model from single images, then predicts multi-view pose keypoints based on one-shot support from a chosen view, leveraging supervisory signals to enhance motion consistency. Experimental results show that DynaPose4D achieves excellent coherence, consistency, and fluidity in dynamic motion generation. These findings not only validate the efficacy of the DynaPose4D framework but also indicate its potential applications in the domains of computer vision and animation production.",
        "tags": [
            "3D",
            "Gaussian Splatting",
            "Pose Estimation"
        ]
    },
    {
        "id": "200",
        "title": "CHOIR: Collaborative Harmonization fOr Inference Robustness",
        "author": [
            "Xiangjue Dong",
            "Cong Wang",
            "Maria Teleki",
            "Millennium Bismay",
            "James Caverlee"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22475",
        "abstract": "Persona-assigned Large Language Models (LLMs) can adopt diverse roles, enabling personalized and context-aware reasoning. However, even minor demographic perturbations in personas, such as simple pronoun changes, can alter reasoning trajectories, leading to divergent sets of correct answers. Instead of treating these variations as biases to be mitigated, we explore their potential as a constructive resource to improve reasoning robustness. We propose CHOIR (Collaborative Harmonization fOr Inference Robustness), a test-time framework that harmonizes multiple persona-conditioned reasoning signals into a unified prediction. CHOIR orchestrates a collaborative decoding process among counterfactual personas, dynamically balancing agreement and divergence in their reasoning paths. Experiments on various reasoning benchmarks demonstrate that CHOIR consistently enhances performance across demographics, model architectures, scales, and tasks - without additional training. Improvements reach up to 26.4% for individual demographic groups and 19.2% on average across five demographics. It remains effective even when base personas are suboptimal. By reframing persona variation as a constructive signal, CHOIR provides a scalable and generalizable approach to more reliable LLM reasoning.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "201",
        "title": "Agent-GSPO: Communication-Efficient Multi-Agent Systems via Group Sequence Policy Optimization",
        "author": [
            "Yijia Fan",
            "Jusheng Zhang",
            "Jing Yang",
            "Keze Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22477",
        "abstract": "To combat the prohibitive communication costs of ``free-for-all\" multi-agent systems (MAS), we introduce \\textbf{Agent-GSPO}, a framework that directly optimizes for token economy using sequence-level reinforcement learning. Agent-GSPO leverages the stable and memory-efficient Group Sequence Policy Optimization (GSPO) algorithm to train agents on a communication-aware reward that explicitly penalizes verbosity. Across seven reasoning benchmarks, Agent-GSPO not only achieves new state-of-the-art performance but does so with a fraction of the token consumption of existing methods. By fostering emergent strategies like ``strategic silence,\" our approach provides a practical blueprint for developing scalable and economically viable multi-agent systems.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "202",
        "title": "TLSQKT: A Question-Aware Dual-Channel Transformer for Literacy Tracing from Learning Sequences",
        "author": [
            "Zhifeng Wang",
            "Yaowei Dong",
            "Chunyan Zeng"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22488",
        "abstract": "Knowledge tracing (KT) supports personalized learning by modeling how students' knowledge states evolve over time. However, most KT models emphasize mastery of discrete knowledge components, limiting their ability to characterize broader literacy development. We reframe the task as Literacy Tracing (LT), which models the growth of higher-order cognitive abilities and literacy from learners' interaction sequences, and we instantiate this paradigm with a Transformer-based model, TLSQKT (Transformer for Learning Sequences with Question-Aware Knowledge Tracing). TLSQKT employs a dual-channel design that jointly encodes student responses and item semantics, while question-aware interaction and self-attention capture long-range dependencies in learners' evolving states. Experiments on three real-world datasets - one public benchmark, one private knowledge-component dataset, and one private literacy dataset - show that TLSQKT consistently outperforms strong KT baselines on literacy-oriented metrics and reveals interpretable developmental trajectories of learners' literacy. Transfer experiments further indicate that knowledge-tracing signals can be leveraged for literacy tracing, offering a practical route when dedicated literacy labels are limited. These findings position literacy tracing as a scalable component of intelligent educational systems and lay the groundwork for literacy evaluation in future large-scale educational models.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "203",
        "title": "Frustratingly Easy Task-aware Pruning for Large Language Models",
        "author": [
            "Yuanhe Tian",
            "Junjie Liu",
            "Xican Yang",
            "Haishan Ye",
            "Yan Song"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22489",
        "abstract": "Pruning provides a practical solution to reduce the resources required to run large language models (LLMs) to benefit from their effective capabilities as well as control their cost for training and inference. Research on LLM pruning often ranks the importance of LLM parameters using their magnitudes and calibration-data activations and removes (or masks) the less important ones, accordingly reducing LLMs' size. However, these approaches primarily focus on preserving the LLM's ability to generate fluent sentences, while neglecting performance on specific domains and tasks. In this paper, we propose a simple yet effective pruning approach for LLMs that preserves task-specific capabilities while shrinking their parameter space. We first analyze how conventional pruning minimizes loss perturbation under general-domain calibration and extend this formulation by incorporating task-specific feature distributions into the importance computation of existing pruning algorithms. Thus, our framework computes separate importance scores using both general and task-specific calibration data, partitions parameters into shared and exclusive groups based on activation-norm differences, and then fuses their scores to guide the pruning process. This design enables our method to integrate seamlessly with various foundation pruning techniques and preserve the LLM's specialized abilities under compression. Experiments on widely used benchmarks demonstrate that our approach is effective and consistently outperforms the baselines with identical pruning ratios and different settings.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "204",
        "title": "A Novel Discrete-time Model of Information Diffusion on Social Networks Considering Users Behavior",
        "author": [
            "Tran Van Khanh",
            "Do Xuan Cho",
            "Hoang Phi Dung"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22501",
        "abstract": "In this paper, we introduce the SDIR (Susceptible-Delayable-Infected-Recovered) model, an extension of the classical SIR epidemic framework, to provide a more explicit characterization of user behavior in online social networks. The newly merged state D (delayable) represents users who have received the information but delayed its spreading and may eventually choose not to share it at all. Based on the mean-field approximation method, we derive the dynamical equations of the model and investigate its convergence and stability conditions. Under these conditions, we further propose an approximation algorithm for the edge-deletion problem, aiming to minimize the influence of information diffusion by identifying approximate solutions.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "205",
        "title": "Accelerating Materials Design via LLM-Guided Evolutionary Search",
        "author": [
            "Nikhil Abhyankar",
            "Sanchit Kabra",
            "Saaketh Desai",
            "Chandan K. Reddy"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22503",
        "abstract": "Materials discovery requires navigating vast chemical and structural spaces while satisfying multiple, often conflicting, objectives. We present LLM-guided Evolution for MAterials design (LLEMA), a unified framework that couples the scientific knowledge embedded in large language models with chemistry-informed evolutionary rules and memory-based refinement. At each iteration, an LLM proposes crystallographically specified candidates under explicit property constraints; a surrogate-augmented oracle estimates physicochemical properties; and a multi-objective scorer updates success/failure memories to guide subsequent generations. Evaluated on 14 realistic tasks spanning electronics, energy, coatings, optics, and aerospace, LLEMA discovers candidates that are chemically plausible, thermodynamically stable, and property-aligned, achieving higher hit-rates and stronger Pareto fronts than generative and LLM-only baselines. Ablation studies confirm the importance of rule-guided generation, memory-based refinement, and surrogate prediction. By enforcing synthesizability and multi-objective trade-offs, LLEMA delivers a principled pathway to accelerate practical materials discovery.\nCode: https://github.com/scientific-discovery/LLEMA",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "206",
        "title": "On Steerability Factors for Growing Vine Robots",
        "author": [
            "Ciera McFarland",
            "Antonio Alvarez",
            "Sarah Taher",
            "Nathaniel Hanson",
            "Margaret McGuinness"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22504",
        "abstract": "Vine robots extend their tubular bodies by everting material from the tip, enabling navigation in complex environments with a minimalist soft body. Despite their promise for field applications, especially in the urban search and rescue domain, performance is constrained by the weight of attached sensors or tools, as well as other design and control choices. This work investigates how tip load, pressure, length, diameter, and fabrication method shape vine robot steerability--the ability to maneuver with controlled curvature--for robots that steer with series pouch motor-style pneumatic actuators. We conduct two groups of experiments: (1) studying tip load, chamber pressure, length, and diameter in a robot supporting itself against gravity, and (2) studying fabrication method and ratio of actuator to chamber pressure in a robot supported on the ground. Results show that steerability decreases with increasing tip load, is best at moderate chamber pressure, increases with length, and is largely unaffected by diameter. Robots with actuators attached on their exterior begin curving at low pressure ratios, but curvature saturates at high pressure ratios; those with actuators integrated into the robot body require higher pressure ratios to begin curving but achieve higher curvature overall. We demonstrate that robots optimized with these principles outperform those with ad hoc parameters in a mobility task that involves maximizing upward and horizontal curvatures.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "207",
        "title": "Resource Allocation for XR with Edge Offloading: A Reinforcement Learning Approach",
        "author": [
            "Alperen Duru",
            "Mohammad Mozaffari",
            "Ticao Zhang",
            "Mehrnaz Afshang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22505",
        "abstract": "Future immersive XR applications will require energy-efficient, high data rate, and low-latency wireless communications in uplink and downlink. One of the key considerations for supporting such XR applications is intelligent and adaptive resource allocation with edge offloading. To address these demands, this paper proposes a reinforcement learning-based resource allocation framework that dynamically allocates uplink and downlink slots while making offloading decisions based on the XR headset's capabilities and network conditions. The paper presents a numerical analysis of the tradeoff between frame loss rate (FLR) and energy efficiency, identifying decision regions for partial offloading to optimize performance. Results show that for the used set of system parameters, partial offloading can extend the coverage area by 55% and reduce energy consumption by up to 34%, compared to always or never offloading. The results demonstrate that the headset's local computing capability plays a crucial role in offloading decisions. Higher computing abilities enable more efficient local processing, reduce the need for offloading, and enhance energy savings.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "208",
        "title": "CANDI: Hybrid Discrete-Continuous Diffusion Models",
        "author": [
            "Patrick Pynadath",
            "Jiaxin Shi",
            "Ruqi Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22510",
        "abstract": "While continuous diffusion has shown remarkable success in continuous domains such as image generation, its direct application to discrete data has underperformed compared to purely discrete formulations. This gap is counterintuitive, given that continuous diffusion learns score functions that enable joint evolution across multiple positions. To understand this gap, we introduce token identifiability as an analytical framework for understanding how Gaussian noise corrupts discrete data through two mechanisms: discrete identity corruption and continuous rank degradation. We reveal that these mechanisms scale differently with vocabulary size, creating a temporal dissonance: at noise levels where discrete corruption preserves enough structure for conditional learning, continuous denoising is trivial; at noise levels where continuous denoising is meaningful, discrete corruption destroys nearly all conditional structure. To solve this, we propose CANDI (Continuous ANd DIscrete diffusion), a hybrid framework that decouples discrete and continuous corruption, enabling simultaneous learning of both conditional structure and continuous geometry. We empirically validate the temporal dissonance phenomenon and demonstrate that CANDI successfully avoids it. This unlocks the benefits of continuous diffusion for discrete spaces: on controlled generation, CANDI enables classifier-based guidance with off-the-shelf classifiers through simple gradient addition; on text generation, CANDI outperforms masked diffusion at low NFE, demonstrating the value of learning continuous gradients for discrete spaces.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "209",
        "title": "Transitive RL: Value Learning via Divide and Conquer",
        "author": [
            "Seohong Park",
            "Aditya Oberai",
            "Pranav Atreya",
            "Sergey Levine"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22512",
        "abstract": "In this work, we present Transitive Reinforcement Learning (TRL), a new value learning algorithm based on a divide-and-conquer paradigm. TRL is designed for offline goal-conditioned reinforcement learning (GCRL) problems, where the aim is to find a policy that can reach any state from any other state in the smallest number of steps. TRL converts a triangle inequality structure present in GCRL into a practical divide-and-conquer value update rule. This has several advantages compared to alternative value learning paradigms. Compared to temporal difference (TD) methods, TRL suffers less from bias accumulation, as in principle it only requires $O(\\log T)$ recursions (as opposed to $O(T)$ in TD learning) to handle a length-$T$ trajectory. Unlike Monte Carlo methods, TRL suffers less from high variance as it performs dynamic programming. Experimentally, we show that TRL achieves the best performance in highly challenging, long-horizon benchmark tasks compared to previous offline GCRL algorithms.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "210",
        "title": "Ant-inspired Walling Strategies for Scalable Swarm Separation: Reinforcement Learning Approaches Based on Finite State Machines",
        "author": [
            "Shenbagaraj Kannapiran",
            "Elena Oikonomou",
            "Albert Chu",
            "Spring Berman",
            "Theodore P. Pavlic"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22524",
        "abstract": "In natural systems, emergent structures often arise to balance competing demands. Army ants, for example, form temporary \"walls\" that prevent interference between foraging trails. Inspired by this behavior, we developed two decentralized controllers for heterogeneous robotic swarms to maintain spatial separation while executing concurrent tasks. The first is a finite-state machine (FSM)-based controller that uses encounter-triggered transitions to create rigid, stable walls. The second integrates FSM states with a Deep Q-Network (DQN), dynamically optimizing separation through emergent \"demilitarized zones.\" In simulation, both controllers reduce mixing between subgroups, with the DQN-enhanced controller improving adaptability and reducing mixing by 40-50% while achieving faster convergence.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "211",
        "title": "Bag-of-Word-Groups (BoWG): A Robust and Efficient Loop Closure Detection Method Under Perceptual Aliasing",
        "author": [
            "Xiang Fei",
            "Tina Tian",
            "Howie Choset",
            "Lu Li"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22529",
        "abstract": "Loop closure is critical in Simultaneous Localization and Mapping (SLAM) systems to reduce accumulative drift and ensure global mapping consistency. However, conventional methods struggle in perceptually aliased environments, such as narrow pipes, due to vector quantization, feature sparsity, and repetitive textures, while existing solutions often incur high computational costs. This paper presents Bag-of-Word-Groups (BoWG), a novel loop closure detection method that achieves superior precision-recall, robustness, and computational efficiency. The core innovation lies in the introduction of word groups, which captures the spatial co-occurrence and proximity of visual words to construct an online dictionary. Additionally, drawing inspiration from probabilistic transition models, we incorporate temporal consistency directly into similarity computation with an adaptive scheme, substantially improving precision-recall performance. The method is further strengthened by a feature distribution analysis module and dedicated post-verification mechanisms. To evaluate the effectiveness of our method, we conduct experiments on both public datasets and a confined-pipe dataset we constructed. Results demonstrate that BoWG surpasses state-of-the-art methods, including both traditional and learning-based approaches, in terms of precision-recall and computational efficiency. Our approach also exhibits excellent scalability, achieving an average processing time of 16 ms per image across 17,565 images in the Bicocca25b dataset.",
        "tags": [
            "Detection",
            "SLAM",
            "Vector Quantization"
        ]
    },
    {
        "id": "212",
        "title": "Finding the Needle in the Crash Stack: Industrial-Scale Crash Root Cause Localization with AutoCrashFL",
        "author": [
            "Sungmin Kang",
            "Sumi Yun",
            "Jingun Hong",
            "Shin Yoo",
            "Gabin An"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22530",
        "abstract": "Fault Localization (FL) aims to identify root causes of program failures. FL typically targets failures observed from test executions, and as such, often involves dynamic analyses to improve accuracy, such as coverage profiling or mutation testing. However, for large industrial software, measuring coverage for every execution is prohibitively expensive, making the use of such techniques difficult. To address these issues and apply FL in an industrial setting, this paper proposes AutoCrashFL, an LLM agent for the localization of crashes that only requires the crashdump from the Program Under Test (PUT) and access to the repository of the corresponding source code. We evaluate AutoCrashFL against real-world crashes of SAP HANA, an industrial software project consisting of more than 35 million lines of code. Experiments reveal that AutoCrashFL is more effective in localization, as it identified 30% crashes at the top, compared to 17% achieved by the baseline. Through thorough analysis, we find that AutoCrashFL has attractive practical properties: it is relatively more effective for complex bugs, and it can indicate confidence in its results. Overall, these results show the practicality of LLM agent deployment on an industrial scale.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "213",
        "title": "Text to Trust: Evaluating Fine-Tuning and LoRA Trade-offs in Language Models for Unfair Terms of Service Detection",
        "author": [
            "Noshitha Padma Pratyusha Juttu",
            "Sahithi Singireddy",
            "Sravani Gona",
            "Sujal Timilsina"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22531",
        "abstract": "Large Language Models (LLMs) have transformed text understanding, yet their adaptation to specialized legal domains remains constrained by the cost of full fine-tuning. This study provides a systematic evaluation of fine tuning, parameter efficient adaptation (LoRA, QLoRA), and zero-shot prompting strategies for unfair clause detection in Terms of Service (ToS) documents, a key application in legal NLP. We finetune BERT and DistilBERT, apply 4-bit Low-Rank Adaptation (LoRA) to models such as TinyLlama, LLaMA 3B/7B, and SaulLM, and evaluate GPT-4o and O-versions in zero-shot settings. Experiments on the CLAUDETTE-ToS benchmark and the Multilingual Scraper Corpus show that full fine-tuning achieves the strongest precision recall balance, while LoRA-based models provide competitive recall with up to 3x lower memory cost. These findings highlight practical design trade-offs for efficient and domain-adapted LLMs, contributing open baselines for fine-tuning research in legal text processing.",
        "tags": [
            "BERT",
            "Detection",
            "GPT",
            "LLM",
            "LLaMA",
            "LoRA"
        ]
    },
    {
        "id": "214",
        "title": "SRSR: Enhancing Semantic Accuracy in Real-World Image Super-Resolution with Spatially Re-Focused Text-Conditioning",
        "author": [
            "Chen Chen",
            "Majid Abdolshah",
            "Violetta Shevchenko",
            "Hongdong Li",
            "Chang Xu",
            "Pulak Purkait"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22534",
        "abstract": "Existing diffusion-based super-resolution approaches often exhibit semantic ambiguities due to inaccuracies and incompleteness in their text conditioning, coupled with the inherent tendency for cross-attention to divert towards irrelevant pixels. These limitations can lead to semantic misalignment and hallucinated details in the generated high-resolution outputs. To address these, we propose a novel, plug-and-play spatially re-focused super-resolution (SRSR) framework that consists of two core components: first, we introduce Spatially Re-focused Cross-Attention (SRCA), which refines text conditioning at inference time by applying visually-grounded segmentation masks to guide cross-attention. Second, we introduce a Spatially Targeted Classifier-Free Guidance (STCFG) mechanism that selectively bypasses text influences on ungrounded pixels to prevent hallucinations. Extensive experiments on both synthetic and real-world datasets demonstrate that SRSR consistently outperforms seven state-of-the-art baselines in standard fidelity metrics (PSNR and SSIM) across all datasets, and in perceptual quality measures (LPIPS and DISTS) on two real-world benchmarks, underscoring its effectiveness in achieving both high semantic fidelity and perceptual quality in super-resolution.",
        "tags": [
            "Diffusion",
            "Segmentation",
            "Super Resolution"
        ]
    },
    {
        "id": "215",
        "title": "OFFSIDE: Benchmarking Unlearning Misinformation in Multimodal Large Language Models",
        "author": [
            "Hao Zheng",
            "Zirui Pang",
            "Ling li",
            "Zhijie Deng",
            "Yuhan Pu",
            "Zhaowei Zhu",
            "Xiaobo Xia",
            "Jiaheng Wei"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22535",
        "abstract": "Advances in Multimodal Large Language Models (MLLMs) intensify concerns about data privacy, making Machine Unlearning (MU), the selective removal of learned information, a critical necessity. However, existing MU benchmarks for MLLMs are limited by a lack of image diversity, potential inaccuracies, and insufficient evaluation scenarios, which fail to capture the complexity of real-world applications. To facilitate the development of MLLMs unlearning and alleviate the aforementioned limitations, we introduce OFFSIDE, a novel benchmark for evaluating misinformation unlearning in MLLMs based on football transfer rumors. This manually curated dataset contains 15.68K records for 80 players, providing a comprehensive framework with four test sets to assess forgetting efficacy, generalization, utility, and robustness. OFFSIDE supports advanced settings like selective unlearning and corrective relearning, and crucially, unimodal unlearning (forgetting only text data). Our extensive evaluation of multiple baselines reveals key findings: (1) Unimodal methods (erasing text-based knowledge) fail on multimodal rumors; (2) Unlearning efficacy is largely driven by catastrophic forgetting; (3) All methods struggle with \"visual rumors\" (rumors appear in the image); (4) The unlearned rumors can be easily recovered and (5) All methods are vulnerable to prompt attacks. These results expose significant vulnerabilities in current approaches, highlighting the need for more robust multimodal unlearning solutions. The code is available at \\href{https://github.com/zh121800/OFFSIDE}{https://github.com/zh121800/OFFSIDE}.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "216",
        "title": "FAPO: Flawed-Aware Policy Optimization for Efficient and Reliable Reasoning",
        "author": [
            "Yuyang Ding",
            "Chi Zhang",
            "Juntao Li",
            "Haibin Lin",
            "Xin Liu",
            "Min Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22543",
        "abstract": "Reinforcement learning with verifiable rewards (RLVR) has emerged as a promising paradigm for enhancing the reasoning capabilities of large language models (LLMs). In this context, models explore reasoning trajectories and exploit rollouts with correct answers as positive signals for policy optimization. However, these rollouts might involve flawed patterns such as answer-guessing and jump-in-reasoning. Such flawed-positive rollouts are rewarded identically to fully correct ones, causing policy models to internalize these unreliable reasoning patterns. In this work, we first conduct a systematic study of flawed-positive rollouts in RL and find that they enable rapid capability gains during the early optimization stage, while constraining reasoning capability later by reinforcing unreliable patterns. Building on these insights, we propose Flawed-Aware Policy Optimization (FAPO), which presents a parameter-free reward penalty for flawed-positive rollouts, enabling the policy to leverage them as useful shortcuts in the warm-up stage, securing stable early gains, while gradually shifting optimization toward reliable reasoning in the later refinement stage. To accurately and comprehensively detect flawed-positive rollouts, we introduce a generative reward model (GenRM) with a process-level reward that precisely localizes reasoning errors. Experiments show that FAPO is effective in broad domains, improving outcome correctness, process reliability, and training stability without increasing the token budget.",
        "tags": [
            "LLM",
            "RL"
        ]
    },
    {
        "id": "217",
        "title": "LooGLE v2: Are LLMs Ready for Real World Long Dependency Challenges?",
        "author": [
            "Ziyuan He",
            "Yuxuan Wang",
            "Jiaqi Li",
            "Kexin Liang",
            "Muhan Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22548",
        "abstract": "Large language models (LLMs) are equipped with increasingly extended context windows recently, yet their long context understanding capabilities over long dependency tasks remain fundamentally limited and underexplored. This gap is especially significant in many real-world long-context applications that were rarely benchmarked. In this paper, we introduce LooGLE v2, a novel benchmark designed to evaluate LLMs' long context ability in real-world applications and scenarios. Our benchmark consists of automatically collected real-world long texts, ranging from 16k to 2M tokens, encompassing domains in law, finance, game and code. Accordingly, we delicately design 10 types of domain-specific long-dependency tasks and generate 1,934 QA instances with various diversity and complexity in a scalable data curation pipeline for further practical needs. We conduct a comprehensive assessment of 6 locally deployed and 4 API-based LLMs. The evaluation results show that even the best-performing model achieves only a 59.2% overall score on our benchmark. Despite the extensive context windows, popular LLMs are only capable of understanding a much shorter length of context than they claim to be, revealing significant limitations in their ability to handle real-world tasks with long dependencies and highlighting substantial room for model improvement in practical long-context understanding.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "218",
        "title": "DDTR: Diffusion Denoising Trace Recovery",
        "author": [
            "Maximilian Matyash",
            "Avigdor Gal",
            "Arik Senderovich"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22553",
        "abstract": "With recent technological advances, process logs, which were traditionally deterministic in nature, are being captured from non-deterministic sources, such as uncertain sensors or machine learning models (that predict activities using cameras). In the presence of stochastically-known logs, logs that contain probabilistic information, the need for stochastic trace recovery increases, to offer reliable means of understanding the processes that govern such systems. We design a novel deep learning approach for stochastic trace recovery, based on Diffusion Denoising Probabilistic Models (DDPM), which makes use of process knowledge (either implicitly by discovering a model or explicitly by injecting process knowledge in the training phase) to recover traces by denoising. We conduct an empirical evaluation demonstrating state-of-the-art performance with up to a 25% improvement over existing methods, along with increased robustness under high noise levels.",
        "tags": [
            "DDPM",
            "Diffusion"
        ]
    },
    {
        "id": "219",
        "title": "SABlock: Semantic-Aware KV Cache Eviction with Adaptive Compression Block Size",
        "author": [
            "Jinhan Chen",
            "Jianchun Liu",
            "Hongli Xu",
            "Xianjun Gao",
            "Shilong Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22556",
        "abstract": "The growing memory footprint of the Key-Value (KV) cache poses a severe scalability bottleneck for long-context Large Language Model (LLM) inference. While KV cache eviction has emerged as an effective solution by discarding less critical tokens, existing token-, block-, and sentence-level compression methods struggle to balance semantic coherence and memory efficiency. To this end, we introduce SABlock, a \\underline{s}emantic-aware KV cache eviction framework with \\underline{a}daptive \\underline{block} sizes. Specifically, SABlock first performs semantic segmentation to align compression boundaries with linguistic structures, then applies segment-guided token scoring to refine token importance estimation. Finally, for each segment, a budget-driven search strategy adaptively determines the optimal block size that preserves semantic integrity while improving compression efficiency under a given cache budget. Extensive experiments on long-context benchmarks demonstrate that SABlock consistently outperforms state-of-the-art baselines under the same memory budgets. For instance, on Needle-in-a-Haystack (NIAH), SABlock achieves 99.9% retrieval accuracy with only 96 KV entries, nearly matching the performance of the full-cache baseline that retains up to 8K entries. Under a fixed cache budget of 1,024, SABlock further reduces peak memory usage by 46.28% and achieves up to 9.5x faster decoding on a 128K context length.",
        "tags": [
            "LLM",
            "Segmentation"
        ]
    },
    {
        "id": "220",
        "title": "SPIRAL: Self-Play Incremental Racing Algorithm for Learning in Multi-Drone Competitions",
        "author": [
            "Onur AkgÃ¼n"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22568",
        "abstract": "This paper introduces SPIRAL (Self-Play Incremental Racing Algorithm for Learning), a novel approach for training autonomous drones in multi-agent racing competitions. SPIRAL distinctively employs a self-play mechanism to incrementally cultivate complex racing behaviors within a challenging, dynamic environment. Through this self-play core, drones continuously compete against increasingly proficient versions of themselves, naturally escalating the difficulty of competitive interactions. This progressive learning journey guides agents from mastering fundamental flight control to executing sophisticated cooperative multi-drone racing strategies. Our method is designed for versatility, allowing integration with any state-of-the-art Deep Reinforcement Learning (DRL) algorithms within its self-play framework. Simulations demonstrate the significant advantages of SPIRAL and benchmark the performance of various DRL algorithms operating within it. Consequently, we contribute a versatile, scalable, and self-improving learning framework to the field of autonomous drone racing. SPIRAL's capacity to autonomously generate appropriate and escalating challenges through its self-play dynamic offers a promising direction for developing robust and adaptive racing strategies in multi-agent environments. This research opens new avenues for enhancing the performance and reliability of autonomous racing drones in increasingly complex and competitive scenarios.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "221",
        "title": "Curriculum-Based Iterative Self-Play for Scalable Multi-Drone Racing",
        "author": [
            "Onur AkgÃ¼n"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22570",
        "abstract": "The coordination of multiple autonomous agents in high-speed, competitive environments represents a significant engineering challenge. This paper presents CRUISE (Curriculum-Based Iterative Self-Play for Scalable Multi-Drone Racing), a reinforcement learning framework designed to solve this challenge in the demanding domain of multi-drone racing. CRUISE overcomes key scalability limitations by synergistically combining a progressive difficulty curriculum with an efficient self-play mechanism to foster robust competitive behaviors. Validated in high-fidelity simulation with realistic quadrotor dynamics, the resulting policies significantly outperform both a standard reinforcement learning baseline and a state-of-the-art game-theoretic planner. CRUISE achieves nearly double the planner's mean racing speed, maintains high success rates, and demonstrates robust scalability as agent density increases. Ablation studies confirm that the curriculum structure is the critical component for this performance leap. By providing a scalable and effective training methodology, CRUISE advances the development of autonomous systems for dynamic, competitive tasks and serves as a blueprint for future real-world deployment.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "222",
        "title": "STATUS Bench: A Rigorous Benchmark for Evaluating Object State Understanding in Vision-Language Models",
        "author": [
            "Mahiro Ukai",
            "Shuhei Kurita",
            "Nakamasa Inoue"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22571",
        "abstract": "Object state recognition aims to identify the specific condition of objects, such as their positional states (e.g., open or closed) and functional states (e.g., on or off). While recent Vision-Language Models (VLMs) are capable of performing a variety of multimodal tasks, it remains unclear how precisely they can identify object states. To alleviate this issue, we introduce the STAte and Transition UnderStanding Benchmark (STATUS Bench), the first benchmark for rigorously evaluating the ability of VLMs to understand subtle variations in object states in diverse situations. Specifically, STATUS Bench introduces a novel evaluation scheme that requires VLMs to perform three tasks simultaneously: object state identification (OSI), image retrieval (IR), and state change identification (SCI). These tasks are defined over our fully hand-crafted dataset involving image pairs, their corresponding object state descriptions and state change descriptions. Furthermore, we introduce a large-scale training dataset, namely STATUS Train, which consists of 13 million semi-automatically created descriptions. This dataset serves as the largest resource to facilitate further research in this area. In our experiments, we demonstrate that STATUS Bench enables rigorous consistency evaluation and reveal that current state-of-the-art VLMs still significantly struggle to capture subtle object state distinctions. Surprisingly, under the proposed rigorous evaluation scheme, most open-weight VLMs exhibited chance-level zero-shot performance. After fine-tuning on STATUS Train, Qwen2.5-VL achieved performance comparable to Gemini 2.0 Flash. These findings underscore the necessity of STATUS Bench and Train for advancing object state recognition in VLM research.",
        "tags": [
            "VLM"
        ]
    },
    {
        "id": "223",
        "title": "Pedagogy-driven Evaluation of Generative AI-powered Intelligent Tutoring Systems",
        "author": [
            "Kaushal Kumar Maurya",
            "Ekaterina Kochmar"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22581",
        "abstract": "The interdisciplinary research domain of Artificial Intelligence in Education (AIED) has a long history of developing Intelligent Tutoring Systems (ITSs) by integrating insights from technological advancements, educational theories, and cognitive psychology. The remarkable success of generative AI (GenAI) models has accelerated the development of large language model (LLM)-powered ITSs, which have potential to imitate human-like, pedagogically rich, and cognitively demanding tutoring. However, the progress and impact of these systems remain largely untraceable due to the absence of reliable, universally accepted, and pedagogy-driven evaluation frameworks and benchmarks. Most existing educational dialogue-based ITS evaluations rely on subjective protocols and non-standardized benchmarks, leading to inconsistencies and limited generalizability. In this work, we take a step back from mainstream ITS development and provide comprehensive state-of-the-art evaluation practices, highlighting associated challenges through real-world case studies from careful and caring AIED research. Finally, building on insights from previous interdisciplinary AIED research, we propose three practical, feasible, and theoretically grounded research directions, rooted in learning science principles and aimed at establishing fair, unified, and scalable evaluation methodologies for ITSs.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "224",
        "title": "ATOM: AdapTive and OptiMized dynamic temporal knowledge graph construction using LLMs",
        "author": [
            "Yassir Lairgi",
            "Ludovic Moncla",
            "Khalid Benabdeslem",
            "RÃ©my Cazabet",
            "Pierre ClÃ©au"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22590",
        "abstract": "In today's rapidly expanding data landscape, knowledge extraction from unstructured text is vital for real-time analytics, temporal inference, and dynamic memory frameworks. However, traditional static knowledge graph (KG) construction often overlooks the dynamic and time-sensitive nature of real-world data, limiting adaptability to continuous changes. Moreover, recent zero- or few-shot approaches that avoid domain-specific fine-tuning or reliance on prebuilt ontologies often suffer from instability across multiple runs, as well as incomplete coverage of key facts. To address these challenges, we introduce ATOM (AdapTive and OptiMized), a few-shot and scalable approach that builds and continuously updates Temporal Knowledge Graphs (TKGs) from unstructured texts. ATOM splits input documents into minimal, self-contained \"atomic\" facts, improving extraction exhaustivity and stability. Then, it constructs atomic TKGs from these facts while employing a dual-time modeling that distinguishes when information is observed from when it is valid. The resulting atomic TKGs are subsequently merged in parallel. Empirical evaluations demonstrate that ATOM achieves ~18% higher exhaustivity, ~17% better stability, and over 90% latency reduction compared to baseline methods, demonstrating a strong scalability potential for dynamic TKG construction.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "225",
        "title": "AutoBench: Automating LLM Evaluation through Reciprocal Peer Assessment",
        "author": [
            "Dario Loi",
            "Elena Maria MuiÃ ",
            "Federico Siciliano",
            "Giovanni Trappolini",
            "Vincenzo CrisÃ ",
            "Peter Kruger",
            "Fabrizio Silvestri"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22593",
        "abstract": "We present AutoBench, a fully automated and self-sustaining framework for evaluating Large Language Models (LLMs) through reciprocal peer assessment. This paper provides a rigorous scientific validation of the AutoBench methodology, originally developed as an open-source project by eZecute S.R.L.. Unlike static benchmarks that suffer from test-set contamination and limited adaptability, AutoBench dynamically generates novel evaluation tasks while models alternately serve as question generators, contestants, and judges across diverse domains. An iterative weighting mechanism amplifies the influence of consistently reliable evaluators, aggregating peer judgments into consensus-based rankings that reflect collective model agreement. Our experiments demonstrate strong correlations with established benchmarks including MMLU-Pro and GPQA (respectively 78\\% and 63\\%), validating this peer-driven evaluation paradigm. The multi-judge design significantly outperforms single-judge baselines, confirming that distributed evaluation produces more robust and human-consistent assessments. AutoBench offers a scalable, contamination-resistant alternative to static benchmarks for the continuous evaluation of evolving language models.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "226",
        "title": "A Framework for Quantifying How Pre-Training and Context Benefit In-Context Learning",
        "author": [
            "Bingqing Song",
            "Jiaxiang Li",
            "Rong Wang",
            "Songtao Lu",
            "Mingyi Hong"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22594",
        "abstract": "Pre-trained large language models have demonstrated a strong ability to learn from context, known as in-context learning (ICL). Despite a surge of recent applications that leverage such capabilities, it is by no means clear, at least theoretically, how the ICL capabilities arise, and in particular, what is the precise role played by key factors such as pre-training procedure as well as context construction. In this work, we propose a new framework to analyze the ICL performance, for a class of realistic settings, which includes network architectures, data encoding, data generation, and prompt construction process. As a first step, we construct a simple example with a one-layer transformer, and show an interesting result, namely when the pre-train data distribution is different from the query task distribution, a properly constructed context can shift the output distribution towards the query task distribution, in a quantifiable manner, leading to accurate prediction on the query topic. We then extend the findings in the previous step to a more general case, and derive the precise relationship between ICL performance, context length and the KL divergence between pre-train and query task distribution. Finally, we provide experiments to validate our theoretical results.",
        "tags": [
            "LLM",
            "Transformer"
        ]
    },
    {
        "id": "227",
        "title": "RoGER-SLAM: A Robust Gaussian Splatting SLAM System for Noisy and Low-light Environment Resilience",
        "author": [
            "Huilin Yin",
            "Zhaolin Yang",
            "Linchuan Zhang",
            "Gerhard Rigoll",
            "Johannes Betz"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22600",
        "abstract": "The reliability of Simultaneous Localization and Mapping (SLAM) is severely constrained in environments where visual inputs suffer from noise and low illumination. Although recent 3D Gaussian Splatting (3DGS) based SLAM frameworks achieve high-fidelity mapping under clean conditions, they remain vulnerable to compounded degradations that degrade mapping and tracking performance. A key observation underlying our work is that the original 3DGS rendering pipeline inherently behaves as an implicit low-pass filter, attenuating high-frequency noise but also risking over-smoothing. Building on this insight, we propose RoGER-SLAM, a robust 3DGS SLAM system tailored for noise and low-light resilience. The framework integrates three innovations: a Structure-Preserving Robust Fusion (SP-RoFusion) mechanism that couples rendered appearance, depth, and edge cues; an adaptive tracking objective with residual balancing regularization; and a Contrastive Language-Image Pretraining (CLIP)-based enhancement module, selectively activated under compounded degradations to restore semantic and structural fidelity. Comprehensive experiments on Replica, TUM, and real-world sequences show that RoGER-SLAM consistently improves trajectory accuracy and reconstruction quality compared with other 3DGS-SLAM systems, especially under adverse imaging conditions.",
        "tags": [
            "3D",
            "CLIP",
            "Gaussian Splatting",
            "SLAM"
        ]
    },
    {
        "id": "228",
        "title": "Projection Embedded Diffusion Bridge for CT Reconstruction from Incomplete Data",
        "author": [
            "Yuang Wang",
            "Pengfei Jin",
            "Siyeop Yoon",
            "Matthew Tivnan",
            "Shaoyang Zhang",
            "Li Zhang",
            "Quanzheng Li",
            "Zhiqiang Chen",
            "Dufan Wu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22605",
        "abstract": "Reconstructing CT images from incomplete projection data remains challenging due to the ill-posed nature of the problem. Diffusion bridge models have recently shown promise in restoring clean images from their corresponding Filtered Back Projection (FBP) reconstructions, but incorporating data consistency into these models remains largely underexplored. Incorporating data consistency can improve reconstruction fidelity by aligning the reconstructed image with the observed projection data, and can enhance detail recovery by integrating structural information contained in the projections. In this work, we propose the Projection Embedded Diffusion Bridge (PEDB). PEDB introduces a novel reverse stochastic differential equation (SDE) to sample from the distribution of clean images conditioned on both the FBP reconstruction and the incomplete projection data. By explicitly conditioning on the projection data in sampling the clean images, PEDB naturally incorporates data consistency. We embed the projection data into the score function of the reverse SDE. Under certain assumptions, we derive a tractable expression for the posterior score. In addition, we introduce a free parameter to control the level of stochasticity in the reverse process. We also design a discretization scheme for the reverse SDE to mitigate discretization error. Extensive experiments demonstrate that PEDB achieves strong performance in CT reconstruction from three types of incomplete data, including sparse-view, limited-angle, and truncated projections. For each of these types, PEDB outperforms evaluated state-of-the-art diffusion bridge models across standard, noisy, and domain-shift evaluations.",
        "tags": [
            "Diffusion",
            "SDE"
        ]
    },
    {
        "id": "229",
        "title": "Everything counts: the managed omnirelevance of speech in 'human - voice agent' interaction",
        "author": [
            "Damien Rudaz",
            "Mathias Broth",
            "Jakub Mlynar"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22610",
        "abstract": "To this day, turn-taking models determining voice agents' conduct have been examined from a technical point of view, while the interactional constraints or resources they constitute for human conversationalists have not been empirically described. From the detailed analysis of corpora of naturalistic data, we document how, whether in interaction with rule-based robots from a 'pre-LLM era' or with the most recent voice agents, humans' conduct was produced in reference to the ever-present risk that, each time they spoke, their talk may trigger a new uncalled-for contribution from the artificial agent. We argue that this 'omnirelevance of human speech' is a constitutive feature of current human-agent interaction that, due to recent improvements in voice capture technology, weighs on human practices even more today than in the past. Specifically, we document how, in multiparty settings, humans shaped their conduct in such a way as to remain undetected by the machine's sensors.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "230",
        "title": "Does In-IDE Calibration of Large Language Models work at Scale?",
        "author": [
            "Roham Koohestani",
            "Agnia Sergeyuk",
            "David Gros",
            "Claudio Spiess",
            "Sergey Titov",
            "Prem Devanbu",
            "Maliheh Izadi"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22614",
        "abstract": "The introduction of large language models into integrated development environments (IDEs) is revolutionizing software engineering, yet it poses challenges to the usefulness and reliability of Artificial Intelligence-generated code. Post-hoc calibration of internal model confidences aims to align probabilities with an acceptability measure. Prior work suggests calibration can improve alignment, but at-scale evidence is limited. In this work, we investigate the feasibility of applying calibration of code models to an in-IDE context. We study two aspects of the problem: (1) the technical method for implementing confidence calibration and improving the reliability of code generation models, and (2) the human-centered design principles for effectively communicating reliability signal to developers. First, we develop a scalable and flexible calibration framework which can be used to obtain calibration weights for open-source models using any dataset, and evaluate whether calibrators improve the alignment between model confidence and developer acceptance behavior. Through a large-scale analysis of over 24 million real-world developer interactions across multiple programming languages, we find that a general, post-hoc calibration model based on Platt-scaling does not, on average, improve the reliability of model confidence signals. We also find that while dynamically personalizing calibration to individual users can be effective, its effectiveness is highly dependent on the volume of user interaction data. Second, we conduct a multi-phase design study with 3 expert designers and 153 professional developers, combining scenario-based design, semi-structured interviews, and survey validation, revealing a clear preference for presenting reliability signals via non-numerical, color-coded indicators within the in-editor code generation workflow.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "231",
        "title": "PerCoR: Evaluating Commonsense Reasoning in Persian via Multiple-Choice Sentence Completion",
        "author": [
            "Morteza Alikhani",
            "Mohammadtaha Bagherifard",
            "Erfan Zinvandi",
            "Mehran Sarmadi"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22616",
        "abstract": "We introduced PerCoR (Persian Commonsense Reasoning), the first large-scale Persian benchmark for commonsense reasoning. PerCoR contains 106K multiple-choice sentence-completion problems drawn from more than forty news, cultural, and other web sources. We introduce a novel conjunction-based segmentation strategy to generate coherent sentence-completion pairs, enabling broad topical and structural diversity. To create challenging distractors, we propose DRESS-AF (Distractor Ranking via Embedding Similarity Scoring and Adversarial Filtering), a generation-free adversarial filtering method that selects distractors from the pool of gold continuations while maximising model confusion. Human annotators score 89% on PerCoR, while OpenAI-o3 achieves the highest performance at 92.18%, followed closely by Claude-Sonnet-3.7 (91.17%). The strongest open-source model, DeepSeek-R1, reaches 82.51%, underscoring both the dataset's difficulty and the remaining performance gap in Persian commonsense reasoning. We further show that DRESS-AF transfers to the English HellaSwag benchmark, increasing its difficulty without hurting human solvability. The dataset is available at https://huggingface.co/datasets/MCINext/PerCoR.",
        "tags": [
            "DeepSeek",
            "Segmentation"
        ]
    },
    {
        "id": "232",
        "title": "Cross-Species Transfer Learning in Agricultural AI: Evaluating ZebraPose Adaptation for Dairy Cattle Pose Estimation",
        "author": [
            "Mackenzie Tapp",
            "Sibi Chakravarthy Parivendan",
            "Kashfia Sailunaz",
            "Suresh Neethirajan"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22618",
        "abstract": "Pose estimation serves as a cornerstone of computer vision for understanding animal posture, behavior, and welfare. Yet, agricultural applications remain constrained by the scarcity of large, annotated datasets for livestock, especially dairy cattle. This study evaluates the potential and limitations of cross-species transfer learning by adapting ZebraPose - a vision transformer-based model trained on synthetic zebra imagery - for 27-keypoint detection in dairy cows under real barn conditions. Using three configurations - a custom on-farm dataset (375 images, Sussex, New Brunswick, Canada), a subset of the APT-36K benchmark dataset, and their combination, we systematically assessed model accuracy and generalization across environments. While the combined model achieved promising performance (AP = 0.86, AR = 0.87, PCK 0.5 = 0.869) on in-distribution data, substantial generalization failures occurred when applied to unseen barns and cow populations. These findings expose the synthetic-to-real domain gap as a major obstacle to agricultural AI deployment and emphasize that morphological similarity between species is insufficient for cross-domain transfer. The study provides practical insights into dataset diversity, environmental variability, and computational constraints that influence real-world deployment of livestock monitoring systems. We conclude with a call for agriculture-first AI design, prioritizing farm-level realism, cross-environment robustness, and open benchmark datasets to advance trustworthy and scalable animal-centric technologies.",
        "tags": [
            "Detection",
            "Pose Estimation",
            "Transformer",
            "ViT"
        ]
    },
    {
        "id": "233",
        "title": "SwiftSolve: A Self-Iterative, Complexity-Aware Multi-Agent Framework for Competitive Programming",
        "author": [
            "Adhyayan Veer Singh",
            "Aaron Shen",
            "Brian Law",
            "Ahmed Ismail",
            "Jonas Rohweder",
            "Sean O'Brien",
            "Kevin Zhu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22626",
        "abstract": "Correctness alone is insufficient: LLM-generated programs frequently satisfy unit tests while violating contest time or memory budgets. We present SwiftSolve, a complexity-aware multi-agent system for competitive programming that couples algorithmic planning with empirical profiling and complexity-guided repair. We frame competitive programming as a software environment where specialized agents act as programmers, each assuming roles such as planning, coding, profiling, and complexity analysis. A Planner proposes an algorithmic sketch; a deterministic Static Pruner filters high-risk plans; a Coder emits ISO C++17; a Profiler compiles and executes candidates on a fixed input-size schedule to record wall time and peak memory; and a Complexity Analyst fits log-log growth (s, R2) with an LLM fallback to assign a complexity class and dispatch targeted patches to either the Planner or Coder. Agents communicate via typed, versioned JSON; a controller enforces iteration caps and diminishing returns stopping. Evaluated on 26 problems (16 BigO, 10 Codeforces Div. 2) in a POSIX sandbox (2 s / 256-512 MB), SwiftSolve attains pass@1 = 61.54% (16/26) on the first attempt and Solved@<=3 = 80.77% with marginal latency change (mean 11.96 s to 12.66 s per attempt). Aggregate run-level success is 73.08% at 12.40 s mean. Failures are predominantly resource-bound, indicating inefficiency rather than logic errors. Against Claude Opus 4, SwiftSolve improves run-level success (73.1% vs 52.6%) at approximately 2x runtime overhead (12.4 s vs 6.8 s). Beyond correctness (pass@k), we report efficiency metrics (eff@k for runtime and memory, incidence of TLE or MLE, and complexity fit accuracy on BigO), demonstrating that profiling and complexity-guided replanning reduce inefficiency while preserving accuracy.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "234",
        "title": "Sentra-Guard: A Multilingual Human-AI Framework for Real-Time Defense Against Adversarial LLM Jailbreaks",
        "author": [
            "Md. Mehedi Hasan",
            "Ziaur Rahman",
            "Rafid Mostafiz",
            "Md. Abir Hossain"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22628",
        "abstract": "This paper presents a real-time modular defense system named Sentra-Guard. The system detects and mitigates jailbreak and prompt injection attacks targeting large language models (LLMs). The framework uses a hybrid architecture with FAISS-indexed SBERT embedding representations that capture the semantic meaning of prompts, combined with fine-tuned transformer classifiers, which are machine learning models specialized for distinguishing between benign and adversarial language inputs. It identifies adversarial prompts in both direct and obfuscated attack vectors. A core innovation is the classifier-retriever fusion module, which dynamically computes context-aware risk scores that estimate how likely a prompt is to be adversarial based on its content and context. The framework ensures multilingual resilience with a language-agnostic preprocessing layer. This component automatically translates non-English prompts into English for semantic evaluation, enabling consistent detection across over 100 languages. The system includes a HITL feedback loop, where decisions made by the automated system are reviewed by human experts for continual learning and rapid adaptation under adversarial pressure. Sentra-Guard maintains an evolving dual-labeled knowledge base of benign and malicious prompts, enhancing detection reliability and reducing false positives. Evaluation results show a 99.96% detection rate (AUC = 1.00, F1 = 1.00) and an attack success rate (ASR) of only 0.004%. This outperforms leading baselines such as LlamaGuard-2 (1.3%) and OpenAI Moderation (3.7%). Unlike black-box approaches, Sentra-Guard is transparent, fine-tunable, and compatible with diverse LLM backends. Its modular design supports scalable deployment in both commercial and open-source environments. The system establishes a new state-of-the-art in adversarial LLM defense.",
        "tags": [
            "Detection",
            "LLM",
            "Transformer"
        ]
    },
    {
        "id": "235",
        "title": "Integrating Linguistics and AI: Morphological Analysis and Corpus development of Endangered Toto Language of West Bengal",
        "author": [
            "Ambalika Guha",
            "Sajal Saha",
            "Debanjan Ballav",
            "Soumi Mitra",
            "Hritwick Chakraborty"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22629",
        "abstract": "Preserving linguistic diversity is necessary as every language offers a distinct perspective on the world. There have been numerous global initiatives to preserve endangered languages through documentation. This paper is a part of a project which aims to develop a trilingual (Toto-Bangla-English) language learning application to digitally archive and promote the endangered Toto language of West Bengal, India. This application, designed for both native Toto speakers and non-native learners, aims to revitalize the language by ensuring accessibility and usability through Unicode script integration and a structured language corpus. The research includes detailed linguistic documentation collected via fieldwork, followed by the creation of a morpheme-tagged, trilingual corpus used to train a Small Language Model (SLM) and a Transformer-based translation engine. The analysis covers inflectional morphology such as person-number-gender agreement, tense-aspect-mood distinctions, and case marking, alongside derivational strategies that reflect word-class changes. Script standardization and digital literacy tools were also developed to enhance script usage. The study offers a sustainable model for preserving endangered languages by incorporating traditional linguistic methodology with AI. This bridge between linguistic research with technological innovation highlights the value of interdisciplinary collaboration for community-based language revitalization.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "236",
        "title": "FastVLM: Self-Speculative Decoding for Fast Vision-Language Model Inference",
        "author": [
            "Divya Jyoti Bajpai",
            "Manjesh Kumar Hanawal"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22641",
        "abstract": "Vision-language Models (VLMs) have made significant strides in visual understanding and query response generation, but often face challenges of high computational cost and inference latency due to autoregressive decoding. In this work, we introduce an imitation-learning-based Self-Speculative Decoding (SSD) framework, named FastVLM, to address these limitations. Our approach employs a lightweight draft model for token generation in an autoregressive manner, while a full model verifies these tokens non-autoregressively. Accepted tokens proceed seamlessly, while rejected tokens are corrected by the full model and used to guide the draft model's refinement. Through an imitation network, FastVLM enhances the draft model by integrating deeper level insights from the full model's architecture. Also, it maintains the performance integrity of the full model while training the draft model, achieving a balance between efficiency and accuracy. Our method speeds up the inference process by 1.55-1.85x as compared to the final layer with minimal loss in performance.",
        "tags": [
            "VLM"
        ]
    },
    {
        "id": "237",
        "title": "Self-Attention Decomposition For Training Free Diffusion Editing",
        "author": [
            "Tharun Anand",
            "Mohammad Hassan Vali",
            "Arno Solin"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22650",
        "abstract": "Diffusion models achieve remarkable fidelity in image synthesis, yet precise control over their outputs for targeted editing remains challenging. A key step toward controllability is to identify interpretable directions in the model's latent representations that correspond to semantic attributes. Existing approaches for finding interpretable directions typically rely on sampling large sets of images or training auxiliary networks, which limits efficiency. We propose an analytical method that derives semantic editing directions directly from the pretrained parameters of diffusion models, requiring neither additional data nor fine-tuning. Our insight is that self-attention weight matrices encode rich structural information about the data distribution learned during training. By computing the eigenvectors of these weight matrices, we obtain robust and interpretable editing directions. Experiments demonstrate that our method produces high-quality edits across multiple datasets while reducing editing time significantly by 60% over current benchmarks.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "238",
        "title": "UCB-type Algorithm for Budget-Constrained Expert Learning",
        "author": [
            "Ilgam Latypov",
            "Alexandra Suvorikova",
            "Alexey Kroshnin",
            "Alexander Gasnikov",
            "Yuriy Dorn"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22654",
        "abstract": "In many modern applications, a system must dynamically choose between several adaptive learning algorithms that are trained online. Examples include model selection in streaming environments, switching between trading strategies in finance, and orchestrating multiple contextual bandit or reinforcement learning agents. At each round, a learner must select one predictor among $K$ adaptive experts to make a prediction, while being able to update at most $M \\le K$ of them under a fixed training budget.\nWe address this problem in the \\emph{stochastic setting} and introduce \\algname{M-LCB}, a computationally efficient UCB-style meta-algorithm that provides \\emph{anytime regret guarantees}. Its confidence intervals are built directly from realized losses, require no additional optimization, and seamlessly reflect the convergence properties of the underlying experts. If each expert achieves internal regret $\\tilde O(T^\\alpha)$, then \\algname{M-LCB} ensures overall regret bounded by $\\tilde O\\!\\Bigl(\\sqrt{\\tfrac{KT}{M}} \\;+\\; (K/M)^{1-\\alpha}\\,T^\\alpha\\Bigr)$.\nTo our knowledge, this is the first result establishing regret guarantees when multiple adaptive experts are trained simultaneously under per-round budget constraints. We illustrate the framework with two representative cases: (i) parametric models trained online with stochastic losses, and (ii) experts that are themselves multi-armed bandit algorithms. These examples highlight how \\algname{M-LCB} extends the classical bandit paradigm to the more realistic scenario of coordinating stateful, self-learning experts under limited resources.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "239",
        "title": "Conjugate Relation Modeling for Few-Shot Knowledge Graph Completion",
        "author": [
            "Zilong Wang",
            "Qingtian Zeng",
            "Hua Duan",
            "Cheng Cheng",
            "Minghao Zou",
            "Ziyang Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22656",
        "abstract": "Few-shot Knowledge Graph Completion (FKGC) infers missing triples from limited support samples, tackling long-tail distribution challenges. Existing methods, however, struggle to capture complex relational patterns and mitigate data sparsity. To address these challenges, we propose a novel FKGC framework for conjugate relation modeling (CR-FKGC). Specifically, it employs a neighborhood aggregation encoder to integrate higher-order neighbor information, a conjugate relation learner combining an implicit conditional diffusion relation module with a stable relation module to capture stable semantics and uncertainty offsets, and a manifold conjugate decoder for efficient evaluation and inference of missing triples in manifold space. Experiments on three benchmarks demonstrate that our method achieves superior performance over state-of-the-art methods.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "240",
        "title": "LVD-GS: Gaussian Splatting SLAM for Dynamic Scenes via Hierarchical Explicit-Implicit Representation Collaboration Rendering",
        "author": [
            "Wenkai Zhu",
            "Xu Li",
            "Qimin Xu",
            "Benwu Wang",
            "Kun Wei",
            "Yiming Peng",
            "Zihang Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22669",
        "abstract": "3D Gaussian Splatting SLAM has emerged as a widely used technique for high-fidelity mapping in spatial intelligence. However, existing methods often rely on a single representation scheme, which limits their performance in large-scale dynamic outdoor scenes and leads to cumulative pose errors and scale ambiguity. To address these challenges, we propose \\textbf{LVD-GS}, a novel LiDAR-Visual 3D Gaussian Splatting SLAM system. Motivated by the human chain-of-thought process for information seeking, we introduce a hierarchical collaborative representation module that facilitates mutual reinforcement for mapping optimization, effectively mitigating scale drift and enhancing reconstruction robustness. Furthermore, to effectively eliminate the influence of dynamic objects, we propose a joint dynamic modeling module that generates fine-grained dynamic masks by fusing open-world segmentation with implicit residual constraints, guided by uncertainty estimates from DINO-Depth features. Extensive evaluations on KITTI, nuScenes, and self-collected datasets demonstrate that our approach achieves state-of-the-art performance compared to existing methods.",
        "tags": [
            "3D",
            "CoT",
            "Gaussian Splatting",
            "SLAM",
            "Segmentation"
        ]
    },
    {
        "id": "241",
        "title": "Tools are under-documented: Simple Document Expansion Boosts Tool Retrieval",
        "author": [
            "Xuan Lu",
            "Haohang Huang",
            "Rui Meng",
            "Yaohui Jin",
            "Wenjun Zeng",
            "Xiaoyu Shen"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22670",
        "abstract": "Large Language Models (LLMs) have recently demonstrated strong capabilities in tool use, yet progress in tool retrieval remains hindered by incomplete and heterogeneous tool documentation. To address this challenge, we introduce Tool-DE, a new benchmark and framework that systematically enriches tool documentation with structured fields to enable more effective tool retrieval, together with two dedicated models, Tool-Embed and Tool-Rank. We design a scalable document expansion pipeline that leverages both open- and closed-source LLMs to generate, validate, and refine enriched tool profiles at low cost, producing large-scale corpora with 50k instances for embedding-based retrievers and 200k for rerankers. On top of this data, we develop two models specifically tailored for tool retrieval: Tool-Embed, a dense retriever, and Tool-Rank, an LLM-based reranker. Extensive experiments on ToolRet and Tool-DE demonstrate that document expansion substantially improves retrieval performance, with Tool-Embed and Tool-Rank achieving new state-of-the-art results on both benchmarks. We further analyze the contribution of individual fields to retrieval effectiveness, as well as the broader impact of document expansion on both training and evaluation. Overall, our findings highlight both the promise and limitations of LLM-driven document expansion, positioning Tool-DE, along with the proposed Tool-Embed and Tool-Rank, as a foundation for future research in tool retrieval.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "242",
        "title": "Alias-Free ViT: Fractional Shift Invariance via Linear Attention",
        "author": [
            "Hagay Michaeli",
            "Daniel Soudry"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22673",
        "abstract": "Transformers have emerged as a competitive alternative to convnets in vision tasks, yet they lack the architectural inductive bias of convnets, which may hinder their potential performance. Specifically, Vision Transformers (ViTs) are not translation-invariant and are more sensitive to minor image translations than standard convnets. Previous studies have shown, however, that convnets are also not perfectly shift-invariant, due to aliasing in downsampling and nonlinear layers. Consequently, anti-aliasing approaches have been proposed to certify convnets' translation robustness. Building on this line of work, we propose an Alias-Free ViT, which combines two main components. First, it uses alias-free downsampling and nonlinearities. Second, it uses linear cross-covariance attention that is shift-equivariant to both integer and fractional translations, enabling a shift-invariant global representation. Our model maintains competitive performance in image classification and outperforms similar-sized models in terms of robustness to adversarial translations.",
        "tags": [
            "ViT"
        ]
    },
    {
        "id": "243",
        "title": "Do Stop Me Now: Detecting Boilerplate Responses with a Single Iteration",
        "author": [
            "Yuval Kainan",
            "Shaked Zychlinski"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22679",
        "abstract": "Large Language Models (LLMs) often expend significant computational resources generating boilerplate responses, such as refusals, simple acknowledgements and casual greetings, which adds unnecessary cost and latency. To address this inefficiency, we propose a simple yet highly effective method for detecting such responses after only a single generation step. We demonstrate that the log-probability distribution of the first generated token serves as a powerful signal for classifying the nature of the entire subsequent response. Our experiments, conducted across a diverse range of small, large, and reasoning-specialized models, show that the first-token log-probability vectors form distinctly separable clusters for different response types. Using a lightweight k-NN classifier, we achieve high accuracy in predicting whether a response will be a substantive answer or a form of boilerplate response, including user-specified refusals. The primary implication is a practical, computationally trivial technique, optimizing LLM inference by enabling early termination or redirection to a smaller model, thereby yielding significant savings in computational cost. This work presents a direct path toward more efficient and sustainable LLM deployment.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "244",
        "title": "Uncertainty-Aware Autonomous Vehicles: Predicting the Road Ahead",
        "author": [
            "Shireen Kudukkil Manchingal",
            "Armand Amaritei",
            "Mihir Gohad",
            "Maryam Sultana",
            "Julian F. P. Kooij",
            "Fabio Cuzzolin",
            "Andrew Bradley"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22680",
        "abstract": "Autonomous Vehicle (AV) perception systems have advanced rapidly in recent years, providing vehicles with the ability to accurately interpret their environment. Perception systems remain susceptible to errors caused by overly-confident predictions in the case of rare events or out-of-sample data. This study equips an autonomous vehicle with the ability to 'know when it is uncertain', using an uncertainty-aware image classifier as part of the AV software stack. Specifically, the study exploits the ability of Random-Set Neural Networks (RS-NNs) to explicitly quantify prediction uncertainty. Unlike traditional CNNs or Bayesian methods, RS-NNs predict belief functions over sets of classes, allowing the system to identify and signal uncertainty clearly in novel or ambiguous scenarios. The system is tested in a real-world autonomous racing vehicle software stack, with the RS-NN classifying the layout of the road ahead and providing the associated uncertainty of the prediction. Performance of the RS-NN under a range of road conditions is compared against traditional CNN and Bayesian neural networks, with the RS-NN achieving significantly higher accuracy and superior uncertainty calibration. This integration of RS-NNs into Robot Operating System (ROS)-based vehicle control pipeline demonstrates that predictive uncertainty can dynamically modulate vehicle speed, maintaining high-speed performance under confident predictions while proactively improving safety through speed reductions in uncertain scenarios. These results demonstrate the potential of uncertainty-aware neural networks - in particular RS-NNs - as a practical solution for safer and more robust autonomous driving.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "245",
        "title": "RoboSVG: A Unified Framework for Interactive SVG Generation with Multi-modal Guidance",
        "author": [
            "Jiuniu Wang",
            "Gongjie Zhang",
            "Quanhao Qian",
            "Junlong Gao",
            "Deli Zhao",
            "Ran Xu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22684",
        "abstract": "Scalable Vector Graphics (SVGs) are fundamental to digital design and robot control, encoding not only visual structure but also motion paths in interactive drawings. In this work, we introduce RoboSVG, a unified multimodal framework for generating interactive SVGs guided by textual, visual, and numerical signals. Given an input query, the RoboSVG model first produces multimodal guidance, then synthesizes candidate SVGs through dedicated generation modules, and finally refines them under numerical guidance to yield high-quality outputs. To support this framework, we construct RoboDraw, a large-scale dataset of one million examples, each pairing an SVG generation condition (e.g., text, image, and partial SVG) with its corresponding ground-truth SVG code. RoboDraw dataset enables systematic study of four tasks, including basic generation (Text-to-SVG, Image-to-SVG) and interactive generation (PartialSVG-to-SVG, PartialImage-to-SVG). Extensive experiments demonstrate that RoboSVG achieves superior query compliance and visual fidelity across tasks, establishing a new state of the art in versatile SVG generation. The dataset and source code of this project will be publicly available soon.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "246",
        "title": "FlowCritic: Bridging Value Estimation with Flow Matching in Reinforcement Learning",
        "author": [
            "Shan Zhong",
            "Shutong Ding",
            "He Diao",
            "Xiangyu Wang",
            "Kah Chan Teh",
            "Bei Peng"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22686",
        "abstract": "Reliable value estimation serves as the cornerstone of reinforcement learning (RL) by evaluating long-term returns and guiding policy improvement, significantly influencing the convergence speed and final performance. Existing works improve the reliability of value function estimation via multi-critic ensembles and distributional RL, yet the former merely combines multi point estimation without capturing distributional information, whereas the latter relies on discretization or quantile regression, limiting the expressiveness of complex value distributions. Inspired by flow matching's success in generative modeling, we propose a generative paradigm for value estimation, named FlowCritic. Departing from conventional regression for deterministic value prediction, FlowCritic leverages flow matching to model value distributions and generate samples for value estimation.",
        "tags": [
            "Flow Matching",
            "RL"
        ]
    },
    {
        "id": "247",
        "title": "Rule-Based Explanations for Retrieval-Augmented LLM Systems",
        "author": [
            "Joel Rorseth",
            "Parke Godfrey",
            "Lukasz Golab",
            "Divesh Srivastava",
            "Jarek Szlichta"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22689",
        "abstract": "If-then rules are widely used to explain machine learning models; e.g., \"if employed = no, then loan application = rejected.\" We present the first proposal to apply rules to explain the emerging class of large language models (LLMs) with retrieval-augmented generation (RAG). Since RAG enables LLM systems to incorporate retrieved information sources at inference time, rules linking the presence or absence of sources can explain output provenance; e.g., \"if a Times Higher Education ranking article is retrieved, then the LLM ranks Oxford first.\" To generate such rules, a brute force approach would probe the LLM with all source combinations and check if the presence or absence of any sources leads to the same output. We propose optimizations to speed up rule generation, inspired by Apriori-like pruning from frequent itemset mining but redefined within the scope of our novel problem. We conclude with qualitative and quantitative experiments demonstrating our solutions' value and efficiency.",
        "tags": [
            "LLM",
            "RAG"
        ]
    },
    {
        "id": "248",
        "title": "SALSA: Single-pass Autoregressive LLM Structured Classification",
        "author": [
            "Ruslan Berdichevsky",
            "Shai Nahum-Gefen",
            "Elad Ben Zaken"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22691",
        "abstract": "Despite their impressive generalization capabilities, instruction-tuned Large Language Models often underperform on text classification benchmarks. We introduce SALSA, a coherent pipeline that combines structured prompting, class-to-token mapping, and parameter-efficient fine-tuning, thereby avoiding cold-start training. Each class label is mapped to a distinct output token, and prompts are constructed to elicit a single-token response. During inference, the model's output is projected only onto the logits of the relevant class tokens, enabling efficient and accurate classification in a single forward pass. SALSA achieves state-of-the-art results across diverse benchmarks, demonstrating its robustness and scalability for LLM-based classification applications.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "249",
        "title": "Windsock is Dancing: Adaptive Multimodal Retrieval-Augmented Generation",
        "author": [
            "Shu Zhao",
            "Tianyi Shen",
            "Nilesh Ahuja",
            "Omesh Tickoo",
            "Vijaykrishnan Narayanan"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22694",
        "abstract": "Multimodal Retrieval-Augmented Generation (MRAG) has emerged as a promising method to generate factual and up-to-date responses of Multimodal Large Language Models (MLLMs) by incorporating non-parametric knowledge from external knowledge bases. However, existing MRAG approaches suffer from static retrieval strategies, inflexible modality selection, and suboptimal utilization of retrieved information, leading to three critical challenges: determining when to retrieve, what modality to incorporate, and how to utilize retrieved information effectively. To address these challenges, we introduce Windsock, a query-dependent module making decisions on retrieval necessity and modality selection, effectively reducing computational overhead and improving response quality. Additionally, we propose Dynamic Noise-Resistance (DANCE) Instruction Tuning, an adaptive training strategy that enhances MLLMs' ability to utilize retrieved information while maintaining robustness against noise. Moreover, we adopt a self-assessment approach leveraging knowledge within MLLMs to convert question-answering datasets to MRAG training datasets. Extensive experiments demonstrate that our proposed method significantly improves the generation quality by 17.07% while reducing 8.95% retrieval times.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "250",
        "title": "RL-AVIST: Reinforcement Learning for Autonomous Visual Inspection of Space Targets",
        "author": [
            "Matteo El-Hariry",
            "Andrej Orsula",
            "Matthieu Geist",
            "Miguel Olivares-Mendez"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22699",
        "abstract": "The growing need for autonomous on-orbit services such as inspection, maintenance, and situational awareness calls for intelligent spacecraft capable of complex maneuvers around large orbital targets. Traditional control systems often fall short in adaptability, especially under model uncertainties, multi-spacecraft configurations, or dynamically evolving mission contexts. This paper introduces RL-AVIST, a Reinforcement Learning framework for Autonomous Visual Inspection of Space Targets. Leveraging the Space Robotics Bench (SRB), we simulate high-fidelity 6-DOF spacecraft dynamics and train agents using DreamerV3, a state-of-the-art model-based RL algorithm, with PPO and TD3 as model-free baselines. Our investigation focuses on 3D proximity maneuvering tasks around targets such as the Lunar Gateway and other space assets. We evaluate task performance under two complementary regimes: generalized agents trained on randomized velocity vectors, and specialized agents trained to follow fixed trajectories emulating known inspection orbits. Furthermore, we assess the robustness and generalization of policies across multiple spacecraft morphologies and mission domains. Results demonstrate that model-based RL offers promising capabilities in trajectory fidelity, and sample efficiency, paving the way for scalable, retrainable control solutions for future space operations",
        "tags": [
            "3D",
            "PPO",
            "RL",
            "Robotics"
        ]
    },
    {
        "id": "251",
        "title": "Atlas Urban Index: A VLM-Based Approach for Spatially and Temporally Calibrated Urban Development Monitoring",
        "author": [
            "Mithul Chander",
            "Sai Pragnya Ranga",
            "Prathamesh Mayekar"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22702",
        "abstract": "We introduce the {\\em Atlas Urban Index} (AUI), a metric for measuring urban development computed using Sentinel-2 \\citep{spoto2012sentinel2} satellite imagery. Existing approaches, such as the {\\em Normalized Difference Built-up Index} (NDBI), often struggle to accurately capture urban development due to factors like atmospheric noise, seasonal variation, and cloud cover. These limitations hinder large-scale monitoring of human development and urbanization. To address these challenges, we propose an approach that leverages {\\em Vision-Language Models }(VLMs) to provide a development score for regions. Specifically, we collect a time series of Sentinel-2 images for each region. Then, we further process the images within fixed time windows to get an image with minimal cloud cover, which serves as the representative image for that time window. To ensure consistent scoring, we adopt two strategies: (i) providing the VLM with a curated set of reference images representing different levels of urbanization, and (ii) supplying the most recent past image to both anchor temporal consistency and mitigate cloud-related noise in the current image. Together, these components enable AUI to overcome the challenges of traditional urbanization indices and produce more reliable and stable development scores. Our qualitative experiments on Bangalore suggest that AUI outperforms standard indices such as NDBI.",
        "tags": [
            "VLM"
        ]
    },
    {
        "id": "252",
        "title": "IGGT: Instance-Grounded Geometry Transformer for Semantic 3D Reconstruction",
        "author": [
            "Hao Li",
            "Zhengyu Zou",
            "Fangfu Liu",
            "Xuanyang Zhang",
            "Fangzhou Hong",
            "Yukang Cao",
            "Yushi Lan",
            "Manyuan Zhang",
            "Gang Yu",
            "Dingwen Zhang",
            "Ziwei Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22706",
        "abstract": "Humans naturally perceive the geometric structure and semantic content of a 3D world as intertwined dimensions, enabling coherent and accurate understanding of complex scenes. However, most prior approaches prioritize training large geometry models for low-level 3D reconstruction and treat high-level spatial understanding in isolation, overlooking the crucial interplay between these two fundamental aspects of 3D-scene analysis, thereby limiting generalization and leading to poor performance in downstream 3D understanding tasks. Recent attempts have mitigated this issue by simply aligning 3D models with specific language models, thus restricting perception to the aligned model's capacity and limiting adaptability to downstream tasks. In this paper, we propose InstanceGrounded Geometry Transformer (IGGT), an end-to-end large unified transformer to unify the knowledge for both spatial reconstruction and instance-level contextual understanding. Specifically, we design a 3D-Consistent Contrastive Learning strategy that guides IGGT to encode a unified representation with geometric structures and instance-grounded clustering through only 2D visual inputs. This representation supports consistent lifting of 2D visual inputs into a coherent 3D scene with explicitly distinct object instances. To facilitate this task, we further construct InsScene-15K, a large-scale dataset with high-quality RGB images, poses, depth maps, and 3D-consistent instance-level mask annotations with a novel data curation pipeline.",
        "tags": [
            "3D",
            "Transformer"
        ]
    },
    {
        "id": "253",
        "title": "RaCoT: Plug-and-Play Contrastive Example Generation Mechanism for Enhanced LLM Reasoning Reliability",
        "author": [
            "Kaitong Cai",
            "Jusheng Zhang",
            "Yijia Fan",
            "Jing Yang",
            "Keze Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22710",
        "abstract": "Retrieval-Augmented Generation (RAG) faces a core bottleneck with knowledge-sparse and semantically ambiguous long-tail queries, where retrieval noise distorts reasoning and necessitates costly post-processing. To tackle this, we propose RaCoT (Retrieval-aware Contrastive-of-Thought), a novel framework that shifts contrastive thinking to the pre-retrieval stage. By automatically generating a semantically adjacent yet differently answered contrastive question and extracting a $\\Delta$-Prompt to capture their key differences, RaCoT guides the model to proactively focus on the ``critical details that determine answer divergence.\" This approach allows it to suppress semantic interference within a single retrieval pass, overcoming the theoretical bottleneck of single-vector queries that struggle to simultaneously encode signals for what to attend to and what to ignore. On six authoritative benchmarks, including PopQA and TriviaQA-unfiltered, RaCoT outperforms strong baselines like RankRAG and Self-RAG by 0.9-2.4 percentage points. It exhibits superior robustness, with a performance drop of only 8.6\\% in adversarial tests, far surpassing the over 15\\% degradation in other methods. Furthermore, its low latency (3.12s) and token overhead (11.54) place it on the accuracy-efficiency Pareto frontier, while ablation studies validate the necessity of each component. Ultimately, RaCoT reframes the RAG paradigm from ``post-hoc context cleaning\" to ``a priori shaping of discriminative reasoning\", offering an efficient and robust path toward reliable AI systems for real-time, resource-constrained deployments.",
        "tags": [
            "LLM",
            "RAG"
        ]
    },
    {
        "id": "254",
        "title": "LRW-Persian: Lip-reading in the Wild Dataset for Persian Language",
        "author": [
            "Zahra Taghizadeh",
            "Mohammad Shahverdikondori",
            "Arian Noori",
            "Alireza Dadgarnia"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22716",
        "abstract": "Lipreading has emerged as an increasingly important research area for developing robust speech recognition systems and assistive technologies for the hearing-impaired. However, non-English resources for visual speech recognition remain limited. We introduce LRW-Persian, the largest in-the-wild Persian word-level lipreading dataset, comprising $743$ target words and over $414{,}000$ video samples extracted from more than $1{,}900$ hours of footage across $67$ television programs. Designed as a benchmark-ready resource, LRW-Persian provides speaker-disjoint training and test splits, wide regional and dialectal coverage, and rich per-clip metadata including head pose, age, and gender. To ensure large-scale data quality, we establish a fully automated end-to-end curation pipeline encompassing transcription based on Automatic Speech Recognition(ASR), active-speaker localization, quality filtering, and pose/mask screening. We further fine-tune two widely used lipreading architectures on LRW-Persian, establishing reference performance and demonstrating the difficulty of Persian visual speech recognition. By filling a critical gap in low-resource languages, LRW-Persian enables rigorous benchmarking, supports cross-lingual transfer, and provides a foundation for advancing multimodal speech research in underrepresented linguistic contexts. The dataset is publicly available at: https://lrw-persian.vercel.app.",
        "tags": [
            "CLIP"
        ]
    },
    {
        "id": "255",
        "title": "Edge Collaborative Gaussian Splatting with Integrated Rendering and Communication",
        "author": [
            "Yujie Wan",
            "Chenxuan Liu",
            "Shuai Wang",
            "Tong Zhang",
            "James Jianqiao Yu",
            "Kejiang Ye",
            "Dusit Niyato",
            "Chengzhong Xu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22718",
        "abstract": "Gaussian splatting (GS) struggles with degraded rendering quality on low-cost devices. To address this issue, we present edge collaborative GS (ECO-GS), where each user can switch between a local small GS model to guarantee timeliness and a remote large GS model to guarantee fidelity. However, deciding how to engage the large GS model is nontrivial, due to the interdependency between rendering requirements and resource conditions. To this end, we propose integrated rendering and communication (IRAC), which jointly optimizes collaboration status (i.e., deciding whether to engage large GS) and edge power allocation (i.e., enabling remote rendering) under communication constraints across different users by minimizing a newly-derived GS switching function. Despite the nonconvexity of the problem, we propose an efficient penalty majorization minimization (PMM) algorithm to obtain the critical point solution. Furthermore, we develop an imitation learning optimization (ILO) algorithm, which reduces the computational time by over 100x compared to PMM. Experiments demonstrate the superiority of PMM and the real-time execution capability of ILO.",
        "tags": [
            "Gaussian Splatting"
        ]
    },
    {
        "id": "256",
        "title": "Critical Insights into Leading Conversational AI Models",
        "author": [
            "Urja Kohli",
            "Aditi Singh",
            "Arun Sharma"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22729",
        "abstract": "Big Language Models (LLMs) are changing the way businesses use software, the way people live their lives and the way industries work. Companies like Google, High-Flyer, Anthropic, OpenAI and Meta are making better LLMs. So, it's crucial to look at how each model is different in terms of performance, moral behaviour and usability, as these differences are based on the different ideas that built them. This study compares five top LLMs: Google's Gemini, High-Flyer's DeepSeek, Anthropic's Claude, OpenAI's GPT models and Meta's LLaMA. It performs this by analysing three important factors: Performance and Accuracy, Ethics and Bias Mitigation and Usability and Integration. It was found that Claude has good moral reasoning, Gemini is better at multimodal capabilities and has strong ethical frameworks. DeepSeek is great at reasoning based on facts, LLaMA is good for open applications and ChatGPT delivers balanced performance with a focus on usage. It was concluded that these models are different in terms of how well they work, how easy they are to use and how they treat people ethically, making it a point that each model should be utilised by the user in a way that makes the most of its strengths.",
        "tags": [
            "DeepSeek",
            "GPT",
            "LLM",
            "LLaMA"
        ]
    },
    {
        "id": "257",
        "title": "ATLAS: Actor-Critic Task-Completion with Look-ahead Action Simulation",
        "author": [
            "Jiali Cheng",
            "Anjishnu Kumar",
            "Roshan Lal",
            "Rishi Rajasekaran",
            "Hani Ramezani",
            "Omar Zia Khan",
            "Oleg Rokhlenko",
            "Sunny Chiu-Webster",
            "Gang Hua",
            "Hadi Amiri"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22732",
        "abstract": "We observe that current state-of-the-art web-agents are unable to effectively adapt to new environments without neural network fine-tuning, without which they produce inefficient execution plans due to a lack of awareness of the structure and dynamics of the new environment. To address this limitation, we introduce ATLAS (Actor-Critic Task-completion with Look-ahead Action Simulation), a memory-augmented agent that is able to make plans grounded in a model of the environment by simulating the consequences of those actions in cognitive space. Our agent starts by building a \"cognitive map\" by performing a lightweight curiosity driven exploration of the environment. The planner proposes candidate actions; the simulator predicts their consequences in cognitive space; a critic analyzes the options to select the best roll-out and update the original plan; and a browser executor performs the chosen action. On the WebArena-Lite Benchmark, we achieve a 63% success rate compared to 53.9% success rate for the previously published state-of-the-art. Unlike previous systems, our modular architecture requires no website-specific LLM fine-tuning. Ablations show sizable drops without the world-model, hierarchical planner, and look-ahead-based replanner confirming their complementary roles within the design of our system",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "258",
        "title": "$\\text{E}^2\\text{Rank}$: Your Text Embedding can Also be an Effective and Efficient Listwise Reranker",
        "author": [
            "Qi Liu",
            "Yanzhao Zhang",
            "Mingxin Li",
            "Dingkun Long",
            "Pengjun Xie",
            "Jiaxin Mao"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22733",
        "abstract": "Text embedding models serve as a fundamental component in real-world search applications. By mapping queries and documents into a shared embedding space, they deliver competitive retrieval performance with high efficiency. However, their ranking fidelity remains limited compared to dedicated rerankers, especially recent LLM-based listwise rerankers, which capture fine-grained query-document and document-document interactions. In this paper, we propose a simple yet effective unified framework $\\text{E}^2\\text{Rank}$, means Efficient Embedding-based Ranking (also means Embedding-to-Rank), which extends a single text embedding model to perform both high-quality retrieval and listwise reranking through continued training under a listwise ranking objective, thereby achieving strong effectiveness with remarkable efficiency. By applying cosine similarity between the query and document embeddings as a unified ranking function, the listwise ranking prompt, which is constructed from the original query and its candidate documents, serves as an enhanced query enriched with signals from the top-K documents, akin to pseudo-relevance feedback (PRF) in traditional retrieval models. This design preserves the efficiency and representational quality of the base embedding model while significantly improving its reranking performance. Empirically, $\\textrm{E}^2\\text{Rank}$ achieves state-of-the-art results on the BEIR reranking benchmark and demonstrates competitive performance on the reasoning-intensive BRIGHT benchmark, with very low reranking latency. We also show that the ranking training process improves embedding performance on the MTEB benchmark. Our findings indicate that a single embedding model can effectively unify retrieval and reranking, offering both computational efficiency and competitive ranking accuracy.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "259",
        "title": "Cross-view Localization and Synthesis - Datasets, Challenges and Opportunities",
        "author": [
            "Ningli Xu",
            "Rongjun Qin"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22736",
        "abstract": "Cross-view localization and synthesis are two fundamental tasks in cross-view visual understanding, which deals with cross-view datasets: overhead (satellite or aerial) and ground-level imagery. These tasks have gained increasing attention due to their broad applications in autonomous navigation, urban planning, and augmented reality. Cross-view localization aims to estimate the geographic position of ground-level images based on information provided by overhead imagery while cross-view synthesis seeks to generate ground-level images based on information from the overhead imagery. Both tasks remain challenging due to significant differences in viewing perspective, resolution, and occlusion, which are widely embedded in cross-view datasets. Recent years have witnessed rapid progress driven by the availability of large-scale datasets and novel approaches. Typically, cross-view localization is formulated as an image retrieval problem where ground-level features are matched with tiled overhead images feature, extracted by convolutional neural networks (CNNs) or vision transformers (ViTs) for cross-view feature embedding. Cross-view synthesis, on the other hand, seeks to generate ground-level views based on information from overhead imagery, generally using generative adversarial networks (GANs) or diffusion models. This paper presents a comprehensive survey of advances in cross-view localization and synthesis, reviewing widely used datasets, highlighting key challenges, and providing an organized overview of state-of-the-art techniques. Furthermore, it discusses current limitations, offers comparative analyses, and outlines promising directions for future research. We also include the project page via https://github.com/GDAOSU/Awesome-Cross-View-Methods.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "260",
        "title": "Policies over Poses: Reinforcement Learning based Distributed Pose-Graph Optimization for Multi-Robot SLAM",
        "author": [
            "Sai Krishna Ghanta",
            "Ramviyas Parasuraman"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22740",
        "abstract": "We consider the distributed pose-graph optimization (PGO) problem, which is fundamental in accurate trajectory estimation in multi-robot simultaneous localization and mapping (SLAM). Conventional iterative approaches linearize a highly non-convex optimization objective, requiring repeated solving of normal equations, which often converge to local minima and thus produce suboptimal estimates. We propose a scalable, outlier-robust distributed planar PGO framework using Multi-Agent Reinforcement Learning (MARL). We cast distributed PGO as a partially observable Markov game defined on local pose-graphs, where each action refines a single edge's pose estimate. A graph partitioner decomposes the global pose graph, and each robot runs a recurrent edge-conditioned Graph Neural Network (GNN) encoder with adaptive edge-gating to denoise noisy edges. Robots sequentially refine poses through a hybrid policy that utilizes prior action memory and graph embeddings. After local graph correction, a consensus scheme reconciles inter-robot disagreements to produce a globally consistent estimate. Our extensive evaluations on a comprehensive suite of synthetic and real-world datasets demonstrate that our learned MARL-based actors reduce the global objective by an average of 37.5% more than the state-of-the-art distributed PGO framework, while enhancing inference efficiency by at least 6X. We also demonstrate that actor replication allows a single learned policy to scale effortlessly to substantially larger robot teams without any retraining. Code is publicly available at https://github.com/herolab-uga/policies-over-poses.",
        "tags": [
            "RL",
            "Robotics",
            "SLAM"
        ]
    },
    {
        "id": "261",
        "title": "Low-Resource Dialect Adaptation of Large Language Models: A French Dialect Case-Study",
        "author": [
            "Eeham Khan",
            "Firas Saidani",
            "Owen Van Esbroeck",
            "Richard Khoury",
            "Leila Kosseim"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22747",
        "abstract": "Despite the widespread adoption of large language models (LLMs), their strongest capabilities remain largely confined to a small number of high-resource languages for which there is abundant training data. Recently, continual pre-training (CPT) has emerged as a means to fine-tune these models to low-resource regional dialects. In this paper, we study the use of CPT for dialect learning under tight data and compute budgets. Using low-rank adaptation (LoRA) and compute-efficient continual pre-training, we adapt three LLMs to the QuÃ©bec French dialect using a very small dataset and benchmark them on the COLE suite. Our experiments demonstrate an improvement on the minority dialect benchmarks with minimal regression on the prestige language benchmarks with under 1% of model parameters updated. Analysis of the results demonstrate that gains are highly contingent on corpus composition. These findings indicate that CPT with parameter-efficient fine-tuning (PEFT) can narrow the dialect gap by providing cost-effective and sustainable language resource creation, expanding high-quality LLM access to minority linguistic communities. We release the first QuÃ©bec French LLMs on HuggingFace.",
        "tags": [
            "LLM",
            "LoRA"
        ]
    },
    {
        "id": "262",
        "title": "Multi-Modal Fact-Verification Framework for Reducing Hallucinations in Large Language Models",
        "author": [
            "Piyushkumar Patel"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22751",
        "abstract": "While Large Language Models have transformed how we interact with AI systems, they suffer from a critical flaw: they confidently generate false information that sounds entirely plausible. This hallucination problem has become a major barrier to deploying these models in real-world applications where accuracy matters. We developed a fact verification framework that catches and corrects these errors in real-time by cross checking LLM outputs against multiple knowledge sources. Our system combines structured databases, live web searches, and academic literature to verify factual claims as they're generated. When we detect inconsistencies, we automatically correct them while preserving the natural flow of the response. Testing across various domains showed we could reduce hallucinations by 67% without sacrificing response quality. Domain experts in healthcare, finance, and scientific research rated our corrected outputs 89% satisfactory a significant improvement over unverified LLM responses. This work offers a practical solution for making LLMs more trustworthy in applications where getting facts wrong isn't an option.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "263",
        "title": "Beyond Semantics: How Temporal Biases Shape Retrieval in Transformer and State-Space Models",
        "author": [
            "Anooshka Bajaj",
            "Deven Mahesh Mistry",
            "Sahaj Singh Maini",
            "Yash Aggarwal",
            "Zoran Tiganj"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22752",
        "abstract": "In-context learning is governed by both temporal and semantic relationships, shaping how Large Language Models (LLMs) retrieve contextual information. Analogous to human episodic memory, where the retrieval of specific events is enabled by separating events that happened at different times, this work probes the ability of various pretrained LLMs, including transformer and state-space models, to differentiate and retrieve temporally separated events. Specifically, we prompted models with sequences containing multiple presentations of the same token, which reappears at the sequence end. By fixing the positions of these repeated tokens and permuting all others, we removed semantic confounds and isolated temporal effects on next-token prediction. Across diverse sequences, models consistently placed the highest probabilities on tokens following a repeated token, but with a notable bias for those nearest the beginning or end of the input. An ablation experiment linked this phenomenon in transformers to induction heads. Extending the analysis to unique semantic contexts with partial overlap further demonstrated that memories embedded in the middle of a prompt are retrieved less reliably. Despite architectural differences, state-space and transformer models showed comparable temporal biases. Our findings deepen the understanding of temporal biases in in-context learning and offer an illustration of how these biases can enable temporal separation and episodic retrieval.",
        "tags": [
            "LLM",
            "SSMs",
            "Transformer"
        ]
    },
    {
        "id": "264",
        "title": "TWC-SLAM: Multi-Agent Cooperative SLAM with Text Semantics and WiFi Features Integration for Similar Indoor Environments",
        "author": [
            "Chunyu Li",
            "Shoubin Chen",
            "Dong Li",
            "Weixing Xue",
            "Qingquan Li"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22754",
        "abstract": "Multi-agent cooperative SLAM often encounters challenges in similar indoor environments characterized by repetitive structures, such as corridors and rooms. These challenges can lead to significant inaccuracies in shared location identification when employing point cloud-based techniques. To mitigate these issues, we introduce TWC-SLAM, a multi-agent cooperative SLAM framework that integrates text semantics and WiFi signal features to enhance location identification and loop closure detection. TWC-SLAM comprises a single-agent front-end odometry module based on FAST-LIO2, a location identification and loop closure detection module that leverages text semantics and WiFi features, and a global mapping module. The agents are equipped with sensors capable of capturing textual information and detecting WiFi signals. By correlating these data sources, TWC-SLAM establishes a common location, facilitating point cloud alignment across different agents' maps. Furthermore, the system employs loop closure detection and optimization modules to achieve global optimization and cohesive mapping. We evaluated our approach using an indoor dataset featuring similar corridors, rooms, and text signs. The results demonstrate that TWC-SLAM significantly improves the performance of cooperative SLAM systems in complex environments with repetitive architectural features.",
        "tags": [
            "Detection",
            "SLAM"
        ]
    },
    {
        "id": "265",
        "title": "Distributionally Robust Optimization via Diffusion Ambiguity Modeling",
        "author": [
            "Jiaqi Wen",
            "Jianyi Yang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22757",
        "abstract": "This paper studies Distributionally Robust Optimization (DRO), a fundamental framework for enhancing the robustness and generalization of statistical learning and optimization. An effective ambiguity set for DRO must involve distributions that remain consistent with the nominal distribution while being diverse enough to account for a variety of potential scenarios. Moreover, it should lead to tractable DRO solutions. To this end, we propose a diffusion-based ambiguity set design that captures various adversarial distributions beyond the nominal support space while maintaining consistency with the nominal distribution. Building on this ambiguity modeling, we propose Diffusion-based DRO (D-DRO), a tractable DRO algorithm that solves the inner maximization over the parameterized diffusion model space. We formally establish the stationary convergence performance of D-DRO and empirically demonstrate its superior Out-of-Distribution (OOD) generalization performance in a ML prediction task.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "266",
        "title": "Iterative Layer Pruning for Efficient Translation Inference",
        "author": [
            "Yasmin Moslem",
            "Muhammad Hazim Al Farouq",
            "John D. Kelleher"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22763",
        "abstract": "Large language models (LLMs) have transformed many areas of natural language processing, including machine translation. However, efficient deployment of LLMs remains challenging due to their intensive computational requirements. In this paper, we address this challenge and present our submissions to the Model Compression track at the Conference on Machine Translation (WMT 2025). In our experiments, we investigate iterative layer pruning guided by layer importance analysis. We evaluate this method using the Aya-Expanse-8B model for translation from Czech to German, and from English to Egyptian Arabic. Our approach achieves substantial reductions in model size and inference time, while maintaining the translation quality of the baseline models.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "267",
        "title": "Jarvis: Towards Personalized AI Assistant via Personal KV-Cache Retrieval",
        "author": [
            "Binxiao Xu",
            "Junyu Feng",
            "Ruichuan An",
            "Yulin Luo",
            "Shilin Yan",
            "Hao Liang",
            "Ming Lu",
            "Wentao Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22765",
        "abstract": "The rapid development of Vision-language models (VLMs) enables open-ended perception and reasoning. Recent works have started to investigate how to adapt general-purpose VLMs into personalized assistants. Even commercial models such as ChatGPT now support model personalization by incorporating user-specific information. However, existing methods either learn a set of concept tokens or train a VLM to utilize user-specific information. However, both pipelines struggle to generate accurate answers as personalized assistants. We introduce Jarvis, an innovative framework for a personalized AI assistant through personal KV-Cache retrieval, which stores user-specific information in the KV-Caches of both textual and visual tokens. The textual tokens are created by summarizing user information into metadata, while the visual tokens are produced by extracting distinct image patches from the user's images. When answering a question, Jarvis first retrieves related KV-Caches from personal storage and uses them to ensure accuracy in responses. We also introduce a fine-grained benchmark built with the same distinct image patch mining pipeline, emphasizing accurate question answering based on fine-grained user-specific information. Jarvis is capable of providing more accurate responses, particularly when they depend on specific local details. Jarvis achieves state-of-the-art results in both visual question answering and text-only tasks across multiple datasets, indicating a practical path toward personalized AI assistants. The code and dataset will be released.",
        "tags": [
            "GPT",
            "VLM"
        ]
    },
    {
        "id": "268",
        "title": "TELL-TALE: Task Efficient LLMs with Task Aware Layer Elimination",
        "author": [
            "Omar Naim",
            "Krish Sharma",
            "Nicholas Asher"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22767",
        "abstract": "In this paper we introduce Tale, Task-Aware Layer Elimination, an inference-time algorithm that prunes entire transformer layers in an LLM by directly optimizing task-specific validation performance. We evaluate TALE on 9 tasks and 5 models, including LLaMA 3.1 8B, Qwen 2.5 7B, Qwen 2.5 0.5B, Mistral 7B, and Lucie 7B, under both zero-shot and few-shot settings. Unlike prior approaches, TALE requires no retraining and consistently improves accuracy while reducing computational cost across all benchmarks. Furthermore, applying TALE during finetuning leads to additional performance gains. Finally, TALE provides flexible user control over trade-offs between accuracy and efficiency. Mutual information analysis shows that certain layers act as bottlenecks, degrading task-relevant representations. Tale's selective layer removal remedies this problem, producing smaller, faster, and more accurate models that are also faster to fine-tune while offering new insights into transformer interpretability.",
        "tags": [
            "LLM",
            "LLaMA",
            "Qwen",
            "Transformer"
        ]
    },
    {
        "id": "269",
        "title": "MMPersuade: A Dataset and Evaluation Framework for Multimodal Persuasion",
        "author": [
            "Haoyi Qiu",
            "Yilun Zhou",
            "Pranav Narayanan Venkit",
            "Kung-Hsiang Huang",
            "Jiaxin Zhang",
            "Nanyun Peng",
            "Chien-Sheng Wu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22768",
        "abstract": "As Large Vision-Language Models (LVLMs) are increasingly deployed in domains such as shopping, health, and news, they are exposed to pervasive persuasive content. A critical question is how these models function as persuadees-how and why they can be influenced by persuasive multimodal inputs. Understanding both their susceptibility to persuasion and the effectiveness of different persuasive strategies is crucial, as overly persuadable models may adopt misleading beliefs, override user preferences, or generate unethical or unsafe outputs when exposed to manipulative messages. We introduce MMPersuade, a unified framework for systematically studying multimodal persuasion dynamics in LVLMs. MMPersuade contributes (i) a comprehensive multimodal dataset that pairs images and videos with established persuasion principles across commercial, subjective and behavioral, and adversarial contexts, and (ii) an evaluation framework that quantifies both persuasion effectiveness and model susceptibility via third-party agreement scoring and self-estimated token probabilities on conversation histories. Our study of six leading LVLMs as persuadees yields three key insights: (i) multimodal inputs substantially increase persuasion effectiveness-and model susceptibility-compared to text alone, especially in misinformation scenarios; (ii) stated prior preferences decrease susceptibility, yet multimodal information maintains its persuasive advantage; and (iii) different strategies vary in effectiveness across contexts, with reciprocity being most potent in commercial and subjective contexts, and credibility and logic prevailing in adversarial contexts. By jointly analyzing persuasion effectiveness and susceptibility, MMPersuade provides a principled foundation for developing models that are robust, preference-consistent, and ethically aligned when engaging with persuasive multimodal content.",
        "tags": [
            "VLM"
        ]
    },
    {
        "id": "270",
        "title": "Scalable Supervising Software Agents with Patch Reasoner",
        "author": [
            "Junjielong Xu",
            "Boyin Tan",
            "Xiaoyuan Liu",
            "Chao Peng",
            "Pengfei Gao",
            "Pinjia He"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22775",
        "abstract": "While large language model agents have advanced software engineering tasks, the unscalable nature of existing test-based supervision is limiting the potential improvement of data scaling. The reason is twofold: (1) building and running test sandbox is rather heavy and fragile, and (2) data with high-coverage tests is naturally rare and threatened by test hacking via edge cases. In this paper, we propose R4P, a patch verifier model to provide scalable rewards for training and testing SWE agents via reasoning. We consider that patch verification is fundamentally a reasoning task, mirroring how human repository maintainers review patches without writing and running new reproduction tests. To obtain sufficient reference and reduce the risk of reward hacking, R4P uses a group-wise objective for RL training, enabling it to verify multiple patches against each other's modification and gain a dense reward for stable training. R4P achieves 72.2% Acc. for verifying patches from SWE-bench-verified, surpassing OpenAI o3. To demonstrate R4P's practicality, we design and train a lite scaffold, Mini-SE, with pure reinforcement learning where all rewards are derived from R4P. As a result, Mini-SE achieves 26.2% Pass@1 on SWE-bench-verified, showing a 10.0% improvement over the original Qwen3-32B. This can be further improved to 32.8% with R4P for test-time scaling. Furthermore, R4P verifies patches within a second, 50x faster than testing on average. The stable scaling curves of rewards and accuracy along with high efficiency reflect R4P's practicality.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "271",
        "title": "SeeDNorm: Self-Rescaled Dynamic Normalization",
        "author": [
            "Wenrui Cai",
            "Defa Zhu",
            "Qingjie Liu",
            "Qiyang Min"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22777",
        "abstract": "Normalization layer constitutes an essential component in neural networks. In transformers, the predominantly used RMSNorm constrains vectors to a unit hypersphere, followed by dimension-wise rescaling through a learnable scaling coefficient $\\gamma$ to maintain the representational capacity of the model. However, RMSNorm discards the input norm information in forward pass and a static scaling factor $\\gamma$ may be insufficient to accommodate the wide variability of input data and distributional shifts, thereby limiting further performance improvements, particularly in zero-shot scenarios that large language models routinely encounter. To address this limitation, we propose SeeDNorm, which enhances the representational capability of the model by dynamically adjusting the scaling coefficient based on the current input, thereby preserving the input norm information and enabling data-dependent, self-rescaled dynamic normalization. During backpropagation, SeeDNorm retains the ability of RMSNorm to dynamically adjust gradient according to the input norm. We provide a detailed analysis of the training optimization for SeedNorm and proposed corresponding solutions to address potential instability issues that may arise when applying SeeDNorm. We validate the effectiveness of SeeDNorm across models of varying sizes in large language model pre-training as well as supervised and unsupervised computer vision tasks. By introducing a minimal number of parameters and with neglligible impact on model efficiency, SeeDNorm achieves consistently superior performance compared to previously commonly used normalization layers such as RMSNorm and LayerNorm, as well as element-wise activation alternatives to normalization layers like DyT.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "272",
        "title": "PIP-LLM: Integrating PDDL-Integer Programming with LLMs for Coordinating Multi-Robot Teams Using Natural Language",
        "author": [
            "Guangyao Shi",
            "Yuwei Wu",
            "Vijay Kumar",
            "Gaurav S. Sukhatme"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22784",
        "abstract": "Enabling robot teams to execute natural language commands requires translating high-level instructions into feasible, efficient multi-robot plans. While Large Language Models (LLMs) combined with Planning Domain Description Language (PDDL) offer promise for single-robot scenarios, existing approaches struggle with multi-robot coordination due to brittle task decomposition, poor scalability, and low coordination efficiency.\nWe introduce PIP-LLM, a language-based coordination framework that consists of PDDL-based team-level planning and Integer Programming (IP) based robot-level planning. PIP-LLMs first decomposes the command by translating the command into a team-level PDDL problem and solves it to obtain a team-level plan, abstracting away robot assignment. Each team-level action represents a subtask to be finished by the team. Next, this plan is translated into a dependency graph representing the subtasks' dependency structure. Such a dependency graph is then used to guide the robot-level planning, in which each subtask node will be formulated as an IP-based task allocation problem, explicitly optimizing travel costs and workload while respecting robot capabilities and user-defined constraints. This separation of planning from assignment allows PIP-LLM to avoid the pitfalls of syntax-based decomposition and scale to larger teams. Experiments across diverse tasks show that PIP-LLM improves plan success rate, reduces maximum and average travel costs, and achieves better load balancing compared to state-of-the-art baselines.",
        "tags": [
            "LLM",
            "Robotics"
        ]
    },
    {
        "id": "273",
        "title": "Collaborative LLM Agents for C4 Software Architecture Design Automation",
        "author": [
            "Kamil Szczepanik",
            "JarosÅaw A. Chudziak"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22787",
        "abstract": "Software architecture design is a fundamental part of creating every software system. Despite its importance, producing a C4 software architecture model, the preferred notation for such architecture, remains manual and time-consuming. We introduce an LLM-based multi-agent system that automates this task by simulating a dialogue between role-specific experts who analyze requirements and generate the Context, Container, and Component views of the C4 model. Quality is assessed with a hybrid evaluation framework: deterministic checks for structural and syntactic integrity and C4 rule consistency, plus semantic and qualitative scoring via an LLM-as-a-Judge approach. Tested on five canonical system briefs, the workflow demonstrates fast C4 model creation, sustains high compilation success, and delivers semantic fidelity. A comparison of four state-of-the-art LLMs shows different strengths relevant to architectural design. This study contributes to automated software architecture design and its evaluation methods.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "274",
        "title": "Learning Neural Observer-Predictor Models for Limb-level Sampling-based Locomotion Planning",
        "author": [
            "Abhijeet M. Kulkarni",
            "Ioannis Poulakakis",
            "Guoquan Huang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22789",
        "abstract": "Accurate full-body motion prediction is essential for the safe, autonomous navigation of legged robots, enabling critical capabilities like limb-level collision checking in cluttered environments. Simplified kinematic models often fail to capture the complex, closed-loop dynamics of the robot and its low-level controller, limiting their predictions to simple planar motion. To address this, we present a learning-based observer-predictor framework that accurately predicts this motion. Our method features a neural observer with provable UUB guarantees that provides a reliable latent state estimate from a history of proprioceptive measurements. This stable estimate initializes a computationally efficient predictor, designed for the rapid, parallel evaluation of thousands of potential trajectories required by modern sampling-based planners. We validated the system by integrating our neural predictor into an MPPI-based planner on a Vision 60 quadruped. Hardware experiments successfully demonstrated effective, limb-aware motion planning in a challenging, narrow passage and over small objects, highlighting our system's ability to provide a robust foundation for high-performance, collision-aware planning on dynamic robotic platforms.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "275",
        "title": "VEHME: A Vision-Language Model For Evaluating Handwritten Mathematics Expressions",
        "author": [
            "Thu Phuong Nguyen",
            "Duc M. Nguyen",
            "Hyotaek Jeon",
            "Hyunwook Lee",
            "Hyunmin Song",
            "Sungahn Ko",
            "Taehwan Kim"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22798",
        "abstract": "Automatically assessing handwritten mathematical solutions is an important problem in educational technology with practical applications, but it remains a significant challenge due to the diverse formats, unstructured layouts, and symbolic complexity of student work. To address this challenge, we introduce VEHME-a Vision-Language Model for Evaluating Handwritten Mathematics Expressions-designed to assess open-form handwritten math responses with high accuracy and interpretable reasoning traces. VEHME integrates a two-phase training pipeline: (i) supervised fine-tuning using structured reasoning data, and (ii) reinforcement learning that aligns model outputs with multi-dimensional grading objectives, including correctness, reasoning depth, and error localization. To enhance spatial understanding, we propose an Expression-Aware Visual Prompting Module, trained on our synthesized multi-line math expressions dataset to robustly guide attention in visually heterogeneous inputs. Evaluated on AIHub and FERMAT datasets, VEHME achieves state-of-the-art performance among open-source models and approaches the accuracy of proprietary systems, demonstrating its potential as a scalable and accessible tool for automated math assessment. Our training and experiment code is publicly available at our GitHub repository.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "276",
        "title": "MAGIC-Talk: Motion-aware Audio-Driven Talking Face Generation with Customizable Identity Control",
        "author": [
            "Fatemeh Nazarieh",
            "Zhenhua Feng",
            "Diptesh Kanojia",
            "Muhammad Awais",
            "Josef Kittler"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22810",
        "abstract": "Audio-driven talking face generation has gained significant attention for applications in digital media and virtual avatars. While recent methods improve audio-lip synchronization, they often struggle with temporal consistency, identity preservation, and customization, especially in long video generation. To address these issues, we propose MAGIC-Talk, a one-shot diffusion-based framework for customizable and temporally stable talking face generation. MAGIC-Talk consists of ReferenceNet, which preserves identity and enables fine-grained facial editing via text prompts, and AnimateNet, which enhances motion coherence using structured motion priors. Unlike previous methods requiring multiple reference images or fine-tuning, MAGIC-Talk maintains identity from a single image while ensuring smooth transitions across frames. Additionally, a progressive latent fusion strategy is introduced to improve long-form video quality by reducing motion inconsistencies and flickering. Extensive experiments demonstrate that MAGIC-Talk outperforms state-of-the-art methods in visual quality, identity preservation, and synchronization accuracy, offering a robust solution for talking face generation.",
        "tags": [
            "Diffusion",
            "Talking Face",
            "Video Generation"
        ]
    },
    {
        "id": "277",
        "title": "Analytical Swarm Chemistry: Characterization and Analysis of Emergent Swarm Behaviors",
        "author": [
            "Ricardo Vega",
            "Connor Mattson",
            "Kevin Zhu",
            "Daniel S. Brown",
            "Cameron Nowzari"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22821",
        "abstract": "Swarm robotics has potential for a wide variety of applications, but real-world deployments remain rare due to the difficulty of predicting emergent behaviors arising from simple local interactions. Traditional engineering approaches design controllers to achieve desired macroscopic outcomes under idealized conditions, while agent-based and artificial life studies explore emergent phenomena in a bottom-up, exploratory manner. In this work, we introduce Analytical Swarm Chemistry, a framework that integrates concepts from engineering, agent-based and artificial life research, and chemistry. This framework combines macrostate definitions with phase diagram analysis to systematically explore how swarm parameters influence emergent behavior. Inspired by concepts from chemistry, the framework treats parameters like thermodynamic variables, enabling visualization of regions in parameter space that give rise to specific behaviors. Applying this framework to agents with minimally viable capabilities, we identify sufficient conditions for behaviors such as milling and diffusion and uncover regions of the parameter space that reliably produce these behaviors. Preliminary validation on real robots demonstrates that these regions correspond to observable behaviors in practice. By providing a principled, interpretable approach, this framework lays the groundwork for predictable and reliable emergent behavior in real-world swarm systems.",
        "tags": [
            "Diffusion",
            "Robotics"
        ]
    },
    {
        "id": "278",
        "title": "Cross-Lingual Stability and Bias in Instruction-Tuned Language Models for Humanitarian NLP",
        "author": [
            "Poli Nemkova",
            "Amrit Adhikari",
            "Matthew Pearson",
            "Vamsi Krishna Sadu",
            "Mark V. Albert"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22823",
        "abstract": "Humanitarian organizations face a critical choice: invest in costly commercial APIs or rely on free open-weight models for multilingual human rights monitoring. While commercial systems offer reliability, open-weight alternatives lack empirical validation -- especially for low-resource languages common in conflict zones. This paper presents the first systematic comparison of commercial and open-weight large language models (LLMs) for human-rights-violation detection across seven languages, quantifying the cost-reliability trade-off facing resource-constrained organizations. Across 78,000 multilingual inferences, we evaluate six models -- four instruction-aligned (Claude-Sonnet-4, DeepSeek-V3, Gemini-Flash-2.0, GPT-4.1-mini) and two open-weight (LLaMA-3-8B, Mistral-7B) -- using both standard classification metrics and new measures of cross-lingual reliability: Calibration Deviation (CD), Decision Bias (B), Language Robustness Score (LRS), and Language Stability Score (LSS). Results show that alignment, not scale, determines stability: aligned models maintain near-invariant accuracy and balanced calibration across typologically distant and low-resource languages (e.g., Lingala, Burmese), while open-weight models exhibit significant prompt-language sensitivity and calibration drift. These findings demonstrate that multilingual alignment enables language-agnostic reasoning and provide practical guidance for humanitarian organizations balancing budget constraints with reliability in multilingual deployment.",
        "tags": [
            "DeepSeek",
            "Detection",
            "GPT",
            "LLM",
            "LLaMA"
        ]
    },
    {
        "id": "279",
        "title": "Logical GANs: Adversarial Learning through Ehrenfeucht Fraisse Games",
        "author": [
            "Mirco A. Mannucci"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22824",
        "abstract": "GANs promise indistinguishability, logic explains it. We put the two on a budget: a discriminator that can only ``see'' up to a logical depth $k$, and a generator that must look correct to that bounded observer. \\textbf{LOGAN} (LOGical GANs) casts the discriminator as a depth-$k$ Ehrenfeucht--FraÃ¯ssÃ© (EF) \\emph{Opponent} that searches for small, legible faults (odd cycles, nonplanar crossings, directed bridges), while the generator plays \\emph{Builder}, producing samples that admit a $k$-round matching to a target theory $T$. We ship a minimal toolkit -- an EF-probe simulator and MSO-style graph checkers -- and four experiments including real neural GAN training with PyTorch. Beyond verification, we score samples with a \\emph{logical loss} that mixes budgeted EF round-resilience with cheap certificate terms, enabling a practical curriculum on depth. Framework validation demonstrates $92\\%$--$98\\%$ property satisfaction via simulation (Exp.~3), while real neural GAN training achieves $5\\%$--$14\\%$ improvements on challenging properties and $98\\%$ satisfaction on connectivity (matching simulation) through adversarial learning (Exp.~4). LOGAN is a compact, reproducible path toward logic-bounded generation with interpretable failures, proven effectiveness (both simulated and real training), and dials for control.",
        "tags": [
            "GAN"
        ]
    },
    {
        "id": "280",
        "title": "Kinematically Controllable Cable Robots with Reconfigurable End-effectors",
        "author": [
            "Nan Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22825",
        "abstract": "To enlarge the translational workspace of cable-driven robots, one common approach is to increase the number of cables. However, this introduces two challenges: (1) cable interference significantly reduces the rotational workspace, and (2) the solution of tensions in cables becomes non-unique, resulting in difficulties for kinematic control of the robot. In this work, we design structurally simple reconfigurable end-effectors for cable robots. By incorporating a spring, a helical-grooved shaft, and a matching nut, relative linear motions between end-effector components are converted into relative rotations, thereby expanding the rotational workspace of the mechanism. Meanwhile, a bearing is introduced to provide an additional rotational degree of freedom, making the mechanism non-redundant. As a result, the robot's motion can be controlled purely through kinematics without additional tension sensing and control.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "281",
        "title": "FairJudge: MLLM Judging for Social Attributes and Prompt Image Alignment",
        "author": [
            "Zahraa Al Sahili",
            "Maryam Fetanat",
            "Maimuna Nowaz",
            "Ioannis Patras",
            "Matthew Purver"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22827",
        "abstract": "Text-to-image (T2I) systems lack simple, reproducible ways to evaluate how well images match prompts and how models treat social attributes. Common proxies -- face classifiers and contrastive similarity -- reward surface cues, lack calibrated abstention, and miss attributes only weakly visible (for example, religion, culture, disability). We present FairJudge, a lightweight protocol that treats instruction-following multimodal LLMs as fair judges. It scores alignment with an explanation-oriented rubric mapped to [-1, 1]; constrains judgments to a closed label set; requires evidence grounded in the visible content; and mandates abstention when cues are insufficient. Unlike CLIP-only pipelines, FairJudge yields accountable, evidence-aware decisions; unlike mitigation that alters generators, it targets evaluation fairness. We evaluate gender, race, and age on FairFace, PaTA, and FairCoT; extend to religion, culture, and disability; and assess profession correctness and alignment on IdenProf, FairCoT-Professions, and our new DIVERSIFY-Professions. We also release DIVERSIFY, a 469-image corpus of diverse, non-iconic scenes. Across datasets, judge models outperform contrastive and face-centric baselines on demographic prediction and improve mean alignment while maintaining high profession accuracy, enabling more reliable, reproducible fairness audits.",
        "tags": [
            "CLIP",
            "LLM",
            "Text-to-Image"
        ]
    },
    {
        "id": "282",
        "title": "LLM-based Fusion of Multi-modal Features for Commercial Memorability Prediction",
        "author": [
            "Aleksandar Pramov"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22829",
        "abstract": "This paper addresses the prediction of commercial (brand) memorability as part of \"Subtask 2: Commercial/Ad Memorability\" within the \"Memorability: Predicting movie and commercial memorability\" task at the MediaEval 2025 workshop competition. We propose a multimodal fusion system with a Gemma-3 LLM backbone that integrates pre-computed visual (ViT) and textual (E5) features by multi-modal projections. The model is adapted using Low-Rank Adaptation (LoRA). A heavily-tuned ensemble of gradient boosted trees serves as a baseline. A key contribution is the use of LLM-generated rationale prompts, grounded in expert-derived aspects of memorability, to guide the fusion model. The results demonstrate that the LLM-based system exhibits greater robustness and generalization performance on the final test set, compared to the baseline.\nThe paper's codebase can be found at https://github.com/dsgt-arc/mediaeval-2025-memorability",
        "tags": [
            "LLM",
            "LoRA",
            "ViT"
        ]
    },
    {
        "id": "283",
        "title": "Exploration of Summarization by Generative Language Models for Automated Scoring of Long Essays",
        "author": [
            "Haowei Hua",
            "Hong Jiao",
            "Xinyi Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22830",
        "abstract": "BERT and its variants are extensively explored for automated scoring. However, a limit of 512 tokens for these encoder-based models showed the deficiency in automated scoring of long essays. Thus, this research explores generative language models for automated scoring of long essays via summarization and prompting. The results revealed great improvement of scoring accuracy with QWK increased from 0.822 to 0.8878 for the Learning Agency Lab Automated Essay Scoring 2.0 dataset.",
        "tags": [
            "BERT"
        ]
    },
    {
        "id": "284",
        "title": "HRM-Agent: Training a recurrent reasoning model in dynamic environments using reinforcement learning",
        "author": [
            "Long H Dang",
            "David Rawlinson"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22832",
        "abstract": "The Hierarchical Reasoning Model (HRM) has impressive reasoning abilities given its small size, but has only been applied to supervised, static, fully-observable problems. One of HRM's strengths is its ability to adapt its computational effort to the difficulty of the problem. However, in its current form it cannot integrate and reuse computation from previous time-steps if the problem is dynamic, uncertain or partially observable, or be applied where the correct action is undefined, characteristics of many real-world problems.\nThis paper presents HRM-Agent, a variant of HRM trained using only reinforcement learning. We show that HRM can learn to navigate to goals in dynamic and uncertain maze environments. Recent work suggests that HRM's reasoning abilities stem from its recurrent inference process. We explore the dynamics of the recurrent inference process and find evidence that it is successfully reusing computation from earlier environment time-steps.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "285",
        "title": "Toward Agents That Reason About Their Computation",
        "author": [
            "Adrian Orenstein",
            "Jessica Chen",
            "Gwyneth Anne Delos Santos",
            "Bayley Sapara",
            "Michael Bowling"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22833",
        "abstract": "While reinforcement learning agents can achieve superhuman performance in many complex tasks, they typically do not become more computationally efficient as they improve. In contrast, humans gradually require less cognitive effort as they become more proficient at a task. If agents could reason about their compute as they learn, could they similarly reduce their computation footprint? If they could, we could have more energy efficient agents or free up compute cycles for other processes like planning. In this paper, we experiment with showing agents the cost of their computation and giving them the ability to control when they use compute. We conduct our experiments on the Arcade Learning Environment, and our results demonstrate that with the same training compute budget, agents that reason about their compute perform better on 75% of games. Furthermore, these agents use three times less compute on average. We analyze individual games and show where agents gain these efficiencies.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "286",
        "title": "Rethinking the Text-Vision Reasoning Imbalance in MLLMs through the Lens of Training Recipes",
        "author": [
            "Guanyu Yao",
            "Qiucheng Wu",
            "Yang Zhang",
            "Zhaowen Wang",
            "Handong Zhao",
            "Shiyu Chang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22836",
        "abstract": "Multimodal large language models (MLLMs) have demonstrated strong capabilities on vision-and-language tasks. However, recent findings reveal an imbalance in their reasoning capabilities across visual and textual modalities. Specifically, current MLLMs often over-rely on textual cues while under-attending to visual content, resulting in suboptimal performance on tasks that require genuine visual reasoning. We refer to this phenomenon as the \\textit{modality gap}, defined as the performance disparity between text-centric and vision-centric inputs. In this paper, we analyze the modality gap through the lens of training recipes. We first show that existing training recipes tend to amplify this gap. Then, we systematically explore strategies to bridge it from two complementary perspectives: data and loss design. Our findings provide insights into developing training recipes that mitigate the modality gap and promote more balanced multimodal reasoning. Our code is publicly available at https://github.com/UCSB-NLP-Chang/Bridging-Modality-Gap.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "287",
        "title": "Semantic-Preserving Cross-Style Visual Reasoning for Robust Multi-Modal Understanding in Large Vision-Language Models",
        "author": [
            "Aya Nakayama",
            "Brian Wong",
            "Yuji Nishimura",
            "Kaito Tanaka"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22838",
        "abstract": "The \"style trap\" poses a significant challenge for Large Vision-Language Models (LVLMs), hindering robust semantic understanding across diverse visual styles, especially in in-context learning (ICL). Existing methods often fail to effectively decouple style from content, hindering generalization. To address this, we propose the Semantic-Preserving Cross-Style Visual Reasoner (SP-CSVR), a novel framework for stable semantic understanding and adaptive cross-style visual reasoning. SP-CSVR integrates a Cross-Style Feature Encoder (CSFE) for style-content disentanglement, a Semantic-Aligned In-Context Decoder (SAICD) for efficient few-shot style adaptation, and an Adaptive Semantic Consistency Module (ASCM) employing multi-task contrastive learning to enforce cross-style semantic invariance. Extensive experiments on a challenging multi-style dataset demonstrate SP-CSVR's state-of-the-art performance across visual captioning, visual question answering, and in-context style adaptation. Comprehensive evaluations, including ablation studies and generalization analysis, confirm SP-CSVR's efficacy in enhancing robustness, generalization, and efficiency across diverse visual styles.",
        "tags": [
            "VLM"
        ]
    },
    {
        "id": "288",
        "title": "Lyapunov Function-guided Reinforcement Learning for Flight Control",
        "author": [
            "Yifei Li",
            "Erik-Jan van Kampen"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22840",
        "abstract": "A cascaded online learning flight control system has been developed and enhanced with respect to action smoothness. In this paper, we investigate the convergence performance of the control system, characterized by the increment of a Lyapunov function candidate. The derivation of this metric accounts for discretization errors and state prediction errors introduced by the incremental model. Comparative results are presented through flight control simulations.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "289",
        "title": "Leveraging Large Language Models to Identify Conversation Threads in Collaborative Learning",
        "author": [
            "Prerna Ravi",
            "Dong Won Lee",
            "Beatriz Flamia",
            "Jasmine David",
            "Brandon Hanks",
            "Cynthia Breazeal",
            "Emma Anderson",
            "Grace Lin"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22844",
        "abstract": "Understanding how ideas develop and flow in small-group conversations is critical for analyzing collaborative learning. A key structural feature of these interactions is threading, the way discourse talk naturally organizes into interwoven topical strands that evolve over time. While threading has been widely studied in asynchronous text settings, detecting threads in synchronous spoken dialogue remains challenging due to overlapping turns and implicit cues. At the same time, large language models (LLMs) show promise for automating discourse analysis but often struggle with long-context tasks that depend on tracing these conversational links. In this paper, we investigate whether explicit thread linkages can improve LLM-based coding of relational moves in group talk. We contribute a systematic guidebook for identifying threads in synchronous multi-party transcripts and benchmark different LLM prompting strategies for automated threading. We then test how threading influences performance on downstream coding of conversational analysis frameworks, that capture core collaborative actions such as agreeing, building, and eliciting. Our results show that providing clear conversational thread information improves LLM coding performance and underscores the heavy reliance of downstream analysis on well-structured dialogue. We also discuss practical trade-offs in time and cost, emphasizing where human-AI hybrid approaches can yield the best value. Together, this work advances methods for combining LLMs and robust conversational thread structures to make sense of complex, real-time group interactions.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "290",
        "title": "Once Upon an Input: Reasoning via Per-Instance Program Synthesis",
        "author": [
            "Adam Stein",
            "Neelay Velingker",
            "Mayur Naik",
            "Eric Wong"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22849",
        "abstract": "Large language models (LLMs) excel at zero-shot inference but continue to struggle with complex, multi-step reasoning. Recent methods that augment LLMs with intermediate reasoning steps such as Chain of Thought (CoT) and Program of Thought (PoT) improve performance but often produce undesirable solutions, especially in algorithmic domains. We introduce Per-Instance Program Synthesis (PIPS), a method that generates and refines programs at the instance-level using structural feedback without relying on task-specific guidance or explicit test cases. To further improve performance, PIPS incorporates a confidence metric that dynamically chooses between direct inference and program synthesis on a per-instance basis. Experiments across three frontier LLMs and 30 benchmarks including all tasks of Big Bench Extra Hard (BBEH), visual question answering tasks, relational reasoning tasks, and mathematical reasoning tasks show that PIPS improves the absolute harmonic mean accuracy by up to 8.6% and 9.4% compared to PoT and CoT respectively, and reduces undesirable program generations by 65.1% on the algorithmic tasks compared to PoT with Gemini-2.0-Flash.",
        "tags": [
            "CoT",
            "LLM"
        ]
    },
    {
        "id": "291",
        "title": "Semantic Surgery: Zero-Shot Concept Erasure in Diffusion Models",
        "author": [
            "Lexiang Xiong",
            "Chengyu Liu",
            "Jingwen Ye",
            "Yan Liu",
            "Yuecong Xu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22851",
        "abstract": "Concept erasure in text-to-image diffusion models is crucial for mitigating harmful content, yet existing methods often compromise generative quality. We introduce Semantic Surgery, a novel training-free, zero-shot framework for concept erasure that operates directly on text embeddings before the diffusion process. It dynamically estimates the presence of target concepts in a prompt and performs a calibrated vector subtraction to neutralize their influence at the source, enhancing both erasure completeness and locality. The framework includes a Co-Occurrence Encoding module for robust multi-concept erasure and a visual feedback loop to address latent concept persistence. As a training-free method, Semantic Surgery adapts dynamically to each prompt, ensuring precise interventions. Extensive experiments on object, explicit content, artistic style, and multi-celebrity erasure tasks show our method significantly outperforms state-of-the-art approaches. We achieve superior completeness and robustness while preserving locality and image quality (e.g., 93.58 H-score in object erasure, reducing explicit content to just 1 instance, and 8.09 H_a in style erasure with no quality degradation). This robustness also allows our framework to function as a built-in threat detection system, offering a practical solution for safer text-to-image generation.",
        "tags": [
            "Detection",
            "Diffusion",
            "Text-to-Image"
        ]
    },
    {
        "id": "292",
        "title": "Encoder-Decoder Diffusion Language Models for Efficient Training and Inference",
        "author": [
            "Marianne Arriola",
            "Yair Schiff",
            "Hao Phung",
            "Aaron Gokaslan",
            "Volodymyr Kuleshov"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22852",
        "abstract": "Discrete diffusion models enable parallel token sampling for faster inference than autoregressive approaches. However, prior diffusion models use a decoder-only architecture, which requires sampling algorithms that invoke the full network at every denoising step and incur high computational cost. Our key insight is that discrete diffusion models perform two types of computation: 1) representing clean tokens and 2) denoising corrupted tokens, which enables us to use separate modules for each task. We propose an encoder-decoder architecture to accelerate discrete diffusion inference, which relies on an encoder to represent clean tokens and a lightweight decoder to iteratively refine a noised sequence. We also show that this architecture enables faster training of block diffusion models, which partition sequences into blocks for better quality and are commonly used in diffusion language model inference. We introduce a framework for Efficient Encoder-Decoder Diffusion (E2D2), consisting of an architecture with specialized training and sampling algorithms, and we show that E2D2 achieves superior trade-offs between generation quality and inference throughput on summarization, translation, and mathematical reasoning tasks. We provide the code, model weights, and blog post on the project page: https://m-arriola.com/e2d2",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "293",
        "title": "Guardian: Decoupling Exploration from Safety in Reinforcement Learning",
        "author": [
            "Kaitong Cai",
            "Jusheng Zhang",
            "Jing Yang",
            "Keze Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22859",
        "abstract": "Hybrid offline--online reinforcement learning (O2O RL) promises both sample efficiency and robust exploration, but suffers from instability due to distribution shift between offline and online data. We introduce RLPD-GX, a framework that decouples policy optimization from safety enforcement: a reward-seeking learner explores freely, while a projection-based guardian guarantees rule-consistent execution and safe value backups. This design preserves the exploratory value of online interactions without collapsing to conservative policies. To further stabilize training, we propose dynamic curricula that gradually extend temporal horizons and anneal offline--online data mixing. We prove convergence via a contraction property of the guarded Bellman operator, and empirically show state-of-the-art performance on Atari-100k, achieving a normalized mean score of 3.02 (+45\\% over prior hybrid methods) with stronger safety and stability. Beyond Atari, ablations demonstrate consistent gains across safety-critical and long-horizon tasks, underscoring the generality of our design. Extensive and comprehensive results highlight decoupled safety enforcement as a simple yet principled route to robust O2O RL, suggesting a broader paradigm for reconciling exploration and safety in reinforcement learning.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "294",
        "title": "Far from the Shallow: Brain-Predictive Reasoning Embedding through Residual Disentanglement",
        "author": [
            "Linyang He",
            "Tianjun Zhong",
            "Richard Antonello",
            "Gavin Mischler",
            "Micah Goldblum",
            "Nima Mesgarani"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22860",
        "abstract": "Understanding how the human brain progresses from processing simple linguistic inputs to performing high-level reasoning is a fundamental challenge in neuroscience. While modern large language models (LLMs) are increasingly used to model neural responses to language, their internal representations are highly \"entangled,\" mixing information about lexicon, syntax, meaning, and reasoning. This entanglement biases conventional brain encoding analyses toward linguistically shallow features (e.g., lexicon and syntax), making it difficult to isolate the neural substrates of cognitively deeper processes. Here, we introduce a residual disentanglement method that computationally isolates these components. By first probing an LM to identify feature-specific layers, our method iteratively regresses out lower-level representations to produce four nearly orthogonal embeddings for lexicon, syntax, meaning, and, critically, reasoning. We used these disentangled embeddings to model intracranial (ECoG) brain recordings from neurosurgical patients listening to natural speech. We show that: 1) This isolated reasoning embedding exhibits unique predictive power, accounting for variance in neural activity not explained by other linguistic features and even extending to the recruitment of visual regions beyond classical language areas. 2) The neural signature for reasoning is temporally distinct, peaking later (~350-400ms) than signals related to lexicon, syntax, and meaning, consistent with its position atop a processing hierarchy. 3) Standard, non-disentangled LLM embeddings can be misleading, as their predictive success is primarily attributable to linguistically shallow features, masking the more subtle contributions of deeper cognitive processing.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "295",
        "title": "Long-Term PM2.5 Forecasting Using a DTW-Enhanced CNN-GRU Model",
        "author": [
            "Amirali Ataee Naeini",
            "Arshia Ataee Naeini",
            "Fatemeh Karami Mohammadi",
            "Omid Ghaffarpasand"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22863",
        "abstract": "Reliable long-term forecasting of PM2.5 concentrations is critical for public health early-warning systems, yet existing deep learning approaches struggle to maintain prediction stability beyond 48 hours, especially in cities with sparse monitoring networks. This paper presents a deep learning framework that combines Dynamic Time Warping (DTW) for intelligent station similarity selection with a CNN-GRU architecture to enable extended-horizon PM2.5 forecasting in Isfahan, Iran, a city characterized by complex pollution dynamics and limited monitoring coverage. Unlike existing approaches that rely on computationally intensive transformer models or external simulation tools, our method integrates three key innovations: (i) DTW-based historical sampling to identify similar pollution patterns across peer stations, (ii) a lightweight CNN-GRU architecture augmented with meteorological features, and (iii) a scalable design optimized for sparse networks. Experimental validation using multi-year hourly data from eight monitoring stations demonstrates superior performance compared to state-of-the-art deep learning methods, achieving R2 = 0.91 for 24-hour forecasts. Notably, this is the first study to demonstrate stable 10-day PM2.5 forecasting (R2 = 0.73 at 240 hours) without performance degradation, addressing critical early-warning system requirements. The framework's computational efficiency and independence from external tools make it particularly suitable for deployment in resource-constrained urban environments.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "296",
        "title": "Interpreting and Mitigating Unwanted Uncertainty in LLMs",
        "author": [
            "Tiasa Singha Roy",
            "Ayush Rajesh Jhaveri",
            "Ilias Triantafyllopoulos"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22866",
        "abstract": "Despite their impressive capabilities, Large Language Models (LLMs) exhibit unwanted uncertainty, a phenomenon where a model changes a previously correct answer into an incorrect one when re-prompted. This behavior undermines trust and poses serious risks in high-stakes domains. In this work, we investigate the mechanisms that drive this phenomenon. We adapt the Needle-in-a-Haystack retrieval framework and integrate a Flip-style re-evaluation prompt to simulate realistic answer-flipping scenarios. We find that retrieval heads are not primarily responsible for avoiding uncertainty. Instead, we identify a small set of non-retrieval attention heads that disproportionately attend to misleading tokens in uncertain contexts. Masking these heads yields significant improvements, reducing flip behavior by up to 15% without introducing incoherence or overcorrection. However, when tested for downstream tasks, we observe trade-offs with flip behavior. Our findings contribute to the growing field of mechanistic interpretability and present a simple yet effective technique for mitigating uncertainty-driven failure modes in LLMs.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "297",
        "title": "Seeing the Unseen: Towards Zero-Shot Inspection for Wind Turbine Blades using Knowledge-Augmented Vision Language Models",
        "author": [
            "Yang Zhang",
            "Qianyu Zhou",
            "Farhad Imani",
            "Jiong Tang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22868",
        "abstract": "Wind turbine blades operate in harsh environments, making timely damage detection essential for preventing failures and optimizing maintenance. Drone-based inspection and deep learning are promising, but typically depend on large, labeled datasets, which limit their ability to detect rare or evolving damage types. To address this, we propose a zero-shot-oriented inspection framework that integrates Retrieval-Augmented Generation (RAG) with Vision-Language Models (VLM). A multimodal knowledge base is constructed, comprising technical documentation, representative reference images, and domain-specific guidelines. A hybrid text-image retriever with keyword-aware reranking assembles the most relevant context to condition the VLM at inference, injecting domain knowledge without task-specific training. We evaluate the framework on 30 labeled blade images covering diverse damage categories. Although the dataset is small due to the difficulty of acquiring verified blade imagery, it covers multiple representative defect types. On this test set, the RAG-grounded VLM correctly classified all samples, whereas the same VLM without retrieval performed worse in both accuracy and precision. We further compare against open-vocabulary baselines and incorporate uncertainty Clopper-Pearson confidence intervals to account for the small-sample setting. Ablation studies indicate that the key advantage of the framework lies in explainability and generalizability: retrieved references ground the reasoning process and enable the detection of previously unseen defects by leveraging domain knowledge rather than relying solely on visual cues. This research contributes a data-efficient solution for industrial inspection that reduces dependence on extensive labeled datasets.",
        "tags": [
            "Detection",
            "RAG",
            "VLM"
        ]
    },
    {
        "id": "298",
        "title": "A Comprehensive Dataset for Human vs. AI Generated Text Detection",
        "author": [
            "Rajarshi Roy",
            "Nasrin Imanpour",
            "Ashhar Aziz",
            "Shashwat Bajpai",
            "Gurpreet Singh",
            "Shwetangshu Biswas",
            "Kapil Wanaskar",
            "Parth Patwa",
            "Subhankar Ghosh",
            "Shreyas Dixit",
            "Nilesh Ranjan Pal",
            "Vipula Rawte",
            "Ritvik Garimella",
            "Gaytri Jena",
            "Amit Sheth",
            "Vasu Sharma",
            "Aishwarya Naresh Reganti",
            "Vinija Jain",
            "Aman Chadha",
            "Amitava Das"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22874",
        "abstract": "The rapid advancement of large language models (LLMs) has led to increasingly human-like AI-generated text, raising concerns about content authenticity, misinformation, and trustworthiness. Addressing the challenge of reliably detecting AI-generated text and attributing it to specific models requires large-scale, diverse, and well-annotated datasets. In this work, we present a comprehensive dataset comprising over 58,000 text samples that combine authentic New York Times articles with synthetic versions generated by multiple state-of-the-art LLMs including Gemma-2-9b, Mistral-7B, Qwen-2-72B, LLaMA-8B, Yi-Large, and GPT-4-o. The dataset provides original article abstracts as prompts, full human-authored narratives. We establish baseline results for two key tasks: distinguishing human-written from AI-generated text, achieving an accuracy of 58.35\\%, and attributing AI texts to their generating models with an accuracy of 8.92\\%. By bridging real-world journalistic content with modern generative models, the dataset aims to catalyze the development of robust detection and attribution methods, fostering trust and transparency in the era of generative AI. Our dataset is available at: https://huggingface.co/datasets/gsingh1-py/train.",
        "tags": [
            "Detection",
            "GPT",
            "LLM",
            "LLaMA",
            "Qwen"
        ]
    },
    {
        "id": "299",
        "title": "Batch Speculative Decoding Done Right",
        "author": [
            "Ranran Haoran Zhang",
            "Soumik Dey",
            "Ashirbad Mishra",
            "Hansi Wu",
            "Binbin Li",
            "Rui Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22876",
        "abstract": "Speculative decoding speeds up LLM inference by using a small draft model to propose multiple tokens that a target model verifies in parallel. Extending this idea to batches is essential for production serving, but it introduces the ragged tensor problem: sequences in the same batch accept different numbers of draft tokens, breaking right-alignment and corrupting position IDs, attention masks, and KV-cache state. We show that several existing batch implementations violate output equivalence-the fundamental requirement that speculative decoding must produce identical token sequences to standard autoregressive generation. These violations occur precisely due to improper handling of the ragged tensor problem. In response, we (1) characterize the synchronization requirements that guarantee correctness, (2) present a correctness-first batch speculative decoding EQSPEC that exposes realignment as consuming 40% of overhead, and (3) introduce EXSPEC, which maintains a sliding pool of sequences and dynamically forms same-length groups, to reduce the realignment overhead while preserving per-sequence speculative speedups. On the SpecBench dataset, across Vicuna-7B/68M, Qwen3-8B/0.6B, and GLM-4-9B/0.6B target/draft pairs, our approach achieves up to 3$\\times$ throughput improvement at batch size 8 compared to batch size 1, with efficient scaling through batch size 8, while maintaining 95% output equivalence. Our method requires no custom kernels and integrates cleanly with existing inference stacks. Our code is available at https://github.com/eBay/spec_dec.",
        "tags": [
            "GLM",
            "LLM",
            "Vicuna"
        ]
    },
    {
        "id": "300",
        "title": "Limits of Generative Pre-Training in Structured EMR Trajectories with Irregular Sampling",
        "author": [
            "Nicholas I-Hsien Kuo",
            "Blanca Gallego",
            "Louisa Jorm"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22878",
        "abstract": "Foundation models refer to architectures trained on vast datasets using autoregressive pre-training from natural language processing to capture intricate patterns and motifs. They were originally developed to transfer such learned knowledge to downstream predictive tasks. Recently, however, some studies repurpose these learned representations for phenotype discovery without rigorous validation, risking superficially realistic but clinically incoherent embeddings. To test this mismatch, we trained two autoregressive models -- a sequence-to-sequence LSTM and a reduced Transformer -- on longitudinal ART for HIV and Acute Hypotension datasets. Controlled irregularity was added during training via random inter-visit gaps, while test sequences stayed complete. Patient-trajectory synthesis evaluated distributional and correlational fidelity. Both reproduced feature distributions but failed to preserve cross-feature structure -- showing that generative pre-training yields local realism but limited clinical coherence. These results highlight the need for domain-specific evaluation and support trajectory synthesis as a practical probe before fine-tuning or deployment.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "301",
        "title": "Offline Preference Optimization via Maximum Marginal Likelihood Estimation",
        "author": [
            "Saeed Najafi",
            "Alona Fyshe"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22881",
        "abstract": "Aligning Large Language Models (LLMs) with human preferences is crucial, but standard methods like Reinforcement Learning from Human Feedback (RLHF) are often complex and unstable. In this work, we propose a new, simpler approach that recasts alignment through the lens of Maximum Marginal Likelihood (MML) estimation. Our new MML based Preference Optimization (MMPO) maximizes the marginal log-likelihood of a preferred text output, using the preference pair as samples for approximation, and forgoes the need for both an explicit reward model and entropy maximization. We theoretically demonstrate that MMPO implicitly performs preference optimization, producing a weighted gradient that naturally up-weights chosen responses over rejected ones. Across models ranging from 135M to 8B parameters, we empirically show that MMPO: 1) is more stable with respect to the hyperparameter $\\beta$ compared to alternative baselines, and 2) achieves competitive or superior preference alignment while better preserving the base model's general language capabilities. Through a series of ablation experiments, we show that this improved performance is indeed attributable to MMPO's implicit preference optimization within the gradient updates.",
        "tags": [
            "LLM",
            "RL",
            "RLHF"
        ]
    },
    {
        "id": "302",
        "title": "Never Too Rigid to Reach: Adaptive Virtual Model Control with LLM- and Lyapunov-Based Reinforcement Learning",
        "author": [
            "Jingzehua Xu",
            "Yangyang Li",
            "Yangfei Chen",
            "Guanwen Xie",
            "Shuai Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22892",
        "abstract": "Robotic arms are increasingly deployed in uncertain environments, yet conventional control pipelines often become rigid and brittle when exposed to perturbations or incomplete information. Virtual Model Control (VMC) enables compliant behaviors by embedding virtual forces and mapping them into joint torques, but its reliance on fixed parameters and limited coordination among virtual components constrains adaptability and may undermine stability as task objectives evolve. To address these limitations, we propose Adaptive VMC with Large Language Model (LLM)- and Lyapunov-Based Reinforcement Learning (RL), which preserves the physical interpretability of VMC while supporting stability-guaranteed online adaptation. The LLM provides structured priors and high-level reasoning that enhance coordination among virtual components, improve sample efficiency, and facilitate flexible adjustment to varying task requirements. Complementarily, Lyapunov-based RL enforces theoretical stability constraints, ensuring safe and reliable adaptation under uncertainty. Extensive simulations on a 7-DoF Panda arm demonstrate that our approach effectively balances competing objectives in dynamic tasks, achieving superior performance while highlighting the synergistic benefits of LLM guidance and Lyapunov-constrained adaptation.",
        "tags": [
            "LLM",
            "RL"
        ]
    },
    {
        "id": "303",
        "title": "On Generalization in Agentic Tool Calling: CoreThink Agentic Reasoner and MAVEN Dataset",
        "author": [
            "Vishvesh Bhat",
            "Omkar Ghugarkar",
            "Julian McAuley"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22898",
        "abstract": "Generalization across Agentic tool-calling environments remains a key unsolved challenge in developing reliable agentic reasoning systems. While large language models (LLMs) demonstrate strong performance on isolated benchmarks, their ability to transfer reasoning strategies and co-ordinate tools across diverse domains is poorly understood. In this work, we conduct a large-scale evaluation of state-of-the-art LLMs on multiple tool-calling benchmarksBFCL v3, TauBench, Tau2Bench, and AceBenchand introduce MAVEN (Math & Physics Adversarial Verification & Evaluation Network), a new out of distribution (OOD) benchmark designed to stress-test multi-step reasoning through explicit verification and adversarial task composition. Our results show that most current models achieve below 50% accuracy on MAVEN, revealing a significant generalization gap across tool-use settings.\nTo address this, we present the CoreThink Agentic Reasoner, a framework that augments LLMs with a lightweight symbolic reasoning layer for structured decomposition and adaptive tool orchestration. Without additional training, it generalizes across all benchmarks, achieving state-of-the-art performance with 530% improvements over existing baselines at roughly one-tenth the computational cost.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "304",
        "title": "On the Anisotropy of Score-Based Generative Models",
        "author": [
            "Andreas Floros",
            "Seyed-Mohsen Moosavi-Dezfooli",
            "Pier Luigi Dragotti"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22899",
        "abstract": "We investigate the role of network architecture in shaping the inductive biases of modern score-based generative models. To this end, we introduce the Score Anisotropy Directions (SADs), architecture-dependent directions that reveal how different networks preferentially capture data structure. Our analysis shows that SADs form adaptive bases aligned with the architecture's output geometry, providing a principled way to predict generalization ability in score models prior to training. Through both synthetic data and standard image benchmarks, we demonstrate that SADs reliably capture fine-grained model behavior and correlate with downstream performance, as measured by Wasserstein metrics. Our work offers a new lens for explaining and predicting directional biases of generative models.",
        "tags": [
            "Score-Based Generative"
        ]
    },
    {
        "id": "305",
        "title": "Modeling Political Discourse with Sentence-BERT and BERTopic",
        "author": [
            "Margarida Mendonca",
            "Alvaro Figueira"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22904",
        "abstract": "Social media has reshaped political discourse, offering politicians a platform for direct engagement while reinforcing polarization and ideological divides. This study introduces a novel topic evolution framework that integrates BERTopic-based topic modeling with Moral Foundations Theory (MFT) to analyze the longevity and moral dimensions of political topics in Twitter activity during the 117th U.S. Congress. We propose a methodology for tracking dynamic topic shifts over time and measuring their association with moral values and quantifying topic persistence. Our findings reveal that while overarching themes remain stable, granular topics tend to dissolve rapidly, limiting their long-term influence. Moreover, moral foundations play a critical role in topic longevity, with Care and Loyalty dominating durable topics, while partisan differences manifest in distinct moral framing strategies. This work contributes to the field of social network analysis and computational political discourse by offering a scalable, interpretable approach to understanding moral-driven topic evolution on social media.",
        "tags": [
            "BERT"
        ]
    },
    {
        "id": "306",
        "title": "Language Server CLI Empowers Language Agents with Process Rewards",
        "author": [
            "Yifan Zhang",
            "Lanser Contributors"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22907",
        "abstract": "Large language models routinely hallucinate APIs and mislocalize edits, while language servers compute verified, IDE-grade facts about real code. We present Lanser-CLI, a CLI-first orchestration layer that pins and mediates a Language Server Protocol (LSP) server for coding agents and CI, exposing deterministic, replayable workflows. Our position is that language servers provide not only structural information (definitions, references, types, diagnostics) but also an actionable process reward: machine-checked, step-wise signals that align an agent's planning loop with program reality. In this work, Lanser-CLI contributes: (i) a robust addressing scheme beyond brittle \"file:line:col\" via a Selector DSL (symbolic, AST-path, and content-anchored selectors) with a principled relocation algorithm; (ii) deterministic Analysis Bundles that normalize Language Server responses and capture environment/capability metadata with stable content hashes; (iii) a safety envelope for mutating operations (rename, code actions) with preview, workspace jails, and Git-aware, transactional apply; and (iv) a process-reward functional derived from Language Server facts (diagnostic deltas, disambiguation confidence, and safe-apply checks) that is computable online and replayable offline. We formalize determinism under frozen snapshots and establish a monotonicity property for the process reward, making it suitable for process supervision and counterfactual analysis. Project Page: https://github.com/yifanzhang-pro/lanser-cli",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "307",
        "title": "HyPerNav: Hybrid Perception for Object-Oriented Navigation in Unknown Environment",
        "author": [
            "Zecheng Yin",
            "Hao Zhao",
            "Zhen Li"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22917",
        "abstract": "Objective-oriented navigation(ObjNav) enables robot to navigate to target object directly and autonomously in an unknown environment. Effective perception in navigation in unknown environment is critical for autonomous robots. While egocentric observations from RGB-D sensors provide abundant local information, real-time top-down maps offer valuable global context for ObjNav. Nevertheless, the majority of existing studies focus on a single source, seldom integrating these two complementary perceptual modalities, despite the fact that humans naturally attend to both. With the rapid advancement of Vision-Language Models(VLMs), we propose Hybrid Perception Navigation (HyPerNav), leveraging VLMs' strong reasoning and vision-language understanding capabilities to jointly perceive both local and global information to enhance the effectiveness and intelligence of navigation in unknown environments. In both massive simulation evaluation and real-world validation, our methods achieved state-of-the-art performance against popular baselines. Benefiting from hybrid perception approach, our method captures richer cues and finds the objects more effectively, by simultaneously leveraging information understanding from egocentric observations and the top-down map. Our ablation study further proved that either of the hybrid perception contributes to the navigation performance.",
        "tags": [
            "Robotics",
            "VLM"
        ]
    },
    {
        "id": "308",
        "title": "Improving Human Verification of LLM Reasoning through Interactive Explanation Interfaces",
        "author": [
            "Runtao Zhou",
            "Giang Nguyen",
            "Nikita Kharya",
            "Anh Nguyen",
            "Chirag Agarwal"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22922",
        "abstract": "The reasoning capabilities of Large Language Models (LLMs) have led to their increasing employment in several critical applications, particularly education, where they support problem-solving, tutoring, and personalized study. While there are a plethora of works showing the effectiveness of LLMs in generating step-by-step solutions through chain-of-thought (CoT) reasoning on reasoning benchmarks, little is understood about whether the generated CoT is helpful for end-users in improving their ability to comprehend mathematical reasoning problems and detect errors/hallucinations in LLM-generated solutions. To address this gap and contribute to understanding how reasoning can improve human-AI interaction, we present three new interactive reasoning interfaces: interactive CoT (iCoT), interactive Program-of-Thought (iPoT), and interactive Graph (iGraph), and a novel framework that generates the LLM's reasoning from traditional CoT to alternative, interactive formats. Across 125 participants, we found that interactive interfaces significantly improved performance. Specifically, the iGraph interface yielded the highest clarity and error detection rate (85.6%), followed by iPoT (82.5%), iCoT (80.6%), all outperforming standard CoT (73.5%). Interactive interfaces also led to faster response times, where participants using iGraph were fastest (57.9 secs), compared to iCoT and iPoT (60 secs), and the standard CoT baseline (64.7 secs). Furthermore, participants preferred the iGraph reasoning interface, citing its superior ability to enable users to follow the LLM's reasoning process. We discuss the implications of these results and provide recommendations for the future design of reasoning models.",
        "tags": [
            "CoT",
            "Detection",
            "LLM"
        ]
    },
    {
        "id": "309",
        "title": "Simple Denoising Diffusion Language Models",
        "author": [
            "Huaisheng Zhu",
            "Zhengyu Chen",
            "Shijie Zhou",
            "Zhihui Xie",
            "Yige Yuan",
            "Zhimeng Guo",
            "Siyuan Xu",
            "Hangfan Zhang",
            "Vasant Honavar",
            "Teng Xiao"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22926",
        "abstract": "Diffusion models have recently been extended to language generation through Masked Diffusion Language Models (MDLMs), which achieve performance competitive with strong autoregressive models. However, MDLMs tend to degrade in the few-step regime and cannot directly adopt existing few-step distillation methods designed for continuous diffusion models, as they lack the intrinsic property of mapping from noise to data. Recent Uniform-state Diffusion Models (USDMs), initialized from a uniform prior, alleviate some limitations but still suffer from complex loss formulations that hinder scalability. In this work, we propose a simplified denoising-based loss for USDMs that optimizes only noise-replaced tokens, stabilizing training and matching ELBO-level performance. Furthermore, by framing denoising as self-supervised learning, we introduce a simple modification to our denoising loss with contrastive-inspired negative gradients, which is practical and yield additional improvements in generation quality.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "310",
        "title": "Gen-LangSplat: Generalized Language Gaussian Splatting with Pre-Trained Feature Compression",
        "author": [
            "Pranav Saxena"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22930",
        "abstract": "Modeling open-vocabulary language fields in 3D is essential for intuitive human-AI interaction and querying within physical environments. State-of-the-art approaches, such as LangSplat, leverage 3D Gaussian Splatting to efficiently construct these language fields, encoding features distilled from high-dimensional models like CLIP. However, this efficiency is currently offset by the requirement to train a scene-specific language autoencoder for feature compression, introducing a costly, per-scene optimization bottleneck that hinders deployment scalability. In this work, we introduce Gen-LangSplat, that eliminates this requirement by replacing the scene-wise autoencoder with a generalized autoencoder, pre-trained extensively on the large-scale ScanNet dataset. This architectural shift enables the use of a fixed, compact latent space for language features across any new scene without any scene-specific training. By removing this dependency, our entire language field construction process achieves a efficiency boost while delivering querying performance comparable to, or exceeding, the original LangSplat method. To validate our design choice, we perform a thorough ablation study empirically determining the optimal latent embedding dimension and quantifying representational fidelity using Mean Squared Error and cosine similarity between the original and reprojected 512-dimensional CLIP embeddings. Our results demonstrate that generalized embeddings can efficiently and accurately support open-vocabulary querying in novel 3D scenes, paving the way for scalable, real-time interactive 3D AI applications.",
        "tags": [
            "3D",
            "CLIP",
            "Gaussian Splatting"
        ]
    },
    {
        "id": "311",
        "title": "Robust Uncertainty Quantification for Self-Evolving Large Language Models via Continual Domain Pretraining",
        "author": [
            "Xiaofan Zhou",
            "Lu Cheng"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22931",
        "abstract": "Continual Learning (CL) is essential for enabling self-evolving large language models (LLMs) to adapt and remain effective amid rapid knowledge growth. Yet, despite its importance, little attention has been given to establishing statistical reliability guarantees for LLMs under CL, particularly in the setting of continual domain pretraining (CDP). Conformal Prediction (CP) has shown promise in offering correctness guarantees for LLMs, but it faces major challenges in CDP: testing data often stems from unknown or shifting domain distributions, under which CP may no longer provide valid guarantees. Moreover, when high coverage is required, CP can yield excessively large prediction sets for unanswerable queries, reducing informativeness. To address these challenges, we introduce an adaptive rejection and non-exchangeable CP framework. Our method first estimates the distribution of questions across domains in the test set using transformer-based clustering, then reweights or resamples the calibration data accordingly. Building on this, adaptive rejection CP allows the LLM to selectively abstain from answering when its confidence or competence shifts significantly. Extensive experiments demonstrate that our framework enhances both the effectiveness and reliability of CP under CDP scenarios. Our code is available at: https://anonymous.4open.science/r/CPCL-8C12/",
        "tags": [
            "LLM",
            "Transformer"
        ]
    },
    {
        "id": "312",
        "title": "How Can AI Augment Access to Justice? Public Defenders' Perspectives on AI Adoption",
        "author": [
            "Inyoung Cheong",
            "Patty Liu",
            "Dominik Stammbach",
            "Peter Henderson"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22933",
        "abstract": "Public defenders are asked to do more with less: representing clients deserving of adequate counsel while facing overwhelming caseloads and scarce resources. While artificial intelligence (AI) and large language models (LLMs) are promoted as tools to alleviate this burden, such proposals are detached from the lived realities of public defenders. This study addresses that gap through semi-structured interviews with fourteen practitioners across the United States to examine their experiences with AI, anticipated applications, and ethical concerns. We find that AI adoption is constrained by costs, restrictive office norms, confidentiality risks, and unsatisfactory tool quality. To clarify where AI can and cannot contribute, we propose a task-level map of public defense. Public defenders view AI as most useful for evidence investigation to analyze overwhelming amounts of digital records, with narrower roles in legal research & writing, and client communication. Courtroom representation and defense strategy are considered least compatible with AI assistance, as they depend on contextual judgment and trust. Public defenders emphasize safeguards for responsible use, including mandatory human verification, limits on overreliance, and the preservation of relational aspect of lawyering. Building on these findings, we outline a research agenda that promotes equitable access to justice by prioritizing open-source models, domain-specific datasets and evaluation, and participatory design that incorporates defenders' perspectives into system development.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "313",
        "title": "Positional Preservation Embedding for Multimodal Large Language Models",
        "author": [
            "Mouxiao Huang",
            "Borui Jiang",
            "Dehua Zheng",
            "Hailin Hu",
            "Kai Han",
            "Xinghao Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22936",
        "abstract": "Multimodal large language models (MLLMs) have achieved strong performance on vision-language tasks, yet often suffer from inefficiencies due to redundant visual tokens. Existing token merging methods reduce sequence length but frequently disrupt spatial layouts and temporal continuity by disregarding positional relationships. In this work, we propose a novel encoding operator dubbed as \\textbf{P}ositional \\textbf{P}reservation \\textbf{E}mbedding (\\textbf{PPE}), which has the main hallmark of preservation of spatiotemporal structure during visual token compression. PPE explicitly introduces the disentangled encoding of 3D positions in the token dimension, enabling each compressed token to encapsulate different positions from multiple original tokens. Furthermore, we show that PPE can effectively support cascade clustering -- a progressive token compression strategy that leads to better performance retention. PPE is a parameter-free and generic operator that can be seamlessly integrated into existing token merging methods without any adjustments. Applied to state-of-the-art token merging framework, PPE achieves consistent improvements of $2\\%\\sim5\\%$ across multiple vision-language benchmarks, including MMBench (general vision understanding), TextVQA (layout understanding) and VideoMME (temporal understanding). These results demonstrate that preserving positional cues is critical for efficient and effective MLLM reasoning.",
        "tags": [
            "3D",
            "LLM"
        ]
    },
    {
        "id": "314",
        "title": "Bi-Encoder Contrastive Learning for Fingerprint and Iris Biometrics",
        "author": [
            "Matthew So",
            "Judah Goldfeder",
            "Mark Lis",
            "Hod Lipson"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22937",
        "abstract": "There has been a historic assumption that the biometrics of an individual are statistically uncorrelated. We test this assumption by training Bi-Encoder networks on three verification tasks, including fingerprint-to-fingerprint matching, iris-to-iris matching, and cross-modal fingerprint-to-iris matching using 274 subjects with $\\sim$100k fingerprints and 7k iris images. We trained ResNet-50 and Vision Transformer backbones in Bi-Encoder architectures such that the contrastive loss between images sampled from the same individual is minimized. The iris ResNet architecture reaches 91 ROC AUC score for iris-to-iris matching, providing clear evidence that the left and right irises of an individual are correlated. Fingerprint models reproduce the positive intra-subject suggested by prior work in this space. This is the first work attempting to use Vision Transformers for this matching. Cross-modal matching rises only slightly above chance, which suggests that more data and a more sophisticated pipeline is needed to obtain compelling results. These findings continue challenge independence assumptions of biometrics and we plan to extend this work to other biometrics in the future. Code available: https://github.com/MatthewSo/bio_fingerprints_iris.",
        "tags": [
            "Transformer",
            "ViT"
        ]
    },
    {
        "id": "315",
        "title": "RL-AUX: Reinforcement Learning for Auxiliary Task Generation",
        "author": [
            "Judah Goldfeder",
            "Matthew So",
            "Hod Lipson"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22940",
        "abstract": "Auxiliary Learning (AL) is a special case of Multi-task Learning (MTL) in which a network trains on auxiliary tasks to improve performance on its main task. This technique is used to improve generalization and, ultimately, performance on the network's main task. AL has been demonstrated to improve performance across multiple domains, including navigation, image classification, and natural language processing. One weakness of AL is the need for labeled auxiliary tasks, which can require human effort and domain expertise to generate. Meta Learning techniques have been used to solve this issue by learning an additional auxiliary task generation network that can create helpful tasks for the primary network. The most prominent techniques rely on Bi-Level Optimization, which incurs computational cost and increased code complexity. To avoid the need for Bi-Level Optimization, we present an RL-based approach to dynamically create auxiliary tasks. In this framework, an RL agent is tasked with selecting auxiliary labels for every data point in a training set. The agent is rewarded when their selection improves the performance on the primary task. We also experiment with learning optimal strategies for weighing the auxiliary loss per data point. On the 20-Superclass CIFAR100 problem, our RL approach outperforms human-labeled auxiliary tasks and performs as well as a prominent Bi-Level Optimization technique. Our weight learning approaches significantly outperform all of these benchmarks. For example, a Weight-Aware RL-based approach helps the VGG16 architecture achieve 80.9% test accuracy while the human-labeled auxiliary task setup achieved 75.53%. The goal of this work is to (1) prove that RL is a viable approach to dynamically generate auxiliary tasks and (2) demonstrate that per-sample auxiliary task weights can be learned alongside the auxiliary task labels and can achieve strong results.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "316",
        "title": "Hazard-Responsive Digital Twin for Climate-Driven Urban Resilience and Equity",
        "author": [
            "Zhenglai Shen",
            "Hongyu Zhou"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22941",
        "abstract": "Compounding climate hazards, such as wildfire-induced outages and urban heatwaves, challenge the stability and equity of cities. We present a Hazard-Responsive Digital Twin (H-RDT) that combines physics-informed neural network modeling, multimodal data fusion, and equity-aware risk analytics for urban-scale response. In a synthetic district with diverse building archetypes and populations, a simulated wildfire-outage-heatwave cascade shows that H-RDT maintains stable indoor temperature predictions (approximately 31 to 33 C) under partial sensor loss, reproducing outage-driven surges and recovery. The reinforcement learning based fusion module adaptively reweights IoT, UAV, and satellite inputs to sustain spatiotemporal coverage, while the equity-adjusted mapping isolates high-vulnerability clusters (schools, clinics, low-income housing). Prospective interventions, such as preemptive cooling-center activation and microgrid sharing, reduce population-weighted thermal risk by 11 to 13 percent, shrink the 95th-percentile (tail) risk by 7 to 17 percent, and cut overheating hours by up to 9 percent. Beyond the synthetic demonstration, the framework establishes a transferable foundation for real-city implementation, linking physical hazard modeling with social equity and decision intelligence. The H-RDT advances digital urban resilience toward adaptive, learning-based, and equity-centered decision support for climate adaptation.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "317",
        "title": "LightBagel: A Light-weighted, Double Fusion Framework for Unified Multimodal Understanding and Generation",
        "author": [
            "Zeyu Wang",
            "Zilong Chen",
            "Chenhui Gou",
            "Feng Li",
            "Chaorui Deng",
            "Deyao Zhu",
            "Kunchang Li",
            "Weihao Yu",
            "Haoqin Tu",
            "Haoqi Fan",
            "Cihang Xie"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22946",
        "abstract": "Unified multimodal models have recently shown remarkable gains in both capability and versatility, yet most leading systems are still trained from scratch and require substantial computational resources. In this paper, we show that competitive performance can be obtained far more efficiently by strategically fusing publicly available models specialized for either generation or understanding. Our key design is to retain the original blocks while additionally interleaving multimodal self-attention blocks throughout the networks. This double fusion mechanism (1) effectively enables rich multi-modal fusion while largely preserving the original strengths of the base models, and (2) catalyzes synergistic fusion of high-level semantic representations from the understanding encoder with low-level spatial signals from the generation encoder. By training with only ~ 35B tokens, this approach achieves strong results across multiple benchmarks: 0.91 on GenEval for compositional text-to-image generation, 82.16 on DPG-Bench for complex text-to-image generation, 6.06 on GEditBench, and 3.77 on ImgEdit-Bench for image editing. By fully releasing the entire suite of code, model weights, and datasets, we hope to support future research on unified multimodal modeling.",
        "tags": [
            "Image Editing",
            "Text-to-Image"
        ]
    },
    {
        "id": "318",
        "title": "Hankel Singular Value Regularization for Highly Compressible State Space Models",
        "author": [
            "Paul Schwerdtner",
            "Jules Berman",
            "Benjamin Peherstorfer"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22951",
        "abstract": "Deep neural networks using state space models as layers are well suited for long-range sequence tasks but can be challenging to compress after training. We use that regularizing the sum of Hankel singular values of state space models leads to a fast decay of these singular values and thus to compressible models. To make the proposed Hankel singular value regularization scalable, we develop an algorithm to efficiently compute the Hankel singular values during training iterations by exploiting the specific block-diagonal structure of the system matrices that is we use in our state space model parametrization. Experiments on Long Range Arena benchmarks demonstrate that the regularized state space layers are up to 10$\\times$ more compressible than standard state space layers while maintaining high accuracy.",
        "tags": [
            "SSMs"
        ]
    },
    {
        "id": "319",
        "title": "Tagging-Augmented Generation: Assisting Language Models in Finding Intricate Knowledge In Long Contexts",
        "author": [
            "Anwesan Pal",
            "Karen Hovsepian",
            "Tinghao Guo",
            "Mengnan Zhao",
            "Somendra Tripathi",
            "Nikos Kanakaris",
            "George Mihaila",
            "Sumit Nigam"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22956",
        "abstract": "Recent investigations into effective context lengths of modern flagship large language models (LLMs) have revealed major limitations in effective question answering (QA) and reasoning over long and complex contexts for even the largest and most impressive cadre of models. While approaches like retrieval-augmented generation (RAG) and chunk-based re-ranking attempt to mitigate this issue, they are sensitive to chunking, embedding and retrieval strategies and models, and furthermore, rely on extensive pre-processing, knowledge acquisition and indexing steps. In this paper, we propose Tagging-Augmented Generation (TAG), a lightweight data augmentation strategy that boosts LLM performance in long-context scenarios, without degrading and altering the integrity and composition of retrieved documents. We validate our hypothesis by augmenting two challenging and directly relevant question-answering benchmarks -- NoLima and NovelQA -- and show that tagging the context or even just adding tag definitions into QA prompts leads to consistent performance gains over the baseline -- up to 17% for 32K token contexts, and 2.9% in complex reasoning question-answering for multi-hop queries requiring knowledge across a wide span of text. Additional details are available at https://sites.google.com/view/tag-emnlp.",
        "tags": [
            "LLM",
            "RAG"
        ]
    },
    {
        "id": "320",
        "title": "FAME: Fairness-aware Attention-modulated Video Editing",
        "author": [
            "Zhangkai Wu",
            "Xuhui Fan",
            "Zhongyuan Xie",
            "Kaize Shi",
            "Zhidong Li",
            "Longbing Cao"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22960",
        "abstract": "Training-free video editing (VE) models tend to fall back on gender stereotypes when rendering profession-related prompts. We propose \\textbf{FAME} for \\textit{Fairness-aware Attention-modulated Video Editing} that mitigates profession-related gender biases while preserving prompt alignment and temporal consistency for coherent VE. We derive fairness embeddings from existing minority representations by softly injecting debiasing tokens into the text encoder. Simultaneously, FAME integrates fairness modulation into both temporal self attention and prompt-to-region cross attention to mitigate the motion corruption and temporal inconsistency caused by directly introducing fairness cues. For temporal self attention, FAME introduces a region constrained attention mask combined with time decay weighting, which enhances intra-region coherence while suppressing irrelevant inter-region interactions. For cross attention, it reweights tokens to region matching scores by incorporating fairness sensitive similarity masks derived from debiasing prompt embeddings. Together, these modulations keep fairness-sensitive semantics tied to the right visual regions and prevent temporal drift across frames. Extensive experiments on new VE fairness-oriented benchmark \\textit{FairVE} demonstrate that FAME achieves stronger fairness alignment and semantic fidelity, surpassing existing VE baselines.",
        "tags": [
            "Video Editing"
        ]
    },
    {
        "id": "321",
        "title": "CompressionAttack: Exploiting Prompt Compression as a New Attack Surface in LLM-Powered Agents",
        "author": [
            "Zesen Liu",
            "Zhixiang Zhang",
            "Yuchong Xie",
            "Dongdong She"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22963",
        "abstract": "LLM-powered agents often use prompt compression to reduce inference costs, but this introduces a new security risk. Compression modules, which are optimized for efficiency rather than safety, can be manipulated by adversarial inputs, causing semantic drift and altering LLM behavior. This work identifies prompt compression as a novel attack surface and presents CompressionAttack, the first framework to exploit it. CompressionAttack includes two strategies: HardCom, which uses discrete adversarial edits for hard compression, and SoftCom, which performs latent-space perturbations for soft compression. Experiments on multiple LLMs show up to 80% attack success and 98% preference flips, while remaining highly stealthy and transferable. Case studies in VSCode Cline and Ollama confirm real-world impact, and current defenses prove ineffective, highlighting the need for stronger protections.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "322",
        "title": "MAD-Fact: A Multi-Agent Debate Framework for Long-Form Factuality Evaluation in LLMs",
        "author": [
            "Yucheng Ning",
            "Xixun Lin",
            "Fang Fang",
            "Yanan Cao"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22967",
        "abstract": "The widespread adoption of Large Language Models (LLMs) raises critical concerns about the factual accuracy of their outputs, especially in high-risk domains such as biomedicine, law, and education. Existing evaluation methods for short texts often fail on long-form content due to complex reasoning chains, intertwined perspectives, and cumulative information. To address this, we propose a systematic approach integrating large-scale long-form datasets, multi-agent verification mechanisms, and weighted evaluation metrics. We construct LongHalluQA, a Chinese long-form factuality dataset; and develop MAD-Fact, a debate-based multi-agent verification system. We introduce a fact importance hierarchy to capture the varying significance of claims in long-form texts. Experiments on two benchmarks show that larger LLMs generally maintain higher factual consistency, while domestic models excel on Chinese content. Our work provides a structured framework for evaluating and enhancing factual reliability in long-form LLM outputs, guiding their safe deployment in sensitive domains.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "323",
        "title": "Measuring Teaching with LLMs",
        "author": [
            "Michael Hardy"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22968",
        "abstract": "Objective and scalable measurement of teaching quality is a persistent challenge in education. While Large Language Models (LLMs) offer potential, general-purpose models have struggled to reliably apply complex, authentic classroom observation instruments. This paper uses custom LLMs built on sentence-level embeddings, an architecture better suited for the long-form, interpretive nature of classroom transcripts than conventional subword tokenization. We systematically evaluate five different sentence embeddings under a data-efficient training regime designed to prevent overfitting. Our results demonstrate that these specialized models can achieve human-level and even super-human performance with expert human ratings above 0.65 and surpassing the average human-human rater correlation. Further, through analysis of annotation context windows, we find that more advanced models-those better aligned with human judgments-attribute a larger share of score variation to lesson-level features rather than isolated utterances, challenging the sufficiency of single-turn annotation paradigms. Finally, to assess external validity, we find that aggregate model scores align with teacher value-added measures, indicating they are capturing features relevant to student learning. However, this trend does not hold at the individual item level, suggesting that while the models learn useful signals, they have not yet achieved full generalization. This work establishes a viable and powerful new methodology for AI-driven instructional measurement, offering a path toward providing scalable, reliable, and valid feedback for educator development.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "324",
        "title": "Multi-Agent Conditional Diffusion Model with Mean Field Communication as Wireless Resource Allocation Planner",
        "author": [
            "Kechen Meng",
            "Sinuo Zhang",
            "Rongpeng Li",
            "Xiangming Meng",
            "Chan Wang",
            "Ming Lei",
            "Zhifeng Zhao"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22969",
        "abstract": "In wireless communication systems, efficient and adaptive resource allocation plays a crucial role in enhancing overall Quality of Service (QoS). While centralized Multi-Agent Reinforcement Learning (MARL) frameworks rely on a central coordinator for policy training and resource scheduling, they suffer from scalability issues and privacy risks. In contrast, the Distributed Training with Decentralized Execution (DTDE) paradigm enables distributed learning and decision-making, but it struggles with non-stationarity and limited inter-agent cooperation, which can severely degrade system performance. To overcome these challenges, we propose the Multi-Agent Conditional Diffusion Model Planner (MA-CDMP) for decentralized communication resource management. Built upon the Model-Based Reinforcement Learning (MBRL) paradigm, MA-CDMP employs Diffusion Models (DMs) to capture environment dynamics and plan future trajectories, while an inverse dynamics model guides action generation, thereby alleviating the sample inefficiency and slow convergence of conventional DTDE methods. Moreover, to approximate large-scale agent interactions, a Mean-Field (MF) mechanism is introduced as an assistance to the classifier in DMs. This design mitigates inter-agent non-stationarity and enhances cooperation with minimal communication overhead in distributed settings. We further theoretically establish an upper bound on the distributional approximation error introduced by the MF-based diffusion generation, guaranteeing convergence stability and reliable modeling of multi-agent stochastic dynamics. Extensive experiments demonstrate that MA-CDMP consistently outperforms existing MARL baselines in terms of average reward and QoS metrics, showcasing its scalability and practicality for real-world wireless network optimization.",
        "tags": [
            "Diffusion",
            "RL"
        ]
    },
    {
        "id": "325",
        "title": "VALA: Learning Latent Anchors for Training-Free and Temporally Consistent",
        "author": [
            "Zhangkai Wu",
            "Xuhui Fan",
            "Zhongyuan Xie",
            "Kaize Shi",
            "Longbing Cao"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22970",
        "abstract": "Recent advances in training-free video editing have enabled lightweight and precise cross-frame generation by leveraging pre-trained text-to-image diffusion models. However, existing methods often rely on heuristic frame selection to maintain temporal consistency during DDIM inversion, which introduces manual bias and reduces the scalability of end-to-end inference. In this paper, we propose~\\textbf{VALA} (\\textbf{V}ariational \\textbf{A}lignment for \\textbf{L}atent \\textbf{A}nchors), a variational alignment module that adaptively selects key frames and compresses their latent features into semantic anchors for consistent video editing. To learn meaningful assignments, VALA propose a variational framework with a contrastive learning objective. Therefore, it can transform cross-frame latent representations into compressed latent anchors that preserve both content and temporal coherence. Our method can be fully integrated into training-free text-to-image based video editing models. Extensive experiments on real-world video editing benchmarks show that VALA achieves state-of-the-art performance in inversion fidelity, editing quality, and temporal consistency, while offering improved efficiency over prior methods.",
        "tags": [
            "DDIM",
            "Diffusion",
            "Text-to-Image",
            "Video Editing"
        ]
    },
    {
        "id": "326",
        "title": "Scaling Up Occupancy-centric Driving Scene Generation: Dataset and Method",
        "author": [
            "Bohan Li",
            "Xin Jin",
            "Hu Zhu",
            "Hongsi Liu",
            "Ruikai Li",
            "Jiazhe Guo",
            "Kaiwen Cai",
            "Chao Ma",
            "Yueming Jin",
            "Hao Zhao",
            "Xiaokang Yang",
            "Wenjun Zeng"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22973",
        "abstract": "Driving scene generation is a critical domain for autonomous driving, enabling downstream applications, including perception and planning evaluation. Occupancy-centric methods have recently achieved state-of-the-art results by offering consistent conditioning across frames and modalities; however, their performance heavily depends on annotated occupancy data, which still remains scarce. To overcome this limitation, we curate Nuplan-Occ, the largest semantic occupancy dataset to date, constructed from the widely used Nuplan benchmark. Its scale and diversity facilitate not only large-scale generative modeling but also autonomous driving downstream applications. Based on this dataset, we develop a unified framework that jointly synthesizes high-quality semantic occupancy, multi-view videos, and LiDAR point clouds. Our approach incorporates a spatio-temporal disentangled architecture to support high-fidelity spatial expansion and temporal forecasting of 4D dynamic occupancy. To bridge modal gaps, we further propose two novel techniques: a Gaussian splatting-based sparse point map rendering strategy that enhances multi-view video generation, and a sensor-aware embedding strategy that explicitly models LiDAR sensor properties for realistic multi-LiDAR simulation. Extensive experiments demonstrate that our method achieves superior generation fidelity and scalability compared to existing approaches, and validates its practical value in downstream tasks. Repo: https://github.com/Arlo0o/UniScene-Unified-Occupancy-centric-Driving-Scene-Generation/tree/v2",
        "tags": [
            "Gaussian Splatting",
            "Video Generation"
        ]
    },
    {
        "id": "327",
        "title": "VoMP: Predicting Volumetric Mechanical Property Fields",
        "author": [
            "Rishit Dagli",
            "Donglai Xiang",
            "Vismay Modi",
            "Charles Loop",
            "Clement Fuji Tsang",
            "Anka He Chen",
            "Anita Hu",
            "Gavriel State",
            "David I.W. Levin",
            "Maria Shugrina"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22975",
        "abstract": "Physical simulation relies on spatially-varying mechanical properties, often laboriously hand-crafted. VoMP is a feed-forward method trained to predict Young's modulus ($E$), Poisson's ratio ($\\nu$), and density ($\\rho$) throughout the volume of 3D objects, in any representation that can be rendered and voxelized. VoMP aggregates per-voxel multi-view features and passes them to our trained Geometry Transformer to predict per-voxel material latent codes. These latents reside on a manifold of physically plausible materials, which we learn from a real-world dataset, guaranteeing the validity of decoded per-voxel materials. To obtain object-level training data, we propose an annotation pipeline combining knowledge from segmented 3D datasets, material databases, and a vision-language model, along with a new benchmark. Experiments show that VoMP estimates accurate volumetric properties, far outperforming prior art in accuracy and speed.",
        "tags": [
            "3D",
            "Transformer"
        ]
    },
    {
        "id": "328",
        "title": "The Reasoning Trap: How Enhancing LLM Reasoning Amplifies Tool Hallucination",
        "author": [
            "Chenlong Yin",
            "Zeyang Sha",
            "Shiwen Cui",
            "Changhua Meng"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22977",
        "abstract": "Enhancing the reasoning capabilities of Large Language Models (LLMs) is a key strategy for building Agents that \"think then act.\" However, recent observations, like OpenAI's o3, suggest a paradox: stronger reasoning often coincides with increased hallucination, yet no prior work has systematically examined whether reasoning enhancement itself causes tool hallucination. To address this gap, we pose the central question: Does strengthening reasoning increase tool hallucination? To answer this, we introduce SimpleToolHalluBench, a diagnostic benchmark measuring tool hallucination in two failure modes: (i) no tool available, and (ii) only distractor tools available. Through controlled experiments, we establish three key findings. First, we demonstrate a causal relationship: progressively enhancing reasoning through RL increases tool hallucination proportionally with task performance gains. Second, this effect transcends overfitting - training on non-tool tasks (e.g., mathematics) still amplifies subsequent tool hallucination. Third, the effect is method-agnostic, appearing when reasoning is instilled via supervised fine-tuning and when it is merely elicited at inference by switching from direct answers to step-by-step thinking. We also evaluate mitigation strategies including Prompt Engineering and Direct Preference Optimization (DPO), revealing a fundamental reliability-capability trade-off: reducing hallucination consistently degrades utility. Mechanistically, Reasoning RL disproportionately collapses tool-reliability-related representations, and hallucinations surface as amplified divergences concentrated in late-layer residual streams. These findings reveal that current reasoning enhancement methods inherently amplify tool hallucination, highlighting the need for new training objectives that jointly optimize for capability and reliability.",
        "tags": [
            "DPO",
            "LLM",
            "RL"
        ]
    },
    {
        "id": "329",
        "title": "Reasoning About Reasoning: Towards Informed and Reflective Use of LLM Reasoning in HCI",
        "author": [
            "Ramaravind Kommiya Mothilal",
            "Sally Zhang",
            "Syed Ishtiaque Ahmed",
            "Shion Guha"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22978",
        "abstract": "Reasoning is a distinctive human-like characteristic attributed to LLMs in HCI due to their ability to simulate various human-level tasks. However, this work argues that the reasoning behavior of LLMs in HCI is often decontextualized from the underlying mechanics and subjective decisions that condition the emergence and human interpretation of this behavior. Through a systematic survey of 258 CHI papers from 2020-2025 on LLMs, we discuss how HCI hardly perceives LLM reasoning as a product of sociotechnical orchestration and often references it as an object of application. We argue that such abstraction leads to oversimplification of reasoning methodologies from NLP/ML and results in a distortion of LLMs' empirically studied capabilities and (un)known limitations. Finally, drawing on literature from both NLP/ML and HCI, as a constructive step forward, we develop reflection prompts to support HCI practitioners engage with LLM reasoning in an informed and reflective way.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "330",
        "title": "Exploring Semantic-constrained Adversarial Example with Instruction Uncertainty Reduction",
        "author": [
            "Jin Hu",
            "Jiakai Wang",
            "Linna Jing",
            "Haolin Li",
            "Haodong Liu",
            "Haotong Qin",
            "Aishan Liu",
            "Ke Xu",
            "Xianglong Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22981",
        "abstract": "Recently, semantically constrained adversarial examples (SemanticAE), which are directly generated from natural language instructions, have become a promising avenue for future research due to their flexible attacking forms. To generate SemanticAEs, current methods fall short of satisfactory attacking ability as the key underlying factors of semantic uncertainty in human instructions, such as referring diversity, descriptive incompleteness, and boundary ambiguity, have not been fully investigated. To tackle the issues, this paper develops a multi-dimensional instruction uncertainty reduction (InSUR) framework to generate more satisfactory SemanticAE, i.e., transferable, adaptive, and effective. Specifically, in the dimension of the sampling method, we propose the residual-driven attacking direction stabilization to alleviate the unstable adversarial optimization caused by the diversity of language references. By coarsely predicting the language-guided sampling process, the optimization process will be stabilized by the designed ResAdv-DDIM sampler, therefore releasing the transferable and robust adversarial capability of multi-step diffusion models. In task modeling, we propose the context-encoded attacking scenario constraint to supplement the missing knowledge from incomplete human instructions. Guidance masking and renderer integration are proposed to regulate the constraints of 2D/3D SemanticAE, activating stronger scenario-adapted attacks. Moreover, in the dimension of generator evaluation, we propose the semantic-abstracted attacking evaluation enhancement by clarifying the evaluation boundary, facilitating the development of more effective SemanticAE generators. Extensive experiments demonstrate the superiority of the transfer attack performance of InSUR. Moreover, we realize the reference-free generation of semantically constrained 3D adversarial examples for the first time.",
        "tags": [
            "3D",
            "DDIM",
            "Diffusion"
        ]
    },
    {
        "id": "331",
        "title": "Capsule Network-Based Multimodal Fusion for Mortgage Risk Assessment from Unstructured Data Sources",
        "author": [
            "Mahsa Tavakoli",
            "Rohitash Chandra",
            "Cristian Bravo"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22987",
        "abstract": "Mortgage risk assessment traditionally relies on structured financial data, which is often proprietary, confidential, and costly. In this study, we propose a novel multimodal deep learning framework that uses cost-free, publicly available, unstructured data sources, including textual information, images, and sentiment scores, to generate credit scores that approximate commercial scorecards. Our framework adopts a two-phase approach. In the unimodal phase, we identify the best-performing models for each modality, i.e. BERT for text, VGG for image data, and a multilayer perceptron for sentiment-based features. In the fusion phase, we introduce the capsule-based fusion network (FusionCapsNet), a novel fusion strategy inspired by capsule networks, but fundamentally redesigned for multimodal integration. Unlike standard capsule networks, our method adapts a specific mechanism in capsule networks to each modality and restructures the fusion process to preserve spatial, contextual, and modality-specific information. It also enables adaptive weighting so that stronger modalities dominate without ignoring complementary signals.\nOur framework incorporates sentiment analysis across distinct news categories to capture borrower and market dynamics and employs GradCAM-based visualizations as an interpretability tool. These components are designed features of the framework, while our results later demonstrate that they effectively enrich contextual understanding and highlight the influential factors driving mortgage risk predictions. Our results show that our multimodal FusionCapsNet framework not only exceeds individual unimodal models but also outperforms benchmark fusion strategies such as addition, concatenation, and cross attention in terms of AUC, partial AUC, and F1 score, demonstrating clear gains in both predictive accuracy and interpretability for mortgage risk assessment.",
        "tags": [
            "BERT"
        ]
    },
    {
        "id": "332",
        "title": "Can Language Models Compose Skills In-Context?",
        "author": [
            "Zidong Liu",
            "Zhuoyan Xu",
            "Zhenmei Shi",
            "Yingyu Liang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22993",
        "abstract": "Composing basic skills from simple tasks to accomplish composite tasks is crucial for modern intelligent systems. We investigate the in-context composition ability of language models to perform composite tasks that combine basic skills demonstrated in in-context examples. This is more challenging than the standard setting, where skills and their composition can be learned in training. We conduct systematic experiments on various representative open-source language models, utilizing linguistic and logical tasks designed to probe composition abilities. The results reveal that simple task examples can have a surprising negative impact on the performance, because the models generally struggle to recognize and assemble the skills correctly, even with Chain-of-Thought examples. Theoretical analysis further shows that it is crucial to align examples with the corresponding steps in the composition. This inspires a method for the probing tasks, whose improved performance provides positive support for our insights.",
        "tags": [
            "CoT"
        ]
    },
    {
        "id": "333",
        "title": "SceneDecorator: Towards Scene-Oriented Story Generation with Scene Planning and Scene Consistency",
        "author": [
            "Quanjian Song",
            "Donghao Zhou",
            "Jingyu Lin",
            "Fei Shen",
            "Jiaze Wang",
            "Xiaowei Hu",
            "Cunjian Chen",
            "Pheng-Ann Heng"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22994",
        "abstract": "Recent text-to-image models have revolutionized image generation, but they still struggle with maintaining concept consistency across generated images. While existing works focus on character consistency, they often overlook the crucial role of scenes in storytelling, which restricts their creativity in practice. This paper introduces scene-oriented story generation, addressing two key challenges: (i) scene planning, where current methods fail to ensure scene-level narrative coherence by relying solely on text descriptions, and (ii) scene consistency, which remains largely unexplored in terms of maintaining scene consistency across multiple stories. We propose SceneDecorator, a training-free framework that employs VLM-Guided Scene Planning to ensure narrative coherence across different scenes in a ``global-to-local'' manner, and Long-Term Scene-Sharing Attention to maintain long-term scene consistency and subject diversity across generated stories. Extensive experiments demonstrate the superior performance of SceneDecorator, highlighting its potential to unleash creativity in the fields of arts, films, and games.",
        "tags": [
            "Text-to-Image",
            "VLM"
        ]
    },
    {
        "id": "334",
        "title": "An Intelligent Water-Saving Irrigation System Based on Multi-Sensor Fusion and Visual Servoing Control",
        "author": [
            "ZhengKai Huang",
            "YiKun Wang",
            "ChenYu Hui",
            "XiaoCheng"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23003",
        "abstract": "This paper introduces an intelligent water-saving irrigation system designed to address critical challenges in precision agriculture, such as inefficient water use and poor terrain adaptability. The system integrates advanced computer vision, robotic control, and real-time stabilization technologies via a multi-sensor fusion approach. A lightweight YOLO model, deployed on an embedded vision processor (K210), enables real-time plant container detection with over 96% accuracy under varying lighting conditions. A simplified hand-eye calibration algorithm-designed for 'handheld camera' robot arm configurations-ensures that the end effector can be precisely positioned, with a success rate exceeding 90%. The active leveling system, driven by the STM32F103ZET6 main control chip and JY901S inertial measurement data, can stabilize the irrigation platform on slopes up to 10 degrees, with a response time of 1.8 seconds. Experimental results across three simulated agricultural environments (standard greenhouse, hilly terrain, complex lighting) demonstrate a 30-50% reduction in water consumption compared to conventional flood irrigation, with water use efficiency exceeding 92% in all test cases.",
        "tags": [
            "Detection",
            "Robotics"
        ]
    },
    {
        "id": "335",
        "title": "Understanding In-Context Learning Beyond Transformers: An Investigation of State Space and Hybrid Architectures",
        "author": [
            "Shenran Wang",
            "Timothy Tin-Long Tse",
            "Jian Zhu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23006",
        "abstract": "We perform in-depth evaluations of in-context learning (ICL) on state-of-the-art transformer, state-space, and hybrid large language models over two categories of knowledge-based ICL tasks. Using a combination of behavioral probing and intervention-based methods, we have discovered that, while LLMs of different architectures can behave similarly in task performance, their internals could remain different. We discover that function vectors (FVs) responsible for ICL are primarily located in the self-attention and Mamba layers, and speculate that Mamba2 uses a different mechanism from FVs to perform ICL. FVs are more important for ICL involving parametric knowledge retrieval, but not for contextual knowledge understanding. Our work contributes to a more nuanced understanding across architectures and task types. Methodologically, our approach also highlights the importance of combining both behavioural and mechanistic analyses to investigate LLM capabilities.",
        "tags": [
            "LLM",
            "Mamba",
            "Transformer"
        ]
    },
    {
        "id": "336",
        "title": "CoMo: Compositional Motion Customization for Text-to-Video Generation",
        "author": [
            "Youcan Xu",
            "Zhen Wang",
            "Jiaxin Shi",
            "Kexin Li",
            "Feifei Shao",
            "Jun Xiao",
            "Yi Yang",
            "Jun Yu",
            "Long Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23007",
        "abstract": "While recent text-to-video models excel at generating diverse scenes, they struggle with precise motion control, particularly for complex, multi-subject motions. Although methods for single-motion customization have been developed to address this gap, they fail in compositional scenarios due to two primary challenges: motion-appearance entanglement and ineffective multi-motion blending. This paper introduces CoMo, a novel framework for $\\textbf{compositional motion customization}$ in text-to-video generation, enabling the synthesis of multiple, distinct motions within a single video. CoMo addresses these issues through a two-phase approach. First, in the single-motion learning phase, a static-dynamic decoupled tuning paradigm disentangles motion from appearance to learn a motion-specific module. Second, in the multi-motion composition phase, a plug-and-play divide-and-merge strategy composes these learned motions without additional training by spatially isolating their influence during the denoising process. To facilitate research in this new domain, we also introduce a new benchmark and a novel evaluation metric designed to assess multi-motion fidelity and blending. Extensive experiments demonstrate that CoMo achieves state-of-the-art performance, significantly advancing the capabilities of controllable video generation. Our project page is at https://como6.github.io/.",
        "tags": [
            "Text-to-Video",
            "Video Generation"
        ]
    },
    {
        "id": "337",
        "title": "UGAE: Unified Geometry and Attribute Enhancement for G-PCC Compressed Point Clouds",
        "author": [
            "Pan Zhao",
            "Hui Yuan",
            "Chongzhen Tian",
            "Tian Guo",
            "Raouf Hamzaoui",
            "Zhigeng Pan"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23009",
        "abstract": "Lossy compression of point clouds reduces storage and transmission costs; however, it inevitably leads to irreversible distortion in geometry structure and attribute information. To address these issues, we propose a unified geometry and attribute enhancement (UGAE) framework, which consists of three core components: post-geometry enhancement (PoGE), pre-attribute enhancement (PAE), and post-attribute enhancement (PoAE). In PoGE, a Transformer-based sparse convolutional U-Net is used to reconstruct the geometry structure with high precision by predicting voxel occupancy probabilities. Building on the refined geometry structure, PAE introduces an innovative enhanced geometry-guided recoloring strategy, which uses a detail-aware K-Nearest Neighbors (DA-KNN) method to achieve accurate recoloring and effectively preserve high-frequency details before attribute compression. Finally, at the decoder side, PoAE uses an attribute residual prediction network with a weighted mean squared error (W-MSE) loss to enhance the quality of high-frequency regions while maintaining the fidelity of low-frequency regions. UGAE significantly outperformed existing methods on three benchmark datasets: 8iVFB, Owlii, and MVUB. Compared to the latest G-PCC test model (TMC13v29), UGAE achieved an average BD-PSNR gain of 9.98 dB and 90.98% BD-bitrate savings for geometry under the D1 metric, as well as a 3.67 dB BD-PSNR improvement with 56.88% BD-bitrate savings for attributes on the Y component. Additionally, it improved perceptual quality significantly.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "338",
        "title": "TALM: Dynamic Tree-Structured Multi-Agent Framework with Long-Term Memory for Scalable Code Generation",
        "author": [
            "Ming-Tung Shen",
            "Yuh-Jzer Joung"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23010",
        "abstract": "Agentic code generation requires large language models (LLMs) capable of complex context management and multi-step reasoning. Prior multi-agent frameworks attempt to address these challenges through collaboration, yet they often suffer from rigid workflows and high reasoning recovery costs. To overcome these limitations, we propose TALM (Tree-Structured Multi-Agent Framework with Long-Term Memory), a dynamic framework that integrates structured task decomposition, localized re-reasoning, and long-term memory mechanisms. TALM employs an extensible tree-based collaboration structure. The parent-child relationships, when combined with a divide-and-conquer strategy, enhance reasoning flexibility and enable efficient error correction across diverse task scopes. Furthermore, a long-term memory module enables semantic querying and integration of prior knowledge, supporting implicit self-improvement through experience reuse. Experimental results on HumanEval, BigCodeBench, and ClassEval benchmarks demonstrate that TALM consistently delivers strong reasoning performance and high token efficiency, highlighting its robustness and practical utility in complex code generation tasks.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "339",
        "title": "LangLingual: A Personalised, Exercise-oriented English Language Learning Tool Leveraging Large Language Models",
        "author": [
            "Sammriddh Gupta",
            "Sonit Singh",
            "Aditya Joshi",
            "Mira Kim"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23011",
        "abstract": "Language educators strive to create a rich experience for learners, while they may be restricted in the extend of feedback and practice they can provide. We present the design and development of LangLingual, a conversational agent built using the LangChain framework and powered by Large Language Models. The system is specifically designed to provide real-time, grammar-focused feedback, generate context-aware language exercises and track learner proficiency over time. The paper discusses the architecture, implementation and evaluation of LangLingual in detail. The results indicate strong usability, positive learning outcomes and encouraging learner engagement.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "340",
        "title": "Softmax is $1/2$-Lipschitz: A tight bound across all $\\ell_p$ norms",
        "author": [
            "Pravin Nair"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23012",
        "abstract": "The softmax function is a basic operator in machine learning and optimization, used in classification, attention mechanisms, reinforcement learning, game theory, and problems involving log-sum-exp terms. Existing robustness guarantees of learning models and convergence analysis of optimization algorithms typically consider the softmax operator to have a Lipschitz constant of $1$ with respect to the $\\ell_2$ norm. In this work, we prove that the softmax function is contractive with the Lipschitz constant $1/2$, uniformly across all $\\ell_p$ norms with $p \\ge 1$. We also show that the local Lipschitz constant of softmax attains $1/2$ for $p = 1$ and $p = \\infty$, and for $p \\in (1,\\infty)$, the constant remains strictly below $1/2$ and the supremum $1/2$ is achieved only in the limit. To our knowledge, this is the first comprehensive norm-uniform analysis of softmax Lipschitz continuity. We demonstrate how the sharper constant directly improves a range of existing theoretical results on robustness and convergence. We further validate the sharpness of the $1/2$ Lipschitz constant of the softmax operator through empirical studies on attention-based architectures (ViT, GPT-2, Qwen3-8B) and on stochastic policies in reinforcement learning.",
        "tags": [
            "GPT",
            "RL",
            "ViT"
        ]
    },
    {
        "id": "341",
        "title": "MoEMeta: Mixture-of-Experts Meta Learning for Few-Shot Relational Learning",
        "author": [
            "Han Wu",
            "Jie Yin"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23013",
        "abstract": "Few-shot knowledge graph relational learning seeks to perform reasoning over relations given only a limited number of training examples. While existing approaches largely adopt a meta-learning framework for enabling fast adaptation to new relations, they suffer from two key pitfalls. First, they learn relation meta-knowledge in isolation, failing to capture common relational patterns shared across tasks. Second, they struggle to effectively incorporate local, task-specific contexts crucial for rapid adaptation. To address these limitations, we propose MoEMeta, a novel meta-learning framework that disentangles globally shared knowledge from task-specific contexts to enable both effective generalization and rapid adaptation. MoEMeta introduces two key innovations: (i) a mixture-of-experts (MoE) model that learns globally shared relational prototypes to enhance generalization, and (ii) a task-tailored adaptation mechanism that captures local contexts for fast task-specific adaptation. By balancing global generalization with local adaptability, MoEMeta significantly advances few-shot relational learning. Extensive experiments and analyses on three KG benchmarks demonstrate that MoEMeta consistently outperforms existing baselines, achieving state-of-the-art performance.",
        "tags": [
            "MoE"
        ]
    },
    {
        "id": "342",
        "title": "ManiDP: Manipulability-Aware Diffusion Policy for Posture-Dependent Bimanual Manipulation",
        "author": [
            "Zhuo Li",
            "Junjia Liu",
            "Dianxi Li",
            "Tao Teng",
            "Miao Li",
            "Sylvain Calinon",
            "Darwin Caldwell",
            "Fei Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23016",
        "abstract": "Recent work has demonstrated the potential of diffusion models in robot bimanual skill learning. However, existing methods ignore the learning of posture-dependent task features, which are crucial for adapting dual-arm configurations to meet specific force and velocity requirements in dexterous bimanual manipulation. To address this limitation, we propose Manipulability-Aware Diffusion Policy (ManiDP), a novel imitation learning method that not only generates plausible bimanual trajectories, but also optimizes dual-arm configurations to better satisfy posture-dependent task requirements. ManiDP achieves this by extracting bimanual manipulability from expert demonstrations and encoding the encapsulated posture features using Riemannian-based probabilistic models. These encoded posture features are then incorporated into a conditional diffusion process to guide the generation of task-compatible bimanual motion sequences. We evaluate ManiDP on six real-world bimanual tasks, where the experimental results demonstrate a 39.33$\\%$ increase in average manipulation success rate and a 0.45 improvement in task compatibility compared to baseline methods. This work highlights the importance of integrating posture-relevant robotic priors into bimanual skill diffusion to enable human-like adaptability and dexterity.",
        "tags": [
            "Diffusion",
            "Robotics"
        ]
    },
    {
        "id": "343",
        "title": "M$^{3}$T2IBench: A Large-Scale Multi-Category, Multi-Instance, Multi-Relation Text-to-Image Benchmark",
        "author": [
            "Huixuan Zhang",
            "Xiaojun Wan"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23020",
        "abstract": "Text-to-image models are known to struggle with generating images that perfectly align with textual prompts. Several previous studies have focused on evaluating image-text alignment in text-to-image generation. However, these evaluations either address overly simple scenarios, especially overlooking the difficulty of prompts with multiple different instances belonging to the same category, or they introduce metrics that do not correlate well with human evaluation. In this study, we introduce M$^3$T2IBench, a large-scale, multi-category, multi-instance, multi-relation along with an object-detection-based evaluation metric, $AlignScore$, which aligns closely with human evaluation. Our findings reveal that current open-source text-to-image models perform poorly on this challenging benchmark. Additionally, we propose the Revise-Then-Enforce approach to enhance image-text alignment. This training-free post-editing method demonstrates improvements in image-text alignment across a broad range of diffusion models. \\footnote{Our code and data has been released in supplementary material and will be made publicly available after the paper is accepted.}",
        "tags": [
            "Detection",
            "Diffusion",
            "Text-to-Image"
        ]
    },
    {
        "id": "344",
        "title": "UniAIDet: A Unified and Universal Benchmark for AI-Generated Image Content Detection and Localization",
        "author": [
            "Huixuan Zhang",
            "Xiaojun Wan"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23023",
        "abstract": "With the rapid proliferation of image generative models, the authenticity of digital images has become a significant concern. While existing studies have proposed various methods for detecting AI-generated content, current benchmarks are limited in their coverage of diverse generative models and image categories, often overlooking end-to-end image editing and artistic images. To address these limitations, we introduce UniAIDet, a unified and comprehensive benchmark that includes both photographic and artistic images. UniAIDet covers a wide range of generative models, including text-to-image, image-to-image, image inpainting, image editing, and deepfake models. Using UniAIDet, we conduct a comprehensive evaluation of various detection methods and answer three key research questions regarding generalization capability and the relation between detection and localization. Our benchmark and analysis provide a robust foundation for future research.",
        "tags": [
            "Detection",
            "Image Editing",
            "Inpainting",
            "Text-to-Image"
        ]
    },
    {
        "id": "345",
        "title": "Mixed Density Diffuser: Efficient Planning with Non-uniform Temporal Resolution",
        "author": [
            "Crimson Stambaugh",
            "Rajesh P. N. Rao"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23026",
        "abstract": "Recent studies demonstrate that diffusion planners benefit from sparse-step planning over single-step planning. Training models to skip steps in their trajectories helps capture long-term dependencies without additional or memory computational cost. However, predicting excessively sparse plans degrades performance. We hypothesize this temporal density threshold is non-uniform across a temporal horizon and that certain parts of a planned trajectory should be more densely planned. We propose Mixed Density Diffuser (MDD), a diffusion planner where the densities throughout the horizon are tunable hyperparameters. MDD achieves a new SOTA across the Maze2D, Franka Kitchen, and Antmaze D4RL task domains.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "346",
        "title": "Towards Stable and Effective Reinforcement Learning for Mixture-of-Experts",
        "author": [
            "Di Zhang",
            "Xun Wu",
            "Shaohan Huang",
            "Yaru Hao",
            "Li Dong",
            "Zewen Chi",
            "Zhifang Sui",
            "Furu Wei"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23027",
        "abstract": "Recent advances in reinforcement learning (RL) have substantially improved the training of large-scale language models, leading to significant gains in generation quality and reasoning ability. However, most existing research focuses on dense models, while RL training for Mixture-of-Experts (MoE) architectures remains underexplored. To address the instability commonly observed in MoE training, we propose a novel router-aware approach to optimize importance sampling (IS) weights in off-policy RL. Specifically, we design a rescaling strategy guided by router logits, which effectively reduces gradient variance and mitigates training divergence. Experimental results demonstrate that our method significantly improves both the convergence stability and the final performance of MoE models, highlighting the potential of RL algorithmic innovations tailored to MoE architectures and providing a promising direction for efficient training of large-scale expert models.",
        "tags": [
            "MoE",
            "RL"
        ]
    },
    {
        "id": "347",
        "title": "Nested AutoRegressive Models",
        "author": [
            "Hongyu Wu",
            "Xuhui Fan",
            "Zhangkai Wu",
            "Longbing Cao"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23028",
        "abstract": "AutoRegressive (AR) models have demonstrated competitive performance in image generation, achieving results comparable to those of diffusion models. However, their token-by-token image generation mechanism remains computationally intensive and existing solutions such as VAR often lead to limited sample diversity. In this work, we propose a Nested AutoRegressive~(NestAR) model, which proposes nested AutoRegressive architectures in generating images. NestAR designs multi-scale modules in a hierarchical order. These different scaled modules are constructed in an AR architecture, where one larger-scale module is conditioned on outputs from its previous smaller-scale module. Within each module, NestAR uses another AR structure to generate ``patches'' of tokens. The proposed nested AR architecture reduces the overall complexity from $\\mathcal{O}(n)$ to $\\mathcal{O}(\\log n)$ in generating $n$ image tokens, as well as increases image diversities. NestAR further incorporates flow matching loss to use continuous tokens, and develops objectives to coordinate these multi-scale modules in model training. NestAR achieves competitive image generation performance while significantly lowering computational cost.",
        "tags": [
            "Diffusion",
            "Flow Matching"
        ]
    },
    {
        "id": "348",
        "title": "P1GPT: a multi-agent LLM workflow module for multi-modal financial information analysis",
        "author": [
            "Chen-Che Lu",
            "Yun-Cheng Chou",
            "Teng-Ruei Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23032",
        "abstract": "Recent advances in large language models (LLMs) have enabled multi-agent reasoning systems capable of collaborative decision-making. However, in financial analysis, most frameworks remain narrowly focused on either isolated single-agent predictors or loosely connected analyst ensembles, and they lack a coherent reasoning workflow that unifies diverse data modalities. We introduce P1GPT, a layered multi-agent LLM framework for multi-modal financial information analysis and interpretable trading decision support. Unlike prior systems that emulate trading teams through role simulation, P1GPT implements a structured reasoning pipeline that systematically fuses technical, fundamental, and news-based insights through coordinated agent communication and integration-time synthesis. Backtesting on multi-modal datasets across major U.S. equities demonstrates that P1GPT achieves superior cumulative and risk-adjusted returns, maintains low drawdowns, and provides transparent causal rationales. These findings suggest that structured reasoning workflows, rather than agent role imitation, offer a scalable path toward explainable and trustworthy financial AI systems.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "349",
        "title": "Incentivizing Agentic Reasoning in LLM Judges via Tool-Integrated Reinforcement Learning",
        "author": [
            "Ran Xu",
            "Jingjing Chen",
            "Jiayu Ye",
            "Yu Wu",
            "Jun Yan",
            "Carl Yang",
            "Hongkun Yu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23038",
        "abstract": "Large Language Models (LLMs) are widely used as judges to evaluate response quality, providing a scalable alternative to human evaluation. However, most LLM judges operate solely on intrinsic text-based reasoning, limiting their ability to verify complex constraints or perform accurate computation. Motivated by the success of tool-integrated reasoning (TIR) in numerous tasks, we propose TIR-Judge, an end-to-end RL framework for training LLM judges that integrates a code executor for precise evaluation. TIR-Judge is built on three principles: (i) diverse training across verifiable and non-verifiable domains, (ii) flexible judgment formats (pointwise, pairwise, listwise), and (iii) iterative RL that bootstraps directly from the initial model without distillation. On seven public benchmarks, TIR-Judge surpasses strong reasoning-based judges by up to 6.4% (pointwise) and 7.7% (pairwise), and achieves listwise performance comparable to Claude-Opus-4 despite having only 8B parameters. Remarkably, TIR-Judge-Zero - trained entirely without distilled judge trajectories, matches the performance of distilled variants, demonstrating that tool-augmented judges can self-evolve through iterative reinforcement learning.",
        "tags": [
            "LLM",
            "RL"
        ]
    },
    {
        "id": "350",
        "title": "LLM Meets Diffusion: A Hybrid Framework for Crystal Material Generation",
        "author": [
            "Subhojyoti Khastagir",
            "Kishalay Das",
            "Pawan Goyal",
            "Seung-Cheol Lee",
            "Satadeep Bhattacharjee",
            "Niloy Ganguly"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23040",
        "abstract": "Recent advances in generative modeling have shown significant promise in designing novel periodic crystal structures. Existing approaches typically rely on either large language models (LLMs) or equivariant denoising models, each with complementary strengths: LLMs excel at handling discrete atomic types but often struggle with continuous features such as atomic positions and lattice parameters, while denoising models are effective at modeling continuous variables but encounter difficulties in generating accurate atomic compositions. To bridge this gap, we propose CrysLLMGen, a hybrid framework that integrates an LLM with a diffusion model to leverage their complementary strengths for crystal material generation. During sampling, CrysLLMGen first employs a fine-tuned LLM to produce an intermediate representation of atom types, atomic coordinates, and lattice structure. While retaining the predicted atom types, it passes the atomic coordinates and lattice structure to a pre-trained equivariant diffusion model for refinement. Our framework outperforms state-of-the-art generative models across several benchmark tasks and datasets. Specifically, CrysLLMGen not only achieves a balanced performance in terms of structural and compositional validity but also generates more stable and novel materials compared to LLM-based and denoisingbased models Furthermore, CrysLLMGen exhibits strong conditional generation capabilities, effectively producing materials that satisfy user-defined constraints. Code is available at https://github.com/kdmsit/crysllmgen",
        "tags": [
            "Diffusion",
            "LLM"
        ]
    },
    {
        "id": "351",
        "title": "HieraMamba: Video Temporal Grounding via Hierarchical Anchor-Mamba Pooling",
        "author": [
            "Joungbin An",
            "Kristen Grauman"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23043",
        "abstract": "Video temporal grounding, the task of localizing the start and end times of a natural language query in untrimmed video, requires capturing both global context and fine-grained temporal detail. This challenge is particularly pronounced in long videos, where existing methods often compromise temporal fidelity by over-downsampling or relying on fixed windows. We present HieraMamba, a hierarchical architecture that preserves temporal structure and semantic richness across scales. At its core are Anchor-MambaPooling (AMP) blocks, which utilize Mamba's selective scanning to produce compact anchor tokens that summarize video content at multiple granularities. Two complementary objectives, anchor-conditioned and segment-pooled contrastive losses, encourage anchors to retain local detail while remaining globally discriminative. HieraMamba sets a new state-of-the-art on Ego4D-NLQ, MAD, and TACoS, demonstrating precise, temporally faithful localization in long, untrimmed videos.",
        "tags": [
            "Mamba"
        ]
    },
    {
        "id": "352",
        "title": "Advantage Shaping as Surrogate Reward Maximization: Unifying Pass@K Policy Gradients",
        "author": [
            "Christos Thrampoulidis",
            "Sadegh Mahdavi",
            "Wenlong Deng"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23049",
        "abstract": "This note reconciles two seemingly distinct approaches to policy gradient optimization for the Pass@K objective in reinforcement learning with verifiable rewards: (1) direct REINFORCE-style methods, and (2) advantage-shaping techniques that directly modify GRPO. We show that these are two sides of the same coin. By reverse-engineering existing advantage-shaping algorithms, we reveal that they implicitly optimize surrogate rewards. We specifically interpret practical ``hard-example up-weighting'' modifications to GRPO as reward-level regularization. Conversely, starting from surrogate reward objectives, we provide a simple recipe for deriving both existing and new advantage-shaping methods. This perspective provides a lens for RLVR policy gradient optimization beyond our original motivation of Pass@K.",
        "tags": [
            "GRPO",
            "RL"
        ]
    },
    {
        "id": "353",
        "title": "Knocking-Heads Attention",
        "author": [
            "Zhanchao Zhou",
            "Xiaodong Chen",
            "Haoxing Chen",
            "Zhenzhong Lan",
            "Jianguo Li"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23052",
        "abstract": "Multi-head attention (MHA) has become the cornerstone of modern large language models, enhancing representational capacity through parallel attention heads. However, increasing the number of heads inherently weakens individual head capacity, and existing attention mechanisms - whether standard MHA or its variants like grouped-query attention (GQA) and grouped-tied attention (GTA) - simply concatenate outputs from isolated heads without strong interaction. To address this limitation, we propose knocking-heads attention (KHA), which enables attention heads to \"knock\" on each other - facilitating cross-head feature-level interactions before the scaled dot-product attention. This is achieved by applying a shared, diagonally-initialized projection matrix across all heads. The diagonal initialization preserves head-specific specialization at the start of training while allowing the model to progressively learn integrated cross-head representations. KHA adds only minimal parameters and FLOPs and can be seamlessly integrated into MHA, GQA, GTA, and other attention variants. We validate KHA by training a 6.1B parameter MoE model (1.01B activated) on 1T high-quality tokens. Compared to baseline attention mechanisms, KHA brings superior and more stable training dynamics, achieving better performance across downstream tasks.",
        "tags": [
            "LLM",
            "MoE"
        ]
    },
    {
        "id": "354",
        "title": "AirFed: Federated Graph-Enhanced Multi-Agent Reinforcement Learning for Multi-UAV Cooperative Mobile Edge Computing",
        "author": [
            "Zhiyu Wang",
            "Suman Raj",
            "Rajkumar Buyya"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23053",
        "abstract": "Multiple Unmanned Aerial Vehicles (UAVs) cooperative Mobile Edge Computing (MEC) systems face critical challenges in coordinating trajectory planning, task offloading, and resource allocation while ensuring Quality of Service (QoS) under dynamic and uncertain environments. Existing approaches suffer from limited scalability, slow convergence, and inefficient knowledge sharing among UAVs, particularly when handling large-scale IoT device deployments with stringent deadline constraints. This paper proposes AirFed, a novel federated graph-enhanced multi-agent reinforcement learning framework that addresses these challenges through three key innovations. First, we design dual-layer dynamic Graph Attention Networks (GATs) that explicitly model spatial-temporal dependencies among UAVs and IoT devices, capturing both service relationships and collaborative interactions within the network topology. Second, we develop a dual-Actor single-Critic architecture that jointly optimizes continuous trajectory control and discrete task offloading decisions. Third, we propose a reputation-based decentralized federated learning mechanism with gradient-sensitive adaptive quantization, enabling efficient and robust knowledge sharing across heterogeneous UAVs. Extensive experiments demonstrate that AirFed achieves 42.9% reduction in weighted cost compared to state-of-the-art baselines, attains over 99% deadline satisfaction and 94.2% IoT device coverage rate, and reduces communication overhead by 54.5%. Scalability analysis confirms robust performance across varying UAV numbers, IoT device densities, and system scales, validating AirFed's practical applicability for large-scale UAV-MEC deployments.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "355",
        "title": "From Online User Feedback to Requirements: Evaluating Large Language Models for Classification and Specification Tasks",
        "author": [
            "Manjeshwar Aniruddh Mallya",
            "Alessio Ferrari",
            "Mohammad Amin Zadenoori",
            "Jacek DÄbrowski"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23055",
        "abstract": "[Context and Motivation] Online user feedback provides valuable information to support requirements engineering (RE). However, analyzing online user feedback is challenging due to its large volume and noise. Large language models (LLMs) show strong potential to automate this process and outperform previous techniques. They can also enable new tasks, such as generating requirements specifications.\n[Question-Problem] Despite their potential, the use of LLMs to analyze user feedback for RE remains underexplored. Existing studies offer limited empirical evidence, lack thorough evaluation, and rarely provide replication packages, undermining validity and reproducibility.\n[Principal Idea-Results] We evaluate five lightweight open-source LLMs on three RE tasks: user request classification, NFR classification, and requirements specification generation. Classification performance was measured on two feedback datasets, and specification quality via human evaluation. LLMs achieved moderate-to-high classification accuracy (F1 ~ 0.47-0.68) and moderately high specification quality (mean ~ 3/5).\n[Contributions] We newly explore lightweight LLMs for feedback-driven requirements development. Our contributions are: (i) an empirical evaluation of lightweight LLMs on three RE tasks, (ii) a replication package, and (iii) insights into their capabilities and limitations for RE.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "356",
        "title": "Seq-DeepIPC: Sequential Sensing for End-to-End Control in Legged Robot Navigation",
        "author": [
            "Oskar Natan",
            "Jun Miura"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23057",
        "abstract": "We present Seq-DeepIPC, a sequential end-to-end perception-to-control model for legged robot navigation in realworld environments. Seq-DeepIPC advances intelligent sensing for autonomous legged navigation by tightly integrating multi-modal perception (RGB-D + GNSS) with temporal fusion and control. The model jointly predicts semantic segmentation and depth estimation, giving richer spatial features for planning and control. For efficient deployment on edge devices, we use EfficientNet-B0 as the encoder, reducing computation while maintaining accuracy. Heading estimation is simplified by removing the noisy IMU and instead computing the bearing angle directly from consecutive GNSS positions. We collected a larger and more diverse dataset that includes both road and grass terrains, and validated Seq-DeepIPC on a robot dog. Comparative and ablation studies show that sequential inputs improve perception and control in our models, while other baselines do not benefit. Seq-DeepIPC achieves competitive or better results with reasonable model size; although GNSS-only heading is less reliable near tall buildings, it is robust in open areas. Overall, Seq-DeepIPC extends end-to-end navigation beyond wheeled robots to more versatile and temporally-aware systems. To support future research, we will release the codes to our GitHub repository at https://github.com/oskarnatan/Seq-DeepIPC.",
        "tags": [
            "Depth Estimation",
            "Robotics",
            "Segmentation"
        ]
    },
    {
        "id": "357",
        "title": "Awakening Facial Emotional Expressions in Human-Robot",
        "author": [
            "Yongtong Zhu",
            "Lei Li",
            "Iggy Qian",
            "WenBin Zhou",
            "Ye Yuan",
            "Qingdu Li",
            "Na Liu",
            "Jianwei Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23059",
        "abstract": "The facial expression generation capability of humanoid social robots is critical for achieving natural and human-like interactions, playing a vital role in enhancing the fluidity of human-robot interactions and the accuracy of emotional expression. Currently, facial expression generation in humanoid social robots still relies on pre-programmed behavioral patterns, which are manually coded at high human and time costs. To enable humanoid robots to autonomously acquire generalized expressive capabilities, they need to develop the ability to learn human-like expressions through self-training. To address this challenge, we have designed a highly biomimetic robotic face with physical-electronic animated facial units and developed an end-to-end learning framework based on KAN (Kolmogorov-Arnold Network) and attention mechanisms. Unlike previous humanoid social robots, we have also meticulously designed an automated data collection system based on expert strategies of facial motion primitives to construct the dataset. Notably, to the best of our knowledge, this is the first open-source facial dataset for humanoid social robots. Comprehensive evaluations indicate that our approach achieves accurate and diverse facial mimicry across different test subjects.",
        "tags": [
            "KAN",
            "Robotics"
        ]
    },
    {
        "id": "358",
        "title": "Multi-Stage Field Extraction of Financial Documents with OCR and Compact Vision-Language Models",
        "author": [
            "Yichao Jin",
            "Yushuo Wang",
            "Qishuai Zhong",
            "Kent Chiu Jin-Chun",
            "Kenneth Zhu Ke",
            "Donald MacDonald"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23066",
        "abstract": "Financial documents are essential sources of information for regulators, auditors, and financial institutions, particularly for assessing the wealth and compliance of Small and Medium-sized Businesses. However, SMB documents are often difficult to parse. They are rarely born digital and instead are distributed as scanned images that are none machine readable. The scans themselves are low in resolution, affected by skew or rotation, and often contain noisy backgrounds. These documents also tend to be heterogeneous, mixing narratives, tables, figures, and multilingual content within the same report. Such characteristics pose major challenges for automated information extraction, especially when relying on end to end large Vision Language Models, which are computationally expensive, sensitive to noise, and slow when applied to files with hundreds of pages.\nWe propose a multistage pipeline that leverages traditional image processing models and OCR extraction, together with compact VLMs for structured field extraction of large-scale financial documents. Our approach begins with image pre-processing, including segmentation, orientation detection, and size normalization. Multilingual OCR is then applied to recover page-level text. Upon analyzing the text information, pages are retrieved for coherent sections. Finally, compact VLMs are operated within these narrowed-down scopes to extract structured financial indicators.\nOur approach is evaluated using an internal corpus of multi-lingual, scanned financial documents. The results demonstrate that compact VLMs, together with a multistage pipeline, achieves 8.8 times higher field level accuracy relative to directly feeding the whole document into large VLMs, only at 0.7 percent of the GPU cost and 92.6 percent less end-to-end service latency.",
        "tags": [
            "Detection",
            "Segmentation",
            "VLM"
        ]
    },
    {
        "id": "359",
        "title": "Checkstyle+: Reducing Technical Debt Through The Use of Linters with LLMs",
        "author": [
            "Ella Dodor",
            "Cristina V. Lopes"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23068",
        "abstract": "Good code style improves program readability, maintainability, and collaboration, and is an integral component of software quality. Developers, however, often cut corners when following style rules, leading to the wide adoption of tools such as linters in professional software development projects. Traditional linters like Checkstyle operate using rigid, rule-based mechanisms that effectively detect many surface-level violations. However, in most programming languages, there is a subset of style rules that require a more nuanced understanding of code, and fall outside the scope of such static analysis. In this paper, we propose Checkstyle+, a hybrid approach that augments Checkstyle with large language model (LLM) capabilities, to identify style violations that elude the conventional rule-based analysis. Checkstyle+ is evaluated on a sample of 380 Java code files, drawn from a broader dataset of 30,800 real-world Java programs sourced from accepted Codeforces submissions. The results show that Checkstyle+ achieves superior performance over standard Checkstyle in detecting violations of the semantically nuanced rules.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "360",
        "title": "Quality-Aware Translation Tagging in Multilingual RAG system",
        "author": [
            "Hoyeon Moon",
            "Byeolhee Kim",
            "Nikhil Verma"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23070",
        "abstract": "Multilingual Retrieval-Augmented Generation (mRAG) often retrieves English documents and translates them into the query language for low-resource settings. However, poor translation quality degrades response generation performance. Existing approaches either assume sufficient translation quality or utilize the rewriting method, which introduces factual distortion and hallucinations. To mitigate these problems, we propose Quality-Aware Translation Tagging in mRAG (QTT-RAG), which explicitly evaluates translation quality along three dimensions-semantic equivalence, grammatical accuracy, and naturalness&fluency-and attach these scores as metadata without altering the original content. We evaluate QTT-RAG against CrossRAG and DKM-RAG as baselines in two open-domain QA benchmarks (XORQA, MKQA) using six instruction-tuned LLMs ranging from 2.4B to 14B parameters, covering two low-resource languages (Korean and Finnish) and one high-resource language (Chinese). QTT-RAG outperforms the baselines by preserving factual integrity while enabling generator models to make informed decisions based on translation reliability. This approach allows for effective usage of cross-lingual documents in low-resource settings with limited native language documents, offering a practical and robust solution across multilingual domains.",
        "tags": [
            "LLM",
            "RAG"
        ]
    },
    {
        "id": "361",
        "title": "Fast-MIA: Efficient and Scalable Membership Inference for LLMs",
        "author": [
            "Hiromu Takahashi",
            "Shotaro Ishihara"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23074",
        "abstract": "We propose Fast-MIA (https://github.com/Nikkei/fast-mia), a Python library for efficiently evaluating membership inference attacks (MIA) against Large Language Models (LLMs). MIA against LLMs has emerged as a crucial challenge due to growing concerns over copyright, security, and data privacy, and has attracted increasing research attention. However, the progress of this research is significantly hindered by two main obstacles: (1) the high computational cost of inference in LLMs, and (2) the lack of standardized and maintained implementations of MIA methods, which makes large-scale empirical comparison difficult. To address these challenges, our library provides fast batch inference and includes implementations of representative MIA methods under a unified evaluation framework. This library supports easy implementation of reproducible benchmarks with simple configuration and extensibility. We release Fast-MIA as an open-source (Apache License 2.0) tool to support scalable and transparent research on LLMs.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "362",
        "title": "A Survey on LLM Mid-training",
        "author": [
            "Chengying Tu",
            "Xuemiao Zhang",
            "Rongxiang Weng",
            "Rumei Li",
            "Chen Zhang",
            "Yang Bai",
            "Hongfei Yan",
            "Jingang Wang",
            "Xunliang Cai"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23081",
        "abstract": "Recent advances in foundation models have highlighted the significant benefits of multi-stage training, with a particular emphasis on the emergence of mid-training as a vital stage that bridges pre-training and post-training. Mid-training is distinguished by its use of intermediate data and computational resources, systematically enhancing specified capabilities such as mathematics, coding, reasoning, and long-context extension, while maintaining foundational competencies. This survey provides a formal definition of mid-training for large language models (LLMs) and investigates optimization frameworks that encompass data curation, training strategies, and model architecture optimization. We analyze mainstream model implementations in the context of objective-driven interventions, illustrating how mid-training serves as a distinct and critical stage in the progressive development of LLM capabilities. By clarifying the unique contributions of mid-training, this survey offers a comprehensive taxonomy and actionable insights, supporting future research and innovation in the advancement of LLMs.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "363",
        "title": "Smaller Models, Smarter Rewards: A Two-Sided Approach to Process and Outcome Rewards",
        "author": [
            "Jan Niklas Groeneveld",
            "Xi Qin",
            "Alexander Schaefer",
            "Yaad Oren"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23083",
        "abstract": "Generating high-quality code remains a challenge for Large Language Models (LLMs). For the evolution of reasoning models on this task, reward models are a necessary intermediate step. These models judge outcomes or intermediate steps. Decoder-only transformer models can be turned into reward models by introducing a regression layer and supervised fine-tuning. While it is known that reflection capabilities generally increase with the size of a model, we want to investigate whether state-of-the-art small language models like the Phi-4 family can be turned into usable reward models blending the consideration of process rewards and outcome rewards.\nTargeting this goal, we construct a dataset of code samples with correctness labels derived from the APPS coding challenge benchmark. We then train a value-head model to estimate the success probability of intermediate outputs. Our evaluation shows that small LLMs are capable of serving as effective reward models or code evaluation critics, successfully identifying correct solutions among multiple candidates. Using this critic, we achieve over a 20% improvement in the search capability of the most accurate code out of multiple generations.",
        "tags": [
            "LLM",
            "Transformer"
        ]
    },
    {
        "id": "364",
        "title": "MAP4TS: A Multi-Aspect Prompting Framework for Time-Series Forecasting with Large Language Models",
        "author": [
            "Suchan Lee",
            "Jihoon Choi",
            "Sohyeon Lee",
            "Minseok Song",
            "Bong-Gyu Jang",
            "Hwanjo Yu",
            "Soyeon Caren Han"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23090",
        "abstract": "Recent advances have investigated the use of pretrained large language models (LLMs) for time-series forecasting by aligning numerical inputs with LLM embedding spaces. However, existing multimodal approaches often overlook the distinct statistical properties and temporal dependencies that are fundamental to time-series data. To bridge this gap, we propose MAP4TS, a novel Multi-Aspect Prompting Framework that explicitly incorporates classical time-series analysis into the prompt design. Our framework introduces four specialized prompt components: a Global Domain Prompt that conveys dataset-level context, a Local Domain Prompt that encodes recent trends and series-specific behaviors, and a pair of Statistical and Temporal Prompts that embed handcrafted insights derived from autocorrelation (ACF), partial autocorrelation (PACF), and Fourier analysis. Multi-Aspect Prompts are combined with raw time-series embeddings and passed through a cross-modality alignment module to produce unified representations, which are then processed by an LLM and projected for final forecasting. Extensive experiments across eight diverse datasets show that MAP4TS consistently outperforms state-of-the-art LLM-based methods. Our ablation studies further reveal that prompt-aware designs significantly enhance performance stability and that GPT-2 backbones, when paired with structured prompts, outperform larger models like LLaMA in long-term forecasting tasks.",
        "tags": [
            "GPT",
            "LLM",
            "LLaMA"
        ]
    },
    {
        "id": "365",
        "title": "Revisiting Multimodal Positional Encoding in Vision-Language Models",
        "author": [
            "Jie Huang",
            "Xuejing Liu",
            "Sibo Song",
            "Ruibing Hou",
            "Hong Chang",
            "Junyang Lin",
            "Shuai Bai"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23095",
        "abstract": "Multimodal position encoding is essential for vision-language models, yet there has been little systematic investigation into multimodal position encoding. We conduct a comprehensive analysis of multimodal Rotary Positional Embedding (RoPE) by examining its two core components: position design and frequency allocation. Through extensive experiments, we identify three key guidelines: positional coherence, full frequency utilization, and preservation of textual priors-ensuring unambiguous layout, rich representation, and faithful transfer from the pre-trained LLM. Based on these insights, we propose Multi-Head RoPE (MHRoPE) and MRoPE-Interleave (MRoPE-I), two simple and plug-and-play variants that require no architectural changes. Our methods consistently outperform existing approaches across diverse benchmarks, with significant improvements in both general and fine-grained multimodal understanding. Code will be avaliable at https://github.com/JJJYmmm/Multimodal-RoPEs.",
        "tags": [
            "LLM",
            "RoPE",
            "VLM"
        ]
    },
    {
        "id": "366",
        "title": "Beyond Imprecise Distance Metrics: LLM-Predicted Target Call Stacks for Directed Greybox Fuzzing",
        "author": [
            "Yifan Zhang",
            "Xin Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23101",
        "abstract": "Directed greybox fuzzing (DGF) aims to efficiently trigger bugs at specific target locations by prioritizing seeds whose execution paths are more likely to mutate into triggering target bugs. However, existing DGF approaches suffer from imprecise probability calculations due to their reliance on complex distance metrics derived from static analysis. The over-approximations inherent in static analysis cause a large number of irrelevant execution paths to be mistakenly considered to potentially mutate into triggering target bugs, significantly reducing fuzzing efficiency. We propose to replace static analysis-based distance metrics with precise call stack representations. Call stacks represent precise control flows, thereby avoiding false information in static analysis. We leverage large language models (LLMs) to predict vulnerability-triggering call stacks for guiding seed prioritization. Our approach constructs call graphs through static analysis to identify methods that can potentially reach target locations, then utilizes LLMs to predict the most likely call stack sequence that triggers the vulnerability. Seeds whose execution paths have higher overlap with the predicted call stack are prioritized for mutation. This is the first work to integrate LLMs into the core seed prioritization mechanism of DGF. We implement our approach and evaluate it against several state-of-the-art fuzzers. On a suite of real-world programs, our approach triggers vulnerabilities $1.86\\times$ to $3.09\\times$ faster compared to baselines. In addition, our approach identifies 10 new vulnerabilities and 2 incomplete fixes in the latest versions of programs used in our controlled experiments through directed patch testing, with 10 assigned CVE IDs.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "367",
        "title": "Sampling from Energy distributions with Target Concrete Score Identity",
        "author": [
            "Sergei Kholkin",
            "Francisco Vargas",
            "Alexander Korotin"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23106",
        "abstract": "We introduce the Target Concrete Score Identity Sampler (TCSIS), a method for sampling from unnormalized densities on discrete state spaces by learning the reverse dynamics of a Continuous-Time Markov Chain (CTMC). Our approach builds on a forward in time CTMC with a uniform noising kernel and relies on the proposed Target Concrete Score Identity, which relates the concrete score, the ratio of marginal probabilities of two states, to a ratio of expectations of Boltzmann factors under the forward uniform diffusion kernel. This formulation enables Monte Carlo estimation of the concrete score without requiring samples from the target distribution or computation of the partition function. We approximate the concrete score with a neural network and propose two algorithms: Self-Normalized TCSIS and Unbiased TCSIS. Finally, we demonstrate the effectiveness of TCSIS on problems from statistical physics.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "368",
        "title": "An Automated Tape Laying System Employing a Uniaxial Force Control Device",
        "author": [
            "Bernhard Rameder",
            "Hubert Gattringer",
            "Ronald Naderer",
            "Andreas Mueller"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23109",
        "abstract": "This paper deals with the design of a cost effective automated tape laying system (ATL system) with integrated uniaxial force control to ensure the necessary compaction forces as well as with an accurate temperature control to guarantee the used tape being melted appropriate. It is crucial to control the substrate and the oncoming tape onto a specific temperature level to ensure an optimal consolidation between the different layers of the product. Therefore, it takes several process steps from the spooled tape on the coil until it is finally tacked onto the desired mold. The different modules are divided into the tape storage spool, a tape-guiding roller, a tape processing unit, a heating zone and the consolidation unit. Moreover, a special robot control concept for testing the ATL system is presented. In contrast to many other systems, with this approach, the tape laying device is spatially fixed and the shape is moved accordingly by the robot, which allows for handling of rather compact and complex shapes. The functionality of the subsystems and the taping process itself was finally approved in experimental results using a carbon fiber reinforced HDPE tape.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "369",
        "title": "Residual Diffusion Bridge Model for Image Restoration",
        "author": [
            "Hebaixu Wang",
            "Jing Zhang",
            "Haoyang Chen",
            "Haonan Guo",
            "Di Wang",
            "Jiayi Ma",
            "Bo Du"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23116",
        "abstract": "Diffusion bridge models establish probabilistic paths between arbitrary paired distributions and exhibit great potential for universal image restoration. Most existing methods merely treat them as simple variants of stochastic interpolants, lacking a unified analytical perspective. Besides, they indiscriminately reconstruct images through global noise injection and removal, inevitably distorting undegraded regions due to imperfect reconstruction. To address these challenges, we propose the Residual Diffusion Bridge Model (RDBM). Specifically, we theoretically reformulate the stochastic differential equations of generalized diffusion bridge and derive the analytical formulas of its forward and reverse processes. Crucially, we leverage the residuals from given distributions to modulate the noise injection and removal, enabling adaptive restoration of degraded regions while preserving intact others. Moreover, we unravel the fundamental mathematical essence of existing bridge models, all of which are special cases of RDBM and empirically demonstrate the optimality of our proposed models. Extensive experiments are conducted to demonstrate the state-of-the-art performance of our method both qualitatively and quantitatively across diverse image restoration tasks. Code is publicly available at https://github.com/MiliLab/RDBM.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "370",
        "title": "OmniDexGrasp: Generalizable Dexterous Grasping via Foundation Model and Force Feedback",
        "author": [
            "Yi-Lin Wei",
            "Zhexi Luo",
            "Yuhao Lin",
            "Mu Lin",
            "Zhizhao Liang",
            "Shuoyu Chen",
            "Wei-Shi Zheng"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23119",
        "abstract": "Enabling robots to dexterously grasp and manipulate objects based on human commands is a promising direction in robotics. However, existing approaches are challenging to generalize across diverse objects or tasks due to the limited scale of semantic dexterous grasp datasets. Foundation models offer a new way to enhance generalization, yet directly leveraging them to generate feasible robotic actions remains challenging due to the gap between abstract model knowledge and physical robot execution. To address these challenges, we propose OmniDexGrasp, a generalizable framework that achieves omni-capabilities in user prompting, dexterous embodiment, and grasping tasks by combining foundation models with the transfer and control strategies. OmniDexGrasp integrates three key modules: (i) foundation models are used to enhance generalization by generating human grasp images supporting omni-capability of user prompt and task; (ii) a human-image-to-robot-action transfer strategy converts human demonstrations into executable robot actions, enabling omni dexterous embodiment; (iii) force-aware adaptive grasp strategy ensures robust and stable grasp execution. Experiments in simulation and on real robots validate the effectiveness of OmniDexGrasp on diverse user prompts, grasp task and dexterous hands, and further results show its extensibility to dexterous manipulation tasks.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "371",
        "title": "Beyond Higher Rank: Token-wise Input-Output Projections for Efficient Low-Rank Adaptation",
        "author": [
            "Shiwei Li",
            "Xiandi Luo",
            "Haozhao Wang",
            "Xing Tang",
            "Ziqiang Cui",
            "Dugang Liu",
            "Yuhua Li",
            "Xiuqiang He",
            "Ruixuan Li"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23123",
        "abstract": "Low-rank adaptation (LoRA) is a parameter-efficient fine-tuning (PEFT) method widely used in large language models (LLMs). LoRA essentially describes the projection of an input space into a low-dimensional output space, with the dimensionality determined by the LoRA rank. In standard LoRA, all input tokens share the same weights and undergo an identical input-output projection. This limits LoRA's ability to capture token-specific information due to the inherent semantic differences among tokens. To address this limitation, we propose Token-wise Projected Low-Rank Adaptation (TopLoRA), which dynamically adjusts LoRA weights according to the input token, thereby learning token-wise input-output projections in an end-to-end manner. Formally, the weights of TopLoRA can be expressed as $B\\Sigma_X A$, where $A$ and $B$ are low-rank matrices (as in standard LoRA), and $\\Sigma_X$ is a diagonal matrix generated from each input token $X$. Notably, TopLoRA does not increase the rank of LoRA weights but achieves more granular adaptation by learning token-wise LoRA weights (i.e., token-wise input-output projections). Extensive experiments across multiple models and datasets demonstrate that TopLoRA consistently outperforms LoRA and its variants. The code is available at https://github.com/Leopold1423/toplora-neurips25.",
        "tags": [
            "LLM",
            "LoRA"
        ]
    },
    {
        "id": "372",
        "title": "Lost in Tokenization: Context as the Key to Unlocking Biomolecular Understanding in Scientific LLMs",
        "author": [
            "Kai Zhuang",
            "Jiawei Zhang",
            "Yumou Liu",
            "Hanqun Cao",
            "Chunbin Gu",
            "Mengdi Liu",
            "Zhangyang Gao",
            "Zitong Jerry Wang",
            "Xuanhe Zhou",
            "Pheng-Ann Heng",
            "Lijun Wu",
            "Conghui He",
            "Cheng Tan"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23127",
        "abstract": "Scientific Large Language Models (Sci-LLMs) have emerged as a promising frontier for accelerating biological discovery. However, these models face a fundamental challenge when processing raw biomolecular sequences: the tokenization dilemma. Whether treating sequences as a specialized language, risking the loss of functional motif information, or as a separate modality, introducing formidable alignment challenges, current strategies fundamentally limit their reasoning capacity. We challenge this sequence-centric paradigm by positing that a more effective strategy is to provide Sci-LLMs with high-level structured context derived from established bioinformatics tools, thereby bypassing the need to interpret low-level noisy sequence data directly. Through a systematic comparison of leading Sci-LLMs on biological reasoning tasks, we tested three input modes: sequence-only, context-only, and a combination of both. Our findings are striking: the context-only approach consistently and substantially outperforms all other modes. Even more revealing, the inclusion of the raw sequence alongside its high-level context consistently degrades performance, indicating that raw sequences act as informational noise, even for models with specialized tokenization schemes. These results suggest that the primary strength of existing Sci-LLMs lies not in their nascent ability to interpret biomolecular syntax from scratch, but in their profound capacity for reasoning over structured, human-readable knowledge. Therefore, we argue for reframing Sci-LLMs not as sequence decoders, but as powerful reasoning engines over expert knowledge. This work lays the foundation for a new class of hybrid scientific AI agents, repositioning the developmental focus from direct sequence interpretation towards high-level knowledge synthesis. The code is available at http://github.com/opendatalab-raise-dev/CoKE.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "373",
        "title": "Combining High Level Scheduling and Low Level Control to Manage Fleets of Mobile Robots",
        "author": [
            "Sabino Francesco Roselli",
            "Ze Zhang",
            "Knut Ãkesson"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23129",
        "abstract": "The deployment of mobile robots for material handling in industrial environments requires scalable coordination of large fleets in dynamic settings. This paper presents a two-layer framework that combines high-level scheduling with low-level control. Tasks are assigned and scheduled using the compositional algorithm ComSat, which generates time-parameterized routes for each robot. These schedules are then used by a distributed Model Predictive Control (MPC) system in real time to compute local reference trajectories, accounting for static and dynamic obstacles. The approach ensures safe, collision-free operation, and supports rapid rescheduling in response to disruptions such as robot failures or environmental changes. We evaluate the method in simulated 2D environments with varying road capacities and traffic conditions, demonstrating high task completion rates and robust behavior even under congestion. The modular structure of the framework allows for computational tractability and flexibility, making it suitable for deployment in complex, real-world industrial scenarios.",
        "tags": [
            "MPC",
            "Robotics"
        ]
    },
    {
        "id": "374",
        "title": "Rethinking GSPO: The Perplexity-Entropy Equivalence",
        "author": [
            "Chi Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23142",
        "abstract": "We provide a new perspective on GSPO's length-normalized importance ratios by establishing their connection to information-theoretic quantities. We show that GSPO's sequence-level weight $s(\\theta) = (\\pi_\\theta/\\pi_{\\theta_{\\text{old}}})^{1/|y|}$ can be equivalently expressed as the inverse perplexity ratio $\\text{PPL}_{\\theta_{\\text{old}}}/\\text{PPL}_\\theta$ and as the exponential cross-entropy change $\\exp(\\Delta H)$. While the perplexity-entropy relationship follows from standard definitions, this observation provides a useful lens for understanding GSPO: the algorithm weights policy gradient updates by perplexity ratios, offering an information-theoretic interpretation of the importance weights. This perspective helps explain GSPO's empirical properties, including log-domain variance reduction through geometric averaging and stability in training mixture-of-experts models. We validate the mathematical equivalences and variance predictions through controlled experiments on mathematical reasoning tasks.",
        "tags": [
            "MoE"
        ]
    },
    {
        "id": "375",
        "title": "DQ3D: Depth-guided Query for Transformer-Based 3D Object Detection in Traffic Scenarios",
        "author": [
            "Ziyu Wang",
            "Wenhao Li",
            "Ji Wu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23144",
        "abstract": "3D object detection from multi-view images in traffic scenarios has garnered significant attention in recent years. Many existing approaches rely on object queries that are generated from 3D reference points to localize objects. However, a limitation of these methods is that some reference points are often far from the target object, which can lead to false positive detections. In this paper, we propose a depth-guided query generator for 3D object detection (DQ3D) that leverages depth information and 2D detections to ensure that reference points are sampled from the surface or interior of the object. Furthermore, to address partially occluded objects in current frame, we introduce a hybrid attention mechanism that fuses historical detection results with depth-guided queries, thereby forming hybrid queries. Evaluation on the nuScenes dataset demonstrates that our method outperforms the baseline by 6.3\\% in terms of mean Average Precision (mAP) and 4.3\\% in the NuScenes Detection Score (NDS).",
        "tags": [
            "3D",
            "Detection",
            "Transformer"
        ]
    },
    {
        "id": "376",
        "title": "Adapting Interleaved Encoders with PPO for Language-Guided Reinforcement Learning in BabyAI",
        "author": [
            "Aryan Mathur",
            "Asaduddin Ahmed"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23148",
        "abstract": "Deep reinforcement learning agents often struggle when tasks require understanding both vision and language. Conventional architectures typically isolate perception (for example, CNN-based visual encoders) from decision-making (policy networks). This separation can be inefficient, since the policy's failures do not directly help the perception module learn what is important. To address this, we implement the Perception-Decision Interleaving Transformer (PDiT) architecture introduced by Mao et al. (2023), a model that alternates between perception and decision layers within a single transformer. This interleaving allows feedback from decision-making to refine perceptual features dynamically. In addition, we integrate a contrastive loss inspired by CLIP to align textual mission embeddings with visual scene features. We evaluate the PDiT encoders on the BabyAI GoToLocal environment and find that the approach achieves more stable rewards and stronger alignment compared to a standard PPO baseline. The results suggest that interleaved transformer encoders are a promising direction for developing more integrated autonomous agents.",
        "tags": [
            "CLIP",
            "PPO",
            "RL",
            "Transformer"
        ]
    },
    {
        "id": "377",
        "title": "Exploring LR-FHSS Modulation for Enhanced IoT Connectivity: A Measurement Campaign",
        "author": [
            "Alexis Delplace",
            "Samer Lahoud",
            "Kinda Khawam"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23152",
        "abstract": "This paper presents the first comprehensive real-world measurement campaign comparing LR-FHSS and LoRa modulations within LoRaWAN networks in urban environments. Conducted in Halifax, Canada, the campaign used a LoRaWAN platform capable of operating both modulations in the FCC-regulated US915 band. Real-world measurements are crucial for capturing the effects of urban topology and signal propagation challenges, which are difficult to fully replicate in simulations. Results show that LR-FHSS can achieve up to a 20% improvement in Packet Reception Rate (PRR) over traditional LoRa in dense urban areas. Additionally, the study investigated path loss and Received Signal Strength Indicator (RSSI), finding that LR-FHSS achieved a minimum RSSI of -138 dBm compared to LoRa's -120 dBm. The findings demonstrate that the introduction of LR-FHSS enhances communication robustness and reliability under regulatory limitations and suggest promising applications in LoRaWAN networks.",
        "tags": [
            "LoRA"
        ]
    },
    {
        "id": "378",
        "title": "ENTP: Enhancing Low-Quality SFT Data via Neural-Symbolic Text Purge-Mix",
        "author": [
            "Zile Yang",
            "Ling Li",
            "Na Di",
            "Jinlong Pang",
            "Yao Zhou",
            "Hao Cheng",
            "Bo Han",
            "Jiaheng Wei"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23160",
        "abstract": "Supervised Fine-Tuning (SFT) adapts pre-trained Large Language Models (LLMs) to domain-specific instructions by training on a carefully curated subset of high-quality instruction-response pairs, typically drawn from a larger dataset that often contains many low-quality or noisy samples. However, existing quality-first paradigms often overlook valuable signals in discarded low-quality data and rely on imperfect quality filters. We introduce ENTP (Enhancing low-quality SFT data via Neural-symbolic Text Purge-Mix), a framework that revitalizes low-quality corpora through symbolic purification and neural reconstruction. The symbolic module identifies and prunes noisy samples based on statistical priors, while the neural component synthesizes enriched instruction-response pairs by leveraging latent representations and model knowledge. This neural-symbolic synergy enhances data informativeness and diversity. Experiments show that ENTP-augmented datasets, constructed exclusively from low-quality data, outperform 13 established data-selection baselines across five instruction-following benchmarks, and even surpass fine-tuning on the full original dataset (approximately 300K examples). Our results highlight the untapped potential of low-quality data and underscore the importance of intelligent purification and synthesis for efficient instruction alignment.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "379",
        "title": "Beyond Direct Generation: A Decomposed Approach to Well-Crafted Screenwriting with LLMs",
        "author": [
            "Hang Lei",
            "Shengyi Zong",
            "Zhaoyan Li",
            "Ziren Zhou",
            "Hao Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23163",
        "abstract": "The screenplay serves as the foundation for television production, defining narrative structure, character development, and dialogue. While Large Language Models (LLMs) show great potential in creative writing, direct end-to-end generation approaches often fail to produce well-crafted screenplays. We argue this failure stems from forcing a single model to simultaneously master two disparate capabilities: creative narrative construction and rigid format adherence. The resulting outputs may mimic superficial style but lack the deep structural integrity and storytelling substance required for professional use. To enable LLMs to generate high-quality screenplays, we introduce Dual-Stage Refinement (DSR), a decomposed framework that decouples creative narrative generation from format conversion. The first stage transforms a brief outline into rich, novel-style prose. The second stage refines this narrative into a professionally formatted screenplay. This separation enables the model to specialize in one distinct capability at each stage. A key challenge in implementing DSR is the scarcity of paired outline-to-novel training data. We address this through hybrid data synthesis: reverse synthesis deconstructs existing screenplays into structured inputs, while forward synthesis leverages these inputs to generate high-quality narrative texts as training targets. Blind evaluations by professional screenwriters show that DSR achieves a 75% win rate against strong baselines like Gemini-2.5-Pro and reaches 82.7% of human-level performance. Our work demonstrates that decomposed generation architecture with tailored data synthesis effectively specializes LLMs in complex creative domains.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "380",
        "title": "Guiding Skill Discovery with Foundation Models",
        "author": [
            "Zhao Yang",
            "Thomas M. Moerland",
            "Mike Preuss",
            "Aske Plaat",
            "Vincent FranÃ§ois-Lavet",
            "Edward S. Hu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23167",
        "abstract": "Learning diverse skills without hand-crafted reward functions could accelerate reinforcement learning in downstream tasks. However, existing skill discovery methods focus solely on maximizing the diversity of skills without considering human preferences, which leads to undesirable behaviors and possibly dangerous skills. For instance, a cheetah robot trained using previous methods learns to roll in all directions to maximize skill diversity, whereas we would prefer it to run without flipping or entering hazardous areas. In this work, we propose a Foundation model Guided (FoG) skill discovery method, which incorporates human intentions into skill discovery through foundation models. Specifically, FoG extracts a score function from foundation models to evaluate states based on human intentions, assigning higher values to desirable states and lower to undesirable ones. These scores are then used to re-weight the rewards of skill discovery algorithms. By optimizing the re-weighted skill discovery rewards, FoG successfully learns to eliminate undesirable behaviors, such as flipping or rolling, and to avoid hazardous areas in both state-based and pixel-based tasks. Interestingly, we show that FoG can discover skills involving behaviors that are difficult to define. Interactive visualisations are available from https://sites.google.com/view/submission-fog.",
        "tags": [
            "RL",
            "Robotics"
        ]
    },
    {
        "id": "381",
        "title": "TARC: Time-Adaptive Robotic Control",
        "author": [
            "Arnav Sukhija",
            "Lenart Treven",
            "Jin Cheng",
            "Florian DÃ¶rfler",
            "Stelian Coros",
            "Andreas Krause"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23176",
        "abstract": "Fixed-frequency control in robotics imposes a trade-off between the efficiency of low-frequency control and the robustness of high-frequency control, a limitation not seen in adaptable biological systems. We address this with a reinforcement learning approach in which policies jointly select control actions and their application durations, enabling robots to autonomously modulate their control frequency in response to situational demands. We validate our method with zero-shot sim-to-real experiments on two distinct hardware platforms: a high-speed RC car and a quadrupedal robot. Our method matches or outperforms fixed-frequency baselines in terms of rewards while significantly reducing the control frequency and exhibiting adaptive frequency control under real-world conditions.",
        "tags": [
            "RL",
            "Robotics"
        ]
    },
    {
        "id": "382",
        "title": "SI-Bench: Benchmarking Social Intelligence of Large Language Models in Human-to-Human Conversations",
        "author": [
            "Shuai Huang",
            "Wenxuan Zhao",
            "Jun Gao"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23182",
        "abstract": "As large language models (LLMs) develop anthropomorphic abilities, they are increasingly being deployed as autonomous agents to interact with humans. However, evaluating their performance in realistic and complex social interactions remains a significant challenge. Most previous research built datasets through simulated agent-to-agent interactions, which fails to capture the authentic linguistic styles and relational dynamics found in real human conversations. To address this gap, we introduce SI-Bench, a novel benchmark designed to evaluate aspects of social intelligence in LLMs. Grounded in broad social science theories, SI-Bench contains 2,221 authentic multi-turn dialogues collected from a social networking application. We further selected a subset of 312 dialogues for manual annotation across 8 major models. The experiments show that SOTA models have surpassed the human expert in process reasoning under complex social situations, yet they still fall behind humans in reply quality. Moreover, introducing Chain-of-Thought (CoT) reasoning may degrade the performance of LLMs in social dialogue tasks. All datasets are openly available at https://github.com/SI-Bench/SI-Bench.git.",
        "tags": [
            "CoT",
            "LLM"
        ]
    },
    {
        "id": "383",
        "title": "Evaluation of Vision-LLMs in Surveillance Video",
        "author": [
            "Pascal Benschop",
            "Cristian Meo",
            "Justin Dauwels",
            "Jelte P. Mense"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23190",
        "abstract": "The widespread use of cameras in our society has created an overwhelming amount of video data, far exceeding the capacity for human monitoring. This presents a critical challenge for public safety and security, as the timely detection of anomalous or criminal events is crucial for effective response and prevention. The ability for an embodied agent to recognize unexpected events is fundamentally tied to its capacity for spatial reasoning. This paper investigates the spatial reasoning of vision-language models (VLMs) by framing anomalous action recognition as a zero-shot, language-grounded task, addressing the embodied perception challenge of interpreting dynamic 3D scenes from sparse 2D video. Specifically, we investigate whether small, pre-trained vision--LLMs can act as spatially-grounded, zero-shot anomaly detectors by converting video into text descriptions and scoring labels via textual entailment. We evaluate four open models on UCF-Crime and RWF-2000 under prompting and privacy-preserving conditions. Few-shot exemplars can improve accuracy for some models, but may increase false positives, and privacy filters -- especially full-body GAN transforms -- introduce inconsistencies that degrade accuracy. These results chart where current vision--LLMs succeed (simple, spatially salient events) and where they falter (noisy spatial cues, identity obfuscation). Looking forward, we outline concrete paths to strengthen spatial grounding without task-specific training: structure-aware prompts, lightweight spatial memory across clips, scene-graph or 3D-pose priors during description, and privacy methods that preserve action-relevant geometry. This positions zero-shot, language-grounded pipelines as adaptable building blocks for embodied, real-world video understanding. Our implementation for evaluating VLMs is publicly available at: https://github.com/pascalbenschopTU/VLLM_AnomalyRecognition",
        "tags": [
            "3D",
            "Detection",
            "GAN",
            "LLM",
            "VLM"
        ]
    },
    {
        "id": "384",
        "title": "DecoDINO: 3D Human-Scene Contact Prediction with Semantic Classification",
        "author": [
            "Lukas Bierling",
            "Davide Pasero",
            "Fleur Dolmans",
            "Helia Ghasemi",
            "Angelo Broere"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23203",
        "abstract": "Accurate vertex-level contact prediction between humans and surrounding objects is a prerequisite for high fidelity human object interaction models used in robotics, AR/VR, and behavioral simulation. DECO was the first in the wild estimator for this task but is limited to binary contact maps and struggles with soft surfaces, occlusions, children, and false-positive foot contacts. We address these issues and introduce DecoDINO, a three-branch network based on DECO's framework. It uses two DINOv2 ViT-g/14 encoders, class-balanced loss weighting to reduce bias, and patch-level cross-attention for improved local reasoning. Vertex features are finally passed through a lightweight MLP with a softmax to assign semantic contact labels. We also tested a vision-language model (VLM) to integrate text features, but the simpler architecture performed better and was used instead. On the DAMON benchmark, DecoDINO (i) raises the binary-contact F1 score by 7$\\%$, (ii) halves the geodesic error, and (iii) augments predictions with object-level semantic labels. Ablation studies show that LoRA fine-tuning and the dual encoders are key to these improvements. DecoDINO outperformed the challenge baseline in both tasks of the DAMON Challenge. Our code is available at https://github.com/DavidePasero/deco/tree/main.",
        "tags": [
            "3D",
            "LoRA",
            "Robotics",
            "VLM",
            "ViT"
        ]
    },
    {
        "id": "385",
        "title": "If They Disagree, Will You Conform? Exploring the Role of Robots' Value Awareness in a Decision-Making Task",
        "author": [
            "Giulia Pusceddu",
            "Giulio Antonio Abbo",
            "Francesco Rea",
            "Tony Belpaeme",
            "Alessandra Sciutti"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23204",
        "abstract": "This study investigates whether the opinions of robotic agents are more likely to influence human decision-making when the robots are perceived as value-aware (i.e., when they display an understanding of human principles). We designed an experiment in which participants interacted with two Furhat robots - one programmed to be Value-Aware and the other Non-Value-Aware - during a labeling task for images representing human values. Results indicate that participants distinguished the Value-Aware robot from the Non-Value-Aware one. Although their explicit choices did not indicate a clear preference for one robot over the other, participants directed their gaze more toward the Value-Aware robot. Additionally, the Value-Aware robot was perceived as more loyal, suggesting that value awareness in a social robot may enhance its perceived commitment to the group. Finally, when both robots disagreed with the participant, conformity occurred in about one out of four trials, and participants took longer to confirm their responses, suggesting that two robots expressing dissent may introduce hesitation in decision-making. On one hand, this highlights the potential risk that robots, if misused, could manipulate users for unethical purposes. On the other hand, it reinforces the idea that social robots might encourage reflection in ambiguous situations and help users avoid scams.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "386",
        "title": "VR-Drive: Viewpoint-Robust End-to-End Driving with Feed-Forward 3D Gaussian Splatting",
        "author": [
            "Hoonhee Cho",
            "Jae-Young Kang",
            "Giwon Lee",
            "Hyemin Yang",
            "Heejun Park",
            "Seokwoo Jung",
            "Kuk-Jin Yoon"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23205",
        "abstract": "End-to-end autonomous driving (E2E-AD) has emerged as a promising paradigm that unifies perception, prediction, and planning into a holistic, data-driven framework. However, achieving robustness to varying camera viewpoints, a common real-world challenge due to diverse vehicle configurations, remains an open problem. In this work, we propose VR-Drive, a novel E2E-AD framework that addresses viewpoint generalization by jointly learning 3D scene reconstruction as an auxiliary task to enable planning-aware view synthesis. Unlike prior scene-specific synthesis approaches, VR-Drive adopts a feed-forward inference strategy that supports online training-time augmentation from sparse views without additional annotations. To further improve viewpoint consistency, we introduce a viewpoint-mixed memory bank that facilitates temporal interaction across multiple viewpoints and a viewpoint-consistent distillation strategy that transfers knowledge from original to synthesized views. Trained in a fully end-to-end manner, VR-Drive effectively mitigates synthesis-induced noise and improves planning under viewpoint shifts. In addition, we release a new benchmark dataset to evaluate E2E-AD performance under novel camera viewpoints, enabling comprehensive analysis. Our results demonstrate that VR-Drive is a scalable and robust solution for the real-world deployment of end-to-end autonomous driving systems.",
        "tags": [
            "3D",
            "Gaussian Splatting"
        ]
    },
    {
        "id": "387",
        "title": "Increasing LLM Coding Capabilities through Diverse Synthetic Coding Tasks",
        "author": [
            "Amal Abed",
            "Ivan Lukic",
            "JÃ¶rg K.H. Franke",
            "Frank Hutter"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23208",
        "abstract": "Large language models (LLMs) have shown impressive promise in code generation, yet their progress remains limited by the shortage of large-scale datasets that are both diverse and well-aligned with human reasoning. Most existing resources pair problems with solutions, but omit the intermediate thought process that guides coding. To close this gap, we present a scalable synthetic data generation pipeline that produces nearly 800k instruction-reasoning-code-test quadruplets. Each sample combines a task, a step-by-step reasoning trace, a working solution, and executable tests, enabling models to learn not just the what but also the how of problem solving. Our pipeline combines four key components: curated contest problems, web-mined content filtered by relevance classifiers, data expansion guided by reasoning patterns, and multi-stage execution-based validation. A genetic mutation algorithm further increases task diversity while maintaining consistency between reasoning traces and code implementations. Our key finding is that fine-tuning LLMs on this dataset yields consistent improvements on coding benchmarks. Beyond raw accuracy, reasoning-aware data can substitute for model scaling, generalize across architectures, and outperform leading open-source alternatives under identical sample budgets. Our work establishes reasoning-centered synthetic data generation as an efficient approach for advancing coding capabilities in LLMs. We publish our dataset and generation pipeline to facilitate further research.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "388",
        "title": "Human-Like Goalkeeping in a Realistic Football Simulation: a Sample-Efficient Reinforcement Learning Approach",
        "author": [
            "Alessandro Sestini",
            "Joakim Bergdahl",
            "Jean-Philippe Barrette-LaPierre",
            "Florian Fuchs",
            "Brady Chen",
            "Micheal Jones",
            "Linus GisslÃ©n"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23216",
        "abstract": "While several high profile video games have served as testbeds for Deep Reinforcement Learning (DRL), this technique has rarely been employed by the game industry for crafting authentic AI behaviors. Previous research focuses on training super-human agents with large models, which is impractical for game studios with limited resources aiming for human-like agents. This paper proposes a sample-efficient DRL method tailored for training and fine-tuning agents in industrial settings such as the video game industry. Our method improves sample efficiency of value-based DRL by leveraging pre-collected data and increasing network plasticity. We evaluate our method training a goalkeeper agent in EA SPORTS FC 25, one of the best-selling football simulations today. Our agent outperforms the game's built-in AI by 10% in ball saving rate. Ablation studies show that our method trains agents 50% faster compared to standard DRL methods. Finally, qualitative evaluation from domain experts indicates that our approach creates more human-like gameplay compared to hand-crafted agents. As a testimony of the impact of the approach, the method is intended to replace the hand-crafted counterpart in next iterations of the series.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "389",
        "title": "Process Reward Models for Sentence-Level Verification of LVLM Radiology Reports",
        "author": [
            "Alois Thomas",
            "Maya Varma",
            "Jean-Benoit Delbrouck",
            "Curtis P. Langlotz"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23217",
        "abstract": "Automating radiology report generation with Large Vision-Language Models (LVLMs) holds great potential, yet these models often produce clinically critical hallucinations, posing serious risks. Existing hallucination detection methods frequently lack the necessary sentence-level granularity or robust generalization across different LVLM generators. We introduce a novel approach: a sentence-level Process Reward Model (PRM) adapted for this vision-language task. Our PRM predicts the factual correctness of each generated sentence, conditioned on clinical context and preceding text. When fine-tuned on MIMIC-CXR with weakly-supervised labels, a lightweight 0.5B-parameter PRM outperforms existing verification techniques, demonstrating, for instance, relative improvements of 7.5% in Matthews Correlation Coefficient and 1.8% in AUROC over strong white-box baselines on outputs from one LVLM. Unlike methods reliant on internal model states, our PRM demonstrates strong generalization to an unseen LVLM. We further show its practical utility: PRM scores effectively filter low-quality reports, improving F1-CheXbert scores by 4.5% (when discarding the worst 10% of reports). Moreover, when guiding a novel weighted best-of-N selection process on the MIMIC-CXR test set, our PRM show relative improvements in clinical metrics of 7.4% for F1-CheXbert and 0.6% for BERTScore. These results demonstrate that a lightweight, context-aware PRM provides a model-agnostic safety layer for clinical LVLMs without access to internal activations",
        "tags": [
            "Detection",
            "VLM"
        ]
    },
    {
        "id": "390",
        "title": "Workspace Registration and Collision Detection for Industrial Robotics Applications",
        "author": [
            "Klaus Zauner",
            "Josef El Dib",
            "Hubert Gattringer",
            "Andreas Mueller"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23227",
        "abstract": "Motion planning for robotic manipulators relies on precise knowledge of the environment in order to be able to define restricted areas and to take collision objects into account. To capture the workspace, point clouds of the environment are acquired using various sensors. The collision objects are identified by region growing segmentation and VCCS algorithm. Subsequently the point clusters are approximated. The aim of the present paper is to compare different sensors, to illustrate the process from detection to the finished collision environment and to detect collisions between the robot and this environment.",
        "tags": [
            "Detection",
            "Robotics",
            "Segmentation"
        ]
    },
    {
        "id": "391",
        "title": "Optimal Dimensioning of Elastic-Link Manipulators regarding Lifetime Estimation",
        "author": [
            "Klaus Zauner",
            "Hubert Gattringer",
            "Andreas Mueller"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23234",
        "abstract": "Resourceful operation and design of robots is key for sustainable industrial automation. This will be enabled by lightweight design along with time and energy optimal control of robotic manipulators. Design and control of such systems is intertwined as the control must take into account inherent mechanical compliance while the design must accommodate the dynamic requirements demanded by the control. As basis for such design optimization, a method for estimating the lifetime of elastic link robotic manipulators is presented. This is applied to the geometry optimization of flexible serial manipulators performing pick-and-place operations, where the optimization objective is a combination of overall weight and vibration amplitudes. The lifetime estimation draws from a fatigue analysis combining the rainflow counting algorithm and the method of critical cutting plane. Tresca hypothesis is used to formulate an equivalent stress, and linear damage accumulation is assumed. The final robot geometry is selected from a Pareto front as a tradeoff of lifetime and vibration characteristic. The method is illustrated for a three degrees of freedom articulated robotic manipulator.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "392",
        "title": "Autoregressive Styled Text Image Generation, but Make it Reliable",
        "author": [
            "Carmine Zaccagnino",
            "Fabio Quattrini",
            "Vittorio Pippi",
            "Silvia Cascianelli",
            "Alessio Tonioni",
            "Rita Cucchiara"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23240",
        "abstract": "Generating faithful and readable styled text images (especially for Styled Handwritten Text generation - HTG) is an open problem with several possible applications across graphic design, document understanding, and image editing. A lot of research effort in this task is dedicated to developing strategies that reproduce the stylistic characteristics of a given writer, with promising results in terms of style fidelity and generalization achieved by the recently proposed Autoregressive Transformer paradigm for HTG. However, this method requires additional inputs, lacks a proper stop mechanism, and might end up in repetition loops, generating visual artifacts. In this work, we rethink the autoregressive formulation by framing HTG as a multimodal prompt-conditioned generation task, and tackle the content controllability issues by introducing special textual input tokens for better alignment with the visual ones. Moreover, we devise a Classifier-Free-Guidance-based strategy for our autoregressive model. Through extensive experimental validation, we demonstrate that our approach, dubbed Eruku, compared to previous solutions requires fewer inputs, generalizes better to unseen styles, and follows more faithfully the textual prompt, improving content adherence.",
        "tags": [
            "Image Editing",
            "Transformer"
        ]
    },
    {
        "id": "393",
        "title": "Multi-Stakeholder Alignment in LLM-Powered Collaborative AI Systems: A Multi-Agent Framework for Intelligent Tutoring",
        "author": [
            "Alexandre P Uchoa",
            "Carlo E T Oliveira",
            "Claudia L R Motta",
            "Daniel Schneider"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23245",
        "abstract": "The integration of Large Language Models into Intelligent Tutoring Systems pre-sents significant challenges in aligning with diverse and often conflicting values from students, parents, teachers, and institutions. Existing architectures lack for-mal mechanisms for negotiating these multi-stakeholder tensions, creating risks in accountability and bias. This paper introduces the Advisory Governance Layer (AGL), a non-intrusive, multi-agent framework designed to enable distributed stakeholder participation in AI governance. The AGL employs specialized agents representing stakeholder groups to evaluate pedagogical actions against their spe-cific policies in a privacy-preserving manner, anticipating future advances in per-sonal assistant technology that will enhance stakeholder value expression. Through a novel policy taxonomy and conflict-resolution protocols, the frame-work provides structured, auditable governance advice to the ITS without altering its core pedagogical decision-making. This work contributes a reference architec-ture and technical specifications for aligning educational AI with multi-stakeholder values, bridging the gap between high-level ethical principles and practical implementation.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "394",
        "title": "A Video Is Not Worth a Thousand Words",
        "author": [
            "Sam Pollard",
            "Michael Wray"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23253",
        "abstract": "As we become increasingly dependent on vision language models (VLMs) to answer questions about the world around us, there is a significant amount of research devoted to increasing both the difficulty of video question answering (VQA) datasets, and the context lengths of the models that they evaluate. The reliance on large language models as backbones has lead to concerns about potential text dominance, and the exploration of interactions between modalities is underdeveloped. How do we measure whether we're heading in the right direction, with the complexity that multi-modal models introduce? We propose a joint method of computing both feature attributions and modality scores based on Shapley values, where both the features and modalities are arbitrarily definable. Using these metrics, we compare $6$ VLM models of varying context lengths on $4$ representative datasets, focusing on multiple-choice VQA. In particular, we consider video frames and whole textual elements as equal features in the hierarchy, and the multiple-choice VQA task as an interaction between three modalities: video, question and answer. Our results demonstrate a dependence on text and show that the multiple-choice VQA task devolves into a model's ability to ignore distractors. Code available at https://github.com/sjpollard/a-video-is-not-worth-a-thousand-words.",
        "tags": [
            "LLM",
            "VLM"
        ]
    },
    {
        "id": "395",
        "title": "Deep Active Inference with Diffusion Policy and Multiple Timescale World Model for Real-World Exploration and Navigation",
        "author": [
            "Riko Yokozawa",
            "Kentaro Fujii",
            "Yuta Nomura",
            "Shingo Murata"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23258",
        "abstract": "Autonomous robotic navigation in real-world environments requires exploration to acquire environmental information as well as goal-directed navigation in order to reach specified targets. Active inference (AIF) based on the free-energy principle provides a unified framework for these behaviors by minimizing the expected free energy (EFE), thereby combining epistemic and extrinsic values. To realize this practically, we propose a deep AIF framework that integrates a diffusion policy as the policy model and a multiple timescale recurrent state-space model (MTRSSM) as the world model. The diffusion policy generates diverse candidate actions while the MTRSSM predicts their long-horizon consequences through latent imagination, enabling action selection that minimizes EFE. Real-world navigation experiments demonstrated that our framework achieved higher success rates and fewer collisions compared with the baselines, particularly in exploration-demanding scenarios. These results highlight how AIF based on EFE minimization can unify exploration and goal-directed navigation in real-world robotic settings.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "396",
        "title": "PAHQ: Accelerating Automated Circuit Discovery through Mixed-Precision Inference Optimization",
        "author": [
            "Xinhai Wang",
            "Shu Yang",
            "Liangyu Wang",
            "Lin Zhang",
            "Huanyi Xie",
            "Lijie Hu",
            "Di Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23264",
        "abstract": "Circuit discovery, which involves identifying sparse and task-relevant subnetworks in pre-trained language models, is a cornerstone of mechanistic interpretability. Automated Circuit Discovery (ACDC) has emerged as a pivotal methodology in circuit discovery, but its application to large language models is severely limited by computational inefficiency and prohibitively high memory requirements. Although several accelerated approaches have been proposed, they primarily rely on linear approximations to ACDC, which significantly compromises analytical faithfulness. Our proposed method for accelerating automated circuit discovery, Per Attention Head Quantization (PAHQ), takes a fundamentally different approach by optimizing the efficiency of each individual patching operation. PAHQ leverages a fundamental alignment between activation patching and mixed-precision quantization (MPQ): interpretability analysis through patching essentially performs targeted ablation studies. Therefore, we can maintain high precision exclusively for investigated components while safely reducing precision elsewhere in the network. PAHQ-accelerated ACDC reduces runtime by up to 80\\% and memory consumption by up to 30\\% compared to unaccelerated ACDC while maintaining faithfulness. Importantly, our method readily integrates with existing edge-based circuit discovery techniques by modifying the attention computation mechanism. This training-free approach provides a practical and novel pathway for accelerating mechanistic interpretability methods. Our code is available at https://github.com/626619403/PAHQ.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "397",
        "title": "Code Aesthetics with Agentic Reward Feedback",
        "author": [
            "Bang Xiao",
            "Lingjie Jiang",
            "Shaohan Huang",
            "Tengchao Lv",
            "Yupan Huang",
            "Xun Wu",
            "Lei Cui",
            "Furu Wei"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23272",
        "abstract": "Large Language Models (LLMs) have become valuable assistants for developers in code-related tasks. While LLMs excel at traditional programming tasks such as code generation and bug fixing, they struggle with visually-oriented coding tasks, often producing suboptimal aesthetics. In this paper, we introduce a new pipeline to enhance the aesthetic quality of LLM-generated code. We first construct AesCode-358K, a large-scale instruction-tuning dataset focused on code aesthetics. Next, we propose agentic reward feedback, a multi-agent system that evaluates executability, static aesthetics, and interactive aesthetics. Building on this, we develop GRPO-AR, which integrates these signals into the GRPO algorithm for joint optimization of functionality and code aesthetics. Finally, we develop OpenDesign, a benchmark for assessing code aesthetics. Experimental results show that combining supervised fine-tuning on AesCode-358K with reinforcement learning using agentic reward feedback significantly improves performance on OpenDesign and also enhances results on existing benchmarks such as PandasPlotBench. Notably, our AesCoder-4B surpasses GPT-4o and GPT-4.1, and achieves performance comparable to large open-source models with 480B-685B parameters, underscoring the effectiveness of our approach.",
        "tags": [
            "GPT",
            "GRPO",
            "LLM",
            "RL"
        ]
    },
    {
        "id": "398",
        "title": "Privacy-Preserving Semantic Communication over Wiretap Channels with Learnable Differential Privacy",
        "author": [
            "Weixuan Chen",
            "Qianqian Yang",
            "Shuo Shao",
            "Shunpu Tang",
            "Zhiguo Shi",
            "Shui Yu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23274",
        "abstract": "While semantic communication (SemCom) improves transmission efficiency by focusing on task-relevant information, it also raises critical privacy concerns. Many existing secure SemCom approaches rely on restrictive or impractical assumptions, such as favorable channel conditions for the legitimate user or prior knowledge of the eavesdropper's model. To address these limitations, this paper proposes a novel secure SemCom framework for image transmission over wiretap channels, leveraging differential privacy (DP) to provide approximate privacy guarantees. Specifically, our approach first extracts disentangled semantic representations from source images using generative adversarial network (GAN) inversion method, and then selectively perturbs private semantic representations with approximate DP noise. Distinct from conventional DP-based protection methods, we introduce DP noise with learnable pattern, instead of traditional white Gaussian or Laplace noise, achieved through adversarial training of neural networks (NNs). This design mitigates the inherent non-invertibility of DP while effectively protecting private information. Moreover, it enables explicitly controllable security levels by adjusting the privacy budget according to specific security requirements, which is not achieved in most existing secure SemCom approaches. Experimental results demonstrate that, compared with the previous DP-based method and direct transmission, the proposed method significantly degrades the reconstruction quality for the eavesdropper, while introducing only slight degradation in task performance. Under comparable security levels, our approach achieves an LPIPS advantage of 0.06-0.29 and an FPPSR advantage of 0.10-0.86 for the legitimate user compared with the previous DP-based method.",
        "tags": [
            "GAN"
        ]
    },
    {
        "id": "399",
        "title": "Adaptive Stochastic Coefficients for Accelerating Diffusion Sampling",
        "author": [
            "Ruoyu Wang",
            "Beier Zhu",
            "Junzhi Li",
            "Liangyu Yuan",
            "Chi Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23285",
        "abstract": "Diffusion-based generative processes, formulated as differential equation solving, frequently balance computational speed with sample quality. Our theoretical investigation of ODE- and SDE-based solvers reveals complementary weaknesses: ODE solvers accumulate irreducible gradient error along deterministic trajectories, while SDE methods suffer from amplified discretization errors when the step budget is limited. Building upon this insight, we introduce AdaSDE, a novel single-step SDE solver that aims to unify the efficiency of ODEs with the error resilience of SDEs. Specifically, we introduce a single per-step learnable coefficient, estimated via lightweight distillation, which dynamically regulates the error correction strength to accelerate diffusion sampling. Notably, our framework can be integrated with existing solvers to enhance their capabilities. Extensive experiments demonstrate state-of-the-art performance: at 5 NFE, AdaSDE achieves FID scores of 4.18 on CIFAR-10, 8.05 on FFHQ and 6.96 on LSUN Bedroom. Codes are available in https://github.com/WLU-wry02/AdaSDE.",
        "tags": [
            "Diffusion",
            "ODE",
            "SDE"
        ]
    },
    {
        "id": "400",
        "title": "Predicting symbolic ODEs from multiple trajectories",
        "author": [
            "Yakup Emre Åahin",
            "Niki Kilbertus",
            "SÃ¶ren Becker"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23295",
        "abstract": "We introduce MIO, a transformer-based model for inferring symbolic ordinary differential equations (ODEs) from multiple observed trajectories of a dynamical system. By combining multiple instance learning with transformer-based symbolic regression, the model effectively leverages repeated observations of the same system to learn more generalizable representations of the underlying dynamics. We investigate different instance aggregation strategies and show that even simple mean aggregation can substantially boost performance. MIO is evaluated on systems ranging from one to four dimensions and under varying noise levels, consistently outperforming existing baselines.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "401",
        "title": "CNOT Minimal Circuit Synthesis: A Reinforcement Learning Approach",
        "author": [
            "Riccardo Romanello",
            "Daniele Lizzio Bosco",
            "Jacopo Cossio",
            "Dusan Sutulovic",
            "Giuseppe Serra",
            "Carla Piazza",
            "Paolo Burelli"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23304",
        "abstract": "CNOT gates are fundamental to quantum computing, as they facilitate entanglement, a crucial resource for quantum algorithms. Certain classes of quantum circuits are constructed exclusively from CNOT gates. Given their widespread use, it is imperative to minimise the number of CNOT gates employed. This problem, known as CNOT minimisation, remains an open challenge, with its computational complexity yet to be fully characterised. In this work, we introduce a novel reinforcement learning approach to address this task. Instead of training multiple reinforcement learning agents for different circuit sizes, we use a single agent up to a fixed size $m$. Matrices of sizes different from m are preprocessed using either embedding or Gaussian striping. To assess the efficacy of our approach, we trained an agent with m = 8, and evaluated it on matrices of size n that range from 3 to 15. The results we obtained show that our method overperforms the state-of-the-art algorithm as the value of n increases.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "402",
        "title": "ReconViaGen: Towards Accurate Multi-view 3D Object Reconstruction via Generation",
        "author": [
            "Jiahao Chang",
            "Chongjie Ye",
            "Yushuang Wu",
            "Yuantao Chen",
            "Yidan Zhang",
            "Zhongjin Luo",
            "Chenghong Li",
            "Yihao Zhi",
            "Xiaoguang Han"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23306",
        "abstract": "Existing multi-view 3D object reconstruction methods heavily rely on sufficient overlap between input views, where occlusions and sparse coverage in practice frequently yield severe reconstruction incompleteness. Recent advancements in diffusion-based 3D generative techniques offer the potential to address these limitations by leveraging learned generative priors to hallucinate invisible parts of objects, thereby generating plausible 3D structures. However, the stochastic nature of the inference process limits the accuracy and reliability of generation results, preventing existing reconstruction frameworks from integrating such 3D generative priors. In this work, we comprehensively analyze the reasons why diffusion-based 3D generative methods fail to achieve high consistency, including (a) the insufficiency in constructing and leveraging cross-view connections when extracting multi-view image features as conditions, and (b) the poor controllability of iterative denoising during local detail generation, which easily leads to plausible but inconsistent fine geometric and texture details with inputs. Accordingly, we propose ReconViaGen to innovatively integrate reconstruction priors into the generative framework and devise several strategies that effectively address these issues. Extensive experiments demonstrate that our ReconViaGen can reconstruct complete and accurate 3D models consistent with input views in both global structure and local http://details.Project page: https://jiahao620.github.io/reconviagen.",
        "tags": [
            "3D",
            "Diffusion"
        ]
    },
    {
        "id": "403",
        "title": "Network Intrusion Detection: Evolution from Conventional Approaches to LLM Collaboration and Emerging Risks",
        "author": [
            "Yaokai Feng",
            "Kouichi Sakurai"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23313",
        "abstract": "This survey systematizes the evolution of network intrusion detection systems (NIDS), from conventional methods such as signature-based and neural network (NN)-based approaches to recent integrations with large language models (LLMs). It clearly and concisely summarizes the current status, strengths, and limitations of conventional techniques, and explores the practical benefits of integrating LLMs into NIDS. Recent research on the application of LLMs to NIDS in diverse environments is reviewed, including conventional network infrastructures, autonomous vehicle environments and IoT environments.\nFrom this survey, readers will learn that: 1) the earliest methods, signature-based IDSs, continue to make significant contributions to modern systems, despite their well-known weaknesses; 2) NN-based detection, although considered promising and under development for more than two decades, and despite numerous related approaches, still faces significant challenges in practical deployment; 3) LLMs are useful for NIDS in many cases, and a number of related approaches have been proposed; however, they still face significant challenges in practical applications. Moreover, they can even be exploited as offensive tools, such as for generating malware, crafting phishing messages, or launching cyberattacks. Recently, several studies have been proposed to address these challenges, which are also reviewed in this survey; and 4) strategies for constructing domain-specific LLMs have been proposed and are outlined in this survey, as it is nearly impossible to train a NIDS-specific LLM from scratch.",
        "tags": [
            "Detection",
            "LLM"
        ]
    },
    {
        "id": "404",
        "title": "Towards Scaling Deep Neural Networks with Predictive Coding: Theory and Practice",
        "author": [
            "Francesco Innocenti"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23323",
        "abstract": "Backpropagation (BP) is the standard algorithm for training the deep neural networks that power modern artificial intelligence including large language models. However, BP is energy inefficient and unlikely to be implemented by the brain. This thesis studies an alternative, potentially more efficient brain-inspired algorithm called predictive coding (PC). Unlike BP, PC networks (PCNs) perform inference by iterative equilibration of neuron activities before learning or weight updates. Recent work has suggested that this iterative inference procedure provides a range of benefits over BP, such as faster training. However, these advantages have not been consistently observed, the inference and learning dynamics of PCNs are still poorly understood, and deep PCNs remain practically untrainable. Here, we make significant progress towards scaling PCNs by taking a theoretical approach grounded in optimisation theory. First, we show that the learning dynamics of PC can be understood as an approximate trust-region method using second-order information, despite explicitly using only first-order local updates. Second, going beyond this approximation, we show that PC can in principle make use of arbitrarily higher-order information, such that for feedforward networks the effective landscape on which PC learns is far more benign and robust to vanishing gradients than the (mean squared error) loss landscape. Third, motivated by a study of the inference dynamics of PCNs, we propose a new parameterisation called ``$\\mu$PC'', which for the first time allows stable training of 100+ layer networks with little tuning and competitive performance on simple tasks. Overall, this thesis significantly advances our fundamental understanding of the inference and learning dynamics of PCNs, while highlighting the need for future research to focus on hardware co-design if PC is to compete with BP at scale.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "405",
        "title": "Partnering with Generative AI: Experimental Evaluation of Human-Led and Model-Led Interaction in Human-AI Co-Creation",
        "author": [
            "Sebastian Maier",
            "Manuel Schneider",
            "Stefan Feuerriegel"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23324",
        "abstract": "Large language models (LLMs) show strong potential to support creative tasks, but the role of the interface design is poorly understood. In particular, the effect of different modes of collaboration between humans and LLMs on co-creation outcomes is unclear. To test this, we conducted a randomized controlled experiment ($N = 486$) comparing: (a) two variants of reflective, human-led modes in which the LLM elicits elaboration through suggestions or questions, against (b) a proactive, model-led mode in which the LLM independently rewrites ideas. By assessing the effects on idea quality, diversity, and perceived ownership, we found that the model-led mode substantially improved idea quality but reduced idea diversity and users' perceived idea ownership. The reflective, human-led mode also improved idea quality, yet while preserving diversity and ownership. Our findings highlight the importance of designing interactions with generative AI systems as reflective thought partners that complement human strengths and augment creative processes.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "406",
        "title": "Transferable Deep Reinforcement Learning for Cross-Domain Navigation: from Farmland to the Moon",
        "author": [
            "Shreya Santra",
            "Thomas Robbins",
            "Kazuya Yoshida"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23329",
        "abstract": "Autonomous navigation in unstructured environments is essential for field and planetary robotics, where robots must efficiently reach goals while avoiding obstacles under uncertain conditions. Conventional algorithmic approaches often require extensive environment-specific tuning, limiting scalability to new domains. Deep Reinforcement Learning (DRL) provides a data-driven alternative, allowing robots to acquire navigation strategies through direct interactions with their environment. This work investigates the feasibility of DRL policy generalization across visually and topographically distinct simulated domains, where policies are trained in terrestrial settings and validated in a zero-shot manner in extraterrestrial environments. A 3D simulation of an agricultural rover is developed and trained using Proximal Policy Optimization (PPO) to achieve goal-directed navigation and obstacle avoidance in farmland settings. The learned policy is then evaluated in a lunar-like simulated environment to assess transfer performance. The results indicate that policies trained under terrestrial conditions retain a high level of effectiveness, achieving close to 50\\% success in lunar simulations without the need for additional training and fine-tuning. This underscores the potential of cross-domain DRL-based policy transfer as a promising approach to developing adaptable and efficient autonomous navigation for future planetary exploration missions, with the added benefit of minimizing retraining costs.",
        "tags": [
            "3D",
            "PPO",
            "RL",
            "Robotics"
        ]
    },
    {
        "id": "407",
        "title": "Adaptive Blockwise Search: Inference-Time Alignment for Large Language Models",
        "author": [
            "Mohammad Atif Quamar",
            "Mohammad Areeb",
            "Nishant Sharma",
            "Ananth Shreekumar",
            "Jonathan Rosenthal",
            "Muslum Ozgur Ozmen",
            "Mikhail Kuznetsov",
            "Z. Berkay Celik"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23334",
        "abstract": "LLM alignment remains a critical challenge. Inference-time methods provide a flexible alternative to fine-tuning, but their uniform computational effort often yields suboptimal alignment. We hypothesize that for many alignment tasks, the initial tokens of a response are disproportionately more critical. To leverage this principle, we introduce AdaSearch, a novel blockwise search strategy. It adaptively allocates a fixed computational budget using a sampling schedule, focusing search effort on these critical tokens. We apply AdaSearch to sequential decoding and introduce its tree-search counterpart, AdaBeam. Our comprehensive evaluation across eight LLMs demonstrates that AdaSearch outperforms strong Best-of-N and fine-tuning baselines. Specifically, win-rates improve by over 10% for harmlessness generation, controlled sentiment generation, and for mathematical reasoning tasks relative to Best-of-N.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "408",
        "title": "BaZi-Based Character Simulation Benchmark: Evaluating AI on Temporal and Persona Reasoning",
        "author": [
            "Siyuan Zheng",
            "Pai Liu",
            "Xi Chen",
            "Jizheng Dong",
            "Sihan Jia"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23337",
        "abstract": "Human-like virtual characters are crucial for games, storytelling, and virtual reality, yet current methods rely heavily on annotated data or handcrafted persona prompts, making it difficult to scale up and generate realistic, contextually coherent personas. We create the first QA dataset for BaZi-based persona reasoning, where real human experiences categorized into wealth, health, kinship, career, and relationships are represented as life-event questions and answers. Furthermore, we propose the first BaZi-LLM system that integrates symbolic reasoning with large language models to generate temporally dynamic and fine-grained virtual personas. Compared with mainstream LLMs such as DeepSeek-v3 and GPT-5-mini, our method achieves a 30.3%-62.6% accuracy improvement. In addition, when incorrect BaZi information is used, our model's accuracy drops by 20%-45%, showing the potential of culturally grounded symbolic-LLM integration for realistic character simulation.",
        "tags": [
            "DeepSeek",
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "409",
        "title": "LightKGG: Simple and Efficient Knowledge Graph Generation from Textual Data",
        "author": [
            "Teng Lin"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23341",
        "abstract": "The scarcity of high-quality knowledge graphs (KGs) remains a critical bottleneck for downstream AI applications, as existing extraction methods rely heavily on error-prone pattern-matching techniques or resource-intensive large language models (LLMs). While recent tools leverage LLMs to generate KGs, their computational demands limit accessibility for low-resource environments. Our paper introduces LightKGG, a novel framework that enables efficient KG extraction from textual data using small-scale language models (SLMs) through two key technical innovations: (1) Context-integrated Graph extraction integrates contextual information with nodes and edges into a unified graph structure, reducing the reliance on complex semantic processing while maintaining more key information; (2) Topology-enhanced relationship inference leverages the inherent topology of the extracted graph to efficiently infer relationships, enabling relationship discovery without relying on complex language understanding capabilities of LLMs. By enabling accurate KG construction with minimal hardware requirements, this work bridges the gap between automated knowledge extraction and practical deployment scenarios while introducing scientifically rigorous methods for optimizing SLM efficiency in structured NLP tasks.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "410",
        "title": "Block-Diagonal LoRA for Eliminating Communication Overhead in Tensor Parallel LoRA Serving",
        "author": [
            "Xinyu Wang",
            "Jonas M. KÃ¼bler",
            "Kailash Budhathoki",
            "Yida Wang",
            "MatthÃ¤us Kleindessner"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23346",
        "abstract": "When serving a single base LLM with several different LoRA adapters simultaneously, the adapters cannot simply be merged with the base model's weights as the adapter swapping would create overhead and requests using different adapters could not be batched. Rather, the LoRA computations have to be separated from the base LLM computations, and in a multi-device setup the LoRA adapters can be sharded in a way that is well aligned with the base model's tensor parallel execution, as proposed in S-LoRA. However, the S-LoRA sharding strategy encounters some communication overhead, which may be small in theory, but can be large in practice. In this paper, we propose to constrain certain LoRA factors to be block-diagonal, which allows for an alternative way of sharding LoRA adapters that does not require any additional communication for the LoRA computations. We demonstrate in extensive experiments that our block-diagonal LoRA approach is similarly parameter efficient as standard LoRA (i.e., for a similar number of parameters it achieves similar downstream performance) and that it leads to significant end-to-end speed-up over S-LoRA. For example, when serving on eight A100 GPUs, we observe up to 1.79x (1.23x) end-to-end speed-up with 0.87x (1.74x) the number of adapter parameters for Llama-3.1-70B, and up to 1.63x (1.3x) end-to-end speed-up with 0.86x (1.73x) the number of adapter parameters for Llama-3.1-8B.",
        "tags": [
            "LLM",
            "LLaMA",
            "LoRA"
        ]
    },
    {
        "id": "411",
        "title": "Validating Formal Specifications with LLM-generated Test Cases",
        "author": [
            "Alcino Cunha",
            "Nuno Macedo"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23350",
        "abstract": "Validation is a central activity when developing formal specifications. Similarly to coding, a possible validation technique is to define upfront test cases or scenarios that a future specification should satisfy or not. Unfortunately, specifying such test cases is burdensome and error prone, which could cause users to skip this validation task. This paper reports the results of an empirical evaluation of using pre-trained large language models (LLMs) to automate the generation of test cases from natural language requirements. In particular, we focus on test cases for structural requirements of simple domain models formalized in the Alloy specification language. Our evaluation focuses on the state-of-art GPT-5 model, but results from other closed- and open-source LLMs are also reported. The results show that, in this context, GPT-5 is already quite effective at generating positive (and negative) test cases that are syntactically correct and that satisfy (or not) the given requirement, and that can detect many wrong specifications written by humans.",
        "tags": [
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "412",
        "title": "Large language model-based task planning for service robots: A review",
        "author": [
            "Shaohan Bian",
            "Ying Zhang",
            "Guohui Tian",
            "Zhiqiang Miao",
            "Edmond Q. Wu",
            "Simon X. Yang",
            "Changchun Hua"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23357",
        "abstract": "With the rapid advancement of large language models (LLMs) and robotics, service robots are increasingly becoming an integral part of daily life, offering a wide range of services in complex environments. To deliver these services intelligently and efficiently, robust and accurate task planning capabilities are essential. This paper presents a comprehensive overview of the integration of LLMs into service robotics, with a particular focus on their role in enhancing robotic task planning. First, the development and foundational techniques of LLMs, including pre-training, fine-tuning, retrieval-augmented generation (RAG), and prompt engineering, are reviewed. We then explore the application of LLMs as the cognitive core-`brain'-of service robots, discussing how LLMs contribute to improved autonomy and decision-making. Furthermore, recent advancements in LLM-driven task planning across various input modalities are analyzed, including text, visual, audio, and multimodal inputs. Finally, we summarize key challenges and limitations in current research and propose future directions to advance the task planning capabilities of service robots in complex, unstructured domestic environments. This review aims to serve as a valuable reference for researchers and practitioners in the fields of artificial intelligence and robotics.",
        "tags": [
            "LLM",
            "RAG",
            "Robotics"
        ]
    },
    {
        "id": "413",
        "title": "How AI Forecasts AI Jobs: Benchmarking LLM Predictions of Labor Market Changes",
        "author": [
            "Sheri Osborn",
            "Rohit Valecha",
            "H. Raghav Rao",
            "Dan Sass",
            "Anthony Rios"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23358",
        "abstract": "Artificial intelligence is reshaping labor markets, yet we lack tools to systematically forecast its effects on employment. This paper introduces a benchmark for evaluating how well large language models (LLMs) can anticipate changes in job demand, especially in occupations affected by AI. Existing research has shown that LLMs can extract sentiment, summarize economic reports, and emulate forecaster behavior, but little work has assessed their use for forward-looking labor prediction. Our benchmark combines two complementary datasets: a high-frequency index of sector-level job postings in the United States, and a global dataset of projected occupational changes due to AI adoption. We format these data into forecasting tasks with clear temporal splits, minimizing the risk of information leakage. We then evaluate LLMs using multiple prompting strategies, comparing task-scaffolded, persona-driven, and hybrid approaches across model families. We assess both quantitative accuracy and qualitative consistency over time. Results show that structured task prompts consistently improve forecast stability, while persona prompts offer advantages on short-term trends. However, performance varies significantly across sectors and horizons, highlighting the need for domain-aware prompting and rigorous evaluation protocols. By releasing our benchmark, we aim to support future research on labor forecasting, prompt design, and LLM-based economic reasoning. This work contributes to a growing body of research on how LLMs interact with real-world economic data, and provides a reproducible testbed for studying the limits and opportunities of AI as a forecasting tool in the context of labor markets.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "414",
        "title": "PlanarTrack: A high-quality and challenging benchmark for large-scale planar object tracking",
        "author": [
            "Yifan Jiao",
            "Xinran Liu",
            "Xiaoqiong Liu",
            "Xiaohui Yuan",
            "Heng Fan",
            "Libo Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23368",
        "abstract": "Planar tracking has drawn increasing interest owing to its key roles in robotics and augmented reality. Despite recent great advancement, further development of planar tracking, particularly in the deep learning era, is largely limited compared to generic tracking due to the lack of large-scale platforms. To mitigate this, we propose PlanarTrack, a large-scale high-quality and challenging benchmark for planar tracking. Specifically, PlanarTrack consists of 1,150 sequences with over 733K frames, including 1,000 short-term and 150 new long-term videos, which enables comprehensive evaluation of short- and long-term tracking performance. All videos in PlanarTrack are recorded in unconstrained conditions from the wild, which makes PlanarTrack challenging but more realistic for real-world applications. To ensure high-quality annotations, each video frame is manually annotated by four corner points with multi-round meticulous inspection and refinement. To enhance target diversity of PlanarTrack, we only capture a unique target in one sequence, which is different from existing benchmarks. To our best knowledge, PlanarTrack is by far the largest and most diverse and challenging dataset dedicated to planar tracking. To understand performance of existing methods on PlanarTrack and to provide a comparison for future research, we evaluate 10 representative planar trackers with extensive comparison and in-depth analysis. Our evaluation reveals that, unsurprisingly, the top planar trackers heavily degrade on the challenging PlanarTrack, which indicates more efforts are required for improving planar tracking. Our data and results will be released at https://github.com/HengLan/PlanarTrack",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "415",
        "title": "One-Timestep is Enough: Achieving High-performance ANN-to-SNN Conversion via Scale-and-Fire Neurons",
        "author": [
            "Qiuyang Chen",
            "Huiqi Yang",
            "Qingyan Meng",
            "Zhengyu Ma"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23383",
        "abstract": "Spiking Neural Networks (SNNs) are gaining attention as energy-efficient alternatives to Artificial Neural Networks (ANNs), especially in resource-constrained settings. While ANN-to-SNN conversion (ANN2SNN) achieves high accuracy without end-to-end SNN training, existing methods rely on large time steps, leading to high inference latency and computational cost. In this paper, we propose a theoretical and practical framework for single-timestep ANN2SNN. We establish the Temporal-to-Spatial Equivalence Theory, proving that multi-timestep integrate-and-fire (IF) neurons can be equivalently replaced by single-timestep multi-threshold neurons (MTN). Based on this theory, we introduce the Scale-and-Fire Neuron (SFN), which enables effective single-timestep ($T=1$) spiking through adaptive scaling and firing. Furthermore, we develop the SFN-based Spiking Transformer (SFormer), a specialized instantiation of SFN within Transformer architectures, where spike patterns are aligned with attention distributions to mitigate the computational, energy, and hardware overhead of the multi-threshold design. Extensive experiments on image classification, object detection, and instance segmentation demonstrate that our method achieves state-of-the-art performance under single-timestep inference. Notably, we achieve 88.8% top-1 accuracy on ImageNet-1K at $T=1$, surpassing existing conversion methods.",
        "tags": [
            "Detection",
            "Segmentation",
            "Transformer"
        ]
    },
    {
        "id": "416",
        "title": "The Best of N Worlds: Aligning Reinforcement Learning with Best-of-N Sampling via max@k Optimisation",
        "author": [
            "Farid Bagirov",
            "Mikhail Arkhipov",
            "Ksenia Sycheva",
            "Evgeniy Glukhov",
            "Egor Bogomolov"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23393",
        "abstract": "The application of Reinforcement Learning with Verifiable Rewards (RLVR) to mathematical and coding domains has demonstrated significant improvements in the reasoning and problem-solving abilities of Large Language Models. Despite its success in single generation problem solving, the reinforcement learning fine-tuning process may harm the model's exploration ability, as reflected in decreased diversity of generations and a resulting degradation of performance during Best-of-N sampling for large N values. In this work, we focus on optimizing the max@k metric, a continuous generalization of pass@k. We derive an unbiased on-policy gradient estimate for direct optimization of this metric. Furthermore, we extend our derivations to the off-policy updates, a common element in modern RLVR algorithms, that allows better sample efficiency. Empirically, we show that our objective effectively optimizes max@k metric in off-policy scenarios, aligning the model with the Best-of-N inference strategy.",
        "tags": [
            "LLM",
            "RL"
        ]
    },
    {
        "id": "417",
        "title": "Detecting Religious Language in Climate Discourse",
        "author": [
            "Evy Beijen",
            "Pien Pieterse",
            "Yusuf Ãelik",
            "Willem Th. van Peursen",
            "Sandjai Bhulai",
            "Meike Morren"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23395",
        "abstract": "Religious language continues to permeate contemporary discourse, even in ostensibly secular domains such as environmental activism and climate change debates. This paper investigates how explicit and implicit forms of religious language appear in climate-related texts produced by secular and religious nongovernmental organizations (NGOs). We introduce a dual methodological approach: a rule-based model using a hierarchical tree of religious terms derived from ecotheology literature, and large language models (LLMs) operating in a zero-shot setting. Using a dataset of more than 880,000 sentences, we compare how these methods detect religious language and analyze points of agreement and divergence. The results show that the rule-based method consistently labels more sentences as religious than LLMs. These findings highlight not only the methodological challenges of computationally detecting religious language but also the broader tension over whether religious language should be defined by vocabulary alone or by contextual meaning. This study contributes to digital methods in religious studies by demonstrating both the potential and the limitations of approaches for analyzing how the sacred persists in climate discourse.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "418",
        "title": "EMTSF:Extraordinary Mixture of SOTA Models for Time Series Forecasting",
        "author": [
            "Musleh Alharthi",
            "Kaleel Mahmood",
            "Sarosh Patel",
            "Ausif Mahmood"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23396",
        "abstract": "The immense success of the Transformer architecture\nin Natural Language Processing has led to its adoption in Time Se ries Forecasting (TSF), where superior performance has been shown.\nHowever, a recent important paper questioned their effectiveness by\ndemonstrating that a simple single layer linear model outperforms\nTransformer-based models. This was soon shown to be not as valid,\nby a better transformer-based model termed PatchTST. More re cently, TimeLLM demonstrated even better results by repurposing a\nLarge Language Model (LLM) for the TSF domain. Again, a follow\nup paper challenged this by demonstrating that removing the LLM\ncomponent or replacing it with a basic attention layer in fact yields\nbetter performance. One of the challenges in forecasting is the fact\nthat TSF data favors the more recent past, and is sometimes subject\nto unpredictable events. Based upon these recent insights in TSF, we\npropose a strong Mixture of Experts (MoE) framework. Our method\ncombines the state-of-the-art (SOTA) models including xLSTM, en hanced Linear, PatchTST, and minGRU, among others. This set of\ncomplimentary and diverse models for TSF are integrated in a Trans former based MoE gating network. Our proposed model outperforms\nall existing TSF models on standard benchmarks, surpassing even the\nlatest approaches based on MoE frameworks.",
        "tags": [
            "LLM",
            "MoE",
            "Transformer"
        ]
    },
    {
        "id": "419",
        "title": "VideoTG-R1: Boosting Video Temporal Grounding via Curriculum Reinforcement Learning on Reflected Boundary Annotations",
        "author": [
            "Lu Dong",
            "Haiyu Zhang",
            "Han Lin",
            "Ziang Yan",
            "Xiangyu Zeng",
            "Hongjie Zhang",
            "Yifei Huang",
            "Yi Wang",
            "Zhen-Hua Ling",
            "Limin Wang",
            "Yali Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23397",
        "abstract": "Video temporal grounding (VTG) aims to locate precise segments in videos based on language queries, which is a fundamental challenge in video understanding. While recent Multimodal Large Language Models (MLLMs) have shown promise in tackling VTG through reinforcement learning (RL), they overlook the challenges arising from both the quality and difficulty of training samples. (1) Partially annotated samples. Many samples contain relevant segments beyond the annotated interval, introducing ambiguous supervision. (2) Hard-to-ground samples. Samples with poor zero-shot performance produce consistently low and indistinguishable rewards during RL training, exhibiting no clear preference among multiple outputs and thus hindering learning efficiency. To address these challenges, we propose VideoTG-R1, a novel curriculum RL framework with reflected boundary annotations, enabling data-efficient training. Specifically, we propose a Boundary Reflection Agent that utilizes MLLMs to predict query-relevant timestamps outside the annotated intervals, allowing us to identify and filter out partially annotated samples, thereby reducing ambiguity. Furthermore, we introduce a Difficulty Estimation Agent to assess the training difficulty of each sample and design a curriculum RL strategy that dynamically masks the videos of hard-to-ground samples according to the training steps, easing the training difficulty and providing clearer preference. Experiments on the VTG and grounded VideoQA tasks demonstrate the effectiveness of our method. Remarkably, with only 10% of the training samples and 21% of the computational budget, VideoTG-R1 outperforms full-data counterparts under both group relative policy optimization (GRPO) and supervised fine-tuning (SFT). The code is available at https://github.com/ldong1111/VideoTG-R1.",
        "tags": [
            "GRPO",
            "LLM",
            "RL"
        ]
    },
    {
        "id": "420",
        "title": "AutoStreamPipe: LLM Assisted Automatic Generation of Data Stream Processing Pipelines",
        "author": [
            "Abolfazl Younesi",
            "Zahra Najafabadi Samani",
            "Thomas Fahringer"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23408",
        "abstract": "Data pipelines are essential in stream processing as they enable the efficient collection, processing, and delivery of real-time data, supporting rapid data analysis. In this paper, we present AutoStreamPipe, a novel framework that employs Large Language Models (LLMs) to automate the design, generation, and deployment of stream processing pipelines. AutoStreamPipe bridges the semantic gap between high-level user intent and platform-specific implementations across distributed stream processing systems for structured multi-agent reasoning by integrating a Hypergraph of Thoughts (HGoT) as an extended version of GoT. AutoStreamPipe combines resilient execution strategies, advanced query analysis, and HGoT to deliver pipelines with good accuracy. Experimental evaluations on diverse pipelines demonstrate that AutoStreamPipe significantly reduces development time (x6.3) and error rates (x5.19), as measured by a novel Error-Free Score (EFS), compared to LLM code-generation methods.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "421",
        "title": "Causal Deep Q Network",
        "author": [
            "Elouanes Khelifi",
            "Amir Saki",
            "Usef Faghihi"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23424",
        "abstract": "Deep Q Networks (DQN) have shown remarkable success in various reinforcement learning tasks. However, their reliance on associative learning often leads to the acquisition of spurious correlations, hindering their problem-solving capabilities. In this paper, we introduce a novel approach to integrate causal principles into DQNs, leveraging the PEACE (Probabilistic Easy vAriational Causal Effect) formula for estimating causal effects. By incorporating causal reasoning during training, our proposed framework enhances the DQN's understanding of the underlying causal structure of the environment, thereby mitigating the influence of confounding factors and spurious correlations. We demonstrate that integrating DQNs with causal capabilities significantly enhances their problem-solving capabilities without compromising performance. Experimental results on standard benchmark environments showcase that our approach outperforms conventional DQNs, highlighting the effectiveness of causal reasoning in reinforcement learning. Overall, our work presents a promising avenue for advancing the capabilities of deep reinforcement learning agents through principled causal inference.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "422",
        "title": "Education Paradigm Shift To Maintain Human Competitive Advantage Over AI",
        "author": [
            "Stanislav Selitskiy",
            "Chihiro Inoue"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23436",
        "abstract": "Discussion about the replacement of intellectual human labour by ``thinking machines'' has been present in the public and expert discourse since the creation of Artificial Intelligence (AI) as an idea and terminology since the middle of the twentieth century. Until recently, it was more of a hypothetical concern. However, in recent years, with the rise of Generative AI, especially Large Language Models (LLM), and particularly with the widespread popularity of the ChatGPT model, that concern became practical. Many domains of human intellectual labour have to adapt to the new AI tools that give humans new functionality and opportunity, but also question the viability and necessity of some human work that used to be considered intellectual yet has now become an easily automatable commodity. Education, unexpectedly, has now become burdened by an especially crucial role of charting long-range strategies for discovering viable human skills that would guarantee their place in the world of the ubiquitous use of AI in the intellectual sphere. We highlight weaknesses of the current AI and, especially, of its LLM-based core, show that root causes of LLMs' weaknesses are unfixable by the current technologies, and propose directions in the constructivist paradigm for the changes in Education that ensure long-term advantages of humans over AI tools.",
        "tags": [
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "423",
        "title": "An Information-Theoretic Analysis of Out-of-Distribution Generalization in Meta-Learning with Applications to Meta-RL",
        "author": [
            "Xingtu Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23448",
        "abstract": "In this work, we study out-of-distribution generalization in meta-learning from an information-theoretic perspective. We focus on two scenarios: (i) when the testing environment mismatches the training environment, and (ii) when the training environment is broader than the testing environment. The first corresponds to the standard distribution mismatch setting, while the second reflects a broad-to-narrow training scenario. We further formalize the generalization problem in meta-reinforcement learning and establish corresponding generalization bounds. Finally, we analyze the generalization performance of a gradient-based meta-reinforcement learning algorithm.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "424",
        "title": "BrowseConf: Confidence-Guided Test-Time Scaling for Web Agents",
        "author": [
            "Litu Ou",
            "Kuan Li",
            "Huifeng Yin",
            "Liwen Zhang",
            "Zhongwang Zhang",
            "Xixi Wu",
            "Rui Ye",
            "Zile Qiao",
            "Yong Jiang",
            "Pengjun Xie",
            "Fei Huang",
            "Jingren Zhou"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23458",
        "abstract": "Confidence in LLMs is a useful indicator of model uncertainty and answer reliability. Existing work mainly focused on single-turn scenarios, while research on confidence in complex multi-turn interactions is limited. In this paper, we investigate whether LLM-based search agents have the ability to communicate their own confidence through verbalized confidence scores after long sequences of actions, a significantly more challenging task compared to outputting confidence in a single interaction. Experimenting on open-source agentic models, we first find that models exhibit much higher task accuracy at high confidence while having near-zero accuracy when confidence is low. Based on this observation, we propose Test-Time Scaling (TTS) methods that use confidence scores to determine answer quality, encourage the model to try again until reaching a satisfactory confidence level. Results show that our proposed methods significantly reduce token consumption while demonstrating competitive performance compared to baseline fixed budget TTS methods.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "425",
        "title": "A Finite Element framework for bulk-surface coupled PDEs to solve moving boundary problems in biophysics",
        "author": [
            "Alessandro Contri",
            "AndrÃ© Massing",
            "Padmini Rangamani"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23459",
        "abstract": "We consider moving boundary problems for biophysics and introduce a new computational framework to handle the complexity of the bulk-surface PDEs. In our framework, interpretability is maintained by adapting the fast, generalizable and accurate structure preservation scheme in [Q. Cheng and J. Shen, \\textit{Computer Methods in Applied Mechanics and Engineering}, 391 (2022)]. We show that mesh distortion is mitigated by adopting the pioneering work of [B. Duan and B. Li, \\textit{SIAM J. Sci. Comput.}, 46 (2024)], which is tied to an Arbitrary Lagrangian Eulerian (ALE) framework. We test our algorithms accuracy on moving surfaces with boundary for the following PDEs: advection-diffusion-reaction equations, phase-field models of Cahn-Hilliard type, and Helfrich energy gradient flows. We performed convergence studies for all the schemes introduced to demonstrate accuracy. We use a staggered approach to achieve coupling and further verify the convergence of this coupling using numerical experiments. Finally, we demonstrate broad applicability of our work by simulating state-of-the-art tests of biophysical models that involve membrane deformation.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "426",
        "title": "Evaluating Large Language Models for Stance Detection on Financial Targets from SEC Filing Reports and Earnings Call Transcripts",
        "author": [
            "Nikesh Gyawali",
            "Doina Caragea",
            "Alex Vasenkov",
            "Cornelia Caragea"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23464",
        "abstract": "Financial narratives from U.S. Securities and Exchange Commission (SEC) filing reports and quarterly earnings call transcripts (ECTs) are very important for investors, auditors, and regulators. However, their length, financial jargon, and nuanced language make fine-grained analysis difficult. Prior sentiment analysis in the financial domain required a large, expensive labeled dataset, making the sentence-level stance towards specific financial targets challenging. In this work, we introduce a sentence-level corpus for stance detection focused on three core financial metrics: debt, earnings per share (EPS), and sales. The sentences were extracted from Form 10-K annual reports and ECTs, and labeled for stance (positive, negative, neutral) using the advanced ChatGPT-o3-pro model under rigorous human validation. Using this corpus, we conduct a systematic evaluation of modern large language models (LLMs) using zero-shot, few-shot, and Chain-of-Thought (CoT) prompting strategies. Our results show that few-shot with CoT prompting performs best compared to supervised baselines, and LLMs' performance varies across the SEC and ECT datasets. Our findings highlight the practical viability of leveraging LLMs for target-specific stance in the financial domain without requiring extensive labeled data.",
        "tags": [
            "CoT",
            "Detection",
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "427",
        "title": "Video-Thinker: Sparking \"Thinking with Videos\" via Reinforcement Learning",
        "author": [
            "Shijian Wang",
            "Jiarui Jin",
            "Xingjian Wang",
            "Linxin Song",
            "Runhao Fu",
            "Hecheng Wang",
            "Zongyuan Ge",
            "Yuan Lu",
            "Xuelian Cheng"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23473",
        "abstract": "Recent advances in image reasoning methods, particularly \"Thinking with Images\", have demonstrated remarkable success in Multimodal Large Language Models (MLLMs); however, this dynamic reasoning paradigm has not yet been extended to video reasoning tasks. In this paper, we propose Video-Thinker, which empowers MLLMs to think with videos by autonomously leveraging their intrinsic \"grounding\" and \"captioning\" capabilities to generate reasoning clues throughout the inference process. To spark this capability, we construct Video-Thinker-10K, a curated dataset featuring autonomous tool usage within chain-of-thought reasoning sequences. Our training strategy begins with Supervised Fine-Tuning (SFT) to learn the reasoning format, followed by Group Relative Policy Optimization (GRPO) to strengthen this reasoning capability. Through this approach, Video-Thinker enables MLLMs to autonomously navigate grounding and captioning tasks for video reasoning, eliminating the need for constructing and calling external tools. Extensive experiments demonstrate that Video-Thinker achieves significant performance gains on both in-domain tasks and challenging out-of-domain video reasoning benchmarks, including Video-Holmes, CG-Bench-Reasoning, and VRBench. Our Video-Thinker-7B substantially outperforms existing baselines such as Video-R1 and establishes state-of-the-art performance among 7B-sized MLLMs.",
        "tags": [
            "CoT",
            "GRPO",
            "LLM",
            "RL"
        ]
    },
    {
        "id": "428",
        "title": "Policy-Aware Generative AI for Safe, Auditable Data Access Governance",
        "author": [
            "Shames Al Mandalawi",
            "Muzakkiruddin Ahmed Mohammed",
            "Hendrika Maclean",
            "Mert Can Cakmak",
            "John R. Talburt"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23474",
        "abstract": "Enterprises need access decisions that satisfy least privilege, comply with regulations, and remain auditable. We present a policy aware controller that uses a large language model (LLM) to interpret natural language requests against written policies and metadata, not raw data. The system, implemented with Google Gemini~2.0 Flash, executes a six-stage reasoning framework (context interpretation, user validation, data classification, business purpose test, compliance mapping, and risk synthesis) with early hard policy gates and deny by default. It returns APPROVE, DENY, CONDITIONAL together with cited controls and a machine readable rationale. We evaluate on fourteen canonical cases across seven scenario families using a privacy preserving benchmark. Results show Exact Decision Match improving from 10/14 to 13/14 (92.9\\%) after applying policy gates, DENY recall rising to 1.00, False Approval Rate on must-deny families dropping to 0, and Functional Appropriateness and Compliance Adherence at 14/14. Expert ratings of rationale quality are high, and median latency is under one minute. These findings indicate that policy constrained LLM reasoning, combined with explicit gates and audit trails, can translate human readable policies into safe, compliant, and traceable machine decisions.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "429",
        "title": "MMTutorBench: The First Multimodal Benchmark for AI Math Tutoring",
        "author": [
            "Tengchao Yang",
            "Sichen Guo",
            "Mengzhao Jia",
            "Jiaming Su",
            "Yuanyang Liu",
            "Zhihan Zhang",
            "Meng Jiang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23477",
        "abstract": "Effective math tutoring requires not only solving problems but also diagnosing students' difficulties and guiding them step by step. While multimodal large language models (MLLMs) show promise, existing benchmarks largely overlook these tutoring skills. We introduce MMTutorBench, the first benchmark for AI math tutoring, consisting of 685 problems built around pedagogically significant key-steps. Each problem is paired with problem-specific rubrics that enable fine-grained evaluation across six dimensions, and structured into three tasks-Insight Discovery, Operation Formulation, and Operation Execution. We evaluate 12 leading MLLMs and find clear performance gaps between proprietary and open-source systems, substantial room compared to human tutors, and consistent trends across input variants: OCR pipelines degrade tutoring quality, few-shot prompting yields limited gains, and our rubric-based LLM-as-a-Judge proves highly reliable. These results highlight both the difficulty and diagnostic value of MMTutorBench for advancing AI tutoring.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "430",
        "title": "MergeMix: A Unified Augmentation Paradigm for Visual and Multi-Modal Understanding",
        "author": [
            "Xin Jin",
            "Siyuan Li",
            "Siyong Jian",
            "Kai Yu",
            "Huan Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23479",
        "abstract": "Vision-language alignment in multi-modal large language models (MLLMs) typically relies on supervised fine-tuning (SFT) or reinforcement learning (RL). SFT is stable and efficient but requires large-scale human annotations and cannot capture subtle preferences, while RL brings in a reward signal for training, but suffers from overhead and instability. These limitations highlight a trade-off between scalability, robustness, and alignment quality. To address this, we propose MergeMix, a training-time augmentation paradigm that bridges SFT and RL. It first applies an attention-aware image mixing via token merge with more cluster representation and spatial context, and then presents a preference-driven training paradigm for MLLMs by building preference pairs with mixed images and raw images, and optimizing via SimPO loss. As a mixup augmentation, MergeMix enhances attention consistency and efficiency, surpassing other heuristic-based methods in classification. Extensive experiments demonstrate that MergeMix achieves competitive accuracy with improved efficiency, providing a scalable approach to preference alignment in classification and MLLMs.",
        "tags": [
            "LLM",
            "RL"
        ]
    },
    {
        "id": "431",
        "title": "On the Faithfulness of Visual Thinking: Measurement and Enhancement",
        "author": [
            "Zujing Liu",
            "Junwen Pan",
            "Qi She",
            "Yuan Gao",
            "Guisong Xia"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23482",
        "abstract": "Recent large vision-language models (LVLMs) can generate vision-text multimodal chain-of-thought (MCoT) traces after reinforcement fine-tuning (RFT). However, we observe that the visual information incorporated in MCoT is often inaccurate, though still yield correct answers, indicating a lack of faithfulness in the MCoT reasoning process. We attribute this unfaithfulness to the RL reward in RFT, which solely incentivizes the format of interleaved vision-text cues, ie, it encourages the model to incorporate visual information into its text reasoning steps without considering the correctness of the visual information. In this paper, we first probe the faithfulness of MCoT by measuring how much the prediction changes when its visual and textual thoughts are intervened. Surprisingly, the model's predictions remain nearly unchanged under visual intervention but change significantly under textual intervention, indicating that the visual evidence is largely ignored. To further analyze visual information, we introduce an automated LVLM-based evaluation metric that quantifies the faithfulness of visual cues from two perspectives: reliability and sufficiency. Our evaluation reveals that the visual information in current MCoT traces is simultaneously unreliable and insufficient. To address this issue, we propose a novel MCoT learning strategy termed Sufficient-Component Cause Model (SCCM) learning. This approach encourages the MCoT to generate sufficient yet minimal visual components that are independently capable of leading to correct answers. We note that the proposed SCCM is annotation-free and compatible with various RFT for MCoT in a plug-and-play manner. Empirical results demonstrate that SCCM consistently improves the visual faithfulness across a suite of fine-grained perception and reasoning benchmarks. Code is available at https://github.com/EugeneLiu01/Faithful_Thinking_with_Image.",
        "tags": [
            "CoT",
            "RL",
            "VLM"
        ]
    },
    {
        "id": "432",
        "title": "Learning to Reason Efficiently with Discounted Reinforcement Learning",
        "author": [
            "Alex Ayoub",
            "Kavosh Asadi",
            "Dale Schuurmans",
            "Csaba SzepesvÃ¡ri",
            "Karim Bouyarmane"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23486",
        "abstract": "Large reasoning models (LRMs) often consume excessive tokens, inflating computational cost and latency. We challenge the assumption that longer responses improve accuracy. By penalizing reasoning tokens using a discounted reinforcement learning setup (interpretable as a small token cost) and analyzing Blackwell optimality in restricted policy classes, we encourage concise yet accurate reasoning. Experiments confirm our theoretical results that this approach shortens chains of thought while preserving accuracy.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "433",
        "title": "Are Agents Just Automata? On the Formal Equivalence Between Agentic AI and the Chomsky Hierarchy",
        "author": [
            "Roham Koohestani",
            "Ziyou Li",
            "Anton Podkopaev",
            "Maliheh Izadi"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23487",
        "abstract": "This paper establishes a formal equivalence between the architectural classes of modern agentic AI systems and the abstract machines of the Chomsky hierarchy. We posit that the memory architecture of an AI agent is the definitive feature determining its computational power and that it directly maps it to a corresponding class of automaton. Specifically, we demonstrate that simple reflex agents are equivalent to Finite Automata, hierarchical task-decomposition agents are equivalent to Pushdown Automata, and agents employing readable/writable memory for reflection are equivalent to TMs. This Automata-Agent Framework provides a principled methodology for right-sizing agent architectures to optimize computational efficiency and cost. More critically, it creates a direct pathway to formal verification, enables the application of mature techniques from automata theory to guarantee agent safety and predictability. By classifying agents, we can formally delineate the boundary between verifiable systems and those whose behavior is fundamentally undecidable. We address the inherent probabilistic nature of LLM-based agents by extending the framework to probabilistic automata that allow quantitative risk analysis. The paper concludes by outlining an agenda for developing static analysis tools and grammars for agentic frameworks.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "434",
        "title": "Yesnt: Are Diffusion Relighting Models Ready for Capture Stage Compositing? A Hybrid Alternative to Bridge the Gap",
        "author": [
            "Elisabeth JÃ¼ttner",
            "Leona Krath",
            "Stefan Korfhage",
            "Hannah DrÃ¶ge",
            "Matthias B. Hullin",
            "Markus Plack"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23494",
        "abstract": "Volumetric video relighting is essential for bringing captured performances into virtual worlds, but current approaches struggle to deliver temporally stable, production-ready results. Diffusion-based intrinsic decomposition methods show promise for single frames, yet suffer from stochastic noise and instability when extended to sequences, while video diffusion models remain constrained by memory and scale. We propose a hybrid relighting framework that combines diffusion-derived material priors with temporal regularization and physically motivated rendering. Our method aggregates multiple stochastic estimates of per-frame material properties into temporally consistent shading components, using optical-flow-guided regularization. For indirect effects such as shadows and reflections, we extract a mesh proxy from Gaussian Opacity Fields and render it within a standard graphics pipeline. Experiments on real and synthetic captures show that this hybrid strategy achieves substantially more stable relighting across sequences than diffusion-only baselines, while scaling beyond the clip lengths feasible for video diffusion. These results indicate that hybrid approaches, which balance learned priors with physically grounded constraints, are a practical step toward production-ready volumetric video relighting.",
        "tags": [
            "CLIP",
            "Diffusion"
        ]
    },
    {
        "id": "435",
        "title": "COOPERA: Continual Open-Ended Human-Robot Assistance",
        "author": [
            "Chenyang Ma",
            "Kai Lu",
            "Ruta Desai",
            "Xavier Puig",
            "Andrew Markham",
            "Niki Trigoni"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23495",
        "abstract": "To understand and collaborate with humans, robots must account for individual human traits, habits, and activities over time. However, most robotic assistants lack these abilities, as they primarily focus on predefined tasks in structured environments and lack a human model to learn from. This work introduces COOPERA, a novel framework for COntinual, OPen-Ended human-Robot Assistance, where simulated humans, driven by psychological traits and long-term intentions, interact with robots in complex environments. By integrating continuous human feedback, our framework, for the first time, enables the study of long-term, open-ended human-robot collaboration (HRC) in different collaborative tasks across various time-scales. Within COOPERA, we introduce a benchmark and an approach to personalize the robot's collaborative actions by learning human traits and context-dependent intents. Experiments validate the extent to which our simulated humans reflect realistic human behaviors and demonstrate the value of inferring and personalizing to human intents for open-ended and long-term HRC. Project Page: https://dannymcy.github.io/coopera/",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "436",
        "title": "VOLD: Reasoning Transfer from LLMs to Vision-Language Models via On-Policy Distillation",
        "author": [
            "Walid Bousselham",
            "Hilde Kuehne",
            "Cordelia Schmid"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23497",
        "abstract": "Training vision-language models (VLMs) for complex reasoning remains a challenging task, i.a. due to the scarcity of high-quality image-text reasoning data. Conversely, text-based reasoning resources are abundant and scalable, but it is still an open question how to leveraging them for VLM reasoning. To address this problem, we propose VOLD, a framework to transfer reasoning capabilities from text-only teacher models to VLM student models. To this end, VOLD combines reinforcement learning via Group Relative Policy Optimization (GRPO) with on-policy distillation, which allows the student reasoning traces to be guided by the teacher model, resulting in a significant gain over using GRPO alone. We further show that a cold-start alignment is essential for an effective transfer during the online training phase in this scenario and that without sufficient distributional alignment between teacher and student, on-policy distillation fails to provide meaningful guidance. We evaluate VOLD across diverse benchmarks including MMMU-Pro, MathVision, MathVista, and LogicVista, showing that VOLD outperforms the baseline model significantly and improves over the state of the art by a margin. Our ablation shows the importance of a cold-start alignment via SFT for on-policy distillation with a text-only teacher.",
        "tags": [
            "GRPO",
            "LLM",
            "RL",
            "VLM"
        ]
    },
    {
        "id": "437",
        "title": "Towards Deep Physics-Informed Kolmogorov-Arnold Networks",
        "author": [
            "Spyros Rigas",
            "Fotios Anagnostopoulos",
            "Michalis Papachristou",
            "Georgios Alexandridis"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23501",
        "abstract": "Since their introduction, Kolmogorov-Arnold Networks (KANs) have been successfully applied across several domains, with physics-informed machine learning (PIML) emerging as one of the areas where they have thrived. In the PIML setting, Chebyshev-based physics-informed KANs (cPIKANs) have become the standard due to their computational efficiency. However, like their multilayer perceptron-based counterparts, cPIKANs face significant challenges when scaled to depth, leading to training instabilities that limit their applicability to several PDE problems. To address this, we propose a basis-agnostic, Glorot-like initialization scheme that preserves activation variance and yields substantial improvements in stability and accuracy over the default initialization of cPIKANs. Inspired by the PirateNet architecture, we further introduce Residual-Gated Adaptive KANs (RGA KANs), designed to mitigate divergence in deep cPIKANs where initialization alone is not sufficient. Through empirical tests and information bottleneck analysis, we show that RGA KANs successfully traverse all training phases, unlike baseline cPIKANs, which stagnate in the diffusion phase in specific PDE settings. Evaluations on seven standard forward PDE benchmarks under a fixed training pipeline with adaptive components demonstrate that RGA KANs consistently outperform parameter-matched cPIKANs and PirateNets - often by several orders of magnitude - while remaining stable in settings where the others diverge.",
        "tags": [
            "Diffusion",
            "KAN"
        ]
    },
    {
        "id": "438",
        "title": "Bayes-Split-Edge: Bayesian Optimization for Constrained Collaborative Inference in Wireless Edge Systems",
        "author": [
            "Fatemeh Zahra Safaeipour",
            "Jacob Chakareski",
            "Morteza Hashemi"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23503",
        "abstract": "Mobile edge devices (e.g., AR/VR headsets) typically need to complete timely inference tasks while operating with limited on-board computing and energy resources. In this paper, we investigate the problem of collaborative inference in wireless edge networks, where energy-constrained edge devices aim to complete inference tasks within given deadlines. These tasks are carried out using neural networks, and the edge device seeks to optimize inference performance under energy and delay constraints. The inference process can be split between the edge device and an edge server, thereby achieving collaborative inference over wireless networks. We formulate an inference utility optimization problem subject to energy and delay constraints, and propose a novel solution called Bayes-Split-Edge, which leverages Bayesian optimization for collaborative split inference over wireless edge networks. Our solution jointly optimizes the transmission power and the neural network split point. The Bayes-Split-Edge framework incorporates a novel hybrid acquisition function that balances inference task utility, sample efficiency, and constraint violation penalties. We evaluate our approach using the VGG19 model on the ImageNet-Mini dataset, and Resnet101 on Tiny-ImageNet, and real-world mMobile wireless channel datasets. Numerical results demonstrate that Bayes-Split-Edge achieves up to 2.4x reduction in evaluation cost compared to standard Bayesian optimization and achieves near-linear convergence. It also outperforms several baselines, including CMA-ES, DIRECT, exhaustive search, and Proximal Policy Optimization (PPO), while matching exhaustive search performance under tight constraints. These results confirm that the proposed framework provides a sample-efficient solution requiring maximum 20 function evaluations and constraint-aware optimization for wireless split inference in edge computing systems.",
        "tags": [
            "PPO"
        ]
    },
    {
        "id": "439",
        "title": "Emotion-Coherent Reasoning for Multimodal LLMs via Emotional Rationale Verifier",
        "author": [
            "Hyeongseop Rha",
            "Jeong Hun Yeo",
            "Yeonju Kim",
            "Yong Man Ro"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23506",
        "abstract": "The recent advancement of Multimodal Large Language Models (MLLMs) is transforming human-computer interaction (HCI) from surface-level exchanges into more nuanced and emotionally intelligent communication. To realize this shift, emotion understanding becomes essential allowing systems to capture subtle cues underlying user intent. Furthermore, providing faithful explanations for predicted emotions is crucial to ensure interpretability and build user trust. However, current MLLM-based methods often generate emotion explanations that diverge from the target labels and sometimes even contradict their own predicted emotions. This inconsistency poses a critical risk for misunderstanding and erodes reliability in interactive settings. To address this, we propose a novel approach: the Emotional Rationale Verifier (ERV) and an Explanation Reward. Our method guides the model to produce reasoning that is explicitly consistent with the target emotion during multimodal emotion recognition without modifying the model architecture or requiring additional paired video-description annotations. Our method significantly improves faithful explanation-prediction consistency and explanation emotion accuracy on the MAFW and DFEW datasets. Through extensive experiments and human evaluations, we show that our approach not only enhances alignment between explanation and prediction but also empowers MLLMs to deliver emotionally coherent, trustworthy interactions, marking a key step toward truly human-like HCI systems.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "440",
        "title": "Deductive Chain-of-Thought Augmented Socially-aware Robot Navigation World Model",
        "author": [
            "Weizheng Wang",
            "Obi Ike",
            "Soyun Choi",
            "Sungeun Hong",
            "Byung-Cheol Min"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23509",
        "abstract": "Social robot navigation increasingly relies on large language models for reasoning, path planning, and enabling movement in dynamic human spaces. However, relying solely on LLMs for planning often leads to unpredictable and unsafe behaviors, especially in dynamic human spaces, due to limited physical grounding and weak logical consistency. In this work, we introduce NaviWM, a socially-aware robot Navigation World Model that augments LLM reasoning with a structured world model and a logic-driven chain-of-thought process. NaviWM consists of two main components: (1) a spatial-temporal world model that captures the positions, velocities, and activities of agents in the environment, and (2) a deductive reasoning module that guides LLMs through a multi-step, logic-based inference process. This integration enables the robot to generate navigation decisions that are both socially compliant and physically safe, under well-defined constraints such as personal space, collision avoidance, and timing. Unlike previous methods based on prompting or fine-tuning, NaviWM encodes social norms as first-order logic, enabling interpretable and verifiable reasoning. Experiments show that NaviWM improves success rates and reduces social violations, particularly in crowded environments. These results demonstrate the benefit of combining formal reasoning with LLMs for robust social navigation. Additional experimental details and demo videos for this work can be found at: https://sites.google.com/view/NaviWM.",
        "tags": [
            "CoT",
            "LLM",
            "Robotics"
        ]
    },
    {
        "id": "441",
        "title": "FreeFuse: Multi-Subject LoRA Fusion via Auto Masking at Test Time",
        "author": [
            "Yaoli Liu",
            "Yao-Xiang Ding",
            "Kun Zhou"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23515",
        "abstract": "This paper proposes FreeFuse, a novel training-free approach for multi-subject text-to-image generation through automatic fusion of multiple subject LoRAs. In contrast to existing methods that either focus on pre-inference LoRA weight merging or rely on segmentation models and complex techniques like noise blending to isolate LoRA outputs, our key insight is that context-aware dynamic subject masks can be automatically derived from cross-attention layer weights. Mathematical analysis shows that directly applying these masks to LoRA outputs during inference well approximates the case where the subject LoRA is integrated into the diffusion model and used individually for the masked region. FreeFuse demonstrates superior practicality and efficiency as it requires no additional training, no modification to LoRAs, no auxiliary models, and no user-defined prompt templates or region specifications. Alternatively, it only requires users to provide the LoRA activation words for seamless integration into standard workflows. Extensive experiments validate that FreeFuse outperforms existing approaches in both generation quality and usability under the multi-subject generation tasks. The project page is at https://future-item.github.io/FreeFuse/",
        "tags": [
            "Diffusion",
            "LoRA",
            "Segmentation",
            "Text-to-Image"
        ]
    },
    {
        "id": "442",
        "title": "Explicit Memory through Online 3D Gaussian Splatting Improves Class-Agnostic Video Segmentation",
        "author": [
            "Anthony Opipari",
            "Aravindhan K Krishnan",
            "Shreekant Gayaka",
            "Min Sun",
            "Cheng-Hao Kuo",
            "Arnie Sen",
            "Odest Chadwicke Jenkins"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23521",
        "abstract": "Remembering where object segments were predicted in the past is useful for improving the accuracy and consistency of class-agnostic video segmentation algorithms. Existing video segmentation algorithms typically use either no object-level memory (e.g. FastSAM) or they use implicit memories in the form of recurrent neural network features (e.g. SAM2). In this paper, we augment both types of segmentation models using an explicit 3D memory and show that the resulting models have more accurate and consistent predictions. For this, we develop an online 3D Gaussian Splatting (3DGS) technique to store predicted object-level segments generated throughout the duration of a video. Based on this 3DGS representation, a set of fusion techniques are developed, named FastSAM-Splat and SAM2-Splat, that use the explicit 3DGS memory to improve their respective foundation models' predictions. Ablation experiments are used to validate the proposed techniques' design and hyperparameter settings. Results from both real-world and simulated benchmarking experiments show that models which use explicit 3D memories result in more accurate and consistent predictions than those which use no memory or only implicit neural network memories. Project Page: https://topipari.com/projects/FastSAM-Splat/",
        "tags": [
            "3D",
            "Gaussian Splatting",
            "RNN",
            "Segmentation"
        ]
    },
    {
        "id": "443",
        "title": "When No Paths Lead to Rome: Benchmarking Systematic Neural Relational Reasoning",
        "author": [
            "Anirban Das",
            "Irtaza Khalid",
            "Rafael PeÃ±aloza",
            "Steven Schockaert"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23532",
        "abstract": "Designing models that can learn to reason in a systematic way is an important and long-standing challenge. In recent years, a wide range of solutions have been proposed for the specific case of systematic relational reasoning, including Neuro-Symbolic approaches, variants of the Transformer architecture, and specialised Graph Neural Networks. However, existing benchmarks for systematic relational reasoning focus on an overly simplified setting, based on the assumption that reasoning can be reduced to composing relational paths. In fact, this assumption is hard-baked into the architecture of several recent models, leading to approaches that can perform well on existing benchmarks but are difficult to generalise to other settings. To support further progress in the field of systematic relational reasoning with neural networks, we introduce NoRA, a new benchmark which adds several levels of difficulty and requires models to go beyond path-based reasoning.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "444",
        "title": "Sequential Multi-Agent Dynamic Algorithm Configuration",
        "author": [
            "Chen Lu",
            "Ke Xue",
            "Lei Yuan",
            "Yao Wang",
            "Yaoyuan Wang",
            "Sheng Fu",
            "Chao Qian"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23535",
        "abstract": "Dynamic algorithm configuration (DAC) is a recent trend in automated machine learning, which can dynamically adjust the algorithm's configuration during the execution process and relieve users from tedious trial-and-error tuning tasks. Recently, multi-agent reinforcement learning (MARL) approaches have improved the configuration of multiple heterogeneous hyperparameters, making various parameter configurations for complex algorithms possible. However, many complex algorithms have inherent inter-dependencies among multiple parameters (e.g., determining the operator type first and then the operator's parameter), which are, however, not considered in previous approaches, thus leading to sub-optimal results. In this paper, we propose the sequential multi-agent DAC (Seq-MADAC) framework to address this issue by considering the inherent inter-dependencies of multiple parameters. Specifically, we propose a sequential advantage decomposition network, which can leverage action-order information through sequential advantage decomposition. Experiments from synthetic functions to the configuration of multi-objective optimization algorithms demonstrate Seq-MADAC's superior performance over state-of-the-art MARL methods and show strong generalization across problem classes. Seq-MADAC establishes a new paradigm for the widespread dependency-aware automated algorithm configuration. Our code is available at https://github.com/lamda-bbo/seq-madac.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "445",
        "title": "IPQA: A Benchmark for Core Intent Identification in Personalized Question Answering",
        "author": [
            "Jieyong Kim",
            "Maryam Amirizaniani",
            "Soojin Yoon",
            "Dongha Lee"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23536",
        "abstract": "Intent identification serves as the foundation for generating appropriate responses in personalized question answering (PQA). However, existing benchmarks evaluate only response quality or retrieval performance without directly measuring intent identification capabilities. This gap is critical because without understanding which intents users prioritize, systems cannot generate responses satisfying individual information needs. To address this, we introduce the concept of core intents: intents users prioritize when selecting answers to satisfy their information needs. To evaluate these core intents, we propose IPQA, a benchmark for core Intent identification in Personalized Question Answering. Since users do not explicitly state their prioritized intents, we derive core intents from observable behavior patterns in answer selection, grounded in satisficing theory where users choose answers meeting their acceptance thresholds. We construct a dataset with various domains through systematic filtering, LLM-based annotation, and rigorous quality control combining automated verification with human validation. Experimental evaluations across state-of-the-art language models reveal that current systems struggle with core intent identification in personalized contexts. Models fail to identify core intents from user histories, with performance degrading as question complexity increases. The code and dataset will be made publicly available to facilitate future research in this direction.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "446",
        "title": "LimRank: Less is More for Reasoning-Intensive Information Reranking",
        "author": [
            "Tingyu Song",
            "Yilun Zhao",
            "Siyue Zhang",
            "Chen Zhao",
            "Arman Cohan"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23544",
        "abstract": "Existing approaches typically rely on large-scale fine-tuning to adapt LLMs for information reranking tasks, which is computationally expensive. In this work, we demonstrate that modern LLMs can be effectively adapted using only minimal, high-quality supervision. To enable this, we design LIMRANK-SYNTHESIZER, a reusable and open-source pipeline for generating diverse, challenging, and realistic reranking examples. Using this synthetic data, we fine-tune our reranker model, LIMRANK. We evaluate LIMRANK on two challenging benchmarks, i.e., BRIGHT for reasoning-intensive retrieval and FollowIR for instruction-following retrieval. Our experiments demonstrate that LIMRANK achieves competitive performance, while being trained on less than 5% of the data typically used in prior work. Further ablation studies demonstrate the effectiveness of LIMRANK-SYNTHESIZER and the strong generalization capabilities of LIMRANK across downstream tasks, including scientific literature search and retrieval-augmented generation for knowledge-intensive problem solving.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "447",
        "title": "A U-Net and Transformer Pipeline for Multilingual Image Translation",
        "author": [
            "Siddharth Sahay",
            "Radhika Agarwal"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23554",
        "abstract": "This paper presents an end-to-end multilingual translation pipeline that integrates a custom U-Net for text detection, the Tesseract engine for text recognition, and a from-scratch sequence-to-sequence (Seq2Seq) Transformer for Neural Machine Translation (NMT). Our approach first utilizes a U-Net model, trained on a synthetic dataset , to accurately segment and detect text regions from an image. These detected regions are then processed by Tesseract to extract the source text. This extracted text is fed into a custom Transformer model trained from scratch on a multilingual parallel corpus spanning 5 languages. Unlike systems reliant on monolithic pre-trained models, our architecture emphasizes full customization and adaptability. The system is evaluated on its text detection accuracy, text recognition quality, and translation performance via BLEU scores. The complete pipeline demonstrates promising results, validating the viability of a custom-built system for translating text directly from images.",
        "tags": [
            "Detection",
            "Transformer"
        ]
    },
    {
        "id": "448",
        "title": "ISA-Bench: Benchmarking Instruction Sensitivity for Large Audio Language Models",
        "author": [
            "Bohan Li",
            "Wenbin Huang",
            "Yuhang Qiu",
            "Yiwei Guo",
            "Hankun Wang",
            "Zhihan Li",
            "Jing Peng",
            "Ziyang Ma",
            "Xie Chen",
            "Kai Yu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23558",
        "abstract": "Large Audio Language Models (LALMs), which couple acoustic perception with large language models (LLMs) to extract and understand diverse information from audio, have attracted intense interest from both academic and industrial communities. However, existing LALMs are highly sensitive to how instructions are phrased, affecting both (i) instruction-following rates and (ii) task performance. Yet, no existing benchmarks offer a systematic and comprehensive evaluation of this sensitivity. We introduce ISA-Bench, a dynamic benchmark evaluating instruction sensitivity for LALMs along three axes: instruction description, output format, and task composition. We assess recent open-source and proprietary LALMs using ISA-Bench, profiling both compliance and accuracy under controlled instruction variations. Experimental results reveal that even state-of-the-art LALMs suffer significant instruction sensitivity, leading to degraded performance on fundamental audio understanding tasks. To mitigate this issue, we fine-tune Qwen2-Audio on a specifically constructed complex instruction-variant dataset, achieving a marked improvement in instruction-following performance. However, this also induces nontrivial catastrophic forgetting: the model loses some previously mastered task capabilities when exposed to new instruction styles. Our benchmark provides a standardized basis for assessing and improving instruction sensitivity in LALMs, underscoring the need for instruction-robust audio understanding in real-world pipelines.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "449",
        "title": "ReCode: Unify Plan and Action for Universal Granularity Control",
        "author": [
            "Zhaoyang Yu",
            "Jiayi Zhang",
            "Huixue Su",
            "Yufan Zhao",
            "Yifan Wu",
            "Mingyi Deng",
            "Jinyu Xiang",
            "Yizhang Lin",
            "Lingxiao Tang",
            "Yingchao Li",
            "Yuyu Luo",
            "Bang Liu",
            "Chenglin Wu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23564",
        "abstract": "Real-world tasks require decisions at varying granularities, and humans excel at this by leveraging a unified cognitive representation where planning is fundamentally understood as a high-level form of action. However, current Large Language Model (LLM)-based agents lack this crucial capability to operate fluidly across decision granularities. This limitation stems from existing paradigms that enforce a rigid separation between high-level planning and low-level action, which impairs dynamic adaptability and limits generalization. We propose ReCode (Recursive Code Generation), a novel paradigm that addresses this limitation by unifying planning and action within a single code representation. In this representation, ReCode treats high-level plans as abstract placeholder functions, which the agent then recursively decomposes into finer-grained sub-functions until reaching primitive actions. This recursive approach dissolves the rigid boundary between plan and action, enabling the agent to dynamically control its decision granularity. Furthermore, the recursive structure inherently generates rich, multi-granularity training data, enabling models to learn hierarchical decision-making processes. Extensive experiments show ReCode significantly surpasses advanced baselines in inference performance and demonstrates exceptional data efficiency in training, validating our core insight that unifying planning and action through recursive code generation is a powerful and effective approach to achieving universal granularity control. The code is available at https://github.com/FoundationAgents/ReCode.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "450",
        "title": "EgoThinker: Unveiling Egocentric Reasoning with Spatio-Temporal CoT",
        "author": [
            "Baoqi Pei",
            "Yifei Huang",
            "Jilan Xu",
            "Yuping He",
            "Guo Chen",
            "Fei Wu",
            "Yu Qiao",
            "Jiangmiao Pang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23569",
        "abstract": "Egocentric video reasoning centers on an unobservable agent behind the camera who dynamically shapes the environment, requiring inference of hidden intentions and recognition of fine-grained interactions. This core challenge limits current multimodal large language models MLLMs, which excel at visible event reasoning but lack embodied, first-person understanding. To bridge this gap, we introduce EgoThinker, a novel framework that endows MLLMs with robust egocentric reasoning capabilities through spatio-temporal chain-of-thought supervision and a two-stage learning curriculum. First, we introduce EgoRe-5M, a large-scale egocentric QA dataset constructed from 13M diverse egocentric video clips. This dataset features multi-minute segments annotated with detailed CoT rationales and dense hand-object grounding. Second, we employ SFT on EgoRe-5M to instill reasoning skills, followed by reinforcement fine-tuning RFT to further enhance spatio-temporal localization. Experimental results show that EgoThinker outperforms existing methods across multiple egocentric benchmarks, while achieving substantial improvements in fine-grained spatio-temporal localization tasks. Full code and data are released at https://github.com/InternRobotics/EgoThinker.",
        "tags": [
            "CoT",
            "LLM"
        ]
    },
    {
        "id": "451",
        "title": "RobotArena $\\infty$: Scalable Robot Benchmarking via Real-to-Sim Translation",
        "author": [
            "Yash Jangir",
            "Yidi Zhang",
            "Kashu Yamazaki",
            "Chenyu Zhang",
            "Kuan-Hsun Tu",
            "Tsung-Wei Ke",
            "Lei Ke",
            "Yonatan Bisk",
            "Katerina Fragkiadaki"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23571",
        "abstract": "The pursuit of robot generalists - instructable agents capable of performing diverse tasks across diverse environments - demands rigorous and scalable evaluation. Yet real-world testing of robot policies remains fundamentally constrained: it is labor-intensive, slow, unsafe at scale, and difficult to reproduce. Existing simulation benchmarks are similarly limited, as they train and test policies within the same synthetic domains and cannot assess models trained from real-world demonstrations or alternative simulation environments. As policies expand in scope and complexity, these barriers only intensify, since defining \"success\" in robotics often hinges on nuanced human judgments of execution quality. In this paper, we introduce a new benchmarking framework that overcomes these challenges by shifting VLA evaluation into large-scale simulated environments augmented with online human feedback. Leveraging advances in vision-language models, 2D-to-3D generative modeling, and differentiable rendering, our approach automatically converts video demonstrations from widely used robot datasets into simulated counterparts. Within these digital twins, we assess VLA policies using both automated VLM-guided scoring and scalable human preference judgments collected from crowdworkers, transforming human involvement from tedious scene setup, resetting, and safety supervision into lightweight preference comparisons. To measure robustness, we systematically perturb simulated environments along multiple axes, such as textures and object placements, stress-testing policy generalization under controlled variation. The result is a continuously evolving, reproducible, and scalable benchmark for real-world trained robot manipulation policies, addressing a critical missing capability in today's robotics landscape.",
        "tags": [
            "3D",
            "Robotics",
            "VLM"
        ]
    },
    {
        "id": "452",
        "title": "More Than Generation: Unifying Generation and Depth Estimation via Text-to-Image Diffusion Models",
        "author": [
            "Hongkai Lin",
            "Dingkang Liang",
            "Mingyang Du",
            "Xin Zhou",
            "Xiang Bai"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23574",
        "abstract": "Generative depth estimation methods leverage the rich visual priors stored in pre-trained text-to-image diffusion models, demonstrating astonishing zero-shot capability. However, parameter updates during training lead to catastrophic degra- dation in the image generation capability of the pre-trained model. We introduce MERGE, a unified model for image generation and depth estimation, starting from a fixed pre-trained text-to-image model. MERGE demonstrates that the pre-trained text-to-image model can do more than image generation, but also expand to depth estimation effortlessly. Specifically, MERGE introduces a play- and-plug framework that enables seamless switching between image generation and depth estimation modes through simple and pluggable converters. Meanwhile, we propose a Group Reuse Mechanism to encourage parameter reuse and im- prove the utilization of the additional learnable parameters. MERGE unleashes the powerful depth estimation capability of the pre-trained text-to-image model while preserving its original image generation ability. Compared to other unified models for image generation and depth estimation, MERGE achieves state-of- the-art performance across multiple depth estimation benchmarks. The code will be made available at https://github.com/H-EmbodVis/MERGE",
        "tags": [
            "Depth Estimation",
            "Diffusion",
            "Text-to-Image"
        ]
    },
    {
        "id": "453",
        "title": "UrbanVLA: A Vision-Language-Action Model for Urban Micromobility",
        "author": [
            "Anqi Li",
            "Zhiyong Wang",
            "Jiazhao Zhang",
            "Minghan Li",
            "Yunpeng Qi",
            "Zhibo Chen",
            "Zhizheng Zhang",
            "He Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23576",
        "abstract": "Urban micromobility applications, such as delivery robots, demand reliable navigation across large-scale urban environments while following long-horizon route instructions. This task is particularly challenging due to the dynamic and unstructured nature of real-world city areas, yet most existing navigation methods remain tailored to short-scale and controllable scenarios. Effective urban micromobility requires two complementary levels of navigation skills: low-level capabilities such as point-goal reaching and obstacle avoidance, and high-level capabilities, such as route-visual alignment. To this end, we propose UrbanVLA, a route-conditioned Vision-Language-Action (VLA) framework designed for scalable urban navigation. Our method explicitly aligns noisy route waypoints with visual observations during execution, and subsequently plans trajectories to drive the robot. To enable UrbanVLA to master both levels of navigation, we employ a two-stage training pipeline. The process begins with Supervised Fine-Tuning (SFT) using simulated environments and trajectories parsed from web videos. This is followed by Reinforcement Fine-Tuning (RFT) on a mixture of simulation and real-world data, which enhances the model's safety and adaptability in real-world settings. Experiments demonstrate that UrbanVLA surpasses strong baselines by more than 55% in the SocialNav task on MetaUrban. Furthermore, UrbanVLA achieves reliable real-world navigation, showcasing both scalability to large-scale urban environments and robustness against real-world uncertainties.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "454",
        "title": "Reduced AI Acceptance After the Generative AI Boom: Evidence From a Two-Wave Survey Study",
        "author": [
            "Joachim Baumann",
            "Aleksandra Urman",
            "Ulrich Leicht-Deobald",
            "Zachary J. Roman",
            "AnikÃ³ HannÃ¡k",
            "Markus Christen"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23578",
        "abstract": "The rapid adoption of generative artificial intelligence (GenAI) technologies has led many organizations to integrate AI into their products and services, often without considering user preferences. Yet, public attitudes toward AI use, especially in impactful decision-making scenarios, are underexplored. Using a large-scale two-wave survey study (n_wave1=1514, n_wave2=1488) representative of the Swiss population, we examine shifts in public attitudes toward AI before and after the launch of ChatGPT. We find that the GenAI boom is significantly associated with reduced public acceptance of AI (see Figure 1) and increased demand for human oversight in various decision-making contexts. The proportion of respondents finding AI \"not acceptable at all\" increased from 23% to 30%, while support for human-only decision-making rose from 18% to 26%. These shifts have amplified existing social inequalities in terms of widened educational, linguistic, and gender gaps post-boom. Our findings challenge industry assumptions about public readiness for AI deployment and highlight the critical importance of aligning technological development with evolving public preferences.",
        "tags": [
            "GPT"
        ]
    },
    {
        "id": "455",
        "title": "Hope Speech Detection in Social Media English Corpora: Performance of Traditional and Transformer Models",
        "author": [
            "Luis Ramos",
            "Hiram Calvo",
            "Olga Kolesnikova"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23585",
        "abstract": "The identification of hope speech has become a promised NLP task, considering the need to detect motivational expressions of agency and goal-directed behaviour on social media platforms. This proposal evaluates traditional machine learning models and fine-tuned transformers for a previously split hope speech dataset as train, development and test set. On development test, a linear-kernel SVM and logistic regression both reached a macro-F1 of 0.78; SVM with RBF kernel reached 0.77, and NaÃ¯ve Bayes hit 0.75. Transformer models delivered better results, the best model achieved weighted precision of 0.82, weighted recall of 0.80, weighted F1 of 0.79, macro F1 of 0.79, and 0.80 accuracy. These results suggest that while optimally configured traditional machine learning models remain agile, transformer architectures detect some subtle semantics of hope to achieve higher precision and recall in hope speech detection, suggesting that larges transformers and LLMs could perform better in small datasets.",
        "tags": [
            "Detection",
            "LLM",
            "Transformer"
        ]
    },
    {
        "id": "456",
        "title": "A Survey of Data Agents: Emerging Paradigm or Overstated Hype?",
        "author": [
            "Yizhang Zhu",
            "Liangwei Wang",
            "Chenyu Yang",
            "Xiaotian Lin",
            "Boyan Li",
            "Wei Zhou",
            "Xinyu Liu",
            "Zhangyang Peng",
            "Tianqi Luo",
            "Yu Li",
            "Chengliang Chai",
            "Chong Chen",
            "Shimin Di",
            "Ju Fan",
            "Ji Sun",
            "Nan Tang",
            "Fugee Tsung",
            "Jiannan Wang",
            "Chenglin Wu",
            "Yanwei Xu",
            "Shaolei Zhang",
            "Yong Zhang",
            "Xuanhe Zhou",
            "Guoliang Li",
            "Yuyu Luo"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23587",
        "abstract": "The rapid advancement of large language models (LLMs) has spurred the emergence of data agents--autonomous systems designed to orchestrate Data + AI ecosystems for tackling complex data-related tasks. However, the term \"data agent\" currently suffers from terminological ambiguity and inconsistent adoption, conflating simple query responders with sophisticated autonomous architectures. This terminological ambiguity fosters mismatched user expectations, accountability challenges, and barriers to industry growth. Inspired by the SAE J3016 standard for driving automation, this survey introduces the first systematic hierarchical taxonomy for data agents, comprising six levels that delineate and trace progressive shifts in autonomy, from manual operations (L0) to a vision of generative, fully autonomous data agents (L5), thereby clarifying capability boundaries and responsibility allocation. Through this lens, we offer a structured review of existing research arranged by increasing autonomy, encompassing specialized data agents for data management, preparation, and analysis, alongside emerging efforts toward versatile, comprehensive systems with enhanced autonomy. We further analyze critical evolutionary leaps and technical gaps for advancing data agents, especially the ongoing L2-to-L3 transition, where data agents evolve from procedural execution to autonomous orchestration. Finally, we conclude with a forward-looking roadmap, envisioning the advent of proactive, generative data agents.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "457",
        "title": "FARMER: Flow AutoRegressive Transformer over Pixels",
        "author": [
            "Guangting Zheng",
            "Qinyu Zhao",
            "Tao Yang",
            "Fei Xiao",
            "Zhijie Lin",
            "Jie Wu",
            "Jiajun Deng",
            "Yanyong Zhang",
            "Rui Zhu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23588",
        "abstract": "Directly modeling the explicit likelihood of the raw data distribution is key topic in the machine learning area, which achieves the scaling successes in Large Language Models by autoregressive modeling. However, continuous AR modeling over visual pixel data suffer from extremely long sequences and high-dimensional spaces. In this paper, we present FARMER, a novel end-to-end generative framework that unifies Normalizing Flows (NF) and Autoregressive (AR) models for tractable likelihood estimation and high-quality image synthesis directly from raw pixels. FARMER employs an invertible autoregressive flow to transform images into latent sequences, whose distribution is modeled implicitly by an autoregressive model. To address the redundancy and complexity in pixel-level modeling, we propose a self-supervised dimension reduction scheme that partitions NF latent channels into informative and redundant groups, enabling more effective and efficient AR modeling. Furthermore, we design a one-step distillation scheme to significantly accelerate inference speed and introduce a resampling-based classifier-free guidance algorithm to boost image generation quality. Extensive experiments demonstrate that FARMER achieves competitive performance compared to existing pixel-based generative models while providing exact likelihoods and scalable training.",
        "tags": [
            "LLM",
            "Normalizing Flows",
            "Transformer"
        ]
    },
    {
        "id": "458",
        "title": "InFlux: A Benchmark for Self-Calibration of Dynamic Intrinsics of Video Cameras",
        "author": [
            "Erich Liang",
            "Roma Bhattacharjee",
            "Sreemanti Dey",
            "Rafael Moschopoulos",
            "Caitlin Wang",
            "Michel Liao",
            "Grace Tan",
            "Andrew Wang",
            "Karhan Kayan",
            "Stamatis Alexandropoulos",
            "Jia Deng"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23589",
        "abstract": "Accurately tracking camera intrinsics is crucial for achieving 3D understanding from 2D video. However, most 3D algorithms assume that camera intrinsics stay constant throughout a video, which is often not true for many real-world in-the-wild videos. A major obstacle in this field is a lack of dynamic camera intrinsics benchmarks--existing benchmarks typically offer limited diversity in scene content and intrinsics variation, and none provide per-frame intrinsic changes for consecutive video frames. In this paper, we present Intrinsics in Flux (InFlux), a real-world benchmark that provides per-frame ground truth intrinsics annotations for videos with dynamic intrinsics. Compared to prior benchmarks, InFlux captures a wider range of intrinsic variations and scene diversity, featuring 143K+ annotated frames from 386 high-resolution indoor and outdoor videos with dynamic camera intrinsics. To ensure accurate per-frame intrinsics, we build a comprehensive lookup table of calibration experiments and extend the Kalibr toolbox to improve its accuracy and robustness. Using our benchmark, we evaluate existing baseline methods for predicting camera intrinsics and find that most struggle to achieve accurate predictions on videos with dynamic intrinsics. For the dataset, code, videos, and submission, please visit https://influx.cs.princeton.edu/.",
        "tags": [
            "3D",
            "FLUX"
        ]
    },
    {
        "id": "459",
        "title": "Lightweight Robust Direct Preference Optimization",
        "author": [
            "Cheol Woo Kim",
            "Shresth Verma",
            "Mauricio Tec",
            "Milind Tambe"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23590",
        "abstract": "Direct Preference Optimization (DPO) has become a popular method for fine-tuning large language models (LLMs) due to its stability and simplicity. However, it is also known to be sensitive to noise in the data and prone to overfitting. Recent works have proposed using distributionally robust optimization (DRO) to address potential noise and distributional shift in the data. However, these methods often suffer from excessive conservatism and high computational cost. We propose DPO-PRO (DPO with Preference Robustness), a robust fine-tuning algorithm based on DPO which accounts for uncertainty in the preference distribution through a lightweight DRO formulation. Unlike prior DRO-based variants, DPO-PRO focuses solely on uncertainty in preferences, avoiding unnecessary conservatism and incurring negligible computational overhead. We further show that DPO-PRO is equivalent to a regularized DPO objective that penalizes model overconfidence under weak preference signals. We evaluate DPO-PRO on standard alignment benchmarks and a real-world public health task. Experimental results show that our method consistently improves robustness to noisy preference signals compared to existing DPO variants.",
        "tags": [
            "DPO",
            "LLM"
        ]
    },
    {
        "id": "460",
        "title": "PRISM-Bench: A Benchmark of Puzzle-Based Visual Tasks with CoT Error Detection",
        "author": [
            "Yusu Qian",
            "Cheng Wan",
            "Chao Jia",
            "Yinfei Yang",
            "Qingyu Zhao",
            "Zhe Gan"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23594",
        "abstract": "We introduce \\textbf{PRISM-Bench}, a benchmark of puzzle-based visual challenges designed to evaluate not only whether models can solve problems, but how their reasoning unfolds. Unlike prior evaluations that measure only final-answer accuracy, PRISM-Bench introduces a diagnostic task: given a visual puzzle and a step-by-step chain-of-thought (CoT) containing exactly one error, models must identify the first incorrect step. This setting enables fine-grained assessment of logical consistency, error detection, and visual reasoning. The puzzles in PRISM-Bench require multi-step symbolic, geometric, and analogical reasoning, resisting shortcuts based on superficial pattern matching. Evaluations across state-of-the-art MLLMs reveal a persistent gap between fluent generation and faithful reasoning: models that produce plausible CoTs often fail to locate simple logical faults. By disentangling answer generation from reasoning verification, PRISM-Bench offers a sharper lens on multimodal reasoning competence and underscores the need for diagnostic evaluation protocols in the development of trustworthy MLLMs.",
        "tags": [
            "CoT",
            "Detection"
        ]
    },
    {
        "id": "461",
        "title": "Multi-Agent Evolve: LLM Self-Improve through Co-evolution",
        "author": [
            "Yixing Chen",
            "Yiding Wang",
            "Siqi Zhu",
            "Haofei Yu",
            "Tao Feng",
            "Muhan Zhan",
            "Mostofa Patwary",
            "Jiaxuan You"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23595",
        "abstract": "Reinforcement Learning (RL) has demonstrated significant potential in enhancing the reasoning capabilities of large language models (LLMs). However, the success of RL for LLMs heavily relies on human-curated datasets and verifiable rewards, which limit their scalability and generality. Recent Self-Play RL methods, inspired by the success of the paradigm in games and Go, aim to enhance LLM reasoning capabilities without human-annotated data. However, their methods primarily depend on a grounded environment for feedback (e.g., a Python interpreter or a game engine); extending them to general domains remains challenging. To address these challenges, we propose Multi-Agent Evolve (MAE), a framework that enables LLMs to self-evolve in solving diverse tasks, including mathematics, reasoning, and general knowledge Q&A. The core design of MAE is based on a triplet of interacting agents (Proposer, Solver, Judge) that are instantiated from a single LLM, and applies reinforcement learning to optimize their behaviors. The Proposer generates questions, the Solver attempts solutions, and the Judge evaluates both while co-evolving. Experiments on Qwen2.5-3B-Instruct demonstrate that MAE achieves an average improvement of 4.54% on multiple benchmarks. These results highlight MAE as a scalable, data-efficient method for enhancing the general reasoning abilities of LLMs with minimal reliance on human-curated supervision.",
        "tags": [
            "LLM",
            "RL"
        ]
    },
    {
        "id": "462",
        "title": "Think Twice: Branch-and-Rethink Reasoning Reward Model",
        "author": [
            "Yizhu Jiao",
            "Jiaqi Zeng",
            "Julien Veron Vialard",
            "Oleksii Kuchaiev",
            "Jiawei Han",
            "Olivier Delalleau"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23596",
        "abstract": "Large language models (LLMs) increasingly rely on thinking models that externalize intermediate steps and allocate extra test-time compute, with think-twice strategies showing that a deliberate second pass can elicit stronger reasoning. In contrast, most reward models (RMs) still compress many quality dimensions into a single scalar in one shot, a design that induces judgment diffusion: attention spreads across evaluation criteria, yielding diluted focus and shallow analysis. We introduce branch-and-rethink (BR-RM), a two-turn RM that transfers the think-twice principle to reward modeling. Turn 1 performs adaptive branching, selecting a small set of instance-critical dimensions (such as factuality and safety) and sketching concise, evidence-seeking hypotheses. Turn 2 executes branch-conditioned rethinking, a targeted reread that tests those hypotheses and scrutinizes only what matters most. We train with GRPO-style reinforcement learning over structured two-turn traces using a simple binary outcome reward with strict format checks, making the approach compatible with standard RLHF pipelines. By converting all-at-oncescoringintofocused, second-lookreasoning, BR-RMreducesjudgmentdiffusionandimproves sensitivity to subtle yet consequential errors while remaining practical and scalable. Experimental results demonstrate that our model achieves state-of-the-art performance on three challenging reward modeling benchmarks across diverse domains. The code and the model will be released soon.",
        "tags": [
            "Diffusion",
            "GRPO",
            "LLM",
            "RL",
            "RLHF"
        ]
    },
    {
        "id": "463",
        "title": "Alita-G: Self-Evolving Generative Agent for Agent Generation",
        "author": [
            "Jiahao Qiu",
            "Xuan Qi",
            "Hongru Wang",
            "Xinzhe Juan",
            "Yimin Wang",
            "Zelin Zhao",
            "Jiayi Geng",
            "Jiacheng Guo",
            "Peihang Li",
            "Jingzhe Shi",
            "Shilong Liu",
            "Mengdi Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23601",
        "abstract": "Large language models (LLMs) have been shown to perform better when scaffolded into agents with memory, tools, and feedback. Beyond this, self-evolving agents have emerged, but current work largely limits adaptation to prompt rewriting or failure retries. Therefore, we present ALITA-G, a self-evolution framework that transforms a general-purpose agent into a domain expert by systematically generating, abstracting, and curating Model Context Protocol (MCP) tools. In this framework, a generalist agent executes a curated suite of target-domain tasks and synthesizes candidate MCPs from successful trajectories. These are then abstracted to parameterized primitives and consolidated into an MCP Box. At inference time, ALITA-G performs retrieval-augmented MCP selection with the help of each tool's descriptions and use cases, before executing an agent equipped with the MCP Executor. Across several benchmarks GAIA, PathVQA, and Humanity's Last Exam, ALITA-G attains strong gains while reducing computation costs. On GAIA validation, it achieves 83.03% pass@1 and 89.09% pass@3, establishing a new state-of-the-art result while reducing mean tokens per example by approximately 15% relative to a strong baseline agent. ALITA-G thus provides a principled pathway from generalist capability to reusable, domain-specific competence, improving both accuracy and efficiency on complex reasoning tasks.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "464",
        "title": "PixelRefer: A Unified Framework for Spatio-Temporal Object Referring with Arbitrary Granularity",
        "author": [
            "Yuqian Yuan",
            "Wenqiao Zhang",
            "Xin Li",
            "Shihao Wang",
            "Kehan Li",
            "Wentong Li",
            "Jun Xiao",
            "Lei Zhang",
            "Beng Chin Ooi"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23603",
        "abstract": "Multimodal large language models (MLLMs) have demonstrated strong general-purpose capabilities in open-world visual comprehension. However, most existing MLLMs primarily focus on holistic, scene-level understanding, often overlooking the need for fine-grained, object-centric reasoning. In this paper, we present PixelRefer, a unified region-level MLLM framework that enables advanced fine-grained understanding over user-specified regions across both images and videos. Motivated by the observation that LLM attention predominantly focuses on object-level tokens, we propose a Scale-Adaptive Object Tokenizer (SAOT) to generate compact and semantically rich object representations from free-form regions. Our analysis reveals that global visual tokens contribute mainly in early LLM layers, inspiring the design of PixelRefer-Lite, an efficient variant that employs an Object-Centric Infusion module to pre-fuse global context into object tokens. This yields a lightweight Object-Only Framework that substantially reduces computational cost while maintaining high semantic fidelity. To facilitate fine-grained instruction tuning, we curate PixelRefer-2.2M, a high-quality object-centric instruction dataset. Extensive experiments across a range of benchmarks validate that PixelRefer achieves leading performance with fewer training samples, while PixelRefer-Lite offers competitive accuracy with notable gains in efficiency.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "465",
        "title": "Variational Masked Diffusion Models",
        "author": [
            "Yichi Zhang",
            "Alex Schwing",
            "Zhizhen Zhao"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23606",
        "abstract": "Masked diffusion models have recently emerged as a flexible framework for discrete generative modeling. However, a key limitation of standard masked diffusion is its inability to effectively capture dependencies among tokens that are predicted concurrently, leading to degraded generation quality when dependencies among tokens are important. To explicitly model dependencies among tokens, we propose Variational Masked Diffusion (VMD), a framework that introduces latent variables into the masked diffusion process. Through controlled experiments on synthetic datasets, we demonstrate that VMD successfully learns dependencies that conventional masked diffusion fails to capture. We further validate the effectiveness of our approach on Sudoku puzzles and text datasets, where learning of dependencies among tokens improves global consistency. Across these domains, VMD enhances both generation quality and dependency awareness, highlighting the value of integrating variational inference into masked diffusion. Our code is available at: https://riccizz.github.io/VMD.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "466",
        "title": "Concerto: Joint 2D-3D Self-Supervised Learning Emerges Spatial Representations",
        "author": [
            "Yujia Zhang",
            "Xiaoyang Wu",
            "Yixing Lao",
            "Chengyao Wang",
            "Zhuotao Tian",
            "Naiyan Wang",
            "Hengshuang Zhao"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23607",
        "abstract": "Humans learn abstract concepts through multisensory synergy, and once formed, such representations can often be recalled from a single modality. Inspired by this principle, we introduce Concerto, a minimalist simulation of human concept learning for spatial cognition, combining 3D intra-modal self-distillation with 2D-3D cross-modal joint embedding. Despite its simplicity, Concerto learns more coherent and informative spatial features, as demonstrated by zero-shot visualizations. It outperforms both standalone SOTA 2D and 3D self-supervised models by 14.2% and 4.8%, respectively, as well as their feature concatenation, in linear probing for 3D scene perception. With full fine-tuning, Concerto sets new SOTA results across multiple scene understanding benchmarks (e.g., 80.7% mIoU on ScanNet). We further present a variant of Concerto tailored for video-lifted point cloud spatial understanding, and a translator that linearly projects Concerto representations into CLIP's language space, enabling open-world perception. These results highlight that Concerto emerges spatial representations with superior fine-grained geometric and semantic consistency.",
        "tags": [
            "3D",
            "CLIP"
        ]
    },
    {
        "id": "467",
        "title": "DialoSpeech: Dual-Speaker Dialogue Generation with LLM and Flow Matching",
        "author": [
            "Hanke Xie",
            "Dake Guo",
            "Chengyou Wang",
            "Yue Li",
            "Wenjie Tian",
            "Xinfa Zhu",
            "Xinsheng Wang",
            "Xiulin Li",
            "Guanqiong Miao",
            "Bo Liu",
            "Lei Xie"
        ],
        "pdf": "https://arxiv.org/pdf/2510.08373",
        "abstract": "Recent advances in text-to-speech (TTS) synthesis, particularly those leveraging large language models (LLMs), have significantly improved expressiveness and naturalness. However, generating human-like, interactive dialogue speech remains challenging. Current systems face limitations due to the scarcity of dual-track data and difficulties in achieving naturalness, contextual coherence, and interactional dynamics, such as turn-taking, overlapping speech, and speaker consistency, in multi-turn conversations. To address these challenges, we propose DialoSpeech, a dual-track architecture combining a large language model with Chunked Flow Matching for expressive, human-like dialogue speech synthesis. DialoSpeech generates natural multi-turn conversations with coherent speaker turns and natural overlaps, supporting both Chinese and English and cross-lingual speech synthesis. We introduce a data processing pipeline to construct dual-track dialogue datasets, facilitating scalable training and experimental validation. Experiments show that our model outperforms baselines, offering a solution for generating human-like spoken dialogues. Audio samples are available at https://tiamojames.github.io/DialoSpeech",
        "tags": [
            "Flow Matching",
            "LLM"
        ]
    },
    {
        "id": "468",
        "title": "Right Place, Right Time: Market Simulation-based RL for Execution Optimisation",
        "author": [
            "Ollie Olby",
            "Andreea Bacalum",
            "Rory Baggott",
            "Namid Stillman"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22206",
        "abstract": "Execution algorithms are vital to modern trading, they enable market participants to execute large orders while minimising market impact and transaction costs. As these algorithms grow more sophisticated, optimising them becomes increasingly challenging. In this work, we present a reinforcement learning (RL) framework for discovering optimal execution strategies, evaluated within a reactive agent-based market simulator. This simulator creates reactive order flow and allows us to decompose slippage into its constituent components: market impact and execution risk. We assess the RL agent's performance using the efficient frontier based on work by Almgren and Chriss, measuring its ability to balance risk and cost. Results show that the RL-derived strategies consistently outperform baselines and operate near the efficient frontier, demonstrating a strong ability to optimise for risk and impact. These findings highlight the potential of reinforcement learning as a powerful tool in the trader's toolkit.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "469",
        "title": "Reinforcement learning-guided optimization of critical current in high-temperature superconductors",
        "author": [
            "Mouyang Cheng",
            "Qiwei Wan",
            "Bowen Yu",
            "Eunbi Rha",
            "Michael J Landry",
            "Mingda Li"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22424",
        "abstract": "High-temperature superconductors are essential for next-generation energy and quantum technologies, yet their performance is often limited by the critical current density ($J_c$), which is strongly influenced by microstructural defects. Optimizing $J_c$ through defect engineering is challenging due to the complex interplay of defect type, density, and spatial correlation. Here we present an integrated workflow that combines reinforcement learning (RL) with time-dependent Ginzburg-Landau (TDGL) simulations to autonomously identify optimal defect configurations that maximize $J_c$. In our framework, TDGL simulations generate current-voltage characteristics to evaluate $J_c$, which serves as the reward signal that guides the RL agent to iteratively refine defect configurations. We find that the agent discovers optimal defect densities and correlations in two-dimensional thin-film geometries, enhancing vortex pinning and $J_c$ relative to the pristine thin-film, approaching 60\\% of theoretical depairing limit with up to 15-fold enhancement compared to random initialization. This RL-driven approach provides a scalable strategy for defect engineering, with broad implications for advancing HTS applications in fusion magnets, particle accelerators, and other high-field technologies.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "470",
        "title": "Multi-Modal Masked Autoencoders for Learning Image-Spectrum Associations for Galaxy Evolution and Cosmology",
        "author": [
            "Morgan Himes",
            "Samiksha Krishnamurthy",
            "Andrew Lizarraga",
            "Srinath Saikrishnan",
            "Vikram Seenivasan",
            "Jonathan Soriano",
            "Ying Nian Wu",
            "Tuan Do"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22527",
        "abstract": "Upcoming surveys will produce billions of galaxy images but comparatively few spectra, motivating models that learn cross-modal representations. We build a dataset of 134,533 galaxy images (HSC-PDR2) and spectra (DESI-DR1) and adapt a Multi-Modal Masked Autoencoder (MMAE) to embed both images and spectra in a shared representation. The MMAE is a transformer-based architecture, which we train by masking 75% of the data and reconstructing missing image and spectral tokens. We use this model to test three applications: spectral and image reconstruction from heavily masked data and redshift regression from images alone. It recovers key physical features, such as galaxy shapes, atomic emission line peaks, and broad continuum slopes, though it struggles with fine image details and line strengths. For redshift regression, the MMAE performs comparably or better than prior multi-modal models in terms of prediction scatter even when missing spectra in testing. These results highlight both the potential and limitations of masked autoencoders in astrophysics and motivate extensions to additional modalities, such as text, for foundation models.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "471",
        "title": "UltraVoice: Scaling Fine-Grained Style-Controlled Speech Conversations for Spoken Dialogue Models",
        "author": [
            "Wenming Tu",
            "Guanrou Yang",
            "Ruiqi Yan",
            "Wenxi Chen",
            "Ziyang Ma",
            "Yipeng Kang",
            "Kai Yu",
            "Xie Chen",
            "Zilong Zheng"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22588",
        "abstract": "Spoken dialogue models currently lack the ability for fine-grained speech style control, a critical capability for human-like interaction that is often overlooked in favor of purely functional capabilities like reasoning and question answering. To address this limitation, we introduce UltraVoice, the first large-scale speech dialogue dataset engineered for multiple fine-grained speech style control. Encompassing over 830 hours of speech dialogues, UltraVoice provides instructions across six key speech stylistic dimensions: emotion, speed, volume, accent, language, and composite styles. Fine-tuning leading models such as SLAM-Omni and VocalNet on UltraVoice significantly enhances their fine-grained speech stylistic controllability without degrading core conversational abilities. Specifically, our fine-tuned models achieve improvements of 29.12-42.33% in Mean Opinion Score (MOS) and 14.61-40.09 percentage points in Instruction Following Rate (IFR) on multi-dimensional control tasks designed in the UltraVoice. Moreover, on the URO-Bench benchmark, our fine-tuned models demonstrate substantial gains in core understanding, reasoning, and conversational abilities, with average improvements of +10.84% on the Basic setting and +7.87% on the Pro setting. Furthermore, the dataset's utility extends to training controllable Text-to-Speech (TTS) models, underscoring its high quality and broad applicability for expressive speech synthesis. The complete dataset and model checkpoints are available at: https://github.com/bigai-nlco/UltraVoice.",
        "tags": [
            "SLAM"
        ]
    },
    {
        "id": "472",
        "title": "Mitigating Attention Sinks and Massive Activations in Audio-Visual Speech Recognition with LLMS",
        "author": [
            "Anand",
            "Umberto Cappellazzo",
            "Stavros Petridis",
            "Maja Pantic"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22603",
        "abstract": "Large language models (LLMs) have recently advanced auditory speech recognition (ASR), visual speech recognition (VSR), and audio-visual speech recognition (AVSR). However, understanding of their internal dynamics under fine-tuning remains limited. In natural language processing, recent work has revealed attention sinks, tokens that attract disproportionately high attention, and associated massive activations in which some features of sink tokens exhibit huge activation in LLMs. In this work, we are the first to study these phenomena in multimodal speech recognition. Through a detailed analysis of audio-visual LLMs, we identify attention sinks and massive activations not only at the BOS token but also at intermediate low-semantic tokens across ASR, VSR, and AVSR. We show that massive activations originate in the MLP layers and correspond to fixed feature indices across all sink tokens. We further show that intermediate sink tokens exhibit high cosine similarity to the BOS token, thereby amplifying attention and activation. Building on these insights, we introduce a simple decorrelation loss that reduces cosine similarity between BOS and other tokens, effectively mitigating intermediate sinks and massive activations. Furthermore, our method improves word error rate (WER) under high audio-visual feature downsampling while remaining stable at lower downsampling rates.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "473",
        "title": "TABL-ABM: A Hybrid Framework for Synthetic LOB Generation",
        "author": [
            "Ollie Olby",
            "Rory Baggott",
            "Namid Stillman"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22685",
        "abstract": "The recent application of deep learning models to financial trading has heightened the need for high fidelity financial time series data. This synthetic data can be used to supplement historical data to train large trading models. The state-of-the-art models for the generative application often rely on huge amounts of historical data and large, complicated models. These models range from autoregressive and diffusion-based models through to architecturally simpler models such as the temporal-attention bilinear layer. Agent-based approaches to modelling limit order book dynamics can also recreate trading activity through mechanistic models of trader behaviours. In this work, we demonstrate how a popular agent-based framework for simulating intraday trading activity, the Chiarella model, can be combined with one of the most performant deep learning models for forecasting multi-variate time series, the TABL model. This forecasting model is coupled to a simulation of a matching engine with a novel method for simulating deleted order flow. Our simulator gives us the ability to test the generative abilities of the forecasting model using stylised facts. Our results show that this methodology generates realistic price dynamics however, when analysing deeper, parts of the markets microstructure are not accurately recreated, highlighting the necessity for including more sophisticated agent behaviors into the modeling framework to help account for tail events.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "474",
        "title": "Scalable Neural Decoders for Practical Real-Time Quantum Error Correction",
        "author": [
            "Changwon Lee",
            "Tak Hur",
            "Daniel K. Park"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22724",
        "abstract": "Real-time, scalable, and accurate decoding is a critical component for realizing a fault-tolerant quantum computer. While Transformer-based neural decoders such as \\textit{AlphaQubit} have demonstrated high accuracy, the computational complexity of their core attention mechanism, which scales as $\\mathcal{O}(d^4)$ with code distance $d$, results in decoding speeds insufficient for practical real-time applications. In this work, we introduce and evaluate a \\textit{Mamba}-based decoder, a state-space model with $\\mathcal{O}(d^2)$ complexity. In memory experiments using Sycamore hardware data, our Mamba decoder matches the performance of its Transformer-based counterpart, providing that its superior efficiency does not come at the cost of performance. Crucially, in simulated real-time scenarios that account for decoder-induced noise, the Mamba decoder significantly outperforms the Transformer, exhibiting a higher error threshold of $0.0104$ compared to $0.0097$. These results demonstrate that Mamba decoders offer a compelling balance between speed and accuracy, making them a promising architecture for scalable, real-time quantum error correction.",
        "tags": [
            "Mamba",
            "Transformer"
        ]
    },
    {
        "id": "475",
        "title": "Neural-HAR: A Dimension-Gated CNN Accelerator for Real-Time Radar Human Activity Recognition",
        "author": [
            "Yizhuo Wu",
            "Francesco Fioranelli",
            "Chang Gao"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22772",
        "abstract": "Radar-based human activity recognition (HAR) is attractive for unobtrusive and privacy-preserving monitoring, yet many CNN/RNN solutions remain too heavy for edge deployment, and even lightweight ViT/SSM variants often exceed practical compute and memory budgets. We introduce Neural-HAR, a dimension-gated CNN accelerator tailored for real-time radar HAR on resource-constrained platforms. At its core is GateCNN, a parameter-efficient Doppler-temporal network that (i) embeds Doppler vectors to emphasize frequency evolution over time and (ii) applies dual-path gated convolutions that modulate Doppler-aware content features with temporal gates, complemented by a residual path for stable training. On the University of Glasgow UoG2020 continuous radar dataset, GateCNN attains 86.4% accuracy with only 2.7k parameters and 0.28M FLOPs per inference, comparable to CNN-BiGRU at a fraction of the complexity. Our FPGA prototype on Xilinx Zynq-7000 Z-7007S reaches 107.5 $\\mu$s latency and 15 mW dynamic power using LUT-based ROM and distributed RAM only (zero DSP/BRAM), demonstrating real-time, energy-efficient edge inference. Code and HLS conversion scripts are available at https://github.com/lab-emi/AIRHAR.",
        "tags": [
            "RNN",
            "ViT"
        ]
    },
    {
        "id": "476",
        "title": "A Free Probabilistic Framework for Denoising Diffusion Models: Entropy, Transport, and Reverse Processes",
        "author": [
            "Swagatam Das"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22778",
        "abstract": "This work develops a rigorous framework for diffusion-based generative modeling in the setting of free probability. We extend classical denoising diffusion probabilistic models to free diffusion processes -- stochastic dynamics acting on noncommutative random variables whose spectral measures evolve by free additive convolution. The forward dynamics satisfy a free Fokker--Planck equation that increases Voiculescu's free entropy and dissipates free Fisher information, providing a noncommutative analogue of the classical de Bruijn identity. Using tools from free stochastic analysis, including a free Malliavin calculus and a Clark--Ocone representation, we derive the reverse-time stochastic differential equation driven by the conjugate variable, the free analogue of the score function. We further develop a variational formulation of these flows in the free Wasserstein space, showing that the resulting gradient-flow structure converges to the semicircular equilibrium law. Together, these results connect modern diffusion models with the information geometry of free entropy and establish a mathematical foundation for generative modeling with operator-valued or high-dimensional structured data.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "477",
        "title": "Region-Adaptive Learned Hierarchical Encoding for 3D Gaussian Splatting Data",
        "author": [
            "Shashank N. Sridhara",
            "Birendra Kathariya",
            "Fangjun Pu",
            "Peng Yin",
            "Eduardo Pavez",
            "Antonio Ortega"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22812",
        "abstract": "We introduce Region-Adaptive Learned Hierarchical Encoding (RALHE) for 3D Gaussian Splatting (3DGS) data. While 3DGS has recently become popular for novel view synthesis, the size of trained models limits its deployment in bandwidth-constrained applications such as volumetric media streaming. To address this, we propose a learned hierarchical latent representation that builds upon the principles of \"overfitted\" learned image compression (e.g., Cool-Chic and C3) to efficiently encode 3DGS attributes. Unlike images, 3DGS data have irregular spatial distributions of Gaussians (geometry) and consist of multiple attributes (signals) defined on the irregular geometry. Our codec is designed to account for these differences between images and 3DGS. Specifically, we leverage the octree structure of the voxelized 3DGS geometry to obtain a hierarchical multi-resolution representation. Our approach overfits latents to each Gaussian attribute under a global rate constraint. These latents are decoded independently through a lightweight decoder network. To estimate the bitrate during training, we employ an autoregressive probability model that leverages octree-derived contexts from the 3D point structure. The multi-resolution latents, decoder, and autoregressive entropy coding networks are jointly optimized for each Gaussian attribute. Experiments demonstrate that the proposed RALHE compression framework achieves a rendering PSNR gain of up to 2dB at low bitrates (less than 1 MB) compared to the baseline 3DGS compression methods.",
        "tags": [
            "3D",
            "Gaussian Splatting"
        ]
    },
    {
        "id": "478",
        "title": "Clinic-Oriented Feasibility of a Sensor-Fused Wearable for Upper-Limb Function",
        "author": [
            "Thanyanee Srichaisak",
            "Arissa Ieochai",
            "Aueaphum Aueawattthanaphisut"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22913",
        "abstract": "Background: Upper-limb weakness and tremor (4--12 Hz) limit activities of daily living (ADL) and reduce adherence to home rehabilitation. Objective: To assess technical feasibility and clinician-relevant signals of a sensor-fused wearable targeting the triceps brachii and extensor pollicis brevis. Methods: A lightweight node integrates surface EMG (1 kHz), IMU (100--200 Hz), and flex/force sensors with on-device INT8 inference (Tiny 1D-CNN/Transformer) and a safety-bounded assist policy (angle/torque/jerk limits; stall/time-out). Healthy adults (n = 12) performed three ADL-like tasks. Primary outcomes: Tremor Index (TI), range of motion (ROM), repetitions (Reps min$^{-1}$). Secondary: EMG median-frequency slope (fatigue trend), closed-loop latency, session completion, and device-related adverse events. Analyses used subject-level paired medians with BCa 95\\% CIs; exact Wilcoxon $p$-values are reported in the Results. Results: Assistance was associated with lower tremor prominence and improved task throughput: TI decreased by $-0.092$ (95\\% CI [$-0.102$, $-0.079$]), ROM increased by $+12.65\\%$ (95\\% CI [$+8.43$, $+13.89$]), and Reps rose by $+2.99$ min$^{-1}$ (95\\% CI [$+2.61$, $+3.35$]). Median on-device latency was 8.7 ms at a 100 Hz loop rate; all sessions were completed with no device-related adverse events. Conclusions: Multimodal sensing with low-latency, safety-bounded assistance produced improved movement quality (TI $\\downarrow$) and throughput (ROM, Reps $\\uparrow$) in a pilot technical-feasibility setting, supporting progression to IRB-approved patient studies. Trial registration: Not applicable (pilot non-clinical).",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "479",
        "title": "PASS-Enhanced MEC: Joint Optimization of Task Offloading and Uplink PASS Beamforming",
        "author": [
            "Zhaoming Hu",
            "Ruikang Zhong",
            "Xidong Mu",
            "Dengao Li",
            "Yuanwei Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.22948",
        "abstract": "A pinching-antenna system (PASS)-enhanced mobile edge computing (MEC) architecture is investigated to improve the task offloading efficiency and latency performance in dynamic wireless environments. By leveraging dielectric waveguides and flexibly adjustable pinching antennas, PASS establishes short-distance line-of-sight (LoS) links while effectively mitigating the significant path loss and potential signal blockage, making it a promising solution for high-frequency MEC systems. We formulate a network latency minimization problem to joint optimize uplink PASS beamforming and task offloading. The resulting problem is modeled as a Markov decision process (MDP) and solved via the deep reinforcement learning (DRL) method. To address the instability introduced by the $\\max$ operator in the objective function, we propose a load balancing-aware proximal policy optimization (LBPPO) algorithm. LBPPO incorporates both node-level and waveguide-level load balancing information into the policy design, maintaining computational and transmission delay equilibrium, respectively. Simulation results demonstrate that the proposed PASS-enhanced MEC with adaptive uplink PASS beamforming exhibit stronger convergence capability than fixed-PA baselines and conventional MIMO-assisted MEC, especially in scenarios with a large number of UEs or high transmit power.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "480",
        "title": "Coupled Flow Matching",
        "author": [
            "Wenxi Cai",
            "Yuheng Wang",
            "Naichen Shi"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23015",
        "abstract": "We introduce Coupled Flow Matching (CPFM), a framework that integrates controllable dimensionality reduction and high-fidelity reconstruction. CPFM learns coupled continuous flows for both the high-dimensional data x and the low-dimensional embedding y, which enables sampling p(y|x) via a latent-space flow and p(x|y) via a data-space flow. Unlike classical dimension-reduction methods, where information discarded during compression is often difficult to recover, CPFM preserves the knowledge of residual information within the weights of a flow network. This design provides bespoke controllability: users may decide which semantic factors to retain explicitly in the latent space, while the complementary information remains recoverable through the flow network. Coupled flow matching builds on two components: (i) an extended Gromov-Wasserstein optimal transport objective that establishes a probabilistic correspondence between data and embeddings, and (ii) a dual-conditional flow-matching network that extrapolates the correspondence to the underlying space. Experiments on multiple benchmarks show that CPFM yields semantically rich embeddings and reconstructs data with higher fidelity than existing baselines.",
        "tags": [
            "Flow Matching"
        ]
    },
    {
        "id": "481",
        "title": "Physics-informed diffusion models for extrapolating crystal structures beyond known motifs",
        "author": [
            "Andrij Vasylenko",
            "Federico Ottomano",
            "Christopher M. Collins",
            "Rahul Savani",
            "Matthew S. Dyer",
            "Matthew J. Rosseinsky"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23181",
        "abstract": "Discovering materials with previously unreported crystal frameworks is key to achieving transformative functionality. Generative artificial intelligence offers a scalable means to propose candidate crystal structures, however existing approaches mainly reproduce decorated variants of established motifs rather than uncover new configurations. Here we develop a physics-informed diffusion method, supported by chemically grounded validation protocol, which embeds descriptors of compactness and local environment diversity to balance physical plausibility with structural novelty. Conditioning on these metrics improves generative performance across architectures, increasing the fraction of structures outside 100 most common prototypes up to 67%. When crystal structure prediction (CSP) is seeded with generative structures, most candidates (97%) are reconstructed by CSP, yielding 145 (66%) low-energy frameworks not matching any known prototypes. These results show that while generative models are not substitutes for CSP, their chemically informed, diversity-guided outputs can enhance CSP efficiency, establishing a practical generative-CSP synergy for discovery-oriented exploration of chemical space.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "482",
        "title": "Provable test-time adaptivity and distributional robustness of in-context learning",
        "author": [
            "Tianyi Ma",
            "Tengyao Wang",
            "Richard J. Samworth"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23254",
        "abstract": "We study in-context learning problems where a Transformer is pretrained on tasks drawn from a mixture distribution $\\pi=\\sum_{\\alpha\\in\\mathcal{A}} \\lambda_{\\alpha} \\pi_{\\alpha}$, called the pretraining prior, in which each mixture component $\\pi_{\\alpha}$ is a distribution on tasks of a specific difficulty level indexed by $\\alpha$. Our goal is to understand the performance of the pretrained Transformer when evaluated on a different test distribution $\\mu$, consisting of tasks of fixed difficulty $\\beta\\in\\mathcal{A}$, and with potential distribution shift relative to $\\pi_\\beta$, subject to the chi-squared divergence $\\chi^2(\\mu,\\pi_{\\beta})$ being at most $\\kappa$. In particular, we consider nonparametric regression problems with random smoothness, and multi-index models with random smoothness as well as random effective dimension. We prove that a large Transformer pretrained on sufficient data achieves the optimal rate of convergence corresponding to the difficulty level $\\beta$, uniformly over test distributions $\\mu$ in the chi-squared divergence ball. Thus, the pretrained Transformer is able to achieve faster rates of convergence on easier tasks and is robust to distribution shift at test time. Finally, we prove that even if an estimator had access to the test distribution $\\mu$, the convergence rate of its expected risk over $\\mu$ could not be faster than that of our pretrained Transformers, thereby providing a more appropriate optimality guarantee than minimax lower bounds.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "483",
        "title": "Exploring Vulnerability in AI Industry",
        "author": [
            "Claudio Pirrone",
            "Stefano Fricano",
            "Gioacchino Fazio"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23421",
        "abstract": "The rapid ascent of Foundation Models (FMs), enabled by the Transformer architecture, drives the current AI ecosystem. Characterized by large-scale training and downstream adaptability, FMs (as GPT family) have achieved massive public adoption, fueling a turbulent market shaped by platform economics and intense investment. Assessing the vulnerability of this fast-evolving industry is critical yet challenging due to data limitations. This paper proposes a synthetic AI Vulnerability Index (AIVI) focusing on the upstream value chain for FM production, prioritizing publicly available data. We model FM output as a function of five inputs: Compute, Data, Talent, Capital, and Energy, hypothesizing that supply vulnerability in any input threatens the industry. Key vulnerabilities include compute concentration, data scarcity and legal risks, talent bottlenecks, capital intensity and strategic dependencies, as well as escalating energy demands. Acknowledging imperfect input substitutability, we propose a weighted geometrical average of aggregate subindexes, normalized using theoretical or empirical benchmarks. Despite limitations and room for improvement, this preliminary index aims to quantify systemic risks in AI's core production engine, and implicitly shed a light on the risks for downstream value chain.",
        "tags": [
            "GPT",
            "Transformer"
        ]
    },
    {
        "id": "484",
        "title": "Minimizing Human Intervention in Online Classification",
        "author": [
            "William RÃ©veillard",
            "Vasileios Saketos",
            "Alexandre Proutiere",
            "Richard Combes"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23557",
        "abstract": "We introduce and study an online problem arising in question answering systems. In this problem, an agent must sequentially classify user-submitted queries represented by $d$-dimensional embeddings drawn i.i.d. from an unknown distribution. The agent may consult a costly human expert for the correct label, or guess on her own without receiving feedback. The goal is to minimize regret against an oracle with free expert access. When the time horizon $T$ is at least exponential in the embedding dimension $d$, one can learn the geometry of the class regions: in this regime, we propose the Conservative Hull-based Classifier (CHC), which maintains convex hulls of expert-labeled queries and calls the expert as soon as a query lands outside all known hulls. CHC attains $\\mathcal{O}(\\log^d T)$ regret in $T$ and is minimax optimal for $d=1$. Otherwise, the geometry cannot be reliably learned without additional distributional assumptions. We show that when the queries are drawn from a subgaussian mixture, for $T \\le e^d$, a Center-based Classifier (CC) achieves regret proportional to $N\\log{N}$ where $N$ is the number of labels. To bridge these regimes, we introduce the Generalized Hull-based Classifier (GHC), a practical extension of CHC that allows for more aggressive guessing via a tunable threshold parameter. Our approach is validated with experiments, notably on real-world question-answering datasets using embeddings derived from state-of-the-art large language models.",
        "tags": [
            "LLM"
        ]
    }
]