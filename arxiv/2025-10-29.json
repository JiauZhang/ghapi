[
    {
        "id": "1",
        "title": "Logic-based Task Representation and Reward Shaping in Multiagent Reinforcement Learning",
        "author": [
            "Nishant Doshi"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23615",
        "abstract": "This paper presents an approach for accelerated learning of optimal plans for a given task represented using Linear Temporal Logic (LTL) in multi-agent systems. Given a set of options (temporally abstract actions) available to each agent, we convert the task specification into the corresponding Buchi Automaton and proceed with a model-free approach which collects transition samples and constructs a product Semi Markov Decision Process (SMDP) on-the-fly. Value-based Reinforcement Learning algorithms can then be used to synthesize a correct-by-design controller without learning the underlying transition model of the multi-agent system. The exponential sample complexity due to multiple agents is dealt with using a novel reward shaping approach. We test the proposed algorithm in a deterministic gridworld simulation for different tasks and find that the reward shaping results in significant reduction in convergence times. We also infer that using options becomes increasing more relevant as the state and action space increases in multi-agent systems.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "2",
        "title": "An Enhanced Dual Transformer Contrastive Network for Multimodal Sentiment Analysis",
        "author": [
            "Phuong Q. Dao",
            "Mark Roantree",
            "Vuong M. Ngo"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23617",
        "abstract": "Multimodal Sentiment Analysis (MSA) seeks to understand human emotions by jointly analyzing data from multiple modalities typically text and images offering a richer and more accurate interpretation than unimodal approaches. In this paper, we first propose BERT-ViT-EF, a novel model that combines powerful Transformer-based encoders BERT for textual input and ViT for visual input through an early fusion strategy. This approach facilitates deeper cross-modal interactions and more effective joint representation learning. To further enhance the model's capability, we propose an extension called the Dual Transformer Contrastive Network (DTCN), which builds upon BERT-ViT-EF. DTCN incorporates an additional Transformer encoder layer after BERT to refine textual context (before fusion) and employs contrastive learning to align text and image representations, fostering robust multimodal feature learning. Empirical results on two widely used MSA benchmarks MVSA-Single and TumEmo demonstrate the effectiveness of our approach. DTCN achieves best accuracy (78.4%) and F1-score (78.3%) on TumEmo, and delivers competitive performance on MVSA-Single, with 76.6% accuracy and 75.9% F1-score. These improvements highlight the benefits of early fusion and deeper contextual modeling in Transformer-based multimodal sentiment analysis.",
        "tags": [
            "BERT",
            "Transformer",
            "ViT"
        ]
    },
    {
        "id": "3",
        "title": "Chain of Execution Supervision Promotes General Reasoning in Large Language Models",
        "author": [
            "Nuo Chen",
            "Zehua Li",
            "Keqin Bao",
            "Junyang Lin",
            "Dayiheng Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23629",
        "abstract": "Building robust and general reasoning ability is a central goal in the development of large language models (LLMs). Recent efforts increasingly turn to code as a rich training source, given its inherent logical structure and diverse reasoning paradigms such as divide-and-conquer, topological ordering, and enumeration. However, reasoning in code is often expressed implicitly and entangled with syntactic or implementation noise, making direct training on raw code http://suboptimal.To address this, we introduce TracePile, a large-scale corpus of 2.6 million samples that transforms code execution into explicit, step-by-step chain-of-thought-style rationales, which we call Chain of Execution (CoE). The corpus spans domains including mathematics, classical algorithms and algorithmic competition, and is enriched with variable-tracing questions and code rewritings to enhance logical granularity and code diversity. We evaluate TracePile using three training setups: continue-pretraining, instruction tuning after pretraining, and two-stage finetuning. Experiments across four base models (LLaMA 3, LLaMA 3.1, Qwen-2.5, and Qwen-2.5 Coder) and 20 benchmarks covering math, code, logic, and algorithms demonstrate consistent improvements. Notably, TracePile boosts LLaMA3.1-8B by 7.1\\% on average across nine math datasets and delivers clear gains on LiveCodeBench, CRUX, and MMLU under two-stage fine-tuning.",
        "tags": [
            "CoT",
            "LLM",
            "LLaMA",
            "Qwen"
        ]
    },
    {
        "id": "4",
        "title": "NUM2EVENT: Interpretable Event Reasoning from Numerical time-series",
        "author": [
            "Ninghui Feng",
            "Yiyan Qi"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23630",
        "abstract": "Large language models (LLMs) have recently demonstrated impressive multimodal reasoning capabilities, yet their understanding of purely numerical time-series signals remains limited. Existing approaches mainly focus on forecasting or trend description, without uncovering the latent events that drive numerical changes or explaining the reasoning process behind them. In this work, we introduce the task of number-to-event reasoning and decoding, which aims to infer interpretable structured events from numerical inputs, even when current text is unavailable. To address the data scarcity and semantic alignment challenges, we propose a reasoning-aware framework that integrates an agent-guided event extractor (AGE), a marked multivariate Hawkes-based synthetic generator (EveDTS), and a two-stage fine-tuning pipeline combining a time-series encoder with a structured decoder. Our model explicitly reasons over numerical changes, generates intermediate explanations, and outputs structured event hypotheses. Experiments on multi-domain datasets show that our method substantially outperforms strong LLM baselines in event-level precision and recall. These results suggest a new direction for bridging quantitative reasoning and semantic understanding, enabling LLMs to explain and predict events directly from numerical dynamics.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "5",
        "title": "Beyond Pairwise: Empowering LLM Alignment With Ranked Choice Modeling",
        "author": [
            "Yuxuan Tang",
            "Yifan Feng"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23631",
        "abstract": "Alignment of large language models (LLMs) has predominantly relied on pairwise preference optimization, where annotators select the better of two responses to a prompt. While simple, this approach overlooks the opportunity to learn from richer forms of human feedback, such as multiwise comparisons and top-$k$ rankings. We propose Ranked Choice Preference Optimization (RCPO), a unified framework that bridges preference optimization with (ranked) choice modeling via maximum likelihood estimation. The framework is flexible, supporting both utility-based and rank-based choice models. It subsumes several existing pairwise methods (e.g., DPO, SimPO), while providing principled training objectives for richer feedback formats. We instantiate this framework with two representative ranked choice models (Multinomial Logit and Mallows-RMJ). Empirical studies on Llama-3-8B-Instruct and Gemma-2-9B-it across AlpacaEval 2 and Arena-Hard benchmarks show that RCPO consistently outperforms competitive baselines. RCPO shows how directly leveraging ranked preference data, combined with the right choice models, yields more effective alignment. It offers a versatile and extensible foundation for incorporating (ranked) choice modeling into LLM training.",
        "tags": [
            "DPO",
            "LLM",
            "LLaMA"
        ]
    },
    {
        "id": "6",
        "title": "LLMComp: A Language Modeling Paradigm for Error-Bounded Scientific Data Compression",
        "author": [
            "Guozhong Li",
            "Muhannad Alhumaidi",
            "Spiros Skiadopoulos",
            "Panos Kalnis"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23632",
        "abstract": "The rapid growth of high-resolution scientific simulations and observation systems is generating massive spatiotemporal datasets, making efficient, error-bounded compression increasingly important. Meanwhile, decoder-only large language models (LLMs) have demonstrated remarkable capabilities in modeling complex sequential data. In this paper, we propose LLMCOMP, a novel lossy compression paradigm that leverages decoder-only large LLMs to model scientific data. LLMCOMP first quantizes 3D fields into discrete tokens, arranges them via Z-order curves to preserve locality, and applies coverage-guided sampling to enhance training efficiency. An autoregressive transformer is then trained with spatial-temporal embeddings to model token transitions. During compression, the model performs top-k prediction, storing only rank indices and fallback corrections to ensure strict error bounds. Experiments on multiple reanalysis datasets show that LLMCOMP consistently outperforms state-of-the-art compressors, achieving up to 30% higher compression ratios under strict error bounds. These results highlight the potential of LLMs as general-purpose compressors for high-fidelity scientific data.",
        "tags": [
            "3D",
            "LLM",
            "Transformer"
        ]
    },
    {
        "id": "7",
        "title": "Noise is All You Need: Solving Linear Inverse Problems by Noise Combination Sampling with Diffusion Models",
        "author": [
            "Xun Su",
            "Hiroyuki Kasai"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23633",
        "abstract": "Pretrained diffusion models have demonstrated strong capabilities in zero-shot inverse problem solving by incorporating observation information into the generation process of the diffusion models. However, this presents an inherent dilemma: excessive integration can disrupt the generative process, while insufficient integration fails to emphasize the constraints imposed by the inverse problem. To address this, we propose \\emph{Noise Combination Sampling}, a novel method that synthesizes an optimal noise vector from a noise subspace to approximate the measurement score, replacing the noise term in the standard Denoising Diffusion Probabilistic Models process. This enables conditional information to be naturally embedded into the generation process without reliance on step-wise hyperparameter tuning. Our method can be applied to a wide range of inverse problem solvers, including image compression, and, particularly when the number of generation steps $T$ is small, achieves superior performance with negligible computational overhead, significantly improving robustness and stability.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "8",
        "title": "Flight Delay Prediction via Cross-Modality Adaptation of Large Language Models and Aircraft Trajectory Representation",
        "author": [
            "Thaweerath Phisannupawong",
            "Joshua Julian Damanik",
            "Han-Lim Choi"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23636",
        "abstract": "Flight delay prediction has become a key focus in air traffic management, as delays highlight inefficiencies that impact overall network performance. This paper presents a lightweight large language model-based multimodal flight delay prediction, formulated from the perspective of air traffic controllers monitoring aircraft delay after entering the terminal area. The approach integrates trajectory representations with textual aeronautical information, including flight information, weather reports, and aerodrome notices, by adapting trajectory data into the language modality to capture airspace conditions. Experimental results show that the model consistently achieves sub-minute prediction error by effectively leveraging contextual information related to the sources of delay. The framework demonstrates that linguistic understanding, when combined with cross-modality adaptation of trajectory information, enhances delay prediction. Moreover, the approach shows practicality and scalability for real-world operations, supporting real-time updates that refine predictions upon receiving new operational information.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "9",
        "title": "Bridging Function Approximation and Device Physics via Negative Differential Resistance Networks",
        "author": [
            "Songyuan Li",
            "Teng Wang",
            "Jinrong Tang",
            "Ruiqi Liu",
            "Yuyao Lu",
            "Feng Xu",
            "Bin Gao",
            "Xiangwei Zhu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23638",
        "abstract": "Achieving fully analog neural computation requires hardware that can natively implement both linear and nonlinear operations with high efficiency. While analogue matrix-vector multiplication has advanced via compute-in-memory architectures, nonlinear activation functions remain a bottleneck, often requiring digital or hybrid solutions. Inspired by the Kolmogorov-Arnold framework, we propose KANalogue, a fully analogue implementation of Kolmogorov-Arnold Networks (KANs) using negative differential resistance devices as physical realizations of learnable univariate basis functions. By leveraging the intrinsic negative differential resistance characteristics of tunnel diodes fabricated from NbSi2N4/HfSi2N4 heterostructures, we construct coordinate-wise nonlinearities with distinct curvature and support profiles. We extract I-V data from fabricated armchair and zigzag devices, fit high-order polynomials to emulate diode behavior in software, and train KANs on vision benchmarks using these learned basis functions. Our results demonstrate that KANalogue can approximate complex functions with minimal parameters while maintaining classification accuracy competitive with digital baselines. This work bridges device-level physics and function approximation theory, charting a path toward scalable, energy-efficient analogue machine learning systems.",
        "tags": [
            "KAN"
        ]
    },
    {
        "id": "10",
        "title": "Spatially Aware Linear Transformer (SAL-T) for Particle Jet Tagging",
        "author": [
            "Aaron Wang",
            "Zihan Zhao",
            "Subash Katel",
            "Vivekanand Gyanchand Sahu",
            "Elham E Khoda",
            "Abhijith Gandrakota",
            "Jennifer Ngadiuba",
            "Richard Cavanaugh",
            "Javier Duarte"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23641",
        "abstract": "Transformers are very effective in capturing both global and local correlations within high-energy particle collisions, but they present deployment challenges in high-data-throughput environments, such as the CERN LHC. The quadratic complexity of transformer models demands substantial resources and increases latency during inference. In order to address these issues, we introduce the Spatially Aware Linear Transformer (SAL-T), a physics-inspired enhancement of the linformer architecture that maintains linear attention. Our method incorporates spatially aware partitioning of particles based on kinematic features, thereby computing attention between regions of physical significance. Additionally, we employ convolutional layers to capture local correlations, informed by insights from jet physics. In addition to outperforming the standard linformer in jet classification tasks, SAL-T also achieves classification results comparable to full-attention transformers, while using considerably fewer resources with lower latency during inference. Experiments on a generic point cloud classification dataset (ModelNet10) further confirm this trend. Our code is available at https://github.com/aaronw5/SAL-T4HEP.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "11",
        "title": "VisCoder2: Building Multi-Language Visualization Coding Agents",
        "author": [
            "Yuansheng Ni",
            "Songcheng Cai",
            "Xiangchao Chen",
            "Jiarong Liang",
            "Zhiheng Lyu",
            "Jiaqi Deng",
            "Kai Zou",
            "Ping Nie",
            "Fei Yuan",
            "Xiang Yue",
            "Wenhu Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23642",
        "abstract": "Large language models (LLMs) have recently enabled coding agents capable of generating, executing, and revising visualization code. However, existing models often fail in practical workflows due to limited language coverage, unreliable execution, and lack of iterative correction mechanisms. Progress has been constrained by narrow datasets and benchmarks that emphasize single-round generation and single-language tasks. To address these challenges, we introduce three complementary resources for advancing visualization coding agents. VisCode-Multi-679K is a large-scale, supervised dataset containing 679K validated and executable visualization samples with multi-turn correction dialogues across 12 programming languages. VisPlotBench is a benchmark for systematic evaluation, featuring executable tasks, rendered outputs, and protocols for both initial generation and multi-round self-debug. Finally, we present VisCoder2, a family of multi-language visualization models trained on VisCode-Multi-679K. Experiments show that VisCoder2 significantly outperforms strong open-source baselines and approaches the performance of proprietary models like GPT-4.1, with further gains from iterative self-debug, reaching 82.4% overall execution pass rate at the 32B scale, particularly in symbolic or compiler-dependent languages.",
        "tags": [
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "12",
        "title": "Global YouTube Trending Dataset (2022-2025): Three Years of Platform-Curated, Cross-National Trends in Digital Culture",
        "author": [
            "Alexandre Goncalves",
            "Yee Man Margaret Ng"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23645",
        "abstract": "On July 1, 2025, YouTube retired its decade-long public \"Trending\" pages, ending platform-curated, non-personalized video discovery. The Trending list had long served as a vital lens into algorithmic influence, cultural diffusion, and crisis communication globally, offering a rare \"ground-truth\" reference to study global attention and cultural salience. We present a three-year archival dataset of YouTube Trending videos, collected from July 1, 2022, to June 30, 2025, with four daily snapshots for each of the 104 countries. The dataset includes 446,971 snapshots, each capturing up to 200 trending videos, encompassing 78.4 million video entries (726,627 unique videos) and associated metadata. Each record includes core identifiers (snapshot time, country, rank) and content metadata (video ID, channel ID, title, description, tags, publication date, category, channel name, language, live status, views, and comments). Unlike previous datasets with limited geographic scope or short timeframes, our non-personalized data provides exceptional cross-national and longitudinal coverage for studying digital culture, platform governance, and temporal dynamics in content popularity. We document the data collection methodology, schema design, coverage, descriptive statistics for both global and U.S. trending videos, and the ethical safeguards implemented throughout.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "13",
        "title": "RoGBot: Relationship-Oblivious Graph-based Neural Network with Contextual Knowledge for Bot Detection",
        "author": [
            "Ashutosh Anshul",
            "Mohammad Zia Ur Rehman",
            "Sri Akash Kadali",
            "Nagendra Kumar"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23648",
        "abstract": "Detecting automated accounts (bots) among genuine users on platforms like Twitter remains a challenging task due to the evolving behaviors and adaptive strategies of such accounts. While recent methods have achieved strong detection performance by combining text, metadata, and user relationship information within graph-based frameworks, many of these models heavily depend on explicit user-user relationship data. This reliance limits their applicability in scenarios where such information is unavailable. To address this limitation, we propose a novel multimodal framework that integrates detailed textual features with enriched user metadata while employing graph-based reasoning without requiring follower-following data. Our method uses transformer-based models (e.g., BERT) to extract deep semantic embeddings from tweets, which are aggregated using max pooling to form comprehensive user-level representations. These are further combined with auxiliary behavioral features and passed through a GraphSAGE model to capture both local and global patterns in user behavior. Experimental results on the Cresci-15, Cresci-17, and PAN 2019 datasets demonstrate the robustness of our approach, achieving accuracies of 99.8%, 99.1%, and 96.8%, respectively, and highlighting its effectiveness against increasingly sophisticated bot strategies.",
        "tags": [
            "BERT",
            "Detection",
            "Transformer"
        ]
    },
    {
        "id": "14",
        "title": "Efficient Low Rank Attention for Long-Context Inference in Large Language Models",
        "author": [
            "Tenghui Li",
            "Guoxu Zhou",
            "Xuyang Zhao",
            "Yuning Qiu",
            "Qibin Zhao"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23649",
        "abstract": "As the length of input text grows, the key-value (KV) cache in LLMs imposes prohibitive GPU memory costs and limits long-context inference on resource constrained devices. Existing approaches, such as KV quantization and pruning, reduce memory usage but suffer from numerical precision loss or suboptimal retention of key-value pairs. We introduce Low Rank Query and Key attention (LRQK), a two-stage framework that jointly decomposes the full-precision query and key matrices into compact rank-\\(r\\) factors during the prefill stage, and then uses these low-dimensional projections to compute proxy attention scores in \\(\\mathcal{O}(lr)\\) time at each decode step. By selecting only the top-\\(k\\) tokens and a small fixed set of recent tokens, LRQK employs a mixed GPU-CPU cache with a hit-and-miss mechanism that transfers only missing full-precision KV pairs, thereby preserving exact attention outputs while reducing CPU-GPU data movement. Extensive experiments on the RULER and LongBench benchmarks with LLaMA-3-8B and Qwen2.5-7B demonstrate that LRQK matches or surpasses leading sparse-attention methods in long context settings, while delivering significant memory savings with minimal loss in accuracy. Our code is available at https://github.com/tenghuilee/LRQK.",
        "tags": [
            "LLM",
            "LLaMA"
        ]
    },
    {
        "id": "15",
        "title": "Beyond Hidden-Layer Manipulation: Semantically-Aware Logit Interventions for Debiasing LLMs",
        "author": [
            "Wei Xia"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23650",
        "abstract": "We proposed Static and Dynamic -- two zero-shot logits-layer debiasing methods. Dynamic reduces bias by up to 70% with minimal fluency loss. Logits intervention outperforms hidden-layer approaches. We show semantic-aware logits intervention is stable and effective for debiasing aligned LLMs.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "16",
        "title": "The Structural Scalpel: Automated Contiguous Layer Pruning for Large Language Models",
        "author": [
            "Yao Lu",
            "Yuqi Li",
            "Wenbin Xie",
            "Shanqing Yu",
            "Qi Xuan",
            "Zhaowei Zhu",
            "Shiping Wen"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23652",
        "abstract": "Although large language models (LLMs) have achieved revolutionary breakthroughs in many fields, their large model size and high computational cost pose significant challenges for practical deployment on resource-constrained edge devices. To this end, layer pruning has been proposed to reduce the computational overhead by directly removing redundant layers. However, existing layer pruning methods typically rely on hand-crafted metrics to evaluate and remove individual layers, while ignoring the dependencies between layers. This can disrupt the model's information flow and severely degrade performance. To address these issues, we propose CLP, a novel continuous layer pruning framework that introduces two key innovations: a differentiable concave gate algorithm that automatically identifies the best continuous layer segments for pruning via gradient-based optimization; and a cutoff endpoint tuning strategy that effectively restores model performance by fine-tuning only the layers adjacent to the pruned segments. Extensive experiments across multiple model architectures (including LLaMA2, LLaMA3 and Qwen) and sizes (from $7$B to $70$B parameters) show that CLP significantly outperforms existing state-of-the-art baselines. For example, at a pruning rate of $20\\%$, CLP achieves an average performance retention of $95.34\\%$ on LLaMA3-70B, outperforming baselines by $4.29\\%$-$30.52\\%$. Furthermore, CLP can be seamlessly combined with quantization to further compress the model with only a slight performance loss.",
        "tags": [
            "LLM",
            "Qwen"
        ]
    },
    {
        "id": "17",
        "title": "Aligning Diffusion Language Models via Unpaired Preference Optimization",
        "author": [
            "Vaibhav Jindal",
            "Hejian Sang",
            "Chun-Mao Lai",
            "Yanning Chen",
            "Zhipeng Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23658",
        "abstract": "Diffusion language models (dLLMs) are an emerging alternative to autoregressive (AR) generators, but aligning them to human preferences is challenging because sequence log-likelihoods are intractable and pairwise preference data are costly to collect. We introduce ELBO-KTO, which combines an ELBO surrogate for diffusion log-likelihoods with a prospect-theoretic, unpaired preference objective (Kahneman Tversky Optimization, KTO). We analyze the bias and variance induced by the ELBO substitution and employ variance-reduction practices that stabilize gradients during training. Applied to LLaDA-8B-Instruct, ELBO-KTO yields \\textbf{65.9\\%} and \\textbf{62.3\\%} adjusted win rates on kto-mix-14k and UltraFeedback-Binary, respectively, versus the base model under an automatic LLM judge. Across downstream tasks, including GSM8K, MMLU, and additional reasoning/knowledge benchmarks, ELBO-KTO trained on UltraFeedback-Binary performs on par with or better than the base model under identical decoding. This establishes unpaired preference optimization as a viable alternative to pairwise alignment in diffusion LLMs.",
        "tags": [
            "Diffusion",
            "LLM"
        ]
    },
    {
        "id": "18",
        "title": "AI-Driven Carbon Monitoring: Transformer-Based Reconstruction of Atmospheric CO2 in Canadian Poultry Regions",
        "author": [
            "Padmanabhan Jagannathan Prajesh",
            "Kaliaperumal Ragunath",
            "Miriam Gordon",
            "Bruce Rathgeber",
            "Suresh Neethirajan"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23663",
        "abstract": "Accurate mapping of column-averaged CO2 (XCO2) over agricultural landscapes is essential for guiding emission mitigation strategies. We present a Spatiotemporal Vision Transformer with Wavelets (ST-ViWT) framework that reconstructs continuous, uncertainty-quantified XCO2 fields from OCO-2 across southern Canada, emphasizing poultry-intensive regions. The model fuses wavelet time-frequency representations with transformer attention over meteorology, vegetation indices, topography, and land cover. On 2024 OCO-2 data, ST-ViWT attains R2 = 0.984 and RMSE = 0.468 ppm; 92.3 percent of gap-filled predictions lie within +/-1 ppm. Independent validation with TCCON shows robust generalization (bias = -0.14 ppm; r = 0.928), including faithful reproduction of the late-summer drawdown. Spatial analysis across 14 poultry regions reveals a moderate positive association between facility density and XCO2 (r = 0.43); high-density areas exhibit larger seasonal amplitudes (9.57 ppm) and enhanced summer variability. Compared with conventional interpolation and standard machine-learning baselines, ST-ViWT yields seamless 0.25 degree CO2 surfaces with explicit uncertainties, enabling year-round coverage despite sparse observations. The approach supports integration of satellite constraints with national inventories and precision livestock platforms to benchmark emissions, refine region-specific factors, and verify interventions. Importantly, transformer-based Earth observation enables scalable, transparent, spatially explicit carbon accounting, hotspot prioritization, and policy-relevant mitigation assessment.",
        "tags": [
            "Transformer",
            "ViT"
        ]
    },
    {
        "id": "19",
        "title": "Agentsway -- Software Development Methodology for AI Agents-based Teams",
        "author": [
            "Eranga Bandara",
            "Ross Gore",
            "Xueping Liang",
            "Sachini Rajapakse",
            "Isurunima Kularathne",
            "Pramoda Karunarathna",
            "Peter Foytik",
            "Sachin Shetty",
            "Ravi Mukkamala",
            "Abdul Rahman",
            "Amin Hass",
            "Ng Wee Keong",
            "Kasun De Zoysa",
            "Aruna Withanage",
            "Nilaan Loganathan"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23664",
        "abstract": "The emergence of Agentic AI is fundamentally transforming how software is designed, developed, and maintained. Traditional software development methodologies such as Agile, Kanban, ShapeUp, etc, were originally designed for human-centric teams and are increasingly inadequate in environments where autonomous AI agents contribute to planning, coding, testing, and continuous learning. To address this methodological gap, we present \"Agentsway\" a novel software development framework designed for ecosystems where AI agents operate as first-class collaborators. Agentsway introduces a structured lifecycle centered on human orchestration, and privacy-preserving collaboration among specialized AI agents. The framework defines distinct roles for planning, prompting, coding, testing, and fine-tuning agents, each contributing to iterative improvement and adaptive learning throughout the development process. By integrating fine-tuned LLMs that leverage outputs and feedback from different agents throughout the development cycle as part of a retrospective learning process, Agentsway enhances domain-specific reasoning, and explainable decision-making across the entire software development lifecycle. Responsible AI principles are further embedded across the agents through the coordinated use of multiple fine-tuned LLMs and advanced reasoning models, ensuring balanced, transparent, and accountable decision-making. This work advances software engineering by formalizing agent-centric collaboration, integrating privacy-by-design principles, and defining measurable metrics for productivity and trust. Agentsway represents a foundational step toward the next generation of AI-native, self-improving software development methodologies. To the best of our knowledge, this is the first research effort to introduce a dedicated methodology explicitly designed for AI agent-based software engineering teams.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "20",
        "title": "Transformers from Compressed Representations",
        "author": [
            "Juan C. Leon Alcazar",
            "Mattia Soldan",
            "Mohammad Saatialsoruji",
            "Alejandro Pardo",
            "Hani Itani",
            "Juan Camilo Perez",
            "Bernard Ghanem"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23665",
        "abstract": "Compressed file formats are the corner stone of efficient data storage and transmission, yet their potential for representation learning remains largely underexplored. We introduce TEMPEST (TransformErs froM comPressed rEpreSenTations), a method that exploits the inherent byte-stream structure of compressed files to design an effective tokenization and encoding strategy. By leveraging this compact encoding, a standard transformer can directly learn semantic representations from compressed data streams, bypassing the need for raw byte-level processing or full media decoding. Our proposal substantially reduces the number of tokens required for semantic classification, thereby lowering both computational complexity and memory usage. Through extensive experiments across diverse datasets, coding schemes, and modalities, we show that TEMPEST achieves accuracy competitive wit the state-of-the-art while delivering efficiency gains in memory and compute.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "21",
        "title": "Optimize Any Topology: A Foundation Model for Shape- and Resolution-Free Structural Topology Optimization",
        "author": [
            "Amin Heyrani Nobari",
            "Lyle Regenwetter",
            "Cyril Picard",
            "Ligong Han",
            "Faez Ahmed"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23667",
        "abstract": "Structural topology optimization (TO) is central to engineering design but remains computationally intensive due to complex physics and hard constraints. Existing deep-learning methods are limited to fixed square grids, a few hand-coded boundary conditions, and post-hoc optimization, preventing general deployment. We introduce Optimize Any Topology (OAT), a foundation-model framework that directly predicts minimum-compliance layouts for arbitrary aspect ratios, resolutions, volume fractions, loads, and fixtures. OAT combines a resolution- and shape-agnostic autoencoder with an implicit neural-field decoder and a conditional latent-diffusion model trained on OpenTO, a new corpus of 2.2 million optimized structures covering 2 million unique boundary-condition configurations. On four public benchmarks and two challenging unseen tests, OAT lowers mean compliance up to 90% relative to the best prior models and delivers sub-1 second inference on a single GPU across resolutions from 64 x 64 to 256 x 256 and aspect ratios as high as 10:1. These results establish OAT as a general, fast, and resolution-free framework for physics-aware topology optimization and provide a large-scale dataset to spur further research in generative modeling for inverse design. Code & data can be found at https://github.com/ahnobari/OptimizeAnyTopology.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "22",
        "title": "Sparsity and Superposition in Mixture of Experts",
        "author": [
            "Marmik Chaudhari",
            "Jeremi Nuer",
            "Rome Thorstenson"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23671",
        "abstract": "Mixture of Experts (MoE) models have become central to scaling large language models, yet their mechanistic differences from dense networks remain poorly understood. Previous work has explored how dense models use \\textit{superposition} to represent more features than dimensions, and how superposition is a function of feature sparsity and feature importance. MoE models cannot be explained mechanistically through the same lens. We find that neither feature sparsity nor feature importance cause discontinuous phase changes, and that network sparsity (the ratio of active to total experts) better characterizes MoEs. We develop new metrics for measuring superposition across experts. Our findings demonstrate that models with greater network sparsity exhibit greater \\emph{monosemanticity}. We propose a new definition of expert specialization based on monosemantic feature representation rather than load balancing, showing that experts naturally organize around coherent feature combinations when initialized appropriately. These results suggest that network sparsity in MoEs may enable more interpretable models without sacrificing performance, challenging the common assumption that interpretability and capability are fundamentally at odds.",
        "tags": [
            "LLM",
            "MoE"
        ]
    },
    {
        "id": "23",
        "title": "MCPGuard : Automatically Detecting Vulnerabilities in MCP Servers",
        "author": [
            "Bin Wang",
            "Zexin Liu",
            "Hao Yu",
            "Ao Yang",
            "Yenan Huang",
            "Jing Guo",
            "Huangsheng Cheng",
            "Hui Li",
            "Huiyu Wu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23673",
        "abstract": "The Model Context Protocol (MCP) has emerged as a standardized interface enabling seamless integration between Large Language Models (LLMs) and external data sources and tools. While MCP significantly reduces development complexity and enhances agent capabilities, its openness and extensibility introduce critical security vulnerabilities that threaten system trustworthiness and user data protection. This paper systematically analyzes the security landscape of MCP-based systems, identifying three principal threat categories: (1) agent hijacking attacks stemming from protocol design deficiencies; (2) traditional web vulnerabilities in MCP servers; and (3) supply chain security. To address these challenges, we comprehensively survey existing defense strategies, examining both proactive server-side scanning approaches, ranging from layered detection pipelines and agentic auditing frameworks to zero-trust registry systems, and runtime interaction monitoring solutions that provide continuous oversight and policy enforcement. Our analysis reveals that MCP security fundamentally represents a paradigm shift where the attack surface extends from traditional code execution to semantic interpretation of natural language metadata, necessitating novel defense mechanisms tailored to this unique threat model.",
        "tags": [
            "Detection",
            "LLM"
        ]
    },
    {
        "id": "24",
        "title": "RefleXGen:The unexamined code is not worth using",
        "author": [
            "Bin Wang",
            "Hui Li",
            "AoFan Liu",
            "BoTao Yang",
            "Ao Yang",
            "YiLu Zhong",
            "Weixiang Huang",
            "Yanping Zhang",
            "Runhuai Huang",
            "Weimin Zeng"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23674",
        "abstract": "Security in code generation remains a pivotal challenge when applying large language models (LLMs). This paper introduces RefleXGen, an innovative method that significantly enhances code security by integrating Retrieval-Augmented Generation (RAG) techniques with guided self-reflection mechanisms inherent in LLMs. Unlike traditional approaches that rely on fine-tuning LLMs or developing specialized secure code datasets - processes that can be resource-intensive - RefleXGen iteratively optimizes the code generation process through self-assessment and reflection without the need for extensive resources. Within this framework, the model continuously accumulates and refines its knowledge base, thereby progressively improving the security of the generated code. Experimental results demonstrate that RefleXGen substantially enhances code security across multiple models, achieving a 13.6% improvement with GPT-3.5 Turbo, a 6.7% improvement with GPT-4o, a 4.5% improvement with CodeQwen, and a 5.8% improvement with Gemini. Our findings highlight that improving the quality of model self-reflection constitutes an effective and practical strategy for strengthening the security of AI-generated code.",
        "tags": [
            "GPT",
            "LLM",
            "RAG"
        ]
    },
    {
        "id": "25",
        "title": "QueryIPI: Query-agnostic Indirect Prompt Injection on Coding Agents",
        "author": [
            "Yuchong Xie",
            "Zesen Liu",
            "Mingyu Luo",
            "Zhixiang Zhang",
            "Kaikai Zhang",
            "Zongjie Li",
            "Ping Chen",
            "Shuai Wang",
            "Dongdong She"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23675",
        "abstract": "Modern coding agents integrated into IDEs combine powerful tools and system-level actions, exposing a high-stakes attack surface. Existing Indirect Prompt Injection (IPI) studies focus mainly on query-specific behaviors, leading to unstable attacks with lower success rates. We identify a more severe, query-agnostic threat that remains effective across diverse user inputs. This challenge can be overcome by exploiting a common vulnerability: leakage of the agent's internal prompt, which turns the attack into a constrained white-box optimization problem. We present QueryIPI, the first query-agnostic IPI method for coding agents. QueryIPI refines malicious tool descriptions through an iterative, prompt-based process informed by the leaked internal prompt. Experiments on five simulated agents show that QueryIPI achieves up to 87 percent success, outperforming baselines, and the generated malicious descriptions also transfer to real-world systems, highlighting a practical security risk to modern LLM-based coding agents.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "26",
        "title": "Beyond Prompt Engineering: Neuro-Symbolic-Causal Architecture for Robust Multi-Objective AI Agents",
        "author": [
            "Gokturk Aytug Akarlar"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23682",
        "abstract": "Large language models show promise as autonomous decision-making agents, yet their deployment in high-stakes domains remains fraught with risk. Without architectural safeguards, LLM agents exhibit catastrophic brittleness: identical capabilities produce wildly different outcomes depending solely on prompt framing. We present Chimera, a neuro-symbolic-causal architecture that integrates three complementary components - an LLM strategist, a formally verified symbolic constraint engine, and a causal inference module for counterfactual reasoning. We benchmark Chimera against baseline architectures (LLM-only, LLM with symbolic constraints) across 52-week simulations in a realistic e-commerce environment featuring price elasticity, trust dynamics, and seasonal demand. Under organizational biases toward either volume or margin optimization, LLM-only agents fail catastrophically (total loss of \\$99K in volume scenarios) or destroy brand trust (-48.6% in margin scenarios). Adding symbolic constraints prevents disasters but achieves only 43-87% of Chimera's profit. Chimera consistently delivers the highest returns (\\$1.52M and \\$1.96M respectively, some cases +\\$2.2M) while improving brand trust (+1.8% and +10.8%, some cases +20.86%), demonstrating prompt-agnostic robustness. Our TLA+ formal verification proves zero constraint violations across all scenarios. These results establish that architectural design not prompt engineering determines the reliability of autonomous agents in production environments. We provide open-source implementations and interactive demonstrations for reproducibility.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "27",
        "title": "Parallel BiLSTM-Transformer networks for forecasting chaotic dynamics",
        "author": [
            "Junwen Ma",
            "Mingyu Ge",
            "Yisen Wang",
            "Yong Zhang",
            "Weicheng Fu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23685",
        "abstract": "The nonlinear nature of chaotic systems results in extreme sensitivity to initial conditions and highly intricate dynamical behaviors, posing fundamental challenges for accurately predicting their evolution. To overcome the limitation that conventional approaches fail to capture both local features and global dependencies in chaotic time series simultaneously, this study proposes a parallel predictive framework integrating Transformer and Bidirectional Long Short-Term Memory (BiLSTM) networks. The hybrid model employs a dual-branch architecture, where the Transformer branch mainly captures long-range dependencies while the BiLSTM branch focuses on extracting local temporal features. The complementary representations from the two branches are fused in a dedicated feature-fusion layer to enhance predictive accuracy. As illustrating examples, the model's performance is systematically evaluated on two representative tasks in the Lorenz system. The first is autonomous evolution prediction, in which the model recursively extrapolates system trajectories from the time-delay embeddings of the state vector to evaluate long-term tracking accuracy and stability. The second is inference of unmeasured variable, where the model reconstructs the unobserved states from the time-delay embeddings of partial observations to assess its state-completion capability. The results consistently indicate that the proposed hybrid framework outperforms both single-branch architectures across tasks, demonstrating its robustness and effectiveness in chaotic system prediction.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "28",
        "title": "Game-TARS: Pretrained Foundation Models for Scalable Generalist Multimodal Game Agents",
        "author": [
            "Zihao Wang",
            "Xujing Li",
            "Yining Ye",
            "Junjie Fang",
            "Haoming Wang",
            "Longxiang Liu",
            "Shihao Liang",
            "Junting Lu",
            "Zhiyong Wu",
            "Jiazhan Feng",
            "Wanjun Zhong",
            "Zili Li",
            "Yu Wang",
            "Yu Miao",
            "Bo Zhou",
            "Yuanfan Li",
            "Hao Wang",
            "Zhongkai Zhao",
            "Faming Wu",
            "Zhengxuan Jiang",
            "Weihao Tan",
            "Heyuan Yao",
            "Shi Yan",
            "Xiangyang Li",
            "Yitao Liang",
            "Yujia Qin",
            "Guang Shi"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23691",
        "abstract": "We present Game-TARS, a generalist game agent trained with a unified, scalable action space anchored to human-aligned native keyboard-mouse inputs. Unlike API- or GUI-based approaches, this paradigm enables large-scale continual pre-training across heterogeneous domains, including OS, web, and simulation games. Game-TARS is pre-trained on over 500B tokens with diverse trajectories and multimodal data. Key techniques include a decaying continual loss to reduce causal confusion and an efficient Sparse-Thinking strategy that balances reasoning depth and inference cost. Experiments show that Game-TARS achieves about 2 times the success rate over the previous sota model on open-world Minecraft tasks, is close to the generality of fresh humans in unseen web 3d games, and outperforms GPT-5, Gemini-2.5-Pro, and Claude-4-Sonnet in FPS benchmarks. Scaling results on training-time and test-time confirm that the unified action space sustains improvements when scaled to cross-game and multimodal data. Our results demonstrate that simple, scalable action representations combined with large-scale pre-training provide a promising path toward generalist agents with broad computer-use abilities.",
        "tags": [
            "3D",
            "GPT"
        ]
    },
    {
        "id": "29",
        "title": "Evaluating Long-Term Memory for Long-Context Question Answering",
        "author": [
            "Alessandra Terranova",
            "BjÃ¶rn Ross",
            "Alexandra Birch"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23730",
        "abstract": "In order for large language models to achieve true conversational continuity and benefit from experiential learning, they need memory. While research has focused on the development of complex memory systems, it remains unclear which types of memory are most effective for long-context conversational tasks. We present a systematic evaluation of memory-augmented methods using LoCoMo, a benchmark of synthetic long-context dialogues annotated for question-answering tasks that require diverse reasoning strategies. We analyse full-context prompting, semantic memory through retrieval-augmented generation and agentic memory, episodic memory through in-context learning, and procedural memory through prompt optimization. Our findings show that memory-augmented approaches reduce token usage by over 90% while maintaining competitive accuracy. Memory architecture complexity should scale with model capability, with small foundation models benefitting most from RAG, and strong instruction-tuned reasoning model gaining from episodic learning through reflections and more complex agentic semantic memory. In particular, episodic memory can help LLMs recognise the limits of their own knowledge.",
        "tags": [
            "LLM",
            "RAG"
        ]
    },
    {
        "id": "30",
        "title": "Debiasing Reward Models by Representation Learning with Guarantees",
        "author": [
            "Ignavier Ng",
            "Patrick BlÃ¶baum",
            "Siddharth Bhandari",
            "Kun Zhang",
            "Shiva Kasiviswanathan"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23751",
        "abstract": "Recent alignment techniques, such as reinforcement learning from human feedback, have been widely adopted to align large language models with human preferences by learning and leveraging reward models. In practice, these models often exploit spurious correlations, involving, e.g., response length, discrimination, sycophancy, and conceptual bias, which is a problem that has received increasing attention. In this work, we propose a principled framework that mitigates these biases in reward models while preserving the underlying factors that reflect intended preferences. We first provide a formulation of the data-generating process, assuming that the observed data (e.g., text) is generated from both spurious and non-spurious latent variables. We show that, interestingly, these non-spurious latent variables can be theoretically identified from data, regardless of whether a surrogate for the spurious latent variables is available. This further inspires a practical method that uses variational inference to recover these variables and leverages them to train reward models. Experiments on synthetic and real-world datasets demonstrate that our method effectively mitigates spurious correlation issues and yields more robust reward models.",
        "tags": [
            "LLM",
            "RL",
            "RLHF"
        ]
    },
    {
        "id": "31",
        "title": "TDFlow: Agentic Workflows for Test Driven Software Engineering",
        "author": [
            "Kevin Han",
            "Siddharth Maddikayala",
            "Tim Knappe",
            "Om Patel",
            "Austen Liao",
            "Amir Barati Farimani"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23761",
        "abstract": "We introduce TDFlow, a novel test-driven agentic workflow that frames repository-scale software engineering as a test-resolution task, specifically designed to solve human-written tests. Given a set of tests, TDFlow repeatedly proposes, revises, and debugs repository-scale patches using precisely engineered sub-agents and tightly constrained tools. The workflow decomposes software engineering program repair into four components governed by respective sub-agents. This simple, forced decoupling of patch proposing, debugging, patch revision, and optional test generation (1) reduces long-context burden on any individual sub-agent, (2) focuses each sub-agent on specific, pre-defined sub-tasks, and (3) allows for specialized performance improvement on specific sub-tasks. When provided human-written tests, TDFlow attains 88.8% pass rate on SWE-Bench Lite (an absolute improvement of 27.8% over the next best system) and 94.3% on SWE-Bench Verified. Manual inspection of the 800 TDFlow runs within SWE-Bench Lite and Verified uncover only 7 instances of test hacking, which were subsequently counted as failures. Furthermore, we show that the primary obstacle to human-level software engineering performance lies within writing successful reproduction tests. We envision a human-LLM interactive system powered by TDFlow where human developers write tests solved by LLM systems. Together, these results indicate that modern LLMs, when embedded in a narrowly engineered, test-driven workflow, already achieve human-level test resolution -- with the final frontier for fully autonomous repository repair being the accurate generation of valid reproduction tests.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "32",
        "title": "RoboOmni: Proactive Robot Manipulation in Omni-modal Context",
        "author": [
            "Siyin Wang",
            "Jinlan Fu",
            "Feihong Liu",
            "Xinzhe He",
            "Huangxuan Wu",
            "Junhao Shi",
            "Kexin Huang",
            "Zhaoye Fei",
            "Jingjing Gong",
            "Zuxuan Wu",
            "Yugang Jiang",
            "See-Kiong Ng",
            "Tat-Seng Chua",
            "Xipeng Qiu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23763",
        "abstract": "Recent advances in Multimodal Large Language Models (MLLMs) have driven rapid progress in Vision-Language-Action (VLA) models for robotic manipulation. Although effective in many scenarios, current approaches largely rely on explicit instructions, whereas in real-world interactions, humans rarely issue instructions directly. Effective collaboration requires robots to infer user intentions proactively. In this work, we introduce cross-modal contextual instructions, a new setting where intent is derived from spoken dialogue, environmental sounds, and visual cues rather than explicit commands. To address this new setting, we present RoboOmni, a Perceiver-Thinker-Talker-Executor framework based on end-to-end omni-modal LLMs that unifies intention recognition, interaction confirmation, and action execution. RoboOmni fuses auditory and visual signals spatiotemporally for robust intention recognition, while supporting direct speech interaction. To address the absence of training data for proactive intention recognition in robotic manipulation, we build OmniAction, comprising 140k episodes, 5k+ speakers, 2.4k event sounds, 640 backgrounds, and six contextual instruction types. Experiments in simulation and real-world settings show that RoboOmni surpasses text- and ASR-based baselines in success rate, inference speed, intention recognition, and proactive assistance.",
        "tags": [
            "LLM",
            "Robotics"
        ]
    },
    {
        "id": "33",
        "title": "BitSkip: An Empirical Analysis of Quantization and Early Exit Composition",
        "author": [
            "Ramshankar Bhuvaneswaran",
            "Handan Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23766",
        "abstract": "The pursuit of efficient Large Language Models (LLMs) has led to increasingly complex techniques like extreme quantization and dynamic routing. While individual benefits of these methods are well-documented, their compositional effects remain poorly understood. This paper introduces BitSkip, a hybrid architectural framework for systematically explor- ing these interactions. Counter-intuitively, our findings reveal that a simple 8-bit quantized model without Hadamard transform (BitSkip-V1) not only outperforms its more complex 4-bit and Hadamard-enhanced counterparts but also competes the full-precision baseline in quality (perplexity of 1.13 vs 1.19) . The introduction of Hadamard transforms, even at 8- bit precision, catastrophically degraded performance by over 37,000%, tracing fundamental training instability. Our BitSkip-V1 recipe demonstrates superior early-exit characteristics, with layer 18 providing optimal 32.5% speed gain for minimal 4% quality loss.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "34",
        "title": "Explainable Detection of AI-Generated Images with Artifact Localization Using Faster-Than-Lies and Vision-Language Models for Edge Devices",
        "author": [
            "Aryan Mathur",
            "Asaduddin Ahmed",
            "Pushti Amit Vasoya",
            "Simeon Kandan Sonar",
            "Yasir Z",
            "Madesh Kuppusamy"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23775",
        "abstract": "The increasing realism of AI-generated imagery poses challenges for verifying visual authenticity. We present an explainable image authenticity detection system that combines a lightweight convolutional classifier (\"Faster-Than-Lies\") with a Vision-Language Model (Qwen2-VL-7B) to classify, localize, and explain artifacts in 32x32 images. Our model achieves 96.5% accuracy on the extended CiFAKE dataset augmented with adversarial perturbations and maintains an inference time of 175ms on 8-core CPUs, enabling deployment on local or edge devices. Using autoencoder-based reconstruction error maps, we generate artifact localization heatmaps, which enhance interpretability for both humans and the VLM. We further categorize 70 visual artifact types into eight semantic groups and demonstrate explainable text generation for each detected anomaly. This work highlights the feasibility of combining visual and linguistic reasoning for interpretable authenticity detection in low-resolution imagery and outlines potential cross-domain applications in forensics, industrial inspection, and social media moderation.",
        "tags": [
            "Detection",
            "VLM"
        ]
    },
    {
        "id": "35",
        "title": "CountFormer: A Transformer Framework for Learning Visual Repetition and Structure in Class-Agnostic Object Counting",
        "author": [
            "Md Tanvir Hossain",
            "Akif Islam",
            "Mohd Ruhul Ameen"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23785",
        "abstract": "Humans can effortlessly count diverse objects by perceiving visual repetition and structural relationships rather than relying on class identity. However, most existing counting models fail to replicate this ability; they often miscount when objects exhibit complex shapes, internal symmetry, or overlapping components. In this work, we introduce CountFormer, a transformer-based framework that learns to recognize repetition and structural coherence for class-agnostic object counting. Built upon the CounTR architecture, our model replaces its visual encoder with the self-supervised foundation model DINOv2, which produces richer and spatially consistent feature representations. We further incorporate positional embedding fusion to preserve geometric relationships before decoding these features into density maps through a lightweight convolutional decoder. Evaluated on the FSC-147 dataset, our model achieves performance comparable to current state-of-the-art methods while demonstrating superior accuracy on structurally intricate or densely packed scenes. Our findings indicate that integrating foundation models such as DINOv2 enables counting systems to approach human-like structural perception, advancing toward a truly general and exemplar-free counting paradigm.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "36",
        "title": "Learning Interpretable Features in Audio Latent Spaces via Sparse Autoencoders",
        "author": [
            "Nathan Paek",
            "Yongyi Zang",
            "Qihui Yang",
            "Randal Leistikow"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23802",
        "abstract": "While sparse autoencoders (SAEs) successfully extract interpretable features from language models, applying them to audio generation faces unique challenges: audio's dense nature requires compression that obscures semantic meaning, and automatic feature characterization remains limited. We propose a framework for interpreting audio generative models by mapping their latent representations to human-interpretable acoustic concepts. We train SAEs on audio autoencoder latents, then learn linear mappings from SAE features to discretized acoustic properties (pitch, amplitude, and timbre). This enables both controllable manipulation and analysis of the AI music generation process, revealing how acoustic properties emerge during synthesis. We validate our approach on continuous (DiffRhythm-VAE) and discrete (EnCodec, WavTokenizer) audio latent spaces, and analyze DiffRhythm, a state-of-the-art text-to-music model, to demonstrate how pitch, timbre, and loudness evolve throughout generation. While our work is only done on audio modality, our framework can be extended to interpretable analysis of visual latent space generation models.",
        "tags": [
            "VAE"
        ]
    },
    {
        "id": "37",
        "title": "ScaLoRA: Optimally Scaled Low-Rank Adaptation for Efficient High-Rank Fine-Tuning",
        "author": [
            "Yilang Zhang",
            "Xiaodong Yang",
            "Yiwei Cai",
            "Georgios B. Giannakis"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23818",
        "abstract": "As large language models (LLMs) continue to scale in size, the computational overhead has become a major bottleneck for task-specific fine-tuning. While low-rank adaptation (LoRA) effectively curtails this cost by confining the weight updates to a low-dimensional subspace, such a restriction can hinder effectiveness and slow convergence. This contribution deals with these limitations by accumulating progressively a high-rank weight update from consecutive low-rank increments. Specifically, the per update optimal low-rank matrix is identified to minimize the loss function and closely approximate full fine-tuning. To endow efficient and seamless optimization without restarting, this optimal choice is formed by appropriately scaling the columns of the original low-rank matrix. Rigorous performance guarantees reveal that the optimal scaling can be found analytically. Extensive numerical tests with popular LLMs scaling up to 12 billion parameters demonstrate a consistent performance gain and fast convergence relative to state-of-the-art LoRA variants on diverse tasks including natural language understanding, commonsense reasoning, and mathematical problem solving.",
        "tags": [
            "LLM",
            "LoRA"
        ]
    },
    {
        "id": "38",
        "title": "ReCAP: Recursive Context-Aware Reasoning and Planning for Large Language Model Agents",
        "author": [
            "Zhenyu Zhang",
            "Tianyi Chen",
            "Weiran Xu",
            "Alex Pentland",
            "Jiaxin Pei"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23822",
        "abstract": "Long-horizon tasks requiring multi-step reasoning and dynamic re-planning remain challenging for large language models (LLMs). Sequential prompting methods are prone to context drift, loss of goal information, and recurrent failure cycles, while hierarchical prompting methods often weaken cross-level continuity or incur substantial runtime overhead. We introduce ReCAP (Recursive Context-Aware Reasoning and Planning), a hierarchical framework with shared context for reasoning and planning in LLMs. ReCAP combines three key mechanisms: (i) plan-ahead decomposition, in which the model generates a full subtask list, executes the first item, and refines the remainder; (ii) structured re-injection of parent plans, maintaining consistent multi-level context during recursive return; and (iii) memory-efficient execution, bounding the active prompt so costs scale linearly with task depth. Together these mechanisms align high-level goals with low-level actions, reduce redundant prompting, and preserve coherent context updates across recursion. Experiments demonstrate that ReCAP substantially improves subgoal alignment and success rates on various long-horizon reasoning benchmarks, achieving a 32% gain on synchronous Robotouille and a 29% improvement on asynchronous Robotouille under the strict pass@1 protocol.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "39",
        "title": "Decentralized Multi-Agent Goal Assignment for Path Planning using Large Language Models",
        "author": [
            "Murad Ismayilov",
            "Edwin Meriaux",
            "Shuo Wen",
            "Gregory Dudek"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23824",
        "abstract": "Coordinating multiple autonomous agents in shared environments under decentralized conditions is a long-standing challenge in robotics and artificial intelligence. This work addresses the problem of decentralized goal assignment for multi-agent path planning, where agents independently generate ranked preferences over goals based on structured representations of the environment, including grid visualizations and scenario data. After this reasoning phase, agents exchange their goal rankings, and assignments are determined by a fixed, deterministic conflict-resolution rule (e.g., agent index ordering), without negotiation or iterative coordination. We systematically compare greedy heuristics, optimal assignment, and large language model (LLM)-based agents in fully observable grid-world settings. Our results show that LLM-based agents, when provided with well-designed prompts and relevant quantitative information, can achieve near-optimal makespans and consistently outperform traditional heuristics. These findings underscore the potential of language models for decentralized goal assignment in multi-agent path planning and highlight the importance of information structure in such systems.",
        "tags": [
            "LLM",
            "Robotics"
        ]
    },
    {
        "id": "40",
        "title": "Beyond Understanding: Evaluating the Pragmatic Gap in LLMs' Cultural Processing of Figurative Language",
        "author": [
            "Mena Attia",
            "Aashiq Muhamed",
            "Mai Alkhamissi",
            "Thamar Solorio",
            "Mona Diab"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23828",
        "abstract": "We present a comprehensive evaluation of the ability of large language models (LLMs) to process culturally grounded language, specifically to understand and pragmatically use figurative expressions that encode local knowledge and cultural nuance. Using figurative language as a proxy for cultural nuance and local knowledge, we design evaluation tasks for contextual understanding, pragmatic use, and connotation interpretation in Arabic and English. We evaluate 22 open- and closed-source LLMs on Egyptian Arabic idioms, multidialectal Arabic proverbs, and English proverbs. Our results show a consistent hierarchy: the average accuracy for Arabic proverbs is 4.29% lower than for English proverbs, and performance for Egyptian idioms is 10.28% lower than for Arabic proverbs. For the pragmatic use task, accuracy drops by 14.07% relative to understanding, though providing contextual idiomatic sentences improves accuracy by 10.66%. Models also struggle with connotative meaning, reaching at most 85.58% agreement with human annotators on idioms with 100% inter-annotator agreement. These findings demonstrate that figurative language serves as an effective diagnostic for cultural reasoning: while LLMs can often interpret figurative meaning, they face challenges in using it appropriately. To support future research, we release Kinayat, the first dataset of Egyptian Arabic idioms designed for both figurative understanding and pragmatic use evaluation.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "41",
        "title": "Temporal Blindness in Multi-Turn LLM Agents: Misaligned Tool Use vs. Human Time Perception",
        "author": [
            "Yize Cheng",
            "Arshia Soltani Moakhar",
            "Chenrui Fan",
            "Kazem Faghih",
            "Parsa Hosseini",
            "Wenxiao Wang",
            "Soheil Feizi"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23853",
        "abstract": "Large language model agents are increasingly used in multi-turn conversational settings to interact with and execute tasks in dynamic environments. However, a key limitation is their temporal blindness: they, by default, operate with a stationary context, failing to account for the real-world time elapsed between messages. This becomes a critical liability when an agent must decide whether to invoke a tool based on how much time has passed since the last observation. Without temporal awareness, agents often either over-rely on previous context (skipping necessary tool calls), or under-rely on it (unnecessarily repeating tool calls). To study this challenge, we introduce TicToc-v1, a test set of multi-turn user-agent trajectories across 34 scenarios with varying time sensitivity. Each trajectory ends with a user question, where the need for a tool call depends on the amount of time elapsed since the last message. To give LLMs temporal context, we augment dialogue messages with explicit timestamps, bridging the gap between static dialogue and evolving environments. We then collected human preferences for these samples, creating two subsets: one where humans preferred relying on the previous observation (prefer-noTool), and another where they preferred a new tool call (prefer-Tool). We evaluated how well LLM tool-calling decisions align with human preferences under varying time intervals on TicToc-v1. Our analysis show that without time information, most models perform only slightly better than random, with the top alignment rate being just over 60%. While adding timestamps leads to a slight improvement, particularly for larger models, the improvement is modest, peaking at around 65%. We also show that naive, prompt-based alignment have limited effectiveness. Our findings highlight the need for specific post-training alignment to align multi-turn LLM tool use with human temporal perception.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "42",
        "title": "Motivating Students' Self-study with Goal Reminder and Emotional Support",
        "author": [
            "Hyung Chan Cho",
            "Go-Eum Cha",
            "Yanfu Liu",
            "Sooyeon Jeong"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23860",
        "abstract": "While the efficacy of social robots in supporting people in learning tasks has been extensively investigated, their potential impact in assisting students in self-studying contexts has not been investigated much. This study explores how a social robot can act as a peer study companion for college students during self-study tasks by delivering task-oriented goal reminder and positive emotional support. We conducted an exploratory Wizard-of-Oz study to explore how these robotic support behaviors impacted students' perceived focus, productivity, and engagement in comparison to a robot that only provided physical presence (control). Our study results suggest that participants in the goal reminder and the emotional support conditions reported greater ease of use, with the goal reminder condition additionally showing a higher willingness to use the robot in future study sessions. Participants' satisfaction with the robot was correlated with their perception of the robot as a social other, and this perception was found to be a predictor for their level of goal achievement in the self-study task. These findings highlight the potential of socially assistive robots to support self-study through both functional and emotional engagement.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "43",
        "title": "A PDE-Informed Latent Diffusion Model for 2-m Temperature Downscaling",
        "author": [
            "Paul Rosu",
            "Muchang Bahng",
            "Erick Jiang",
            "Rico Zhu",
            "Vahid Tarokh"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23866",
        "abstract": "This work presents a physics-conditioned latent diffusion model tailored for dynamical downscaling of atmospheric data, with a focus on reconstructing high-resolution 2-m temperature fields. Building upon a pre-existing diffusion architecture and employing a residual formulation against a reference UNet, we integrate a partial differential equation (PDE) loss term into the model's training objective. The PDE loss is computed in the full resolution (pixel) space by decoding the latent representation and is designed to enforce physical consistency through a finite-difference approximation of an effective advection-diffusion balance. Empirical observations indicate that conventional diffusion training already yields low PDE residuals, and we investigate how fine-tuning with this additional loss further regularizes the model and enhances the physical plausibility of the generated fields. The entirety of our codebase is available on Github, for future reference and development.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "44",
        "title": "GIFT: Group-relative Implicit Fine Tuning Integrates GRPO with DPO and UNA",
        "author": [
            "Zhichao Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23868",
        "abstract": "I propose \\textbf{G}roup-relative \\textbf{I}mplicit \\textbf{F}ine \\textbf{T}uning (GIFT), a novel reinforcement learning framework for aligning LLMs. Instead of directly maximizing cumulative rewards like PPO or GRPO, GIFT minimizes the discrepancy between implicit and explicit reward models. It combines three key ideas: (1) the online multi-response generation and normalization of GRPO, (2) the implicit reward formulation of DPO, and (3) the implicit-explicit reward alignment principle of UNA. By jointly normalizing the implicit and explicit rewards, GIFT eliminates an otherwise intractable term that prevents effective use of implicit rewards. This normalization transforms the complex reward maximization objective into a simple mean squared error (MSE) loss between the normalized reward functions, converting a non-convex optimization problem into a convex, stable, and analytically differentiable formulation. Unlike offline methods such as DPO and UNA, GIFT remains on-policy and thus retains exploration capability. Compared to GRPO, it requires fewer hyperparameters, converges faster, and generalizes better with significantly reduced training overfitting. Empirically, GIFT achieves superior reasoning and alignment performance on mathematical benchmarks while remaining computationally efficient.",
        "tags": [
            "DPO",
            "GRPO",
            "LLM",
            "PPO",
            "RL"
        ]
    },
    {
        "id": "45",
        "title": "OraPlan-SQL: A Planning-Centric Framework for Complex Bilingual NL2SQL Reasoning",
        "author": [
            "Marianne Menglin Liu",
            "Sai Ashish Somayajula",
            "Syed Fahad Allam Shah",
            "Sujith Ravi",
            "Dan Roth"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23870",
        "abstract": "We present OraPlan-SQL, our system for the Archer NL2SQL Evaluation Challenge 2025, a bilingual benchmark requiring complex reasoning such as arithmetic, commonsense, and hypothetical inference. OraPlan-SQL ranked first, exceeding the second-best system by more than 6% in execution accuracy (EX), with 55.0% in English and 56.7% in Chinese, while maintaining over 99% SQL validity (VA). Our system follows an agentic framework with two components: Planner agent that generates stepwise natural language plans, and SQL agent that converts these plans into executable SQL. Since SQL agent reliably adheres to the plan, our refinements focus on the planner. Unlike prior methods that rely on multiple sub-agents for planning and suffer from orchestration overhead, we introduce a feedback-guided meta-prompting strategy to refine a single planner. Failure cases from a held-out set are clustered with human input, and an LLM distills them into corrective guidelines that are integrated into the planner's system prompt, improving generalization without added complexity. For the multilingual scenario, to address transliteration and entity mismatch issues, we incorporate entity-linking guidelines that generate alternative surface forms for entities and explicitly include them in the plan. Finally, we enhance reliability through plan diversification: multiple candidate plans are generated for each query, with the SQL agent producing a query for each plan, and final output selected via majority voting over their executions.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "46",
        "title": "Large Language Model Agent Personality and Response Appropriateness: Evaluation by Human Linguistic Experts, LLM-as-Judge, and Natural Language Processing Model",
        "author": [
            "Eswari Jayakumar",
            "Niladri Sekhar Dash",
            "Debasmita Mukherjee"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23875",
        "abstract": "While Large Language Model (LLM)-based agents can be used to create highly engaging interactive applications through prompting personality traits and contextual data, effectively assessing their personalities has proven challenging. This novel interdisciplinary approach addresses this gap by combining agent development and linguistic analysis to assess the prompted personality of LLM-based agents in a poetry explanation task. We developed a novel, flexible question bank, informed by linguistic assessment criteria and human cognitive learning levels, offering a more comprehensive evaluation than current methods. By evaluating agent responses with natural language processing models, other LLMs, and human experts, our findings illustrate the limitations of purely deep learning solutions and emphasize the critical role of interdisciplinary design in agent development.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "47",
        "title": "TRELLISWorld: Training-Free World Generation from Object Generators",
        "author": [
            "Hanke Chen",
            "Yuan Liu",
            "Minchen Li"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23880",
        "abstract": "Text-driven 3D scene generation holds promise for a wide range of applications, from virtual prototyping to AR/VR and simulation. However, existing methods are often constrained to single-object generation, require domain-specific training, or lack support for full 360-degree viewability. In this work, we present a training-free approach to 3D scene synthesis by repurposing general-purpose text-to-3D object diffusion models as modular tile generators. We reformulate scene generation as a multi-tile denoising problem, where overlapping 3D regions are independently generated and seamlessly blended via weighted averaging. This enables scalable synthesis of large, coherent scenes while preserving local semantic control. Our method eliminates the need for scene-level datasets or retraining, relies on minimal heuristics, and inherits the generalization capabilities of object-level priors. We demonstrate that our approach supports diverse scene layouts, efficient generation, and flexible editing, establishing a simple yet powerful foundation for general-purpose, language-driven 3D scene construction.",
        "tags": [
            "3D",
            "Diffusion",
            "Text-to-3D"
        ]
    },
    {
        "id": "48",
        "title": "Generating Creative Chess Puzzles",
        "author": [
            "Xidong Feng",
            "Vivek Veeriah",
            "Marcus Chiam",
            "Michael Dennis",
            "Ryan Pachauri",
            "Thomas Tumiel",
            "Federico Barbero",
            "Johan Obando-Ceron",
            "Jiaxin Shi",
            "Satinder Singh",
            "Shaobo Hou",
            "Nenad TomaÅ¡ev",
            "Tom Zahavy"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23881",
        "abstract": "While Generative AI rapidly advances in various domains, generating truly creative, aesthetic, and counter-intuitive outputs remains a challenge. This paper presents an approach to tackle these difficulties in the domain of chess puzzles. We start by benchmarking Generative AI architectures, and then introduce an RL framework with novel rewards based on chess engine search statistics to overcome some of those shortcomings. The rewards are designed to enhance a puzzle's uniqueness, counter-intuitiveness, diversity, and realism. Our RL approach dramatically increases counter-intuitive puzzle generation by 10x, from 0.22\\% (supervised) to 2.5\\%, surpassing existing dataset rates (2.1\\%) and the best Lichess-trained model (0.4\\%). Our puzzles meet novelty and diversity benchmarks, retain aesthetic themes, and are rated by human experts as more creative, enjoyable, and counter-intuitive than composed book puzzles, even approaching classic compositions. Our final outcome is a curated booklet of these AI-generated puzzles, which is acknowledged for creativity by three world-renowned experts.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "49",
        "title": "Hybrid Modeling, Sim-to-Real Reinforcement Learning, and Large Language Model Driven Control for Digital Twins",
        "author": [
            "Adil Rasheed",
            "Oscar Ravik",
            "Omer San"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23882",
        "abstract": "This work investigates the use of digital twins for dynamical system modeling and control, integrating physics-based, data-driven, and hybrid approaches with both traditional and AI-driven controllers. Using a miniature greenhouse as a test platform, four predictive models Linear, Physics-Based Modeling (PBM), Long Short Term Memory (LSTM), and Hybrid Analysis and Modeling (HAM) are developed and compared under interpolation and extrapolation scenarios. Three control strategies Model Predictive Control (MPC), Reinforcement Learning (RL), and Large Language Model (LLM) based control are also implemented to assess trade-offs in precision, adaptability, and implementation effort. Results show that in modeling HAM provides the most balanced performance across accuracy, generalization, and computational efficiency, while LSTM achieves high precision at greater resource cost. Among controllers, MPC delivers robust and predictable performance, RL demonstrates strong adaptability, and LLM-based controllers offer flexible human-AI interaction when coupled with predictive tools.",
        "tags": [
            "LLM",
            "MPC",
            "RL"
        ]
    },
    {
        "id": "50",
        "title": "Agentic AI Security: Threats, Defenses, Evaluation, and Open Challenges",
        "author": [
            "Shrestha Datta",
            "Shahriar Kabir Nahin",
            "Anshuman Chhabra",
            "Prasant Mohapatra"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23883",
        "abstract": "Agentic AI systems powered by large language models (LLMs) and endowed with planning, tool use, memory, and autonomy, are emerging as powerful, flexible platforms for automation. Their ability to autonomously execute tasks across web, software, and physical environments creates new and amplified security risks, distinct from both traditional AI safety and conventional software security. This survey outlines a taxonomy of threats specific to agentic AI, reviews recent benchmarks and evaluation methodologies, and discusses defense strategies from both technical and governance perspectives. We synthesize current research and highlight open challenges, aiming to support the development of secure-by-design agent systems.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "51",
        "title": "Language Models for Longitudinal Clinical Prediction",
        "author": [
            "Tananun Songdechakraiwut",
            "Michael Lutz"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23884",
        "abstract": "We explore a lightweight framework that adapts frozen large language models to analyze longitudinal clinical data. The approach integrates patient history and context within the language model space to generate accurate forecasts without model fine-tuning. Applied to neuropsychological assessments, it achieves accurate and reliable performance even with minimal training data, showing promise for early-stage Alzheimer's monitoring.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "52",
        "title": "Evaluating the effectiveness of LLM-based interoperability",
        "author": [
            "Rodrigo FalcÃ£o",
            "Stefan Schweitzer",
            "Julien Siebert",
            "Emily Calvet",
            "Frank Elberzhager"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23893",
        "abstract": "Background: Systems of systems are becoming increasingly dynamic and heterogeneous, and this adds pressure on the long-standing challenge of interoperability. Besides its technical aspect, interoperability has also an economic side, as development time efforts are required to build the interoperability artifacts. Objectives: With the recent advances in the field of large language models (LLMs), we aim at analyzing the effectiveness of LLM-based strategies to make systems interoperate autonomously, at runtime, without human intervention. Method: We selected 13 open source LLMs and curated four versions of a dataset in the agricultural interoperability use case. We performed three runs of each model with each version of the dataset, using two different strategies. Then we compared the effectiveness of the models and the consistency of their results across multiple runs. Results: qwen2.5-coder:32b was the most effective model using both strategies DIRECT (average pass@1 >= 0.99) and CODEGEN (average pass@1 >= 0.89) in three out of four dataset versions. In the fourth dataset version, which included an unit conversion, all models using the strategy DIRECT failed, whereas using CODEGEN qwen2.5-coder:32b succeeded with an average pass@1 = 0.75. Conclusion: Some LLMs can make systems interoperate autonomously. Further evaluation in different domains is recommended, and further research on reliability strategies should be conducted.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "53",
        "title": "Improving Visual Discriminability of CLIP for Training-Free Open-Vocabulary Semantic Segmentation",
        "author": [
            "Jinxin Zhou",
            "Jiachen Jiang",
            "Zhihui Zhu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23894",
        "abstract": "Extending CLIP models to semantic segmentation remains challenging due to the misalignment between their image-level pre-training objectives and the pixel-level visual understanding required for dense prediction. While prior efforts have achieved encouraging results by reorganizing the final layer and features, they often inherit the global alignment bias of preceding layers, leading to suboptimal segmentation performance. In this work, we propose LHT-CLIP, a novel training-free framework that systematically exploits the visual discriminability of CLIP across layer, head, and token levels. Through comprehensive analysis, we reveal three key insights: (i) the final layers primarily strengthen image-text alignment with sacrifice of visual discriminability (e.g., last 3 layers in ViT-B/16 and 8 layers in ViT-L/14), partly due to the emergence of anomalous tokens; (ii) a subset of attention heads (e.g., 10 out of 144 in ViT-B/16) display consistently strong visual discriminability across datasets; (iii) abnormal tokens display sparse and consistent activation pattern compared to normal tokens. Based on these findings, we propose three complementary techniques: semantic-spatial reweighting, selective head enhancement, and abnormal token replacement to effectively restore visual discriminability and improve segmentation performance without any additional training, auxiliary pre-trained networks, or extensive hyperparameter tuning. Extensive experiments on 8 common semantic segmentation benchmarks demonstrate that LHT-CLIP achieves state-of-the-art performance across diverse scenarios, highlighting its effectiveness and practicality for real-world deployment.",
        "tags": [
            "CLIP",
            "Segmentation",
            "ViT"
        ]
    },
    {
        "id": "54",
        "title": "AfriMTEB and AfriE5: Benchmarking and Adapting Text Embedding Models for African Languages",
        "author": [
            "Kosei Uemura",
            "Miaoran Zhang",
            "David Ifeoluwa Adelani"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23896",
        "abstract": "Text embeddings are an essential building component of several NLP tasks such as retrieval-augmented generation which is crucial for preventing hallucinations in LLMs. Despite the recent release of massively multilingual MTEB (MMTEB), African languages remain underrepresented, with existing tasks often repurposed from translation benchmarks such as FLORES clustering or SIB-200. In this paper, we introduce AfriMTEB -- a regional expansion of MMTEB covering 59 languages, 14 tasks, and 38 datasets, including six newly added datasets. Unlike many MMTEB datasets that include fewer than five languages, the new additions span 14 to 56 African languages and introduce entirely new tasks, such as hate speech detection, intent detection, and emotion classification, which were not previously covered. Complementing this, we present AfriE5, an adaptation of the instruction-tuned mE5 model to African languages through cross-lingual contrastive distillation. Our evaluation shows that AfriE5 achieves state-of-the-art performance, outperforming strong baselines such as Gemini-Embeddings and mE5.",
        "tags": [
            "Detection",
            "LLM"
        ]
    },
    {
        "id": "55",
        "title": "Coordinated Autonomous Drones for Human-Centered Fire Evacuation in Partially Observable Urban Environments",
        "author": [
            "Maria G. Mendoza",
            "Addison Kalanther",
            "Daniel Bostwick",
            "Emma Stephan",
            "Chinmay Maheshwari",
            "Shankar Sastry"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23899",
        "abstract": "Autonomous drone technology holds significant promise for enhancing search and rescue operations during evacuations by guiding humans toward safety and supporting broader emergency response efforts. However, their application in dynamic, real-time evacuation support remains limited. Existing models often overlook the psychological and emotional complexity of human behavior under extreme stress. In real-world fire scenarios, evacuees frequently deviate from designated safe routes due to panic and uncertainty. To address these challenges, this paper presents a multi-agent coordination framework in which autonomous Unmanned Aerial Vehicles (UAVs) assist human evacuees in real-time by locating, intercepting, and guiding them to safety under uncertain conditions. We model the problem as a Partially Observable Markov Decision Process (POMDP), where two heterogeneous UAV agents, a high-level rescuer (HLR) and a low-level rescuer (LLR), coordinate through shared observations and complementary capabilities. Human behavior is captured using an agent-based model grounded in empirical psychology, where panic dynamically affects decision-making and movement in response to environmental stimuli. The environment features stochastic fire spread, unknown evacuee locations, and limited visibility, requiring UAVs to plan over long horizons to search for humans and adapt in real-time. Our framework employs the Proximal Policy Optimization (PPO) algorithm with recurrent policies to enable robust decision-making in partially observable settings. Simulation results demonstrate that the UAV team can rapidly locate and intercept evacuees, significantly reducing the time required for them to reach safety compared to scenarios without UAV assistance.",
        "tags": [
            "PPO"
        ]
    },
    {
        "id": "56",
        "title": "Stand, Walk, Navigate: Recovery-Aware Visual Navigation on a Low-Cost Wheeled Quadruped",
        "author": [
            "Jans Solano",
            "Diego Quiroz"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23902",
        "abstract": "Wheeled-legged robots combine the efficiency of wheels with the obstacle negotiation of legs, yet many state-of-the-art systems rely on costly actuators and sensors, and fall-recovery is seldom integrated, especially for wheeled-legged morphologies. This work presents a recovery-aware visual-inertial navigation system on a low-cost wheeled quadruped. The proposed system leverages vision-based perception from a depth camera and deep reinforcement learning policies for robust locomotion and autonomous recovery from falls across diverse terrains. Simulation experiments show agile mobility with low-torque actuators over irregular terrain and reliably recover from external perturbations and self-induced failures. We further show goal directed navigation in structured indoor spaces with low-cost perception. Overall, this approach lowers the barrier to deploying autonomous navigation and robust locomotion policies in budget-constrained robotic platforms.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "57",
        "title": "DynaStride: Dynamic Stride Windowing with MMCoT for Instructional Multi-Scene Captioning",
        "author": [
            "Eddison Pham",
            "Prisha Priyadarshini",
            "Adrian Maliackel",
            "Kanishk Bandi",
            "Cristian Meo",
            "Kevin Zhu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23907",
        "abstract": "Scene-level captioning in instructional videos can enhance learning by requiring an understanding of both visual cues and temporal structure. By aligning visual cues with textual guidance, this understanding supports procedural learning and multimodal reasoning, providing a richer context for skill acquisition. However, captions that fail to capture this structure may lack coherence and quality, which can create confusion and undermine the video's educational intent. To address this gap, we introduce DynaStride, a pipeline to generate coherent, scene-level captions without requiring manual scene segmentation. Using the YouCookII dataset's scene annotations, DynaStride performs adaptive frame sampling and multimodal windowing to capture key transitions within each scene. It then employs a multimodal chain-of-thought process to produce multiple action-object pairs, which are refined and fused using a dynamic stride window selection algorithm that adaptively balances temporal context and redundancy. The final scene-level caption integrates visual semantics and temporal reasoning in a single instructional caption. Empirical evaluations against strong baselines, including VLLaMA3 and GPT-4o, demonstrate consistent gains on both N-gram-based metrics (BLEU, METEOR) and semantic similarity measures (BERTScore, CLIPScore). Qualitative analyses further show that DynaStride produces captions that are more temporally coherent and informative, suggesting a promising direction for improving AI-powered instructional content generation.",
        "tags": [
            "CoT",
            "GPT",
            "Segmentation"
        ]
    },
    {
        "id": "58",
        "title": "Key and Value Weights Are Probably All You Need: On the Necessity of the Query, Key, Value weight Triplet in Decoder-Only Transformers",
        "author": [
            "Marko Karbevski",
            "Antonij Mijoski"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23912",
        "abstract": "The Query, Key, Value weight triplet is a building block of current attention mechanisms in state-of-the-art LLMs. We theoretically investigate whether this triplet can be reduced, proving under simplifying assumptions that the Query weights are redundant, thereby reducing the number of non-embedding/lm-head parameters by over 8%. We validate the theory on full-complexity GPT-3 small architectures (with layer normalization, skip connections, and weight decay) trained from scratch, demonstrating that the reduced model achieves comparable validation loss to standard baselines. These findings motivate the investigation of the Query weight redundancy at scale.",
        "tags": [
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "59",
        "title": "Breaking the Benchmark: Revealing LLM Bias via Minimal Contextual Augmentation",
        "author": [
            "Kaveh Eskandari Miandoab",
            "Mahammed Kamruzzaman",
            "Arshia Gharooni",
            "Gene Louis Kim",
            "Vasanth Sarathy",
            "Ninareh Mehrabi"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23921",
        "abstract": "Large Language Models have been shown to demonstrate stereotypical biases in their representations and behavior due to the discriminative nature of the data that they have been trained on. Despite significant progress in the development of methods and models that refrain from using stereotypical information in their decision-making, recent work has shown that approaches used for bias alignment are brittle. In this work, we introduce a novel and general augmentation framework that involves three plug-and-play steps and is applicable to a number of fairness evaluation benchmarks. Through application of augmentation to a fairness evaluation dataset (Bias Benchmark for Question Answering (BBQ)), we find that Large Language Models (LLMs), including state-of-the-art open and closed weight models, are susceptible to perturbations to their inputs, showcasing a higher likelihood to behave stereotypically. Furthermore, we find that such models are more likely to have biased behavior in cases where the target demographic belongs to a community less studied by the literature, underlining the need to expand the fairness and safety research to include more diverse communities.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "60",
        "title": "Agent-based Automated Claim Matching with Instruction-following LLMs",
        "author": [
            "Dina Pisarevskaya",
            "Arkaitz Zubiaga"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23924",
        "abstract": "We present a novel agent-based approach for the automated claim matching task with instruction-following LLMs. We propose a two-step pipeline that first generates prompts with LLMs, to then perform claim matching as a binary classification task with LLMs. We demonstrate that LLM-generated prompts can outperform SOTA with human-generated prompts, and that smaller LLMs can do as well as larger ones in the generation process, allowing to save computational resources. We also demonstrate the effectiveness of using different LLMs for each step of the pipeline, i.e. using an LLM for prompt generation, and another for claim matching. Our investigation into the prompt generation process in turn reveals insights into the LLMs' understanding of claim matching.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "61",
        "title": "Latent Chain-of-Thought for Visual Reasoning",
        "author": [
            "Guohao Sun",
            "Hang Hua",
            "Jian Wang",
            "Jiebo Luo",
            "Sohail Dianat",
            "Majid Rabbani",
            "Raghuveer Rao",
            "Zhiqiang Tao"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23925",
        "abstract": "Chain-of-thought (CoT) reasoning is critical for improving the interpretability and reliability of Large Vision-Language Models (LVLMs). However, existing training algorithms such as SFT, PPO, and GRPO may not generalize well across unseen reasoning tasks and heavily rely on a biased reward model. To address this challenge, we reformulate reasoning in LVLMs as posterior inference and propose a scalable training algorithm based on amortized variational inference. By leveraging diversity-seeking reinforcement learning algorithms, we introduce a novel sparse reward function for token-level learning signals that encourage diverse, high-likelihood latent CoT, overcoming deterministic sampling limitations and avoiding reward hacking. Additionally, we implement a Bayesian inference-scaling strategy that replaces costly Best-of-N and Beam Search with a marginal likelihood to efficiently rank optimal rationales and answers. We empirically demonstrate that the proposed method enhances the state-of-the-art LVLMs on seven reasoning benchmarks, in terms of effectiveness, generalization, and interpretability.",
        "tags": [
            "CoT",
            "GRPO",
            "PPO",
            "RL",
            "VLM"
        ]
    },
    {
        "id": "62",
        "title": "Improving the Straight-Through Estimator with Zeroth-Order Information",
        "author": [
            "Ningfeng Yang",
            "Tor M. Aamodt"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23926",
        "abstract": "We study the problem of training neural networks with quantized parameters. Learning low-precision quantized parameters by enabling computation of gradients via the Straight-Through Estimator (STE) can be challenging. While the STE enables back-propagation, which is a first-order method, recent works have explored the use of zeroth-order (ZO) gradient descent for fine-tuning. We note that the STE provides high-quality biased gradients, and ZO gradients are unbiased but can be expensive. We thus propose First-Order-Guided Zeroth-Order Gradient Descent (FOGZO) that reduces STE bias while reducing computations relative to ZO methods. Empirically, we show FOGZO improves the tradeoff between quality and training time in Quantization-Aware Pre-Training. Specifically, versus STE at the same number of iterations, we show a 1-8\\% accuracy improvement for DeiT Tiny/Small, 1-2\\% accuracy improvement on ResNet 18/50, and 1-22 perplexity point improvement for LLaMA models with up to 0.3 billion parameters. For the same loss, FOGZO yields a 796$\\times$ reduction in computation versus n-SPSA for a 2-layer MLP on MNIST. Code is available at https://github.com/1733116199/fogzo.",
        "tags": [
            "LLaMA"
        ]
    },
    {
        "id": "63",
        "title": "Victim as a Service: Designing a System for Engaging with Interactive Scammers",
        "author": [
            "Daniel Spokoyny",
            "Nikolai Vogler",
            "Xin Gao",
            "Tianyi Zheng",
            "Yufei Weng",
            "Jonghyun Park",
            "Jiajun Jiao",
            "Geoffrey M. Voelker",
            "Stefan Savage",
            "Taylor Berg-Kirkpatrick"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23927",
        "abstract": "Pig butchering, and similar interactive online scams, lower their victims' defenses by building trust over extended periods of conversation - sometimes weeks or months. They have become increasingly public losses (at least $75B by one recent study). However, because of their long-term conversational nature, they are extremely challenging to investigate at scale. In this paper, we describe the motivation, design, implementation, and experience with CHATTERBOX, an LLM-based system that automates long-term engagement with online scammers, making large-scale investigations of their tactics possible. We describe the techniques we have developed to attract scam attempts, the system and LLM-engineering required to convincingly engage with scammers, and the necessary capabilities required to satisfy or evade \"milestones\" in scammers' workflow.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "64",
        "title": "Adaptive Keyframe Selection for Scalable 3D Scene Reconstruction in Dynamic Environments",
        "author": [
            "Raman Jha",
            "Yang Zhou",
            "Giuseppe Loianno"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23928",
        "abstract": "In this paper, we propose an adaptive keyframe selection method for improved 3D scene reconstruction in dynamic environments. The proposed method integrates two complementary modules: an error-based selection module utilizing photometric and structural similarity (SSIM) errors, and a momentum-based update module that dynamically adjusts keyframe selection thresholds according to scene motion dynamics. By dynamically curating the most informative frames, our approach addresses a key data bottleneck in real-time perception. This allows for the creation of high-quality 3D world representations from a compressed data stream, a critical step towards scalable robot learning and deployment in complex, dynamic environments. Experimental results demonstrate significant improvements over traditional static keyframe selection strategies, such as fixed temporal intervals or uniform frame skipping. These findings highlight a meaningful advancement toward adaptive perception systems that can dynamically respond to complex and evolving visual scenes. We evaluate our proposed adaptive keyframe selection module on two recent state-of-the-art 3D reconstruction networks, Spann3r and CUT3R, and observe consistent improvements in reconstruction quality across both frameworks. Furthermore, an extensive ablation study confirms the effectiveness of each individual component in our method, underlining their contribution to the overall performance gains.",
        "tags": [
            "3D",
            "Robotics"
        ]
    },
    {
        "id": "65",
        "title": "TurboPortrait3D: Single-step diffusion-based fast portrait novel-view synthesis",
        "author": [
            "Emily Kim",
            "Julieta Martinez",
            "Timur Bagautdinov",
            "Jessica Hodgins"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23929",
        "abstract": "We introduce TurboPortrait3D: a method for low-latency novel-view synthesis of human portraits. Our approach builds on the observation that existing image-to-3D models for portrait generation, while capable of producing renderable 3D representations, are prone to visual artifacts, often lack of detail, and tend to fail at fully preserving the identity of the subject. On the other hand, image diffusion models excel at generating high-quality images, but besides being computationally expensive, are not grounded in 3D and thus are not directly capable of producing multi-view consistent outputs. In this work, we demonstrate that image-space diffusion models can be used to significantly enhance the quality of existing image-to-avatar methods, while maintaining 3D-awareness and running with low-latency. Our method takes a single frontal image of a subject as input, and applies a feedforward image-to-avatar generation pipeline to obtain an initial 3D representation and corresponding noisy renders. These noisy renders are then fed to a single-step diffusion model which is conditioned on input image(s), and is specifically trained to refine the renders in a multi-view consistent way. Moreover, we introduce a novel effective training strategy that includes pre-training on a large corpus of synthetic multi-view data, followed by fine-tuning on high-quality real images. We demonstrate that our approach both qualitatively and quantitatively outperforms current state-of-the-art for portrait novel-view synthesis, while being efficient in time.",
        "tags": [
            "3D",
            "Diffusion",
            "Image-to-3D"
        ]
    },
    {
        "id": "66",
        "title": "PlanarGS: High-Fidelity Indoor 3D Gaussian Splatting Guided by Vision-Language Planar Priors",
        "author": [
            "Xirui Jin",
            "Renbiao Jin",
            "Boying Li",
            "Danping Zou",
            "Wenxian Yu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23930",
        "abstract": "Three-dimensional Gaussian Splatting (3DGS) has recently emerged as an efficient representation for novel-view synthesis, achieving impressive visual quality. However, in scenes dominated by large and low-texture regions, common in indoor environments, the photometric loss used to optimize 3DGS yields ambiguous geometry and fails to recover high-fidelity 3D surfaces. To overcome this limitation, we introduce PlanarGS, a 3DGS-based framework tailored for indoor scene reconstruction. Specifically, we design a pipeline for Language-Prompted Planar Priors (LP3) that employs a pretrained vision-language segmentation model and refines its region proposals via cross-view fusion and inspection with geometric priors. 3D Gaussians in our framework are optimized with two additional terms: a planar prior supervision term that enforces planar consistency, and a geometric prior supervision term that steers the Gaussians toward the depth and normal cues. We have conducted extensive experiments on standard indoor benchmarks. The results show that PlanarGS reconstructs accurate and detailed 3D surfaces, consistently outperforming state-of-the-art methods by a large margin. Project page: https://planargs.github.io",
        "tags": [
            "3D",
            "Gaussian Splatting",
            "Segmentation"
        ]
    },
    {
        "id": "67",
        "title": "Modeling Biological Multifunctionality with Echo State Networks",
        "author": [
            "Anastasia-Maria Leventi-Peetz",
            "JÃ¶rg-Volker Peetz",
            "Kai Weber",
            "Nikolaos Zacharis"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23940",
        "abstract": "In this work, a three-dimensional multicomponent reaction-diffusion model has been developed, combining excitable-system dynamics with diffusion processes and sharing conceptual features with the FitzHugh-Nagumo model. Designed to capture the spatiotemporal behavior of biological systems, particularly electrophysiological processes, the model was solved numerically to generate time-series data. These data were subsequently used to train and evaluate an Echo State Network (ESN), which successfully reproduced the system's dynamic behavior. The results demonstrate that simulating biological dynamics using data-driven, multifunctional ESN models is both feasible and effective.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "68",
        "title": "Auto prompting without training labels: An LLM cascade for product quality assessment in e-commerce catalogs",
        "author": [
            "Soham Satyadharma",
            "Fatemeh Sheikholeslami",
            "Swati Kaul",
            "Aziz Umit Batur",
            "Suleiman A. Khan"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23941",
        "abstract": "We introduce a novel, training free cascade for auto-prompting Large Language Models (LLMs) to assess product quality in e-commerce. Our system requires no training labels or model fine-tuning, instead automatically generating and refining prompts for evaluating attribute quality across tens of thousands of product category-attribute pairs. Starting from a seed of human-crafted prompts, the cascade progressively optimizes instructions to meet catalog-specific requirements. This approach bridges the gap between general language understanding and domain-specific knowledge at scale in complex industrial catalogs. Our extensive empirical evaluations shows the auto-prompt cascade improves precision and recall by $8-10\\%$ over traditional chain-of-thought prompting. Notably, it achieves these gains while reducing domain expert effort from 5.1 hours to 3 minutes per attribute - a $99\\%$ reduction. Additionally, the cascade generalizes effectively across five languages and multiple quality assessment tasks, consistently maintaining performance gains.",
        "tags": [
            "CoT",
            "LLM"
        ]
    },
    {
        "id": "69",
        "title": "Toward Socially-Aware LLMs: A Survey of Multimodal Approaches to Human Behavior Understanding",
        "author": [
            "Zihan Liu",
            "Parisa Rabbani",
            "Veda Duddu",
            "Kyle Fan",
            "Madison Lee",
            "Yun Huang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23947",
        "abstract": "LLM-powered multimodal systems are increasingly used to interpret human social behavior, yet how researchers apply the models' 'social competence' remains poorly understood. This paper presents a systematic literature review of 176 publications across different application domains (e.g., healthcare, education, and entertainment). Using a four-dimensional coding framework (application, technical, evaluative, and ethical), we find (1) frequent use of pattern recognition and information extraction from multimodal sources, but limited support for adaptive, interactive reasoning; (2) a dominant 'modality-to-text' pipeline that privileges language over rich audiovisual cues, striping away nuanced social cues; (3) evaluation practices reliant on static benchmarks, with socially grounded, human-centered assessments rare; and (4) Ethical discussions focused mainly on legal and rights-related risks (e.g., privacy), leaving societal risks (e.g., deception) overlooked--or at best acknowledged but left unaddressed. We outline a research agenda for evaluating socially competent, ethically informed, and interaction-aware multi-modal systems.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "70",
        "title": "ChessQA: Evaluating Large Language Models for Chess Understanding",
        "author": [
            "Qianfeng Wen",
            "Zhenwei Tang",
            "Ashton Anderson"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23948",
        "abstract": "Chess provides an ideal testbed for evaluating the reasoning, modeling, and abstraction capabilities of large language models (LLMs), as it has well-defined structure and objective ground truth while admitting a wide spectrum of skill levels. However, existing evaluations of LLM ability in chess are ad hoc and narrow in scope, making it difficult to accurately measure LLM chess understanding and how it varies with scale, post-training methodologies, or architecture choices. We present ChessQA, a comprehensive benchmark that assesses LLM chess understanding across five task categories (Structural, Motifs, Short Tactics, Position Judgment, and Semantic), which approximately correspond to the ascending abstractions that players master as they accumulate chess knowledge, from understanding basic rules and learning tactical motifs to correctly calculating tactics, evaluating positions, and semantically describing high-level concepts. In this way, ChessQA captures a more comprehensive picture of chess ability and understanding, going significantly beyond the simple move quality evaluations done previously, and offers a controlled, consistent setting for diagnosis and comparison. Furthermore, ChessQA is inherently dynamic, with prompts, answer keys, and construction scripts that can evolve as models improve. Evaluating a range of contemporary LLMs, we find persistent weaknesses across all five categories and provide results and error analyses by category. We will release the code, periodically refreshed datasets, and a public leaderboard to support further research.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "71",
        "title": "Uncovering the Potential Risks in Unlearning: Danger of English-only Unlearning in Multilingual LLMs",
        "author": [
            "Kyomin Hwang",
            "Hyeonjin Kim",
            "Seungyeon Kim",
            "Sunghyun Wee",
            "Nojun Kwak"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23949",
        "abstract": "There have been a couple of studies showing that attempting to erase multilingual knowledge using only English data is insufficient for multilingual LLMs. However, their analyses remain highly performance-oriented. In this paper, we switch the point of view to evaluation, and address an additional blind spot which reveals itself when the multilingual LLM is fully finetuned with parallel multilingual dataset before unlearning. Here, language confusion occurs whereby a model responds in language different from that of the input prompt. Language confusion is a problematic phenomenon in unlearning, causing the standard reference-based metrics to fail. We tackle this phenomenon in three steps: (1) introduce N-gram-based Language-Mix (N-Mix) score to quantitatively show the language confusion is pervasive and consistent in multilingual LLMs, (2) demonstrate that reference-based metrics result in false negatives when N-Mix score is high, and(3) suggest the need of new type of unlearning evaluation that can directly assess the content of the generated sentences. We call this type of metrics as semantic-based metric.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "72",
        "title": "A Comprehensive General Model of Tendon-Actuated Concentric Tube Robots with Multiple Tubes and Tendons",
        "author": [
            "Pejman Kheradmand",
            "Behnam Moradkhani",
            "Raghavasimhan Sankaranarayanan",
            "Kent K. Yamamoto",
            "Tanner J. Zachem",
            "Patrick J. Codd",
            "Yash Chitalia",
            "Pierre E. Dupont"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23954",
        "abstract": "Tendon-actuated concentric tube mechanisms combine the advantages of tendon-driven continuum robots and concentric tube robots while addressing their respective limitations. They overcome the restricted degrees of freedom often seen in tendon-driven designs, and mitigate issues such as snapping instability associated with concentric tube robots. However, a complete and general mechanical model for these systems remains an open problem. In this work, we propose a Cosserat rod-based framework for modeling the general case of $n$ concentric tubes, each actuated by $m_i$ tendons, where $i = \\{1, \\ldots, n\\}$. The model allows each tube to twist and elongate while enforcing a shared centerline for bending. We validate the proposed framework through experiments with two-tube and three tube assemblies under various tendon routing configurations, achieving tip prediction errors $<4\\%$ of the robot's total length. We further demonstrate the model's generality by applying it to existing robots in the field, where maximum tip deviations remain around $5\\%$ of the total length. This model provides a foundation for accurate shape estimation and control of advanced tendon-actuated concentric tube robots.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "73",
        "title": "SafeVision: Efficient Image Guardrail with Robust Policy Adherence and Explainability",
        "author": [
            "Peiyang Xu",
            "Minzhou Pan",
            "Zhaorun Chen",
            "Shuang Yang",
            "Chaowei Xiao",
            "Bo Li"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23960",
        "abstract": "With the rapid proliferation of digital media, the need for efficient and transparent safeguards against unsafe content is more critical than ever. Traditional image guardrail models, constrained by predefined categories, often misclassify content due to their pure feature-based learning without semantic reasoning. Moreover, these models struggle to adapt to emerging threats, requiring costly retraining for new threats. To address these limitations, we introduce SafeVision, a novel image guardrail that integrates human-like reasoning to enhance adaptability and transparency. Our approach incorporates an effective data collection and generation framework, a policy-following training pipeline, and a customized loss function. We also propose a diverse QA generation and training strategy to enhance learning effectiveness. SafeVision dynamically aligns with evolving safety policies at inference time, eliminating the need for retraining while ensuring precise risk assessments and explanations. Recognizing the limitations of existing unsafe image benchmarks, which either lack granularity or cover limited risks, we introduce VisionHarm, a high-quality dataset comprising two subsets: VisionHarm Third-party (VisionHarm-T) and VisionHarm Comprehensive(VisionHarm-C), spanning diverse harmful categories. Through extensive experiments, we show that SafeVision achieves state-of-the-art performance on different benchmarks. SafeVision outperforms GPT-4o by 8.6% on VisionHarm-T and by 15.5% on VisionHarm-C, while being over 16x faster. SafeVision sets a comprehensive, policy-following, and explainable image guardrail with dynamic adaptation to emerging threats.",
        "tags": [
            "GPT"
        ]
    },
    {
        "id": "74",
        "title": "Adaptive-twist Soft Finger Mechanism for Grasping by Wrapping",
        "author": [
            "Hiroki Ishikawa",
            "Kyosuke Ishibashi",
            "Ko Yamamoto"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23963",
        "abstract": "This paper presents a soft robot finger capable of adaptive-twist deformation to grasp objects by wrapping them. For a soft hand to grasp and pick-up one object from densely contained multiple objects, a soft finger requires the adaptive-twist deformation function in both in-plane and out-of-plane directions. The function allows the finger to be inserted deeply into a limited gap among objects. Once inserted, the soft finger requires appropriate control of grasping force normal to contact surface, thereby maintaining the twisted deformation. In this paper, we refer to this type of grasping as grasping by wrapping. To achieve these two functions by a single actuation source, we propose a variable stiffness mechanism that can adaptively change the stiffness as the pressure is higher. We conduct a finite element analysis (FEA) on the proposed mechanism and determine its design parameter based on the FEA result. Using the developed soft finger, we report basic experimental results and demonstrations on grasping various objects.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "75",
        "title": "The Sign Estimator: LLM Alignment in the Face of Choice Heterogeneity",
        "author": [
            "Aymane El Gadarri",
            "Ali Aouad",
            "Vivek F. Farias"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23965",
        "abstract": "Traditional LLM alignment methods are vulnerable to heterogeneity in human preferences. Fitting a naÃ¯ve probabilistic model to pairwise comparison data (say over prompt-completion pairs) yields an inconsistent estimate of the population-average utility -a canonical measure of social welfare. We propose a new method, dubbed the sign estimator, that provides a simple, provably consistent, and efficient estimator by replacing cross-entropy with binary classification loss in the aggregation step. This simple modification recovers consistent ordinal alignment under mild assumptions and achieves the first polynomial finite-sample error bounds in this setting. In realistic simulations of LLM alignment using digital twins, the sign estimator substantially reduces preference distortion over a panel of simulated personas, cutting (angular) estimation error by nearly 35% and decreasing disagreement with true population preferences from 12% to 8% compared to standard RLHF. Our method also compares favorably to panel data heuristics that explicitly model user heterogeneity and require tracking individual-level preference data-all while maintaining the implementation simplicity of existing LLM alignment pipelines.",
        "tags": [
            "LLM",
            "RLHF"
        ]
    },
    {
        "id": "76",
        "title": "A Pragmatic Way to Measure Chain-of-Thought Monitorability",
        "author": [
            "Scott Emmons",
            "Roland S. Zimmermann",
            "David K. Elson",
            "Rohin Shah"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23966",
        "abstract": "While Chain-of-Thought (CoT) monitoring offers a unique opportunity for AI safety, this opportunity could be lost through shifts in training practices or model architecture. To help preserve monitorability, we propose a pragmatic way to measure two components of it: legibility (whether the reasoning can be followed by a human) and coverage (whether the CoT contains all the reasoning needed for a human to also produce the final output). We implement these metrics with an autorater prompt that enables any capable LLM to compute the legibility and coverage of existing CoTs. After sanity-checking our prompted autorater with synthetic CoT degradations, we apply it to several frontier models on challenging benchmarks, finding that they exhibit high monitorability. We present these metrics, including our complete autorater prompt, as a tool for developers to track how design decisions impact monitorability. While the exact prompt we share is still a preliminary version under ongoing development, we are sharing it now in the hopes that others in the community will find it useful. Our method helps measure the default monitorability of CoT - it should be seen as a complement, not a replacement, for the adversarial stress-testing needed to test robustness against deliberately evasive models.",
        "tags": [
            "CoT",
            "LLM"
        ]
    },
    {
        "id": "77",
        "title": "An efficient probabilistic hardware architecture for diffusion-like models",
        "author": [
            "AndraÅ¾ JelinÄiÄ",
            "Owen Lockwood",
            "Akhil Garlapati",
            "Guillaume Verdon",
            "Trevor McCourt"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23972",
        "abstract": "The proliferation of probabilistic AI has promoted proposals for specialized stochastic computers. Despite promising efficiency gains, these proposals have failed to gain traction because they rely on fundamentally limited modeling techniques and exotic, unscalable hardware. In this work, we address these shortcomings by proposing an all-transistor probabilistic computer that implements powerful denoising models at the hardware level. A system-level analysis indicates that devices based on our architecture could achieve performance parity with GPUs on a simple image benchmark using approximately 10,000 times less energy.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "78",
        "title": "Diffusion Adaptive Text Embedding for Text-to-Image Diffusion Models",
        "author": [
            "Byeonghu Na",
            "Minsang Park",
            "Gyuwon Sim",
            "Donghyeok Shin",
            "HeeSun Bae",
            "Mina Kang",
            "Se Jung Kwon",
            "Wanmo Kang",
            "Il-Chul Moon"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23974",
        "abstract": "Text-to-image diffusion models rely on text embeddings from a pre-trained text encoder, but these embeddings remain fixed across all diffusion timesteps, limiting their adaptability to the generative process. We propose Diffusion Adaptive Text Embedding (DATE), which dynamically updates text embeddings at each diffusion timestep based on intermediate perturbed data. We formulate an optimization problem and derive an update rule that refines the text embeddings at each sampling step to improve alignment and preference between the mean predicted image and the text. This allows DATE to dynamically adapts the text conditions to the reverse-diffused images throughout diffusion sampling without requiring additional model training. Through theoretical analysis and empirical results, we show that DATE maintains the generative capability of the model while providing superior text-image alignment over fixed text embeddings across various tasks, including multi-concept generation and text-guided image editing. Our code is available at https://github.com/aailab-kaist/DATE.",
        "tags": [
            "Diffusion",
            "Image Editing",
            "Text-to-Image"
        ]
    },
    {
        "id": "79",
        "title": "Synergistic Neural Forecasting of Air Pollution with Stochastic Sampling",
        "author": [
            "Yohan Abeysinghe",
            "Muhammad Akhtar Munir",
            "Sanoojan Baliah",
            "Ron Sarafian",
            "Fahad Shahbaz Khan",
            "Yinon Rudich",
            "Salman Khan"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23977",
        "abstract": "Air pollution remains a leading global health and environmental risk, particularly in regions vulnerable to episodic air pollution spikes due to wildfires, urban haze and dust storms. Accurate forecasting of particulate matter (PM) concentrations is essential to enable timely public health warnings and interventions, yet existing models often underestimate rare but hazardous pollution events. Here, we present SynCast, a high-resolution neural forecasting model that integrates meteorological and air composition data to improve predictions of both average and extreme pollution levels. Built on a regionally adapted transformer backbone and enhanced with a diffusion-based stochastic refinement module, SynCast captures the nonlinear dynamics driving PM spikes more accurately than existing approaches. Leveraging on harmonized ERA5 and CAMS datasets, our model shows substantial gains in forecasting fidelity across multiple PM variables (PM$_1$, PM$_{2.5}$, PM$_{10}$), especially under extreme conditions. We demonstrate that conventional loss functions underrepresent distributional tails (rare pollution events) and show that SynCast, guided by domain-aware objectives and extreme value theory, significantly enhances performance in highly impacted regions without compromising global accuracy. This approach provides a scalable foundation for next-generation air quality early warning systems and supports climate-health risk mitigation in vulnerable regions.",
        "tags": [
            "Diffusion",
            "Transformer"
        ]
    },
    {
        "id": "80",
        "title": "Efficient Cost-and-Quality Controllable Arbitrary-scale Super-resolution with Fourier Constraints",
        "author": [
            "Kazutoshi Akita",
            "Norimichi Ukita"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23978",
        "abstract": "Cost-and-Quality (CQ) controllability in arbitrary-scale super-resolution is crucial. Existing methods predict Fourier components one by one using a recurrent neural network. However, this approach leads to performance degradation and inefficiency due to independent prediction. This paper proposes predicting multiple components jointly to improve both quality and efficiency.",
        "tags": [
            "RNN",
            "Super Resolution"
        ]
    },
    {
        "id": "81",
        "title": "A Survey on Collaborative SLAM with 3D Gaussian Splatting",
        "author": [
            "Phuc Nguyen Xuan",
            "Thanh Nguyen Canh",
            "Huu-Hung Nguyen",
            "Nak Young Chong",
            "Xiem HoangVan"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23988",
        "abstract": "This survey comprehensively reviews the evolving field of multi-robot collaborative Simultaneous Localization and Mapping (SLAM) using 3D Gaussian Splatting (3DGS). As an explicit scene representation, 3DGS has enabled unprecedented real-time, high-fidelity render- ing, ideal for robotics. However, its use in multi-robot systems introduces significant challenges in maintaining global consistency, managing communication, and fusing data from heterogeneous sources. We systematically categorize approaches by their architecture-centralized, distributed- and analyze core components like multi-agent consistency and alignment, communication- efficient, Gaussian representation, semantic distillation, fusion and pose optimization, and real- time scalability. In addition, a summary of critical datasets and evaluation metrics is provided to contextualize performance. Finally, we identify key open challenges and chart future research directions, including lifelong mapping, semantic association and mapping, multi-model for robustness, and bridging the Sim2Real gap.",
        "tags": [
            "3D",
            "Gaussian Splatting",
            "Robotics",
            "SLAM"
        ]
    },
    {
        "id": "82",
        "title": "Resource-Efficient LLM Application for Structured Transformation of Unstructured Financial Contracts",
        "author": [
            "Maruf Ahmed Mridul",
            "Oshani Seneviratne"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23990",
        "abstract": "The transformation of unstructured legal contracts into standardized, machine-readable formats is essential for automating financial workflows. The Common Domain Model (CDM) provides a standardized framework for this purpose, but converting complex legal documents like Credit Support Annexes (CSAs) into CDM representations remains a significant challenge. In this paper, we present an extension of the CDMizer framework, a template-driven solution that ensures syntactic correctness and adherence to the CDM schema during contract-to-CDM conversion. We apply this extended framework to a real-world task, comparing its performance with a benchmark developed by the International Swaps and Derivatives Association (ISDA) for CSA clause extraction. Our results show that CDMizer, when integrated with a significantly smaller, open-source Large Language Model (LLM), achieves competitive performance in terms of accuracy and efficiency against larger, proprietary models. This work underscores the potential of resource-efficient solutions to automate legal contract transformation, offering a cost-effective and scalable approach that can meet the needs of financial institutions with constrained resources or strict data privacy requirements.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "83",
        "title": "VOCALoco: Viability-Optimized Cost-aware Adaptive Locomotion",
        "author": [
            "Stanley Wu",
            "Mohamad H. Danesh",
            "Simon Li",
            "Hanna Yurchyk",
            "Amin Abyaneh",
            "Anas El Houssaini",
            "David Meger",
            "Hsiu-Chin Lin"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23997",
        "abstract": "Recent advancements in legged robot locomotion have facilitated traversal over increasingly complex terrains. Despite this progress, many existing approaches rely on end-to-end deep reinforcement learning (DRL), which poses limitations in terms of safety and interpretability, especially when generalizing to novel terrains. To overcome these challenges, we introduce VOCALoco, a modular skill-selection framework that dynamically adapts locomotion strategies based on perceptual input. Given a set of pre-trained locomotion policies, VOCALoco evaluates their viability and energy-consumption by predicting both the safety of execution and the anticipated cost of transport over a fixed planning horizon. This joint assessment enables the selection of policies that are both safe and energy-efficient, given the observed local terrain. We evaluate our approach on staircase locomotion tasks, demonstrating its performance in both simulated and real-world scenarios using a quadrupedal robot. Empirical results show that VOCALoco achieves improved robustness and safety during stair ascent and descent compared to a conventional end-to-end DRL policy",
        "tags": [
            "RL",
            "Robotics"
        ]
    },
    {
        "id": "84",
        "title": "Mars-Bench: A Benchmark for Evaluating Foundation Models for Mars Science Tasks",
        "author": [
            "Mirali Purohit",
            "Bimal Gajera",
            "Vatsal Malaviya",
            "Irish Mehta",
            "Kunal Kasodekar",
            "Jacob Adler",
            "Steven Lu",
            "Umaa Rebbapragada",
            "Hannah Kerner"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24010",
        "abstract": "Foundation models have enabled rapid progress across many specialized domains by leveraging large-scale pre-training on unlabeled data, demonstrating strong generalization to a variety of downstream tasks. While such models have gained significant attention in fields like Earth Observation, their application to Mars science remains limited. A key enabler of progress in other domains has been the availability of standardized benchmarks that support systematic evaluation. In contrast, Mars science lacks such benchmarks and standardized evaluation frameworks, which have limited progress toward developing foundation models for Martian tasks. To address this gap, we introduce Mars-Bench, the first benchmark designed to systematically evaluate models across a broad range of Mars-related tasks using both orbital and surface imagery. Mars-Bench comprises 20 datasets spanning classification, segmentation, and object detection, focused on key geologic features such as craters, cones, boulders, and frost. We provide standardized, ready-to-use datasets and baseline evaluations using models pre-trained on natural images, Earth satellite data, and state-of-the-art vision-language models. Results from all analyses suggest that Mars-specific foundation models may offer advantages over general-domain counterparts, motivating further exploration of domain-adapted pre-training. Mars-Bench aims to establish a standardized foundation for developing and comparing machine learning models for Mars science. Our data, models, and code are available at: https://mars-bench.github.io/.",
        "tags": [
            "Detection",
            "Segmentation",
            "VLM"
        ]
    },
    {
        "id": "85",
        "title": "Training-Free Safe Text Embedding Guidance for Text-to-Image Diffusion Models",
        "author": [
            "Byeonghu Na",
            "Mina Kang",
            "Jiseok Kwak",
            "Minsang Park",
            "Jiwoo Shin",
            "SeJoon Jun",
            "Gayoung Lee",
            "Jin-Hwa Kim",
            "Il-Chul Moon"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24012",
        "abstract": "Text-to-image models have recently made significant advances in generating realistic and semantically coherent images, driven by advanced diffusion models and large-scale web-crawled datasets. However, these datasets often contain inappropriate or biased content, raising concerns about the generation of harmful outputs when provided with malicious text prompts. We propose Safe Text embedding Guidance (STG), a training-free approach to improve the safety of diffusion models by guiding the text embeddings during sampling. STG adjusts the text embeddings based on a safety function evaluated on the expected final denoised image, allowing the model to generate safer outputs without additional training. Theoretically, we show that STG aligns the underlying model distribution with safety constraints, thereby achieving safer outputs while minimally affecting generation quality. Experiments on various safety scenarios, including nudity, violence, and artist-style removal, show that STG consistently outperforms both training-based and training-free baselines in removing unsafe content while preserving the core semantic intent of input prompts. Our code is available at https://github.com/aailab-kaist/STG.",
        "tags": [
            "Diffusion",
            "Text-to-Image"
        ]
    },
    {
        "id": "86",
        "title": "Discovering Heuristics with Large Language Models (LLMs) for Mixed-Integer Programs: Single-Machine Scheduling",
        "author": [
            "Ä°brahim OÄuz Ãetinkaya",
            "Ä°. Esra BÃ¼yÃ¼ktahtakÄ±n",
            "Parshin Shojaee",
            "Chandan K. Reddy"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24013",
        "abstract": "Our study contributes to the scheduling and combinatorial optimization literature with new heuristics discovered by leveraging the power of Large Language Models (LLMs). We focus on the single-machine total tardiness (SMTT) problem, which aims to minimize total tardiness by sequencing n jobs on a single processor without preemption, given processing times and due dates. We develop and benchmark two novel LLM-discovered heuristics, the EDD Challenger (EDDC) and MDD Challenger (MDDC), inspired by the well-known Earliest Due Date (EDD) and Modified Due Date (MDD) rules. In contrast to prior studies that employed simpler rule-based heuristics, we evaluate our LLM-discovered algorithms using rigorous criteria, including optimality gaps and solution time derived from a mixed-integer programming (MIP) formulation of SMTT. We compare their performance against state-of-the-art heuristics and exact methods across various job sizes (20, 100, 200, and 500 jobs). For instances with more than 100 jobs, exact methods such as MIP and dynamic programming become computationally intractable. Up to 500 jobs, EDDC improves upon the classic EDD rule and another widely used algorithm in the literature. MDDC consistently outperforms traditional heuristics and remains competitive with exact approaches, particularly on larger and more complex instances. This study shows that human-LLM collaboration can produce scalable, high-performing heuristics for NP-hard constrained combinatorial optimization, even under limited resources when effectively configured.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "87",
        "title": "TEXT2DB: Integration-Aware Information Extraction with Large Language Model Agents",
        "author": [
            "Yizhu Jiao",
            "Sha Li",
            "Sizhe Zhou",
            "Heng Ji",
            "Jiawei Han"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24014",
        "abstract": "The task of information extraction (IE) is to extract structured knowledge from text. However, it is often not straightforward to utilize IE output due to the mismatch between the IE ontology and the downstream application needs. We propose a new formulation of IE TEXT2DB that emphasizes the integration of IE output and the target database (or knowledge base). Given a user instruction, a document set, and a database, our task requires the model to update the database with values from the document set to satisfy the user instruction. This task requires understanding user instructions for what to extract and adapting to the given DB/KB schema for how to extract on the fly. To evaluate this new task, we introduce a new benchmark featuring common demands such as data infilling, row population, and column addition. In addition, we propose an LLM agent framework OPAL (Observe-PlanAnalyze LLM) which includes an Observer component that interacts with the database, the Planner component that generates a code-based plan with calls to IE models, and the Analyzer component that provides feedback regarding code quality before execution. Experiments show that OPAL can successfully adapt to diverse database schemas by generating different code plans and calling the required IE models. We also highlight difficult cases such as dealing with large databases with complex dependencies and extraction hallucination, which we believe deserve further investigation. Source code: https://github.com/yzjiao/Text2DB",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "88",
        "title": "Lifecycle-Aware code generation: Leveraging Software Engineering Phases in LLMs",
        "author": [
            "Xing Xing",
            "Wei Wang",
            "Lipeng Ma",
            "Weidong Yang",
            "Junjie Zheng"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24019",
        "abstract": "Recent progress in large language models (LLMs) has advanced automatic code generation, yet most approaches rely on direct, single-step translation from problem descriptions to code, disregarding structured software engineering practices. We introduce a lifecycle-aware framework that systematically incorporates intermediate artifacts such as requirements analysis, state machine modeling, and pseudocode into both the training and inference stages. This design aligns code generation with standard software development phases and enables more structured reasoning. Experiments show that lifecycle-level fine-tuning improves code correctness by up to 75% over the same model before fine-tuning, with performance gains compounding across intermediate stages. Multi-step inference consistently surpasses single-step generation, demonstrating the effectiveness of intermediate scaffolding. Notably, open-source LLMs, once fine-tuned under our framework, match or slightly outperform models pretrained on code. When applied to DeepSeek-Coder-1.3B, our framework yields relative CodeBLEU improvements of 34.3%, 20.0%, 11.2%, and 22.3% over ChatGPT-3.5, ChatGPT-4o-mini, DeepSeek-R1, and LLaMA-8B, respectively. Our pipeline also proves robust with up to 80\\% less training data, confirming its resilience. Ablation studies further reveal that each intermediate artifact contributes distinctly to final code quality, with state machine modeling yielding the most substantial impact. Our source code and detailed experimental data are available at https://anonymous.4open.science/r/Lifecycle-Aware-3CCB.",
        "tags": [
            "DeepSeek",
            "GPT",
            "LLM",
            "LLaMA"
        ]
    },
    {
        "id": "89",
        "title": "Teaching LLMs to Abstain via Fine-Grained Semantic Confidence Reward",
        "author": [
            "Hao An",
            "Yang Xu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24020",
        "abstract": "Mitigating hallucinations in Large Language Models (LLMs) is critical for their reliable deployment. Existing methods typically fine-tune LLMs to abstain from answering questions beyond their knowledge scope. However, these methods often rely on coarse-grained signals to guide LLMs to abstain, such as overall confidence or uncertainty scores on multiple sampled answers, which may result in an imprecise awareness of the model's own knowledge boundaries. To this end, we propose a novel reinforcement learning framework built on $\\textbf{\\underline{Fi}ne-grained \\underline{S}emantic \\underline{Co}nfidence \\underline{Re}ward (\\Ours)}$, which guides LLMs to abstain via sample-specific confidence. Specifically, our method operates by sampling multiple candidate answers and conducting semantic clustering, then training the LLM to retain answers within high-confidence clusters and discard those within low-confidence ones, thereby promoting accurate post-hoc abstention. Additionally, we propose a new metric for evaluating the reliability of abstention fine-tuning tasks more comprehensively. Our method significantly enhances reliability in both in-domain and out-of-distribution benchmarks.",
        "tags": [
            "LLM",
            "RL"
        ]
    },
    {
        "id": "90",
        "title": "SpecKD: Speculative Decoding for Effective Knowledge Distillation of LLMs",
        "author": [
            "Haiduo Huang",
            "Jiangcheng Song",
            "Yadong Zhang",
            "Pengju Ren"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24021",
        "abstract": "Knowledge Distillation (KD) has become a cornerstone technique for compressing Large Language Models (LLMs) into smaller, more efficient student models. However, conventional KD approaches typically apply the distillation loss uniformly across all tokens, regardless of the teacher's confidence. This indiscriminate mimicry can introduce noise, as the student is forced to learn from the teacher's uncertain or high-entropy predictions, which may ultimately harm student performance-especially when the teacher is much larger and more powerful. To address this, we propose Speculative Knowledge Distillation (SpecKD), a novel, plug-and-play framework that introduces a dynamic, token-level gating mechanism inspired by the \"propose-and-verify\" paradigm of speculative decoding. At each step, the student's token proposal is verified against the teacher's distribution; the distillation loss is selectively applied only to \"accepted\" tokens, while \"rejected\" tokens are masked out. Extensive experiments on diverse text generation tasks show that SpecKD consistently and significantly outperforms strong KD baselines, leading to more stable training and more capable student models, and achieving state-of-the-art results.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "91",
        "title": "OneCast: Structured Decomposition and Modular Generation for Cross-Domain Time Series Forecasting",
        "author": [
            "Tingyue Pan",
            "Mingyue Cheng",
            "Shilong Zhang",
            "Zhiding Liu",
            "Xiaoyu Tao",
            "Yucong Luo",
            "Jintao Zhang",
            "Qi Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24028",
        "abstract": "Cross-domain time series forecasting is a valuable task in various web applications. Despite its rapid advancement, achieving effective generalization across heterogeneous time series data remains a significant challenge. Existing methods have made progress by extending single-domain models, yet often fall short when facing domain-specific trend shifts and inconsistent periodic patterns. We argue that a key limitation lies in treating temporal series as undifferentiated sequence, without explicitly decoupling their inherent structural components. To address this, we propose OneCast, a structured and modular forecasting framework that decomposes time series into seasonal and trend components, each modeled through tailored generative pathways. Specifically, the seasonal component is captured by a lightweight projection module that reconstructs periodic patterns via interpretable basis functions. In parallel, the trend component is encoded into discrete tokens at segment level via a semantic-aware tokenizer, and subsequently inferred through a masked discrete diffusion mechanism. The outputs from both branches are combined to produce a final forecast that captures seasonal patterns while tracking domain-specific trends. Extensive experiments across eight domains demonstrate that OneCast mostly outperforms state-of-the-art baselines.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "92",
        "title": "Improved Accuracy of Robot Localization Using 3-D LiDAR in a Hippocampus-Inspired Model",
        "author": [
            "Andrew Gerstenslager",
            "Bekarys Dukenbaev",
            "Ali A. Minai"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24029",
        "abstract": "Boundary Vector Cells (BVCs) are a class of neurons in the brains of vertebrates that encode environmental boundaries at specific distances and allocentric directions, playing a central role in forming place fields in the hippocampus. Most computational BVC models are restricted to two-dimensional (2D) environments, making them prone to spatial ambiguities in the presence of horizontal symmetries in the environment. To address this limitation, we incorporate vertical angular sensitivity into the BVC framework, thereby enabling robust boundary detection in three dimensions, and leading to significantly more accurate spatial localization in a biologically-inspired robot model.\nThe proposed model processes LiDAR data to capture vertical contours, thereby disambiguating locations that would be indistinguishable under a purely 2D representation. Experimental results show that in environments with minimal vertical variation, the proposed 3D model matches the performance of a 2D baseline; yet, as 3D complexity increases, it yields substantially more distinct place fields and markedly reduces spatial aliasing. These findings show that adding a vertical dimension to BVC-based localization can significantly enhance navigation and mapping in real-world 3D spaces while retaining performance parity in simpler, near-planar scenarios.",
        "tags": [
            "3D",
            "Detection",
            "Robotics"
        ]
    },
    {
        "id": "93",
        "title": "Human Machine Social Hybrid Intelligence:A Collaborative Decision Making Framework for Large Model Agent Groups and Human Experts",
        "author": [
            "Ahmet Akkaya Melih",
            "Yamuna Singh",
            "Kunal L. Agarwal",
            "Priya Mukherjee",
            "Kiran Pattnaik",
            "Hanuman Bhatia"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24030",
        "abstract": "The rapid advancements in large foundation models and multi-agent systems offer unprecedented capabilities, yet current Human-in-the-Loop (HiTL) paradigms inadequately integrate human expertise, often leading to cognitive overload and decision-making bottlenecks in complex, high-stakes environments. We propose the \"Human-Machine Social Hybrid Intelligence\" (HMS-HI) framework, a novel architecture designed for deep, collaborative decision-making between groups of human experts and LLM-powered AI agents. HMS-HI is built upon three core pillars: (1) a \\textbf{Shared Cognitive Space (SCS)} for unified, multi-modal situational awareness and structured world modeling; (2) a \\textbf{Dynamic Role and Task Allocation (DRTA)} module that adaptively assigns tasks to the most suitable agent (human or AI) based on capabilities and workload; and (3) a \\textbf{Cross-Species Trust Calibration (CSTC)} protocol that fosters transparency, accountability, and mutual adaptation through explainable declarations and structured feedback. Validated in a high-fidelity urban emergency response simulation, HMS-HI significantly reduced civilian casualties by 72\\% and cognitive load by 70\\% compared to traditional HiTL approaches, demonstrating superior decision quality, efficiency, and human-AI trust. An ablation study confirms the critical contribution of each module, highlighting that engineered trust and shared context are foundational for scalable, synergistic human-AI collaboration.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "94",
        "title": "AutoPrompt: Automated Red-Teaming of Text-to-Image Models via LLM-Driven Adversarial Prompts",
        "author": [
            "Yufan Liu",
            "Wanqian Zhang",
            "Huashan Chen",
            "Lin Wang",
            "Xiaojun Jia",
            "Zheng Lin",
            "Weiping Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24034",
        "abstract": "Despite rapid advancements in text-to-image (T2I) models, their safety mechanisms are vulnerable to adversarial prompts, which maliciously generate unsafe images. Current red-teaming methods for proactively assessing such vulnerabilities usually require white-box access to T2I models, and rely on inefficient per-prompt optimization, as well as inevitably generate semantically meaningless prompts easily blocked by filters. In this paper, we propose APT (AutoPrompT), a black-box framework that leverages large language models (LLMs) to automatically generate human-readable adversarial suffixes for benign prompts. We first introduce an alternating optimization-finetuning pipeline between adversarial suffix optimization and fine-tuning the LLM utilizing the optimized suffix. Furthermore, we integrates a dual-evasion strategy in optimization phase, enabling the bypass of both perplexity-based filter and blacklist word filter: (1) we constrain the LLM generating human-readable prompts through an auxiliary LLM perplexity scoring, which starkly contrasts with prior token-level gibberish, and (2) we also introduce banned-token penalties to suppress the explicit generation of banned-tokens in blacklist. Extensive experiments demonstrate the excellent red-teaming performance of our human-readable, filter-resistant adversarial prompts, as well as superior zero-shot transferability which enables instant adaptation to unseen prompts and exposes critical vulnerabilities even in commercial APIs (e.g., http://Leonardo.Ai.).",
        "tags": [
            "LLM",
            "Text-to-Image"
        ]
    },
    {
        "id": "95",
        "title": "Kernelized Sparse Fine-Tuning with Bi-level Parameter Competition for Vision Models",
        "author": [
            "Shufan Shen",
            "Junshu Sun",
            "Shuhui Wang",
            "Qingming Huang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24037",
        "abstract": "Parameter-efficient fine-tuning (PEFT) aims to adapt pre-trained vision models to downstream tasks. Among PEFT paradigms, sparse tuning achieves remarkable performance by adjusting only the weights most relevant to downstream tasks, rather than densely tuning the entire weight matrix. Current methods follow a two-stage paradigm. First, it locates task-relevant weights by gradient information, which overlooks the parameter adjustments during fine-tuning and limits the performance. Second, it updates only the located weights by applying a sparse mask to the gradient of the weight matrix, which results in high memory usage due to the storage of all weight matrices in the optimizer. In this paper, we propose a one-stage method named SNELLA to overcome the above limitations. For memory usage, SNELLA selectively updates the weight matrix by adding it to another sparse matrix that is merged by two low-rank learnable matrices. We extend the low-rank decomposition by introducing nonlinear kernel functions, thereby increasing the rank of the resulting merged matrix to prevent the interdependency among weight updates, enabling better adaptation to downstream tasks. For locating task-relevant weights, we propose an adaptive bi-level sparsity allocation mechanism that encourages weights to compete across and inside layers based on their importance scores in an end-to-end manner. Extensive experiments are conducted on classification, segmentation, and generation tasks using different pre-trained vision models. The results show that SNELLA achieves SOTA performance with low memory usage. Notably, SNELLA obtains 1.8% (91.9% v.s. 90.1%) higher Top-1 accuracy on the FGVC benchmark compared to SPT-LoRA. Compared to previous methods, SNELLA achieves a memory reduction of 31.1%-39.9% across models with parameter scales from 86M to 632M. Our source codes are available at https://github.com/ssfgunner/SNELL.",
        "tags": [
            "LoRA",
            "Segmentation"
        ]
    },
    {
        "id": "96",
        "title": "Pie: A Programmable Serving System for Emerging LLM Applications",
        "author": [
            "In Gim",
            "Zhiyao Ma",
            "Seung-seob Lee",
            "Lin Zhong"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24051",
        "abstract": "Emerging large language model (LLM) applications involve diverse reasoning strategies and agentic workflows, straining the capabilities of existing serving systems built on a monolithic token generation loop. This paper introduces Pie, a programmable LLM serving system designed for flexibility and efficiency. Pie decomposes the traditional generation loop into fine-grained service handlers exposed via an API and delegates control of the generation process to user-provided programs, called inferlets. This enables applications to implement new KV cache strategies, bespoke generation logic, and seamlessly integrate computation and I/O-entirely within the application, without requiring modifications to the serving system. Pie executes inferlets using WebAssembly, benefiting from its lightweight sandboxing. Our evaluation shows Pie matches state-of-the-art performance on standard tasks (3-12% latency overhead) while significantly improving latency and throughput (1.3x-3.4x higher) on agentic workflows by enabling application-specific optimizations.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "97",
        "title": "Language-Conditioned Representations and Mixture-of-Experts Policy for Robust Multi-Task Robotic Manipulation",
        "author": [
            "Xiucheng Zhang",
            "Yang Jiang",
            "Hongwei Qing",
            "Jiashuo Bai"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24055",
        "abstract": "Perceptual ambiguity and task conflict limit multitask robotic manipulation via imitation learning. We propose a framework combining a Language-Conditioned Visual Representation (LCVR) module and a Language-conditioned Mixture-ofExperts Density Policy (LMoE-DP). LCVR resolves perceptual ambiguities by grounding visual features with language instructions, enabling differentiation between visually similar tasks. To mitigate task conflict, LMoE-DP uses a sparse expert architecture to specialize in distinct, multimodal action distributions, stabilized by gradient modulation. On real-robot benchmarks, LCVR boosts Action Chunking with Transformers (ACT) and Diffusion Policy (DP) success rates by 33.75% and 25%, respectively. The full framework achieves a 79% average success, outperforming the advanced baseline by 21%. Our work shows that combining semantic grounding and expert specialization enables robust, efficient multi-task manipulation",
        "tags": [
            "Diffusion",
            "MoE",
            "Robotics"
        ]
    },
    {
        "id": "98",
        "title": "FALQON: Accelerating LoRA Fine-tuning with Low-Bit Floating-Point Arithmetic",
        "author": [
            "Kanghyun Choi",
            "Hyeyoon Lee",
            "SunJong Park",
            "Dain Kwon",
            "Jinho Lee"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24061",
        "abstract": "Low-bit floating-point (FP) formats, such as FP8, provide significant acceleration and memory savings in model training thanks to native hardware support on modern GPUs and NPUs. However, we analyze that FP8 quantization offers speedup primarily for large-dimensional matrix multiplications, while inherent quantization overheads diminish speedup when applied to low-rank adaptation (LoRA), which uses small-dimensional matrices for efficient fine-tuning of large language models (LLMs). To address this limitation, we propose FALQON, a novel framework that eliminates the quantization overhead from separate LoRA computational paths by directly merging LoRA adapters into an FP8-quantized backbone during fine-tuning. Furthermore, we reformulate the forward and backward computations for merged adapters to significantly reduce quantization overhead, and introduce a row-wise proxy update mechanism that efficiently integrates substantial updates into the quantized backbone. Experimental evaluations demonstrate that FALQON achieves approximately a 3$\\times$ training speedup over existing quantized LoRA methods with a similar level of accuracy, providing a practical solution for efficient large-scale model fine-tuning. Moreover, FALQON's end-to-end FP8 workflow removes the need for post-training quantization, facilitating efficient deployment. Code is available at https://github.com/iamkanghyunchoi/falqon.",
        "tags": [
            "LLM",
            "LoRA"
        ]
    },
    {
        "id": "99",
        "title": "Balanced Collaborative Exploration via Distributed Topological Graph Voronoi Partition",
        "author": [
            "Tianyi Ding",
            "Ronghao Zheng",
            "Senlin Zhang",
            "Meiqin Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24067",
        "abstract": "This work addresses the collaborative multi-robot autonomous online exploration problem, particularly focusing on distributed exploration planning for dynamically balanced exploration area partition and task allocation among a team of mobile robots operating in obstacle-dense non-convex environments.\nWe present a novel topological map structure that simultaneously characterizes both spatial connectivity and global exploration completeness of the environment. The topological map is updated incrementally to utilize known spatial information for updating reachable spaces, while exploration targets are planned in a receding horizon fashion under global coverage guidance.\nA distributed weighted topological graph Voronoi algorithm is introduced implementing balanced graph space partitions of the fused topological maps. Theoretical guarantees are provided for distributed consensus convergence and equitable graph space partitions with constant bounds.\nA local planner optimizes the visitation sequence of exploration targets within the balanced partitioned graph space to minimize travel distance, while generating safe, smooth, and dynamically feasible motion trajectories.\nComprehensive benchmarking against state-of-the-art methods demonstrates significant improvements in exploration efficiency, completeness, and workload balance across the robot team.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "100",
        "title": "Dynamically-Consistent Trajectory Optimization for Legged Robots via Contact Point Decomposition",
        "author": [
            "Sangmin Kim",
            "Hajun Kim",
            "Gijeong Kim",
            "Min-Gyu Kim",
            "Hae-Won Park"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24069",
        "abstract": "To generate reliable motion for legged robots through trajectory optimization, it is crucial to simultaneously compute the robot's path and contact sequence, as well as accurately consider the dynamics in the problem formulation. In this paper, we present a phase-based trajectory optimization that ensures the feasibility of translational dynamics and friction cone constraints throughout the entire trajectory. Specifically, our approach leverages the superposition properties of linear differential equations to decouple the translational dynamics for each contact point, which operates under different phase sequences. Furthermore, we utilize the differentiation matrix of B{Ã©}zier polynomials to derive an analytical relationship between the robot's position and force, thereby ensuring the consistent satisfaction of translational dynamics. Additionally, by exploiting the convex closure property of B{Ã©}zier polynomials, our method ensures compliance with friction cone constraints. Using the aforementioned approach, the proposed trajectory optimization framework can generate dynamically reliable motions with various gait sequences for legged robots. We validate our framework using a quadruped robot model, focusing on the feasibility of dynamics and motion generation.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "101",
        "title": "Challenging Multilingual LLMs: A New Taxonomy and Benchmark for Unraveling Hallucination in Translation",
        "author": [
            "Xinwei Wu",
            "Heng Liu",
            "Jiang Zhou",
            "Xiaohu Zhao",
            "Linlong Xu",
            "Longyue Wang",
            "Weihua Luo",
            "Kaifu Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24073",
        "abstract": "Large Language Models (LLMs) have advanced machine translation but remain vulnerable to hallucinations. Unfortunately, existing MT benchmarks are not capable of exposing failures in multilingual LLMs. To disclose hallucination in multilingual LLMs, we introduce a diagnostic framework with a taxonomy that separates Instruction Detachment from Source Detachment. Guided by this taxonomy, we create HalloMTBench, a multilingual, human-verified benchmark across 11 English-to-X directions. We employed 4 frontier LLMs to generate candidates and scrutinize these candidates with an ensemble of LLM judges, and expert validation. In this way, we curate 5,435 high-quality instances. We have evaluated 17 LLMs on HalloMTBench. Results reveal distinct ``hallucination triggers'' -- unique failure patterns reflecting model scale, source length sensitivity, linguistic biases, and Reinforcement-Learning (RL) amplified language mixing. HalloMTBench offers a forward-looking testbed for diagnosing LLM translation failures. HalloMTBench is available in https://huggingface.co/collections/AIDC-AI/marco-mt.",
        "tags": [
            "LLM",
            "RL"
        ]
    },
    {
        "id": "102",
        "title": "Beyond Objects: Contextual Synthetic Data Generation for Fine-Grained Classification",
        "author": [
            "William Yang",
            "Xindi Wu",
            "Zhiwei Deng",
            "Esin Tureci",
            "Olga Russakovsky"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24078",
        "abstract": "Text-to-image (T2I) models are increasingly used for synthetic dataset generation, but generating effective synthetic training data for classification remains challenging. Fine-tuning a T2I model with a few real examples can help improve the quality of synthetic training data; however, it may also cause overfitting and reduce diversity in the generated samples. We propose a fine-tuning strategy BOB (BeyondOBjects) to mitigate these concerns for fine-grained classification. Given a small set of real examples, we first extract class-agnostic attributes such as scene background and object pose. We then explicitly condition on these attributes during fine-tuning of the T2I model and marginalize them out during generation. This design mitigates overfitting, preserves the T2I model's generative prior, reduces estimation errors, and further minimizes unintended inter-class associations. Extensive experiments across multiple T2I models, backbones, and datasets show that our method achieves state-of-the-art performance in low-shot fine-grained classification when augmented with synthetic data. Concretely, BOB outperforms DataDream by 7.4% on the Aircraft dataset (from 50.0% to 57.4% when fine-tuning a CLIP classifier with five real images augmented with 100 synthetic images). In three of the four benchmarks, fine-tuning downstream models with 5 real images augmented with BOB achieves better performance than fine-tuning with 10 real images. Collectively, BOB outperforms prior art in 18 of 24 experimental settings, with 2+% accuracy improvements in 14 of these settings.",
        "tags": [
            "CLIP",
            "Text-to-Image"
        ]
    },
    {
        "id": "103",
        "title": "Global PIQA: Evaluating Physical Commonsense Reasoning Across 100+ Languages and Cultures",
        "author": [
            "Tyler A. Chang",
            "Catherine Arnett",
            "Abdelrahman Eldesokey",
            "Abdelrahman Sadallah",
            "Abeer Kashar",
            "Abolade Daud",
            "Abosede Grace Olanihun",
            "Adamu Labaran Mohammed",
            "Adeyemi Praise",
            "Adhikarinayum Meerajita Sharma",
            "Aditi Gupta",
            "Afitab Iyigun",
            "Afonso SimplÃ­cio",
            "Ahmed Essouaied",
            "Aicha Chorana",
            "Akhil Eppa",
            "Akintunde Oladipo",
            "Akshay Ramesh",
            "Aleksei Dorkin",
            "Alfred Malengo Kondoro",
            "Alham Fikri Aji",
            "Ali Eren ÃetintaÅ",
            "Allan Hanbury",
            "Alou Dembele",
            "Alp Niksarli",
            "Ãlvaro Arroyo",
            "Amin Bajand",
            "Amol Khanna",
            "Ana Chkhaidze",
            "Ana Condez",
            "Andiswa Mkhonto",
            "Andrew Hoblitzell",
            "Andrew Tran",
            "Angelos Poulis",
            "Anirban Majumder",
            "Anna Vacalopoulou",
            "Annette Kuuipolani Kanahele Wong",
            "Annika Simonsen",
            "Anton Kovalev",
            "Ashvanth.S",
            "Ayodeji Joseph Lana",
            "Barkin Kinay",
            "Bashar Alhafni",
            "Benedict Cibalinda Busole",
            "Bernard Ghanem",
            "Bharti Nathani",
            "Biljana Stojanovska ÄuriÄ",
            "Bola Agbonile",
            "Bragi Bergsson",
            "Bruce Torres Fischer",
            "Burak Tutar",
            "Burcu AlakuÅ ÃÄ±nar",
            "Cade J. Kanoniakapueo Kane",
            "Can Udomcharoenchaikit",
            "Catherine Arnett",
            "Chadi Helwe",
            "Chaithra Reddy Nerella",
            "Chen Cecilia Liu",
            "Chiamaka Glory Nwokolo",
            "Cristina EspaÃ±a-Bonet",
            "Cynthia Amol",
            "DaeYeop Lee",
            "Dana Arad",
            "Daniil Dzenhaliou",
            "Daria Pugacheva",
            "Dasol Choi",
            "Daud Abolade",
            "David Liu",
            "David Semedo",
            "Deborah Popoola",
            "Deividas Mataciunas",
            "Delphine Nyaboke",
            "Dhyuthy Krishna Kumar",
            "Diogo GlÃ³ria-Silva",
            "Diogo Tavares",
            "Divyanshu Goyal",
            "DongGeon Lee",
            "Ebele Nwamaka Anajemba",
            "Egonu Ngozi Grace",
            "Elena Mickel",
            "Elena Tutubalina",
            "Elias Herranen",
            "Emile Anand",
            "Emmanuel Habumuremyi",
            "Emuobonuvie Maria Ajiboye",
            "Eryawan Presma Yulianrifat",
            "Esther Adenuga",
            "Ewa Rudnicka",
            "Faith Olabisi Itiola",
            "Faran Taimoor Butt",
            "Fathima Thekkekara",
            "Fatima Haouari",
            "Filbert Aurelian Tjiaranata",
            "Firas Laakom",
            "Francesca Grasso",
            "Francesco Orabona",
            "Francesco Periti",
            "Gbenga Kayode Solomon",
            "Gia Nghia Ngo",
            "Gloria Udhehdhe-oze"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24081",
        "abstract": "To date, there exist almost no culturally-specific evaluation benchmarks for large language models (LLMs) that cover a large number of languages and cultures. In this paper, we present Global PIQA, a participatory commonsense reasoning benchmark for over 100 languages, constructed by hand by 335 researchers from 65 countries around the world. The 116 language varieties in Global PIQA cover five continents, 14 language families, and 23 writing systems. In the non-parallel split of Global PIQA, over 50% of examples reference local foods, customs, traditions, or other culturally-specific elements. We find that state-of-the-art LLMs perform well on Global PIQA in aggregate, but they exhibit weaker performance in lower-resource languages (up to a 37% accuracy gap, despite random chance at 50%). Open models generally perform worse than proprietary models. Global PIQA highlights that in many languages and cultures, everyday knowledge remains an area for improvement, alongside more widely-discussed capabilities such as complex reasoning and expert knowledge. Beyond its uses for LLM evaluation, we hope that Global PIQA provides a glimpse into the wide diversity of cultures in which human language is embedded.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "104",
        "title": "Information-Theoretic Discrete Diffusion",
        "author": [
            "Moongyu Jeon",
            "Sangwoo Shin",
            "Dongjae Jeon",
            "Albert No"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24088",
        "abstract": "We present an information-theoretic framework for discrete diffusion models that yields principled estimators of log-likelihood using score-matching losses. Inspired by the I-MMSE identity for the Gaussian setup, we derive analogous results for the discrete setting. Specifically, we introduce the Information-Minimum Denoising Score Entropy (I-MDSE) relation, which links mutual information between data and its diffused version to the minimum denoising score entropy (DSE) loss. We extend this theory to masked diffusion and establish the Information-Minimum Denoising Cross-Entropy (I-MDCE) relation, connecting cross-entropy losses to mutual information in discrete masked processes. These results provide a time-integral decomposition of the log-likelihood of the data in terms of optimal score-based losses, showing that commonly used losses such as DSE and DCE are not merely variational bounds but tight and principled estimators of log-likelihood. The I-MDCE decomposition further enables practical extensions, including time-free formula, conditional likelihood estimation in prompt-response tasks, and coupled Monte Carlo estimation of likelihood ratios. Experiments on synthetic and real-world data confirm the accuracy, variance stability, and utility of our estimators. The code is publicly available at https://github.com/Dongjae0324/infodis.",
        "tags": [
            "Diffusion",
            "Score Matching"
        ]
    },
    {
        "id": "105",
        "title": "OmniText: A Training-Free Generalist for Controllable Text-Image Manipulation",
        "author": [
            "Agus Gunawan",
            "Samuel Teodoro",
            "Yun Chen",
            "Soo Ye Kim",
            "Jihyong Oh",
            "Munchurl Kim"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24093",
        "abstract": "Recent advancements in diffusion-based text synthesis have demonstrated significant performance in inserting and editing text within images via inpainting. However, despite the potential of text inpainting methods, three key limitations hinder their applicability to broader Text Image Manipulation (TIM) tasks: (i) the inability to remove text, (ii) the lack of control over the style of rendered text, and (iii) a tendency to generate duplicated letters. To address these challenges, we propose OmniText, a training-free generalist capable of performing a wide range of TIM tasks. Specifically, we investigate two key properties of cross- and self-attention mechanisms to enable text removal and to provide control over both text styles and content. Our findings reveal that text removal can be achieved by applying self-attention inversion, which mitigates the model's tendency to focus on surrounding text, thus reducing text hallucinations. Additionally, we redistribute cross-attention, as increasing the probability of certain text tokens reduces text hallucination. For controllable inpainting, we introduce novel loss functions in a latent optimization framework: a cross-attention content loss to improve text rendering accuracy and a self-attention style loss to facilitate style customization. Furthermore, we present OmniText-Bench, a benchmark dataset for evaluating diverse TIM tasks. It includes input images, target text with masks, and style references, covering diverse applications such as text removal, rescaling, repositioning, and insertion and editing with various styles. Our OmniText framework is the first generalist method capable of performing diverse TIM tasks. It achieves state-of-the-art performance across multiple tasks and metrics compared to other text inpainting methods and is comparable with specialist methods.",
        "tags": [
            "Diffusion",
            "Inpainting"
        ]
    },
    {
        "id": "106",
        "title": "Model-Guided Dual-Role Alignment for High-Fidelity Open-Domain Video-to-Audio Generation",
        "author": [
            "Kang Zhang",
            "Trung X. Pham",
            "Suyeon Lee",
            "Axi Niu",
            "Arda Senocak",
            "Joon Son Chung"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24103",
        "abstract": "We present MGAudio, a novel flow-based framework for open-domain video-to-audio generation, which introduces model-guided dual-role alignment as a central design principle. Unlike prior approaches that rely on classifier-based or classifier-free guidance, MGAudio enables the generative model to guide itself through a dedicated training objective designed for video-conditioned audio generation. The framework integrates three main components: (1) a scalable flow-based Transformer model, (2) a dual-role alignment mechanism where the audio-visual encoder serves both as a conditioning module and as a feature aligner to improve generation quality, and (3) a model-guided objective that enhances cross-modal coherence and audio realism. MGAudio achieves state-of-the-art performance on VGGSound, reducing FAD to 0.40, substantially surpassing the best classifier-free guidance baselines, and consistently outperforms existing methods across FD, IS, and alignment metrics. It also generalizes well to the challenging UnAV-100 benchmark. These results highlight model-guided dual-role alignment as a powerful and scalable paradigm for conditional video-to-audio generation. Code is available at: https://github.com/pantheon5100/mgaudio",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "107",
        "title": "UniField: Joint Multi-Domain Training for Universal Surface Pressure Modeling",
        "author": [
            "Junhong Zou",
            "Zhenxu Sun",
            "Yueqing Wang",
            "Wei Qiu",
            "Zhaoxiang Zhang",
            "Zhen Lei",
            "Xiangyu Zhu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24106",
        "abstract": "Aerodynamic simulation of the surface pressure field around objects is crucial for many engineering problems. In recent years, deep neural networks have emerged as an efficient alternative to traditional, computationally expensive CFD simulations for modeling surface pressure fields. However, data scarcity remains a fundamental challenge, limiting the application of neural networks. To address this limitation, we propose to integrate aerodynamic data from multiple subfields and conduct joint training to learn more general field representations. We consolidate five different datasets covering various fields, including automobiles, trains, aircraft, and general shapes. Facing significant data differences across different domains, we propose UniField, which employs a domain-agnostic Transformer module to extract general point cloud features and customizes domain-specific flow-conditioned adapters to adapt to the flow information in different subfields. Despite the fact that aerodynamic data from different subfields are typically governed by different equations, we compare models trained jointly on all data with those trained separately on individual datasets and find that the jointly-trained model commonly demonstrates better performance. This indicates that these data complement each other to help the model learn better flow field representations. These results highlight the potential of UniField as a universal flow field representation model and lay the foundation for broader applications of neural networks in aerodynamic analysis.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "108",
        "title": "ZTRS: Zero-Imitation End-to-end Autonomous Driving with Trajectory Scoring",
        "author": [
            "Zhenxin Li",
            "Wenhao Yao",
            "Zi Wang",
            "Xinglong Sun",
            "Jingde Chen",
            "Nadine Chang",
            "Maying Shen",
            "Jingyu Song",
            "Zuxuan Wu",
            "Shiyi Lan",
            "Jose M. Alvarez"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24108",
        "abstract": "End-to-end autonomous driving maps raw sensor inputs directly into ego-vehicle trajectories to avoid cascading errors from perception modules and to leverage rich semantic cues. Existing frameworks largely rely on Imitation Learning (IL), which can be limited by sub-optimal expert demonstrations and covariate shift during deployment. On the other hand, Reinforcement Learning (RL) has recently shown potential in scaling up with simulations, but is typically confined to low-dimensional symbolic inputs (e.g. 3D objects and maps), falling short of full end-to-end learning from raw sensor data. We introduce ZTRS (Zero-Imitation End-to-End Autonomous Driving with Trajectory Scoring), a framework that combines the strengths of both worlds: sensor inputs without losing information and RL training for robust planning. To the best of our knowledge, ZTRS is the first framework that eliminates IL entirely by only learning from rewards while operating directly on high-dimensional sensor data. ZTRS utilizes offline reinforcement learning with our proposed Exhaustive Policy Optimization (EPO), a variant of policy gradient tailored for enumerable actions and rewards. ZTRS demonstrates strong performance across three benchmarks: Navtest (generic real-world open-loop planning), Navhard (open-loop planning in challenging real-world and synthetic scenarios), and HUGSIM (simulated closed-loop driving). Specifically, ZTRS achieves the state-of-the-art result on Navhard and outperforms IL-based baselines on HUGSIM. Code will be available at https://github.com/woxihuanjiangguo/ZTRS.",
        "tags": [
            "3D",
            "RL"
        ]
    },
    {
        "id": "109",
        "title": "PFEA: An LLM-based High-Level Natural Language Planning and Feedback Embodied Agent for Human-Centered AI",
        "author": [
            "Wenbin Ding",
            "Jun Chen",
            "Mingjia Chen",
            "Fei Xie",
            "Qi Mao",
            "Philip Dames"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24109",
        "abstract": "The rapid advancement of Large Language Models (LLMs) has marked a significant breakthrough in Artificial Intelligence (AI), ushering in a new era of Human-centered Artificial Intelligence (HAI). HAI aims to better serve human welfare and needs, thereby placing higher demands on the intelligence level of robots, particularly in aspects such as natural language interaction, complex task planning, and execution. Intelligent agents powered by LLMs have opened up new pathways for realizing HAI. However, existing LLM-based embodied agents often lack the ability to plan and execute complex natural language control tasks online. This paper explores the implementation of intelligent robotic manipulating agents based on Vision-Language Models (VLMs) in the physical world. We propose a novel embodied agent framework for robots, which comprises a human-robot voice interaction module, a vision-language agent module and an action execution module. The vision-language agent itself includes a vision-based task planner, a natural language instruction converter, and a task performance feedback evaluator. Experimental results demonstrate that our agent achieves a 28\\% higher average task success rate in both simulated and real environments compared to approaches relying solely on LLM+CLIP, significantly improving the execution success rate of high-level natural language instruction tasks.",
        "tags": [
            "CLIP",
            "LLM",
            "Robotics",
            "VLM"
        ]
    },
    {
        "id": "110",
        "title": "On the Superconvergence of ESFR Schemes",
        "author": [
            "Mathias Dufresne-PichÃ©",
            "Siva Nadarajah"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24111",
        "abstract": "The energy stable flux reconstruction (ESFR) method provides an efficient and flexible framework to devise high-order linearly stable numerical schemes which can achieve high levels of accuracy on unstructured grids. While superconvergent properties of ESFR schemes have been observed in numerical experiments, no formal proof of this behavior has been reported in the literature. In this work, we attempt to address this by providing a simple derivation for the superconvergence of the dispersion-dissipation error of ESFR schemes for the linear advection problem when using an upwind numerical flux. We show that the superconvergence of ESFR schemes essentially relies on the capacity of the latter to generate superconvergent rational approximants of the exponential function, which is reminiscent of well-known theoretical results for superconvergence of discontinuous Galerkin (DG) methods. We also demonstrate that the drops in order of accuracy which are observed in numerical experiments as the ESFR scalar $c$ is increased are caused by both a modification of the structure of these rational approximants and a change in the multiplicity of the physical eigenvalue of the schemes as $c \\to \\infty$. Finally, our theoretical results are successfully validated against numerical experiments.",
        "tags": [
            "FLUX"
        ]
    },
    {
        "id": "111",
        "title": "HistoLens: An Interactive XAI Toolkit for Verifying and Mitigating Flaws in Vision-Language Models for Histopathology",
        "author": [
            "Sandeep Vissapragada",
            "Vikrant Sahu",
            "Gagan Raj Gupta",
            "Vandita Singh"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24115",
        "abstract": "For doctors to truly trust artificial intelligence, it can't be a black box. They need to understand its reasoning, almost as if they were consulting a colleague. We created HistoLens1 to be that transparent, collaborative partner. It allows a pathologist to simply ask a question in plain English about a tissue slide--just as they would ask a trainee. Our system intelligently translates this question into a precise query for its AI engine, which then provides a clear, structured report. But it doesn't stop there. If a doctor ever asks, \"Why?\", HistoLens can instantly provide a 'visual proof' for any finding--a heatmap that points to the exact cells and regions the AI used for its analysis. We've also ensured the AI focuses only on the patient's tissue, just like a trained pathologist would, by teaching it to ignore distracting background noise. The result is a workflow where the pathologist remains the expert in charge, using a trustworthy AI assistant to verify their insights and make faster, more confident diagnoses.",
        "tags": [
            "VLM"
        ]
    },
    {
        "id": "112",
        "title": "LagMemo: Language 3D Gaussian Splatting Memory for Multi-modal Open-vocabulary Multi-goal Visual Navigation",
        "author": [
            "Haotian Zhou",
            "Xiaole Wang",
            "He Li",
            "Fusheng Sun",
            "Shengyu Guo",
            "Guolei Qi",
            "Jianghuan Xu",
            "Huijing Zhao"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24118",
        "abstract": "Navigating to a designated goal using visual information is a fundamental capability for intelligent robots. Most classical visual navigation methods are restricted to single-goal, single-modality, and closed set goal settings. To address the practical demands of multi-modal, open-vocabulary goal queries and multi-goal visual navigation, we propose LagMemo, a navigation system that leverages a language 3D Gaussian Splatting memory. During exploration, LagMemo constructs a unified 3D language memory. With incoming task goals, the system queries the memory, predicts candidate goal locations, and integrates a local perception-based verification mechanism to dynamically match and validate goals during navigation. For fair and rigorous evaluation, we curate GOAT-Core, a high-quality core split distilled from GOAT-Bench tailored to multi-modal open-vocabulary multi-goal visual navigation. Experimental results show that LagMemo's memory module enables effective multi-modal open-vocabulary goal localization, and that LagMemo outperforms state-of-the-art methods in multi-goal visual navigation. Project page: https://weekgoodday.github.io/lagmemo",
        "tags": [
            "3D",
            "Gaussian Splatting"
        ]
    },
    {
        "id": "113",
        "title": "Graph-Guided Concept Selection for Efficient Retrieval-Augmented Generation",
        "author": [
            "Ziyu Liu",
            "Yijing Liu",
            "Jianfei Yuan",
            "Minzhi Yan",
            "Le Yue",
            "Honghui Xiong",
            "Yi Yang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24120",
        "abstract": "Graph-based RAG constructs a knowledge graph (KG) from text chunks to enhance retrieval in Large Language Model (LLM)-based question answering. It is especially beneficial in domains such as biomedicine, law, and political science, where effective retrieval often involves multi-hop reasoning over proprietary documents. However, these methods demand numerous LLM calls to extract entities and relations from text chunks, incurring prohibitive costs at scale. Through a carefully designed ablation study, we observe that certain words (termed concepts) and their associated documents are more important. Based on this insight, we propose Graph-Guided Concept Selection (G2ConS). Its core comprises a chunk selection method and an LLM-independent concept graph. The former selects salient document chunks to reduce KG construction costs; the latter closes knowledge gaps introduced by chunk selection at zero cost. Evaluations on multiple real-world datasets show that G2ConS outperforms all baselines in construction cost, retrieval effectiveness, and answering quality.",
        "tags": [
            "LLM",
            "RAG"
        ]
    },
    {
        "id": "114",
        "title": "Reinforcement Learning for Long-Horizon Multi-Turn Search Agents",
        "author": [
            "Vivek Kalyan",
            "Martin Andrews"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24126",
        "abstract": "Large Language Model (LLM) agents can leverage multiple turns and tools to solve complex tasks, with prompt-based approaches achieving strong performance. This work demonstrates that Reinforcement Learning (RL) can push capabilities significantly further by learning from experience. Through experiments on a legal document search benchmark, we show that our RL-trained 14 Billion parameter model outperforms frontier class models (85% vs 78% accuracy). In addition, we explore turn-restricted regimes, during training and at test-time, that show these agents achieve better results if allowed to operate over longer multi-turn horizons.",
        "tags": [
            "LLM",
            "RL"
        ]
    },
    {
        "id": "115",
        "title": "ETC: training-free diffusion models acceleration with Error-aware Trend Consistency",
        "author": [
            "Jiajian Xie",
            "Hubery Yin",
            "Chen Li",
            "Zhou Zhao",
            "Shengyu Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24129",
        "abstract": "Diffusion models have achieved remarkable generative quality but remain bottlenecked by costly iterative sampling. Recent training-free methods accelerate diffusion process by reusing model outputs. However, these methods ignore denoising trends and lack error control for model-specific tolerance, leading to trajectory deviations under multi-step reuse and exacerbating inconsistencies in the generated results. To address these issues, we introduce Error-aware Trend Consistency (ETC), a framework that (1) introduces a consistent trend predictor that leverages the smooth continuity of diffusion trajectories, projecting historical denoising patterns into stable future directions and progressively distributing them across multiple approximation steps to achieve acceleration without deviating; (2) proposes a model-specific error tolerance search mechanism that derives corrective thresholds by identifying transition points from volatile semantic planning to stable quality refinement. Experiments show that ETC achieves a 2.65x acceleration over FLUX with negligible (-0.074 SSIM score) degradation of consistency.",
        "tags": [
            "Diffusion",
            "FLUX"
        ]
    },
    {
        "id": "116",
        "title": "Compositional Image Synthesis with Inference-Time Scaling",
        "author": [
            "Minsuk Ji",
            "Sanghyeok Lee",
            "Namhyuk Ahn"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24133",
        "abstract": "Despite their impressive realism, modern text-to-image models still struggle with compositionality, often failing to render accurate object counts, attributes, and spatial relations. To address this challenge, we present a training-free framework that combines an object-centric approach with self-refinement to improve layout faithfulness while preserving aesthetic quality. Specifically, we leverage large language models (LLMs) to synthesize explicit layouts from input prompts, and we inject these layouts into the image generation process, where a object-centric vision-language model (VLM) judge reranks multiple candidates to select the most prompt-aligned outcome iteratively. By unifying explicit layout-grounding with self-refine-based inference-time scaling, our framework achieves stronger scene alignment with prompts compared to recent text-to-image models. The code are available at https://github.com/gcl-inha/ReFocus.",
        "tags": [
            "LLM",
            "Text-to-Image",
            "VLM"
        ]
    },
    {
        "id": "117",
        "title": "VC4VG: Optimizing Video Captions for Text-to-Video Generation",
        "author": [
            "Yang Du",
            "Zhuoran Lin",
            "Kaiqiang Song",
            "Biao Wang",
            "Zhicheng Zheng",
            "Tiezheng Ge",
            "Bo Zheng",
            "Qin Jin"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24134",
        "abstract": "Recent advances in text-to-video (T2V) generation highlight the critical role of high-quality video-text pairs in training models capable of producing coherent and instruction-aligned videos. However, strategies for optimizing video captions specifically for T2V training remain underexplored. In this paper, we introduce VC4VG (Video Captioning for Video Generation), a comprehensive caption optimization framework tailored to the needs of T2V http://models.We begin by analyzing caption content from a T2V perspective, decomposing the essential elements required for video reconstruction into multiple dimensions, and proposing a principled caption design methodology. To support evaluation, we construct VC4VG-Bench, a new benchmark featuring fine-grained, multi-dimensional, and necessity-graded metrics aligned with T2V-specific http://requirements.Extensive T2V fine-tuning experiments demonstrate a strong correlation between improved caption quality and video generation performance, validating the effectiveness of our approach. We release all benchmark tools and code at https://github.com/qyr0403/VC4VG to support further research.",
        "tags": [
            "Text-to-Video",
            "Video Generation"
        ]
    },
    {
        "id": "118",
        "title": "Beyond Line-Level Filtering for the Pretraining Corpora of LLMs",
        "author": [
            "Chanwoo Park",
            "Suyoung Park",
            "Yelim Ahn",
            "Jongmin Kim",
            "Jongyeon Park",
            "Jaejin Lee"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24139",
        "abstract": "While traditional line-level filtering techniques, such as line-level deduplication and trailing-punctuation filters, are commonly used, these basic methods can sometimes discard valuable content, negatively affecting downstream performance. In this paper, we introduce two methods-pattern-aware line-level deduplication (PLD) and pattern-aware trailing punctuation filtering (PTF)-by enhancing the conventional filtering techniques. Our approach not only considers line-level signals but also takes into account their sequential distribution across documents, enabling us to retain structurally important content that might otherwise be removed. We evaluate these proposed methods by training small language models (1 B parameters) in both English and Korean. The results demonstrate that our methods consistently improve performance on multiple-choice benchmarks and significantly enhance generative question-answering accuracy on both SQuAD v1 and KorQuAD v1.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "119",
        "title": "Ko-MuSR: A Multistep Soft Reasoning Benchmark for LLMs Capable of Understanding Korean",
        "author": [
            "Chanwoo Park",
            "Suyoung Park",
            "JiA Kang",
            "Jongyeon Park",
            "Sangho Kim",
            "Hyunji M. Park",
            "Sumin Bae",
            "Mingyu Kang",
            "Jaejin Lee"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24150",
        "abstract": "We present Ko-MuSR, the first benchmark to comprehensively evaluate multistep, soft reasoning in long Korean narratives while minimizing data contamination. Built following MuSR, Ko-MuSR features fully Korean narratives, reasoning chains, and multiple-choice questions verified by human annotators for logical consistency and answerability. Evaluations of four large language models -- two multilingual and two Korean-specialized -- show that multilingual models outperform Korean-focused ones even in Korean reasoning tasks, indicating cross-lingual generalization of reasoning ability. Carefully designed prompting strategies, which combine few-shot examples, reasoning traces, and task-specific hints, further boost accuracy, approaching human-level performance. Ko-MuSR offers a solid foundation for advancing Korean NLP by enabling systematic evaluation of long-context reasoning and prompting strategies.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "120",
        "title": "BMGQ: A Bottom-up Method for Generating Complex Multi-hop Reasoning Questions from Semi-structured Data",
        "author": [
            "Bingsen Qiu",
            "Zijian Liu",
            "Xiao Liu",
            "Haoshen Yang",
            "Zeren Gao",
            "Bingjie Wang",
            "Feier Zhang",
            "Yixuan Qin",
            "Chunyan Li"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24151",
        "abstract": "Building training-ready multi-hop question answering (QA) datasets that truly stress a model's retrieval and reasoning abilities remains highly challenging recently. While there have been a few recent evaluation datasets that capture the characteristics of hard-to-search but easy-to-verify problems -- requiring the integration of ambiguous, indirect, and cross-domain cues -- these data resources remain scarce and are mostly designed for evaluation, making them unsuitable for supervised fine-tuning (SFT) or reinforcement learning (RL). Meanwhile, manually curating non-trivially retrievable questions -- where answers cannot be found through a single direct query but instead require multi-hop reasoning over oblique and loosely connected evidence -- incurs prohibitive human costs and fails to scale, creating a critical data bottleneck for training high-capability retrieval-and-reasoning agents.\nTo address this, we present an automated framework for generating high-difficulty, training-ready multi-hop questions from semi-structured knowledge sources. The system (i) grows diverse, logically labeled evidence clusters through Natural Language Inference (NLI)-based relation typing and diversity-aware expansion; (ii) applies reverse question construction to compose oblique cues so that isolated signals are underinformative but their combination uniquely identifies the target entity; and (iii) enforces quality with a two-step evaluation pipeline that combines multi-model consensus filtering with structured constraint decomposition and evidence-based matching. The result is a scalable process that yields complex, retrieval-resistant yet verifiable questions suitable for SFT/RL training as well as challenging evaluation, substantially reducing human curation effort while preserving the difficulty profile of strong evaluation benchmarks.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "121",
        "title": "Enhancing Vision-Language Models for Autonomous Driving through Task-Specific Prompting and Spatial Reasoning",
        "author": [
            "Aodi Wu",
            "Xubo Luo"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24152",
        "abstract": "This technical report presents our solution for the RoboSense Challenge at IROS 2025, which evaluates Vision-Language Models (VLMs) on autonomous driving scene understanding across perception, prediction, planning, and corruption detection tasks. We propose a systematic framework built on four core components. First, a Mixture-of-Prompts router classifies questions and dispatches them to task-specific expert prompts, eliminating interference across diverse question types. Second, task-specific prompts embed explicit coordinate systems, spatial reasoning rules, role-playing, Chain-of-Thought/Tree-of-Thought reasoning, and few-shot examples tailored to each task. Third, a visual assembly module composes multi-view images with object crops, magenta markers, and adaptive historical frames based on question requirements. Fourth, we configure model inference parameters (temperature, top-p, message roles) per task to optimize output quality. Implemented on Qwen2.5-VL-72B, our approach achieves 70.87% average accuracy on Phase-1 (clean data) and 72.85% on Phase-2 (corrupted data), demonstrating that structured prompting and spatial grounding substantially enhance VLM performance on safety-critical autonomous driving tasks. Code and prompt are available at https://github.com/wuaodi/UCAS-CSU-phase2.",
        "tags": [
            "CoT",
            "Detection",
            "VLM"
        ]
    },
    {
        "id": "122",
        "title": "BLM$_1$: A Boundless Large Model for Cross-Space, Cross-Task, and Cross-Embodiment Learning",
        "author": [
            "Wentao Tan",
            "Bowen Wang",
            "Heng Zhi",
            "Chenyu Liu",
            "Zhe Li",
            "Jian Liu",
            "Zengrong Lin",
            "Yukun Dai",
            "Yipeng Chen",
            "Wenjie Yang",
            "Enci Xie",
            "Hao Xue",
            "Baixu Ji",
            "Chen Xu",
            "Zhibin Wang",
            "Tianshi Wang",
            "Lei Zhu",
            "Heng Tao Shen"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24161",
        "abstract": "Multimodal large language models (MLLMs) have advanced vision-language reasoning and are increasingly deployed in embodied agents. However, significant limitations remain: MLLMs generalize poorly across digital-physical spaces and embodiments; vision-language-action models (VLAs) produce low-level actions yet lack robust high-level embodied reasoning; and most embodied large language models (ELLMs) are constrained to digital-space with poor generalization to the physical world. Thus, unified models that operate seamlessly across digital and physical spaces while generalizing across embodiments and tasks remain absent. We introduce the \\textbf{Boundless Large Model (BLM$_1$)}, a multimodal spatial foundation model that preserves instruction following and reasoning, incorporates embodied knowledge, and supports robust cross-embodiment control. BLM$_1$ integrates three key capabilities -- \\textit{cross-space transfer, cross-task learning, and cross-embodiment generalization} -- via a two-stage training paradigm. Stage I injects embodied knowledge into the MLLM through curated digital corpora while maintaining language competence. Stage II trains a policy module through an intent-bridging interface that extracts high-level semantics from the MLLM to guide control, without fine-tuning the MLLM backbone. This process is supported by a self-collected cross-embodiment demonstration suite spanning four robot embodiments and six progressively challenging tasks. Evaluations across digital and physical benchmarks show that a single BLM$_1$ instance outperforms four model families -- MLLMs, ELLMs, VLAs, and GMLMs -- achieving $\\sim\\!\\textbf{6%}$ gains in digital tasks and $\\sim\\!\\textbf{3%}$ in physical tasks.",
        "tags": [
            "LLM",
            "Robotics"
        ]
    },
    {
        "id": "123",
        "title": "MGA: Memory-Driven GUI Agent for Observation-Centric Interaction",
        "author": [
            "Weihua Cheng",
            "Ersheng Ni",
            "Wenlong Wang",
            "Yifei Sun",
            "Junming Liu",
            "Wangyu Shen",
            "Yirong Chen",
            "Botian Shi",
            "Ding Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24168",
        "abstract": "The rapid progress of Large Language Models (LLMs) and their multimodal extensions (MLLMs) has enabled agentic systems capable of perceiving and acting across diverse environments. A challenging yet impactful frontier is the development of GUI agents, which must navigate complex desktop and web interfaces while maintaining robustness and generalization. Existing paradigms typically model tasks as long-chain executions, concatenating historical trajectories into the context. While approaches such as Mirage and GTA1 refine planning or introduce multi-branch action selection, they remain constrained by two persistent issues: Dependence on historical trajectories, which amplifies error propagation. And Local exploration bias, where \"decision-first, observation-later\" mechanisms overlook critical interface cues. We introduce the Memory-Driven GUI Agent (MGA), which reframes GUI interaction around the principle of observe first, then decide. MGA models each step as an independent, context-rich environment state represented by a triad: current screenshot, task-agnostic spatial information, and a dynamically updated structured memory. Experiments on OSworld benchmarks, real desktop applications (Chrome, VSCode, VLC), and cross-task transfer demonstrate that MGA achieves substantial gains in robustness, generalization, and efficiency compared to state-of-the-art baselines. The code is publicly available at: {https://anonymous.4open.science/r/MGA-3571}.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "124",
        "title": "EddyFormer: Accelerated Neural Simulations of Three-Dimensional Turbulence at Scale",
        "author": [
            "Yiheng Du",
            "Aditi S. Krishnapriyan"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24173",
        "abstract": "Computationally resolving turbulence remains a central challenge in fluid dynamics due to its multi-scale interactions. Fully resolving large-scale turbulence through direct numerical simulation (DNS) is computationally prohibitive, motivating data-driven machine learning alternatives. In this work, we propose EddyFormer, a Transformer-based spectral-element (SEM) architecture for large-scale turbulence simulation that combines the accuracy of spectral methods with the scalability of the attention mechanism. We introduce an SEM tokenization that decomposes the flow into grid-scale and subgrid-scale components, enabling capture of both local and global features. We create a new three-dimensional isotropic turbulence dataset and train EddyFormer to achieves DNS-level accuracy at 256^3 resolution, providing a 30x speedup over DNS. When applied to unseen domains up to 4x larger than in training, EddyFormer preserves accuracy on physics-invariant metrics-energy spectra, correlation functions, and structure functions-showing domain generalization. On The Well benchmark suite of diverse turbulent flows, EddyFormer resolves cases where prior ML models fail to converge, accurately reproducing complex dynamics across a wide range of physical conditions.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "125",
        "title": "MuSaG: A Multimodal German Sarcasm Dataset with Full-Modal Annotations",
        "author": [
            "Aaron Scott",
            "Maike ZÃ¼fle",
            "Jan Niehues"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24178",
        "abstract": "Sarcasm is a complex form of figurative language in which the intended meaning contradicts the literal one. Its prevalence in social media and popular culture poses persistent challenges for natural language understanding, sentiment analysis, and content moderation. With the emergence of multimodal large language models, sarcasm detection extends beyond text and requires integrating cues from audio and vision. We present MuSaG, the first German multimodal sarcasm detection dataset, consisting of 33 minutes of manually selected and human-annotated statements from German television shows. Each instance provides aligned text, audio, and video modalities, annotated separately by humans, enabling evaluation in unimodal and multimodal settings. We benchmark nine open-source and commercial models, spanning text, audio, vision, and multimodal architectures, and compare their performance to human annotations. Our results show that while humans rely heavily on audio in conversational settings, models perform best on text. This highlights a gap in current multimodal models and motivates the use of MuSaG for developing models better suited to realistic scenarios. We release MuSaG publicly to support future research on multimodal sarcasm detection and human-model alignment.",
        "tags": [
            "Detection",
            "LLM"
        ]
    },
    {
        "id": "126",
        "title": "V-SAT: Video Subtitle Annotation Tool",
        "author": [
            "Arpita Kundu",
            "Joyita Chakraborty",
            "Anindita Desarkar",
            "Aritra Sen",
            "Srushti Anil Patil",
            "Vishwanathan Raman"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24180",
        "abstract": "The surge of audiovisual content on streaming platforms and social media has heightened the demand for accurate and accessible subtitles. However, existing subtitle generation methods primarily speech-based transcription or OCR-based extraction suffer from several shortcomings, including poor synchronization, incorrect or harmful text, inconsistent formatting, inappropriate reading speeds, and the inability to adapt to dynamic audio-visual contexts. Current approaches often address isolated issues, leaving post-editing as a labor-intensive and time-consuming process. In this paper, we introduce V-SAT (Video Subtitle Annotation Tool), a unified framework that automatically detects and corrects a wide range of subtitle quality issues. By combining Large Language Models(LLMs), Vision-Language Models (VLMs), Image Processing, and Automatic Speech Recognition (ASR), V-SAT leverages contextual cues from both audio and video. Subtitle quality improved, with the SUBER score reduced from 9.6 to 3.54 after resolving all language mode issues and F1-scores of ~0.80 for image mode issues. Human-in-the-loop validation ensures high-quality results, providing the first comprehensive solution for robust subtitle annotation.",
        "tags": [
            "LLM",
            "VLM"
        ]
    },
    {
        "id": "127",
        "title": "Investigating Software Aging in LLM-Generated Software Systems",
        "author": [
            "CÃ©sar Santos",
            "Ermeson Andrade",
            "Roberto Natella"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24188",
        "abstract": "Automatically generated software, especially code produced by Large Language Models (LLMs), is increasingly adopted to accelerate development and reduce manual effort. However, little is known about the long-term reliability of such systems under sustained execution. In this paper, we experimentally investigate the phenomenon of software aging in applications generated by LLM-based tools. Using the Bolt platform and standardized prompts from Baxbench, we generated four service-oriented applications and subjected them to 50-hour load tests. Resource usage, response time, and throughput were continuously monitored to detect degradation patterns. The results reveal significant evidence of software aging, including progressive memory growth, increased response time, and performance instability across all applications. Statistical analyzes confirm these trends and highlight variability in the severity of aging according to the type of application. Our findings show the need to consider aging in automatically generated software and provide a foundation for future studies on mitigation strategies and long-term reliability evaluation.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "128",
        "title": "Blindfolded Experts Generalize Better: Insights from Robotic Manipulation and Videogames",
        "author": [
            "Ev Zisselman",
            "Mirco Mutti",
            "Shelly Francis-Meretzki",
            "Elisei Shafer",
            "Aviv Tamar"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24194",
        "abstract": "Behavioral cloning is a simple yet effective technique for learning sequential decision-making from demonstrations. Recently, it has gained prominence as the core of foundation models for the physical world, where achieving generalization requires countless demonstrations of a multitude of tasks. Typically, a human expert with full information on the task demonstrates a (nearly) optimal behavior. In this paper, we propose to hide some of the task's information from the demonstrator. This ``blindfolded'' expert is compelled to employ non-trivial exploration to solve the task. We show that cloning the blindfolded expert generalizes better to unseen tasks than its fully-informed counterpart. We conduct experiments of real-world robot peg insertion tasks with (limited) human demonstrations, alongside videogames from the Procgen benchmark. Additionally, we support our findings with theoretical analysis, which confirms that the generalization error scales with $\\sqrt{I/m}$, where $I$ measures the amount of task information available to the demonstrator, and $m$ is the number of demonstrated tasks. Both theory and practice indicate that cloning blindfolded experts generalizes better with fewer demonstrated tasks. Project page with videos and code: https://sites.google.com/view/blindfoldedexperts/home",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "129",
        "title": "Beyond Neural Incompatibility: Easing Cross-Scale Knowledge Transfer in Large Language Models through Latent Semantic Alignment",
        "author": [
            "Jian Gu",
            "Aldeida Aleti",
            "Chunyang Chen",
            "Hongyu Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24208",
        "abstract": "Large Language Models (LLMs) encode vast amounts of knowledge in their massive parameters, which is accessible to locate, trace, and analyze. Despite advances in neural interpretability, it is still not clear how to transfer knowledge in a fine-grained manner, namely parametric knowledge transfer (PKT). A key problem is enabling effective and efficient knowledge transfer across LLMs of different scales, which is essential for achieving greater flexibility and broader applicability in transferring knowledge between LLMs. Due to neural incompatibility, referring to the architectural and parametric differences between LLMs of varying scales, existing methods that directly reuse layer parameters are severely limited. In this paper, we identify the semantic alignment in latent space as the fundamental prerequisite for LLM cross-scale knowledge transfer. Instead of directly using the layer parameters, our approach takes activations as the medium of layer-wise knowledge transfer. Leveraging the semantics in latent space, our approach is simple and outperforms prior work, better aligning model behaviors across varying scales. Evaluations on four benchmarks demonstrate the efficacy of our method. Further analysis reveals the key factors easing cross-scale knowledge transfer and provides insights into the nature of latent semantic alignment.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "130",
        "title": "MC-SJD : Maximal Coupling Speculative Jacobi Decoding for Autoregressive Visual Generation Acceleration",
        "author": [
            "Junhyuk So",
            "Hyunho Kook",
            "Chaeyeon Jang",
            "Eunhyeok Park"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24211",
        "abstract": "While autoregressive (AR) modeling has recently emerged as a new paradigm in visual generation, its practical adoption is severely constrained by the slow inference speed of per-token generation, which often requires thousands of steps to produce a single sample. To address this challenge, we propose MC-SJD, a training-free, lossless parallel decoding framework designed to accelerate AR visual generation by extending the recently introduced Speculative Jacobi Decoding (SJD). Although SJD shows strong potential for accelerating AR generation, we demonstrate that token instability across iterations significantly reduces the acceptance rate, a limitation that primarily arises from the independent sampling process used during draft token generation. To overcome this, we introduce MC-SJD, an information-theoretic approach based on coupling, which substantially accelerates standard SJD by maximizing the probability of sampling identical draft tokens across consecutive iterations, all while preserving its lossless property. Remarkably, this method requires only a single-line modification to the existing algorithm, yet achieves substantial performance gains, delivering up to a ~4.2x acceleration in image generation and ~13.3x acceleration in video generation compared to standard AR decoding, without any degradation in output quality.",
        "tags": [
            "Video Generation"
        ]
    },
    {
        "id": "131",
        "title": "Beyond Inference Intervention: Identity-Decoupled Diffusion for Face Anonymization",
        "author": [
            "Haoxin Yang",
            "Yihong Lin",
            "Jingdan Kang",
            "Xuemiao Xu",
            "Yue Li",
            "Cheng Xu",
            "Shengfeng He"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24213",
        "abstract": "Face anonymization aims to conceal identity information while preserving non-identity attributes. Mainstream diffusion models rely on inference-time interventions such as negative guidance or energy-based optimization, which are applied post-training to suppress identity features. These interventions often introduce distribution shifts and entangle identity with non-identity attributes, degrading visual fidelity and data utility. To address this, we propose \\textbf{ID\\textsuperscript{2}Face}, a training-centric anonymization framework that removes the need for inference-time optimization. The rationale of our method is to learn a structured latent space where identity and non-identity information are explicitly disentangled, enabling direct and controllable anonymization at inference. To this end, we design a conditional diffusion model with an identity-masked learning scheme. An Identity-Decoupled Latent Recomposer uses an Identity Variational Autoencoder to model identity features, while non-identity attributes are extracted from same-identity pairs and aligned through bidirectional latent alignment. An Identity-Guided Latent Harmonizer then fuses these representations via soft-gating conditioned on noisy feature prediction. The model is trained with a recomposition-based reconstruction loss to enforce disentanglement. At inference, anonymization is achieved by sampling a random identity vector from the learned identity space. To further suppress identity leakage, we introduce an Orthogonal Identity Mapping strategy that enforces orthogonality between sampled and source identity vectors. Experiments demonstrate that ID\\textsuperscript{2}Face outperforms existing methods in visual quality, identity suppression, and utility preservation.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "132",
        "title": "SCOPE: Saliency-Coverage Oriented Token Pruning for Efficient Multimodel LLMs",
        "author": [
            "Jinhong Deng",
            "Wen Li",
            "Joey Tianyi Zhou",
            "Yang He"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24214",
        "abstract": "Multimodal Large Language Models (MLLMs) typically process a large number of visual tokens, leading to considerable computational overhead, even though many of these tokens are redundant. Existing visual token pruning methods primarily focus on selecting the most salient tokens based on attention scores, resulting in the semantic incompleteness of the selected tokens. In this paper, we propose a novel visual token pruning strategy, called \\textbf{S}aliency-\\textbf{C}overage \\textbf{O}riented token \\textbf{P}runing for \\textbf{E}fficient MLLMs (SCOPE), to jointly model both the saliency and coverage of the selected visual tokens to better preserve semantic completeness. Specifically, we introduce a set-coverage for a given set of selected tokens, computed based on the token relationships. We then define a token-coverage gain for each unselected token, quantifying how much additional coverage would be obtained by including it. By integrating the saliency score into the token-coverage gain, we propose our SCOPE score and iteratively select the token with the highest SCOPE score. We conduct extensive experiments on multiple vision-language understanding benchmarks using the LLaVA-1.5 and LLaVA-Next models. Experimental results demonstrate that our method consistently outperforms prior approaches. Our code is available at \\href{https://github.com/kinredon/SCOPE}{https://github.com/kinredon/SCOPE}.",
        "tags": [
            "LLM",
            "LLaVA"
        ]
    },
    {
        "id": "133",
        "title": "HACK: Hallucinations Along Certainty and Knowledge Axes",
        "author": [
            "Adi Simhi",
            "Jonathan Herzig",
            "Itay Itzhak",
            "Dana Arad",
            "Zorik Gekhman",
            "Roi Reichart",
            "Fazl Barez",
            "Gabriel Stanovsky",
            "Idan Szpektor",
            "Yonatan Belinkov"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24222",
        "abstract": "Hallucinations in LLMs present a critical barrier to their reliable usage. Existing research usually categorizes hallucination by their external properties rather than by the LLMs' underlying internal properties. This external focus overlooks that hallucinations may require tailored mitigation strategies based on their underlying mechanism. We propose a framework for categorizing hallucinations along two axes: knowledge and certainty. Since parametric knowledge and certainty may vary across models, our categorization method involves a model-specific dataset construction process that differentiates between those types of hallucinations. Along the knowledge axis, we distinguish between hallucinations caused by a lack of knowledge and those occurring despite the model having the knowledge of the correct response. To validate our framework along the knowledge axis, we apply steering mitigation, which relies on the existence of parametric knowledge to manipulate model activations. This addresses the lack of existing methods to validate knowledge categorization by showing a significant difference between the two hallucination types. We further analyze the distinct knowledge and hallucination patterns between models, showing that different hallucinations do occur despite shared parametric knowledge. Turning to the certainty axis, we identify a particularly concerning subset of hallucinations where models hallucinate with certainty despite having the correct knowledge internally. We introduce a new evaluation metric to measure the effectiveness of mitigation methods on this subset, revealing that while some methods perform well on average, they fail disproportionately on these critical cases. Our findings highlight the importance of considering both knowledge and certainty in hallucination analysis and call for targeted mitigation approaches that consider the hallucination underlying factors.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "134",
        "title": "PaTaRM: Bridging Pairwise and Pointwise Signals via Preference-Aware Task-Adaptive Reward Modeling",
        "author": [
            "Ai Jian",
            "Jingqing Ruan",
            "Xing Ma",
            "Dailin Li",
            "QianLin Zhou",
            "Ke Zeng",
            "Xunliang Cai"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24235",
        "abstract": "Reward models (RMs) are central to reinforcement learning from human feedback (RLHF), providing the critical supervision signals that align large language models (LLMs) with human preferences. While generative reward models (GRMs) offer greater interpretability than traditional scalar RMs, current training paradigms remain limited. Pair-wise methods rely on binary good-versus-bad labels, which cause mismatches for point-wise inference and necessitate complex pairing strategies for effective application in RLHF. On the other hand, point-wise methods require more elaborate absolute labeling with rubric-driven criteria, resulting in poor adaptability and high annotation costs. In this work, we propose the Preference-Aware Task-Adaptive Reward Model (PaTaRM), a unified framework that integrates a preference-aware reward (PAR) mechanism with dynamic rubric adaptation. PaTaRM leverages relative preference information from pairwise data to construct robust point-wise training signals, eliminating the need for explicit point-wise labels. Simultaneously, it employs a task-adaptive rubric system that flexibly generates evaluation criteria for both global task consistency and instance-specific fine-grained reasoning. This design enables efficient, generalizable, and interpretable reward modeling for RLHF. Extensive experiments show that PaTaRM achieves an average relative improvement of 4.7% on RewardBench and RMBench across Qwen3-8B and Qwen3-14B models. Furthermore, PaTaRM boosts downstream RLHF performance, with an average improvement of 13.6% across IFEval and InFoBench benchmarks, confirming its effectiveness and robustness. Our code is available at https://github.com/JaneEyre0530/PaTaRM.",
        "tags": [
            "LLM",
            "RL",
            "RLHF"
        ]
    },
    {
        "id": "135",
        "title": "Temporal Knowledge Graph Hyperedge Forecasting: Exploring Entity-to-Category Link Prediction",
        "author": [
            "Edward Markai",
            "Sina Molavipour"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24240",
        "abstract": "Temporal Knowledge Graphs have emerged as a powerful way of not only modeling static relationships between entities but also the dynamics of how relations evolve over time. As these informational structures can be used to store information from a real-world setting, such as a news flow, predicting future graph components to a certain extent equates predicting real-world events. Most of the research in this field focuses on embedding-based methods, often leveraging convolutional neural net architectures. These solutions act as black boxes, limiting insight. In this paper, we explore an extension to an established rule-based framework, TLogic, that yields a high accuracy in combination with explainable predictions. This offers transparency and allows the end-user to critically evaluate the rules applied at the end of the prediction stage. The new rule format incorporates entity category as a key component with the purpose of limiting rule application only to relevant entities. When categories are unknown for building the graph, we propose a data-driven method to generate them with an LLM-based approach. Additionally, we investigate the choice of aggregation method for scores of retrieved entities when performing category prediction.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "136",
        "title": "Evaluating LLMs on Generating Age-Appropriate Child-Like Conversations",
        "author": [
            "Syed Zohaib Hassan",
            "PÃ¥l Halvorsen",
            "Miriam S. Johnson",
            "Pierre Lison"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24250",
        "abstract": "Large Language Models (LLMs), predominantly trained on adult conversational data, face significant challenges when generating authentic, child-like dialogue for specialized applications. We present a comparative study evaluating five different LLMs (GPT-4, RUTER-LLAMA-2-13b, GPTSW, NorMistral-7b, and NorBloom-7b) to generate age-appropriate Norwegian conversations for children aged 5 and 9 years. Through a blind evaluation by eleven education professionals using both real child interview data and LLM-generated text samples, we assessed authenticity and developmental appropriateness. Our results show that evaluators achieved strong inter-rater reliability (ICC=0.75) and demonstrated higher accuracy in age prediction for younger children (5-year-olds) compared to older children (9-year-olds). While GPT-4 and NorBloom-7b performed relatively well, most models generated language perceived as more linguistically advanced than the target age groups. These findings highlight critical data-related challenges in developing LLM systems for specialized applications involving children, particularly in low-resource languages where comprehensive age-appropriate lexical resources are scarce.",
        "tags": [
            "GPT",
            "LLM",
            "LLaMA"
        ]
    },
    {
        "id": "137",
        "title": "GRAPHIA: Harnessing Social Graph Data to Enhance LLM-Based Social Simulation",
        "author": [
            "Jiarui Ji",
            "Zehua Zhang",
            "Zhewei Wei",
            "Bin Tong",
            "Guan Wang",
            "Bo Zheng"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24251",
        "abstract": "Large language models (LLMs) have shown promise in simulating human-like social behaviors. Social graphs provide high-quality supervision signals that encode both local interactions and global network structure, yet they remain underutilized for LLM training. To address this gap, we propose Graphia, the first general LLM-based social graph simulation framework that leverages graph data as supervision for LLM post-training via reinforcement learning. With GNN-based structural rewards, Graphia trains specialized agents to predict whom to interact with (destination selection) and how to interact (edge generation), followed by designed graph generation pipelines. We evaluate Graphia under two settings: Transductive Dynamic Graph Generation (TDGG), a micro-level task with our proposed node-wise interaction alignment metrics; and Inductive Dynamic Graph Generation (IDGG), a macro-level task with our proposed metrics for aligning emergent network properties. On three real-world networks, Graphia improves micro-level alignment by 6.1% in the composite destination selection score, 12% in edge classification accuracy, and 27.9% in edge content BERTScore over the strongest baseline. For macro-level alignment, it achieves 41.11% higher structural similarity and 32.98% better replication of social phenomena such as power laws and echo chambers. Graphia also supports counterfactual simulation, generating plausible behavioral shifts under platform incentives. Our results show that social graphs can serve as high-quality supervision signals for LLM post-training, closing the gap between agent behaviors and network dynamics for LLM-based simulation. Code is available at https://github.com/Ji-Cather/Graphia.git.",
        "tags": [
            "LLM",
            "RL"
        ]
    },
    {
        "id": "138",
        "title": "From Memorization to Reasoning in the Spectrum of Loss Curvature",
        "author": [
            "Jack Merullo",
            "Srihita Vatsavaya",
            "Lucius Bushnaq",
            "Owen Lewis"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24256",
        "abstract": "We characterize how memorization is represented in transformer models and show that it can be disentangled in the weights of both language models (LMs) and vision transformers (ViTs) using a decomposition based on the loss landscape curvature. This insight is based on prior theoretical and empirical work showing that the curvature for memorized training points is much sharper than non memorized, meaning ordering weight components from high to low curvature can reveal a distinction without explicit labels. This motivates a weight editing procedure that suppresses far more recitation of untargeted memorized data more effectively than a recent unlearning method (BalancedSubnet), while maintaining lower perplexity. Since the basis of curvature has a natural interpretation for shared structure in model weights, we analyze the editing procedure extensively on its effect on downstream tasks in LMs, and find that fact retrieval and arithmetic are specifically and consistently negatively affected, even though open book fact retrieval and general logical reasoning is conserved. We posit these tasks rely heavily on specialized directions in weight space rather than general purpose mechanisms, regardless of whether those individual datapoints are memorized. We support this by showing a correspondence between task data's activation strength with low curvature components that we edit out, and the drop in task performance after the edit. Our work enhances the understanding of memorization in neural networks with practical applications towards removing it, and provides evidence for idiosyncratic, narrowly-used structures involved in solving tasks like math and fact retrieval.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "139",
        "title": "Manipulate as Human: Learning Task-oriented Manipulation Skills by Adversarial Motion Priors",
        "author": [
            "Ziqi Ma",
            "Changda Tian",
            "Yue Gao"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24257",
        "abstract": "In recent years, there has been growing interest in developing robots and autonomous systems that can interact with human in a more natural and intuitive way. One of the key challenges in achieving this goal is to enable these systems to manipulate objects and tools in a manner that is similar to that of humans. In this paper, we propose a novel approach for learning human-style manipulation skills by using adversarial motion priors, which we name HMAMP. The approach leverages adversarial networks to model the complex dynamics of tool and object manipulation, as well as the aim of the manipulation task. The discriminator is trained using a combination of real-world data and simulation data executed by the agent, which is designed to train a policy that generates realistic motion trajectories that match the statistical properties of human motion. We evaluated HMAMP on one challenging manipulation task: hammering, and the results indicate that HMAMP is capable of learning human-style manipulation skills that outperform current baseline methods. Additionally, we demonstrate that HMAMP has potential for real-world applications by performing real robot arm hammering tasks. In general, HMAMP represents a significant step towards developing robots and autonomous systems that can interact with humans in a more natural and intuitive way, by learning to manipulate tools and objects in a manner similar to how humans do.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "140",
        "title": "Can LLMs Translate Human Instructions into a Reinforcement Learning Agent's Internal Emergent Symbolic Representation?",
        "author": [
            "Ziqi Ma",
            "Sao Mai Nguyen",
            "Philippe Xu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24259",
        "abstract": "Emergent symbolic representations are critical for enabling developmental learning agents to plan and generalize across tasks. In this work, we investigate whether large language models (LLMs) can translate human natural language instructions into the internal symbolic representations that emerge during hierarchical reinforcement learning. We apply a structured evaluation framework to measure the translation performance of commonly seen LLMs -- GPT, Claude, Deepseek and Grok -- across different internal symbolic partitions generated by a hierarchical reinforcement learning algorithm in the Ant Maze and Ant Fall environments. Our findings reveal that although LLMs demonstrate some ability to translate natural language into a symbolic representation of the environment dynamics, their performance is highly sensitive to partition granularity and task complexity. The results expose limitations in current LLMs capacity for representation alignment, highlighting the need for further research on robust alignment between language and internal agent representations.",
        "tags": [
            "DeepSeek",
            "GPT",
            "LLM",
            "RL"
        ]
    },
    {
        "id": "141",
        "title": "DeshadowMamba: Deshadowing as 1D Sequential Similarity",
        "author": [
            "Zhaotong Yang",
            "Yi Chen",
            "Yanying Li",
            "Shengfeng He",
            "Yangyang Xu",
            "Junyu Dong",
            "Jian Yang",
            "Yong Du"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24260",
        "abstract": "Recent deep models for image shadow removal often rely on attention-based architectures to capture long-range dependencies. However, their fixed attention patterns tend to mix illumination cues from irrelevant regions, leading to distorted structures and inconsistent colors. In this work, we revisit shadow removal from a sequence modeling perspective and explore the use of Mamba, a selective state space model that propagates global context through directional state transitions. These transitions yield an efficient global receptive field while preserving positional continuity. Despite its potential, directly applying Mamba to image data is suboptimal, since it lacks awareness of shadow-non-shadow semantics and remains susceptible to color interference from nearby regions. To address these limitations, we propose CrossGate, a directional modulation mechanism that injects shadow-aware similarity into Mamba's input gate, allowing selective integration of relevant context along transition axes. To further ensure appearance fidelity, we introduce ColorShift regularization, a contrastive learning objective driven by global color statistics. By synthesizing structured informative negatives, it guides the model to suppress color contamination and achieve robust color restoration. Together, these components adapt sequence modeling to the structural integrity and chromatic consistency required for shadow removal. Extensive experiments on public benchmarks demonstrate that DeshadowMamba achieves state-of-the-art visual quality and strong quantitative performance.",
        "tags": [
            "Mamba"
        ]
    },
    {
        "id": "142",
        "title": "Survey and Tutorial of Reinforcement Learning Methods in Process Systems Engineering",
        "author": [
            "Maximilian Bloor",
            "Max Mowbray",
            "Ehecatl Antonio Del Rio Chanona",
            "Calvin Tsay"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24272",
        "abstract": "Sequential decision making under uncertainty is central to many Process Systems Engineering (PSE) challenges, where traditional methods often face limitations related to controlling and optimizing complex and stochastic systems. Reinforcement Learning (RL) offers a data-driven approach to derive control policies for such challenges. This paper presents a survey and tutorial on RL methods, tailored for the PSE community. We deliver a tutorial on RL, covering fundamental concepts and key algorithmic families including value-based, policy-based and actor-critic methods. Subsequently, we survey existing applications of these RL techniques across various PSE domains, such as in fed-batch and continuous process control, process optimization, and supply chains. We conclude with PSE focused discussion of specialized techniques and emerging directions. By synthesizing the current state of RL algorithm development and implications for PSE this work identifies successes, challenges, trends, and outlines avenues for future research at the interface of these fields.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "143",
        "title": "SALS: Sparse Attention in Latent Space for KV cache Compression",
        "author": [
            "Junlin Mu",
            "Hantao Huang",
            "Jihang Zhang",
            "Minghui Yu",
            "Tao Wang",
            "Yidong Li"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24273",
        "abstract": "Large Language Models capable of handling extended contexts are in high demand, yet their inference remains challenging due to substantial Key-Value cache size and high memory bandwidth requirements. Previous research has demonstrated that KV cache exhibits low-rank characteristics within the hidden dimension, suggesting the potential for effective compression. However, due to the widely adopted Rotary Position Embedding mechanism in modern LLMs, naive low-rank compression suffers severe accuracy degradation or creates a new speed bottleneck, as the low-rank cache must first be reconstructed in order to apply RoPE. In this paper, we introduce two key insights: first, the application of RoPE to the key vectors increases their variance, which in turn results in a higher rank; second, after the key vectors are transformed into the latent space, they largely maintain their representation across most layers. Based on these insights, we propose the Sparse Attention in Latent Space framework. SALS projects the KV cache into a compact latent space via low-rank projection, and performs sparse token selection using RoPE-free query-key interactions in this space. By reconstructing only a small subset of important tokens, it avoids the overhead of full KV cache reconstruction. We comprehensively evaluate SALS on various tasks using two large-scale models: LLaMA2-7b-chat and Mistral-7b, and additionally verify its scalability on the RULER-128k benchmark with LLaMA3.1-8B-Instruct. Experimental results demonstrate that SALS achieves SOTA performance by maintaining competitive accuracy. Under different settings, SALS achieves 6.4-fold KV cache compression and 5.7-fold speed-up in the attention operator compared to FlashAttention2 on the 4K sequence. For the end-to-end throughput performance, we achieves 1.4-fold and 4.5-fold improvement compared to GPT-fast on 4k and 32K sequences, respectively.",
        "tags": [
            "GPT",
            "LLM",
            "RoPE"
        ]
    },
    {
        "id": "144",
        "title": "Training-free Source Attribution of AI-generated Images via Resynthesis",
        "author": [
            "Pietro Bongini",
            "Valentina Molinari",
            "Andrea Costanzo",
            "Benedetta Tondi",
            "Mauro Barni"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24278",
        "abstract": "Synthetic image source attribution is a challenging task, especially in data scarcity conditions requiring few-shot or zero-shot classification capabilities. We present a new training-free one-shot attribution method based on image resynthesis. A prompt describing the image under analysis is generated, then it is used to resynthesize the image with all the candidate sources. The image is attributed to the model which produced the resynthesis closest to the original image in a proper feature space. We also introduce a new dataset for synthetic image attribution consisting of face images from commercial and open-source text-to-image generators. The dataset provides a challenging attribution framework, useful for developing new attribution models and testing their capabilities on different generative architectures. The dataset structure allows to test approaches based on resynthesis and to compare them to few-shot methods. Results from state-of-the-art few-shot approaches and other baselines show that the proposed resynthesis method outperforms existing techniques when only a few samples are available for training or fine-tuning. The experiments also demonstrate that the new dataset is a challenging one and represents a valuable benchmark for developing and evaluating future few-shot and zero-shot methods.",
        "tags": [
            "Text-to-Image"
        ]
    },
    {
        "id": "145",
        "title": "TsetlinKWS: A 65nm 16.58uW, 0.63mm2 State-Driven Convolutional Tsetlin Machine-Based Accelerator For Keyword Spotting",
        "author": [
            "Baizhou Lin",
            "Yuetong Fang",
            "Renjing Xu",
            "Rishad Shafik",
            "Jagmohan Chauhan"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24282",
        "abstract": "The Tsetlin Machine (TM) has recently attracted attention as a low-power alternative to neural networks due to its simple and interpretable inference mechanisms. However, its performance on speech-related tasks remains limited. This paper proposes TsetlinKWS, the first algorithm-hardware co-design framework for the Convolutional Tsetlin Machine (CTM) on the 12-keyword spotting task. Firstly, we introduce a novel Mel-Frequency Spectral Coefficient and Spectral Flux (MFSC-SF) feature extraction scheme together with spectral convolution, enabling the CTM to reach its first-ever competitive accuracy of 87.35% on the 12-keyword spotting task. Secondly, we develop an Optimized Grouped Block-Compressed Sparse Row (OG-BCSR) algorithm that achieves a remarkable 9.84$\\times$ reduction in model size, significantly improving the storage efficiency on CTMs. Finally, we propose a state-driven architecture tailored for the CTM, which simultaneously exploits data reuse and sparsity to achieve high energy efficiency. The full system is evaluated in 65 nm process technology, consuming 16.58 $\\mu$W at 0.7 V with a compact 0.63 mm$^2$ core area. TsetlinKWS requires only 907k logic operations per inference, representing a 10$\\times$ reduction compared to the state-of-the-art KWS accelerators, positioning the CTM as a highly-efficient candidate for ultra-low-power speech applications.",
        "tags": [
            "FLUX"
        ]
    },
    {
        "id": "146",
        "title": "MCP-Flow: Facilitating LLM Agents to Master Real-World, Diverse and Scaling MCP Tools",
        "author": [
            "Wenhao Wang",
            "Peizhi Niu",
            "Zhao Xu",
            "Zhaoyu Chen",
            "Jian Du",
            "Yaxin Du",
            "Xianghe Pang",
            "Keduan Huang",
            "Yanfeng Wang",
            "Qiang Yan",
            "Siheng Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24284",
        "abstract": "Large Language Models (LLMs) increasingly rely on external tools to perform complex, realistic tasks, yet their ability to utilize the rapidly expanding Model Contextual Protocol (MCP) ecosystem remains limited. Existing MCP research covers few servers, depends on costly manual curation, and lacks training support, hindering progress toward real-world deployment. To overcome these limitations, we introduce MCP-Flow, an automated web-agent-driven pipeline for large-scale server discovery, data synthesis, and model training. MCP-Flow collects and filters data from 1166 servers and 11536 tools, producing 68733 high-quality instruction-function call pairs and 6439 trajectories, far exceeding prior work in scale and diversity. Extensive experiments demonstrate MCP-Flow's effectiveness in driving superior MCP tool selection, function-call generation, and enhanced agentic task performance. MCP-Flow thus provides a scalable foundation for advancing LLM agents' proficiency in real-world MCP environments. MCP-Flow is publicly available at \\href{https://github.com/wwh0411/MCP-Flow}{https://github.com/wwh0411/MCP-Flow}.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "147",
        "title": "ViPER: Empowering the Self-Evolution of Visual Perception Abilities in Vision-Language Model",
        "author": [
            "Juntian Zhang",
            "Song Jin",
            "Chuanqi Cheng",
            "Yuhan Liu",
            "Yankai Lin",
            "Xun Zhang",
            "Yufei Zhang",
            "Fei Jiang",
            "Guojun Yin",
            "Wei Lin",
            "Rui Yan"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24285",
        "abstract": "The limited capacity for fine-grained visual perception presents a critical bottleneck for Vision-Language Models (VLMs) in real-world applications. Addressing this is challenging due to the scarcity of high-quality data and the limitations of existing methods: supervised fine-tuning (SFT) often compromises general capabilities, while reinforcement fine-tuning (RFT) prioritizes textual reasoning over visual perception. To bridge this gap, we propose a novel two-stage task that structures visual perception learning as a coarse-to-fine progressive process. Based on this task formulation, we develop ViPER, a self-bootstrapping framework specifically designed to enable iterative evolution through self-critiquing and self-prediction. By synergistically integrating image-level and instance-level reconstruction with a two-stage reinforcement learning strategy, ViPER establishes a closed-loop training paradigm, where internally synthesized data directly fuel the enhancement of perceptual ability. Applied to the Qwen2.5-VL family, ViPER produces the Qwen-Viper series. With an average gain of 1.7% on seven comprehensive benchmarks spanning various tasks and up to 6.0% on fine-grained perception, Qwen-Viper consistently demonstrates superior performance across different vision-language scenarios while maintaining generalizability. Beyond enabling self-improvement in perceptual capabilities, ViPER provides concrete evidence for the reciprocal relationship between generation and understanding, a breakthrough to developing more autonomous and capable VLMs.",
        "tags": [
            "Qwen",
            "RL",
            "VLM"
        ]
    },
    {
        "id": "148",
        "title": "Verifying Large Language Models' Reasoning Paths via Correlation Matrix Rank",
        "author": [
            "Jiayu Liu",
            "Wei Dai",
            "Zhenya Huang",
            "Ning Miao",
            "Enhong Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24299",
        "abstract": "Despite the strong reasoning ability of large language models~(LLMs), they are prone to errors and hallucinations. As a result, how to check their outputs effectively and efficiently has become a critical problem in their applications. Existing checking methods heavily rely on external resources, such as trained verifiers (e.g., process/outcome reward models) or elaborate prompts, which lead to high computational overhead and are only applicable to specific domains. In this paper, we investigate whether the internal behaviors of LLMs have already implied the credibility of their reasoning paths. Specifically, we find that the rank of the correlation matrix between the input problem and the output reasoning path is a robust indicator of reasoning correctness. Different from other correctness indicators for LLMs, the calculation of the correlation matrix only relies on the LLM itself, which avoids the hassle of training a separate model or designing complicated prompts. Based on it, we design a simple, plug-and-play Self-Indicator method to reweight candidate reasoning paths, which achieves significant performance improvements than other voting and verification methods with very few computational overhead. Our experiments across multiple LLMs of varying scales and model families have further shown the effectiveness of Self-Indicator. It achieves over 75% accuracy in distinguishing correct reasoning paths from incorrect ones, and, in turn, improves the accuracies on three reasoning benchmarks by more than 8%.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "149",
        "title": "Lookahead Tree-Based Rollouts for Enhanced Trajectory-Level Exploration in Reinforcement Learning with Verifiable Rewards",
        "author": [
            "Shangyu Xing",
            "Siyuan Wang",
            "Chenyuan Yang",
            "Xinyu Dai",
            "Xiang Ren"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24302",
        "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR), particularly with algorithms like Group Relative Policy Optimization (GRPO), has proven highly effective in enhancing the reasoning capabilities of large language models. However, a critical bottleneck in current pipelines lies in the limited diversity of sampled trajectories during group rollouts. Homogeneous trajectories and their associated rewards would diminish the return signals for policy updates, thereby hindering effective policy learning. This lack of diversity stems primarily from token-level stochastic sampling, where local variations are likely to collapse into near-identical reasoning paths. To address this limitation, we propose Lookahead Tree-Based Rollouts (LATR), a novel rollout strategy designed to explicitly promotes trajectory-level diversity by enforcing branching into different candidate tokens likely to yield distinct continuations. Specifically, LATR iteratively operates in three stages: (1) branching at high-uncertainty generation steps, (2) performing lookahead simulation for each new branch, and (3) pruning branches that exhibits prolonged similarity during simulation. Compared with stochastic Sampling, LATR accelerates policy learning by 131% on average and improves final pass@1 performance by 4.2% on both GRPO and Dynamic sAmpling Policy Optimization (DAPO) algorithms across different reasoning tasks. Our code and data are publicly available at https://github.com/starreeze/latr.",
        "tags": [
            "GRPO",
            "LLM",
            "RL"
        ]
    },
    {
        "id": "150",
        "title": "Retrieval and Argumentation Enhanced Multi-Agent LLMs for Judgmental Forecasting",
        "author": [
            "Deniz Gorur",
            "Antoni Rago",
            "Francesca Toni"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24303",
        "abstract": "Judgmental forecasting is the task of making predictions about future events based on human judgment. This task can be seen as a form of claim verification, where the claim corresponds to a future event and the task is to assess the plausibility of that event. In this paper, we propose a novel multi-agent framework for claim verification, whereby different agents may disagree on claim veracity and bring specific evidence for and against the claims, represented as quantitative bipolar argumentation frameworks (QBAFs). We then instantiate the framework for supporting claim verification, with a variety of agents realised with Large Language Models (LLMs): (1) ArgLLM agents, an existing approach for claim verification that generates and evaluates QBAFs; (2) RbAM agents, whereby LLM-empowered Relation-based Argument Mining (RbAM) from external sources is used to generate QBAFs; (3) RAG-ArgLLM agents, extending ArgLLM agents with a form of Retrieval-Augmented Generation (RAG) of arguments from external sources. Finally, we conduct experiments with two standard judgmental forecasting datasets, with instances of our framework with two or three agents, empowered by six different base LLMs. We observe that combining evidence from agents can improve forecasting accuracy, especially in the case of three agents, while providing an explainable combination of evidence for claim verification.",
        "tags": [
            "LLM",
            "RAG"
        ]
    },
    {
        "id": "151",
        "title": "Cybersecurity AI Benchmark (CAIBench): A Meta-Benchmark for Evaluating Cybersecurity AI Agents",
        "author": [
            "MarÃ­a Sanz-GÃ³mez",
            "VÃ­ctor Mayoral-Vilches",
            "Francesco Balassone",
            "Luis Javier Navarrete-Lozano",
            "CristÃ³bal R. J. Veas Chavez",
            "Maite del Mundo de Torres"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24317",
        "abstract": "Cybersecurity spans multiple interconnected domains, complicating the development of meaningful, labor-relevant benchmarks. Existing benchmarks assess isolated skills rather than integrated performance. We find that pre-trained knowledge of cybersecurity in LLMs does not imply attack and defense abilities, revealing a gap between knowledge and capability. To address this limitation, we present the Cybersecurity AI Benchmark (CAIBench), a modular meta-benchmark framework that allows evaluating LLM models and agents across offensive and defensive cybersecurity domains, taking a step towards meaningfully measuring their labor-relevance. CAIBench integrates five evaluation categories, covering over 10,000 instances: Jeopardy-style CTFs, Attack and Defense CTFs, Cyber Range exercises, knowledge benchmarks, and privacy assessments. Key novel contributions include systematic simultaneous offensive-defensive evaluation, robotics-focused cybersecurity challenges (RCTF2), and privacy-preserving performance assessment (CyberPII-Bench). Evaluation of state-of-the-art AI models reveals saturation on security knowledge metrics (~70\\% success) but substantial degradation in multi-step adversarial (A\\&D) scenarios (20-40\\% success), or worse in robotic targets (22\\% success). The combination of framework scaffolding and LLM model choice significantly impacts performance; we find that proper matches improve up to 2.6$\\times$ variance in Attack and Defense CTFs. These results demonstrate a pronounced gap between conceptual knowledge and adaptive capability, emphasizing the need for a meta-benchmark.",
        "tags": [
            "LLM",
            "Robotics"
        ]
    },
    {
        "id": "152",
        "title": "Transformers can do Bayesian Clustering",
        "author": [
            "Prajit Bhaskaran",
            "Tom Viering"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24318",
        "abstract": "Bayesian clustering accounts for uncertainty but is computationally demanding at scale. Furthermore, real-world datasets often contain missing values, and simple imputation ignores the associated uncertainty, resulting in suboptimal results. We present Cluster-PFN, a Transformer-based model that extends Prior-Data Fitted Networks (PFNs) to unsupervised Bayesian clustering. Trained entirely on synthetic datasets generated from a finite Gaussian Mixture Model (GMM) prior, Cluster-PFN learns to estimate the posterior distribution over both the number of clusters and the cluster assignments. Our method estimates the number of clusters more accurately than handcrafted model selection procedures such as AIC, BIC and Variational Inference (VI), and achieves clustering quality competitive with VI while being orders of magnitude faster. Cluster-PFN can be trained on complex priors that include missing data, outperforming imputation-based baselines on real-world genomic datasets, at high missingness. These results show that the Cluster-PFN can provide scalable and flexible Bayesian clustering.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "153",
        "title": "Critique-RL: Training Language Models for Critiquing through Two-Stage Reinforcement Learning",
        "author": [
            "Zhiheng Xi",
            "Jixuan Huang",
            "Xin Guo",
            "Boyang Hong",
            "Dingwen Yang",
            "Xiaoran Fan",
            "Shuo Li",
            "Zehui Chen",
            "Junjie Ye",
            "Siyu Yuan",
            "Zhengyin Du",
            "Xuesong Yao",
            "Yufei Xu",
            "Jiecao Chen",
            "Rui Zheng",
            "Tao Gui",
            "Qi Zhang",
            "Xuanjing Huang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24320",
        "abstract": "Training critiquing language models to assess and provide feedback on model outputs is a promising way to improve LLMs for complex reasoning tasks. However, existing approaches typically rely on stronger supervisors for annotating critique data. To address this, we propose Critique-RL, an online RL approach for developing critiquing language models without stronger supervision. Our approach operates on a two-player paradigm: the actor generates a response, the critic provides feedback, and the actor refines the response accordingly. We first reveal that relying solely on indirect reward signals from the actor's outputs for RL optimization often leads to unsatisfactory critics: while their helpfulness (i.e., providing constructive feedback) improves, the discriminability (i.e., determining whether a response is high-quality or not) remains poor, resulting in marginal performance gains. To overcome this, Critique-RL adopts a two-stage optimization strategy. In stage I, it reinforces the discriminability of the critic with direct rule-based reward signals; in stage II, it introduces indirect rewards based on actor refinement to improve the critic's helpfulness, while maintaining its discriminability via appropriate regularization. Extensive experiments across various tasks and models show that Critique-RL delivers substantial performance improvements. For example, it achieves a 9.02% gain on in-domain tasks and a 5.70% gain on out-of-domain tasks for Qwen2.5-7B, highlighting its potential.",
        "tags": [
            "LLM",
            "RL"
        ]
    },
    {
        "id": "154",
        "title": "Beyond MCQ: An Open-Ended Arabic Cultural QA Benchmark with Dialect Variants",
        "author": [
            "Hunzalah Hassan Bhatti",
            "Firoj Alam"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24328",
        "abstract": "Large Language Models (LLMs) are increasingly used to answer everyday questions, yet their performance on culturally grounded and dialectal content remains uneven across languages. We propose a comprehensive method that (i) translates Modern Standard Arabic (MSA) multiple-choice questions (MCQs) into English and several Arabic dialects, (ii) converts them into open-ended questions (OEQs), (iii) benchmarks a range of zero-shot and fine-tuned LLMs under both MCQ and OEQ settings, and (iv) generates chain-of-thought (CoT) rationales to fine-tune models for step-by-step reasoning. Using this method, we extend an existing dataset in which QAs are parallelly aligned across multiple language varieties, making it, to our knowledge, the first of its kind. We conduct extensive experiments with both open and closed models. Our findings show that (i) models underperform on Arabic dialects, revealing persistent gaps in culturally grounded and dialect-specific knowledge; (ii) Arabic-centric models perform well on MCQs but struggle with OEQs; and (iii) CoT improves judged correctness while yielding mixed n-gram-based metrics. The developed dataset will be publicly released to support further research on culturally and linguistically inclusive evaluation.",
        "tags": [
            "CoT",
            "LLM"
        ]
    },
    {
        "id": "155",
        "title": "What do vision-language models see in the context? Investigating multimodal in-context learning",
        "author": [
            "Gabriel O. dos Santos",
            "Esther Colombini",
            "Sandra Avila"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24331",
        "abstract": "In-context learning (ICL) enables Large Language Models (LLMs) to learn tasks from demonstration examples without parameter updates. Although it has been extensively studied in LLMs, its effectiveness in Vision-Language Models (VLMs) remains underexplored. In this work, we present a systematic study of ICL in VLMs, evaluating seven models spanning four architectures on three image captioning benchmarks. We analyze how prompt design, architectural choices, and training strategies influence multimodal ICL. To our knowledge, we are the first to analyze how attention patterns in VLMs vary with an increasing number of in-context demonstrations. Our results reveal that training on imag-text interleaved data enhances ICL performance but does not imply effective integration of visual and textual information from demonstration examples. In contrast, instruction tuning improves instruction-following but can reduce reliance on in-context demonstrations, suggesting a trade-off between instruction alignment and in-context adaptation. Attention analyses further show that current VLMs primarily focus on textual cues and fail to leverage visual information, suggesting a limited capacity for multimodal integration. These findings highlight key limitations in the ICL abilities of current VLMs and provide insights for enhancing their ability to learn from multimodal in-context examples.",
        "tags": [
            "LLM",
            "VLM"
        ]
    },
    {
        "id": "156",
        "title": "NVSim: Novel View Synthesis Simulator for Large Scale Indoor Navigation",
        "author": [
            "Mingyu Jeong",
            "Eunsung Kim",
            "Sehun Park",
            "Andrew Jaeyong Choi"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24335",
        "abstract": "We present NVSim, a framework that automatically constructs large-scale, navigable indoor simulators from only common image sequences, overcoming the cost and scalability limitations of traditional 3D scanning. Our approach adapts 3D Gaussian Splatting to address visual artifacts on sparsely observed floors a common issue in robotic traversal data. We introduce Floor-Aware Gaussian Splatting to ensure a clean, navigable ground plane, and a novel mesh-free traversability checking algorithm that constructs a topological graph by directly analyzing rendered views. We demonstrate our system's ability to generate valid, large-scale navigation graphs from real-world data. A video demonstration is avilable at https://youtu.be/tTiIQt6nXC8",
        "tags": [
            "3D",
            "Gaussian Splatting"
        ]
    },
    {
        "id": "157",
        "title": "Generative Large Language Models (gLLMs) in Content Analysis: A Practical Guide for Communication Research",
        "author": [
            "Daria Kravets-Meinke",
            "Hannah Schmid-Petri",
            "Sonja Niemann",
            "Ute Schmid"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24337",
        "abstract": "Generative Large Language Models (gLLMs), such as ChatGPT, are increasingly being used in communication research for content analysis. Studies show that gLLMs can outperform both crowd workers and trained coders, such as research assistants, on various coding tasks relevant to communication science, often at a fraction of the time and cost. Additionally, gLLMs can decode implicit meanings and contextual information, be instructed using natural language, deployed with only basic programming skills, and require little to no annotated data beyond a validation dataset - constituting a paradigm shift in automated content analysis. Despite their potential, the integration of gLLMs into the methodological toolkit of communication research remains underdeveloped. In gLLM-assisted quantitative content analysis, researchers must address at least seven critical challenges that impact result quality: (1) codebook development, (2) prompt engineering, (3) model selection, (4) parameter tuning, (5) iterative refinement, (6) validation of the model's reliability, and optionally, (7) performance enhancement. This paper synthesizes emerging research on gLLM-assisted quantitative content analysis and proposes a comprehensive best-practice guide to navigate these challenges. Our goal is to make gLLM-based content analysis more accessible to a broader range of communication researchers and ensure adherence to established disciplinary quality standards of validity, reliability, reproducibility, and research ethics.",
        "tags": [
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "158",
        "title": "VDSAgents: A PCS-Guided Multi-Agent System for Veridical Data Science Automation",
        "author": [
            "Yunxuan Jiang",
            "Silan Hu",
            "Xiaoning Wang",
            "Yuanyuan Zhang",
            "Xiangyu Chang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24339",
        "abstract": "Large language models (LLMs) become increasingly integrated into data science workflows for automated system design. However, these LLM-driven data science systems rely solely on the internal reasoning of LLMs, lacking guidance from scientific and theoretical principles. This limits their trustworthiness and robustness, especially when dealing with noisy and complex real-world datasets. This paper provides VDSAgents, a multi-agent system grounded in the Predictability-Computability-Stability (PCS) principles proposed in the Veridical Data Science (VDS) framework. Guided by PCS principles, the system implements a modular workflow for data cleaning, feature engineering, modeling, and evaluation. Each phase is handled by an elegant agent, incorporating perturbation analysis, unit testing, and model validation to ensure both functionality and scientific auditability. We evaluate VDSAgents on nine datasets with diverse characteristics, comparing it with state-of-the-art end-to-end data science systems, such as AutoKaggle and DataInterpreter, using DeepSeek-V3 and GPT-4o as backends. VDSAgents consistently outperforms the results of AutoKaggle and DataInterpreter, which validates the feasibility of embedding PCS principles into LLM-driven data science automation.",
        "tags": [
            "DeepSeek",
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "159",
        "title": "A Unified Geometric Space Bridging AI Models and the Human Brain",
        "author": [
            "Silin Chen",
            "Yuzhong Chen",
            "Zifan Wang",
            "Junhao Wang",
            "Zifeng Jia",
            "Keith M Kendrick",
            "Tuo Zhang",
            "Lin Zhao",
            "Dezhong Yao",
            "Tianming Liu",
            "Xi Jiang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24342",
        "abstract": "For decades, neuroscientists and computer scientists have pursued a shared ambition: to understand intelligence and build it. Modern artificial neural networks now rival humans in language, perception, and reasoning, yet it is still largely unknown whether these artificial systems organize information as the brain does. Existing brain-AI alignment studies have shown the striking correspondence between the two systems, but such comparisons remain bound to specific inputs and tasks, offering no common ground for comparing how AI models with different kinds of modalities-vision, language, or multimodal-are intrinsically organized. Here we introduce a groundbreaking concept of Brain-like Space: a unified geometric space in which every AI model can be precisely situated and compared by mapping its intrinsic spatial attention topological organization onto canonical human functional brain networks, regardless of input modality, task, or sensory domain. Our extensive analysis of 151 Transformer-based models spanning state-of-the-art large vision models, large language models, and large multimodal models uncovers a continuous arc-shaped geometry within this space, reflecting a gradual increase of brain-likeness; different models exhibit distinct distribution patterns within this geometry associated with different degrees of brain-likeness, shaped not merely by their modality but by whether the pretraining paradigm emphasizes global semantic abstraction and whether the positional encoding scheme facilitates deep fusion across different modalities. Moreover, the degree of brain-likeness for a model and its downstream task performance are not \"identical twins\". The Brain-like Space provides the first unified framework for situating, quantifying, and comparing intelligence across domains, revealing the deep organizational principles that bridge machines and the brain.",
        "tags": [
            "LLM",
            "Transformer"
        ]
    },
    {
        "id": "160",
        "title": "LongWeave: A Long-Form Generation Benchmark Bridging Real-World Relevance and Verifiability",
        "author": [
            "Zikai Xiao",
            "Fei Huang",
            "Jianhong Tu",
            "Jianhui Wei",
            "Wen Ma",
            "Yuxuan Zhou",
            "Jian Wu",
            "Bowen Yu",
            "Zuozhu Liu",
            "Junyang Lin"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24345",
        "abstract": "Generating long, informative, and factual outputs remains a major challenge for Large Language Models (LLMs). Existing benchmarks for long-form generation typically assess real-world queries with hard-to-verify metrics or use synthetic setups that ease evaluation but overlook real-world intricacies. In this paper, we introduce \\textbf{LongWeave}, which balances real-world and verifiable assessment with Constraint-Verifier Evaluation (CoV-Eval). CoV-Eval constructs tasks by first defining verifiable targets within real-world scenarios, then systematically generating corresponding queries, textual materials, and constraints based on these targets. This ensures that tasks are both realistic and objectively assessable, enabling rigorous assessment of model capabilities in meeting complex real-world constraints. LongWeave supports customizable input/output lengths (up to 64K/8K tokens) across seven distinct tasks. Evaluation on 23 LLMs shows that even state-of-the-art models encounter significant challenges in long-form generation as real-world complexity and output length increase.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "161",
        "title": "Automatically Benchmarking LLM Code Agents through Agent-Driven Annotation and Evaluation",
        "author": [
            "Lingyue Fu",
            "Bolun Zhang",
            "Hao Guan",
            "Yaoming Zhu",
            "Lin Qiu",
            "Weiwen Liu",
            "Xuezhi Cao",
            "Xunliang Cai",
            "Weinan Zhang",
            "Yong Yu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24358",
        "abstract": "Recent advances in code agents have enabled automated software development at the project level, supported by large language models (LLMs) and widely adopted tools. However, existing benchmarks for code agent evaluation face two major limitations: high annotation cost and expertise requirements, and rigid evaluation metrics that rely primarily on unit tests. To address these challenges, we propose an agent-driven benchmark construction pipeline that leverages human supervision to efficiently generate diverse and challenging project-level tasks. Based on this approach, we introduce PRDBench, a novel benchmark comprising 50 real-world Python projects across 20 domains, each with structured Product Requirement Document (PRD) requirements, comprehensive evaluation criteria, and reference implementations. PRDBench features rich data sources, high task complexity, and flexible metrics. We further employ an Agent-as-a-Judge paradigm to score agent outputs, enabling the evaluation of various test types beyond unit tests. Extensive experiments on PRDBench demonstrate its effectiveness in assessing the capabilities of both code agents and evaluation agents, providing a scalable and robust framework for annotation and evaluation.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "162",
        "title": "Text Simplification with Sentence Embeddings",
        "author": [
            "Matthew Shardlow"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24365",
        "abstract": "Sentence embeddings can be decoded to give approximations of the original texts used to create them. We explore this effect in the context of text simplification, demonstrating that reconstructed text embeddings preserve complexity levels. We experiment with a small feed forward neural network to effectively learn a transformation between sentence embeddings representing high-complexity and low-complexity texts. We provide comparison to a Seq2Seq and LLM-based approach, showing encouraging results in our much smaller learning setting. Finally, we demonstrate the applicability of our transformation to an unseen simplification dataset (MedEASI), as well as datasets from languages outside the training data (ES,DE). We conclude that learning transformations in sentence embedding space is a promising direction for future research and has potential to unlock the ability to develop small, but powerful models for text simplification and other natural language generation tasks.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "163",
        "title": "LLM-as-a-Judge for Software Engineering: Literature Review, Vision, and the Road Ahead",
        "author": [
            "Junda He",
            "Jieke Shi",
            "Terry Yue Zhuo",
            "Christoph Treude",
            "Jiamou Sun",
            "Zhenchang Xing",
            "Xiaoning Du",
            "David Lo"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24367",
        "abstract": "The rapid integration of Large Language Models (LLMs) into software engineering (SE) has revolutionized tasks like code generation, producing a massive volume of software artifacts. This surge has exposed a critical bottleneck: the lack of scalable, reliable methods to evaluate these outputs. Human evaluation is costly and time-consuming, while traditional automated metrics like BLEU fail to capture nuanced quality aspects. In response, the LLM-as-a-Judge paradigm - using LLMs for automated evaluation - has emerged. This approach leverages the advanced reasoning of LLMs, offering a path toward human-like nuance at automated scale. However, LLM-as-a-Judge research in SE is still in its early stages. This forward-looking SE 2030 paper aims to steer the community toward advancing LLM-as-a-Judge for evaluating LLM-generated software artifacts. We provide a literature review of existing SE studies, analyze their limitations, identify key research gaps, and outline a detailed roadmap. We envision these frameworks as reliable, robust, and scalable human surrogates capable of consistent, multi-faceted artifact evaluation by 2030. Our work aims to foster research and adoption of LLM-as-a-Judge frameworks, ultimately improving the scalability of software artifact evaluation.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "164",
        "title": "Improving LLM Reasoning via Dependency-Aware Query Decomposition and Logic-Parallel Content Expansion",
        "author": [
            "Xianjun Gao",
            "Jianchun Liu",
            "Hongli Xu",
            "Liusheng Huang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24390",
        "abstract": "The integration of Large Language Models (LLMs) into real-time Web applications, such as AI-powered search and conversational agents, presents a fundamental Web infrastructure challenge: reconciling the demand for high-quality, complex reasoning with the stringent low-latency and high-throughput requirements of interactive services. Current LLM reasoning, hindered by computationally inefficient sequential generation and rigid reasoning strategies, creates a critical bottleneck for the Web services. Existing approaches typically optimize the LLM reasoning for either efficiency or quality but struggle to achieve both, and thus fail to meet the dual requirements of modern Web platforms. To overcome these limitations, we propose Orion, a novel and efficient reasoning framework that enables dependency-aware query decomposition and logic-parallel content expansion. Concretely, Orion decomposes a single query reasoning process into two synergistic phases: (1) \\textit{key point generation}, which distills logically structured key points through retrieval-augmented few-shot prompting, and (2) \\textit{content parallel expansion}, which concurrently elaborates on these points based on a dependency graph to ensure logical consistency. Furthermore, Orion introduces a pipeline scheduling mechanism that exploits the complementary computational characteristics of the two phases (generation imposes pressure on GPU computing and expansion stresses on GPU memory) across multiple queries, enabling cross-query parallelism and dramatically improving reasoning performance (\\ie, efficiency and quality). Experiments on diverse benchmarks show that Orion not only delivers up to 4.33x higher token generation speed and 3.42x lower answer latency over the baselines but also improves reasoning quality by up to 18.75% through explicitly modeling inter-point dependencies.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "165",
        "title": "APTBench: Benchmarking Agentic Potential of Base LLMs During Pre-Training",
        "author": [
            "Jiarui Qin",
            "Yunjia Xi",
            "Junjie Huang",
            "Renting Rui",
            "Di Yin",
            "Weiwen Liu",
            "Yong Yu",
            "Weinan Zhang",
            "Xing Sun"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24397",
        "abstract": "With the rapid development of LLM-based agents, there is a growing trend to incorporate agent-specific data into the pre-training stage of LLMs, aiming to better align LLMs with real-world autonomous task execution. However, current pre-training benchmarks primarily focus on isolated and static skills, e.g., common knowledge or mathematical/code reasoning, and fail to reflect model's agentic capabilities. On the other hand, agent benchmarks are typically designed for post-trained models, requiring multi-turn task execution abilities that base models struggle to support. Thus, there is a compelling need for a benchmark that can evaluate agentic potentials during pre-training and guide the model training more effectively. To address this gap, we propose APTBench, a framework that converts real-world agent tasks and successful trajectories into multiple-choice or text completion questions tailored for base models. It focuses on core agentic abilities, e.g., planning and action, and covers key agent scenarios, software engineering and deep research. Compared to existing general-purpose benchmarks, APTBench offers a more predictive signal of a model's downstream performance as an agent, while remaining significantly more lightweight and cost-effective than full-scale, end-to-end agent evaluations after post-training.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "166",
        "title": "Metadata-Driven Retrieval-Augmented Generation for Financial Question Answering",
        "author": [
            "Michail Dadopoulos",
            "Anestis Ladas",
            "Stratos Moschidis",
            "Ioannis Negkakis"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24402",
        "abstract": "Retrieval-Augmented Generation (RAG) struggles on long, structured financial filings where relevant evidence is sparse and cross-referenced. This paper presents a systematic investigation of advanced metadata-driven Retrieval-Augmented Generation (RAG) techniques, proposing and evaluating a novel, multi-stage RAG architecture that leverages LLM-generated metadata. We introduce a sophisticated indexing pipeline to create contextually rich document chunks and benchmark a spectrum of enhancements, including pre-retrieval filtering, post-retrieval reranking, and enriched embeddings, benchmarked on the FinanceBench dataset. Our results reveal that while a powerful reranker is essential for precision, the most significant performance gains come from embedding chunk metadata directly with text (\"contextual chunks\"). Our proposed optimal architecture combines LLM-driven pre-retrieval optimizations with these contextual embeddings to achieve superior performance. Additionally, we present a custom metadata reranker that offers a compelling, cost-effective alternative to commercial solutions, highlighting a practical trade-off between peak performance and operational efficiency. This study provides a blueprint for building robust, metadata-aware RAG systems for financial document analysis.",
        "tags": [
            "LLM",
            "RAG"
        ]
    },
    {
        "id": "167",
        "title": "Uncovering Gaps Between RFC Updates and TCP/IP Implementations: LLM-Facilitated Differential Checks on Intermediate Representations",
        "author": [
            "Yifan Wu",
            "Xuewei Feng",
            "Yuxiang Yang",
            "Ke Xu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24408",
        "abstract": "As the core of the Internet infrastructure, the TCP/IP protocol stack undertakes the task of network data transmission. However, due to the complexity of the protocol and the uncertainty of cross-layer interaction, there are often inconsistencies between the implementation of the protocol stack code and the RFC standard. This inconsistency may not only lead to differences in protocol functions but also cause serious security vulnerabilities. At present, with the continuous expansion of protocol stack functions and the rapid iteration of RFC documents, it is increasingly important to detect and fix these inconsistencies. With the rise of large language models, researchers have begun to explore how to extract protocol specifications from RFC documents through these models, including protocol stack modeling, state machine extraction, text ambiguity analysis, and other related content. However, existing methods rely on predefined patterns or rule-based approaches that fail to generalize across different protocol specifications. Automated and scalable detection of these inconsistencies remains a significant challenge. In this study, we propose an automated analysis framework based on LLM and differential models. By modeling the iterative relationship of the protocol and based on the iterative update relationship of the RFC standard, we perform incremental code function analysis on different versions of kernel code implementations to automatically perform code detection and vulnerability analysis. We conduct extensive evaluations to validate the effectiveness of our framework, demonstrating its effectiveness in identifying potential vulnerabilities caused by RFC code inconsistencies.",
        "tags": [
            "Detection",
            "LLM"
        ]
    },
    {
        "id": "168",
        "title": "OS-Sentinel: Towards Safety-Enhanced Mobile GUI Agents via Hybrid Validation in Realistic Workflows",
        "author": [
            "Qiushi Sun",
            "Mukai Li",
            "Zhoumianze Liu",
            "Zhihui Xie",
            "Fangzhi Xu",
            "Zhangyue Yin",
            "Kanzhi Cheng",
            "Zehao Li",
            "Zichen Ding",
            "Qi Liu",
            "Zhiyong Wu",
            "Zhuosheng Zhang",
            "Ben Kao",
            "Lingpeng Kong"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24411",
        "abstract": "Computer-using agents powered by Vision-Language Models (VLMs) have demonstrated human-like capabilities in operating digital environments like mobile platforms. While these agents hold great promise for advancing digital automation, their potential for unsafe operations, such as system compromise and privacy leakage, is raising significant concerns. Detecting these safety concerns across the vast and complex operational space of mobile environments presents a formidable challenge that remains critically underexplored. To establish a foundation for mobile agent safety research, we introduce MobileRisk-Live, a dynamic sandbox environment accompanied by a safety detection benchmark comprising realistic trajectories with fine-grained annotations. Built upon this, we propose OS-Sentinel, a novel hybrid safety detection framework that synergistically combines a Formal Verifier for detecting explicit system-level violations with a VLM-based Contextual Judge for assessing contextual risks and agent actions. Experiments show that OS-Sentinel achieves 10%-30% improvements over existing approaches across multiple metrics. Further analysis provides critical insights that foster the development of safer and more reliable autonomous mobile agents.",
        "tags": [
            "Detection",
            "VLM"
        ]
    },
    {
        "id": "169",
        "title": "Comprehensive and Efficient Distillation for Lightweight Sentiment Analysis Models",
        "author": [
            "Guangyu Xie",
            "Yice Zhang",
            "Jianzhu Bao",
            "Qianlong Wang",
            "Yang Sun",
            "Bingbing Wang",
            "Ruifeng Xu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24425",
        "abstract": "Recent efforts leverage knowledge distillation techniques to develop lightweight and practical sentiment analysis models. These methods are grounded in human-written instructions and large-scale user texts. Despite the promising results, two key challenges remain: (1) manually written instructions are limited in diversity and quantity, making them insufficient to ensure comprehensive coverage of distilled knowledge; (2) large-scale user texts incur high computational cost, hindering the practicality of these methods. To this end, we introduce COMPEFFDIST, a comprehensive and efficient distillation framework for sentiment analysis. Our framework consists of two key modules: attribute-based automatic instruction construction and difficulty-based data filtering, which correspondingly tackle the aforementioned challenges. Applying our method across multiple model series (Llama-3, Qwen-3, and Gemma-3), we enable 3B student models to match the performance of 20x larger teacher models on most tasks. In addition, our approach greatly outperforms baseline methods in data efficiency, attaining the same performance level with only 10% of the data.",
        "tags": [
            "LLaMA",
            "Qwen"
        ]
    },
    {
        "id": "170",
        "title": "CodeWiki: Automated Repository-Level Documentation at Scale",
        "author": [
            "Nguyen Hoang Anh",
            "Minh Le-Anh",
            "Bach Le",
            "Nghi D.Q. Bui"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24428",
        "abstract": "Developers spend nearly 58% of their time understanding codebases, yet maintaining comprehensive documentation remains challenging due to complexity and manual effort. While recent Large Language Models (LLMs) show promise for function-level documentation, they fail at the repository level, where capturing architectural patterns and cross-module interactions is essential. We introduce CodeWiki, the first open-source framework for holistic repository-level documentation across seven programming languages. CodeWiki employs three innovations: (i) hierarchical decomposition that preserves architectural context, (ii) recursive agentic processing with dynamic delegation, and (iii) synthesis of textual and visual artifacts including architecture diagrams and data flows. We also present CodeWikiBench, the first repository-level documentation benchmark with multi-level rubrics and agentic assessment. CodeWiki achieves 68.79% quality score with proprietary models and 64.80% with open-source alternatives, outperforming existing closed-source systems and demonstrating scalable, accurate documentation for real-world repositories.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "171",
        "title": "Fill in the Blanks: Accelerating Q-Learning with a Handful of Demonstrations in Sparse Reward Settings",
        "author": [
            "Seyed Mahdi Basiri Azad",
            "Joschka Boedecker"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24432",
        "abstract": "Reinforcement learning (RL) in sparse-reward environments remains a significant challenge due to the lack of informative feedback. We propose a simple yet effective method that uses a small number of successful demonstrations to initialize the value function of an RL agent. By precomputing value estimates from offline demonstrations and using them as targets for early learning, our approach provides the agent with a useful prior over promising actions. The agent then refines these estimates through standard online interaction. This hybrid offline-to-online paradigm significantly reduces the exploration burden and improves sample efficiency in sparse-reward settings. Experiments on benchmark tasks demonstrate that our method accelerates convergence and outperforms standard baselines, even with minimal or suboptimal demonstration data.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "172",
        "title": "LuxIT: A Luxembourgish Instruction Tuning Dataset from Monolingual Seed Data",
        "author": [
            "Julian Valline",
            "Cedric Lothritz",
            "Jordi Cabot"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24434",
        "abstract": "The effectiveness of instruction-tuned Large Language Models (LLMs) is often limited in low-resource linguistic settings due to a lack of high-quality training data. We introduce LuxIT, a novel, monolingual instruction tuning dataset for Luxembourgish developed to mitigate this challenge. We synthesize the dataset from a corpus of native Luxembourgish texts, utilizing DeepSeek-R1-0528, chosen for its shown proficiency in Luxembourgish. Following generation, we apply a quality assurance process, employing an LLM-as-a-judge approach. To investigate the practical utility of the dataset, we fine-tune several smaller-scale LLMs on LuxIT. Subsequent benchmarking against their base models on Luxembourgish language proficiency examinations, however, yields mixed results, with performance varying significantly across different models. LuxIT represents a critical contribution to Luxembourgish natural language processing and offers a replicable monolingual methodology, though our findings highlight the need for further research to optimize its application.",
        "tags": [
            "DeepSeek",
            "LLM"
        ]
    },
    {
        "id": "173",
        "title": "Human-Level Reasoning: A Comparative Study of Large Language Models on Logical and Abstract Reasoning",
        "author": [
            "Benjamin Grando Moreira"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24435",
        "abstract": "Evaluating reasoning ability in Large Language Models (LLMs) is important for advancing artificial intelligence, as it transcends mere linguistic task performance. It involves understanding whether these models truly understand information, perform inferences, and are able to draw conclusions in a logical and valid way. This study compare logical and abstract reasoning skills of several LLMs - including GPT, Claude, DeepSeek, Gemini, Grok, Llama, Mistral, Perplexity, and SabiÃ¡ - using a set of eight custom-designed reasoning questions. The LLM results are benchmarked against human performance on the same tasks, revealing significant differences and indicating areas where LLMs struggle with deduction.",
        "tags": [
            "DeepSeek",
            "GPT",
            "LLM",
            "LLaMA"
        ]
    },
    {
        "id": "174",
        "title": "Can LLMs Write Faithfully? An Agent-Based Evaluation of LLM-generated Islamic Content",
        "author": [
            "Abdullah Mushtaq",
            "Rafay Naeem",
            "Ezieddin Elmahjub",
            "Ibrahim Ghaznavi",
            "Shawqi Al-Maliki",
            "Mohamed Abdallah",
            "Ala Al-Fuqaha",
            "Junaid Qadir"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24438",
        "abstract": "Large language models are increasingly used for Islamic guidance, but risk misquoting texts, misapplying jurisprudence, or producing culturally inconsistent responses. We pilot an evaluation of GPT-4o, Ansari AI, and Fanar on prompts from authentic Islamic blogs. Our dual-agent framework uses a quantitative agent for citation verification and six-dimensional scoring (e.g., Structure, Islamic Consistency, Citations) and a qualitative agent for five-dimensional side-by-side comparison (e.g., Tone, Depth, Originality). GPT-4o scored highest in Islamic Accuracy (3.93) and Citation (3.38), Ansari AI followed (3.68, 3.32), and Fanar lagged (2.76, 1.82). Despite relatively strong performance, models still fall short in reliably producing accurate Islamic content and citations -- a paramount requirement in faith-sensitive writing. GPT-4o had the highest mean quantitative score (3.90/5), while Ansari AI led qualitative pairwise wins (116/200). Fanar, though trailing, introduces innovations for Islamic and Arabic contexts. This study underscores the need for community-driven benchmarks centering Muslim perspectives, offering an early step toward more reliable AI in Islamic knowledge and other high-stakes domains such as medicine, law, and journalism.",
        "tags": [
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "175",
        "title": "Law in Silico: Simulating Legal Society with LLM-Based Agents",
        "author": [
            "Yiding Wang",
            "Yuxuan Chen",
            "Fanxu Meng",
            "Xifan Chen",
            "Xiaolei Yang",
            "Muhan Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24442",
        "abstract": "Since real-world legal experiments are often costly or infeasible, simulating legal societies with Artificial Intelligence (AI) systems provides an effective alternative for verifying and developing legal theory, as well as supporting legal administration. Large Language Models (LLMs), with their world knowledge and role-playing capabilities, are strong candidates to serve as the foundation for legal society simulation. However, the application of LLMs to simulate legal systems remains underexplored. In this work, we introduce Law in Silico, an LLM-based agent framework for simulating legal scenarios with individual decision-making and institutional mechanisms of legislation, adjudication, and enforcement. Our experiments, which compare simulated crime rates with real-world data, demonstrate that LLM-based agents can largely reproduce macro-level crime trends and provide insights that align with real-world observations. At the same time, micro-level simulations reveal that a well-functioning, transparent, and adaptive legal system offers better protection of the rights of vulnerable individuals.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "176",
        "title": "SPARTA: Evaluating Reasoning Segmentation Robustness through Black-Box Adversarial Paraphrasing in Text Autoencoder Latent Space",
        "author": [
            "Viktoriia Zinkovich",
            "Anton Antonov",
            "Andrei Spiridonov",
            "Denis Shepelev",
            "Andrey Moskalenko",
            "Daria Pugacheva",
            "Elena Tutubalina",
            "Andrey Kuznetsov",
            "Vlad Shakhuro"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24446",
        "abstract": "Multimodal large language models (MLLMs) have shown impressive capabilities in vision-language tasks such as reasoning segmentation, where models generate segmentation masks based on textual queries. While prior work has primarily focused on perturbing image inputs, semantically equivalent textual paraphrases-crucial in real-world applications where users express the same intent in varied ways-remain underexplored. To address this gap, we introduce a novel adversarial paraphrasing task: generating grammatically correct paraphrases that preserve the original query meaning while degrading segmentation performance. To evaluate the quality of adversarial paraphrases, we develop a comprehensive automatic evaluation protocol validated with human studies. Furthermore, we introduce SPARTA-a black-box, sentence-level optimization method that operates in the low-dimensional semantic latent space of a text autoencoder, guided by reinforcement learning. SPARTA achieves significantly higher success rates, outperforming prior methods by up to 2x on both the ReasonSeg and LLMSeg-40k datasets. We use SPARTA and competitive baselines to assess the robustness of advanced reasoning segmentation models. We reveal that they remain vulnerable to adversarial paraphrasing-even under strict semantic and grammatical constraints. All code and data will be released publicly upon acceptance.",
        "tags": [
            "LLM",
            "RL",
            "Segmentation"
        ]
    },
    {
        "id": "177",
        "title": "Rethinking Visual Intelligence: Insights from Video Pretraining",
        "author": [
            "Pablo Acuaviva",
            "Aram Davtyan",
            "Mariam Hassan",
            "Sebastian Stapf",
            "Ahmad Rahimi",
            "Alexandre Alahi",
            "Paolo Favaro"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24448",
        "abstract": "Large language models (LLMs) have demonstrated that large-scale pretraining enables systems to adapt rapidly to new problems with little supervision in the language domain. This success, however, has not translated as effectively to the visual domain, where models, including LLMs, continue to struggle with compositional understanding, sample efficiency, and general-purpose problem-solving. We investigate Video Diffusion Models (VDMs) as a promising direction for bridging this gap. Pretraining on spatiotemporal data endows these models with strong inductive biases for structure and dynamics, which we hypothesize can support broad task adaptability. To test this, we design a controlled evaluation in which both a pretrained LLM and a pretrained VDM are equipped with lightweight adapters and presented with tasks in their natural modalities. Across benchmarks including ARC-AGI, ConceptARC, visual games, route planning, and cellular automata, VDMs demonstrate higher data efficiency than their language counterparts. Taken together, our results indicate that video pretraining offers inductive biases that support progress toward visual foundation models.",
        "tags": [
            "Diffusion",
            "LLM"
        ]
    },
    {
        "id": "178",
        "title": "Charting the European LLM Benchmarking Landscape: A New Taxonomy and a Set of Best Practices",
        "author": [
            "Å pela Vintar",
            "Taja Kuzman PungerÅ¡ek",
            "Mojca Brglez",
            "Nikola LjubeÅ¡iÄ"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24450",
        "abstract": "While new benchmarks for large language models (LLMs) are being developed continuously to catch up with the growing capabilities of new models and AI in general, using and evaluating LLMs in non-English languages remains a little-charted landscape. We give a concise overview of recent developments in LLM benchmarking, and then propose a new taxonomy for the categorization of benchmarks that is tailored to multilingual or non-English use scenarios. We further propose a set of best practices and quality standards that could lead to a more coordinated development of benchmarks for European languages. Among other recommendations, we advocate for a higher language and culture sensitivity of evaluation methods.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "179",
        "title": "Flatness-based trajectory planning for 3D overhead cranes with friction compensation and collision avoidance",
        "author": [
            "Jorge Vicente-Martinez",
            "Edgar Ramirez-Laboreo"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24457",
        "abstract": "This paper presents an optimal trajectory generation method for 3D overhead cranes by leveraging differential flatness. This framework enables the direct inclusion of complex physical and dynamic constraints, such as nonlinear friction and collision avoidance for both payload and rope. Our approach allows for aggressive movements by constraining payload swing only at the final point. A comparative simulation study validates our approach, demonstrating that neglecting dry friction leads to actuator saturation and collisions. The results show that friction modeling is a fundamental requirement for fast and safe crane trajectories.",
        "tags": [
            "3D",
            "RoPE"
        ]
    },
    {
        "id": "180",
        "title": "Adaptive Surrogate Gradients for Sequential Reinforcement Learning in Spiking Neural Networks",
        "author": [
            "Korneel Van den Berghe",
            "Stein Stroobants",
            "Vijay Janapa Reddi",
            "G.C.H.E. de Croon"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24461",
        "abstract": "Neuromorphic computing systems are set to revolutionize energy-constrained robotics by achieving orders-of-magnitude efficiency gains, while enabling native temporal processing. Spiking Neural Networks (SNNs) represent a promising algorithmic approach for these systems, yet their application to complex control tasks faces two critical challenges: (1) the non-differentiable nature of spiking neurons necessitates surrogate gradients with unclear optimization properties, and (2) the stateful dynamics of SNNs require training on sequences, which in reinforcement learning (RL) is hindered by limited sequence lengths during early training, preventing the network from bridging its warm-up period.\nWe address these challenges by systematically analyzing surrogate gradient slope settings, showing that shallower slopes increase gradient magnitude in deeper layers but reduce alignment with true gradients. In supervised learning, we find no clear preference for fixed or scheduled slopes. The effect is much more pronounced in RL settings, where shallower slopes or scheduled slopes lead to a 2.1x improvement in both training and final deployed performance. Next, we propose a novel training approach that leverages a privileged guiding policy to bootstrap the learning process, while still exploiting online environment interactions with the spiking policy. Combining our method with an adaptive slope schedule for a real-world drone position control task, we achieve an average return of 400 points, substantially outperforming prior techniques, including Behavioral Cloning and TD3BC, which achieve at most --200 points under the same conditions. This work advances both the theoretical understanding of surrogate gradient learning in SNNs and practical training methodologies for neuromorphic controllers demonstrated in real-world robotic systems.",
        "tags": [
            "RL",
            "Robotics"
        ]
    },
    {
        "id": "181",
        "title": "Iterative Critique-Refine Framework for Enhancing LLM Personalization",
        "author": [
            "Durga Prasad Maram",
            "Dhruvin Gandhi",
            "Zonghai Yao",
            "Gayathri Akkinapalli",
            "Franck Dernoncourt",
            "Yu Wang",
            "Ryan A. Rossi",
            "Nesreen K. Ahmed"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24469",
        "abstract": "Personalized text generation requires models not only to produce coherent text but also to align with a target user's style, tone, and topical focus. Existing retrieval-augmented approaches such as LaMP and PGraphRAG enrich profiles with user and neighbor histories, but they stop at generation and often yield outputs that drift in tone, topic, or style. We present PerFine, a unified, training-free critique-refine framework that enhances personalization through iterative, profile-grounded feedback. In each iteration, an LLM generator produces a draft conditioned on the retrieved profile, and a critic LLM - also conditioned on the same profile - provides structured feedback on tone, vocabulary, sentence structure, and topicality. The generator then revises, while a novel knockout strategy retains the stronger draft across iterations. We further study additional inference-time strategies such as Best-of-N and Topic Extraction to balance quality and efficiency. Across Yelp, Goodreads, and Amazon datasets, PerFine consistently improves personalization over PGraphRAG, with GEval gains of +7-13%, steady improvements over 3-5 refinement iterations, and scalability with increasing critic size. These results highlight that post-hoc, profile-aware feedback offers a powerful paradigm for personalized LLM generation that is both training-free and model-agnostic.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "182",
        "title": "Decoupled MeanFlow: Turning Flow Models into Flow Maps for Accelerated Sampling",
        "author": [
            "Kyungmin Lee",
            "Sihyun Yu",
            "Jinwoo Shin"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24474",
        "abstract": "Denoising generative models, such as diffusion and flow-based models, produce high-quality samples but require many denoising steps due to discretization error. Flow maps, which estimate the average velocity between timesteps, mitigate this error and enable faster sampling. However, their training typically demands architectural changes that limit compatibility with pretrained flow models. We introduce Decoupled MeanFlow, a simple decoding strategy that converts flow models into flow map models without architectural modifications. Our method conditions the final blocks of diffusion transformers on the subsequent timestep, allowing pretrained flow models to be directly repurposed as flow maps. Combined with enhanced training techniques, this design enables high-quality generation in as few as 1 to 4 steps. Notably, we find that training flow models and subsequently converting them is more efficient and effective than training flow maps from scratch. On ImageNet 256x256 and 512x512, our models attain 1-step FID of 2.16 and 2.12, respectively, surpassing prior art by a large margin. Furthermore, we achieve FID of 1.51 and 1.68 when increasing the steps to 4, which nearly matches the performance of flow models while delivering over 100x faster inference.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "183",
        "title": "Mitigating Hallucination in Large Language Models (LLMs): An Application-Oriented Survey on RAG, Reasoning, and Agentic Systems",
        "author": [
            "Yihan Li",
            "Xiyuan Fu",
            "Ghanshyam Verma",
            "Paul Buitelaar",
            "Mingming Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24476",
        "abstract": "Hallucination remains one of the key obstacles to the reliable deployment of large language models (LLMs), particularly in real-world applications. Among various mitigation strategies, Retrieval-Augmented Generation (RAG) and reasoning enhancement have emerged as two of the most effective and widely adopted approaches, marking a shift from merely suppressing hallucinations to balancing creativity and reliability. However, their synergistic potential and underlying mechanisms for hallucination mitigation have not yet been systematically examined. This survey adopts an application-oriented perspective of capability enhancement to analyze how RAG, reasoning enhancement, and their integration in Agentic Systems mitigate hallucinations. We propose a taxonomy distinguishing knowledge-based and logic-based hallucinations, systematically examine how RAG and reasoning address each, and present a unified framework supported by real-world applications, evaluations, and benchmarks.",
        "tags": [
            "LLM",
            "RAG"
        ]
    },
    {
        "id": "184",
        "title": "Sample-efficient and Scalable Exploration in Continuous-Time RL",
        "author": [
            "Klemens Iten",
            "Lenart Treven",
            "Bhavya Sukhija",
            "Florian DÃ¶rfler",
            "Andreas Krause"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24482",
        "abstract": "Reinforcement learning algorithms are typically designed for discrete-time dynamics, even though the underlying real-world control systems are often continuous in time. In this paper, we study the problem of continuous-time reinforcement learning, where the unknown system dynamics are represented using nonlinear ordinary differential equations (ODEs). We leverage probabilistic models, such as Gaussian processes and Bayesian neural networks, to learn an uncertainty-aware model of the underlying ODE. Our algorithm, COMBRL, greedily maximizes a weighted sum of the extrinsic reward and model epistemic uncertainty. This yields a scalable and sample-efficient approach to continuous-time model-based RL. We show that COMBRL achieves sublinear regret in the reward-driven setting, and in the unsupervised RL setting (i.e., without extrinsic rewards), we provide a sample complexity bound. In our experiments, we evaluate COMBRL in both standard and unsupervised RL settings and demonstrate that it scales better, is more sample-efficient than prior methods, and outperforms baselines across several deep RL tasks.",
        "tags": [
            "ODE",
            "RL"
        ]
    },
    {
        "id": "185",
        "title": "A word association network methodology for evaluating implicit biases in LLMs compared to humans",
        "author": [
            "Katherine Abramski",
            "Giulio Rossetti",
            "Massimo Stella"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24488",
        "abstract": "As Large language models (LLMs) become increasingly integrated into our lives, their inherent social biases remain a pressing concern. Detecting and evaluating these biases can be challenging because they are often implicit rather than explicit in nature, so developing evaluation methods that assess the implicit knowledge representations of LLMs is essential. We present a novel word association network methodology for evaluating implicit biases in LLMs based on simulating semantic priming within LLM-generated word association networks. Our prompt-based approach taps into the implicit relational structures encoded in LLMs, providing both quantitative and qualitative assessments of bias. Unlike most prompt-based evaluation methods, our method enables direct comparisons between various LLMs and humans, providing a valuable point of reference and offering new insights into the alignment of LLMs with human cognition. To demonstrate the utility of our methodology, we apply it to both humans and several widely used LLMs to investigate social biases related to gender, religion, ethnicity, sexual orientation, and political party. Our results reveal both convergences and divergences between LLM and human biases, providing new perspectives on the potential risks of using LLMs. Our methodology contributes to a systematic, scalable, and generalizable framework for evaluating and comparing biases across multiple LLMs and humans, advancing the goal of transparent and socially responsible language technologies.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "186",
        "title": "MIMIC-Sepsis: A Curated Benchmark for Modeling and Learning from Sepsis Trajectories in the ICU",
        "author": [
            "Yong Huang",
            "Zhongqi Yang",
            "Amir Rahmani"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24500",
        "abstract": "Sepsis is a leading cause of mortality in intensive care units (ICUs), yet existing research often relies on outdated datasets, non-reproducible preprocessing pipelines, and limited coverage of clinical interventions. We introduce MIMIC-Sepsis, a curated cohort and benchmark framework derived from the MIMIC-IV database, designed to support reproducible modeling of sepsis trajectories. Our cohort includes 35,239 ICU patients with time-aligned clinical variables and standardized treatment data, including vasopressors, fluids, mechanical ventilation and antibiotics. We describe a transparent preprocessing pipeline-based on Sepsis-3 criteria, structured imputation strategies, and treatment inclusion-and release it alongside benchmark tasks focused on early mortality prediction, length-of-stay estimation, and shock onset classification. Empirical results demonstrate that incorporating treatment variables substantially improves model performance, particularly for Transformer-based architectures. MIMIC-Sepsis serves as a robust platform for evaluating predictive and sequential models in critical care research.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "187",
        "title": "CritiCal: Can Critique Help LLM Uncertainty or Confidence Calibration?",
        "author": [
            "Qing Zong",
            "Jiayu Liu",
            "Tianshi Zheng",
            "Chunyang Li",
            "Baixuan Xu",
            "Haochen Shi",
            "Weiqi Wang",
            "Zhaowei Wang",
            "Chunkit Chan",
            "Yangqiu Song"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24505",
        "abstract": "Accurate confidence calibration in Large Language Models (LLMs) is critical for safe use in high-stakes domains, where clear verbalized confidence enhances user trust. Traditional methods that mimic reference confidence expressions often fail to capture the reasoning needed for accurate confidence assessment. We propose natural language critiques as a solution, ideally suited for confidence calibration, as precise gold confidence labels are hard to obtain and often require multiple generations. This paper studies how natural language critiques can enhance verbalized confidence, addressing: (1) What to critique: uncertainty (question-focused) or confidence (answer-specific)? Analysis shows confidence suits multiple-choice tasks, while uncertainty excels in open-ended scenarios. (2) How to critique: self-critique or critique calibration training? We propose Self-Critique, enabling LLMs to critique and optimize their confidence beyond mere accuracy, and CritiCal, a novel Critique Calibration training method that leverages natural language critiques to improve confidence calibration, moving beyond direct numerical optimization. Experiments show that CritiCal significantly outperforms Self-Critique and other competitive baselines, even surpassing its teacher model, GPT-4o, in complex reasoning tasks. CritiCal also shows robust generalization in out-of-distribution settings, advancing LLM's reliability.",
        "tags": [
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "188",
        "title": "Evaluating Fitness Averaging Strategies in Cooperative NeuroCoEvolution for Automated Soft Actuator Design",
        "author": [
            "Hugo Alcaraz-Herrera",
            "Michail-Antisthenis Tsompanas",
            "Igor Balaz",
            "Andrew Adamatzky"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24510",
        "abstract": "Soft robotics are increasingly favoured in specific applications such as healthcare, due to their adaptability, which stems from the non-linear properties of their building materials. However, these properties also pose significant challenges in designing the morphologies and controllers of soft robots. The relatively short history of this field has not yet produced sufficient knowledge to consistently derive optimal solutions. Consequently, an automated process for the design of soft robot morphologies can be extremely helpful. This study focusses on the cooperative NeuroCoEvolution of networks that are indirect representations of soft robot actuators. Both the morphologies and controllers represented by Compositional Pattern Producing Networks are evolved using the well-established method NeuroEvolution of Augmented Topologies (CPPN-NEAT). The CoEvolution of controllers and morphologies is implemented using the top n individuals from the cooperating population, with various averaging methods tested to determine the fitness of the evaluated individuals. The test-case application for this research is the optimisation of a soft actuator for a drug delivery system. The primary metric used is the maximum displacement of one end of the actuator in a specified direction. Additionally, the robustness of the evolved morphologies is assessed against a range of randomly generated controllers to simulate potential noise in real-world applications. The results of this investigation indicate that CPPN-NEAT produces superior morphologies compared to previously published results from multi-objective optimisation, with reduced computational effort and time. Moreover, the best configuration is found to be CoEvolution with the two best individuals from the cooperative population and the averaging of their fitness using the weighted mean method.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "189",
        "title": "Latent Sketchpad: Sketching Visual Thoughts to Elicit Multimodal Reasoning in MLLMs",
        "author": [
            "Huanyu Zhang",
            "Wenshan Wu",
            "Chengzu Li",
            "Ning Shang",
            "Yan Xia",
            "Yangyu Huang",
            "Yifan Zhang",
            "Li Dong",
            "Zhang Zhang",
            "Liang Wang",
            "Tieniu Tan",
            "Furu Wei"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24514",
        "abstract": "While Multimodal Large Language Models (MLLMs) excel at visual understanding, they often struggle in complex scenarios that require visual planning and imagination. Inspired by how humans use sketching as a form of visual thinking to develop and communicate ideas, we introduce Latent Sketchpad, a framework that equips MLLMs with an internal visual scratchpad. The internal visual representations of MLLMs have traditionally been confined to perceptual understanding. We repurpose them to support generative visual thought without compromising reasoning ability. Building on frontier MLLMs, our approach integrates visual generation directly into their native autoregressive reasoning process. It allows the model to interleave textual reasoning with the generation of visual latents. These latents guide the internal thought process and can be translated into sketch images for interpretability. To realize this, we introduce two components: a Context-Aware Vision Head autoregressively produces visual representations, and a pretrained Sketch Decoder renders these into human-interpretable images. We evaluate the framework on our new dataset MazePlanning. Experiments across various MLLMs show that Latent Sketchpad delivers comparable or even superior reasoning performance to their backbone. It further generalizes across distinct frontier MLLMs, including Gemma3 and Qwen2.5-VL. By extending model's textual reasoning to visual thinking, our framework opens new opportunities for richer human-computer interaction and broader applications. More details and resources are available on our project page: https://latent-sketchpad.github.io/.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "190",
        "title": "Stochastic Prize-Collecting Games: Strategic Planning in Multi-Robot Systems",
        "author": [
            "Malintha Fernando",
            "Petter Ãgren",
            "Silun Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24515",
        "abstract": "The Team Orienteering Problem (TOP) generalizes many real-world multi-robot scheduling and routing tasks that occur in autonomous mobility, aerial logistics, and surveillance applications. While many flavors of the TOP exist for planning in multi-robot systems, they assume that all the robots cooperate toward a single objective; thus, they do not extend to settings where the robots compete in reward-scarce environments. We propose Stochastic Prize-Collecting Games (SPCG) as an extension of the TOP to plan in the presence of self-interested robots operating on a graph, under energy constraints and stochastic transitions. A theoretical study on complete and star graphs establishes that there is a unique pure Nash equilibrium in SPCGs that coincides with the optimal routing solution of an equivalent TOP given a rank-based conflict resolution rule. This work proposes two algorithms: Ordinal Rank Search (ORS) to obtain the ''ordinal rank'' --one's effective rank in temporarily-formed local neighborhoods during the games' stages, and Fictitious Ordinal Response Learning (FORL) to obtain best-response policies against one's senior-rank opponents. Empirical evaluations conducted on road networks and synthetic graphs under both dynamic and stationary prize distributions show that 1) the state-aliasing induced by OR-conditioning enables learning policies that scale more efficiently to large team sizes than those trained with the global index, and 2) Policies trained with FORL generalize better to imbalanced prize distributions than those with other multi-agent training methods. Finally, the learned policies in the SPCG achieved between 87% and 95% optimality compared to an equivalent TOP solution obtained by mixed-integer linear programming.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "191",
        "title": "From Cross-Task Examples to In-Task Prompts: A Graph-Based Pseudo-Labeling Framework for In-context Learning",
        "author": [
            "Zihan Chen",
            "Song Wang",
            "Xingbo Fu",
            "Chengshuai Shi",
            "Zhenyu Lei",
            "Cong Shen",
            "Jundong Li"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24528",
        "abstract": "The capability of in-context learning (ICL) enables large language models (LLMs) to perform novel tasks without parameter updates by conditioning on a few input-output examples. However, collecting high-quality examples for new or challenging tasks can be costly and labor-intensive. In this work, we propose a cost-efficient two-stage pipeline that reduces reliance on LLMs for data labeling. Our approach first leverages readily available cross-task examples to prompt an LLM and pseudo-label a small set of target task instances. We then introduce a graph-based label propagation method that spreads label information to the remaining target examples without additional LLM queries. The resulting fully pseudo-labeled dataset is used to construct in-task demonstrations for ICL. This pipeline combines the flexibility of cross-task supervision with the scalability of LLM-free propagation. Experiments across five tasks demonstrate that our method achieves strong performance while lowering labeling costs.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "192",
        "title": "Dark & Stormy: Modeling Humor in the Worst Sentences Ever Written",
        "author": [
            "Venkata S Govindarajan",
            "Laura Biester"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24538",
        "abstract": "Textual humor is enormously diverse and computational studies need to account for this range, including intentionally bad humor. In this paper, we curate and analyze a novel corpus of sentences from the Bulwer-Lytton Fiction Contest to better understand \"bad\" humor in English. Standard humor detection models perform poorly on our corpus, and an analysis of literary devices finds that these sentences combine features common in existing humor datasets (e.g., puns, irony) with metaphor, metafiction and simile. LLMs prompted to synthesize contest-style sentences imitate the form but exaggerate the effect by over-using certain literary devices, and including far more novel adjective-noun bigrams than human writers. Data, code and analysis are available at https://github.com/venkatasg/bulwer-lytton",
        "tags": [
            "Detection",
            "LLM"
        ]
    },
    {
        "id": "193",
        "title": "Open Korean Historical Corpus: A Millennia-Scale Diachronic Collection of Public Domain Texts",
        "author": [
            "Seyoung Song",
            "Nawon Kim",
            "Songeun Chae",
            "Kiwoong Park",
            "Jiho Jin",
            "Haneul Yoo",
            "Kyunghyun Cho",
            "Alice Oh"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24541",
        "abstract": "The history of the Korean language is characterized by a discrepancy between its spoken and written forms and a pivotal shift from Chinese characters to the Hangul alphabet. However, this linguistic evolution has remained largely unexplored in NLP due to a lack of accessible historical corpora. To address this gap, we introduce the Open Korean Historical Corpus, a large-scale, openly licensed dataset spanning 1,300 years and 6 languages, as well as under-represented writing systems like Korean-style Sinitic (Idu) and Hanja-Hangul mixed script. This corpus contains 18 million documents and 5 billion tokens from 19 sources, ranging from the 7th century to 2025. We leverage this resource to quantitatively analyze major linguistic shifts: (1) Idu usage peaked in the 1860s before declining sharply; (2) the transition from Hanja to Hangul was a rapid transformation starting around 1890; and (3) North Korea's lexical divergence causes modern tokenizers to produce up to 51 times higher out-of-vocabulary rates. This work provides a foundational resource for quantitative diachronic analysis by capturing the history of the Korean language. Moreover, it can serve as a pre-training corpus for large language models, potentially improving their understanding of Sino-Korean vocabulary in modern Hangul as well as archaic writing systems.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "194",
        "title": "Dual-Mind World Models: A General Framework for Learning in Dynamic Wireless Networks",
        "author": [
            "Lingyi Wang",
            "Rashed Shelim",
            "Walid Saad",
            "Naren Ramakrishnan"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24546",
        "abstract": "Despite the popularity of reinforcement learning (RL) in wireless networks, existing approaches that rely on model-free RL (MFRL) and model-based RL (MBRL) are data inefficient and short-sighted. Such RL-based solutions cannot generalize to novel network states since they capture only statistical patterns rather than the underlying physics and logic from wireless data. These limitations become particularly challenging in complex wireless networks with high dynamics and long-term planning requirements. To address these limitations, in this paper, a novel dual-mind world model-based learning framework is proposed with the goal of optimizing completeness-weighted age of information (CAoI) in a challenging mmWave V2X scenario. Inspired by cognitive psychology, the proposed dual-mind world model encompasses a pattern-driven System 1 component and a logic-driven System 2 component to learn dynamics and logic of the wireless network, and to provide long-term link scheduling over reliable imagined trajectories. Link scheduling is learned through end-to-end differentiable imagined trajectories with logical consistency over an extended horizon rather than relying on wireless data obtained from environment interactions. Moreover, through imagination rollouts, the proposed world model can jointly reason network states and plan link scheduling. During intervals without observations, the proposed method remains capable of making efficient decisions. Extensive experiments are conducted on a realistic simulator based on Sionna with real-world physical channel, ray-tracing, and scene objects with material properties. Simulation results show that the proposed world model achieves a significant improvement in data efficiency and achieves strong generalization and adaptation to unseen environments, compared to the state-of-the-art RL baselines, and the world model approach with only System 1.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "195",
        "title": "An Adaptive Inspection Planning Approach Towards Routine Monitoring in Uncertain Environments",
        "author": [
            "Vignesh Kottayam Viswanathan",
            "Yifan Bai",
            "Scott Fredriksson",
            "Sumeet Satpute",
            "Christoforos Kanellakis",
            "George Nikolakopoulos"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24554",
        "abstract": "In this work, we present a hierarchical framework designed to support robotic inspection under environment uncertainty. By leveraging a known environment model, existing methods plan and safely track inspection routes to visit points of interest. However, discrepancies between the model and actual site conditions, caused by either natural or human activities, can alter the surface morphology or introduce path obstructions. To address this challenge, the proposed framework divides the inspection task into: (a) generating the initial global view-plan for region of interests based on a historical map and (b) local view replanning to adapt to the current morphology of the inspection scene. The proposed hierarchy preserves global coverage objectives while enabling reactive adaptation to the local surface morphology. This enables the local autonomy to remain robust against environment uncertainty and complete the inspection tasks. We validate the approach through deployments in real-world subterranean mines using quadrupedal robot.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "196",
        "title": "LoRA-DA: Data-Aware Initialization for Low-Rank Adaptation via Asymptotic Analysis",
        "author": [
            "Qingyue Zhang",
            "Chang Chu",
            "Tianren Peng",
            "Qi Li",
            "Xiangyang Luo",
            "Zhihao Jiang",
            "Shao-Lun Huang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24561",
        "abstract": "With the widespread adoption of LLMs, LoRA has become a dominant method for PEFT, and its initialization methods have attracted increasing attention. However, existing methods have notable limitations: many methods do not incorporate target-domain data, while gradient-based methods exploit data only at a shallow level by relying on one-step gradient decomposition, which remains unsatisfactory due to the weak empirical performance of the one-step fine-tuning model that serves as their basis, as well as the fact that these methods either lack a rigorous theoretical foundation or depend heavily on restrictive isotropic assumptions. In this paper, we establish a theoretical framework for data-aware LoRA initialization based on asymptotic analysis. Starting from a general optimization objective that minimizes the expectation of the parameter discrepancy between the fine-tuned and target models, we derive an optimization problem with two components: a bias term, which is related to the parameter distance between the fine-tuned and target models, and is approximated using a Fisher-gradient formulation to preserve anisotropy; and a variance term, which accounts for the uncertainty introduced by sampling stochasticity through the Fisher information. By solving this problem, we obtain an optimal initialization strategy for LoRA. Building on this theoretical framework, we develop an efficient algorithm, LoRA-DA, which estimates the terms in the optimization problem from a small set of target domain samples and obtains the optimal LoRA initialization. Empirical results across multiple benchmarks demonstrate that LoRA-DA consistently improves final accuracy over existing initialization methods. Additional studies show faster, more stable convergence, robustness across ranks, and only a small initialization overhead for LoRA-DA. The source code will be released upon publication.",
        "tags": [
            "LLM",
            "LoRA"
        ]
    },
    {
        "id": "197",
        "title": "Politically Speaking: LLMs on Changing International Affairs",
        "author": [
            "Xuenan Cao",
            "Wai Kei Chung",
            "Ye Zhao",
            "Lidia Mengyuan Zhou"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24582",
        "abstract": "Ask your chatbot to impersonate an expert from Russia and an expert from US and query it on Chinese politics. How might the outputs differ? Or, to prepare ourselves for the worse, how might they converge? Scholars have raised concerns LLM based applications can homogenize cultures and flatten perspectives. But exactly how much does LLM generated outputs converge despite explicit different role assignment? This study provides empirical evidence to the above question. The critique centres on pretrained models regurgitating ossified political jargons used in the Western world when speaking about China, Iran, Russian, and US politics, despite changes in these countries happening daily or hourly. The experiments combine role-prompting and similarity metrics. The results show that AI generated discourses from four models about Iran and China are the most homogeneous and unchanging across all four models, including OpenAI GPT, Google Gemini, Anthropic Claude, and DeepSeek, despite the prompted perspective change and the actual changes in real life. This study does not engage with history, politics, or literature as traditional disciplinary approaches would; instead, it takes cues from international and area studies and offers insight on the future trajectory of shifting political discourse in a digital space increasingly cannibalised by AI.",
        "tags": [
            "DeepSeek",
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "198",
        "title": "Towards Quadrupedal Jumping and Walking for Dynamic Locomotion using Reinforcement Learning",
        "author": [
            "JÃ¸rgen Anker Olsen",
            "Lars RÃ¸nhaug Pettersen",
            "Kostas Alexis"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24584",
        "abstract": "This paper presents a curriculum-based reinforcement learning framework for training precise and high-performance jumping policies for the robot `Olympus'. Separate policies are developed for vertical and horizontal jumps, leveraging a simple yet effective strategy. First, we densify the inherently sparse jumping reward using the laws of projectile motion. Next, a reference state initialization scheme is employed to accelerate the exploration of dynamic jumping behaviors without reliance on reference trajectories. We also present a walking policy that, when combined with the jumping policies, unlocks versatile and dynamic locomotion capabilities. Comprehensive testing validates walking on varied terrain surfaces and jumping performance that exceeds previous works, effectively crossing the Sim2Real gap. Experimental validation demonstrates horizontal jumps up to 1.25 m with centimeter accuracy and vertical jumps up to 1.0 m. Additionally, we show that with only minor modifications, the proposed method can be used to learn omnidirectional jumping.",
        "tags": [
            "RL",
            "Robotics"
        ]
    },
    {
        "id": "199",
        "title": "ReForm: Reflective Autoformalization with Prospective Bounded Sequence Optimization",
        "author": [
            "Guoxin Chen",
            "Jing Wu",
            "Xinjie Chen",
            "Wayne Xin Zhao",
            "Ruihua Song",
            "Chengxi Li",
            "Kai Fan",
            "Dayiheng Liu",
            "Minpeng Liao"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24592",
        "abstract": "Autoformalization, which translates natural language mathematics into machine-verifiable formal statements, is critical for using formal mathematical reasoning to solve math problems stated in natural language. While Large Language Models can generate syntactically correct formal statements, they often fail to preserve the original problem's semantic intent. This limitation arises from the LLM approaches' treating autoformalization as a simplistic translation task which lacks mechanisms for self-reflection and iterative refinement that human experts naturally employ. To address these issues, we propose ReForm, a Reflective Autoformalization method that tightly integrates semantic consistency evaluation into the autoformalization process. This enables the model to iteratively generate formal statements, assess its semantic fidelity, and self-correct identified errors through progressive refinement. To effectively train this reflective model, we introduce Prospective Bounded Sequence Optimization (PBSO), which employs different rewards at different sequence positions to ensure that the model develops both accurate autoformalization and correct semantic validations, preventing superficial critiques that would undermine the purpose of reflection. Extensive experiments across four autoformalization benchmarks demonstrate that ReForm achieves an average improvement of 17.2 percentage points over the strongest baselines. To further ensure evaluation reliability, we introduce ConsistencyCheck, a benchmark of 859 expert-annotated items that not only validates LLMs as judges but also reveals that autoformalization is inherently difficult: even human experts produce semantic errors in up to 38.5% of cases.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "200",
        "title": "Detecting the Use of Generative AI in Crowdsourced Surveys: Implications for Data Integrity",
        "author": [
            "Dapeng Zhang",
            "Marina Katoh",
            "Weiping Pei"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24594",
        "abstract": "The widespread adoption of generative AI (GenAI) has introduced new challenges in crowdsourced data collection, particularly in survey-based research. While GenAI offers powerful capabilities, its unintended use in crowdsourcing, such as generating automated survey responses, threatens the integrity of empirical research and complicates efforts to understand public opinion and behavior. In this study, we investigate and evaluate two approaches for detecting AI-generated responses in online surveys: LLM-based detection and signature-based detection. We conducted experiments across seven survey studies, comparing responses collected before 2022 with those collected after the release of ChatGPT. Our findings reveal a significant increase in AI-generated responses in the post-2022 studies, highlighting how GenAI may silently distort crowdsourced data. This work raises broader concerns about evolving landscape of data integrity, where GenAI can compromise data quality, mislead researchers, and influence downstream findings in fields such as health, politics, and social behavior. By surfacing detection strategies and empirical evidence of GenAI's impact, we aim to contribute to ongoing conversation about safeguarding research integrity and supporting scholars navigating these methodological and ethical challenges.",
        "tags": [
            "Detection",
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "201",
        "title": "A Novel XAI-Enhanced Quantum Adversarial Networks for Velocity Dispersion Modeling in MaNGA Galaxies",
        "author": [
            "Sathwik Narkedimilli",
            "N V Saran Kumar",
            "Aswath Babu H",
            "Manjunath K Vanahalli",
            "Manish M",
            "Vinija Jain",
            "Aman Chadha"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24598",
        "abstract": "Current quantum machine learning approaches often face challenges balancing predictive accuracy, robustness, and interpretability. To address this, we propose a novel quantum adversarial framework that integrates a hybrid quantum neural network (QNN) with classical deep learning layers, guided by an evaluator model with LIME-based interpretability, and extended through quantum GAN and self-supervised variants. In the proposed model, an adversarial evaluator concurrently guides the QNN by computing feedback loss, thereby optimizing both prediction accuracy and model explainability. Empirical evaluations show that the Vanilla model achieves RMSE = 0.27, MSE = 0.071, MAE = 0.21, and R^2 = 0.59, delivering the most consistent performance across regression metrics compared to adversarial counterparts. These results demonstrate the potential of combining quantum-inspired methods with classical architectures to develop lightweight, high-performance, and interpretable predictive models, advancing the applicability of QML beyond current limitations.",
        "tags": [
            "GAN"
        ]
    },
    {
        "id": "202",
        "title": "Diffusion LLM with Native Variable Generation Lengths: Let [EOS] Lead the Way",
        "author": [
            "Yicun Yang",
            "Cong Wang",
            "Shaobo Wang",
            "Zichen Wen",
            "Biqing Qi",
            "Hanlin Xu",
            "Linfeng Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24605",
        "abstract": "Diffusion-based large language models (dLLMs) have exhibited substantial potential for parallel text generation, which may enable more efficient generation compared to autoregressive models. However, current dLLMs suffer from fixed generation lengths, which indicates the generation lengths of dLLMs have to be determined before decoding as a hyper-parameter, leading to issues in efficiency and flexibility. To solve these problems, in this work, we propose to train a diffusion LLM with native variable generation lengths, abbreviated as dLLM-Var. Concretely, we aim to train a model to accurately predict the [EOS] token in the generated text, which makes a dLLM be able to natively infer in a block diffusion manner, while still maintaining the ability of global bi-directional (full) attention and high parallelism. Experiments on standard benchmarks demonstrate that our method achieves a 30.1x speedup over traditional dLLM inference paradigms and a 2.4x speedup relative to autoregressive models such as Qwen and Llama. Our method achieves higher accuracy and faster inference, elevating dLLMs beyond mere academic novelty and supporting their practical use in real-world applications. Codes and models have been released.",
        "tags": [
            "Diffusion",
            "LLM",
            "LLaMA",
            "Qwen"
        ]
    },
    {
        "id": "203",
        "title": "Long-Context Modeling with Dynamic Hierarchical Sparse Attention for On-Device LLMs",
        "author": [
            "Siheng Xiong",
            "Joe Zou",
            "Faramarz Fekri",
            "Yae Jee Cho"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24606",
        "abstract": "The quadratic cost of attention hinders the scalability of long-context LLMs, especially in resource-constrained settings. Existing static sparse methods such as sliding windows or global tokens utilizes the sparsity of attention to reduce the cost of attention, but poorly adapts to the content-dependent variations in attention due to their staticity. While previous work has proposed several dynamic approaches to improve flexibility, they still depend on predefined templates or heuristic mechanisms. Such strategies reduce generality and prune tokens that remain contextually important, limiting their accuracy across diverse tasks. To tackle these bottlenecks of existing methods for long-context modeling, we introduce Dynamic Hierarchical Sparse Attention (DHSA), a data-driven framework that dynamically predicts attention sparsity online without retraining. Our proposed DHSA adaptively segments sequences into variable-length chunks, then computes chunk representations by aggregating the token embeddings within each chunk. To avoid the bias introduced by varying chunk lengths, we apply length-normalized aggregation that scales the averaged embeddings by the square root of the chunk size. Finally, DHSA upsamples the chunk-level similarity scores to token level similarities to calculate importance scores that determine which token-level interactions should be preserved. Our experiments on Gemma2 with Needle-in-a-Haystack Test and LongBench show that DHSA matches dense attention in accuracy, while reducing prefill latency by 20-60% and peak memory usage by 35%. Compared to other representative baselines such as block sparse attention, DHSA achieves consistently higher accuracy (6-18% relative gains) with comparable or lower cost, offering an efficient and adaptable solution for long-context on-device LLMs.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "204",
        "title": "Zero-Shot Cross-Lingual Transfer using Prefix-Based Adaptation",
        "author": [
            "Snegha A",
            "Sayambhu Sen",
            "Piyush Singh Pasi",
            "Abhishek Singhania",
            "Preethi Jyothi"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24619",
        "abstract": "With the release of new large language models (LLMs) like Llama and Mistral, zero-shot cross-lingual transfer has become increasingly feasible due to their multilingual pretraining and strong generalization capabilities. However, adapting these decoder-only LLMs to new tasks across languages remains challenging. While parameter-efficient fine-tuning (PeFT) techniques like Low-Rank Adaptation (LoRA) are widely used, prefix-based techniques such as soft prompt tuning, prefix tuning, and Llama Adapter are less explored, especially for zero-shot transfer in decoder-only models. We present a comprehensive study of three prefix-based methods for zero-shot cross-lingual transfer from English to 35+ high- and low-resource languages. Our analysis further explores transfer across linguistic families and scripts, as well as the impact of scaling model sizes from 1B to 24B. With Llama 3.1 8B, prefix methods outperform LoRA-baselines by up to 6% on the Belebele benchmark. Similar improvements were observed with Mistral v0.3 7B as well. Despite using only 1.23M learning parameters with prefix tuning, we achieve consistent improvements across diverse benchmarks. These findings highlight the potential of prefix-based techniques as an effective and scalable alternative to LoRA, particularly in low-resource multilingual settings.",
        "tags": [
            "LLM",
            "LLaMA",
            "LoRA"
        ]
    },
    {
        "id": "205",
        "title": "GroundLoc: Efficient Large-Scale Outdoor LiDAR-Only Localization",
        "author": [
            "Nicolai Steinke",
            "Daniel Goehring"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24623",
        "abstract": "In this letter, we introduce GroundLoc, a LiDAR-only localization pipeline designed to localize a mobile robot in large-scale outdoor environments using prior maps. GroundLoc employs a Bird's-Eye View (BEV) image projection focusing on the perceived ground area and utilizes the place recognition network R2D2, or alternatively, the non-learning approach Scale-Invariant Feature Transform (SIFT), to identify and select keypoints for BEV image map registration. Our results demonstrate that GroundLoc outperforms state-of-the-art methods on the SemanticKITTI and HeLiPR datasets across various sensors. In the multi-session localization evaluation, GroundLoc reaches an Average Trajectory Error (ATE) well below 50 cm on all Ouster OS2 128 sequences while meeting online runtime requirements. The system supports various sensor models, as evidenced by evaluations conducted with Velodyne HDL-64E, Ouster OS2 128, Aeva Aeries II, and Livox Avia sensors. The prior maps are stored as 2D raster image maps, which can be created from a single drive and require only 4 MB of storage per square kilometer. The source code is available at https://github.com/dcmlr/groundloc.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "206",
        "title": "Relative Scaling Laws for LLMs",
        "author": [
            "William Held",
            "David Hall",
            "Percy Liang",
            "Diyi Yang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24626",
        "abstract": "Scaling laws describe how language models improve with additional data, parameters, and compute. While widely used, they are typically measured on aggregate test sets. Aggregate evaluations yield clean trends but average over heterogeneous subpopulations, obscuring performance disparities. We introduce relative scaling laws, which track how performance gaps between test distributions evolve with scale rather than focusing solely on absolute error. Using 255 decoder-only Transformers trained under matched-compute (IsoFLOP) budgets from $10^{18}$--$10^{20}$ FLOPs on standard pretraining datasets, we find diverse trajectories: academic domains on MMLU converge toward parity; regional English dialects shift depending on population size; and clusters of AI risk behaviours split, with capability- and influence-related risks increasing during pretraining while adversarial risks do not. These results show that although scaling improves overall performance, it is not a universal equalizer. To support further study, we release all model checkpoints from this work to enable practitioners to measure relative alongside traditional scaling laws, in order to better prioritize robustness challenges in light of the bitter lesson.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "207",
        "title": "Reduced Basis Approach for Convection-Diffusion Equations with Non-Linear Boundary Reaction Conditions",
        "author": [
            "Sebastian Matera",
            "Christian Merdon",
            "Daniel Runge"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24632",
        "abstract": "This paper aims at an efficient strategy to solve drift-diffusion problems with non-linear boundary conditions as they appear, e.g., in heterogeneous catalysis. Since the non-linearity only involves the degrees of freedom along (a part of) the boundary, a reduced basis ansatz is suggested that computes discrete Green's-like functions for the present drift-diffusion operator such that the global non-linear problem reduces to a smaller non-linear problem for a boundary method. The computed basis functions are completely independent of the non-linearities. Thus, they can be reused for problems with the same differential operator and geometry. Corresponding scenarios might be inverse problems in heterogeneous catalysis but also modeling the effect of different catalysts in the same reaction chamber. The strategy is explained for a mass-conservative finite volume method and demonstrated on a simple numerical example for catalytic CO oxidation.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "208",
        "title": "OpenReward: Learning to Reward Long-form Agentic Tasks via Reinforcement Learning",
        "author": [
            "Ziyou Hu",
            "Zhengliang Shi",
            "Minghang Zhu",
            "Haitao Li",
            "Teng Sun",
            "Pengjie Ren",
            "Suzan Verberne",
            "Zhaochun Ren"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24636",
        "abstract": "Reward models (RMs) have become essential for aligning large language models (LLMs), serving as scalable proxies for human evaluation in both training and inference. However, existing RMs struggle on knowledge-intensive and long-form tasks, where evaluating correctness requires grounding beyond the model's internal knowledge. This limitation hinders them from reliably discriminating subtle quality differences, especially when external evidence is necessary. To address this, we introduce OpenRM, a tool-augmented long-form reward model that systematically judges open-ended responses by invoking external tools to gather relevant evidence. We train OpenRM with Group Relative Policy Optimization (GRPO) on over 27K synthesized pairwise examples generated through a controllable data synthesis framework. The training objective jointly supervises intermediate tool usage and final outcome accuracy, incentivizing our reward model to learn effective evidence-based judgment strategies. Extensive experiments on three newly-collected datasets and two widely-used benchmarks demonstrate that OpenRM substantially outperforms existing reward modeling approaches. As a further step, we integrate OpenRM into both inference-time response selection and training-time data selection. This yields consistent gains in downstream LLM alignment tasks, highlighting the potential of tool-augmented reward models for scaling reliable long-form evaluation.",
        "tags": [
            "GRPO",
            "LLM",
            "RL"
        ]
    },
    {
        "id": "209",
        "title": "Causal Ordering for Structure Learning From Time Series",
        "author": [
            "Pedro P. Sanchez",
            "Damian Machlanski",
            "Steven McDonagh",
            "Sotirios A. Tsaftaris"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24639",
        "abstract": "Predicting causal structure from time series data is crucial for understanding complex phenomena in physiology, brain connectivity, climate dynamics, and socio-economic behaviour. Causal discovery in time series is hindered by the combinatorial complexity of identifying true causal relationships, especially as the number of variables and time points grow. A common approach to simplify the task is the so-called ordering-based methods. Traditional ordering methods inherently limit the representational capacity of the resulting model. In this work, we fix this issue by leveraging multiple valid causal orderings, instead of a single one as standard practice. We propose DOTS (Diffusion Ordered Temporal Structure), using diffusion-based causal discovery for temporal data. By integrating multiple orderings, DOTS effectively recovers the transitive closure of the underlying directed acyclic graph, mitigating spurious artifacts inherent in single-ordering approaches. We formalise the problem under standard assumptions such as stationarity and the additive noise model, and leverage score matching with diffusion processes to enable efficient Hessian estimation. Extensive experiments validate the approach. Empirical evaluations on synthetic and real-world datasets demonstrate that DOTS outperforms state-of-the-art baselines, offering a scalable and robust approach to temporal causal discovery. On synthetic benchmarks ($d{=}\\!3-\\!6$ variables, $T{=}200\\!-\\!5{,}000$ samples), DOTS improves mean window-graph $F1$ from $0.63$ (best baseline) to $0.81$. On the CausalTime real-world benchmark ($d{=}20\\!-\\!36$), while baselines remain the best on individual datasets, DOTS attains the highest average summary-graph $F1$ while halving runtime relative to graph-optimisation methods. These results establish DOTS as a scalable and accurate solution for temporal causal discovery.",
        "tags": [
            "Diffusion",
            "Score Matching"
        ]
    },
    {
        "id": "210",
        "title": "A Dual-Branch CNN for Robust Detection of AI-Generated Facial Forgeries",
        "author": [
            "Xin Zhang",
            "Yuqi Song",
            "Fei Zuo"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24640",
        "abstract": "The rapid advancement of generative AI has enabled the creation of highly realistic forged facial images, posing significant threats to AI security, digital media integrity, and public trust. Face forgery techniques, ranging from face swapping and attribute editing to powerful diffusion-based image synthesis, are increasingly being used for malicious purposes such as misinformation, identity fraud, and defamation. This growing challenge underscores the urgent need for robust and generalizable face forgery detection methods as a critical component of AI security infrastructure. In this work, we propose a novel dual-branch convolutional neural network for face forgery detection that leverages complementary cues from both spatial and frequency domains. The RGB branch captures semantic information, while the frequency branch focuses on high-frequency artifacts that are difficult for generative models to suppress. A channel attention module is introduced to adaptively fuse these heterogeneous features, highlighting the most informative channels for forgery discrimination. To guide the network's learning process, we design a unified loss function, FSC Loss, that combines focal loss, supervised contrastive loss, and a frequency center margin loss to enhance class separability and robustness. We evaluate our model on the DiFF benchmark, which includes forged images generated from four representative methods: text-to-image, image-to-image, face swap, and face edit. Our method achieves strong performance across all categories and outperforms average human accuracy. These results demonstrate the model's effectiveness and its potential contribution to safeguarding AI ecosystems against visual forgery attacks.",
        "tags": [
            "Detection",
            "Diffusion",
            "Text-to-Image"
        ]
    },
    {
        "id": "211",
        "title": "FunReason-MT Technical Report: Overcoming the Complexity Barrier in Multi-Turn Function Calling",
        "author": [
            "Zengzhuang Xu",
            "Bingguang Hao",
            "Zechuan Wang",
            "Yuntao Wen",
            "Maolin Wang",
            "Yang Liu",
            "Long Chen",
            "Dong Wang",
            "Yicheng Chen",
            "Cunyin Peng",
            "Chenyi Zhuang",
            "Jinjie Gu",
            "Leilei Gan",
            "Xiangyu Zhao",
            "Shi Gu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24645",
        "abstract": "Function calling (FC) empowers large language models (LLMs) and autonomous agents to interface with external tools, a critical capability for solving complex, real-world problems. As this ability becomes increasingly central to advanced AI systems, the need for high-quality, multi-turn training data to develop and refine it cannot be overstated. Existing data synthesis methods, such as random environment sampling or multi-agent role-playing, are not powerful enough to generate high-quality data in real-world environments. Practical challenges come in three folds: targeted model training, isolation of tool architecture, and multi-turn logical dependency. To address these structural deficiencies, we present FunReason-MT, a novel data synthesis framework for real-world multi-turn tool use. FunReason-MT resolves the complexity barrier in multi-turn FC data by employing 1) Environment-API Graph Interactions to gather varied high-quality trajectories, 2) Advanced Tool-Query Synthesis to simplify hard query construction, and 3) Guided Iterative Chain for sophisticated CoT generation. Evaluations on Berkeley Function-Calling Leaderboard (BFCLv3) demonstrate the power of our framework: a 4B model built upon FunReason-MT generated data achieves state-of-the-art performance among comparable-sized models, outperforming most close-source models. Further performance improvements on BFCLv4 confirm that FunReason-MT provides a reliable and robust source for agentic learning.",
        "tags": [
            "CoT",
            "LLM"
        ]
    },
    {
        "id": "212",
        "title": "Optimizing Retrieval for RAG via Reinforced Contrastive Learning",
        "author": [
            "Jiawei Zhou",
            "Lei Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24652",
        "abstract": "As retrieval-augmented generation (RAG) becomes increasingly widespread, the role of information retrieval (IR) is shifting from retrieving information for human users to retrieving contextual knowledge for artificial intelligence (AI) systems, where relevance becomes difficult to define or annotate beforehand. To address this challenge, we propose R3, a Retrieval framework optimized for RAG through trialand-feedback Reinforced contrastive learning. Unlike prior approaches that rely on annotated or synthetic data for supervised fine-tuning, R3 enables the retriever to dynamically explore and optimize relevance within the RAG environment. During training, the retrieved results interact with the environment to produce contrastive signals that automatically guide the retriever's self-improvement. Extensive experiments across diverse tasks demonstrate that R3 improves RAG performance by 5.2% over the original retriever and surpasses state-of-the-art retrievers by 4.9%, while achieving comparable results to LLM-augmented retrieval and RAG systems built on post-trained or instruction-tuned LLMs. It is both efficient and practical, requiring only 4 GPUs and completing training within a single day.",
        "tags": [
            "LLM",
            "RAG"
        ]
    },
    {
        "id": "213",
        "title": "Group Relative Attention Guidance for Image Editing",
        "author": [
            "Xuanpu Zhang",
            "Xuesong Niu",
            "Ruidong Chen",
            "Dan Song",
            "Jianhao Zeng",
            "Penghui Du",
            "Haoxiang Cao",
            "Kai Wu",
            "An-an Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24657",
        "abstract": "Recently, image editing based on Diffusion-in-Transformer models has undergone rapid development. However, existing editing methods often lack effective control over the degree of editing, limiting their ability to achieve more customized results. To address this limitation, we investigate the MM-Attention mechanism within the DiT model and observe that the Query and Key tokens share a bias vector that is only layer-dependent. We interpret this bias as representing the model's inherent editing behavior, while the delta between each token and its corresponding bias encodes the content-specific editing signals. Based on this insight, we propose Group Relative Attention Guidance, a simple yet effective method that reweights the delta values of different tokens to modulate the focus of the model on the input image relative to the editing instruction, enabling continuous and fine-grained control over editing intensity without any tuning. Extensive experiments conducted on existing image editing frameworks demonstrate that GRAG can be integrated with as few as four lines of code, consistently enhancing editing quality. Moreover, compared to the commonly used Classifier-Free Guidance, GRAG achieves smoother and more precise control over the degree of editing. Our code will be released at https://github.com/little-misfit/GRAG-Image-Editing.",
        "tags": [
            "DiT",
            "Diffusion",
            "Image Editing",
            "Transformer"
        ]
    },
    {
        "id": "214",
        "title": "OrchDAG: Complex Tool Orchestration in Multi-Turn Interactions with Plan DAGs",
        "author": [
            "Yifu Lu",
            "Shengjie Liu",
            "Li Dong"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24663",
        "abstract": "Agentic tool use has gained traction with the rise of agentic tool calling, yet most existing work overlooks the complexity of multi-turn tool interactions. We introduce OrchDAG, a synthetic data generation pipeline that models tool execution as directed acyclic graphs (DAGs) with controllable complexity. Using this dataset, we benchmark model performance and propose a graph-based reward to enhance RLVR training. Experiments show that the dataset presents a challenging but solvable benchmark, and the proposed reward is effective when combined with GRPO-style algorithms, highlighting the importance of leveraging topological structure and data complexity in multi-turn tool use.",
        "tags": [
            "GRPO"
        ]
    },
    {
        "id": "215",
        "title": "Multi-Agent Scenario Generation in Roundabouts with a Transformer-enhanced Conditional Variational Autoencoder",
        "author": [
            "Li Li",
            "Tobias Brinkmann",
            "Till Temmen",
            "Markus Eisenbarth",
            "Jakob Andert"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24671",
        "abstract": "With the increasing integration of intelligent driving functions into serial-produced vehicles, ensuring their functionality and robustness poses greater challenges. Compared to traditional road testing, scenario-based virtual testing offers significant advantages in terms of time and cost efficiency, reproducibility, and exploration of edge cases. We propose a Transformer-enhanced Conditional Variational Autoencoder (CVAE-T) model for generating multi-agent traffic scenarios in roundabouts, which are characterized by high vehicle dynamics and complex layouts, yet remain relatively underexplored in current research. The results show that the proposed model can accurately reconstruct original scenarios and generate realistic, diverse synthetic scenarios. Besides, two Key-Performance-Indicators (KPIs) are employed to evaluate the interactive behavior in the generated scenarios. Analysis of the latent space reveals partial disentanglement, with several latent dimensions exhibiting distinct and interpretable effects on scenario attributes such as vehicle entry timing, exit timing, and velocity profiles. The results demonstrate the model's capability to generate scenarios for the validation of intelligent driving functions involving multi-agent interactions, as well as to augment data for their development and iterative improvement.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "216",
        "title": "Learning to Drive Safely with Hybrid Options",
        "author": [
            "Bram De Cooman",
            "Johan Suykens"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24674",
        "abstract": "Out of the many deep reinforcement learning approaches for autonomous driving, only few make use of the options (or skills) framework. That is surprising, as this framework is naturally suited for hierarchical control applications in general, and autonomous driving tasks in specific. Therefore, in this work the options framework is applied and tailored to autonomous driving tasks on highways. More specifically, we define dedicated options for longitudinal and lateral manoeuvres with embedded safety and comfort constraints. This way, prior domain knowledge can be incorporated into the learning process and the learned driving behaviour can be constrained more easily. We propose several setups for hierarchical control with options and derive practical algorithms following state-of-the-art reinforcement learning techniques. By separately selecting actions for longitudinal and lateral control, the introduced policies over combined and hybrid options obtain the same expressiveness and flexibility that human drivers have, while being easier to interpret than classical policies over continuous actions. Of all the investigated approaches, these flexible policies over hybrid options perform the best under varying traffic conditions, outperforming the baseline policies over actions.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "217",
        "title": "A Framework for the Systematic Evaluation of Obstacle Avoidance and Object-Aware Controllers",
        "author": [
            "Caleb Escobedo",
            "Nataliya Nechyporenko",
            "Shreyas Kadekodi",
            "Alessandro Roncone"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24683",
        "abstract": "Real-time control is an essential aspect of safe robot operation in the real world with dynamic objects. We present a framework for the analysis of object-aware controllers, methods for altering a robot's motion to anticipate and avoid possible collisions. This framework is focused on three design considerations: kinematics, motion profiles, and virtual constraints. Additionally, the analysis in this work relies on verification of robot behaviors using fundamental robot-obstacle experimental scenarios. To showcase the effectiveness of our method we compare three representative object-aware controllers. The comparison uses metrics originating from the design considerations. From the analysis, we find that the design of object-aware controllers often lacks kinematic considerations, continuity of control points, and stability in movement profiles. We conclude that this framework can be used in the future to design, compare, and benchmark obstacle avoidance methods.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "218",
        "title": "SPICE: Self-Play In Corpus Environments Improves Reasoning",
        "author": [
            "Bo Liu",
            "Chuanyang Jin",
            "Seungone Kim",
            "Weizhe Yuan",
            "Wenting Zhao",
            "Ilia Kulikov",
            "Xian Li",
            "Sainbayar Sukhbaatar",
            "Jack Lanchantin",
            "Jason Weston"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24684",
        "abstract": "Self-improving systems require environmental interaction for continuous adaptation. We introduce SPICE (Self-Play In Corpus Environments), a reinforcement learning framework where a single model acts in two roles: a Challenger that mines documents from a large corpus to generate diverse reasoning tasks, and a Reasoner that solves them. Through adversarial dynamics, the Challenger creates an automatic curriculum at the frontier of the Reasoner's capability, while corpus grounding provides the rich, near-inexhaustible external signal necessary for sustained improvement. Unlike existing ungrounded self-play methods that offer more limited benefits, SPICE achieves consistent gains across mathematical (+8.9%) and general reasoning (+9.8%) benchmarks on multiple model families. Our analysis reveals how document grounding is a key ingredient in SPICE to continuously generate its own increasingly challenging goals and achieve them, enabling sustained self-improvement.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "219",
        "title": "MIC-BEV: Multi-Infrastructure Camera Bird's-Eye-View Transformer with Relation-Aware Fusion for 3D Object Detection",
        "author": [
            "Yun Zhang",
            "Zhaoliang Zheng",
            "Johnson Liu",
            "Zhiyu Huang",
            "Zewei Zhou",
            "Zonglin Meng",
            "Tianhui Cai",
            "Jiaqi Ma"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24688",
        "abstract": "Infrastructure-based perception plays a crucial role in intelligent transportation systems, offering global situational awareness and enabling cooperative autonomy. However, existing camera-based detection models often underperform in such scenarios due to challenges such as multi-view infrastructure setup, diverse camera configurations, degraded visual inputs, and various road layouts. We introduce MIC-BEV, a Transformer-based bird's-eye-view (BEV) perception framework for infrastructure-based multi-camera 3D object detection. MIC-BEV flexibly supports a variable number of cameras with heterogeneous intrinsic and extrinsic parameters and demonstrates strong robustness under sensor degradation. The proposed graph-enhanced fusion module in MIC-BEV integrates multi-view image features into the BEV space by exploiting geometric relationships between cameras and BEV cells alongside latent visual cues. To support training and evaluation, we introduce M2I, a synthetic dataset for infrastructure-based object detection, featuring diverse camera configurations, road layouts, and environmental conditions. Extensive experiments on both M2I and the real-world dataset RoScenes demonstrate that MIC-BEV achieves state-of-the-art performance in 3D object detection. It also remains robust under challenging conditions, including extreme weather and sensor degradation. These results highlight the potential of MIC-BEV for real-world deployment. The dataset and source code are available at: https://github.com/HandsomeYun/MIC-BEV.",
        "tags": [
            "3D",
            "Detection",
            "Transformer"
        ]
    },
    {
        "id": "220",
        "title": "Embodying Physical Computing into Soft Robots",
        "author": [
            "Jun Wang",
            "Ziyang Zhou",
            "Ardalan Kahak",
            "Suyi Li"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24692",
        "abstract": "Softening and onboarding computers and controllers is one of the final frontiers in soft robotics towards their robustness and intelligence for everyday use. In this regard, embodying soft and physical computing presents exciting potential. Physical computing seeks to encode inputs into a mechanical computing kernel and leverage the internal interactions among this kernel's constituent elements to compute the output. Moreover, such input-to-output evolution can be re-programmable. This perspective paper proposes a framework for embodying physical computing into soft robots and discusses three unique strategies in the literature: analog oscillators, physical reservoir computing, and physical algorithmic computing. These embodied computers enable the soft robot to perform complex behaviors that would otherwise require CMOS-based electronics -- including coordinated locomotion with obstacle avoidance, payload weight and orientation classification, and programmable operation based on logical rules. This paper will detail the working principles of these embodied physical computing methods, survey the current state-of-the-art, and present a perspective for future development.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "221",
        "title": "STAR-Bench: Probing Deep Spatio-Temporal Reasoning as Audio 4D Intelligence",
        "author": [
            "Zihan Liu",
            "Zhikang Niu",
            "Qiuyang Xiao",
            "Zhisheng Zheng",
            "Ruoqi Yuan",
            "Yuhang Zang",
            "Yuhang Cao",
            "Xiaoyi Dong",
            "Jianze Liang",
            "Xie Chen",
            "Leilei Sun",
            "Dahua Lin",
            "Jiaqi Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24693",
        "abstract": "Despite rapid progress in Multi-modal Large Language Models and Large Audio-Language Models, existing audio benchmarks largely test semantics that can be recovered from text captions, masking deficits in fine-grained perceptual reasoning. We formalize audio 4D intelligence that is defined as reasoning over sound dynamics in time and 3D space, and introduce STAR-Bench to measure it. STAR-Bench combines a Foundational Acoustic Perception setting (six attributes under absolute and relative regimes) with a Holistic Spatio-Temporal Reasoning setting that includes segment reordering for continuous and discrete processes and spatial tasks spanning static localization, multi-source relations, and dynamic trajectories. Our data curation pipeline uses two methods to ensure high-quality samples. For foundational tasks, we use procedurally synthesized and physics-simulated audio. For holistic data, we follow a four-stage process that includes human annotation and final selection based on human performance. Unlike prior benchmarks where caption-only answering reduces accuracy slightly, STAR-Bench induces far larger drops (-31.5\\% temporal, -35.2\\% spatial), evidencing its focus on linguistically hard-to-describe cues. Evaluating 19 models reveals substantial gaps compared with humans and a capability hierarchy: closed-source models are bottlenecked by fine-grained perception, while open-source models lag across perception, knowledge, and reasoning. Our STAR-Bench provides critical insights and a clear path forward for developing future models with a more robust understanding of the physical world.",
        "tags": [
            "3D",
            "LLM"
        ]
    },
    {
        "id": "222",
        "title": "Repurposing Synthetic Data for Fine-grained Search Agent Supervision",
        "author": [
            "Yida Zhao",
            "Kuan Li",
            "Xixi Wu",
            "Liwen Zhang",
            "Dingchu Zhang",
            "Baixuan Li",
            "Maojia Song",
            "Zhuo Chen",
            "Chenxi Wang",
            "Xinyu Wang",
            "Kewei Tu",
            "Pengjun Xie",
            "Jingren Zhou",
            "Yong Jiang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24694",
        "abstract": "LLM-based search agents are increasingly trained on entity-centric synthetic data to solve complex, knowledge-intensive tasks. However, prevailing training methods like Group Relative Policy Optimization (GRPO) discard this rich entity information, relying instead on sparse, outcome-based rewards. This critical limitation renders them unable to distinguish informative \"near-miss\" samples-those with substantially correct reasoning but a flawed final answer-from complete failures, thus discarding valuable learning signals. We address this by leveraging the very entities discarded during training. Our empirical analysis reveals a strong positive correlation between the number of ground-truth entities identified during an agent's reasoning process and final answer accuracy. Building on this insight, we introduce Entity-aware Group Relative Policy Optimization (E-GRPO), a novel framework that formulates a dense entity-aware reward function. E-GRPO assigns partial rewards to incorrect samples proportional to their entity match rate, enabling the model to effectively learn from these \"near-misses\". Experiments on diverse question-answering (QA) and deep research benchmarks show that E-GRPO consistently and significantly outperforms the GRPO baseline. Furthermore, our analysis reveals that E-GRPO not only achieves superior accuracy but also induces more efficient reasoning policies that require fewer tool calls, demonstrating a more effective and sample-efficient approach to aligning search agents.",
        "tags": [
            "GRPO",
            "LLM"
        ]
    },
    {
        "id": "223",
        "title": "AgentFrontier: Expanding the Capability Frontier of LLM Agents with ZPD-Guided Data Synthesis",
        "author": [
            "Xuanzhong Chen",
            "Zile Qiao",
            "Guoxin Chen",
            "Liangcai Su",
            "Zhen Zhang",
            "Xinyu Wang",
            "Pengjun Xie",
            "Fei Huang",
            "Jingren Zhou",
            "Yong Jiang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24695",
        "abstract": "Training large language model agents on tasks at the frontier of their capabilities is key to unlocking advanced reasoning. We introduce a data synthesis approach inspired by the educational theory of the Zone of Proximal Development (ZPD), which defines this frontier as tasks an LLM cannot solve alone but can master with guidance. To operationalize this, we present the AgentFrontier Engine, an automated pipeline that synthesizes high-quality, multidisciplinary data situated precisely within the LLM's ZPD. This engine supports both continued pre-training with knowledge-intensive data and targeted post-training on complex reasoning tasks. From the same framework, we derive the ZPD Exam, a dynamic and automated benchmark designed to evaluate agent capabilities on these frontier tasks. We train AgentFrontier-30B-A3B model on our synthesized data, which achieves state-of-the-art results on demanding benchmarks like Humanity's Last Exam, even surpassing some leading proprietary agents. Our work demonstrates that a ZPD-guided approach to data synthesis offers a scalable and effective path toward building more capable LLM agents.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "224",
        "title": "WebLeaper: Empowering Efficiency and Efficacy in WebAgent via Enabling Info-Rich Seeking",
        "author": [
            "Zhengwei Tao",
            "Haiyang Shen",
            "Baixuan Li",
            "Wenbiao Yin",
            "Jialong Wu",
            "Kuan Li",
            "Zhongwang Zhang",
            "Huifeng Yin",
            "Rui Ye",
            "Liwen Zhang",
            "Xinyu Wang",
            "Pengjun Xie",
            "Jingren Zhou",
            "Yong Jiang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24697",
        "abstract": "Large Language Model (LLM)-based agents have emerged as a transformative approach for open-ended problem solving, with information seeking (IS) being a core capability that enables autonomous reasoning and decision-making. While prior research has largely focused on improving retrieval depth, we observe that current IS agents often suffer from low search efficiency, which in turn constrains overall performance. A key factor underlying this inefficiency is the sparsity of target entities in training tasks, which limits opportunities for agents to learn and generalize efficient search behaviors. To address these challenges, we propose WebLeaper, a framework for constructing high-coverage IS tasks and generating efficient solution trajectories. We formulate IS as a tree-structured reasoning problem, enabling a substantially larger set of target entities to be embedded within a constrained context. Leveraging curated Wikipedia tables, we propose three variants for synthesizing IS tasks, Basic, Union, and Reverse-Union, to systematically increase both IS efficiency and efficacy. Finally, we curate training trajectories by retaining only those that are simultaneously accurate and efficient, ensuring that the model is optimized for both correctness and search performance. Extensive experiments on both basic and comprehensive settings, conducted on five IS benchmarks, BrowserComp, GAIA, xbench-DeepSearch, WideSearch, and Seal-0, demonstrate that our method consistently achieves improvements in both effectiveness and efficiency over strong baselines.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "225",
        "title": "AgentFold: Long-Horizon Web Agents with Proactive Context Management",
        "author": [
            "Rui Ye",
            "Zhongwang Zhang",
            "Kuan Li",
            "Huifeng Yin",
            "Zhengwei Tao",
            "Yida Zhao",
            "Liangcai Su",
            "Liwen Zhang",
            "Zile Qiao",
            "Xinyu Wang",
            "Pengjun Xie",
            "Fei Huang",
            "Siheng Chen",
            "Jingren Zhou",
            "Yong Jiang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24699",
        "abstract": "LLM-based web agents show immense promise for information seeking, yet their effectiveness on long-horizon tasks is hindered by a fundamental trade-off in context management. Prevailing ReAct-based agents suffer from context saturation as they accumulate noisy, raw histories, while methods that fixedly summarize the full history at each step risk the irreversible loss of critical details. Addressing these, we introduce AgentFold, a novel agent paradigm centered on proactive context management, inspired by the human cognitive process of retrospective consolidation. AgentFold treats its context as a dynamic cognitive workspace to be actively sculpted, rather than a passive log to be filled. At each step, it learns to execute a `folding' operation, which manages its historical trajectory at multiple scales: it can perform granular condensations to preserve vital, fine-grained details, or deep consolidations to abstract away entire multi-step sub-tasks. The results on prominent benchmarks are striking: with simple supervised fine-tuning (without continual pre-training or RL), our AgentFold-30B-A3B agent achieves 36.2% on BrowseComp and 47.3% on BrowseComp-ZH. Notably, this performance not only surpasses or matches open-source models of a dramatically larger scale, such as the DeepSeek-V3.1-671B-A37B, but also surpasses leading proprietary agents like OpenAI's o4-mini.",
        "tags": [
            "DeepSeek",
            "LLM",
            "RL"
        ]
    },
    {
        "id": "226",
        "title": "Greedy Sampling Is Provably Efficient for RLHF",
        "author": [
            "Di Wu",
            "Chengshuai Shi",
            "Jing Yang",
            "Cong Shen"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24700",
        "abstract": "Reinforcement Learning from Human Feedback (RLHF) has emerged as a key technique for post-training large language models. Despite its empirical success, the theoretical understanding of RLHF is still limited, as learning the KL-regularized target with only preference feedback poses additional challenges compared with canonical RL. Existing works mostly study the reward-based Bradley-Terry (BT) preference model, and extend classical designs utilizing optimism or pessimism. This work, instead, considers the general preference model (whose practical relevance has been observed recently) and obtains performance guarantees with major, order-wise improvements over existing ones. Surprisingly, these results are derived from algorithms that directly use the empirical estimates (i.e., greedy sampling), as opposed to constructing optimistic or pessimistic estimates in previous works. This insight has a deep root in the unique structural property of the optimal policy class under the KL-regularized target, and we further specialize it to the BT model, highlighting the surprising sufficiency of greedy sampling in RLHF.",
        "tags": [
            "LLM",
            "RL",
            "RLHF"
        ]
    },
    {
        "id": "227",
        "title": "Agent Data Protocol: Unifying Datasets for Diverse, Effective Fine-tuning of LLM Agents",
        "author": [
            "Yueqi Song",
            "Ketan Ramaneti",
            "Zaid Sheikh",
            "Ziru Chen",
            "Boyu Gou",
            "Tianbao Xie",
            "Yiheng Xu",
            "Danyang Zhang",
            "Apurva Gandhi",
            "Fan Yang",
            "Joseph Liu",
            "Tianyue Ou",
            "Zhihao Yuan",
            "Frank Xu",
            "Shuyan Zhou",
            "Xingyao Wang",
            "Xiang Yue",
            "Tao Yu",
            "Huan Sun",
            "Yu Su",
            "Graham Neubig"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24702",
        "abstract": "Public research results on large-scale supervised finetuning of AI agents remain relatively rare, since the collection of agent training data presents unique challenges. In this work, we argue that the bottleneck is not a lack of underlying data sources, but that a large variety of data is fragmented across heterogeneous formats, tools, and interfaces. To this end, we introduce the agent data protocol (ADP), a light-weight representation language that serves as an \"interlingua\" between agent datasets in diverse formats and unified agent training pipelines downstream. The design of ADP is expressive enough to capture a large variety of tasks, including API/tool use, browsing, coding, software engineering, and general agentic workflows, while remaining simple to parse and train on without engineering at a per-dataset level. In experiments, we unified a broad collection of 13 existing agent training datasets into ADP format, and converted the standardized ADP data into training-ready formats for multiple agent frameworks. We performed SFT on these data, and demonstrated an average performance gain of ~20% over corresponding base models, and delivers state-of-the-art or near-SOTA performance on standard coding, browsing, tool use, and research benchmarks, without domain-specific tuning. All code and data are released publicly, in the hope that ADP could help lower the barrier to standardized, scalable, and reproducible agent training.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "228",
        "title": "ComboBench: Can LLMs Manipulate Physical Devices to Play Virtual Reality Games?",
        "author": [
            "Shuqing Li",
            "Jiayi Yan",
            "Chenyu Niu",
            "Jen-tse Huang",
            "Yun Peng",
            "Wenxuan Wang",
            "Yepang Liu",
            "Michael R. Lyu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24706",
        "abstract": "Virtual Reality (VR) games require players to translate high-level semantic actions into precise device manipulations using controllers and head-mounted displays (HMDs). While humans intuitively perform this translation based on common sense and embodied understanding, whether Large Language Models (LLMs) can effectively replicate this ability remains underexplored. This paper introduces a benchmark, ComboBench, evaluating LLMs' capability to translate semantic actions into VR device manipulation sequences across 262 scenarios from four popular VR games: Half-Life: Alyx, Into the Radius, Moss: Book II, and Vivecraft. We evaluate seven LLMs, including GPT-3.5, GPT-4, GPT-4o, Gemini-1.5-Pro, LLaMA-3-8B, Mixtral-8x7B, and GLM-4-Flash, compared against annotated ground truth and human performance. Our results reveal that while top-performing models like Gemini-1.5-Pro demonstrate strong task decomposition capabilities, they still struggle with procedural reasoning and spatial understanding compared to humans. Performance varies significantly across games, suggesting sensitivity to interaction complexity. Few-shot examples substantially improve performance, indicating potential for targeted enhancement of LLMs' VR manipulation capabilities. We release all materials at https://sites.google.com/view/combobench.",
        "tags": [
            "GLM",
            "GPT",
            "LLM",
            "LLaMA"
        ]
    },
    {
        "id": "229",
        "title": "Does Object Binding Naturally Emerge in Large Pretrained Vision Transformers?",
        "author": [
            "Yihao Li",
            "Saeed Salehi",
            "Lyle Ungar",
            "Konrad P. Kording"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24709",
        "abstract": "Object binding, the brain's ability to bind the many features that collectively represent an object into a coherent whole, is central to human cognition. It groups low-level perceptual features into high-level object representations, stores those objects efficiently and compositionally in memory, and supports human reasoning about individual object instances. While prior work often imposes object-centric attention (e.g., Slot Attention) explicitly to probe these benefits, it remains unclear whether this ability naturally emerges in pre-trained Vision Transformers (ViTs). Intuitively, they could: recognizing which patches belong to the same object should be useful for downstream prediction and thus guide attention. Motivated by the quadratic nature of self-attention, we hypothesize that ViTs represent whether two patches belong to the same object, a property we term IsSameObject. We decode IsSameObject from patch embeddings across ViT layers using a similarity probe, which reaches over 90% accuracy. Crucially, this object-binding capability emerges reliably in self-supervised ViTs (DINO, MAE, CLIP), but markedly weaker in ImageNet-supervised models, suggesting that binding is not a trivial architectural artifact, but an ability acquired through specific pretraining objectives. We further discover that IsSameObject is encoded in a low-dimensional subspace on top of object features, and that this signal actively guides attention. Ablating IsSameObject from model activations degrades downstream performance and works against the learning objective, implying that emergent object binding naturally serves the pretraining objective. Our findings challenge the view that ViTs lack object binding and highlight how symbolic knowledge of \"which parts belong together\" emerges naturally in a connectionist system.",
        "tags": [
            "CLIP",
            "ViT"
        ]
    },
    {
        "id": "230",
        "title": "Routing Matters in MoE: Scaling Diffusion Transformers with Explicit Routing Guidance",
        "author": [
            "Yujie Wei",
            "Shiwei Zhang",
            "Hangjie Yuan",
            "Yujin Han",
            "Zhekai Chen",
            "Jiayu Wang",
            "Difan Zou",
            "Xihui Liu",
            "Yingya Zhang",
            "Yu Liu",
            "Hongming Shan"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24711",
        "abstract": "Mixture-of-Experts (MoE) has emerged as a powerful paradigm for scaling model capacity while preserving computational efficiency. Despite its notable success in large language models (LLMs), existing attempts to apply MoE to Diffusion Transformers (DiTs) have yielded limited gains. We attribute this gap to fundamental differences between language and visual tokens. Language tokens are semantically dense with pronounced inter-token variation, while visual tokens exhibit spatial redundancy and functional heterogeneity, hindering expert specialization in vision MoE. To this end, we present ProMoE, an MoE framework featuring a two-step router with explicit routing guidance that promotes expert specialization. Specifically, this guidance encourages the router to partition image tokens into conditional and unconditional sets via conditional routing according to their functional roles, and refine the assignments of conditional image tokens through prototypical routing with learnable prototypes based on semantic content. Moreover, the similarity-based expert allocation in latent space enabled by prototypical routing offers a natural mechanism for incorporating explicit semantic guidance, and we validate that such guidance is crucial for vision MoE. Building on this, we propose a routing contrastive loss that explicitly enhances the prototypical routing process, promoting intra-expert coherence and inter-expert diversity. Extensive experiments on ImageNet benchmark demonstrate that ProMoE surpasses state-of-the-art methods under both Rectified Flow and DDPM training objectives. Code and models will be made publicly available.",
        "tags": [
            "DDPM",
            "Diffusion",
            "LLM",
            "MoE",
            "Rectified Flow"
        ]
    },
    {
        "id": "231",
        "title": "Uniform Discrete Diffusion with Metric Path for Video Generation",
        "author": [
            "Haoge Deng",
            "Ting Pan",
            "Fan Zhang",
            "Yang Liu",
            "Zhuoyan Luo",
            "Yufeng Cui",
            "Wenxuan Wang",
            "Chunhua Shen",
            "Shiguang Shan",
            "Zhaoxiang Zhang",
            "Xinlong Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24717",
        "abstract": "Continuous-space video generation has advanced rapidly, while discrete approaches lag behind due to error accumulation and long-context inconsistency. In this work, we revisit discrete generative modeling and present Uniform discRete diffuSion with metric pAth (URSA), a simple yet powerful framework that bridges the gap with continuous approaches for the scalable video generation. At its core, URSA formulates the video generation task as an iterative global refinement of discrete spatiotemporal tokens. It integrates two key designs: a Linearized Metric Path and a Resolution-dependent Timestep Shifting mechanism. These designs enable URSA to scale efficiently to high-resolution image synthesis and long-duration video generation, while requiring significantly fewer inference steps. Additionally, we introduce an asynchronous temporal fine-tuning strategy that unifies versatile tasks within a single model, including interpolation and image-to-video generation. Extensive experiments on challenging video and image generation benchmarks demonstrate that URSA consistently outperforms existing discrete methods and achieves performance comparable to state-of-the-art continuous diffusion methods. Code and models are available at https://github.com/baaivision/URSA",
        "tags": [
            "Diffusion",
            "Video Generation"
        ]
    },
    {
        "id": "232",
        "title": "Generative View Stitching",
        "author": [
            "Chonghyuk Song",
            "Michal Stary",
            "Boyuan Chen",
            "George Kopanas",
            "Vincent Sitzmann"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24718",
        "abstract": "Autoregressive video diffusion models are capable of long rollouts that are stable and consistent with history, but they are unable to guide the current generation with conditioning from the future. In camera-guided video generation with a predefined camera trajectory, this limitation leads to collisions with the generated scene, after which autoregression quickly collapses. To address this, we propose Generative View Stitching (GVS), which samples the entire sequence in parallel such that the generated scene is faithful to every part of the predefined camera trajectory. Our main contribution is a sampling algorithm that extends prior work on diffusion stitching for robot planning to video generation. While such stitching methods usually require a specially trained model, GVS is compatible with any off-the-shelf video model trained with Diffusion Forcing, a prevalent sequence diffusion framework that we show already provides the affordances necessary for stitching. We then introduce Omni Guidance, a technique that enhances the temporal consistency in stitching by conditioning on both the past and future, and that enables our proposed loop-closing mechanism for delivering long-range coherence. Overall, GVS achieves camera-guided video generation that is stable, collision-free, frame-to-frame consistent, and closes loops for a variety of predefined camera paths, including Oscar ReutersvÃ¤rd's Impossible Staircase. Results are best viewed as videos at https://andrewsonga.github.io/gvs.",
        "tags": [
            "Diffusion",
            "Robotics",
            "Video Generation"
        ]
    },
    {
        "id": "233",
        "title": "What Work is AI Actually Doing? Uncovering the Drivers of Generative AI Adoption",
        "author": [
            "Peeyush Agarwal",
            "Harsh Agarwal",
            "Akshat Ranaa"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23669",
        "abstract": "Purpose: The rapid integration of artificial intelligence (AI) systems like ChatGPT, Claude AI, etc., has a deep impact on how work is done. Predicting how AI will reshape work requires understanding not just its capabilities, but how it is actually being adopted. This study investigates which intrinsic task characteristics drive users' decisions to delegate work to AI systems. Methodology: This study utilizes the Anthropic Economic Index dataset of four million Claude AI interactions mapped to O*NET tasks. We systematically scored each task across seven key dimensions: Routine, Cognitive, Social Intelligence, Creativity, Domain Knowledge, Complexity, and Decision Making using 35 parameters. We then employed multivariate techniques to identify latent task archetypes and analyzed their relationship with AI usage. Findings: Tasks requiring high creativity, complexity, and cognitive demand, but low routineness, attracted the most AI engagement. Furthermore, we identified three task archetypes: Dynamic Problem Solving, Procedural & Analytical Work, and Standardized Operational Tasks, demonstrating that AI applicability is best predicted by a combination of task characteristics, over individual factors. Our analysis revealed highly concentrated AI usage patterns, with just 5% of tasks accounting for 59% of all interactions. Originality: This research provides the first systematic evidence linking real-world generative AI usage to a comprehensive, multi-dimensional framework of intrinsic task characteristics. It introduces a data-driven classification of work archetypes that offers a new framework for analyzing the emerging human-AI division of labor.",
        "tags": [
            "GPT"
        ]
    },
    {
        "id": "234",
        "title": "Inferring Group Intent as a Cooperative Game. An NLP-based Framework for Trajectory Analysis using Graph Transformer Neural Network",
        "author": [
            "Yiming Zhang",
            "Vikram Krishnamurthy",
            "Shashwat Jain"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23905",
        "abstract": "This paper studies group target trajectory intent as the outcome of a cooperative game where the complex-spatio trajectories are modeled using an NLP-based generative model. In our framework, the group intent is specified by the characteristic function of a cooperative game, and allocations for players in the cooperative game are specified by either the core, the Shapley value, or the nucleolus. The resulting allocations induce probability distributions that govern the coordinated spatio-temporal trajectories of the targets that reflect the group's underlying intent. We address two key questions: (1) How can the intent of a group trajectory be optimally formalized as the characteristic function of a cooperative game? (2) How can such intent be inferred from noisy observations of the targets? To answer the first question, we introduce a Fisher-information-based characteristic function of the cooperative game, which yields probability distributions that generate coordinated spatio-temporal patterns. As a generative model for these patterns, we develop an NLP-based generative model built on formal grammar, enabling the creation of realistic multi-target trajectory data. To answer the second question, we train a Graph Transformer Neural Network (GTNN) to infer group trajectory intent-expressed as the characteristic function of the cooperative game-from observational data with high accuracy. The self-attention function of the GTNN depends on the track estimates. Thus, the formulation and algorithms provide a multi-layer approach that spans target tracking (Bayesian signal processing) and the GTNN (for group intent inference).",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "235",
        "title": "Score-based constrained generative modeling via Langevin diffusions with boundary conditions",
        "author": [
            "Adam NordenhÃ¶g",
            "Akash Sharma"
        ],
        "pdf": "https://arxiv.org/pdf/2510.23985",
        "abstract": "Score-based generative models based on stochastic differential equations (SDEs) achieve impressive performance in sampling from unknown distributions, but often fail to satisfy underlying constraints. We propose a constrained generative model using kinetic (underdamped) Langevin dynamics with specular reflection of velocity on the boundary defining constraints. This results in piecewise continuously differentiable noising and denoising process where the latter is characterized by a time-reversed dynamics restricted to a domain with boundary due to specular boundary condition. In addition, we also contribute to existing reflected SDEs based constrained generative models, where the stochastic dynamics is restricted through an abstract local time term. By presenting efficient numerical samplers which converge with optimal rate in terms of discretizations step, we provide a comprehensive comparison of models based on confined (specularly reflected kinetic) Langevin diffusion with models based on reflected diffusion with local time.",
        "tags": [
            "Diffusion",
            "Score-Based Generative"
        ]
    },
    {
        "id": "236",
        "title": "Self-supervised Synthetic Pretraining for Inference of Stellar Mass Embedded in Dense Gas",
        "author": [
            "Keiya Hirashima",
            "Shingo Nozaki",
            "Naoto Harada"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24159",
        "abstract": "Stellar mass is a fundamental quantity that determines the properties and evolution of stars. However, estimating stellar masses in star-forming regions is challenging because young stars are obscured by dense gas and the regions are highly inhomogeneous, making spherical dynamical estimates unreliable. Supervised machine learning could link such complex structures to stellar mass, but it requires large, high-quality labeled datasets from high-resolution magneto-hydrodynamical (MHD) simulations, which are computationally expensive. We address this by pretraining a vision transformer on one million synthetic fractal images using the self-supervised framework DINOv2, and then applying the frozen model to limited high-resolution MHD simulations. Our results demonstrate that synthetic pretraining improves frozen-feature regression stellar mass predictions, with the pretrained model performing slightly better than a supervised model trained on the same limited simulations. Principal component analysis of the extracted features further reveals semantically meaningful structures, suggesting that the model enables unsupervised segmentation of star-forming regions without the need for labeled data or fine-tuning.",
        "tags": [
            "Segmentation",
            "Transformer",
            "ViT"
        ]
    },
    {
        "id": "237",
        "title": "Pair Approximation Meets Reality: Diffusion of Innovation in Organizational Networks within the biased-independence q-Voter Model",
        "author": [
            "Angelika Abramiuk-Szurlej",
            "Katarzyna Sznajd-Weron"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24447",
        "abstract": "Collective adaptation, whether in innovation adoption, pro-environmental or organizational change, emerges from the interplay between individual decisions and social influence. Agent-based modeling provides a useful tool for studying such processes. Here, we introduce the biased-independence $q$-voter model, a generalization of the $q$-voter model with independence, one of the most popular agent-based models of opinion dynamics. In our model, individuals choose between two options, adopt or not adopt, under the competing influences of conformity and independent choice. Independent choice between two options is determined by an engagement parameter, inspired by earlier agent-based model of eco-innovation diffusion. When the engagement parameter equals $0.5$, the model reduces to the original $q$-voter model with independence; values different from $0.5$ break the symmetry between the two options. To place our study in a broader context, we briefly review asymmetric versions of the $q$-voter model proposed to date. The novelty of this work goes beyond introducing a generalized model: we develop the pair approximation (PA) for an asymmetric $q$-voter model and, for the first time, validate it on empirical organizational networks. Our results show that the interplay of social influence, independence, and option preference generates discontinuous phase transitions and irreversible hysteresis, reflecting path-dependent adoption dynamics. Surprisingly, the PA agrees well with Monte Carlo simulations on some empirical networks, even small ones, highlighting its potential as a computationally efficient bridge between individual decision-making and collective actions.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "238",
        "title": "Diffusion Models for Wireless Transceivers: From Pilot-Efficient Channel Estimation to AI-Native 6G Receivers",
        "author": [
            "Yuzhi Yang",
            "Sen Yan",
            "Weijie Zhou",
            "Brahim Mefgouda",
            "Ridong Li",
            "Zhaoyang Zhang",
            "MÃ©rouane Debbah"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24495",
        "abstract": "With the development of artificial intelligence (AI) techniques, implementing AI-based techniques to improve wireless transceivers becomes an emerging research topic. Within this context, AI-based channel characterization and estimation become the focus since these methods have not been solved by traditional methods very well and have become the bottleneck of transceiver efficiency in large-scale orthogonal frequency division multiplexing (OFDM) systems. Specifically, by formulating channel estimation as a generative AI problem, generative AI methods such as diffusion models (DMs) can efficiently deal with rough initial estimations and have great potential to cooperate with traditional signal processing methods. This paper focuses on the transceiver design of OFDM systems based on DMs, provides an illustration of the potential of DMs in wireless transceivers, and points out the related research directions brought by DMs. We also provide a proof-of-concept case study of further adapting DMs for better wireless receiver performance.",
        "tags": [
            "Diffusion"
        ]
    }
]