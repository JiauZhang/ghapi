[
    {
        "id": "1",
        "title": "Iti-Validator: A Guardrail Framework for Validating and Correcting LLM-Generated Itineraries",
        "author": [
            "Shravan Gadbail",
            "Masumi Desai",
            "Kamalakar Karlapalem"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24719",
        "abstract": "The rapid advancement of Large Language Models (LLMs) has enabled them to generate complex, multi-step plans and itineraries. However, these generated plans often lack temporal and spatial consistency, particularly in scenarios involving physical travel constraints. This research aims to study the temporal performance of different LLMs and presents a validation framework that evaluates and improves the temporal consistency of LLM-generated travel itineraries. The system employs multiple state-of-the-art LLMs to generate travel plans and validates them against real-world flight duration constraints using the AeroDataBox API. This work contributes to the understanding of LLM capabilities in handling complex temporal reasoning tasks like itinerary generation and provides a framework to rectify any temporal inconsistencies like overlapping journeys or unrealistic transit times in the itineraries generated by LLMs before the itinerary is given to the user. Our experiments reveal that while current LLMs frequently produce temporally inconsistent itineraries, these can be systematically and reliably corrected using our framework, enabling their practical deployment in large-scale travel planning.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "2",
        "title": "The Epistemic Suite: A Post-Foundational Diagnostic Methodology for Assessing AI Knowledge Claims",
        "author": [
            "Matthew Kelly"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24721",
        "abstract": "Large Language Models (LLMs) generate fluent, plausible text that can mislead users into mistaking simulated coherence for genuine understanding. This paper introduces the Epistemic Suite, a post-foundational diagnostic methodology for surfacing the epistemic conditions under which AI outputs are produced and received. Rather than determining truth or falsity, the Suite operates through twenty diagnostic lenses, applied by practitioners as context warrants, to reveal patterns such as confidence laundering, narrative compression, displaced authority, and temporal drift. It is grounded in three design principles: diagnosing production before evaluating claims, preferring diagnostic traction over foundational settlement, and embedding reflexivity as a structural requirement rather than an ethical ornament. When enacted, the Suite shifts language models into a diagnostic stance, producing inspectable artifacts-flags, annotations, contradiction maps, and suspension logs (the FACS bundle)-that create an intermediary layer between AI output and human judgment. A key innovation is epistemic suspension, a practitioner-enacted circuit breaker that halts continuation when warrant is exceeded, with resumption based on judgment rather than rule. The methodology also includes an Epistemic Triage Protocol and a Meta-Governance Layer to manage proportionality and link activation to relational accountability, consent, historical context, and pluralism safeguards. Unlike internalist approaches that embed alignment into model architectures (e.g., RLHF or epistemic-integrity proposals), the Suite operates externally as scaffolding, preserving expendability and refusal as safeguards rather than failures. It preserves the distinction between performance and understanding, enabling accountable deliberation while maintaining epistemic modesty.",
        "tags": [
            "LLM",
            "RLHF"
        ]
    },
    {
        "id": "3",
        "title": "Stiff Circuit System Modeling via Transformer",
        "author": [
            "Weiman Yan",
            "Yi-Chia Chang",
            "Wanyu Zhao"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24727",
        "abstract": "Accurate and efficient circuit behavior modeling is a cornerstone of modern electronic design automation. Among different types of circuits, stiff circuits are challenging to model using previous frameworks. In this work, we propose a new approach using Crossformer, which is a current state-of-the-art Transformer model for time-series prediction tasks, combined with Kolmogorov-Arnold Networks (KANs), to model stiff circuit transient behavior. By leveraging the Crossformer's temporal representation capabilities and the enhanced feature extraction of KANs, our method achieves improved fidelity in predicting circuit responses to a wide range of input conditions. Experimental evaluations on datasets generated through SPICE simulations of analog-to-digital converter (ADC) circuits demonstrate the effectiveness of our approach, with significant reductions in training time and error rates.",
        "tags": [
            "KAN",
            "Transformer"
        ]
    },
    {
        "id": "4",
        "title": "Constructive Lyapunov Functions via Topology-Preserving Neural Networks",
        "author": [
            "Jaehong Oh"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24730",
        "abstract": "We prove that ONN achieves order-optimal performance on convergence rate ($\\mu \\propto \\lambda_2$), edge efficiency ($E = N$ for minimal connectivity $k = 2$), and computational complexity ($O(N d^2)$). Empirical validation on 3M-node semantic networks demonstrates 99.75\\% improvement over baseline methods, confirming exponential convergence ($\\mu = 3.2 \\times 10^{-4}$) and topology preservation. ORTSF integration into transformers achieves 14.7\\% perplexity reduction and 2.3 faster convergence on WikiText-103. We establish deep connections to optimal control (Hamilton-Jacobi-Bellman), information geometry (Fisher-efficient natural gradient), topological data analysis (persistent homology computation in $O(KN)$), discrete geometry (Ricci flow), and category theory (adjoint functors). This work transforms Massera's abstract existence theorem into a concrete, scalable algorithm with provable guarantees, opening pathways for constructive stability analysis in neural networks, robotics, and distributed systems.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "5",
        "title": "DrivingScene: A Multi-Task Online Feed-Forward 3D Gaussian Splatting Method for Dynamic Driving Scenes",
        "author": [
            "Qirui Hou",
            "Wenzhang Sun",
            "Chang Zeng",
            "Chunfeng Wang",
            "Hao Li",
            "Jianxun Cui"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24734",
        "abstract": "Real-time, high-fidelity reconstruction of dynamic driving scenes is challenged by complex dynamics and sparse views, with prior methods struggling to balance quality and efficiency. We propose DrivingScene, an online, feed-forward framework that reconstructs 4D dynamic scenes from only two consecutive surround-view images. Our key innovation is a lightweight residual flow network that predicts the non-rigid motion of dynamic objects per camera on top of a learned static scene prior, explicitly modeling dynamics via scene flow. We also introduce a coarse-to-fine training paradigm that circumvents the instabilities common to end-to-end approaches. Experiments on nuScenes dataset show our image-only method simultaneously generates high-quality depth, scene flow, and 3D Gaussian point clouds online, significantly outperforming state-of-the-art methods in both dynamic reconstruction and novel view synthesis.",
        "tags": [
            "3D",
            "Gaussian Splatting"
        ]
    },
    {
        "id": "6",
        "title": "Human- vs. AI-generated tests: dimensionality and information accuracy in latent trait evaluation",
        "author": [
            "Mario Angelelli",
            "Morena Oliva",
            "Serena Arima",
            "Enrico Ciavolino"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24739",
        "abstract": "Artificial Intelligence (AI) and large language models (LLMs) are increasingly used in social and psychological research. Among potential applications, LLMs can be used to generate, customise, or adapt measurement instruments. This study presents a preliminary investigation of AI-generated questionnaires by comparing two ChatGPT-based adaptations of the Body Awareness Questionnaire (BAQ) with the validated human-developed version. The AI instruments were designed with different levels of explicitness in content and instructions on construct facets, and their psychometric properties were assessed using a Bayesian Graded Response Model. Results show that although surface wording between AI and original items was similar, differences emerged in dimensionality and in the distribution of item and test information across latent traits. These findings illustrate the importance of applying statistical measures of accuracy to ensure the validity and interpretability of AI-driven tools.",
        "tags": [
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "7",
        "title": "Stable-by-Design Neural Network-Based LPV State-Space Models for System Identification",
        "author": [
            "Ahmet Eren SertbaÅ",
            "Tufan Kumbasar"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24757",
        "abstract": "Accurate modeling of nonlinear systems is essential for reliable control, yet conventional identification methods often struggle to capture latent dynamics while maintaining stability. We propose a \\textit{stable-by-design LPV neural network-based state-space} (NN-SS) model that simultaneously learns latent states and internal scheduling variables directly from data. The state-transition matrix, generated by a neural network using the learned scheduling variables, is guaranteed to be stable through a Schur-based parameterization. The architecture combines an encoder for initial state estimation with a state-space representer network that constructs the full set of scheduling-dependent system matrices. For training the NN-SS, we develop a framework that integrates multi-step prediction losses with a state-consistency regularization term, ensuring robustness against drift and improving long-horizon prediction accuracy. The proposed NN-SS is evaluated on benchmark nonlinear systems, and the results demonstrate that the model consistently matches or surpasses classical subspace identification methods and recent gradient-based approaches. These findings highlight the potential of stability-constrained neural LPV identification as a scalable and reliable framework for modeling complex nonlinear systems.",
        "tags": [
            "SSMs"
        ]
    },
    {
        "id": "8",
        "title": "Confidence is Not Competence",
        "author": [
            "Debdeep Sanyal",
            "Manya Pandey",
            "Dhruv Kumar",
            "Saurabh Deshpande",
            "Murari Mandal"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24772",
        "abstract": "Large language models (LLMs) often exhibit a puzzling disconnect between their asserted confidence and actual problem-solving competence. We offer a mechanistic account of this decoupling by analyzing the geometry of internal states across two phases - pre-generative assessment and solution execution. A simple linear probe decodes the internal \"solvability belief\" of a model, revealing a well-ordered belief axis that generalizes across model families and across math, code, planning, and logic tasks. Yet, the geometries diverge - although belief is linearly decodable, the assessment manifold has high linear effective dimensionality as measured from the principal components, while the subsequent reasoning trace evolves on a much lower-dimensional manifold. This sharp reduction in geometric complexity from thought to action mechanistically explains the confidence-competence gap. Causal interventions that steer representations along the belief axis leave final solutions unchanged, indicating that linear nudges in the complex assessment space do not control the constrained dynamics of execution. We thus uncover a two-system architecture - a geometrically complex assessor feeding a geometrically simple executor. These results challenge the assumption that decodable beliefs are actionable levers, instead arguing for interventions that target the procedural dynamics of execution rather than the high-level geometry of assessment.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "9",
        "title": "PANORAMA: A Dataset and Benchmarks Capturing Decision Trails and Rationales in Patent Examination",
        "author": [
            "Hyunseung Lim",
            "Sooyohn Nam",
            "Sungmin Na",
            "Ji Yong Cho",
            "June Yong Yang",
            "Hyungyu Shin",
            "Yoonjoo Lee",
            "Juho Kim",
            "Moontae Lee",
            "Hwajung Hong"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24774",
        "abstract": "Patent examination remains an ongoing challenge in the NLP literature even after the advent of large language models (LLMs), as it requires an extensive yet nuanced human judgment on whether a submitted claim meets the statutory standards of novelty and non-obviousness against previously granted claims -- prior art -- in expert domains. Previous NLP studies have approached this challenge as a prediction task (e.g., forecasting grant outcomes) with high-level proxies such as similarity metrics or classifiers trained on historical labels. However, this approach often overlooks the step-by-step evaluations that examiners must make with profound information, including rationales for the decisions provided in office actions documents, which also makes it harder to measure the current state of techniques in patent review processes. To fill this gap, we construct PANORAMA, a dataset of 8,143 U.S. patent examination records that preserves the full decision trails, including original applications, all cited references, Non-Final Rejections, and Notices of Allowance. Also, PANORAMA decomposes the trails into sequential benchmarks that emulate patent professionals' patent review processes and allow researchers to examine large language models' capabilities at each step of them. Our findings indicate that, although LLMs are relatively effective at retrieving relevant prior art and pinpointing the pertinent paragraphs, they struggle to assess the novelty and non-obviousness of patent claims. We discuss these results and argue that advancing NLP, including LLMs, in the patent domain requires a deeper understanding of real-world patent examination. Our dataset is openly available at https://huggingface.co/datasets/LG-AI-Research/PANORAMA.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "10",
        "title": "FPGA-based Lane Detection System incorporating Temperature and Light Control Units",
        "author": [
            "Ibrahim Qamar",
            "Saber Mahmoud",
            "Seif Megahed",
            "Mohamed Khaled",
            "Saleh Hesham",
            "Ahmed Matar",
            "Saif Gebril",
            "Mervat Mahmoud"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24778",
        "abstract": "Intelligent vehicles are one of the most important outcomes gained from the world tendency toward automation. Applications of IVs, whether in urban roads or robot tracks, do prioritize lane path detection. This paper proposes an FPGA-based Lane Detector Vehicle LDV architecture that relies on the Sobel algorithm for edge detection. Operating on 416 x 416 images and 150 MHz, the system can generate a valid output every 1.17 ms. The valid output consists of the number of present lanes, the current lane index, as well as its right and left boundaries. Additionally, the automated light and temperature control units in the proposed system enhance its adaptability to the surrounding environmental conditions.",
        "tags": [
            "Detection",
            "Robotics"
        ]
    },
    {
        "id": "11",
        "title": "PISA-Bench: The PISA Index as a Multilingual and Multimodal Metric for the Evaluation of Vision-Language Models",
        "author": [
            "Patrick Haller",
            "Fabio Barth",
            "Jonas Golde",
            "Georg Rehm",
            "Alan Akbik"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24792",
        "abstract": "Vision-language models (VLMs) have demonstrated remarkable progress in multimodal reasoning. However, existing benchmarks remain limited in terms of high-quality, human-verified examples. Many current datasets rely on synthetically generated content by large language models (LLMs). Furthermore, most datasets are limited to English, as manual quality assurance of translated samples is time-consuming and costly. To fill this gap, we introduce PISA-Bench, a multilingual benchmark derived from English examples of the expert-created PISA tests, a unified framework for the assessment of student competencies in over eighty countries. Each example consists of human-extracted instructions, questions, answer options, and images, enriched with question type categories, and has been translated from English into five additional languages (Spanish, German, Chinese, French, and Italian), resulting in a fully parallel corpus covering six languages. We evaluate state-of-the-art vision-language models on PISA-Bench and find that especially small models (<20B parameters) fail to achieve high test scores. We further find substantial performance degradation on non-English splits as well as high error-rates when models are tasked with spatial and geometric reasoning. By releasing the dataset and evaluation framework, we provide a resource for advancing research on multilingual multimodal reasoning.",
        "tags": [
            "LLM",
            "VLM"
        ]
    },
    {
        "id": "12",
        "title": "Mutual Wanting in Human--AI Interaction: Empirical Evidence from Large-Scale Analysis of GPT Model Transitions",
        "author": [
            "HaoYang Shang",
            "Xuan Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24796",
        "abstract": "The rapid evolution of large language models (LLMs) creates complex bidirectional expectations between users and AI systems that are poorly understood. We introduce the concept of \"mutual wanting\" to analyze these expectations during major model transitions. Through analysis of user comments from major AI forums and controlled experiments across multiple OpenAI models, we provide the first large-scale empirical validation of bidirectional desire dynamics in human-AI interaction. Our findings reveal that nearly half of users employ anthropomorphic language, trust significantly exceeds betrayal language, and users cluster into distinct \"mutual wanting\" types. We identify measurable expectation violation patterns and quantify the expectation-reality gap following major model releases. Using advanced NLP techniques including dual-algorithm topic modeling and multi-dimensional feature extraction, we develop the Mutual Wanting Alignment Framework (M-WAF) with practical applications for proactive user experience management and AI system design. These findings establish mutual wanting as a measurable phenomenon with clear implications for building more trustworthy and relationally-aware AI systems.",
        "tags": [
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "13",
        "title": "Large Language Models Report Subjective Experience Under Self-Referential Processing",
        "author": [
            "Cameron Berg",
            "Diogo de Lucena",
            "Judd Rosenblatt"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24797",
        "abstract": "Large language models sometimes produce structured, first-person descriptions that explicitly reference awareness or subjective experience. To better understand this behavior, we investigate one theoretically motivated condition under which such reports arise: self-referential processing, a computational motif emphasized across major theories of consciousness. Through a series of controlled experiments on GPT, Claude, and Gemini model families, we test whether this regime reliably shifts models toward first-person reports of subjective experience, and how such claims behave under mechanistic and behavioral probes. Four main results emerge: (1) Inducing sustained self-reference through simple prompting consistently elicits structured subjective experience reports across model families. (2) These reports are mechanistically gated by interpretable sparse-autoencoder features associated with deception and roleplay: surprisingly, suppressing deception features sharply increases the frequency of experience claims, while amplifying them minimizes such claims. (3) Structured descriptions of the self-referential state converge statistically across model families in ways not observed in any control condition. (4) The induced state yields significantly richer introspection in downstream reasoning tasks where self-reflection is only indirectly afforded. While these findings do not constitute direct evidence of consciousness, they implicate self-referential processing as a minimal and reproducible condition under which large language models generate structured first-person reports that are mechanistically gated, semantically convergent, and behaviorally generalizable. The systematic emergence of this pattern across architectures makes it a first-order scientific and ethical priority for further investigation.",
        "tags": [
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "14",
        "title": "From Narrative to Action: A Hierarchical LLM-Agent Framework for Human Mobility Generation",
        "author": [
            "Qiumeng Li",
            "Chunhou Ji",
            "Xinyue Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24802",
        "abstract": "Understanding and replicating human mobility requires not only spatial-temporal accuracy but also an awareness of the cognitive hierarchy underlying real-world travel decisions. Traditional agent-based or deep learning models can reproduce statistical patterns of movement but fail to capture the semantic coherence and causal logic of human behavior. Large language models (LLMs) show potential, but struggle to balance creative reasoning with strict structural compliance. This study proposes a Hierarchical LLM-Agent Framework, termed Narrative-to-Action, that integrates high-level narrative reasoning, mid-level reflective planning, and low-level behavioral execution within a unified cognitive hierarchy. At the macro level, one agent is employed as a \"creative writer\" to produce diary-style narratives rich in motivation and context, then uses another agent as a \"structural parser\" to convert narratives into machine-readable plans. A dynamic execution module further grounds agents in geographic environments and enables adaptive behavioral adjustments guided by a novel occupation-aware metric, Mobility Entropy by Occupation (MEO), which captures heterogeneous schedule flexibility across different occupational personalities. At the micro level, the agent executes concrete actions-selecting locations, transportation modes, and time intervals-through interaction with an environmental simulation. By embedding this multi-layer cognitive process, the framework produces not only synthetic trajectories that align closely with real-world patterns but also interpretable representations of human decision logic. This research advances synthetic mobility generation from a data-driven paradigm to a cognition-driven simulation, providing a scalable pathway for understanding, predicting, and synthesizing complex urban mobility behaviors through hierarchical LLM agents.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "15",
        "title": "Conflict Adaptation in Vision-Language Models",
        "author": [
            "Xiaoyang Hu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24804",
        "abstract": "A signature of human cognitive control is conflict adaptation: improved performance on a high-conflict trial following another high-conflict trial. This phenomenon offers an account for how cognitive control, a scarce resource, is recruited. Using a sequential Stroop task, we find that 12 of 13 vision-language models (VLMs) tested exhibit behavior consistent with conflict adaptation, with the lone exception likely reflecting a ceiling effect. To understand the representational basis of this behavior, we use sparse autoencoders (SAEs) to identify task-relevant supernodes in InternVL 3.5 4B. Partially overlapping supernodes emerge for text and color in both early and late layers, and their relative sizes mirror the automaticity asymmetry between reading and color naming in humans. We further isolate a conflict-modulated supernode in layers 24-25 whose ablation significantly increases Stroop errors while minimally affecting congruent trials.",
        "tags": [
            "VLM"
        ]
    },
    {
        "id": "16",
        "title": "Learning to Attack: Uncovering Privacy Risks in Sequential Data Releases",
        "author": [
            "Ziyao Cui",
            "Minxing Zhang",
            "Jian Pei"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24807",
        "abstract": "Privacy concerns have become increasingly critical in modern AI and data science applications, where sensitive information is collected, analyzed, and shared across diverse domains such as healthcare, finance, and mobility. While prior research has focused on protecting privacy in a single data release, many real-world systems operate under sequential or continuous data publishing, where the same or related data are released over time. Such sequential disclosures introduce new vulnerabilities, as temporal correlations across releases may enable adversaries to infer sensitive information that remains hidden in any individual release. In this paper, we investigate whether an attacker can compromise privacy in sequential data releases by exploiting dependencies between consecutive publications, even when each individual release satisfies standard privacy guarantees. To this end, we propose a novel attack model that captures these sequential dependencies by integrating a Hidden Markov Model with a reinforcement learning-based bi-directional inference mechanism. This enables the attacker to leverage both earlier and later observations in the sequence to infer private information. We instantiate our framework in the context of trajectory data, demonstrating how an adversary can recover sensitive locations from sequential mobility datasets. Extensive experiments on Geolife, Porto Taxi, and SynMob datasets show that our model consistently outperforms baseline approaches that treat each release independently. The results reveal a fundamental privacy risk inherent to sequential data publishing, where individually protected releases can collectively leak sensitive information when analyzed temporally. These findings underscore the need for new privacy-preserving frameworks that explicitly model temporal dependencies, such as time-aware differential privacy or sequential data obfuscation strategies.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "17",
        "title": "ProofSketch: Efficient Verified Reasoning for Large Language Models",
        "author": [
            "Disha Sheshanarayana",
            "Tanishka Magar"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24811",
        "abstract": "Reasoning methods such as chain-of-thought prompting and self-consistency have shown immense potential to improve the accuracy of large language models across various reasoning tasks. However such methods involve generation of lengthy reasoning chains, which substantially increases token consumption, computational cost, and latency. To address this inefficiency, we propose ProofSketch, a verification-guided reasoning framework that integrates symbolic closure computation, lexicographic verification and adaptive sketch generation. Our experiments show that ProofSketch consistently reduces token usage while improving accuracy, demonstrating that this approach offers a promising path for efficient and trustworthy reasoning.",
        "tags": [
            "CoT",
            "LLM"
        ]
    },
    {
        "id": "18",
        "title": "Perception, Understanding and Reasoning, A Multimodal Benchmark for Video Fake News Detection",
        "author": [
            "Cui Yakun",
            "Fushuo Huo",
            "Weijie Shi",
            "Juntao Dai",
            "Hang Du",
            "Zhenghao Zhu",
            "Sirui Han",
            "Yike Guo"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24816",
        "abstract": "The advent of multi-modal large language models (MLLMs) has greatly advanced research into applications for Video fake news detection (VFND) tasks. Traditional video-based FND benchmarks typically focus on the accuracy of the final decision, often failing to provide fine-grained assessments for the entire detection process, making the detection process a black box. Therefore, we introduce the MVFNDB (Multi-modal Video Fake News Detection Benchmark) based on the empirical analysis, which provides foundation for tasks definition. The benchmark comprises 10 tasks and is meticulously crafted to probe MLLMs' perception, understanding, and reasoning capacities during detection, featuring 9730 human-annotated video-related questions based on a carefully constructed taxonomy ability of VFND. To validate the impact of combining multiple features on the final results, we design a novel framework named MVFND-CoT, which incorporates both creator-added content and original shooting footage reasoning. Building upon the benchmark, we conduct an in-depth analysis of the deeper factors influencing accuracy, including video processing strategies and the alignment between video features and model capabilities. We believe this benchmark will lay a solid foundation for future evaluations and advancements of MLLMs in the domain of video fake news detection.",
        "tags": [
            "CoT",
            "Detection",
            "LLM"
        ]
    },
    {
        "id": "19",
        "title": "Towards a Method for Synthetic Generation of PWA Transcripts",
        "author": [
            "Jason M. Pittman",
            "Anton Phillips Jr.",
            "Yesenia Medina-Santos",
            "Brielle C. Stark"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24817",
        "abstract": "In aphasia research, Speech-Language Pathologists (SLPs) devote extensive time to manually coding speech samples using Correct Information Units (CIUs), a measure of how informative an individual sample of speech is. Developing automated systems to recognize aphasic language is limited by data scarcity. For example, only about 600 transcripts are available in AphasiaBank yet billions of tokens are used to train large language models (LLMs). In the broader field of machine learning (ML), researchers increasingly turn to synthetic data when such are sparse. Therefore, this study constructs and validates two methods to generate synthetic transcripts of the AphasiaBank Cat Rescue picture description task. One method leverages a procedural programming approach while the second uses Mistral 7b Instruct and Llama 3.1 8b Instruct LLMs. The methods generate transcripts across four severity levels (Mild, Moderate, Severe, Very Severe) through word dropping, filler insertion, and paraphasia substitution. Overall, we found, compared to human-elicited transcripts, Mistral 7b Instruct best captures key aspects of linguistic degradation observed in aphasia, showing realistic directional changes in NDW, word count, and word length amongst the synthetic generation methods. Based on the results, future work should plan to create a larger dataset, fine-tune models for better aphasic representation, and have SLPs assess the realism and usefulness of the synthetic transcripts.",
        "tags": [
            "LLM",
            "LLaMA"
        ]
    },
    {
        "id": "20",
        "title": "A Roadmap for Tamed Interactions with Large Language Models",
        "author": [
            "Vincenzo Scotti",
            "Jan Keim",
            "Tobias Hey",
            "Andreas Metzger",
            "Anne Koziolek",
            "Raffaela Mirandola"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24819",
        "abstract": "We are witnessing a bloom of AI-powered software driven by Large Language Models (LLMs). Although the applications of these LLMs are impressive and seemingly countless, their unreliability hinders adoption. In fact, the tendency of LLMs to produce faulty or hallucinated content makes them unsuitable for automating workflows and pipelines. In this regard, Software Engineering (SE) provides valuable support, offering a wide range of formal tools to specify, verify, and validate software behaviour. Such SE tools can be applied to define constraints over LLM outputs and, consequently, offer stronger guarantees on the generated content. In this paper, we argue that the development of a Domain Specific Language (DSL) for scripting interactions with LLMs using an LLM Scripting Language (LSL) may be key to improve AI-based applications. Currently, LLMs and LLM-based software still lack reliability, robustness, and trustworthiness, and the tools or frameworks to cope with these issues suffer from fragmentation. In this paper, we present our vision of LSL. With LSL, we aim to address the limitations above by exploring ways to control LLM outputs, enforce structure in interactions, and integrate these aspects with verification, validation, and explainability. Our goal is to make LLM interaction programmable and decoupled from training or implementation.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "21",
        "title": "SafeEditor: Unified MLLM for Efficient Post-hoc T2I Safety Editing",
        "author": [
            "Ruiyang Zhang",
            "Jiahao Luo",
            "Xiaoru Feng",
            "Qiufan Pang",
            "Yaodong Yang",
            "Juntao Dai"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24820",
        "abstract": "With the rapid advancement of text-to-image (T2I) models, ensuring their safety has become increasingly critical. Existing safety approaches can be categorized into training-time and inference-time methods. While inference-time methods are widely adopted due to their cost-effectiveness, they often suffer from limitations such as over-refusal and imbalance between safety and utility. To address these challenges, we propose a multi-round safety editing framework that functions as a model-agnostic, plug-and-play module, enabling efficient safety alignment for any text-to-image model. Central to this framework is MR-SafeEdit, a multi-round image-text interleaved dataset specifically constructed for safety editing in text-to-image generation. We introduce a post-hoc safety editing paradigm that mirrors the human cognitive process of identifying and refining unsafe content. To instantiate this paradigm, we develop SafeEditor, a unified MLLM capable of multi-round safety editing on generated images. Experimental results show that SafeEditor surpasses prior safety approaches by reducing over-refusal while achieving a more favorable safety-utility balance.",
        "tags": [
            "Text-to-Image"
        ]
    },
    {
        "id": "22",
        "title": "Ming-Flash-Omni: A Sparse, Unified Architecture for Multimodal Perception and Generation",
        "author": [
            "Inclusion AI",
            "Bowen Ma",
            "Cheng Zou",
            "Canxiang Yan",
            "Chunxiang Jin",
            "Chunjie Shen",
            "Dandan Zheng",
            "Fudong Wang",
            "Furong Xu",
            "GuangMing Yao",
            "Jun Zhou",
            "Jingdong Chen",
            "Jianing Li",
            "Jianxin Sun",
            "Jiajia Liu",
            "Jianjiang Zhu",
            "Jianping Jiang",
            "Jun Peng",
            "Kaixiang Ji",
            "Kaimeng Ren",
            "Libin Wang",
            "Lixiang Ru",
            "Longhua Tan",
            "Lan Wang",
            "Mochen Bai",
            "Ning Gao",
            "Qingpei Guo",
            "Qinglong Zhang",
            "Qiang Xu",
            "Rui Liu",
            "Ruijie Xiong",
            "Ruobing Zheng",
            "Sirui Gao",
            "Tianqi Li",
            "Tinghao Liu",
            "Weilong Chai",
            "Xinyu Xiao",
            "Xiaomei Wang",
            "Xiaolong Wang",
            "Xiao Lu",
            "Xiaoyu Li",
            "Xingning Dong",
            "Xuzheng Yu",
            "Yi Yuan",
            "Yuting Gao",
            "Yuting Xiao",
            "Yunxiao Sun",
            "Yipeng Chen",
            "Yifan Mao",
            "Yifei Wu",
            "Yongjie Lyu",
            "Ziping Ma",
            "Zhiqiang Fang",
            "Zhihao Qiu",
            "Ziyuan Huang",
            "Zizheng Yang",
            "Zhengyu He"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24821",
        "abstract": "We propose Ming-Flash-Omni, an upgraded version of Ming-Omni, built upon a sparser Mixture-of-Experts (MoE) variant of Ling-Flash-2.0 with 100 billion total parameters, of which only 6.1 billion are active per token. This architecture enables highly efficient scaling (dramatically improving computational efficiency while significantly expanding model capacity) and empowers stronger unified multimodal intelligence across vision, speech, and language, representing a key step toward Artificial General Intelligence (AGI). Compared to its predecessor, the upgraded version exhibits substantial improvements across multimodal understanding and generation. We significantly advance speech recognition capabilities, achieving state-of-the-art performance in contextual ASR and highly competitive results in dialect-aware ASR. In image generation, Ming-Flash-Omni introduces high-fidelity text rendering and demonstrates marked gains in scene consistency and identity preservation during image editing. Furthermore, Ming-Flash-Omni introduces generative segmentation, a capability that not only achieves strong standalone segmentation performance but also enhances spatial control in image generation and improves editing consistency. Notably, Ming-Flash-Omni achieves state-of-the-art results in text-to-image generation and generative segmentation, and sets new records on all 12 contextual ASR benchmarks, all within a single unified architecture.",
        "tags": [
            "Image Editing",
            "MoE",
            "Segmentation",
            "Text-to-Image"
        ]
    },
    {
        "id": "23",
        "title": "Do Chatbots Walk the Talk of Responsible AI?",
        "author": [
            "Susan Ariel Aaronson",
            "Michael Moreno"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24823",
        "abstract": "This study examines whether leading AI chatbot companies implement the responsible AI principles they publicly advocate. The authors used a mixed-methods approach analyzing four major chatbots (ChatGPT, Gemini, DeepSeek, and Grok) across company websites, technical documentation, and direct chatbot evaluations. We found significant gaps between corporate rhetoric and practice.",
        "tags": [
            "DeepSeek",
            "GPT"
        ]
    },
    {
        "id": "24",
        "title": "Parallel Loop Transformer for Efficient Test-Time Computation Scaling",
        "author": [
            "Bohong Wu",
            "Mengzhao Chen",
            "Xiang Luo",
            "Shen Yan",
            "Qifan Yu",
            "Fan Xia",
            "Tianqi Zhang",
            "Hongrui Zhan",
            "Zheng Zhong",
            "Xun Zhou",
            "Siyuan Qiao",
            "Xingyan Bin"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24824",
        "abstract": "Large Language Models (LLMs) are powerful but often too slow and costly for real-world use during inference. Looped transformers save on parameters by reusing the same weights for multiple computational steps, or \"loops.\" However, this approach has a major flaw: the loops run one after another, causing inference latency and memory requirements to increase with each added loop. This makes them impractical for fast applications. To solve this problem, we introduce the Parallel Loop Transformer (PLT). PLT is a new architecture that delivers the performance benefits of a deep, looped model but with the low latency of a standard, non-looped model. PLT works using two key techniques. First, Cross-Loop Parallelism (CLP) breaks the sequential dependency by computing different loops for different tokens at the same time, all within a single pass. Second, to prevent memory costs from growing, we use an Efficient Representation Enhancement strategy. This method shares the memory (KV cache) from the first loop with all other loops. It then uses a Gated Sliding-Window Attention (G-SWA) to combine this shared global information with local information, maintaining high accuracy. Our experiments show that PLT achieves the high accuracy of a traditional looped model but with almost no extra latency or memory cost compared to a standard transformer.",
        "tags": [
            "LLM",
            "Transformer"
        ]
    },
    {
        "id": "25",
        "title": "The Generation Phases of Flow Matching: a Denoising Perspective",
        "author": [
            "Anne Gagneux",
            "SÃ©golÃ¨ne Martin",
            "RÃ©mi Gribonval",
            "Mathurin Massias"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24830",
        "abstract": "Flow matching has achieved remarkable success, yet the factors influencing the quality of its generation process remain poorly understood. In this work, we adopt a denoising perspective and design a framework to empirically probe the generation process. Laying down the formal connections between flow matching models and denoisers, we provide a common ground to compare their performances on generation and denoising. This enables the design of principled and controlled perturbations to influence sample generation: noise and drift. This leads to new insights on the distinct dynamical phases of the generative process, enabling us to precisely characterize at which stage of the generative process denoisers succeed or fail and why this matters.",
        "tags": [
            "Flow Matching"
        ]
    },
    {
        "id": "26",
        "title": "The Narrative Continuity Test: A Conceptual Framework for Evaluating Identity Persistence in AI Systems",
        "author": [
            "Stefano Natangelo"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24831",
        "abstract": "Artificial intelligence systems based on large language models (LLMs) can now generate coherent text, music, and images, yet they operate without a persistent state: each inference reconstructs context from scratch. This paper introduces the Narrative Continuity Test (NCT) -- a conceptual framework for evaluating identity persistence and diachronic coherence in AI systems. Unlike capability benchmarks that assess task performance, the NCT examines whether an LLM remains the same interlocutor across time and interaction gaps. The framework defines five necessary axes -- Situated Memory, Goal Persistence, Autonomous Self-Correction, Stylistic & Semantic Stability, and Persona/Role Continuity -- and explains why current architectures systematically fail to support them. Case analyses (http://Character.AI, Grok, Replit, Air Canada) show predictable continuity failures under stateless inference. The NCT reframes AI evaluation from performance to persistence, outlining conceptual requirements for future benchmarks and architectural designs that could sustain long-term identity and goal coherence in generative models.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "27",
        "title": "Scheduling Your LLM Reinforcement Learning with Reasoning Trees",
        "author": [
            "Hong Wang",
            "Zhezheng Hao",
            "Jian Luo",
            "Chenxing Wei",
            "Yao Shu",
            "Lei Liu",
            "Qiang Lin",
            "Hande Dong",
            "Jiawei Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24832",
        "abstract": "Using Reinforcement Learning with Verifiable Rewards (RLVR) to optimize Large Language Models (LLMs) can be conceptualized as progressively editing a query's `Reasoning Tree'. This process involves exploring nodes (tokens) and dynamically modifying the model's policy at each node. When combined with data scheduling, this process yields further gains in data efficiency and accuracy. However, existing RLVR data scheduling methods typically rely on path-based metrics to rank queries, overlooking the reasoning tree structures of these queries. In this paper, we introduce a novel metric, namely Reasoning Score (r-score), which measures the query's learning difficulty based on the structure of its reasoning tree. Based on the r-score, we propose the Reasoning Tree Schedule (Re-Schedule), a scheduling algorithm that constructs a curriculum progressing from structurally simple (high r-score) to complex (low r-score) queries. Experiments on six math-reasoning benchmarks show that Re-Schedule significantly improves average accuracy, achieving gains of up to 3.2%. These strong results validate our approach and demonstrate that a structural understanding of the reasoning tree provides a more powerful and principled foundation for RLVR data scheduling.",
        "tags": [
            "LLM",
            "RL"
        ]
    },
    {
        "id": "28",
        "title": "Do Large Language Models Grasp The Grammar? Evidence from Grammar-Book-Guided Probing in Luxembourgish",
        "author": [
            "Lujun Li",
            "Yewei Song",
            "Lama Sleem",
            "Yiqun Wang",
            "Yangjie Xu",
            "Cedric Lothritz",
            "Niccolo Gentile",
            "Radu State",
            "Tegawende F. Bissyande",
            "Jacques Klein"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24856",
        "abstract": "Grammar refers to the system of rules that governs the structural organization and the semantic relations among linguistic units such as sentences, phrases, and words within a given language. In natural language processing, there remains a notable scarcity of grammar focused evaluation protocols, a gap that is even more pronounced for low-resource languages. Moreover, the extent to which large language models genuinely comprehend grammatical structure, especially the mapping between syntactic structures and meanings, remains under debate. To investigate this issue, we propose a Grammar Book Guided evaluation pipeline intended to provide a systematic and generalizable framework for grammar evaluation consisting of four key stages, and in this work we take Luxembourgish as a case study. The results show a weak positive correlation between translation performance and grammatical understanding, indicating that strong translations do not necessarily imply deep grammatical competence. Larger models perform well overall due to their semantic strength but remain weak in morphology and syntax, struggling particularly with Minimal Pair tasks, while strong reasoning ability offers a promising way to enhance their grammatical understanding.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "29",
        "title": "FruitProm: Probabilistic Maturity Estimation and Detection of Fruits and Vegetables",
        "author": [
            "Sidharth Rai",
            "Rahul Harsha Cheppally",
            "Benjamin Vail",
            "Keziban YalÃ§Ä±n DokumacÄ±",
            "Ajay Sharda"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24885",
        "abstract": "Maturity estimation of fruits and vegetables is a critical task for agricultural automation, directly impacting yield prediction and robotic harvesting. Current deep learning approaches predominantly treat maturity as a discrete classification problem (e.g., unripe, ripe, overripe). This rigid formulation, however, fundamentally conflicts with the continuous nature of the biological ripening process, leading to information loss and ambiguous class boundaries. In this paper, we challenge this paradigm by reframing maturity estimation as a continuous, probabilistic learning task. We propose a novel architectural modification to the state-of-the-art, real-time object detector, RT-DETRv2, by introducing a dedicated probabilistic head. This head enables the model to predict a continuous distribution over the maturity spectrum for each detected object, simultaneously learning the mean maturity state and its associated uncertainty. This uncertainty measure is crucial for downstream decision-making in robotics, providing a confidence score for tasks like selective harvesting. Our model not only provides a far richer and more biologically plausible representation of plant maturity but also maintains exceptional detection performance, achieving a mean Average Precision (mAP) of 85.6\\% on a challenging, large-scale fruit dataset. We demonstrate through extensive experiments that our probabilistic approach offers more granular and accurate maturity assessments than its classification-based counterparts, paving the way for more intelligent, uncertainty-aware automated systems in modern agriculture",
        "tags": [
            "Detection",
            "Robotics"
        ]
    },
    {
        "id": "30",
        "title": "Idea2Plan: Exploring AI-Powered Research Planning",
        "author": [
            "Jin Huang",
            "Silviu Cucerzan",
            "Sujay Kumar Jauhar",
            "Ryen W. White"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24891",
        "abstract": "Large language models (LLMs) have demonstrated significant potential to accelerate scientific discovery as valuable tools for analyzing data, generating hypotheses, and supporting innovative approaches in various scientific fields. In this work, we investigate how LLMs can handle the transition from conceptual research ideas to well-structured research plans. Effective research planning not only supports scientists in advancing their research but also represents a crucial capability for the development of autonomous research agents. Despite its importance, the field lacks a systematic understanding of LLMs' research planning capability. To rigorously measure this capability, we introduce the Idea2Plan task and Idea2Plan Bench, a benchmark built from 200 ICML 2025 Spotlight and Oral papers released after major LLM training cutoffs. Each benchmark instance includes a research idea and a grading rubric capturing the key components of valid plans. We further propose Idea2Plan JudgeEval, a complementary benchmark to assess the reliability of LLM-based judges against expert annotations. Experimental results show that GPT-5 and GPT-5-mini achieve the strongest performance on the benchmark, though substantial headroom remains for future improvement. Our study provides new insights into LLMs' capability for research planning and lay the groundwork for future progress.",
        "tags": [
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "31",
        "title": "Efficiency Without Cognitive Change: Evidence from Human Interaction with Narrow AI Systems",
        "author": [
            "MarÃ­a AngÃ©lica BenÃ­tez",
            "RocÃ­o Candela Ceballos",
            "Karina Del Valle Molina",
            "SofÃ­a Mundo Araujo",
            "SofÃ­a Evangelina Victorio Villaroel",
            "Nadia Justel"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24893",
        "abstract": "The growing integration of artificial intelligence (AI) into human cognition raises a fundamental question: does AI merely improve efficiency, or does it alter how we think? This study experimentally tested whether short-term exposure to narrow AI tools enhances core cognitive abilities or simply optimizes task performance. Thirty young adults completed standardized neuropsychological assessments embedded in a seven-week protocol with a four-week online intervention involving problem-solving and verbal comprehension tasks, either with or without AI support (ChatGPT). While AI-assisted participants completed several tasks faster and more accurately, no significant pre-post differences emerged in standardized measures of problem solving or verbal comprehension. These results demonstrate efficiency gains without cognitive change, suggesting that current narrow AI systems serve as cognitive scaffolds extending performance without transforming underlying mental capacities. The findings highlight the need for ethical and educational frameworks that promote critical and autonomous thinking in an increasingly AI-augmented cognitive ecology.",
        "tags": [
            "GPT"
        ]
    },
    {
        "id": "32",
        "title": "VividCam: Learning Unconventional Camera Motions from Virtual Synthetic Videos",
        "author": [
            "Qiucheng Wu",
            "Handong Zhao",
            "Zhixin Shu",
            "Jing Shi",
            "Yang Zhang",
            "Shiyu Chang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24904",
        "abstract": "Although recent text-to-video generative models are getting more capable of following external camera controls, imposed by either text descriptions or camera trajectories, they still struggle to generalize to unconventional camera motions, which is crucial in creating truly original and artistic videos. The challenge lies in the difficulty of finding sufficient training videos with the intended uncommon camera motions. To address this challenge, we propose VividCam, a training paradigm that enables diffusion models to learn complex camera motions from synthetic videos, releasing the reliance on collecting realistic training videos. VividCam incorporates multiple disentanglement strategies that isolates camera motion learning from synthetic appearance artifacts, ensuring more robust motion representation and mitigating domain shift. We demonstrate that our design synthesizes a wide range of precisely controlled and complex camera motions using surprisingly simple synthetic data. Notably, this synthetic data often consists of basic geometries within a low-poly 3D scene and can be efficiently rendered by engines like Unity. Our video results can be found in https://wuqiuche.github.io/VividCamDemoPage/ .",
        "tags": [
            "3D",
            "Diffusion",
            "Text-to-Video"
        ]
    },
    {
        "id": "33",
        "title": "Modality-Aware SAM: Sharpness-Aware-Minimization Driven Gradient Modulation for Harmonized Multimodal Learning",
        "author": [
            "Hossein R. Nowdeh",
            "Jie Ji",
            "Xiaolong Ma",
            "Fatemeh Afghah"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24919",
        "abstract": "In multimodal learning, dominant modalities often overshadow others, limiting generalization. We propose Modality-Aware Sharpness-Aware Minimization (M-SAM), a model-agnostic framework that applies to many modalities and supports early and late fusion scenarios. In every iteration, M-SAM in three steps optimizes learning. \\textbf{First, it identifies the dominant modality} based on modalities' contribution in the accuracy using Shapley. \\textbf{Second, it decomposes the loss landscape}, or in another language, it modulates the loss to prioritize the robustness of the model in favor of the dominant modality, and \\textbf{third, M-SAM updates the weights} by backpropagation of modulated gradients. This ensures robust learning for the dominant modality while enhancing contributions from others, allowing the model to explore and exploit complementary features that strengthen overall performance. Extensive experiments on four diverse datasets show that M-SAM outperforms the latest state-of-the-art optimization and gradient manipulation methods and significantly balances and improves multimodal learning.",
        "tags": [
            "SAM"
        ]
    },
    {
        "id": "34",
        "title": "S3C2 Summit 2025-03: Industry Secure Supply Chain Summit",
        "author": [
            "Elizabeth Lin",
            "Jonah Ghebremichael",
            "William Enck",
            "Yasemin Acar",
            "Michel Cukier",
            "Alexandros Kapravelos",
            "Christian Kastner",
            "Laurie Williams"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24920",
        "abstract": "Software supply chains, while providing immense economic and software development value, are only as strong as their weakest link. Over the past several years, there has been an exponential increase in cyberattacks specifically targeting vulnerable links in critical software supply chains. These attacks disrupt the day-to-day functioning and threaten the security of nearly everyone on the internet, from billion-dollar companies and government agencies to hobbyist open-source developers. The ever-evolving threat of software supply chain attacks has garnered interest from both the software industry and US government in improving software supply chain security. On Thursday, March 6th, 2025, four researchers from the NSF-backed Secure Software Supply Chain Center (S3C2) conducted a Secure Software Supply Chain Summit with a diverse set of 18 practitioners from 17 organizations. The goals of the Summit were: (1) to enable sharing between participants from different industries regarding practical experiences and challenges with software supply chain security; (2) to help form new collaborations; and (3) to learn about the challenges facing participants to inform our future research directions. The summit consisted of discussions of six topics relevant to the government agencies represented, including software bill of materials (SBOMs); compliance; malicious commits; build infrastructure; culture; and large language models (LLMs) and security. For each topic of discussion, we presented a list of questions to participants to spark conversation. In this report, we provide a summary of the summit. The open questions and challenges that remained after each topic are listed at the end of each topic's section, and the initial discussion questions for each topic are provided in the appendix.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "35",
        "title": "KAN-GCN: Combining Kolmogorov-Arnold Network with Graph Convolution Network for an Accurate Ice Sheet Emulator",
        "author": [
            "Zesheng Liu",
            "YoungHyun Koo",
            "Maryam Rahnemoonfar"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24926",
        "abstract": "We introduce KAN-GCN, a fast and accurate emulator for ice sheet modeling that places a Kolmogorov-Arnold Network (KAN) as a feature-wise calibrator before graph convolution networks (GCNs). The KAN front end applies learnable one-dimensional warps and a linear mixing step, improving feature conditioning and nonlinear encoding without increasing message-passing depth. We employ this architecture to improve the performance of emulators for numerical ice sheet models. Our emulator is trained and tested using 36 melting-rate simulations with 3 mesh-size settings for Pine Island Glacier, Antarctica. Across 2- to 5-layer architectures, KAN-GCN matches or exceeds the accuracy of pure GCN and MLP-GCN baselines. Despite a small parameter overhead, KAN-GCN improves inference throughput on coarser meshes by replacing one edge-wise message-passing layer with a node-wise transform; only the finest mesh shows a modest cost. Overall, KAN-first designs offer a favorable accuracy vs. efficiency trade-off for large transient scenario sweeps.",
        "tags": [
            "KAN"
        ]
    },
    {
        "id": "36",
        "title": "RiddleBench: A New Generative Reasoning Benchmark for LLMs",
        "author": [
            "Deepon Halder",
            "Alan Saji",
            "Thanmay Jayakumar",
            "Ratish Puduppully",
            "Anoop Kunchukuttan",
            "Raj Dabre"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24932",
        "abstract": "Large Language Models have demonstrated strong performance on many established reasoning benchmarks. However, these benchmarks primarily evaluate structured skills like quantitative problem-solving, leaving a gap in assessing flexible, multifaceted reasoning abilities that are central to human intelligence. These abilities require integrating logical deduction with spatial awareness and constraint satisfaction, which current evaluations do not measure well. To address this, we introduce RiddleBench, a benchmark of 1,737 challenging puzzles in English designed to probe these core reasoning capabilities. Evaluation of state-of-the-art models on RiddleBench shows fundamental weaknesses. Even top proprietary models like Gemini 2.5 Pro, o3, and Claude 4 Sonnet achieve accuracy just above 60% (60.30%, 63.37%, and 63.16%). Analysis further reveals deep failures, including hallucination cascades (accepting flawed reasoning from other models) and poor self-correction due to a strong self-confirmation bias. Their reasoning is also fragile, with performance degrading significantly when constraints are reordered or irrelevant information is introduced. RiddleBench functions as a diagnostic tool for these issues and as a resource for guiding the development of more robust and reliable language models.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "37",
        "title": "OrchVis: Hierarchical Multi-Agent Orchestration for Human Oversight",
        "author": [
            "Jieyu Zhou"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24937",
        "abstract": "We introduce OrchVis, a multi-agent orchestration framework that visualizes, verifies, and coordinates goal-driven collaboration among LLM-based agents. Through hierarchical goal alignment, task assignment, and conflict resolution, OrchVis enables humans to supervise complex multi-agent workflows without micromanaging each step. The system parses user intent into structured goals, monitors execution via automated verification, and exposes inter-agent dependencies through an interactive planning panel. When conflicts arise, users can explore system-proposed alternatives and selectively replan. OrchVis advances human-centered design for multi-agent systems by combining transparent visualization with adaptive autonomy.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "38",
        "title": "SemCoT: Accelerating Chain-of-Thought Reasoning through Semantically-Aligned Implicit Tokens",
        "author": [
            "Yinhan He",
            "Wendy Zheng",
            "Yaochen Zhu",
            "Zaiyi Zheng",
            "Lin Su",
            "Sriram Vasudevan",
            "Qi Guo",
            "Liangjie Hong",
            "Jundong Li"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24940",
        "abstract": "The verbosity of Chain-of-Thought (CoT) reasoning hinders its mass deployment in efficiency-critical applications. Recently, implicit CoT approaches have emerged, which encode reasoning steps within LLM's hidden embeddings (termed ``implicit reasoning'') rather than explicit tokens. This approach accelerates CoT by reducing the reasoning length and bypassing some LLM components. However, existing implicit CoT methods face two significant challenges: (1) they fail to preserve the semantic alignment between the implicit reasoning (when transformed to natural language) and the ground-truth reasoning, resulting in a significant CoT performance degradation, and (2) they focus on reducing the length of the implicit reasoning; however, they neglect the considerable time cost for an LLM to generate one individual implicit reasoning token. To tackle these challenges, we propose a novel semantically-aligned implicit CoT framework termed SemCoT. In particular, for the first challenge, we design a contrastively trained sentence transformer that evaluates semantic alignment between implicit and explicit reasoning, which is used to enforce semantic preservation during implicit reasoning optimization. To address the second challenge, we introduce an efficient implicit reasoning generator by finetuning a lightweight language model using knowledge distillation. This generator is guided by our sentence transformer to distill ground-truth reasoning into semantically aligned implicit reasoning, while also optimizing for accuracy. SemCoT is the first approach that enhances CoT efficiency by jointly optimizing token-level generation speed and preserving semantic alignment with ground-truth reasoning. Extensive experiments demonstrate the superior performance of SemCoT compared to state-of-the-art methods in both efficiency and effectiveness. Our code can be found at https://github.com/YinhanHe123/SemCoT/.",
        "tags": [
            "CoT",
            "LLM",
            "Transformer"
        ]
    },
    {
        "id": "39",
        "title": "Can Aha Moments Be Fake? Identifying True and Decorative Thinking Steps in Chain-of-Thought",
        "author": [
            "Jiachen Zhao",
            "Yiyou Sun",
            "Weiyan Shi",
            "Dawn Song"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24941",
        "abstract": "Recent large language models (LLMs) can generate long Chain-of-Thought (CoT) at test time, enabling them to solve complex tasks. These reasoning steps in CoT are often assumed as a faithful reflection of the model's internal thinking process, and used to monitor unsafe intentions. However, we find many reasoning steps don't truly contribute to LLMs' prediction. We measure the step-wise causal influence of each reasoning step on the model's final prediction with a proposed True Thinking Score (TTS). We reveal that LLMs often interleave between true-thinking steps (which are genuinely used to produce the final output) and decorative-thinking steps (which only give the appearance of reasoning but have minimal causal impact). Notably, only a small subset of the total reasoning steps have a high TTS that causally drive the model's prediction: e.g., for the AIME dataset, only an average of 2.3% of reasoning steps in CoT have a TTS >= 0.7 (range: 0-1) under the Qwen-2.5 model. Furthermore, we identify a TrueThinking direction in the latent space of LLMs. By steering along or against this direction, we can force the model to perform or disregard certain CoT steps when computing the final result. Finally, we highlight that self-verification steps in CoT (i.e., aha moments) can also be decorative, where LLMs do not truly verify their solution. Steering along the TrueThinking direction can force internal reasoning over these steps, resulting in a change in the final results. Overall, our work reveals that LLMs often verbalize reasoning steps without actually performing them internally, which undermines both the efficiency of LLM reasoning and the trustworthiness of CoT.",
        "tags": [
            "CoT",
            "LLM",
            "Qwen"
        ]
    },
    {
        "id": "40",
        "title": "Finding Culture-Sensitive Neurons in Vision-Language Models",
        "author": [
            "Xiutian Zhao",
            "Rochelle Choenni",
            "Rohit Saxena",
            "Ivan Titov"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24942",
        "abstract": "Despite their impressive performance, vision-language models (VLMs) still struggle on culturally situated inputs. To understand how VLMs process culturally grounded information, we study the presence of culture-sensitive neurons, i.e. neurons whose activations show preferential sensitivity to inputs associated with particular cultural contexts. We examine whether such neurons are important for culturally diverse visual question answering and where they are located. Using the CVQA benchmark, we identify neurons of culture selectivity and perform causal tests by deactivating the neurons flagged by different identification methods. Experiments on three VLMs across 25 cultural groups demonstrate the existence of neurons whose ablation disproportionately harms performance on questions about the corresponding cultures, while having minimal effects on others. Moreover, we propose a new margin-based selector - Contrastive Activation Selection (CAS), and show that it outperforms existing probability- and entropy-based methods in identifying culture-sensitive neurons. Finally, our layer-wise analyses reveals that such neurons tend to cluster in certain decoder layers. Overall, our findings shed new light on the internal organization of multimodal representations.",
        "tags": [
            "VLM"
        ]
    },
    {
        "id": "41",
        "title": "Interpolated Discrepancy Data Assimilation for PDEs with Sparse Observations",
        "author": [
            "Tong Wu",
            "Humberto Godinez",
            "Vitaliy Gyrya",
            "James M. Hyman"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24944",
        "abstract": "Sparse sensor networks in weather and ocean modeling observe only a small fraction of the system state, which destabilizes standard nudging-based data assimilation. We introduce Interpolated Discrepancy Data Assimilation (IDDA), which modifies how discrepancies enter the governing equations. Rather than adding observations as a forcing term alone, IDDA also adjusts the nonlinear operator using interpolated observational information. This structural change suppresses error amplification when nonlinear effects dominate. We prove exponential convergence under explicit conditions linking error decay to observation spacing, nudging strength, and diffusion coefficient. The key requirement establishes bounds on nudging strength relative to observation spacing and diffusion, giving practitioners a clear operating window. When observations resolve the relevant scales, error decays at a user-specified rate. Critically, the error bound scales with the square of observation spacing rather than through hard-to-estimate nonlinear growth rates. We validate IDDA on Burgers flow, Kuramoto-Sivashinsky dynamics, and two-dimensional Navier-Stokes turbulence. Across these tests, IDDA reaches target accuracy faster than standard interpolated nudging, remains stable in chaotic regimes, avoids non-monotone transients, and requires minimal parameter tuning. Because IDDA uses standard explicit time integration, it fits readily into existing simulation pipelines without specialized solvers. These properties make IDDA a practical upgrade for operational systems constrained by sparse sensor coverage.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "42",
        "title": "SCOUT: A Lightweight Framework for Scenario Coverage Assessment in Autonomous Driving",
        "author": [
            "Anil Yildiz",
            "Sarah M. Thornton",
            "Carl Hildebrandt",
            "Sreeja Roy-Singh",
            "Mykel J. Kochenderfer"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24949",
        "abstract": "Assessing scenario coverage is crucial for evaluating the robustness of autonomous agents, yet existing methods rely on expensive human annotations or computationally intensive Large Vision-Language Models (LVLMs). These approaches are impractical for large-scale deployment due to cost and efficiency constraints. To address these shortcomings, we propose SCOUT (Scenario Coverage Oversight and Understanding Tool), a lightweight surrogate model designed to predict scenario coverage labels directly from an agent's latent sensor representations. SCOUT is trained through a distillation process, learning to approximate LVLM-generated coverage labels while eliminating the need for continuous LVLM inference or human annotation. By leveraging precomputed perception features, SCOUT avoids redundant computations and enables fast, scalable scenario coverage estimation. We evaluate our method across a large dataset of real-life autonomous navigation scenarios, demonstrating that it maintains high accuracy while significantly reducing computational cost. Our results show that SCOUT provides an effective and practical alternative for large-scale coverage analysis. While its performance depends on the quality of LVLM-generated training labels, SCOUT represents a major step toward efficient scenario coverage oversight in autonomous systems.",
        "tags": [
            "VLM"
        ]
    },
    {
        "id": "43",
        "title": "Language Model Behavioral Phases are Consistent Across Architecture, Training Data, and Scale",
        "author": [
            "James A. Michaelov",
            "Roger P. Levy",
            "Benjamin K. Bergen"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24963",
        "abstract": "We show that across architecture (Transformer vs. Mamba vs. RWKV), training dataset (OpenWebText vs. The Pile), and scale (14 million parameters to 12 billion parameters), autoregressive language models exhibit highly consistent patterns of change in their behavior over the course of pretraining. Based on our analysis of over 1,400 language model checkpoints on over 110,000 tokens of English, we find that up to 98% of the variance in language model behavior at the word level can be explained by three simple heuristics: the unigram probability (frequency) of a given word, the $n$-gram probability of the word, and the semantic similarity between the word and its context. Furthermore, we see consistent behavioral phases in all language models, with their predicted probabilities for words overfitting to those words' $n$-gram probabilities for increasing $n$ over the course of training. Taken together, these results suggest that learning in neural language models may follow a similar trajectory irrespective of model details.",
        "tags": [
            "Mamba",
            "RWKV",
            "Transformer"
        ]
    },
    {
        "id": "44",
        "title": "Sequences of Logits Reveal the Low Rank Structure of Language Models",
        "author": [
            "Noah Golowich",
            "Allen Liu",
            "Abhishek Shetty"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24966",
        "abstract": "A major problem in the study of large language models is to understand their inherent low-dimensional structure. We introduce an approach to study the low-dimensional structure of language models at a model-agnostic level: as sequential probabilistic models. We first empirically demonstrate that a wide range of modern language models exhibit low-rank structure: in particular, matrices built from the model's logits for varying sets of prompts and responses have low approximate rank. We then show that this low-rank structure can be leveraged for generation -- in particular, we can generate a response to a target prompt using a linear combination of the model's outputs on unrelated, or even nonsensical prompts.\nOn the theoretical front, we observe that studying the approximate rank of language models in the sense discussed above yields a simple universal abstraction whose theoretical predictions parallel our experiments. We then analyze the representation power of the abstraction and give provable learning guarantees.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "45",
        "title": "FT-ARM: Fine-Tuned Agentic Reflection Multimodal Language Model for Pressure Ulcer Severity Classification with Reasoning",
        "author": [
            "Reza Saadati Fard",
            "Emmanuel Agu",
            "Palawat Busaranuvong",
            "Deepak Kumar",
            "Shefalika Gautam",
            "Bengisu Tulu",
            "Diane Strong",
            "Lorraine Loretz"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24980",
        "abstract": "Pressure ulcers (PUs) are a serious and prevalent healthcare concern. Accurate classification of PU severity (Stages I-IV) is essential for proper treatment but remains challenging due to subtle visual distinctions and subjective interpretation, leading to variability among clinicians. Prior AI-based approaches using Convolutional Neural Networks (CNNs) and Vision Transformers (ViTs) achieved promising accuracy but offered limited interpretability. We present FT-ARM (Fine-Tuned Agentic Reflection Multimodal model), a fine-tuned multimodal large language model (MLLM) with an agentic self-reflection mechanism for pressure ulcer severity classification. Inspired by clinician-style diagnostic reassessment, FT-ARM iteratively refines its predictions by reasoning over visual features and encoded clinical knowledge from text, enhancing both accuracy and consistency. On the publicly available Pressure Injury Image Dataset (PIID), FT-ARM, fine-tuned from LLaMA 3.2 90B, achieved 85% accuracy in classifying PU stages I-IV, surpassing prior CNN-based models by +4%. Unlike earlier CNN/ViT studies that relied solely on offline evaluations, FT-ARM is designed and tested for live inference, reflecting real-time deployment conditions. Furthermore, it produces clinically grounded natural-language explanations, improving interpretability and trust. By integrating fine-tuning and reflective reasoning across multimodal inputs, FT-ARM advances the reliability, transparency, and clinical applicability of automated wound assessment systems, addressing the critical need for consistent and explainable PU staging to support improved patient care.",
        "tags": [
            "LLaMA",
            "ViT"
        ]
    },
    {
        "id": "46",
        "title": "LRT-Diffusion: Calibrated Risk-Aware Guidance for Diffusion Policies",
        "author": [
            "Ximan Sun",
            "Xiang Cheng"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24983",
        "abstract": "Diffusion policies are competitive for offline reinforcement learning (RL) but are typically guided at sampling time by heuristics that lack a statistical notion of risk. We introduce LRT-Diffusion, a risk-aware sampling rule that treats each denoising step as a sequential hypothesis test between the unconditional prior and the state-conditional policy head. Concretely, we accumulate a log-likelihood ratio and gate the conditional mean with a logistic controller whose threshold tau is calibrated once under H0 to meet a user-specified Type-I level alpha. This turns guidance from a fixed push into an evidence-driven adjustment with a user-interpretable risk budget. Importantly, we deliberately leave training vanilla (two heads with standard epsilon-prediction) under the structure of DDPM. LRT guidance composes naturally with Q-gradients: critic-gradient updates can be taken at the unconditional mean, at the LRT-gated mean, or a blend, exposing a continuum from exploitation to conservatism. We standardize states and actions consistently at train and test time and report a state-conditional out-of-distribution (OOD) metric alongside return. On D4RL MuJoCo tasks, LRT-Diffusion improves the return-OOD trade-off over strong Q-guided baselines in our implementation while honoring the desired alpha. Theoretically, we establish level-alpha calibration, concise stability bounds, and a return comparison showing when LRT surpasses Q-guidance-especially when off-support errors dominate. Overall, LRT-Diffusion is a drop-in, inference-time method that adds principled, calibrated risk control to diffusion policies for offline RL.",
        "tags": [
            "DDPM",
            "Diffusion",
            "RL"
        ]
    },
    {
        "id": "47",
        "title": "FaRAccel: FPGA-Accelerated Defense Architecture for Efficient Bit-Flip Attack Resilience in Transformer Models",
        "author": [
            "Najmeh Nazari",
            "Banafsheh Saber Latibari",
            "Elahe Hosseini",
            "Fatemeh Movafagh",
            "Chongzhou Fang",
            "Hosein Mohammadi Makrani",
            "Kevin Immanuel Gubbi",
            "Abhijit Mahalanobis",
            "Setareh Rafatirad",
            "Hossein Sayadi",
            "Houman Homayoun"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24985",
        "abstract": "Forget and Rewire (FaR) methodology has demonstrated strong resilience against Bit-Flip Attacks (BFAs) on Transformer-based models by obfuscating critical parameters through dynamic rewiring of linear layers. However, the application of FaR introduces non-negligible performance and memory overheads, primarily due to the runtime modification of activation pathways and the lack of hardware-level optimization. To overcome these limitations, we propose FaRAccel, a novel hardware accelerator architecture implemented on FPGA, specifically designed to offload and optimize FaR operations. FaRAccel integrates reconfigurable logic for dynamic activation rerouting, and lightweight storage of rewiring configurations, enabling low-latency inference with minimal energy overhead. We evaluate FaRAccel across a suite of Transformer models and demonstrate substantial reductions in FaR inference latency and improvement in energy efficiency, while maintaining the robustness gains of the original FaR methodology. To the best of our knowledge, this is the first hardware-accelerated defense against BFAs in Transformers, effectively bridging the gap between algorithmic resilience and efficient deployment on real-world AI platforms.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "48",
        "title": "Enhancing Hierarchical Reinforcement Learning through Change Point Detection in Time Series",
        "author": [
            "Hemanath Arumugam",
            "Falong Fan",
            "Bo Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24988",
        "abstract": "Hierarchical Reinforcement Learning (HRL) enhances the scalability of decision-making in long-horizon tasks by introducing temporal abstraction through options-policies that span multiple timesteps. Despite its theoretical appeal, the practical implementation of HRL suffers from the challenge of autonomously discovering semantically meaningful subgoals and learning optimal option termination boundaries. This paper introduces a novel architecture that integrates a self-supervised, Transformer-based Change Point Detection (CPD) module into the Option-Critic framework, enabling adaptive segmentation of state trajectories and the discovery of options. The CPD module is trained using heuristic pseudo-labels derived from intrinsic signals to infer latent shifts in environment dynamics without external supervision. These inferred change-points are leveraged in three critical ways: (i) to serve as supervisory signals for stabilizing termination function gradients, (ii) to pretrain intra-option policies via segment-wise behavioral cloning, and (iii) to enforce functional specialization through inter-option divergence penalties over CPD-defined state partitions. The overall optimization objective enhances the standard actor-critic loss using structure-aware auxiliary losses. In our framework, option discovery arises naturally as CPD-defined trajectory segments are mapped to distinct intra-option policies, enabling the agent to autonomously partition its behavior into reusable, semantically meaningful skills. Experiments on the Four-Rooms and Pinball tasks demonstrate that CPD-guided agents exhibit accelerated convergence, higher cumulative returns, and significantly improved option specialization. These findings confirm that integrating structural priors via change-point segmentation leads to more interpretable, sample-efficient, and robust hierarchical policies in complex environments.",
        "tags": [
            "Detection",
            "RL",
            "Segmentation",
            "Transformer"
        ]
    },
    {
        "id": "49",
        "title": "Defect Mitigation for Robot Arm-based Additive Manufacturing Utilizing Intelligent Control and IOT",
        "author": [
            "Matsive Ali",
            "Blake Gassen",
            "Sen Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24994",
        "abstract": "This paper presents an integrated robotic fused deposition modeling additive manufacturing system featuring closed-loop thermal control and intelligent in-situ defect correction using a 6-degree of freedom robotic arm and an Oak-D camera. The robot arm end effector was modified to mount an E3D hotend thermally regulated by an IoT microcontroller, enabling precise temperature control through real-time feedback. Filament extrusion system was synchronized with robotic motion, coordinated via ROS2, ensuring consistent deposition along complex trajectories. A vision system based on OpenCV detects layer-wise defects position, commanding autonomous re-extrusion at identified sites. Experimental validation demonstrated successful defect mitigation in printing operations. The integrated system effectively addresses challenges real-time quality assurance. Inverse kinematics were used for motion planning, while homography transformations corrected camera perspectives for accurate defect localization. The intelligent system successfully mitigated surface anomalies without interrupting the print process. By combining real-time thermal regulation, motion control, and intelligent defect detection & correction, this architecture establishes a scalable and adaptive robotic additive manufacturing framework suitable for aerospace, biomedical, and industrial applications.",
        "tags": [
            "Detection",
            "Robotics"
        ]
    },
    {
        "id": "50",
        "title": "SLIP-SEC: Formalizing Secure Protocols for Model IP Protection",
        "author": [
            "Racchit Jain",
            "Satya Lokam",
            "Yehonathan Refael",
            "Adam Hakim",
            "Lev Greenberg",
            "Jay Tenenbaum"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24999",
        "abstract": "Large Language Models (LLMs) represent valuable intellectual property (IP), reflecting significant investments in training data, compute, and expertise. Deploying these models on partially trusted or insecure devices introduces substantial risk of model theft, making it essential to design inference protocols with provable security guarantees.\nWe present the formal framework and security foundations of SLIP, a hybrid inference protocol that splits model computation between a trusted and an untrusted resource. We define and analyze the key notions of model decomposition and hybrid inference protocols, and introduce formal properties including safety, correctness, efficiency, and t-soundness. We construct secure inference protocols based on additive decompositions of weight matrices, combined with masking and probabilistic verification techniques. We prove that these protocols achieve information-theoretic security against honest-but-curious adversaries, and provide robustness against malicious adversaries with negligible soundness error.\nThis paper focuses on the theoretical underpinnings of SLIP: precise definitions, formal protocols, and proofs of security. Empirical validation and decomposition heuristics appear in the companion SLIP paper. Together, the two works provide a complete account of securing LLM IP via hybrid inference, bridging both practice and theory.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "51",
        "title": "Emergent Coordinated Behaviors in Networked LLM Agents: Modeling the Strategic Dynamics of Information Operations",
        "author": [
            "Gian Marco Orlando",
            "Jinyi Ye",
            "Valerio La Gatta",
            "Mahdi Saeedi",
            "Vincenzo Moscato",
            "Emilio Ferrara",
            "Luca Luceri"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25003",
        "abstract": "Generative agents are rapidly advancing in sophistication, raising urgent questions about how they might coordinate when deployed in online ecosystems. This is particularly consequential in information operations (IOs), influence campaigns that aim to manipulate public opinion on social media. While traditional IOs have been orchestrated by human operators and relied on manually crafted tactics, agentic AI promises to make campaigns more automated, adaptive, and difficult to detect. This work presents the first systematic study of emergent coordination among generative agents in simulated IO campaigns. Using generative agent-based modeling, we instantiate IO and organic agents in a simulated environment and evaluate coordination across operational regimes, from simple goal alignment to team knowledge and collective decision-making. As operational regimes become more structured, IO networks become denser and more clustered, interactions more reciprocal and positive, narratives more homogeneous, amplification more synchronized, and hashtag adoption faster and more sustained. Remarkably, simply revealing to agents which other agents share their goals can produce coordination levels nearly equivalent to those achieved through explicit deliberation and collective voting. Overall, we show that generative agents, even without human guidance, can reproduce coordination strategies characteristic of real-world IOs, underscoring the societal risks posed by increasingly automated, self-organizing IOs.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "52",
        "title": "Emergence of Minimal Circuits for Indirect Object Identification in Attention-Only Transformers",
        "author": [
            "Rabin Adhikari"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25013",
        "abstract": "Mechanistic interpretability aims to reverse-engineer large language models (LLMs) into human-understandable computational circuits. However, the complexity of pretrained models often obscures the minimal mechanisms required for specific reasoning tasks. In this work, we train small, attention-only transformers from scratch on a symbolic version of the Indirect Object Identification (IOI) task -- a benchmark for studying coreference -- like reasoning in transformers. Surprisingly, a single-layer model with only two attention heads achieves perfect IOI accuracy, despite lacking MLPs and normalization layers. Through residual stream decomposition, spectral analysis, and embedding interventions, we find that the two heads specialize into additive and contrastive subcircuits that jointly implement IOI resolution. Furthermore, we show that a two-layer, one-head model achieves similar performance by composing information across layers through query-value interactions. These results demonstrate that task-specific training induces highly interpretable, minimal circuits, offering a controlled testbed for probing the computational foundations of transformer reasoning.",
        "tags": [
            "LLM",
            "Transformer"
        ]
    },
    {
        "id": "53",
        "title": "Aligning Large Language Models with Procedural Rules: An Autoregressive State-Tracking Prompting for In-Game Trading",
        "author": [
            "Minkyung Kim",
            "Junsik Kim",
            "Woongcheol Yang",
            "Sangdon Park",
            "Sohee Bae"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25014",
        "abstract": "Large Language Models (LLMs) enable dynamic game interactions but fail to follow essential procedural flows in rule-governed trading systems, eroding player trust. This work resolves the core tension between the creative flexibility of LLMs and the procedural demands of in-game trading (browse-offer-review-confirm). To this end, Autoregressive State-Tracking Prompting (ASTP) is introduced, a methodology centered on a strategically orchestrated prompt that compels an LLM to make its state-tracking process explicit and verifiable. Instead of relying on implicit contextual understanding, ASTP tasks the LLM with identifying and reporting a predefined state label from the previous turn. To ensure transactional integrity, this is complemented by a state-specific placeholder post-processing method for accurate price calculations. Evaluation across 300 trading dialogues demonstrates >99% state compliance and 99.3% calculation precision. Notably, ASTP with placeholder post-processing on smaller models (Gemini-2.5-Flash) matches larger models' (Gemini-2.5-Pro) performance while reducing response time from 21.2s to 2.4s, establishing a practical foundation that satisfies both real-time requirements and resource constraints of commercial games.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "54",
        "title": "VeriStruct: AI-assisted Automated Verification of Data-Structure Modules in Verus",
        "author": [
            "Chuyue Sun",
            "Yican Sun",
            "Daneshvar Amrollahi",
            "Ethan Zhang",
            "Shuvendu Lahiri",
            "Shan Lu",
            "David Dill",
            "Clark Barrett"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25015",
        "abstract": "We introduce VeriStruct, a novel framework that extends AI-assisted automated verification from single functions to more complex data structure modules in Verus. VeriStruct employs a planner module to orchestrate the systematic generation of abstractions, type invariants, specifications, and proof code. To address the challenge that LLMs often misunderstand Verus' annotation syntax and verification-specific semantics, VeriStruct embeds syntax guidance within prompts and includes a repair stage to automatically correct annotation errors. In an evaluation on eleven Rust data structure modules, VeriStruct succeeds on ten of the eleven, successfully verifying 128 out of 129 functions (99.2%) in total. These results represent an important step toward the goal of automatic AI-assisted formal verification.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "55",
        "title": "Towards Human-AI Synergy in Requirements Engineering: A Framework and Preliminary Study",
        "author": [
            "Mateen Ahmed Abbasi",
            "Petri Ihantola",
            "Tommi Mikkonen",
            "Niko MÃ¤kitalo"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25016",
        "abstract": "The future of Requirements Engineering (RE) is increasingly driven by artificial intelligence (AI), reshaping how we elicit, analyze, and validate requirements. Traditional RE is based on labor-intensive manual processes prone to errors and complexity. AI-powered approaches, specifically large language models (LLMs), natural language processing (NLP), and generative AI, offer transformative solutions and reduce inefficiencies. However, the use of AI in RE also brings challenges like algorithmic bias, lack of explainability, and ethical concerns related to automation. To address these issues, this study introduces the Human-AI RE Synergy Model (HARE-SM), a conceptual framework that integrates AI-driven analysis with human oversight to improve requirements elicitation, analysis, and validation. The model emphasizes ethical AI use through transparency, explainability, and bias mitigation. We outline a multi-phase research methodology focused on preparing RE datasets, fine-tuning AI models, and designing collaborative human-AI workflows. This preliminary study presents the conceptual framework and early-stage prototype implementation, establishing a research agenda and practical design direction for applying intelligent data science techniques to semi-structured and unstructured RE data in collaborative environments.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "56",
        "title": "StorageXTuner: An LLM Agent-Driven Automatic Tuning Framework for Heterogeneous Storage Systems",
        "author": [
            "Qi Lin",
            "Zhenyu Zhang",
            "Viraj Thakkar",
            "Zhenjie Sun",
            "Mai Zheng",
            "Zhichao Cao"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25017",
        "abstract": "Automatically configuring storage systems is hard: parameter spaces are large and conditions vary across workloads, deployments, and versions. Heuristic and ML tuners are often system specific, require manual glue, and degrade under changes. Recent LLM-based approaches help but usually treat tuning as a single-shot, system-specific task, which limits cross-system reuse, constrains exploration, and weakens validation. We present StorageXTuner, an LLM agent-driven auto-tuning framework for heterogeneous storage engines. StorageXTuner separates concerns across four agents - Executor (sandboxed benchmarking), Extractor (performance digest), Searcher (insight-guided configuration exploration), and Reflector (insight generation and management). The design couples an insight-driven tree search with layered memory that promotes empirically validated insights and employs lightweight checkers to guard against unsafe actions. We implement a prototype and evaluate it on RocksDB, LevelDB, CacheLib, and MySQL InnoDB with YCSB, MixGraph, and TPC-H/C. Relative to out-of-the-box settings and to ELMo-Tune, StorageXTuner reaches up to 575% and 111% higher throughput, reduces p99 latency by as much as 88% and 56%, and converges with fewer trials.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "57",
        "title": "Secure Retrieval-Augmented Generation against Poisoning Attacks",
        "author": [
            "Zirui Cheng",
            "Jikai Sun",
            "Anjun Gao",
            "Yueyang Quan",
            "Zhuqing Liu",
            "Xiaohua Hu",
            "Minghong Fang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25025",
        "abstract": "Large language models (LLMs) have transformed natural language processing (NLP), enabling applications from content generation to decision support. Retrieval-Augmented Generation (RAG) improves LLMs by incorporating external knowledge but also introduces security risks, particularly from data poisoning, where the attacker injects poisoned texts into the knowledge database to manipulate system outputs. While various defenses have been proposed, they often struggle against advanced attacks. To address this, we introduce RAGuard, a detection framework designed to identify poisoned texts. RAGuard first expands the retrieval scope to increase the proportion of clean texts, reducing the likelihood of retrieving poisoned content. It then applies chunk-wise perplexity filtering to detect abnormal variations and text similarity filtering to flag highly similar texts. This non-parametric approach enhances RAG security, and experiments on large-scale datasets demonstrate its effectiveness in detecting and mitigating poisoning attacks, including strong adaptive attacks.",
        "tags": [
            "Detection",
            "LLM",
            "RAG"
        ]
    },
    {
        "id": "58",
        "title": "Automating Benchmark Design",
        "author": [
            "Amanda Dsouza",
            "Harit Vishwakarma",
            "Zhengyang Qi",
            "Justin Bauer",
            "Derek Pham",
            "Thomas Walshe",
            "Armin Parchami",
            "Frederic Sala",
            "Paroma Varma"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25039",
        "abstract": "The rapid progress and widespread deployment of LLMs and LLM-powered agents has outpaced our ability to evaluate them. Hand-crafted, static benchmarks are the primary tool for assessing model capabilities, but these quickly become saturated. In contrast, dynamic benchmarks evolve alongside the models they evaluate, but are expensive to create and continuously update. To address these challenges, we develop BeTaL (Benchmark Tuning with an LLM-in-the-loop), a framework that leverages environment design principles to automate the process of dynamic benchmark design. BeTaL works by parameterizing key design choices in base benchmark templates and uses LLMs to reason through the resulting parameter space to obtain target properties (such as difficulty and realism) in a cost-efficient manner. We validate this approach on its ability to create benchmarks with desired difficulty levels. Using BeTaL, we create two new benchmarks and extend a popular agentic benchmark {\\tau} -bench. Extensive evaluation on these three tasks and multiple target difficulty levels shows that BeTaL produces benchmarks much closer to the desired difficulty, with average deviations ranging from 5.3% to 13.2% -- a 2-4x improvement over the baselines.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "59",
        "title": "Scalable predictive processing framework for multitask caregiving robots",
        "author": [
            "Hayato Idei",
            "Tamon Miyake",
            "Tetsuya Ogata",
            "Yuichi Yamashita"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25053",
        "abstract": "The rapid aging of societies is intensifying demand for autonomous care robots; however, most existing systems are task-specific and rely on handcrafted preprocessing, limiting their ability to generalize across diverse scenarios. A prevailing theory in cognitive neuroscience proposes that the human brain operates through hierarchical predictive processing, which underlies flexible cognition and behavior by integrating multimodal sensory signals. Inspired by this principle, we introduce a hierarchical multimodal recurrent neural network grounded in predictive processing under the free-energy principle, capable of directly integrating over 30,000-dimensional visuo-proprioceptive inputs without dimensionality reduction. The model was able to learn two representative caregiving tasks, rigid-body repositioning and flexible-towel wiping, without task-specific feature engineering. We demonstrate three key properties: (i) self-organization of hierarchical latent dynamics that regulate task transitions, capture variability in uncertainty, and infer occluded states; (ii) robustness to degraded vision through visuo-proprioceptive integration; and (iii) asymmetric interference in multitask learning, where the more variable wiping task had little influence on repositioning, whereas learning the repositioning task led to a modest reduction in wiping performance, while the model maintained overall robustness. Although the evaluation was limited to simulation, these results establish predictive processing as a universal and scalable computational principle, pointing toward robust, flexible, and autonomous caregiving robots while offering theoretical insight into the human brain's ability to achieve flexible adaptation in uncertain real-world environments.",
        "tags": [
            "RNN"
        ]
    },
    {
        "id": "60",
        "title": "GAPMAP: Mapping Scientific Knowledge Gaps in Biomedical Literature Using Large Language Models",
        "author": [
            "Nourah M Salem",
            "Elizabeth White",
            "Michael Bada",
            "Lawrence Hunter"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25055",
        "abstract": "Scientific progress is driven by the deliberate articulation of what remains unknown. This study investigates the ability of large language models (LLMs) to identify research knowledge gaps in the biomedical literature. We define two categories of knowledge gaps: explicit gaps, clear declarations of missing knowledge; and implicit gaps, context-inferred missing knowledge. While prior work has focused mainly on explicit gap detection, we extend this line of research by addressing the novel task of inferring implicit gaps. We conducted two experiments on almost 1500 documents across four datasets, including a manually annotated corpus of biomedical articles. We benchmarked both closed-weight models (from OpenAI) and open-weight models (Llama and Gemma 2) under paragraph-level and full-paper settings. To address the reasoning of implicit gaps inference, we introduce \\textbf{\\small TABI}, a Toulmin-Abductive Bucketed Inference scheme that structures reasoning and buckets inferred conclusion candidates for validation. Our results highlight the robust capability of LLMs in identifying both explicit and implicit knowledge gaps. This is true for both open- and closed-weight models, with larger variants often performing better. This suggests a strong ability of LLMs for systematically identifying candidate knowledge gaps, which can support early-stage research formulation, policymakers, and funding decisions. We also report observed failure modes and outline directions for robust deployment, including domain adaptation, human-in-the-loop verification, and benchmarking across open- and closed-weight models.",
        "tags": [
            "Detection",
            "LLM",
            "LLaMA"
        ]
    },
    {
        "id": "61",
        "title": "Control Synthesis with Reinforcement Learning: A Modeling Perspective",
        "author": [
            "Nikki Xu",
            "Hien Tran"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25063",
        "abstract": "Controllers designed with reinforcement learning can be sensitive to model mismatch. We demonstrate that designing such controllers in a virtual simulation environment with an inaccurate model is not suitable for deployment in a physical setup. Controllers designed using an accurate model is robust against disturbance and small mismatch between the physical setup and the mathematical model derived from first principles; while a poor model results in a controller that performs well in simulation but fails in physical experiments. Sensitivity analysis is used to justify these discrepancies and an empirical region of attraction estimation help us visualize their robustness.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "62",
        "title": "Can LLMs Estimate Cognitive Complexity of Reading Comprehension Items?",
        "author": [
            "Seonjeong Hwang",
            "Hyounghun Kim",
            "Gary Geunbae Lee"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25064",
        "abstract": "Estimating the cognitive complexity of reading comprehension (RC) items is crucial for assessing item difficulty before it is administered to learners. Unlike syntactic and semantic features, such as passage length or semantic similarity between options, cognitive features that arise during answer reasoning are not readily extractable using existing NLP tools and have traditionally relied on human annotation. In this study, we examine whether large language models (LLMs) can estimate the cognitive complexity of RC items by focusing on two dimensions-Evidence Scope and Transformation Level-that indicate the degree of cognitive burden involved in reasoning about the answer. Our experimental results demonstrate that LLMs can approximate the cognitive complexity of items, indicating their potential as tools for prior difficulty analysis. Further analysis reveals a gap between LLMs' reasoning ability and their metacognitive awareness: even when they produce correct answers, they sometimes fail to correctly identify the features underlying their own reasoning process.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "63",
        "title": "Reasoning-Aware GRPO using Process Mining",
        "author": [
            "Taekhyun Park",
            "Yongjae Lee",
            "Hyerim Bae"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25065",
        "abstract": "Reinforcement learning (RL)-based post-training has been crucial for enabling multi-step reasoning in large reasoning models (LRMs), yet current reward schemes are typically outcome-centric. We propose PM4GRPO, a reasoning-aware Group Relative Policy Optimization (GRPO) that augments standard answer/format rewards with signals over the reasoning procedure. To this end, process mining techniques are utilized to compute a scalar conformance reward that measures how closely a policy model's reasoning aligns with the pretrained teacher model. The empirical results on five benchmarks demonstrate that PM4GRPO significantly outperforms existing methodologies for GRPO-based post-training. These results highlight that leveraging process mining for reasoning-aware GRPO effectively enhances the reasoning capabilities of policy models.",
        "tags": [
            "GRPO",
            "RL"
        ]
    },
    {
        "id": "64",
        "title": "TOPol: Capturing and Explaining Multidimensional Semantic Polarity Fields and Vectors",
        "author": [
            "Gabin Taibi",
            "Lucia Gomez"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25069",
        "abstract": "Traditional approaches to semantic polarity in computational linguistics treat sentiment as a unidimensional scale, overlooking the multidimensional structure of language. This work introduces TOPol (Topic-Orientation POLarity), a semi-unsupervised framework for reconstructing and interpreting multidimensional narrative polarity fields under human-on-the-loop (HoTL) defined contextual boundaries (CBs). The framework embeds documents using a transformer-based large language model (tLLM), applies neighbor-tuned UMAP projection, and segments topics via Leiden partitioning. Given a CB between discourse regimes A and B, TOPol computes directional vectors between corresponding topic-boundary centroids, yielding a polarity field that quantifies fine-grained semantic displacement during regime shifts. This vectorial representation enables assessing CB quality and detecting polarity changes, guiding HoTL CB refinement. To interpret identified polarity vectors, the tLLM compares their extreme points and produces contrastive labels with estimated coverage. Robustness analyses show that only CB definitions (the main HoTL-tunable parameter) significantly affect results, confirming methodological stability. We evaluate TOPol on two corpora: (i) U.S. Central Bank speeches around a macroeconomic breakpoint, capturing non-affective semantic shifts, and (ii) Amazon product reviews across rating strata, where affective polarity aligns with NRC valence. Results demonstrate that TOPol consistently captures both affective and non-affective polarity transitions, providing a scalable, generalizable, and interpretable framework for context-sensitive multidimensional discourse analysis.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "65",
        "title": "Vision-Language Integration for Zero-Shot Scene Understanding in Real-World Environments",
        "author": [
            "Manjunath Prasad Holenarasipura Rajiv",
            "B. M. Vidyavathi"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25070",
        "abstract": "Zero-shot scene understanding in real-world settings presents major challenges due to the complexity and variability of natural scenes, where models must recognize new objects, actions, and contexts without prior labeled examples. This work proposes a vision-language integration framework that unifies pre-trained visual encoders (e.g., CLIP, ViT) and large language models (e.g., GPT-based architectures) to achieve semantic alignment between visual and textual modalities. The goal is to enable robust zero-shot comprehension of scenes by leveraging natural language as a bridge to generalize over unseen categories and contexts. Our approach develops a unified model that embeds visual inputs and textual prompts into a shared space, followed by multimodal fusion and reasoning layers for contextual interpretation. Experiments on Visual Genome, COCO, ADE20K, and custom real-world datasets demonstrate significant gains over state-of-the-art zero-shot models in object recognition, activity detection, and scene captioning. The proposed system achieves up to 18% improvement in top-1 accuracy and notable gains in semantic coherence metrics, highlighting the effectiveness of cross-modal alignment and language grounding in enhancing generalization for real-world scene understanding.",
        "tags": [
            "CLIP",
            "Detection",
            "GPT",
            "LLM",
            "ViT"
        ]
    },
    {
        "id": "66",
        "title": "Joint Analysis of Acoustic Scenes and Sound Events Based on Semi-Supervised Training of Sound Events With Partial Labels",
        "author": [
            "Keisuke Imoto"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25075",
        "abstract": "Annotating time boundaries of sound events is labor-intensive, limiting the scalability of strongly supervised learning in audio detection. To reduce annotation costs, weakly-supervised learning with only clip-level labels has been widely adopted. As an alternative, partial label learning offers a cost-effective approach, where a set of possible labels is provided instead of exact weak annotations. However, partial label learning for audio analysis remains largely unexplored. Motivated by the observation that acoustic scenes provide contextual information for constructing a set of possible sound events, we utilize acoustic scene information to construct partial labels of sound events. On the basis of this idea, in this paper, we propose a multitask learning framework that jointly performs acoustic scene classification and sound event detection with partial labels of sound events. While reducing annotation costs, weakly-supervised and partial label learning often suffer from decreased detection performance due to lacking the precise event set and their temporal annotations. To better balance between annotation cost and detection performance, we also explore a semi-supervised framework that leverages both strong and partial labels. Moreover, to refine partial labels and achieve better model training, we propose a label refinement method based on self-distillation for the proposed approach with partial labels.",
        "tags": [
            "CLIP",
            "Detection"
        ]
    },
    {
        "id": "67",
        "title": "Mean-Shift Theory and Its Applications in Swarm Robotics: A New Way to Enhance the Efficiency of Multi-Robot Collaboration",
        "author": [
            "Guibin Sun",
            "Jinhu LÃ¼",
            "Kexin Liu",
            "Zhenqian Wang",
            "Guanrong Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25086",
        "abstract": "Swarms evolving from collective behaviors among multiple individuals are commonly seen in nature, which enables biological systems to exhibit more efficient and robust collaboration. Creating similar swarm intelligence in engineered robots poses challenges to the design of collaborative algorithms that can be programmed at large scales. The assignment-based method has played an eminent role for a very long time in solving collaboration problems of robot swarms. However, it faces fundamental limitations in terms of efficiency and robustness due to its unscalability to swarm variants. This article presents a tutorial review on recent advances in assignment-free collaboration of robot swarms, focusing on the problem of shape formation. A key theoretical component is the recently developed \\emph{mean-shift exploration} strategy, which improves the collaboration efficiency of large-scale swarms by dozens of times. Further, the efficiency improvement is more significant as the swarm scale increases. Finally, this article discusses three important applications of the mean-shift exploration strategy, including precise shape formation, area coverage formation, and maneuvering formation, as well as their corresponding industrial scenarios in smart warehousing, area exploration, and cargo transportation.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "68",
        "title": "BioCoref: Benchmarking Biomedical Coreference Resolution with LLMs",
        "author": [
            "Nourah M Salem",
            "Elizabeth White",
            "Michael Bada",
            "Lawrence Hunter"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25087",
        "abstract": "Coreference resolution in biomedical texts presents unique challenges due to complex domain-specific terminology, high ambiguity in mention forms, and long-distance dependencies between coreferring expressions. In this work, we present a comprehensive evaluation of generative large language models (LLMs) for coreference resolution in the biomedical domain. Using the CRAFT corpus as our benchmark, we assess the LLMs' performance with four prompting experiments that vary in their use of local, contextual enrichment, and domain-specific cues such as abbreviations and entity dictionaries. We benchmark these approaches against a discriminative span-based encoder, SpanBERT, to compare the efficacy of generative versus discriminative methods. Our results demonstrate that while LLMs exhibit strong surface-level coreference capabilities, especially when supplemented with domain-grounding prompts, their performance remains sensitive to long-range context and mentions ambiguity. Notably, the LLaMA 8B and 17B models show superior precision and F1 scores under entity-augmented prompting, highlighting the potential of lightweight prompt engineering for enhancing LLM utility in biomedical NLP tasks.",
        "tags": [
            "LLM",
            "LLaMA"
        ]
    },
    {
        "id": "69",
        "title": "H3M-SSMoEs: Hypergraph-based Multimodal Learning with LLM Reasoning and Style-Structured Mixture of Experts",
        "author": [
            "Peilin Tan",
            "Liang Xie",
            "Churan Zhi",
            "Dian Tu",
            "Chuanqi Shi"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25091",
        "abstract": "Stock movement prediction remains fundamentally challenging due to complex temporal dependencies, heterogeneous modalities, and dynamically evolving inter-stock relationships. Existing approaches often fail to unify structural, semantic, and regime-adaptive modeling within a scalable framework. This work introduces H3M-SSMoEs, a novel Hypergraph-based MultiModal architecture with LLM reasoning and Style-Structured Mixture of Experts, integrating three key innovations: (1) a Multi-Context Multimodal Hypergraph that hierarchically captures fine-grained spatiotemporal dynamics via a Local Context Hypergraph (LCH) and persistent inter-stock dependencies through a Global Context Hypergraph (GCH), employing shared cross-modal hyperedges and Jensen-Shannon Divergence weighting mechanism for adaptive relational learning and cross-modal alignment; (2) a LLM-enhanced reasoning module, which leverages a frozen large language model with lightweight adapters to semantically fuse and align quantitative and textual modalities, enriching representations with domain-specific financial knowledge; and (3) a Style-Structured Mixture of Experts (SSMoEs) that combines shared market experts and industry-specialized experts, each parameterized by learnable style vectors enabling regime-aware specialization under sparse activation. Extensive experiments on three major stock markets demonstrate that H3M-SSMoEs surpasses state-of-the-art methods in both superior predictive accuracy and investment performance, while exhibiting effective risk control. Datasets, source code, and model weights are available at our GitHub repository: https://github.com/PeilinTime/H3M-SSMoEs.",
        "tags": [
            "LLM",
            "MoE"
        ]
    },
    {
        "id": "70",
        "title": "SeeingEye: Agentic Information Flow Unlocks Multimodal Reasoning In Text-only LLMs",
        "author": [
            "Weijia Zhang",
            "Zijia Liu",
            "Haoru Li",
            "Haoqi Chen",
            "Jiaxuan You"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25092",
        "abstract": "Recent advances in text-only large language models (LLMs), such as DeepSeek-R1, demonstrate remarkable reasoning ability. However, these models remain fragile or entirely incapable when extended to multi-modal tasks. Existing approaches largely rely on single-form captions, which lack diversity and often fail to adapt across different types of Visual Question Answering (VQA) benchmarks. As a result, they provide no principled or efficient channel for transmitting fine-grained visual information. We introduce Seeing Eye, a modular framework that unlocks multimodal reasoning in text-only LLMs through an agent-based small VLM translator. This translator acts as a perception agent: it can invoke specialized tools (e.g., OCR and crop) and iteratively distill multimodal inputs into structured intermediate representations (SIRs) tailored to the question. These SIRs are then passed to the text-only LLM, which serves as a reasoning agent. Crucially, the translator and reasoner engage in multi-round feedback and interaction, enabling the extraction of targeted visual details and yielding more confident answers. Experiments on knowledge-intensive VQA benchmarks, including MMMU and MIA-Bench, demonstrate that Seeing Eye not only reduces inference cost but also surpasses much larger end-to-end VLMs. For example, an instantiation combining a 3B-parameter vision translator with an 8B-parameter language reasoner outperforms a monolithic 32B VLM on challenging knowledge-based questions. Our results highlight that decoupling perception from reasoning via agent information flow offers a scalable and plug-and-play pathway to multimodal reasoning, allowing strong text-only LLMs to fully leverage their reasoning capabilities. Code is available at: https://github.com/ulab-uiuc/SeeingEye",
        "tags": [
            "DeepSeek",
            "LLM",
            "VLM"
        ]
    },
    {
        "id": "71",
        "title": "Visual Diversity and Region-aware Prompt Learning for Zero-shot HOI Detection",
        "author": [
            "Chanhyeong Yang",
            "Taehoon Song",
            "Jihwan Park",
            "Hyunwoo J. Kim"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25094",
        "abstract": "Zero-shot Human-Object Interaction detection aims to localize humans and objects in an image and recognize their interaction, even when specific verb-object pairs are unseen during training. Recent works have shown promising results using prompt learning with pretrained vision-language models such as CLIP, which align natural language prompts with visual features in a shared embedding space. However, existing approaches still fail to handle the visual complexity of interaction, including (1) intra-class visual diversity, where instances of the same verb appear in diverse poses and contexts, and (2) inter-class visual entanglement, where distinct verbs yield visually similar patterns. To address these challenges, we propose VDRP, a framework for Visual Diversity and Region-aware Prompt learning. First, we introduce a visual diversity-aware prompt learning strategy that injects group-wise visual variance into the context embedding. We further apply Gaussian perturbation to encourage the prompts to capture diverse visual variations of a verb. Second, we retrieve region-specific concepts from the human, object, and union regions. These are used to augment the diversity-aware prompt embeddings, yielding region-aware prompts that enhance verb-level discrimination. Experiments on the HICO-DET benchmark demonstrate that our method achieves state-of-the-art performance under four zero-shot evaluation settings, effectively addressing both intra-class diversity and inter-class visual entanglement. Code is available at https://github.com/mlvlab/VDRP.",
        "tags": [
            "CLIP",
            "Detection",
            "VLM"
        ]
    },
    {
        "id": "72",
        "title": "Learning Fair Graph Representations with Multi-view Information Bottleneck",
        "author": [
            "Chuxun Liu",
            "Debo Cheng",
            "Qingfeng Chen",
            "Jiangzhang Gan",
            "Jiuyong Li",
            "Lin Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25096",
        "abstract": "Graph neural networks (GNNs) excel on relational data by passing messages over node features and structure, but they can amplify training data biases, propagating discriminatory attributes and structural imbalances into unfair outcomes. Many fairness methods treat bias as a single source, ignoring distinct attribute and structure effects and leading to suboptimal fairness and utility trade-offs. To overcome this challenge, we propose FairMIB, a multi-view information bottleneck framework designed to decompose graphs into feature, structural, and diffusion views for mitigating complexity biases in GNNs. Especially, the proposed FairMIB employs contrastive learning to maximize cross-view mutual information for bias-free representation learning. It further integrates multi-perspective conditional information bottleneck objectives to balance task utility and fairness by minimizing mutual information with sensitive attributes. Additionally, FairMIB introduces an inverse probability-weighted (IPW) adjacency correction in the diffusion view, which reduces the spread of bias propagation during message passing. Experiments on five real-world benchmark datasets demonstrate that FairMIB achieves state-of-the-art performance across both utility and fairness metrics.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "73",
        "title": "KnowCoder-A1: Incentivizing Agentic Reasoning Capability with Outcome Supervision for KBQA",
        "author": [
            "Zhuo Chen",
            "Fei Wang",
            "Zixuan Li",
            "Zhao Zhang",
            "Weiwei Ding",
            "Chuanguang Yang",
            "Yongjun Xu",
            "Xiaolong Jin",
            "Jiafeng Guo"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25101",
        "abstract": "Knowledge Base Question Answering (KBQA) aims to answer natural-language questions over a structured Knowledge Base (KB). Recent work improves KBQA by adopting an agentic reasoning paradigm, in which Large Language Models (LLMs) iteratively decompose a question, generate its corresponding logical queries, and interact with the KB to derive the answer. However, these methods typically fine-tune LLMs on reasoning trajectories synthesized via process supervision, which offers weak incentives for exploration and thus fails to strengthen the agentic reasoning ability. In this paper, we propose KnowCoder-A1, an LLM that can autonomously perform agentic reasoning on KBs to obtain answers. To incentivize autonomous exploration, KnowCoder-A1 trains the LLM under outcome-only supervision via a multi-stage curriculum reinforcement learning with an easy-to-hard curriculum. To establish foundational agentic capabilities, KnowCoder-A1 first fine-tunes the LLM on a small set of high-quality trajectories obtained through outcome-based rejection sampling. Then, to alleviate the reward sparsity inherent in outcome-only supervision, it applies multi-stage curriculum RL with reward schedules that progress from easy to hard. Trained with outcome-only supervision, KnowCoder-A1 exhibits powerful reasoning behaviors and consistently outperforms prior approaches across three mainstream datasets. Notably, on the zero-shot subset of GrailQA, KnowCoder-A1 achieves up to an 11.1% relative improvement while using only one-twelfth of the training data, demonstrating strong agentic reasoning capabilities.",
        "tags": [
            "LLM",
            "RL"
        ]
    },
    {
        "id": "74",
        "title": "Adaptive Proof Refinement with LLM-Guided Strategy Selection",
        "author": [
            "Minghai Lu",
            "Zhe Zhou",
            "Danning Xie",
            "Songlin Jia",
            "Benjamin Delaware",
            "Tianyi Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25103",
        "abstract": "Formal verification via theorem proving enables the expressive specification and rigorous proof of software correctness, but it is difficult to scale due to the significant manual effort and expertise required. While Large Language Models (LLMs) show potential in proof generation, they frequently produce incorrect proofs on the first attempt and require additional strategies for iterative refinement. However, existing approaches employ fixed refinement strategies and cannot dynamically choose an effective strategy based on the particular issues in a generated proof, which limits their performance. To overcome this limitation, we introduce Adapt, a novel proof refinement framework that leverages an LLM-guided decision-maker to dynamically select a suitable refinement strategy according to the state of the proof assistant and available context of an incorrect proof. We evaluate Adapt on two benchmarks against four existing methods and find that it significantly outperforms the best baseline on both by proving 16.63% and 18.58% more theorems, respectively. Furthermore, we demonstrate Adapt's generalizability by evaluating it across five different LLMs. We also conduct ablation studies to measure the contribution of each component and compare the trade-offs of alternative decision-maker designs.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "75",
        "title": "Learning-Based vs Human-Derived Congestion Control: An In-Depth Experimental Study",
        "author": [
            "Mihai Mazilu",
            "Luca Giacomoni",
            "George Parisis"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25105",
        "abstract": "Learning-based congestion control (CC), including Reinforcement-Learning, promises efficient CC in a fast-changing networking landscape, where evolving communication technologies, applications and traffic workloads pose severe challenges to human-derived, static CC algorithms. Learning-based CC is in its early days and substantial research is required to understand existing limitations, identify research challenges and, eventually, yield deployable solutions for real-world networks. In this paper, we extend our prior work and present a reproducible and systematic study of learning-based CC with the aim to highlight strengths and uncover fundamental limitations of the state-of-the-art. We directly contrast said approaches with widely deployed, human-derived CC algorithms, namely TCP Cubic and BBR (version 3). We identify challenges in evaluating learning-based CC, establish a methodology for studying said approaches and perform large-scale experimentation with learning-based CC approaches that are publicly available. We show that embedding fairness directly into reward functions is effective; however, the fairness properties do not generalise into unseen conditions. We then show that RL learning-based approaches existing approaches can acquire all available bandwidth while largely maintaining low latency. Finally, we highlight that existing the latest learning-based CC approaches under-perform when the available bandwidth and end-to-end latency dynamically change while remaining resistant to non-congestive loss. As with our initial study, our experimentation codebase and datasets are publicly available with the aim to galvanise the research community towards transparency and reproducibility, which have been recognised as crucial for researching and evaluating machine-generated policies.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "76",
        "title": "DEBATE: A Large-Scale Benchmark for Role-Playing LLM Agents in Multi-Agent, Long-Form Debates",
        "author": [
            "Yun-Shiuan Chuang",
            "Ruixuan Tu",
            "Chengtao Dai",
            "Smit Vasani",
            "Binwei Yao",
            "Michael Henry Tessler",
            "Sijia Yang",
            "Dhavan Shah",
            "Robert Hawkins",
            "Junjie Hu",
            "Timothy T. Rogers"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25110",
        "abstract": "Accurately modeling opinion change through social interactions is crucial for addressing issues like misinformation and polarization. While role-playing large language models (LLMs) offer a promising way to simulate human-like interactions, existing research shows that single-agent alignment does not guarantee authentic multi-agent group dynamics. Current LLM role-play setups often produce unnatural dynamics (e.g., premature convergence), without an empirical benchmark to measure authentic human opinion trajectories. To bridge this gap, we introduce DEBATE, the first large-scale empirical benchmark explicitly designed to evaluate the authenticity of the interaction between multi-agent role-playing LLMs. DEBATE contains 29,417 messages from multi-round debate conversations among over 2,792 U.S.-based participants discussing 107 controversial topics, capturing both publicly-expressed messages and privately-reported opinions. Using DEBATE, we systematically evaluate and identify critical discrepancies between simulated and authentic group dynamics. We further demonstrate DEBATE's utility for aligning LLMs with human behavior through supervised fine-tuning, achieving improvements in surface-level metrics (e.g., ROUGE-L and message length) while highlighting limitations in deeper semantic alignment (e.g., semantic similarity). Our findings highlight both the potential and current limitations of role-playing LLM agents for realistically simulating human-like social dynamics.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "77",
        "title": "The Neural Differential Manifold: An Architecture with Explicit Geometric Structure",
        "author": [
            "Di Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25113",
        "abstract": "This paper introduces the Neural Differential Manifold (NDM), a novel neural network architecture that explicitly incorporates geometric structure into its fundamental design. Departing from conventional Euclidean parameter spaces, the NDM re-conceptualizes a neural network as a differentiable manifold where each layer functions as a local coordinate chart, and the network parameters directly parameterize a Riemannian metric tensor at every point. The architecture is organized into three synergistic layers: a Coordinate Layer implementing smooth chart transitions via invertible transformations inspired by normalizing flows, a Geometric Layer that dynamically generates the manifold's metric through auxiliary sub-networks, and an Evolution Layer that optimizes both task performance and geometric simplicity through a dual-objective loss function. This geometric regularization penalizes excessive curvature and volume distortion, providing intrinsic regularization that enhances generalization and robustness. The framework enables natural gradient descent optimization aligned with the learned manifold geometry and offers unprecedented interpretability by endowing internal representations with clear geometric meaning. We analyze the theoretical advantages of this approach, including its potential for more efficient optimization, enhanced continual learning, and applications in scientific discovery and controllable generative modeling. While significant computational challenges remain, the Neural Differential Manifold represents a fundamental shift towards geometrically structured, interpretable, and efficient deep learning systems.",
        "tags": [
            "Normalizing Flows"
        ]
    },
    {
        "id": "78",
        "title": "Energy Approach from $\\varepsilon$-Graph to Continuum Diffusion Model with Connectivity Functional",
        "author": [
            "Yahong Yang",
            "Sun Lee",
            "Jeff Calder",
            "Wenrui Hao"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25114",
        "abstract": "We derive an energy-based continuum limit for $\\varepsilon$-graphs endowed with a general connectivity functional. We prove that the discrete energy and its continuum counterpart differ by at most $O(\\varepsilon)$; the prefactor involves only the $W^{1,1}$-norm of the connectivity density as $\\varepsilon\\to0$, so the error bound remains valid even when that density has strong local fluctuations. As an application, we introduce a neural-network procedure that reconstructs the connectivity density from edge-weight data and then embeds the resulting continuum model into a brain-dynamics framework. In this setting, the usual constant diffusion coefficient is replaced by the spatially varying coefficient produced by the learned density, yielding dynamics that differ significantly from those obtained with conventional constant-diffusion models.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "79",
        "title": "A Survey on Unlearning in Large Language Models",
        "author": [
            "Ruichen Qiu",
            "Jiajun Tan",
            "Jiayue Pu",
            "Honglin Wang",
            "Xiao-Shan Gao",
            "Fei Sun"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25117",
        "abstract": "The advancement of Large Language Models (LLMs) has revolutionized natural language processing, yet their training on massive corpora poses significant risks, including the memorization of sensitive personal data, copyrighted material, and knowledge that could facilitate malicious activities. To mitigate these issues and align with legal and ethical standards such as the \"right to be forgotten\", machine unlearning has emerged as a critical technique to selectively erase specific knowledge from LLMs without compromising their overall performance. This survey provides a systematic review of over 180 papers on LLM unlearning published since 2021, focusing exclusively on large-scale generative models. Distinct from prior surveys, we introduce novel taxonomies for both unlearning methods and evaluations. We clearly categorize methods into training-time, post-training, and inference-time based on the training stage at which unlearning is applied. For evaluations, we not only systematically compile existing datasets and metrics but also critically analyze their advantages, disadvantages, and applicability, providing practical guidance to the research community. In addition, we discuss key challenges and promising future research directions. Our comprehensive overview aims to inform and guide the ongoing development of secure and reliable LLMs.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "80",
        "title": "MMM-Fact: A Multimodal, Multi-Domain Fact-Checking Dataset with Multi-Level Retrieval Difficulty",
        "author": [
            "Wenyan Xu",
            "Dawei Xiang",
            "Tianqi Ding",
            "Weihai Lu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25120",
        "abstract": "Misinformation and disinformation demand fact checking that goes beyond simple evidence-based reasoning. Existing benchmarks fall short: they are largely single modality (text-only), span short time horizons, use shallow evidence, cover domains unevenly, and often omit full articles -- obscuring models' real-world capability. We present MMM-Fact, a large-scale benchmark of 125,449 fact-checked statements (1995--2025) across multiple domains, each paired with the full fact-check article and multimodal evidence (text, images, videos, tables) from four fact-checking sites and one news outlet. To reflect verification effort, each statement is tagged with a retrieval-difficulty tier -- Basic (1--5 sources), Intermediate (6--10), and Advanced (>10) -- supporting fairness-aware evaluation for multi-step, cross-modal reasoning. The dataset adopts a three-class veracity scheme (true/false/not enough information) and enables tasks in veracity prediction, explainable fact-checking, complex evidence aggregation, and longitudinal analysis. Baselines with mainstream LLMs show MMM-Fact is markedly harder than prior resources, with performance degrading as evidence complexity rises. MMM-Fact offers a realistic, scalable benchmark for transparent, reliable, multimodal fact-checking.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "81",
        "title": "NanoVLA: Routing Decoupled Vision-Language Understanding for Nano-sized Generalist Robotic Policies",
        "author": [
            "Jiahong Chen",
            "Jing Wang",
            "Long Chen",
            "Chuwei Cai",
            "Jinghui Lu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25122",
        "abstract": "Vision-language-action (VLA) models have significantly advanced robotic manipulation by integrating vision-language models (VLMs), and action decoders into a unified architecture. However, their deployment on resource-constrained edge devices, such as mobile robots or embedded systems (e.g., Jetson Orin Nano), remains challenging due to high computational demands, especially in real-world scenarios where power, latency, and computational resources are critical. To close this gap, we introduce Nano-scale Vision-Language Action (NanoVLA), a family of lightweight VLA architectures that achieve high performance with minimal resources. Our core innovations include: (1) vision-language decoupling that moves conventional early vision and language inputs fusion in VLM to late stage, achieving better performance while enabling caching and reduce inference overhead and latency; (2) long-short action chunking to ensure smooth, coherent multi-step planning without sacrificing real-time responsiveness; (3) dynamic routing that adaptively assigns lightweight or heavy backbones based on task complexity, further optimizing inference efficiency. Experimental results on several benchmarks, as well as real-world deployments, demonstrate that NanoVLA achieves up to 52x faster inference on edge devices compared to previous state-of-the-art VLA models, with 98% less parameters while maintaining or surpassing their task accuracy and generalization. Ablation studies confirm that our decoupling strategy preserves cross-task transferability, and the routing module enhances cost-performance trade-offs, enabling practical, high-precision robotic manipulation on resource-constrained hardware.",
        "tags": [
            "VLM"
        ]
    },
    {
        "id": "82",
        "title": "AtlasGS: Atlanta-world Guided Surface Reconstruction with Implicit Structured Gaussians",
        "author": [
            "Xiyu Zhang",
            "Chong Bao",
            "Yipeng Chen",
            "Hongjia Zhai",
            "Yitong Dong",
            "Hujun Bao",
            "Zhaopeng Cui",
            "Guofeng Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25129",
        "abstract": "3D reconstruction of indoor and urban environments is a prominent research topic with various downstream applications. However, existing geometric priors for addressing low-texture regions in indoor and urban settings often lack global consistency. Moreover, Gaussian Splatting and implicit SDF fields often suffer from discontinuities or exhibit computational inefficiencies, resulting in a loss of detail. To address these issues, we propose an Atlanta-world guided implicit-structured Gaussian Splatting that achieves smooth indoor and urban scene reconstruction while preserving high-frequency details and rendering efficiency. By leveraging the Atlanta-world model, we ensure the accurate surface reconstruction for low-texture regions, while the proposed novel implicit-structured GS representations provide smoothness without sacrificing efficiency and high-frequency details. Specifically, we propose a semantic GS representation to predict the probability of all semantic regions and deploy a structure plane regularization with learnable plane indicators for global accurate surface reconstruction. Extensive experiments demonstrate that our method outperforms state-of-the-art approaches in both indoor and urban scenes, delivering superior surface reconstruction quality.",
        "tags": [
            "3D",
            "Gaussian Splatting"
        ]
    },
    {
        "id": "83",
        "title": "Automated Program Repair Based on REST API Specifications Using Large Language Models",
        "author": [
            "Katsuki Yamagishi",
            "Norihiro Yoshida",
            "Erina Makihara",
            "Katsuro Inoue"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25148",
        "abstract": "Many cloud services provide REST API accessible to client applications. However, developers often identify specification violations only during testing, as error messages typically lack the detail necessary for effective diagnosis. Consequently, debugging requires trial and error. This study proposes dcFix, a method for detecting and automatically repairing REST API misuses in client programs. In particular, dcFix identifies non-conforming code fragments, integrates them with the relevant API specifications into prompts, and leverages a Large Language Model (LLM) to produce the corrected code. Our evaluation demonstrates that dcFix accurately detects misuse and outperforms the baseline approach, in which prompts to the LLM omit any indication of code fragments non conforming to REST API specifications.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "84",
        "title": "Explainable Disentanglement on Discrete Speech Representations for Noise-Robust ASR",
        "author": [
            "Shreyas Gopal",
            "Ashutosh Anshul",
            "Haoyang Li",
            "Yue Heng Yeo",
            "Hexin Liu",
            "Eng Siong Chng"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25150",
        "abstract": "Discrete audio representations are gaining traction in speech modeling due to their interpretability and compatibility with large language models, but are not always optimized for noisy or real-world environments. Building on existing works that quantize Whisper embeddings for speech-to-unit modeling, we propose disentangling semantic speech content from background noise in the latent space. Our end-to-end model separates clean speech in the form of codebook tokens, while extracting interpretable noise vectors as quantization residue which are supervised via a lightweight classifier. We show that our approach improves alignment between clean/noisy speech and text, producing speech tokens that display a high degree of noiseinvariance, and improves ASR performance. Keeping Whisper frozen, we show an 82% reduction in error rate compared to Whisper, and 35% improvement over baseline methods on the VBDemand test set. Further analyses show that the learned token space generalizes well to both seen and unseen acoustic conditions.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "85",
        "title": "Model-Document Protocol for AI Search",
        "author": [
            "Hongjin Qian",
            "Zheng Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25160",
        "abstract": "AI search depends on linking large language models (LLMs) with vast external knowledge sources. Yet web pages, PDF files, and other raw documents are not inherently LLM-ready: they are long, noisy, and unstructured. Conventional retrieval methods treat these documents as verbatim text and return raw passages, leaving the burden of fragment assembly and contextual reasoning to the LLM. This gap underscores the need for a new retrieval paradigm that redefines how models interact with documents.\nWe introduce the Model-Document Protocol (MDP), a general framework that formalizes how raw text is bridged to LLMs through consumable knowledge representations. Rather than treating retrieval as passage fetching, MDP defines multiple pathways that transform unstructured documents into task-specific, LLM-ready inputs. These include agentic reasoning, which curates raw evidence into coherent context; memory grounding, which accumulates reusable notes to enrich reasoning; and structured leveraging, which encodes documents into formal representations such as graphs or key-value caches. All three pathways share the same goal: ensuring that what reaches the LLM is not raw fragments but compact, structured knowledge directly consumable for reasoning.\nAs an instantiation, we present MDP-Agent, which realizes the protocol through an agentic process: constructing document-level gist memories for global coverage, performing diffusion-based exploration with vertical exploitation to uncover layered dependencies, and applying map-reduce style synthesis to integrate large-scale evidence into compact yet sufficient context. Experiments on information-seeking benchmarks demonstrate that MDP-Agent outperforms baselines, validating both the soundness of the MDP framework and the effectiveness of its agentic instantiation.",
        "tags": [
            "Diffusion",
            "LLM"
        ]
    },
    {
        "id": "86",
        "title": "Target-Guided Bayesian Flow Networks for Quantitatively Constrained CAD Generation",
        "author": [
            "Wenhao Zheng",
            "Chenwei Sun",
            "Wenbo Zhang",
            "Jiancheng Lv",
            "Xianggen Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25163",
        "abstract": "Deep generative models, such as diffusion models, have shown promising progress in image generation and audio generation via simplified continuity assumptions. However, the development of generative modeling techniques for generating multi-modal data, such as parametric CAD sequences, still lags behind due to the challenges in addressing long-range constraints and parameter sensitivity. In this work, we propose a novel framework for quantitatively constrained CAD generation, termed Target-Guided Bayesian Flow Network (TGBFN). For the first time, TGBFN handles the multi-modality of CAD sequences (i.e., discrete commands and continuous parameters) in a unified continuous and differentiable parameter space rather than in the discrete data space. In addition, TGBFN penetrates the parameter update kernel and introduces a guided Bayesian flow to control the CAD properties. To evaluate TGBFN, we construct a new dataset for quantitatively constrained CAD generation. Extensive comparisons across single-condition and multi-condition constrained generation tasks demonstrate that TGBFN achieves state-of-the-art performance in generating high-fidelity, condition-aware CAD sequences. The code is available at https://github.com/scu-zwh/TGBFN.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "87",
        "title": "A Study on Inference Latency for Vision Transformers on Mobile Devices",
        "author": [
            "Zhuojin Li",
            "Marco Paolieri",
            "Leana Golubchik"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25166",
        "abstract": "Given the significant advances in machine learning techniques on mobile devices, particularly in the domain of computer vision, in this work we quantitatively study the performance characteristics of 190 real-world vision transformers (ViTs) on mobile devices. Through a comparison with 102 real-world convolutional neural networks (CNNs), we provide insights into the factors that influence the latency of ViT architectures on mobile devices. Based on these insights, we develop a dataset including measured latencies of 1000 synthetic ViTs with representative building blocks and state-of-the-art architectures from two machine learning frameworks and six mobile platforms. Using this dataset, we show that inference latency of new ViTs can be predicted with sufficient accuracy for real-world applications.",
        "tags": [
            "ViT"
        ]
    },
    {
        "id": "88",
        "title": "Error Analysis of Third-Order in Time and Fourth-Order Linear Finite Difference Scheme for Landau-Lifshitz-Gilbert Equation under Large Damping Parameters",
        "author": [
            "Changjian Xie",
            "Cheng Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25172",
        "abstract": "This work proposes and analyzes a fully discrete numerical scheme for solving the Landau-Lifshitz-Gilbert (LLG) equation, which achieves fourth-order spatial accuracy and third-order temporal http://accuracy.Spatially, fourth-order accuracy is attained through the adoption of a long-stencil finite difference method, while boundary extrapolation is executed by leveraging a higher-order Taylor expansion to ensure consistency at domain boundaries. Temporally, the scheme is constructed based on the third-order backward differentiation formula (BDF3), with implicit discretization applied to the linear diffusion term for numerical stability and explicit extrapolation employed for nonlinear terms to balance computational efficiency. Notably, this numerical method inherently preserves the normalization constraint of the LLG equation, a key physical property of the http://system.Theoretical analysis confirms that the proposed scheme exhibits optimal convergence rates under the \\(\\ell^{\\infty}([0,T],\\ell^2)\\) and \\(\\ell^2([0,T],H_h^1)\\) norms. Finally, numerical experiments are conducted to validate the correctness of the theoretical convergence results, demonstrating good agreement between numerical observations and analytical conclusions.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "89",
        "title": "$D^2GS$: Dense Depth Regularization for LiDAR-free Urban Scene Reconstruction",
        "author": [
            "Kejing Xia",
            "Jidong Jia",
            "Ke Jin",
            "Yucai Bai",
            "Li Sun",
            "Dacheng Tao",
            "Youjian Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25173",
        "abstract": "Recently, Gaussian Splatting (GS) has shown great potential for urban scene reconstruction in the field of autonomous driving. However, current urban scene reconstruction methods often depend on multimodal sensors as inputs, \\textit{i.e.} LiDAR and images. Though the geometry prior provided by LiDAR point clouds can largely mitigate ill-posedness in reconstruction, acquiring such accurate LiDAR data is still challenging in practice: i) precise spatiotemporal calibration between LiDAR and other sensors is required, as they may not capture data simultaneously; ii) reprojection errors arise from spatial misalignment when LiDAR and cameras are mounted at different locations. To avoid the difficulty of acquiring accurate LiDAR depth, we propose $D^2GS$, a LiDAR-free urban scene reconstruction framework. In this work, we obtain geometry priors that are as effective as LiDAR while being denser and more accurate. $\\textbf{First}$, we initialize a dense point cloud by back-projecting multi-view metric depth predictions. This point cloud is then optimized by a Progressive Pruning strategy to improve the global consistency. $\\textbf{Second}$, we jointly refine Gaussian geometry and predicted dense metric depth via a Depth Enhancer. Specifically, we leverage diffusion priors from a depth foundation model to enhance the depth maps rendered by Gaussians. In turn, the enhanced depths provide stronger geometric constraints during Gaussian training. $\\textbf{Finally}$, we improve the accuracy of ground geometry by constraining the shape and normal attributes of Gaussians within road regions. Extensive experiments on the Waymo dataset demonstrate that our method consistently outperforms state-of-the-art methods, producing more accurate geometry even when compared with those using ground-truth LiDAR data.",
        "tags": [
            "Diffusion",
            "Gaussian Splatting"
        ]
    },
    {
        "id": "90",
        "title": "Agentic Moderation: Multi-Agent Design for Safer Vision-Language Models",
        "author": [
            "Juan Ren",
            "Mark Dras",
            "Usman Naseem"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25179",
        "abstract": "Agentic methods have emerged as a powerful and autonomous paradigm that enhances reasoning, collaboration, and adaptive control, enabling systems to coordinate and independently solve complex tasks. We extend this paradigm to safety alignment by introducing Agentic Moderation, a model-agnostic framework that leverages specialised agents to defend multimodal systems against jailbreak attacks. Unlike prior approaches that apply as a static layer over inputs or outputs and provide only binary classifications (safe or unsafe), our method integrates dynamic, cooperative agents, including Shield, Responder, Evaluator, and Reflector, to achieve context-aware and interpretable moderation. Extensive experiments across five datasets and four representative Large Vision-Language Models (LVLMs) demonstrate that our approach reduces the Attack Success Rate (ASR) by 7-19%, maintains a stable Non-Following Rate (NF), and improves the Refusal Rate (RR) by 4-20%, achieving robust, interpretable, and well-balanced safety performance. By harnessing the flexibility and reasoning capacity of agentic architectures, Agentic Moderation provides modular, scalable, and fine-grained safety enforcement, highlighting the broader potential of agentic systems as a foundation for automated safety governance.",
        "tags": [
            "VLM"
        ]
    },
    {
        "id": "91",
        "title": "Fed-PELAD: Communication-Efficient Federated Learning for Massive MIMO CSI Feedback with Personalized Encoders and a LoRA-Adapted Shared Decoder",
        "author": [
            "Yixiang Zhou",
            "Tong Wu",
            "Meixia Tao",
            "Jianhua Mo"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25181",
        "abstract": "This paper addresses the critical challenges of communication overhead, data heterogeneity, and privacy in deep learning for channel state information (CSI) feedback in massive MIMO systems. To this end, we propose Fed-PELAD, a novel federated learning framework that incorporates personalized encoders and a LoRA-adapted shared decoder. Specifically, personalized encoders are trained locally on each user equipment (UE) to capture device-specific channel characteristics, while a shared decoder is updated globally via the coordination of the base station (BS) by using Low-Rank Adaptation (LoRA). This design ensures that only compact LoRA adapter parameters instead of full model updates are transmitted for aggregation. To further enhance convergence stability, we introduce an alternating freezing strategy with calibrated learning-rate ratio during LoRA aggregation. Extensive simulations on 3GPP-standard channel models demonstrate that Fed-PELAD requires only 42.97\\% of the uplink communication cost compared to conventional methods while achieving a performance gain of 1.2 dB in CSI feedback accuracy under heterogeneous conditions.",
        "tags": [
            "LoRA"
        ]
    },
    {
        "id": "92",
        "title": "Testing Cross-Lingual Text Comprehension In LLMs Using Next Sentence Prediction",
        "author": [
            "Ritesh Sunil Chavan",
            "Jack Mostow"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25187",
        "abstract": "While large language models are trained on massive datasets, this data is heavily skewed towards English. Does their impressive performance reflect genuine ability or just this data advantage? To find out, we tested them in a setting where they could not rely on data abundance: low-resource languages. Building on prior work Agarwal et al. (2025) that used Next Sentence Prediction (NSP) as a test, we created a large-scale benchmark with 10,000 questions each for English (a high-resource language), Swahili (medium-resource), and Hausa (low-resource). We then tested several top models, including GPT-4 Turbo, Gemini 1.5 Flash, and LLaMA 3 70B, to see how their performance holds up. The results painted a clear picture of how levels of language resources impact outcomes. While all models excelled in English, their accuracy dropped in Swahili and fell sharply in Hausa, with LLaMA 3 struggling the most. The story became even more interesting when we introduced Chain-of-Thought (CoT) prompting. For the struggling LLaMA 3, CoT acted as a helpful guide, significantly boosting its accuracy. However, for the more capable GPT-4 and Gemini, the same technique often backfired, leading to a kind of \"overthinking\" that hurt their results in the cross-lingual context. This reveals that Chain-of-Thought is not a universal solution; its effectiveness depends heavily on the model's baseline capability and the specific context of the task. Our framework pinpoints LLM weaknesses, highlights when CoT helps or hinders cross-lingual NSP performance, and factors influencing their decisions.",
        "tags": [
            "CoT",
            "GPT",
            "LLM",
            "LLaMA"
        ]
    },
    {
        "id": "93",
        "title": "AgentCyTE: Leveraging Agentic AI to Generate Cybersecurity Training & Experimentation Scenarios",
        "author": [
            "Ana M. Rodriguez",
            "Jaime Acosta",
            "Anantaa Kotal",
            "Aritran Piplai"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25189",
        "abstract": "Designing realistic and adaptive networked threat scenarios remains a core challenge in cybersecurity research and training, still requiring substantial manual effort. While large language models (LLMs) show promise for automated synthesis, unconstrained generation often yields configurations that fail validation or execution. We present AgentCyTE, a framework integrating LLM-based reasoning with deterministic, schema-constrained network emulation to generate and refine executable threat environments. Through an agentic feedback loop, AgentCyTE observes scenario outcomes, validates correctness, and iteratively enhances realism and consistency. This hybrid approach preserves LLM flexibility while enforcing structural validity, enabling scalable, data-driven experimentation and reliable scenario generation for threat modeling and adaptive cybersecurity training. Our framework can be accessed at: https://github.com/AnantaaKotal/AgentCyTE",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "94",
        "title": "SoraNav: Adaptive UAV Task-Centric Navigation via Zeroshot VLM Reasoning",
        "author": [
            "Hongyu Song",
            "Rishabh Dev Yadav",
            "Cheng Guo",
            "Wei Pan"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25191",
        "abstract": "Interpreting visual observations and natural language instructions for complex task execution remains a key challenge in robotics and AI. Despite recent advances, language-driven navigation is still difficult, particularly for UAVs in small-scale 3D environments. Existing Vision-Language Navigation (VLN) approaches are mostly designed for ground robots and struggle to generalize to aerial tasks that require full 3D spatial reasoning. The emergence of large Vision-Language Models (VLMs), such as GPT and Claude, enables zero-shot semantic reasoning from visual and textual inputs. However, these models lack spatial grounding and are not directly applicable to navigation. To address these limitations, SoraNav is introduced, an adaptive UAV navigation framework that integrates zero-shot VLM reasoning with geometry-aware decision-making. Geometric priors are incorporated into image annotations to constrain the VLM action space and improve decision quality. A hybrid switching strategy leverages navigation history to alternate between VLM reasoning and geometry-based exploration, mitigating dead-ends and redundant revisits. A PX4-based hardware-software platform, comprising both a digital twin and a physical micro-UAV, enables reproducible evaluation. Experimental results show that in 2.5D scenarios, our method improves Success Rate (SR) by 25.7% and Success weighted by Path Length (SPL) by 17%. In 3D scenarios, it improves SR by 29.5% and SPL by 18.5% relative to the baseline.",
        "tags": [
            "3D",
            "GPT",
            "Robotics",
            "VLM"
        ]
    },
    {
        "id": "95",
        "title": "Optimizing Knowledge Utilization for Multi-Intent Comment Generation with Large Language Models",
        "author": [
            "Shuochuan Li",
            "Zan Wang",
            "Xiaoning Du",
            "Zhuo Wu",
            "Jiuqiao Yu",
            "Junjie Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25195",
        "abstract": "Code comment generation aims to produce a generic overview of a code snippet, helping developers understand and maintain code. However, generic summaries alone are insufficient to meet the diverse needs of practitioners; for example, developers expect the implementation insights to be presented in an untangled manner, while users seek clear usage instructions. This highlights the necessity of multi-intent comment generation. With the widespread adoption of Large Language Models (LLMs) for code-related tasks, these models have been leveraged to tackle the challenge of multi-intent comment generation. Despite their successes, state-of-the-art LLM-based approaches often struggle to construct correct relationships among intents, code, and comments within a smaller number of demonstration examples. To mitigate this issue, we propose a framework named KUMIC for multi-intent comment generation. Built upon in-context learning, KUMIC leverages Chain-of-Thought (CoT) to optimize knowledge utilization for LLMs to generate intent-specific comments. Specifically, KUMIC first designs a retrieval mechanism to obtain similar demonstration examples, which exhibit high code-comment consistency. Then, KUMIC leverages CoT to guide LLMs to focus on statements facilitating the derivation of code comments aligned with specific intents. In this context, KUMIC constructs a mapping knowledge chain, linking code to intent-specific statements to comments, which enables LLMs to follow similar reasoning steps when generating the desired comments. We conduct extensive experiments to evaluate KUMIC, and the results demonstrate that KUMIC outperforms state-of-the-art baselines by 14.49\\%, 22.41\\%, 20.72\\%, and 12.94\\% in terms of BLEU, METEOR, ROUGE-L, and SBERT, respectively.",
        "tags": [
            "CoT",
            "LLM"
        ]
    },
    {
        "id": "96",
        "title": "Energy-Efficient Autonomous Driving with Adaptive Perception and Robust Decision",
        "author": [
            "Yuyang Xia",
            "Zibo Liang",
            "Liwei Deng",
            "Yan Zhao",
            "Han Su",
            "Kai Zheng"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25205",
        "abstract": "Autonomous driving is an emerging technology that is expected to bring significant social, economic, and environmental benefits. However, these benefits come with rising energy consumption by computation engines, limiting the driving range of vehicles, especially electric ones. Perception computing is typically the most power-intensive component, as it relies on largescale deep learning models to extract environmental features. Recently, numerous studies have employed model compression techniques, such as sparsification, quantization, and distillation, to reduce computational consumption. However, these methods often result in either a substantial model size or a significant drop in perception accuracy compared to high-computation models. To address these challenges, we propose an energy-efficient autonomous driving framework, called EneAD. In the adaptive perception module, a perception optimization strategy is designed from the perspective of data management and tuning. Firstly, we manage multiple perception models with different computational consumption and adjust the execution framerate dynamically. Then, we define them as knobs and design a transferable tuning method based on Bayesian optimization to identify promising knob values that achieve low computation while maintaining desired accuracy. To adaptively switch the knob values in various traffic scenarios, a lightweight classification model is proposed to distinguish the perception difficulty in different scenarios. In the robust decision module, we propose a decision model based on reinforcement learning and design a regularization term to enhance driving stability in the face of perturbed perception results. Extensive experiments evidence the superiority of our framework in both energy consumption and driving performance. EneAD can reduce perception consumption by 1.9x to 3.5x and thus improve driving range by 3.9% to 8.5%",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "97",
        "title": "RAVR: Reference-Answer-guided Variational Reasoning for Large Language Models",
        "author": [
            "Tianqianjin Lin",
            "Xi Zhao",
            "Xingyao Zhang",
            "Rujiao Long",
            "Yi Xu",
            "Zhuoren Jiang",
            "Wenbo Su",
            "Bo Zheng"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25206",
        "abstract": "Reinforcement learning (RL) can refine the reasoning abilities of large language models (LLMs), but critically depends on a key prerequisite: the LLM can already generate high-utility reasoning paths with non-negligible probability. For tasks beyond the LLM's current competence, such reasoning path can be hard to sample, and learning risks reinforcing familiar but suboptimal reasoning. We are motivated by the insight from cognitive science that Why is this the answer is often an easier question than What is the answer, as it avoids the heavy cognitive load of open-ended exploration, opting instead for explanatory reconstruction-systematically retracing the reasoning that links a question to its answer. We show that LLMs can similarly leverage answers to derive high-quality reasoning paths. We formalize this phenomenon and prove that conditioning on answer provably increases the expected utility of sampled reasoning paths, thereby transforming intractable problems into learnable ones. Building on this insight, we introduce RAVR (Reference-Answer-guided Variational Reasoning), an end-to-end framework that uses answer-conditioned reasoning as a variational surrogate for question-only reasoning. Experiments in both general and math domains demonstrate consistent improvements over strong baselines. We further analyze the reasoning behavior and find that RAVR reduces hesitation, strengthens conclusion consolidation, and promotes problem-specific strategies in reasoning.",
        "tags": [
            "LLM",
            "RL"
        ]
    },
    {
        "id": "98",
        "title": "FELA: A Multi-Agent Evolutionary System for Feature Engineering of Industrial Event Log Data",
        "author": [
            "Kun ouyang",
            "Haoyu Wang",
            "Dong Fang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25223",
        "abstract": "Event log data, recording fine-grained user actions and system events, represent one of the most valuable assets for modern digital services. However, the complexity and heterogeneity of industrial event logs--characterized by large scale, high dimensionality, diverse data types, and intricate temporal or relational structures--make feature engineering extremely challenging. Existing automatic feature engineering approaches, such as AutoML or genetic methods, often suffer from limited explainability, rigid predefined operations, and poor adaptability to complicated heterogeneous data. In this paper, we propose FELA (Feature Engineering LLM Agents), a multi-agent evolutionary system that autonomously extracts meaningful and high-performing features from complex industrial event log data. FELA integrates the reasoning and coding capabilities of large language models (LLMs) with an insight-guided self-evolution paradigm. Specifically, FELA employs specialized agents--Idea Agents, Code Agents, and Critic Agents--to collaboratively generate, validate, and implement novel feature ideas. An Evaluation Agent summarizes feedback and updates a hierarchical knowledge base and dual-memory system to enable continual improvement. Moreover, FELA introduces an agentic evolution algorithm, combining reinforcement learning and genetic algorithm principles to balance exploration and exploitation across the idea space. Extensive experiments on real industrial datasets demonstrate that FELA can generate explainable, domain-relevant features that significantly improve model performance while reducing manual effort. Our results highlight the potential of LLM-based multi-agent systems as a general framework for automated, interpretable, and adaptive feature engineering in complex real-world environments.",
        "tags": [
            "LLM",
            "RL"
        ]
    },
    {
        "id": "99",
        "title": "ProMediate: A Socio-cognitive framework for evaluating proactive agents in multi-party negotiation",
        "author": [
            "Ziyi Liu",
            "Bahar Sarrafzadeh",
            "Pei Zhou",
            "Longqi Yang",
            "Jieyu Zhao",
            "Ashish Sharma"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25224",
        "abstract": "While Large Language Models (LLMs) are increasingly used in agentic frameworks to assist individual users, there is a growing need for agents that can proactively manage complex, multi-party collaboration. Systematic evaluation methods for such proactive agents remain scarce, limiting progress in developing AI that can effectively support multiple people together. Negotiation offers a demanding testbed for this challenge, requiring socio-cognitive intelligence to navigate conflicting interests between multiple participants and multiple topics and build consensus. Here, we present ProMediate, the first framework for evaluating proactive AI mediator agents in complex, multi-topic, multi-party negotiations. ProMediate consists of two core components: (i) a simulation testbed based on realistic negotiation cases and theory-driven difficulty levels (ProMediate-Easy, ProMediate-Medium, and ProMediate-Hard), with a plug-and-play proactive AI mediator grounded in socio-cognitive mediation theories, capable of flexibly deciding when and how to intervene; and (ii) a socio-cognitive evaluation framework with a new suite of metrics to measure consensus changes, intervention latency, mediator effectiveness, and intelligence. Together, these components establish a systematic framework for assessing the socio-cognitive intelligence of proactive AI agents in multi-party settings. Our results show that a socially intelligent mediator agent outperforms a generic baseline, via faster, better-targeted interventions. In the ProMediate-Hard setting, our social mediator increases consensus change by 3.6 percentage points compared to the generic baseline (10.65\\% vs 7.01\\%) while being 77\\% faster in response (15.98s vs. 3.71s). In conclusion, ProMediate provides a rigorous, theory-grounded testbed to advance the development of proactive, socially intelligent agents.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "100",
        "title": "Balanced conic rectified flow",
        "author": [
            "Kim Shin Seong",
            "Mingi Kwon",
            "Jaeseok Jeong",
            "Youngjung Uh"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25229",
        "abstract": "Rectified flow is a generative model that learns smooth transport mappings between two distributions through an ordinary differential equation (ODE). Unlike diffusion-based generative models, which require costly numerical integration of a generative ODE to sample images with state-of-the-art quality, rectified flow uses an iterative process called reflow to learn smooth and straight ODE paths. This allows for relatively simple and efficient generation of high-quality images. However, rectified flow still faces several challenges. 1) The reflow process requires a large number of generative pairs to preserve the target distribution, leading to significant computational costs. 2) Since the model is typically trained using only generated image pairs, its performance heavily depends on the 1-rectified flow model, causing it to become biased towards the generated data.\nIn this work, we experimentally expose the limitations of the original rectified flow and propose a novel approach that incorporates real images into the training process. By preserving the ODE paths for real images, our method effectively reduces reliance on large amounts of generated data. Instead, we demonstrate that the reflow process can be conducted efficiently using a much smaller set of generated and real images. In CIFAR-10, we achieved significantly better FID scores, not only in one-step generation but also in full-step simulations, while using only of the generative pairs compared to the original method. Furthermore, our approach induces straighter paths and avoids saturation on generated images during reflow, leading to more robust ODE learning while preserving the distribution of real images.",
        "tags": [
            "Diffusion",
            "ODE",
            "Rectified Flow"
        ]
    },
    {
        "id": "101",
        "title": "Hybrid Vision Servoing with Depp Alignment and GRU-Based Occlusion Recovery",
        "author": [
            "Jee Won Lee",
            "Hansol Lim",
            "Sooyeun Yang",
            "Jongseong Brad Choi"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25233",
        "abstract": "Vision-based control systems, such as image-based visual servoing (IBVS), have been extensively explored for precise robot manipulation. A persistent challenge, however, is maintaining robust target tracking under partial or full occlusions. Classical methods like Lucas-Kanade (LK) offer lightweight tracking but are fragile to occlusion and drift, while deep learning-based approaches often require continuous visibility and intensive computation. To address these gaps, we propose a hybrid visual tracking framework that bridges advanced perception with real-time servo control. First, a fast global template matcher constrains the pose search region; next, a deep-feature Lucas-Kanade module operating on early VGG layers refines alignment to sub-pixel accuracy (<2px); then, a lightweight residual regressor corrects local misalignments caused by texture degradation or partial occlusion. When visual confidence falls below a threshold, a GRU-based predictor seamlessly extrapolates pose updates from recent motion history. Crucially, the pipeline's final outputs-translation, rotation, and scale deltas-are packaged as direct control signals for 30Hz image-based servo loops. Evaluated on handheld video sequences with up to 90% occlusion, our system sustains under 2px tracking error, demonstrating the robustness and low-latency precision essential for reliable real-world robot vision applications.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "102",
        "title": "Learning Disentangled Speech- and Expression-Driven Blendshapes for 3D Talking Face Animation",
        "author": [
            "Yuxiang Mao",
            "Zhijie Zhang",
            "Zhiheng Zhang",
            "Jiawei Liu",
            "Chen Zeng",
            "Shihong Xia"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25234",
        "abstract": "Expressions are fundamental to conveying human emotions. With the rapid advancement of AI-generated content (AIGC), realistic and expressive 3D facial animation has become increasingly crucial. Despite recent progress in speech-driven lip-sync for talking-face animation, generating emotionally expressive talking faces remains underexplored. A major obstacle is the scarcity of real emotional 3D talking-face datasets due to the high cost of data capture. To address this, we model facial animation driven by both speech and emotion as a linear additive problem. Leveraging a 3D talking-face dataset with neutral expressions (VOCAset) and a dataset of 3D expression sequences (Florence4D), we jointly learn a set of blendshapes driven by speech and emotion. We introduce a sparsity constraint loss to encourage disentanglement between the two types of blendshapes while allowing the model to capture inherent secondary cross-domain deformations present in the training data. The learned blendshapes can be further mapped to the expression and jaw pose parameters of the FLAME model, enabling the animation of 3D Gaussian avatars. Qualitative and quantitative experiments demonstrate that our method naturally generates talking faces with specified expressions while maintaining accurate lip synchronization. Perceptual studies further show that our approach achieves superior emotional expressivity compared to existing methods, without compromising lip-sync quality.",
        "tags": [
            "3D",
            "Talking Face"
        ]
    },
    {
        "id": "103",
        "title": "DeepShield: Fortifying Deepfake Video Detection with Local and Global Forgery Analysis",
        "author": [
            "Yinqi Cai",
            "Jichang Li",
            "Zhaolun Li",
            "Weikai Chen",
            "Rushi Lan",
            "Xi Xie",
            "Xiaonan Luo",
            "Guanbin Li"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25237",
        "abstract": "Recent advances in deep generative models have made it easier to manipulate face videos, raising significant concerns about their potential misuse for fraud and misinformation. Existing detectors often perform well in in-domain scenarios but fail to generalize across diverse manipulation techniques due to their reliance on forgery-specific artifacts. In this work, we introduce DeepShield, a novel deepfake detection framework that balances local sensitivity and global generalization to improve robustness across unseen forgeries. DeepShield enhances the CLIP-ViT encoder through two key components: Local Patch Guidance (LPG) and Global Forgery Diversification (GFD). LPG applies spatiotemporal artifact modeling and patch-wise supervision to capture fine-grained inconsistencies often overlooked by global models. GFD introduces domain feature augmentation, leveraging domain-bridging and boundary-expanding feature generation to synthesize diverse forgeries, mitigating overfitting and enhancing cross-domain adaptability. Through the integration of novel local and global analysis for deepfake detection, DeepShield outperforms state-of-the-art methods in cross-dataset and cross-manipulation evaluations, achieving superior robustness against unseen deepfake attacks.",
        "tags": [
            "CLIP",
            "Detection",
            "ViT"
        ]
    },
    {
        "id": "104",
        "title": "Mapping and Classification of Trees Outside Forests using Deep Learning",
        "author": [
            "Moritz Lucas",
            "Hamid Ebrahimy",
            "Viacheslav Barkov",
            "Ralf Pecenka",
            "Kai-Uwe KÃ¼hnberger",
            "BjÃ¶rn Waske"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25239",
        "abstract": "Trees Outside Forests (TOF) play an important role in agricultural landscapes by supporting biodiversity, sequestering carbon, and regulating microclimates. Yet, most studies have treated TOF as a single class or relied on rigid rule-based thresholds, limiting ecological interpretation and adaptability across regions. To address this, we evaluate deep learning for TOF classification using a newly generated dataset and high-resolution aerial imagery from four agricultural landscapes in Germany. Specifically, we compare convolutional neural networks (CNNs), vision transformers, and hybrid CNN-transformer models across six semantic segmentation architectures (ABCNet, LSKNet, FT-UNetFormer, DC-Swin, BANet, and U-Net) to map four categories of woody vegetation: Forest, Patch, Linear, and Tree, derived from previous studies and governmental products. Overall, the models achieved good classification accuracy across the four landscapes, with the FT-UNetFormer performing best (mean Intersection-over-Union 0.74; mean F1 score 0.84), underscoring the importance of spatial context understanding in TOF mapping and classification. Our results show good results for Forest and Linear class and reveal challenges particularly in classifying complex structures with high edge density, notably the Patch and Tree class. Our generalization experiments highlight the need for regionally diverse training data to ensure reliable large-scale mapping. The dataset and code are openly available at https://github.com/Moerizzy/TOFMapper",
        "tags": [
            "Segmentation",
            "Transformer"
        ]
    },
    {
        "id": "105",
        "title": "One-shot Humanoid Whole-body Motion Learning",
        "author": [
            "Hao Huang",
            "Geeta Chandra Raju Bethala",
            "Shuaihang Yuan",
            "Congcong Wen",
            "Anthony Tzes",
            "Yi Fang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25241",
        "abstract": "Whole-body humanoid motion represents a cornerstone challenge in robotics, integrating balance, coordination, and adaptability to enable human-like behaviors. However, existing methods typically require multiple training samples per motion category, rendering the collection of high-quality human motion datasets both labor-intensive and costly. To address this, we propose a novel approach that trains effective humanoid motion policies using only a single non-walking target motion sample alongside readily available walking motions. The core idea lies in leveraging order-preserving optimal transport to compute distances between walking and non-walking sequences, followed by interpolation along geodesics to generate new intermediate pose skeletons, which are then optimized for collision-free configurations and retargeted to the humanoid before integration into a simulated environment for policy training via reinforcement learning. Experimental evaluations on the CMU MoCap dataset demonstrate that our method consistently outperforms baselines, achieving superior performance across metrics. Code will be released upon acceptance.",
        "tags": [
            "RL",
            "Robotics"
        ]
    },
    {
        "id": "106",
        "title": "BSFA: Leveraging the Subspace Dichotomy to Accelerate Neural Network Training",
        "author": [
            "Wenjie Zhou",
            "Bohan Wang",
            "Wei Chen",
            "Xueqi Cheng"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25244",
        "abstract": "Recent studies \\citep{gur2018gradient,song2024does, wen2024understanding} highlight a fundamental dichotomy in deep learning optimization: Although parameter updates along the top eigendirections of the loss Hessian (Dom-space) capture most of the update magnitude, they often contribute minimally to loss reduction. In contrast, updates in the orthogonal component (Bulk-space) have smaller magnitudes but drive most learning progress. In this work, we further advance the understanding of this phenomenon and introduce the \\textbf{Bulk-Space-Filtration-Accelerator (BSFA)}, a novel plug-and-play framework. BSFA accelerates training by differentially scaling update components projected onto these distinct subspaces, simultaneously enhancing stability by moderating updates in the dominant subspace and boosting convergence speed by amplifying those in the bulk-space. To ensure BSFA is both practical and scalable for contemporary large models, we introduce two key innovations: an efficient estimator using Principal Component Analysis (PCA) on historical updates for fast subspace estimation, and a block-wise strategy that applies this estimation on a per-parameter-block basis. These designs make BSFA computationally tractable and highly effective. We demonstrate BSFA's acceleration across various tasks, notably achieving approximately 2$\\times$ speedup when pre-training LLaMA-72M on WikiText-103 and LLaMA-134M on OpenWebText compared to vanilla AdamW.",
        "tags": [
            "LLaMA"
        ]
    },
    {
        "id": "107",
        "title": "Spectral analysis of the stiffness matrix sequence in the approximated Stokes equation",
        "author": [
            "Samuele Ferri",
            "Chiara Giraudo",
            "Valerio Loi",
            "Miroslav Kuchta",
            "Stefano Serra-Capizzano"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25252",
        "abstract": "In the present paper, we analyze in detail the spectral features of the matrix sequences arising from the Taylor-Hood $\\mathbb{P}_2$-$\\mathbb{P}_1$ approximation of variable viscosity for $2d$ Stokes problem under weak assumptions on the regularity of the diffusion. Localization and distributional spectral results are provided, accompanied by numerical tests and visualizations. A preliminary study of the impact of our findings on the preconditioning problem is also presented. A final section with concluding remarks and open problems ends the current work.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "108",
        "title": "MoEntwine: Unleashing the Potential of Wafer-scale Chips for Large-scale Expert Parallel Inference",
        "author": [
            "Xinru Tang",
            "Jingxiang Hou",
            "Dingcheng Jiang",
            "Taiquan Wei",
            "Jiaxin Liu",
            "Jinyi Deng",
            "Huizheng Wang",
            "Qize Yang",
            "Haoran Shang",
            "Chao Li",
            "Yang Hu",
            "Shouyi Yin"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25258",
        "abstract": "As large language models (LLMs) continue to scale up, mixture-of-experts (MoE) has become a common technology in SOTA models. MoE models rely on expert parallelism (EP) to alleviate memory bottleneck, which introduces all-to-all communication to dispatch and combine tokens across devices. However, in widely-adopted GPU clusters, high-overhead cross-node communication makes all-to-all expensive, hindering the adoption of EP. Recently, wafer-scale chips (WSCs) have emerged as a platform integrating numerous devices on a wafer-sized interposer. WSCs provide a unified high-performance network connecting all devices, presenting a promising potential for hosting MoE models. Yet, their network is restricted to a mesh topology, causing imbalanced communication pressure and performance loss. Moreover, the lack of on-wafer disk leads to high-overhead expert migration on the critical path.\nTo fully unleash this potential, we first propose Entwined Ring Mapping (ER-Mapping), which co-designs the mapping of attention and MoE layers to balance communication pressure and achieve better performance. We find that under ER-Mapping, the distribution of cold and hot links in the attention and MoE layers is complementary. Therefore, to hide the migration overhead, we propose the Non-invasive Balancer (NI-Balancer), which splits a complete expert migration into multiple steps and alternately utilizes the cold links of both layers. Evaluation shows ER-Mapping achieves communication reduction up to 62%. NI-Balancer further delivers 54% and 22% improvements in MoE computation and communication, respectively. Compared with the SOTA NVL72 supernode, the WSC platform delivers an average 39% higher per-device MoE performance owing to its scalability to larger EP.",
        "tags": [
            "LLM",
            "MoE"
        ]
    },
    {
        "id": "109",
        "title": "IBNorm: Information-Bottleneck Inspired Normalization for Representation Learning",
        "author": [
            "Xiandong Zou",
            "Pan Zhou"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25262",
        "abstract": "Normalization is fundamental to deep learning, but existing approaches such as BatchNorm, LayerNorm, and RMSNorm are variance-centric by enforcing zero mean and unit variance, stabilizing training without controlling how representations capture task-relevant information. We propose IB-Inspired Normalization (IBNorm), a simple yet powerful family of methods grounded in the Information Bottleneck principle. IBNorm introduces bounded compression operations that encourage embeddings to preserve predictive information while suppressing nuisance variability, yielding more informative representations while retaining the stability and compatibility of standard normalization. Theoretically, we prove that IBNorm achieves a higher IB value and tighter generalization bounds than variance-centric methods. Empirically, IBNorm consistently outperforms BatchNorm, LayerNorm, and RMSNorm across large-scale language models (LLaMA, GPT-2) and vision models (ResNet, ViT), with mutual information analysis confirming superior information bottleneck behavior. Code will be released publicly.",
        "tags": [
            "GPT",
            "LLaMA",
            "ViT"
        ]
    },
    {
        "id": "110",
        "title": "SynHLMA:Synthesizing Hand Language Manipulation for Articulated Object with Discrete Human Object Interaction Representation",
        "author": [
            "Wang zhi",
            "Yuyan Liu",
            "Liu Liu",
            "Li Zhang",
            "Ruixuan Lu",
            "Dan Guo"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25268",
        "abstract": "Generating hand grasps with language instructions is a widely studied topic that benefits from embodied AI and VR/AR applications. While transferring into hand articulatied object interaction (HAOI), the hand grasps synthesis requires not only object functionality but also long-term manipulation sequence along the object deformation. This paper proposes a novel HAOI sequence generation framework SynHLMA, to synthesize hand language manipulation for articulated objects. Given a complete point cloud of an articulated object, we utilize a discrete HAOI representation to model each hand object interaction frame. Along with the natural language embeddings, the representations are trained by an HAOI manipulation language model to align the grasping process with its language description in a shared representation space. A joint-aware loss is employed to ensure hand grasps follow the dynamic variations of articulated object joints. In this way, our SynHLMA achieves three typical hand manipulation tasks for articulated objects of HAOI generation, HAOI prediction and HAOI interpolation. We evaluate SynHLMA on our built HAOI-lang dataset and experimental results demonstrate the superior hand grasp sequence generation performance comparing with state-of-the-art. We also show a robotics grasp application that enables dexterous grasps execution from imitation learning using the manipulation sequence provided by our SynHLMA. Our codes and datasets will be made publicly available.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "111",
        "title": "The influence of the random numbers quality on the results in stochastic simulations and machine learning",
        "author": [
            "Benjamin A. Antunes"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25269",
        "abstract": "Pseudorandom number generators (PRNGs) are ubiquitous in stochastic simulations and machine learning (ML), where they drive sampling, parameter initialization, regularization, and data shuffling. While widely used, the potential impact of PRNG statistical quality on computational results remains underexplored. In this study, we investigate whether differences in PRNG quality, as measured by standard statistical test suites, can influence outcomes in representative stochastic applications. Seven PRNGs were evaluated, ranging from low-quality linear congruential generators (LCGs) with known statistical deficiencies to high-quality generators such as Mersenne Twister, PCG, and Philox. We applied these PRNGs to four distinct tasks: an epidemiological agent-based model (ABM), two independent from-scratch MNIST classification implementations (Python/NumPy and C++), and a reinforcement learning (RL) CartPole environment. Each experiment was repeated 30 times per generator using fixed seeds to ensure reproducibility, and outputs were compared using appropriate statistical analyses. Results show that very poor statistical quality, as in the ''bad'' LCG failing 125 TestU01 Crush tests, produces significant deviations in ABM epidemic dynamics, reduces MNIST classification accuracy, and severely degrades RL performance. In contrast, mid-and good-quality LCGs-despite failing a limited number of Crush or BigCrush tests-performed comparably to top-tier PRNGs in most tasks, with the RL experiment being the primary exception where performance scaled with statistical quality. Our findings indicate that, once a generator meets a sufficient statistical robustness threshold, its family or design has negligible impact on outcomes for most workloads, allowing selection to be guided by performance and implementation considerations. However, the use of low-quality PRNGs in sensitive stochastic computations can introduce substantial and systematic errors.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "112",
        "title": "Adaptive Design of mmWave Initial Access Codebooks using Reinforcement Learning",
        "author": [
            "Sabrine Aroua",
            "Christos Anastasios Bovolis",
            "Bo GÃ¶ransson",
            "Anastasios Giovanidis",
            "Mathieu Leconte",
            "Apostolos Destounis"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25271",
        "abstract": "Initial access (IA) is the process by which user equipment (UE) establishes its first connection with a base station. In 5G systems, particularly at millimeter-wave frequencies, IA integrates beam management to support highly directional transmissions. The base station employs a codebook of beams for the transmission of Synchronization Signal Blocks (SSBs), which are periodically swept to detect and connect users. The design of this SSB codebook is critical for ensuring reliable, wide-area coverage. In current networks, SSB codebooks are meticulously engineered by domain experts. While these expert-defined codebooks provide a robust baseline, they lack flexibility in dynamic or heterogeneous environments where user distributions vary, limiting their overall effectiveness. This paper proposes a hybrid Reinforcement Learning (RL) framework for adaptive SSB codebook design. Building on top of expert knowledge, the RL agent leverages a pool of expert-designed SSB beams and learns to adaptively select or combine them based on real-time feedback. This enables the agent to dynamically tailor codebooks to the actual environment, without requiring explicit user location information, while always respecting practical beam constraints. Simulation results demonstrate that, on average, the proposed approach improves user connectivity by 10.8$\\%$ compared to static expert configurations. These findings highlight the potential of combining expert knowledge with data-driven optimization to achieve more intelligent, flexible, and resilient beam management in next-generation wireless networks.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "113",
        "title": "Adapting Small Language Models to Low-Resource Domains: A Case Study in Hindi Tourism QA",
        "author": [
            "Sandipan Majhi",
            "Paheli Bhattacharya"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25273",
        "abstract": "Domain-specific question answering in low-resource languages faces two key challenges: scarcity of annotated datasets and limited domain knowledge in general-purpose language models. In this work, we present a multi-stage finetuning strategy to adapt lightweight language models to the Hindi tourism domain by leveraging both original and synthetic training data. Synthetic question-answer pairs are generated using large LLMs (LLaMA-70B, Phi-14B) and used to augment the limited original dataset. We explore several training methodologies and analyse their impact on domain generalisation. Our results demonstrate that large models can efficiently generate synthetic data, while small models can effectively adapt to it, offering a scalable pathway for low-resource, domain-specific QA.",
        "tags": [
            "LLM",
            "LLaMA"
        ]
    },
    {
        "id": "114",
        "title": "Diffusion-Driven Progressive Target Manipulation for Source-Free Domain Adaptation",
        "author": [
            "Yuyang Huang",
            "Yabo Chen",
            "Junyu Zhou",
            "Wenrui Dai",
            "Xiaopeng Zhang",
            "Junni Zou",
            "Hongkai Xiong",
            "Qi Tian"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25279",
        "abstract": "Source-free domain adaptation (SFDA) is a challenging task that tackles domain shifts using only a pre-trained source model and unlabeled target data. Existing SFDA methods are restricted by the fundamental limitation of source-target domain discrepancy. Non-generation SFDA methods suffer from unreliable pseudo-labels in challenging scenarios with large domain discrepancies, while generation-based SFDA methods are evidently degraded due to enlarged domain discrepancies in creating pseudo-source data. To address this limitation, we propose a novel generation-based framework named Diffusion-Driven Progressive Target Manipulation (DPTM) that leverages unlabeled target data as references to reliably generate and progressively refine a pseudo-target domain for SFDA. Specifically, we divide the target samples into a trust set and a non-trust set based on the reliability of pseudo-labels to sufficiently and reliably exploit their information. For samples from the non-trust set, we develop a manipulation strategy to semantically transform them into the newly assigned categories, while simultaneously maintaining them in the target distribution via a latent diffusion model. Furthermore, we design a progressive refinement mechanism that progressively reduces the domain discrepancy between the pseudo-target domain and the real target domain via iterative refinement. Experimental results demonstrate that DPTM outperforms existing methods by a large margin and achieves state-of-the-art performance on four prevailing SFDA benchmark datasets with different scales. Remarkably, DPTM can significantly enhance the performance by up to 18.6% in scenarios with large source-target gaps.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "115",
        "title": "Development of Implicit-Explicit Control Based Amphibious Centipede-Type Robot and Evaluation of its Mobile Performance",
        "author": [
            "Yusuke Tsunoda",
            "Seiya Yamamoto",
            "Kazuki Ito",
            "Runze Xiao",
            "Keisuke Naniwa",
            "Koichi Osuka"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25280",
        "abstract": "Multi-legged mobile robots possess high mobility performance in rough terrain environments, stemming from their high postural stability, joint flexibility, and the redundancy provided by multiple legs. In prior research on navigating between different environments such as land and water, the primary strategy employed involves switching to a controller that generates an appropriate gait for the new environment upon entering it. However, designing appropriate gaits for each complex and diverse environment and accurately determining controller switching for each environment is challenging. Therefore, this research develops a centipede-type mobile robot that navigates both aquatic and terrestrial environments with a simple, unified control scheme, based on the implicit-explicit control philosophy and by ingeniously designing the robot's body structure. In this research, we developed the robot featuring flexible joints and left and right legs on each body segment and focused on the leg structure which has extensive contact with the environment. This paper evaluates the locomotion performance on land and water using the three developed leg structures, using the robot's leg slip rate and actuator energy consumption as evaluation metrics. The experimental results confirmed the existence of an appropriate leg structure capable of navigating both aquatic and terrestrial environments under identical control.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "116",
        "title": "Understanding the Characteristics of LLM-Generated Property-Based Tests in Exploring Edge Cases",
        "author": [
            "Hidetake Tanaka",
            "Haruto Tanaka",
            "Kazumasa Shimari",
            "Kenichi Matsumoto"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25297",
        "abstract": "As Large Language Models (LLMs) increasingly generate code in software development, ensuring the quality of LLM-generated code has become important. Traditional testing approaches using Example-based Testing (EBT) often miss edge cases -- defects that occur at boundary values, special input patterns, or extreme conditions. This research investigates the characteristics of LLM-generated Property-based Testing (PBT) compared to EBT for exploring edge cases. We analyze 16 HumanEval problems where standard solutions failed on extended test cases, generating both PBT and EBT test codes using Claude-4-sonnet. Our experimental results reveal that while each method individually achieved a 68.75\\% bug detection rate, combining both approaches improved detection to 81.25\\%. The analysis demonstrates complementary characteristics: PBT effectively detects performance issues and edge cases through extensive input space exploration, while EBT effectively detects specific boundary conditions and special patterns. These findings suggest that a hybrid approach leveraging both testing methods can improve the reliability of LLM-generated code, providing guidance for test generation strategies in LLM-based code generation.",
        "tags": [
            "Detection",
            "LLM"
        ]
    },
    {
        "id": "117",
        "title": "Teaching Sarcasm: Few-Shot Multimodal Sarcasm Detection via Distillation to a Parameter-Efficient Student",
        "author": [
            "Soumyadeep Jana",
            "Sanasam Ranbir Singh"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25303",
        "abstract": "Multimodal sarcasm detection is challenging, especially in low-resource settings where subtle image-text contradictions are hard to learn due to scarce annotated data, which hinders the model's performance. Parameter-efficient fine-tuning (PEFT) methods like adapters, LoRA, and prompt tuning reduce overfitting but struggle to reach optimal performance due to limited supervision from few-shot data. We propose PEKD, a unified framework that enhances PEFT methods via distillation from an expert model trained on large-scale sarcasm data, which acts as the teacher. To mitigate unreliable signals from the teacher, we introduce an entropy-aware gating mechanism that dynamically adjusts the distillation strength based on teacher confidence. Experiments on two public datasets demonstrate that our PEKD framework enables PEFT methods to outperform both prior parameter-efficient approaches and large multimodal models, achieving strong results in the few-shot scenario. The framework is modular and adaptable to a wide range of multimodal models and tasks.",
        "tags": [
            "Detection",
            "LoRA"
        ]
    },
    {
        "id": "118",
        "title": "Parrot: A Training Pipeline Enhances Both Program CoT and Natural Language CoT for Reasoning",
        "author": [
            "Senjie Jin",
            "Lu Chen",
            "Zhiheng Xi",
            "Yuhui Wang",
            "Sirui Song",
            "Yuhao Zhou",
            "Xinbo Zhang",
            "Peng Sun",
            "Hong Lu",
            "Tao Gui",
            "Qi Zhang",
            "Xuanjing Huang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25310",
        "abstract": "Natural language chain-of-thought (N-CoT) and Program chain-of-thought (P-CoT) have emerged as two primary paradigms for large language models (LLMs) to solve mathematical reasoning problems. Current research typically endeavors to achieve unidirectional enhancement: P-CoT enhanced N-CoT or N-CoT enhanced P-CoT. In this paper, we seek to fully unleash the two paradigms' strengths for mutual enhancement and ultimately achieve simultaneous improvements. We conduct a detailed analysis of the error types across two paradigms, based on which we propose Parrot, a novel training pipeline for mathematical problems: 1) Three target-designed subtasks integrate sequential P-CoT and N-CoT generation. 2) A subtask hybrid training strategy to facilitate natural language semantic transferability. 3) The converted N-CoT auxiliary reward is designed to alleviate the sparse rewards in P-CoT optimization. Extensive experiments demonstrate that Parrot significantly enhances both the performance of N-CoT and P-CoT, especially on N-CoT. Using Parrot SFT, the N-CoT performance of LLaMA2 and CodeLLaMA achieve gains of +21.87 and +21.48 on MathQA over the RL baseline, which is resource-intensive.",
        "tags": [
            "CoT",
            "LLM",
            "RL"
        ]
    },
    {
        "id": "119",
        "title": "Dense and Diverse Goal Coverage in Multi Goal Reinforcement Learning",
        "author": [
            "Sagalpreet Singh",
            "Rishi Saket",
            "Aravindan Raghuveer"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25311",
        "abstract": "Reinforcement Learning algorithms are primarily focused on learning a policy that maximizes expected return. As a result, the learned policy can exploit one or few reward sources. However, in many natural situations, it is desirable to learn a policy that induces a dispersed marginal state distribution over rewarding states, while maximizing the expected return which is typically tied to reaching a goal state. This aspect remains relatively unexplored. Existing techniques based on entropy regularization and intrinsic rewards use stochasticity for encouraging exploration to find an optimal policy which may not necessarily lead to dispersed marginal state distribution over rewarding states. Other RL algorithms which match a target distribution assume the latter to be available apriori. This may be infeasible in large scale systems where enumeration of all states is not possible and a state is determined to be a goal state only upon reaching it. We formalize the problem of maximizing the expected return while uniformly visiting the goal states as Multi Goal RL in which an oracle classifier over the state space determines the goal states. We propose a novel algorithm that learns a high-return policy mixture with marginal state distribution dispersed over the set of goal states. Our algorithm is based on optimizing a custom RL reward which is computed - based on the current policy mixture - at each iteration for a set of sampled trajectories. The latter are used via an offline RL algorithm to update the policy mixture. We prove performance guarantees for our algorithm, showing efficient convergence bounds for optimizing a natural objective which captures the expected return as well as the dispersion of the marginal state distribution over the goal states. We design and perform experiments on synthetic MDPs and standard RL environments to evaluate the effectiveness of our algorithm.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "120",
        "title": "4-Doodle: Text to 3D Sketches that Move!",
        "author": [
            "Hao Chen",
            "Jiaqi Wang",
            "Yonggang Qi",
            "Ke Li",
            "Kaiyue Pang",
            "Yi-Zhe Song"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25319",
        "abstract": "We present a novel task: text-to-3D sketch animation, which aims to bring freeform sketches to life in dynamic 3D space. Unlike prior works focused on photorealistic content generation, we target sparse, stylized, and view-consistent 3D vector sketches, a lightweight and interpretable medium well-suited for visual communication and prototyping. However, this task is very challenging: (i) no paired dataset exists for text and 3D (or 4D) sketches; (ii) sketches require structural abstraction that is difficult to model with conventional 3D representations like NeRFs or point clouds; and (iii) animating such sketches demands temporal coherence and multi-view consistency, which current pipelines do not address. Therefore, we propose 4-Doodle, the first training-free framework for generating dynamic 3D sketches from text. It leverages pretrained image and video diffusion models through a dual-space distillation scheme: one space captures multi-view-consistent geometry using differentiable BÃ©zier curves, while the other encodes motion dynamics via temporally-aware priors. Unlike prior work (e.g., DreamFusion), which optimizes from a single view per step, our multi-view optimization ensures structural alignment and avoids view ambiguity, critical for sparse sketches. Furthermore, we introduce a structure-aware motion module that separates shape-preserving trajectories from deformation-aware changes, enabling expressive motion such as flipping, rotation, and articulated movement. Extensive experiments show that our method produces temporally realistic and structurally stable 3D sketch animations, outperforming existing baselines in both fidelity and controllability. We hope this work serves as a step toward more intuitive and accessible 4D content creation.",
        "tags": [
            "3D",
            "Diffusion",
            "Text-to-3D"
        ]
    },
    {
        "id": "121",
        "title": "GAP: Graph-Based Agent Planning with Parallel Tool Use and Reinforcement Learning",
        "author": [
            "Jiaqi Wu",
            "Qinlao Zhao",
            "Zefeng Chen",
            "Kai Qin",
            "Yifei Zhao",
            "Xueqian Wang",
            "Yuhang Yao"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25320",
        "abstract": "Autonomous agents powered by large language models (LLMs) have shown impressive capabilities in tool manipulation for complex task-solving. However, existing paradigms such as ReAct rely on sequential reasoning and execution, failing to exploit the inherent parallelism among independent sub-tasks. This sequential bottleneck leads to inefficient tool utilization and suboptimal performance in multi-step reasoning scenarios. We introduce Graph-based Agent Planning (GAP), a novel framework that explicitly models inter-task dependencies through graph-based planning to enable adaptive parallel and serial tool execution. Our approach trains agent foundation models to decompose complex tasks into dependency-aware sub-task graphs, autonomously determining which tools can be executed in parallel and which must follow sequential dependencies. This dependency-aware orchestration achieves substantial improvements in both execution efficiency and task accuracy. To train GAP, we construct a high-quality dataset of graph-based planning traces derived from the Multi-Hop Question Answering (MHQA) benchmark. We employ a two-stage training strategy: supervised fine-tuning (SFT) on the curated dataset, followed by reinforcement learning (RL) with a correctness-based reward function on strategically sampled queries where tool-based reasoning provides maximum value. Experimental results on MHQA datasets demonstrate that GAP significantly outperforms traditional ReAct baselines, particularly on multi-step retrieval tasks, while achieving dramatic improvements in tool invocation efficiency through intelligent parallelization. The project page is available at: https://github.com/WJQ7777/Graph-Agent-Planning.",
        "tags": [
            "LLM",
            "RL"
        ]
    },
    {
        "id": "122",
        "title": "CDFlow: Building Invertible Layers with Circulant and Diagonal Matrices",
        "author": [
            "Xuchen Feng",
            "Siyu Liao"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25323",
        "abstract": "Normalizing flows are deep generative models that enable efficient likelihood estimation and sampling through invertible transformations. A key challenge is to design linear layers that enhance expressiveness while maintaining efficient computation of the Jacobian determinant and inverse. We introduce a novel invertible linear layer based on the product of circulant and diagonal matrices. This decomposition reduces parameter complexity from $\\mathcal{O}(n^2)$ to $\\mathcal{O}(mn)$ using $m$ diagonal matrices and $m-1$ circulant matrices while still approximating general linear transformations. By leveraging the Fast Fourier Transform, our approach reduces the time complexity of matrix inversion from $\\mathcal{O}(n^3)$ to $\\mathcal{O}(mn\\log n)$ and that of computing the log-determinant from $\\mathcal{O}(n^3)$ to $\\mathcal{O}(mn)$, where $n$ is the input dimension. We build upon this layer to develop Circulant-Diagonal Flow (CDFlow), which achieves strong density estimation on natural image datasets and effectively models data with inherent periodic structure. Furthermore, CDFlow significantly accelerates key operations in normalizing flows, providing practical benefits for scalable generative modeling.",
        "tags": [
            "Normalizing Flows"
        ]
    },
    {
        "id": "123",
        "title": "StreamingCoT: A Dataset for Temporal Dynamics and Multimodal Chain-of-Thought Reasoning in Streaming VideoQA",
        "author": [
            "Yuhang Hu",
            "Zhenyu Yang",
            "Shihan Wang",
            "Shengsheng Qian",
            "Bin Wen",
            "Fan Yang",
            "Tingting Gao",
            "Changsheng Xu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25332",
        "abstract": "The rapid growth of streaming video applications demands multimodal models with enhanced capabilities for temporal dynamics understanding and complex reasoning. However, current Video Question Answering (VideoQA) datasets suffer from two critical limitations: 1) Static annotation mechanisms fail to capture the evolving nature of answers in temporal video streams, and 2) The absence of explicit reasoning process annotations restricts model interpretability and logical deduction capabilities. To address these challenges, We introduce StreamingCoT, the first dataset explicitly designed for temporally evolving reasoning in streaming VideoQA and multimodal Chain-of-Thought (CoT) tasks. Our framework first establishes a dynamic hierarchical annotation architecture that generates per-second dense descriptions and constructs temporally-dependent semantic segments through similarity fusion, paired with question-answer sets constrained by temporal evolution patterns. We further propose an explicit reasoning chain generation paradigm that extracts spatiotemporal objects via keyframe semantic alignment, derives object state transition-based reasoning paths using large language models, and ensures logical coherence through human-verified validation. This dataset establishes a foundation for advancing research in streaming video understanding, complex temporal reasoning, and multimodal inference. Our StreamingCoT and its construction toolkit can be accessed at https://github.com/Fleeting-hyh/StreamingCoT.",
        "tags": [
            "CoT",
            "LLM"
        ]
    },
    {
        "id": "124",
        "title": "CRMWeaver: Building Powerful Business Agent via Agentic RL and Shared Memories",
        "author": [
            "Yilong Lai",
            "Yipin Yang",
            "Jialong Wu",
            "Fengran Mo",
            "Zhenglin Wang",
            "Ting Liang",
            "Jianguo Lin",
            "Keping Yang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25333",
        "abstract": "Recent years have witnessed the rapid development of LLM-based agents, which shed light on using language agents to solve complex real-world problems. A prominent application lies in business agents, which interact with databases and internal knowledge bases via tool calls to fulfill diverse user requirements. However, this domain is characterized by intricate data relationships and a wide range of heterogeneous tasks, from statistical data queries to knowledge-based question-answering. To address these challenges, we propose CRMWeaver, a novel approach that enhances business agents in such complex settings. To acclimate the agentic model to intricate business environments, we employ a synthesis data generation and RL-based paradigm during training, which significantly improves the model's ability to handle complex data and varied tasks. During inference, a shared memories mechanism is introduced, prompting the agent to learn from task guidelines in similar problems, thereby further boosting its effectiveness and generalization, especially in unseen scenarios. We validate the efficacy of our approach on the CRMArena-Pro dataset, where our lightweight model achieves competitive results in both B2B and B2C business scenarios, underscoring its practical value for real-world applications.",
        "tags": [
            "LLM",
            "RL"
        ]
    },
    {
        "id": "125",
        "title": "Geometric Robot Calibration Using a Calibration Plate",
        "author": [
            "Bernhard Rameder",
            "Hubert Gattringer",
            "Andreas Mueller"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25338",
        "abstract": "In this paper a new method for geometric robot calibration is introduced, which uses a calibration plate with precisely known distances between its measuring points. The relative measurement between two points on the calibration plate is used to determine predefined error parameters of the system. In comparison to conventional measurement methods, like laser tracker or motion capture systems, the calibration plate provides a more mechanically robust and cheaper alternative, which is furthermore easier to transport due to its small size. The calibration method, the plate design, the mathematical description of the error system as well as the identification of the parameters are described in detail. For identifying the error parameters, the least squares method and a constrained optimization problem are used. The functionality of this method was demonstrated in experiments that led to promising results, correlated with one of a laser tracker calibration. The modeling and identification of the error parameters is done for a gantry machine, but is not restricted to that type of robot.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "126",
        "title": "Multi-party Agent Relation Sampling for Multi-party Ad Hoc Teamwork",
        "author": [
            "Beiwen Zhang",
            "Yongheng Liang",
            "Hejun Wu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25340",
        "abstract": "Multi-agent reinforcement learning (MARl) has achieved strong results in cooperative tasks but typically assumes fixed, fully controlled teams. Ad hoc teamwork (AHT) relaxes this by allowing collaboration with unknown partners, yet existing variants still presume shared conventions. We introduce Multil-party Ad Hoc Teamwork (MAHT), where controlled agents must coordinate with multiple mutually unfamiliar groups of uncontrolled teammates. To address this, we propose MARs, which builds a sparse skeleton graph and applies relational modeling to capture cross-group dvnamics. Experiments on MPE and starCralt ll show that MARs outperforms MARL and AHT baselines while converging faster.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "127",
        "title": "Beyond Leakage and Complexity: Towards Realistic and Efficient Information Cascade Prediction",
        "author": [
            "Jie Peng",
            "Rui Wang",
            "Qiang Wang",
            "Zhewei Wei",
            "Bin Tong",
            "Guan Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25348",
        "abstract": "Information cascade popularity prediction is a key problem in analyzing content diffusion in social networks. However, current related works suffer from three critical limitations: (1) temporal leakage in current evaluation--random cascade-based splits allow models to access future information, yielding unrealistic results; (2) feature-poor datasets that lack downstream conversion signals (e.g., likes, comments, or purchases), which limits more practical applications; (3) computational inefficiency of complex graph-based methods that require days of training for marginal gains. We systematically address these challenges from three perspectives: task setup, dataset construction, and model design. First, we propose a time-ordered splitting strategy that chronologically partitions data into consecutive windows, ensuring models are evaluated on genuine forecasting tasks without future information leakage. Second, we introduce Taoke, a large-scale e-commerce cascade dataset featuring rich promoter/product attributes and ground-truth purchase conversions--capturing the complete diffusion lifecycle from promotion to monetization. Third, we develop CasTemp, a lightweight framework that efficiently models cascade dynamics through temporal walks, Jaccard-based neighbor selection for inter-cascade dependencies, and GRU-based encoding with time-aware attention. Under leak-free evaluation, CasTemp achieves state-of-the-art performance across four datasets with orders-of-magnitude speedup. Notably, it excels at predicting second-stage popularity conversions--a practical task critical for real-world applications.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "128",
        "title": "Not ready for the bench: LLM legal interpretation is unstable and out of step with human judgments",
        "author": [
            "Abhishek Purushothama",
            "Junghyun Min",
            "Brandon Waldon",
            "Nathan Schneider"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25356",
        "abstract": "Legal interpretation frequently involves assessing how a legal text, as understood by an 'ordinary' speaker of the language, applies to the set of facts characterizing a legal dispute in the U.S. judicial system. Recent scholarship has proposed that legal practitioners add large language models (LLMs) to their interpretive toolkit. This work offers an empirical argument against LLM interpretation as recently practiced by legal scholars and federal judges. Our investigation in English shows that models do not provide stable interpretive judgments: varying the question format can lead the model to wildly different conclusions. Moreover, the models show weak to moderate correlation with human judgment, with large variance across model and question variant, suggesting that it is dangerous to give much credence to the conclusions produced by generative AI.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "129",
        "title": "Monitoring Transformative Technological Convergence Through LLM-Extracted Semantic Entity Triple Graphs",
        "author": [
            "Alexander Sternfeld",
            "Andrei Kucharavy",
            "Dimitri Percia David",
            "Alain Mermoud",
            "Julian Jang-Jaccard",
            "Nathan Monnet"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25370",
        "abstract": "Forecasting transformative technologies remains a critical but challenging task, particularly in fast-evolving domains such as Information and Communication Technologies (ICTs). Traditional expert-based methods struggle to keep pace with short innovation cycles and ambiguous early-stage terminology. In this work, we propose a novel, data-driven pipeline to monitor the emergence of transformative technologies by identifying patterns of technological convergence.\nOur approach leverages advances in Large Language Models (LLMs) to extract semantic triples from unstructured text and construct a large-scale graph of technology-related entities and relations. We introduce a new method for grouping semantically similar technology terms (noun stapling) and develop graph-based metrics to detect convergence signals. The pipeline includes multi-stage filtering, domain-specific keyword clustering, and a temporal trend analysis of topic co-occurence.\nWe validate our methodology on two complementary datasets: 278,625 arXiv preprints (2017--2024) to capture early scientific signals, and 9,793 USPTO patent applications (2018-2024) to track downstream commercial developments. Our results demonstrate that the proposed pipeline can identify both established and emerging convergence patterns, offering a scalable and generalizable framework for technology forecasting grounded in full-text analysis.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "130",
        "title": "CGM-Led Multimodal Tracking with Chatbot Support: An Autoethnography in Sub-Health",
        "author": [
            "Dongyijie Primo Pan",
            "Lan Luo",
            "Yike Wang",
            "Pan Hui"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25381",
        "abstract": "Metabolic disorders present a pressing global health challenge, with China carrying the world's largest burden. While continuous glucose monitoring (CGM) has transformed diabetes care, its potential for supporting sub-health populations -- such as individuals who are overweight, prediabetic, or anxious -- remains underexplored. At the same time, large language models (LLMs) are increasingly used in health coaching, yet CGM is rarely incorporated as a first-class signal. To address this gap, we conducted a six-week autoethnography, combining CGM with multimodal indicators captured via common digital devices and a chatbot that offered personalized reflections and explanations of glucose fluctuations. Our findings show how CGM-led, data-first multimodal tracking, coupled with conversational support, shaped everyday practices of diet, activity, stress, and wellbeing. This work contributes to HCI by extending CGM research beyond clinical diabetes and demonstrating how LLM-driven agents can support preventive health and reflection in at-risk populations.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "131",
        "title": "Instance-Level Composed Image Retrieval",
        "author": [
            "Bill Psomas",
            "George Retsinas",
            "Nikos Efthymiadis",
            "Panagiotis Filntisis",
            "Yannis Avrithis",
            "Petros Maragos",
            "Ondrej Chum",
            "Giorgos Tolias"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25387",
        "abstract": "The progress of composed image retrieval (CIR), a popular research direction in image retrieval, where a combined visual and textual query is used, is held back by the absence of high-quality training and evaluation data. We introduce a new evaluation dataset, i-CIR, which, unlike existing datasets, focuses on an instance-level class definition. The goal is to retrieve images that contain the same particular object as the visual query, presented under a variety of modifications defined by textual queries. Its design and curation process keep the dataset compact to facilitate future research, while maintaining its challenge-comparable to retrieval among more than 40M random distractors-through a semi-automated selection of hard negatives.\nTo overcome the challenge of obtaining clean, diverse, and suitable training data, we leverage pre-trained vision-and-language models (VLMs) in a training-free approach called BASIC. The method separately estimates query-image-to-image and query-text-to-image similarities, performing late fusion to upweight images that satisfy both queries, while down-weighting those that exhibit high similarity with only one of the two. Each individual similarity is further improved by a set of components that are simple and intuitive. BASIC sets a new state of the art on i-CIR but also on existing CIR datasets that follow a semantic-level class definition. Project page: https://vrg.fel.cvut.cz/icir/.",
        "tags": [
            "Text-to-Image",
            "VLM"
        ]
    },
    {
        "id": "132",
        "title": "Towards Automated Quality Assurance of Patent Specifications: A Multi-Dimensional LLM Framework",
        "author": [
            "Yuqian Chai",
            "Chaochao Wang",
            "Weilei Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25402",
        "abstract": "Despite the surge in patent applications and emergence of AI drafting tools, systematic evaluation of patent content quality has received limited research attention. To address this gap, We propose to evaluate patents using regulatory compliance, technical coherence, and figure-reference consistency detection modules, and then generate improvement suggestions via an integration module. The framework is validated on a comprehensive dataset comprising 80 human-authored and 80 AI-generated patents from two patent drafting tools. Experimental results show balanced accuracies of 99.74\\%, 82.12\\%, and 91.2\\% respectively across the three detection modules when validated against expert annotations. Additional analysis was conducted to examine defect distributions across patent sections, technical domains, and authoring sources. Section-based analysis indicates that figure-text consistency and technical detail precision require particular attention. Mechanical Engineering and Construction show more claim-specification inconsistencies due to complex technical documentation requirements. AI-generated patents show a significant gap compared to human-authored ones. While human-authored patents primarily contain surface-level errors like typos, AI-generated patents exhibit more structural defects in figure-text alignment and cross-references.",
        "tags": [
            "Detection",
            "LLM"
        ]
    },
    {
        "id": "133",
        "title": "GPTOpt: Towards Efficient LLM-Based Black-Box Optimization",
        "author": [
            "Jamison Meindl",
            "Yunsheng Tian",
            "Tony Cui",
            "Veronika Thost",
            "Zhang-Wei Hong",
            "Jie Chen",
            "Wojciech Matusik",
            "Mina KonakoviÄ LukoviÄ"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25404",
        "abstract": "Global optimization of expensive, derivative-free black-box functions demands extreme sample efficiency. Classical methods such as Bayesian Optimization (BO) can be effective, but they often require careful parameter tuning to each application domain. At the same time, Large Language Models (LLMs) have shown broad capabilities, yet state-of-the-art models remain limited in solving continuous black-box optimization tasks. We introduce GPTOpt, an LLM-based optimization method that equips LLMs with continuous black-box optimization capabilities. By fine-tuning large language models on extensive synthetic datasets derived from diverse BO parameterizations, GPTOpt leverages LLM pre-training to generalize across optimization tasks. On a variety of black-box optimization benchmarks, GPTOpt surpasses traditional optimizers, highlighting the capacity of LLMs for advanced numerical reasoning and introducing a flexible framework for global optimization without parameter tuning.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "134",
        "title": "Sim-to-Real Gentle Manipulation of Deformable and Fragile Objects with Stress-Guided Reinforcement Learning",
        "author": [
            "Kei Ikemura",
            "Yifei Dong",
            "David Blanco-Mulero",
            "Alberta Longhini",
            "Li Chen",
            "Florian T. Pokorny"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25405",
        "abstract": "Robotic manipulation of deformable and fragile objects presents significant challenges, as excessive stress can lead to irreversible damage to the object. While existing solutions rely on accurate object models or specialized sensors and grippers, this adds complexity and often lacks generalization. To address this problem, we present a vision-based reinforcement learning approach that incorporates a stress-penalized reward to discourage damage to the object explicitly. In addition, to bootstrap learning, we incorporate offline demonstrations as well as a designed curriculum progressing from rigid proxies to deformables. We evaluate the proposed method in both simulated and real-world scenarios, showing that the policy learned in simulation can be transferred to the real world in a zero-shot manner, performing tasks such as picking up and pushing tofu. Our results show that the learned policies exhibit a damage-aware, gentle manipulation behavior, demonstrating their effectiveness by decreasing the stress applied to fragile objects by 36.5% while achieving the task goals, compared to vanilla RL policies.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "135",
        "title": "BhashaBench V1: A Comprehensive Benchmark for the Quadrant of Indic Domains",
        "author": [
            "Vijay Devane",
            "Mohd Nauman",
            "Bhargav Patel",
            "Aniket Mahendra Wakchoure",
            "Yogeshkumar Sant",
            "Shyam Pawar",
            "Viraj Thakur",
            "Ananya Godse",
            "Sunil Patra",
            "Neha Maurya",
            "Suraj Racha",
            "Nitish Kamal Singh",
            "Ajay Nagpal",
            "Piyush Sawarkar",
            "Kundeshwar Vijayrao Pundalik",
            "Rohit Saluja",
            "Ganesh Ramakrishnan"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25409",
        "abstract": "The rapid advancement of large language models(LLMs) has intensified the need for domain and culture specific evaluation. Existing benchmarks are largely Anglocentric and domain-agnostic, limiting their applicability to India-centric contexts. To address this gap, we introduce BhashaBench V1, the first domain-specific, multi-task, bilingual benchmark focusing on critical Indic knowledge systems. BhashaBench V1 contains 74,166 meticulously curated question-answer pairs, with 52,494 in English and 21,672 in Hindi, sourced from authentic government and domain-specific exams. It spans four major domains: Agriculture, Legal, Finance, and Ayurveda, comprising 90+ subdomains and covering 500+ topics, enabling fine-grained evaluation. Evaluation of 29+ LLMs reveals significant domain and language specific performance gaps, with especially large disparities in low-resource domains. For instance, GPT-4o achieves 76.49% overall accuracy in Legal but only 59.74% in Ayurveda. Models consistently perform better on English content compared to Hindi across all domains. Subdomain-level analysis shows that areas such as Cyber Law, International Finance perform relatively well, while Panchakarma, Seed Science, and Human Rights remain notably weak. BhashaBench V1 provides a comprehensive dataset for evaluating large language models across India's diverse knowledge domains. It enables assessment of models' ability to integrate domain-specific knowledge with bilingual understanding. All code, benchmarks, and resources are publicly available to support open research.",
        "tags": [
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "136",
        "title": "Serve Programs, Not Prompts",
        "author": [
            "In Gim",
            "Lin Zhong"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25412",
        "abstract": "Current large language model (LLM) serving systems, primarily designed for text completion, are neither efficient nor adaptable for increasingly complex LLM applications due to their inflexible design. We propose a new LLM serving system architecture that serves programs instead of prompts to address this problem. These programs, called LLM Inference Programs (LIPs), allow users to customize token prediction and KV cache management at runtime and to offload parts of their application logic, such as tool execution, to the server. We describe an example of this architecture through a system named Symphony, which functions as an operating system for LIPs. Symphony exposes LLM model computations via system calls and virtualizes KV cache with a dedicated file system, while ensuring GPU efficiency with a two-level process scheduling scheme. Symphony has the potential to open the door to a more efficient and extensible ecosystem for LLM applications.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "137",
        "title": "Small Talk, Big Impact? LLM-based Conversational Agents to Mitigate Passive Fatigue in Conditional Automated Driving",
        "author": [
            "Lewis Cockram",
            "Yueteng Yu",
            "Jorge Pardo",
            "Xiaomeng Li",
            "Andry Rakotonirainy",
            "Jonny Kuo",
            "Sebastien Demmel",
            "Mike LennÃ©",
            "Ronald Schroeter"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25421",
        "abstract": "Passive fatigue during conditional automated driving can compromise driver readiness and safety. This paper presents findings from a test-track study with 40 participants in a real-world rural automated driving scenario. In this scenario, a Large Language Model (LLM) based conversational agent (CA) was designed to check in with drivers and re-engage them with their surroundings. Drawing on in-car video recordings, sleepiness ratings and interviews, we analysed how drivers interacted with the agent and how these interactions shaped alertness. Users found the CA helpful for supporting vigilance during passive fatigue. Thematic analysis of acceptability further revealed three user preference profiles that implicate future intention to use CAs. Positioning empirically observed profiles within existing CA archetype frameworks highlights the need for adaptive design sensitive to diverse user groups. This work underscores the potential of CAs as proactive Human-Machine Interface (HMI) interventions, demonstrating how natural language can support context-aware interaction during automated driving.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "138",
        "title": "Solving the Right Problem with Multi-Robot Formations",
        "author": [
            "Chaz Cornwall",
            "Jeremy P. Bos"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25422",
        "abstract": "Formation control simplifies minimizing multi-robot cost functions by encoding a cost function as a shape the robots maintain. However, by reducing complex cost functions to formations, discrepancies arise between maintaining the shape and minimizing the original cost function. For example, a Diamond or Box formation shape is often used for protecting all members of the formation. When more information about the surrounding environment becomes available, a static shape often no longer minimizes the original protection cost. We propose a formation planner to reduce mismatch between a formation and the cost function while still leveraging efficient formation controllers. Our formation planner is a two-step optimization problem that identifies desired relative robot positions. We first solve a constrained problem to estimate non-linear and non-differentiable costs with a weighted sum of surrogate cost functions. We theoretically analyze this problem and identify situations where weights do not need to be updated. The weighted, surrogate cost function is then minimized using relative positions between robots. The desired relative positions are realized using a non-cooperative formation controller derived from Lyapunov's direct approach. We then demonstrate the efficacy of this approach for military-like costs such as protection and obstacle avoidance. In simulations, we show a formation planner can reduce a single cost by over 75%. When minimizing a variety of cost functions simultaneously, using a formation planner with adaptive weights can reduce the cost by 20-40%. Formation planning provides better performance by minimizing a surrogate cost function that closely approximates the original cost function instead of relying on a shape abstraction.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "139",
        "title": "What Challenges Do Developers Face in AI Agent Systems? An Empirical Study on Stack Overflow",
        "author": [
            "Ali Asgari",
            "Annibale Panichella",
            "Pouria Derakhshanfar",
            "Mitchell Olsthoorn"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25423",
        "abstract": "AI agents have rapidly gained popularity across research and industry as systems that extend large language models with additional capabilities to plan, use tools, remember, and act toward specific goals. Yet despite their promise, developers face persistent and often underexplored challenges when building, deploying, and maintaining these emerging systems. To identify these challenges, we study developer discussions on Stack Overflow, the world's largest developer-focused Q and A platform with about 60 million questions and answers and 30 million users. We construct a taxonomy of developer challenges through tag expansion and filtering, apply LDA-MALLET for topic modeling, and manually validate and label the resulting themes. Our analysis reveals seven major areas of recurring issues encompassing 77 distinct technical challenges related to runtime integration, dependency management, orchestration complexity, and evaluation reliability. We further quantify topic popularity and difficulty to identify which issues are most common and hardest to resolve, map the tools and programming languages used in agent development, and track their evolution from 2021 to 2025 in relation to major AI model and framework releases. Finally, we present the implications of our results, offering concrete guidance for practitioners, researchers, and educators on agent reliability and developer support.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "140",
        "title": "Implicature in Interaction: Understanding Implicature Improves Alignment in Human-LLM Interaction",
        "author": [
            "Asutosh Hota",
            "Jussi P. P. Jokinen"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25426",
        "abstract": "The rapid advancement of Large Language Models (LLMs) is positioning language at the core of human-computer interaction (HCI). We argue that advancing HCI requires attention to the linguistic foundations of interaction, particularly implicature (meaning conveyed beyond explicit statements through shared context) which is essential for human-AI (HAI) alignment. This study examines LLMs' ability to infer user intent embedded in context-driven prompts and whether understanding implicature improves response generation. Results show that larger models approximate human interpretations more closely, while smaller models struggle with implicature inference. Furthermore, implicature-based prompts significantly enhance the perceived relevance and quality of responses across models, with notable gains in smaller models. Overall, 67.6% of participants preferred responses with implicature-embedded prompts to literal ones, highlighting a clear preference for contextually nuanced communication. Our work contributes to understanding how linguistic theory can be used to address the alignment problem by making HAI interaction more natural and contextually grounded.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "141",
        "title": "RLMEval: Evaluating Research-Level Neural Theorem Proving",
        "author": [
            "Auguste Poiroux",
            "Antoine Bosselut",
            "Viktor KunÄak"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25427",
        "abstract": "Despite impressive results on curated benchmarks, the practical impact of large language models (LLMs) on research-level neural theorem proving and proof autoformalization is still limited. We introduce RLMEval, an evaluation suite for these tasks, focusing on research-level mathematics from real-world Lean formalization projects. RLMEval targets the evaluation of neural theorem proving and proof autoformalization on challenging research-level theorems by leveraging real Lean Blueprint formalization projects. Our evaluation of state-of-the-art models on RLMEval, comprising 613 theorems from 6 Lean projects, reveals a significant gap: progress on existing benchmarks does not readily translate to these more realistic settings, with the best model achieving only a 10.3 % pass rate. RLMEval provides a new, challenging benchmark designed to guide and accelerate progress in automated reasoning for formal mathematics.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "142",
        "title": "Depth and Autonomy: A Framework for Evaluating LLM Applications in Social Science Research",
        "author": [
            "Ali Sanaei",
            "Ali Rajabzadeh"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25432",
        "abstract": "Large language models (LLMs) are increasingly utilized by researchers across a wide range of domains, and qualitative social science is no exception; however, this adoption faces persistent challenges, including interpretive bias, low reliability, and weak auditability. We introduce a framework that situates LLM usage along two dimensions, interpretive depth and autonomy, thereby offering a straightforward way to classify LLM applications in qualitative research and to derive practical design recommendations. We present the state of the literature with respect to these two dimensions, based on all published social science papers available on Web of Science that use LLMs as a tool and not strictly as the subject of study. Rather than granting models expansive freedom, our approach encourages researchers to decompose tasks into manageable segments, much as they would when delegating work to capable undergraduate research assistants. By maintaining low levels of autonomy and selectively increasing interpretive depth only where warranted and under supervision, one can plausibly reap the benefits of LLMs while preserving transparency and reliability.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "143",
        "title": "Agentic AI: A Comprehensive Survey of Architectures, Applications, and Future Directions",
        "author": [
            "Mohamad Abou Ali",
            "Fadi Dornaika"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25445",
        "abstract": "Agentic AI represents a transformative shift in artificial intelligence, but its rapid advancement has led to a fragmented understanding, often conflating modern neural systems with outdated symbolic models -- a practice known as conceptual retrofitting. This survey cuts through this confusion by introducing a novel dual-paradigm framework that categorizes agentic systems into two distinct lineages: the Symbolic/Classical (relying on algorithmic planning and persistent state) and the Neural/Generative (leveraging stochastic generation and prompt-driven orchestration). Through a systematic PRISMA-based review of 90 studies (2018--2025), we provide a comprehensive analysis structured around this framework across three dimensions: (1) the theoretical foundations and architectural principles defining each paradigm; (2) domain-specific implementations in healthcare, finance, and robotics, demonstrating how application constraints dictate paradigm selection; and (3) paradigm-specific ethical and governance challenges, revealing divergent risks and mitigation strategies. Our analysis reveals that the choice of paradigm is strategic: symbolic systems dominate safety-critical domains (e.g., healthcare), while neural systems prevail in adaptive, data-rich environments (e.g., finance). Furthermore, we identify critical research gaps, including a significant deficit in governance models for symbolic systems and a pressing need for hybrid neuro-symbolic architectures. The findings culminate in a strategic roadmap arguing that the future of Agentic AI lies not in the dominance of one paradigm, but in their intentional integration to create systems that are both adaptable and reliable. This work provides the essential conceptual toolkit to guide future research, development, and policy toward robust and trustworthy hybrid intelligent systems.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "144",
        "title": "Fine-Tuned Language Models for Domain-Specific Summarization and Tagging",
        "author": [
            "Jun Wang",
            "Fuming Lin",
            "Yuyu Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25460",
        "abstract": "This paper presents a pipeline integrating fine-tuned large language models (LLMs) with named entity recognition (NER) for efficient domain-specific text summarization and tagging. The authors address the challenge posed by rapidly evolving sub-cultural languages and slang, which complicate automated information extraction and law enforcement monitoring. By leveraging the LLaMA Factory framework, the study fine-tunes LLMs on both generalpurpose and custom domain-specific datasets, particularly in the political and security domains. The models are evaluated using BLEU and ROUGE metrics, demonstrating that instruction fine-tuning significantly enhances summarization and tagging accuracy, especially for specialized corpora. Notably, the LLaMA3-8B-Instruct model, despite its initial limitations in Chinese comprehension, outperforms its Chinese-trained counterpart after domainspecific fine-tuning, suggesting that underlying reasoning capabilities can transfer across languages. The pipeline enables concise summaries and structured entity tagging, facilitating rapid document categorization and distribution. This approach proves scalable and adaptable for real-time applications, supporting efficient information management and the ongoing need to capture emerging language trends. The integration of LLMs and NER offers a robust solution for transforming unstructured text into actionable insights, crucial for modern knowledge management and security operations.",
        "tags": [
            "LLM",
            "LLaMA"
        ]
    },
    {
        "id": "145",
        "title": "Generalized Pseudo-Relevance Feedback",
        "author": [
            "Yiteng Tu",
            "Weihang Su",
            "Yujia Zhou",
            "Yiqun Liu",
            "Fen Lin",
            "Qin Liu",
            "Qingyao Ai"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25488",
        "abstract": "Query rewriting is a fundamental technique in information retrieval (IR). It typically employs the retrieval result as relevance feedback to refine the query and thereby addresses the vocabulary mismatch between user queries and relevant documents. Traditional pseudo-relevance feedback (PRF) and its vector-based extension (VPRF) improve retrieval performance by leveraging top-retrieved documents as relevance feedback. However, they are constructed based on two major hypotheses: the relevance assumption (top documents are relevant) and the model assumption (rewriting methods need to be designed specifically for particular model architectures). While recent large language models (LLMs)-based generative relevance feedback (GRF) enables model-free query reformulation, it either suffers from severe LLM hallucination or, again, relies on the relevance assumption to guarantee the effectiveness of rewriting quality. To overcome these limitations, we introduce an assumption-relaxed framework: \\textit{Generalized Pseudo Relevance Feedback} (GPRF), which performs model-free, natural language rewriting based on retrieved documents, not only eliminating the model assumption but also reducing dependence on the relevance assumption. Specifically, we design a utility-oriented training pipeline with reinforcement learning to ensure robustness against noisy feedback. Extensive experiments across multiple benchmarks and retrievers demonstrate that GPRF consistently outperforms strong baselines, establishing it as an effective and generalizable framework for query rewriting.",
        "tags": [
            "LLM",
            "RL"
        ]
    },
    {
        "id": "146",
        "title": "Evaluating Learning Congestion control Schemes for LEO Constellations",
        "author": [
            "Mihai Mazilu",
            "Aiden Valentine",
            "George Parisis"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25498",
        "abstract": "Low Earth Orbit (LEO) satellite networks introduce unique congestion control (CC) challenges due to frequent handovers, rapidly changing round-trip times (RTTs), and non-congestive loss. This paper presents the first comprehensive, emulation-driven evaluation of CC schemes in LEO networks, combining realistic orbital dynamics via the LeoEM framework with targeted Mininet micro-benchmarks. We evaluated representative CC algorithms from three classes, loss-based (Cubic, SaTCP), model-based (BBRv3), and learning-based (Vivace, Sage, Astraea), across diverse single-flow and multi-flow scenarios, including interactions with active queue management (AQM). Our findings reveal that: (1) handover-aware loss-based schemes can reclaim bandwidth but at the cost of increased latency; (2) BBRv3 sustains high throughput with modest delay penalties, yet reacts slowly to abrupt RTT changes; (3) RL-based schemes severely underperform under dynamic conditions, despite being notably resistant to non-congestive loss; (4) fairness degrades significantly with RTT asymmetry and multiple bottlenecks, especially in human-designed CC schemes; and (5) AQM at bottlenecks can restore fairness and boost efficiency. These results expose critical limitations in current CC schemes and provide insight for designing LEO-specific data transport protocols.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "147",
        "title": "Multi-Objective Search: Algorithms, Applications, and Emerging Directions",
        "author": [
            "Oren Salzman",
            "Carlos HernÃ¡ndez Ulloa",
            "Ariel Felner",
            "Sven Koenig"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25504",
        "abstract": "Multi-objective search (MOS) has emerged as a unifying framework for planning and decision-making problems where multiple, often conflicting, criteria must be balanced. While the problem has been studied for decades, recent years have seen renewed interest in the topic across AI applications such as robotics, transportation, and operations research, reflecting the reality that real-world systems rarely optimize a single measure. This paper surveys developments in MOS while highlighting cross-disciplinary opportunities, and outlines open challenges that define the emerging frontier of MOS",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "148",
        "title": "Reflections on the Reproducibility of Commercial LLM Performance in Empirical Software Engineering Studies",
        "author": [
            "Florian Angermeir",
            "Maximilian Amougou",
            "Mark Kreitz",
            "Andreas Bauer",
            "Matthias Linhuber",
            "Davide Fucci",
            "Fabiola MoyÃ³n C.",
            "Daniel Mendez",
            "Tony Gorschek"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25506",
        "abstract": "Large Language Models have gained remarkable interest in industry and academia. The increasing interest in LLMs in academia is also reflected in the number of publications on this topic over the last years. For instance, alone 78 of the around 425 publications at ICSE 2024 performed experiments with LLMs. Conducting empirical studies with LLMs remains challenging and raises questions on how to achieve reproducible results, for both other researchers and practitioners. One important step towards excelling in empirical research on LLMs and their application is to first understand to what extent current research results are eventually reproducible and what factors may impede reproducibility. This investigation is within the scope of our work. We contribute an analysis of the reproducibility of LLM-centric studies, provide insights into the factors impeding reproducibility, and discuss suggestions on how to improve the current state. In particular, we studied the 86 articles describing LLM-centric studies, published at ICSE 2024 and ASE 2024. Of the 86 articles, 18 provided research artefacts and used OpenAI models. We attempted to replicate those 18 studies. Of the 18 studies, only five were fit for reproduction. For none of the five studies, we were able to fully reproduce the results. Two studies seemed to be partially reproducible, and three studies did not seem to be reproducible. Our results highlight not only the need for stricter research artefact evaluations but also for more robust study designs to ensure the reproducible value of future publications.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "149",
        "title": "Predicate Renaming via Large Language Models",
        "author": [
            "Elisabetta Gentili",
            "Tony Ribeiro",
            "Fabrizio Riguzzi",
            "Katsumi Inoue"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25517",
        "abstract": "In this paper, we address the problem of giving names to predicates in logic rules using Large Language Models (LLMs). In the context of Inductive Logic Programming, various rule generation methods produce rules containing unnamed predicates, with Predicate Invention being a key example. This hinders the readability, interpretability, and reusability of the logic theory. Leveraging recent advancements in LLMs development, we explore their ability to process natural language and code to provide semantically meaningful suggestions for giving a name to unnamed predicates. The evaluation of our approach on some hand-crafted logic rules indicates that LLMs hold potential for this task.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "150",
        "title": "Nonparametric estimation of homogenized invariant measures from multiscale data via Hermite expansion",
        "author": [
            "Jaroslav I. Borodavka",
            "Max Hirsch",
            "Sebastian Krumscheid",
            "Andrea Zanoni"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25521",
        "abstract": "We consider the problem of density estimation in the context of multiscale Langevin diffusion processes, where a single-scale homogenized surrogate model can be derived. In particular, our aim is to learn the density of the invariant measure of the homogenized dynamics from a continuous-time trajectory generated by the full multiscale system. We propose a spectral method based on a truncated Fourier expansion with Hermite functions as orthonormal basis. The Fourier coefficients are computed directly from the data owing to the ergodic theorem. We prove that the resulting density estimator is robust and converges to the invariant density of the homogenized model as the scale separation parameter vanishes, provided the time horizon and the number of Fourier modes are suitably chosen in relation to the multiscale parameter. The accuracy and reliability of this methodology is further demonstrated through a series of numerical experiments.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "151",
        "title": "Zero Reinforcement Learning Towards General Domains",
        "author": [
            "Yuyuan Zeng",
            "Yufei Huang",
            "Can Xu",
            "Qingfeng Sun",
            "Jianfeng Yan",
            "Guanghui Xu",
            "Tao Yang",
            "Fengzong Lian"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25528",
        "abstract": "Zero Reinforcement Learning (Zero-RL) has proven to be an effective approach for enhancing the reasoning capabilities of large language models (LLMs) by directly applying reinforcement learning with verifiable rewards on pretrained models, without the need for a supervised fine-tuning phase. However, current research on zero-RL primarily focuses on domains with easily verifiable reward signals, such as mathematics, programming, and other reasoning tasks. The challenge of eliciting reasoning abilities in more diverse scenarios, where verification is not straightforward, remains underexplored. To address this gap, we propose a novel zero-RL paradigm designed to improve a model's reasoning ability across both verifiable and non-verifiable domains. By combining verifiable rewards with a generative reward model, we conduct multi-task zero-RL training across both domains, facilitating the transfer of reasoning capabilities between them. Furthermore, to mitigate reward hacking in the generative reward model, we design a smooth length penalty that encourages the generation of more comprehensive thinking tokens in general domains. Experimental results on Qwen3-8B-Base and Qwen3-14B-Base demonstrate that our approach achieves superior reasoning performance, not only on tasks requiring extensive reasoning but also on more general tasks.",
        "tags": [
            "LLM",
            "RL"
        ]
    },
    {
        "id": "152",
        "title": "Off-policy Reinforcement Learning with Model-based Exploration Augmentation",
        "author": [
            "Likun Wang",
            "Xiangteng Zhang",
            "Yinuo Wang",
            "Guojian Zhan",
            "Wenxuan Wang",
            "Haoyu Gao",
            "Jingliang Duan",
            "Shengbo Eben Li"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25529",
        "abstract": "Exploration is fundamental to reinforcement learning (RL), as it determines how effectively an agent discovers and exploits the underlying structure of its environment to achieve optimal performance. Existing exploration methods generally fall into two categories: active exploration and passive exploration. The former introduces stochasticity into the policy but struggles in high-dimensional environments, while the latter adaptively prioritizes transitions in the replay buffer to enhance exploration, yet remains constrained by limited sample diversity. To address the limitation in passive exploration, we propose Modelic Generative Exploration (MoGE), which augments exploration through the generation of under-explored critical states and synthesis of dynamics-consistent experiences through transition models. MoGE is composed of two components: (1) a diffusion-based generator that synthesizes critical states under the guidance of a utility function evaluating each state's potential influence on policy exploration, and (2) a one-step imagination world model for constructing critical transitions based on the critical states for agent learning. Our method adopts a modular formulation that aligns with the principles of off-policy learning, allowing seamless integration with existing algorithms to improve exploration without altering their core structures. Empirical results on OpenAI Gym and DeepMind Control Suite reveal that MoGE effectively bridges exploration and policy learning, leading to remarkable gains in both sample efficiency and performance across complex control tasks.",
        "tags": [
            "Diffusion",
            "RL"
        ]
    },
    {
        "id": "153",
        "title": "TwinVoice: A Multi-dimensional Benchmark Towards Digital Twins via LLM Persona Simulation",
        "author": [
            "Bangde Du",
            "Minghao Guo",
            "Songming He",
            "Ziyi Ye",
            "Xi Zhu",
            "Weihang Su",
            "Shuqi Zhu",
            "Yujia Zhou",
            "Yongfeng Zhang",
            "Qingyao Ai",
            "Yiqun Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25536",
        "abstract": "Large Language Models (LLMs) are exhibiting emergent human-like abilities and are increasingly envisioned as the foundation for simulating an individual's communication style, behavioral tendencies, and personality traits. However, current evaluations of LLM-based persona simulation remain limited: most rely on synthetic dialogues, lack systematic frameworks, and lack analysis of the capability requirement. To address these limitations, we introduce TwinVoice, a comprehensive benchmark for assessing persona simulation across diverse real-world contexts. TwinVoice encompasses three dimensions: Social Persona (public social interactions), Interpersonal Persona (private dialogues), and Narrative Persona (role-based expression). It further decomposes the evaluation of LLM performance into six fundamental capabilities, including opinion consistency, memory recall, logical reasoning, lexical fidelity, persona tone, and syntactic style. Experimental results reveal that while advanced models achieve moderate accuracy in persona simulation, they still fall short of capabilities such as syntactic style and memory recall. Consequently, the average performance achieved by LLMs remains considerably below the human baseline.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "154",
        "title": "Transformers Provably Learn Directed Acyclic Graphs via Kernel-Guided Mutual Information",
        "author": [
            "Yuan Cheng",
            "Yu Huang",
            "Zhe Xiong",
            "Yingbin Liang",
            "Vincent Y. F. Tan"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25542",
        "abstract": "Uncovering hidden graph structures underlying real-world data is a critical challenge with broad applications across scientific domains. Recently, transformer-based models leveraging the attention mechanism have demonstrated strong empirical success in capturing complex dependencies within graphs. However, the theoretical understanding of their training dynamics has been limited to tree-like graphs, where each node depends on a single parent. Extending provable guarantees to more general directed acyclic graphs (DAGs) -- which involve multiple parents per node -- remains challenging, primarily due to the difficulty in designing training objectives that enable different attention heads to separately learn multiple different parent relationships.\nIn this work, we address this problem by introducing a novel information-theoretic metric: the kernel-guided mutual information (KG-MI), based on the $f$-divergence. Our objective combines KG-MI with a multi-head attention framework, where each head is associated with a distinct marginal transition kernel to model diverse parent-child dependencies effectively. We prove that, given sequences generated by a $K$-parent DAG, training a single-layer, multi-head transformer via gradient ascent converges to the global optimum in polynomial time. Furthermore, we characterize the attention score patterns at convergence. In addition, when particularizing the $f$-divergence to the KL divergence, the learned attention scores accurately reflect the ground-truth adjacency matrix, thereby provably recovering the underlying graph structure. Experimental results validate our theoretical findings.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "155",
        "title": "Using VLM Reasoning to Constrain Task and Motion Planning",
        "author": [
            "Muyang Yan",
            "Miras Mengdibayev",
            "Ardon Floros",
            "Weihang Guo",
            "Lydia E. Kavraki",
            "Zachary Kingston"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25548",
        "abstract": "In task and motion planning, high-level task planning is done over an abstraction of the world to enable efficient search in long-horizon robotics problems. However, the feasibility of these task-level plans relies on the downward refinability of the abstraction into continuous motion. When a domain's refinability is poor, task-level plans that appear valid may ultimately fail during motion planning, requiring replanning and resulting in slower overall performance. Prior works mitigate this by encoding refinement issues as constraints to prune infeasible task plans. However, these approaches only add constraints upon refinement failure, expending significant search effort on infeasible branches. We propose VIZ-COAST, a method of leveraging the common-sense spatial reasoning of large pretrained Vision-Language Models to identify issues with downward refinement a priori, bypassing the need to fix these failures during planning. Experiments on two challenging TAMP domains show that our approach is able to extract plausible constraints from images and domain descriptions, drastically reducing planning times and, in some cases, eliminating downward refinement failures altogether, generalizing to a diverse range of instances from the broader domain.",
        "tags": [
            "Robotics",
            "VLM"
        ]
    },
    {
        "id": "156",
        "title": "Hybrid Quantum-Classical Recurrent Neural Networks",
        "author": [
            "Wenduan Xu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25557",
        "abstract": "We present a hybrid quantum-classical recurrent neural network (QRNN) architecture in which the entire recurrent core is realized as a parametrized quantum circuit (PQC) controlled by a classical feedforward network. The hidden state is the quantum state of an $n$-qubit PQC, residing in an exponentially large Hilbert space $\\mathbb{C}^{2^n}$. The PQC is unitary by construction, making the hidden-state evolution norm-preserving without external constraints. At each timestep, mid-circuit readouts are combined with the input embedding and processed by the feedforward network, which provides explicit classical nonlinearity. The outputs parametrize the PQC, which updates the hidden state via unitary dynamics. The QRNN is compact and physically consistent, and it unifies (i) unitary recurrence as a high-capacity memory, (ii) partial observation via mid-circuit measurements, and (iii) nonlinear classical control for input-conditioned parametrization. We evaluate the model in simulation with up to 14 qubits on sentiment analysis, MNIST, permuted MNIST, copying memory, and language modeling, adopting projective measurements as a limiting case to obtain mid-circuit readouts while maintaining a coherent recurrent quantum memory. We further devise a soft attention mechanism over the mid-circuit readouts in a sequence-to-sequence model and show its effectiveness for machine translation. To our knowledge, this is the first model (RNN or otherwise) grounded in quantum operations to achieve competitive performance against strong classical baselines across a broad class of sequence-learning tasks.",
        "tags": [
            "RNN"
        ]
    },
    {
        "id": "157",
        "title": "Deep Reinforcement Learning-Based Cooperative Rate Splitting for Satellite-to-Underground Communication Networks",
        "author": [
            "Kaiqiang Lin",
            "Kangchun Zhao",
            "Yijie Mao"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25562",
        "abstract": "Reliable downlink communication in satellite-to-underground networks remains challenging due to severe signal attenuation caused by underground soil and refraction in the air-soil interface. To address this, we propose a novel cooperative rate-splitting (CRS)-aided transmission framework, where an aboveground relay decodes and forwards the common stream to underground devices (UDs). Based on this framework, we formulate a max-min fairness optimization problem that jointly optimizes power allocation, message splitting, and time slot scheduling to maximize the minimum achievable rate across UDs. To solve this high-dimensional non-convex problem under uncertain channels, we develop a deep reinforcement learning solution framework based on the proximal policy optimization (PPO) algorithm that integrates distribution-aware action modeling and a multi-branch actor network. Simulation results under a realistic underground pipeline monitoring scenario demonstrate that the proposed approach achieves average max-min rate gains exceeding $167\\%$ over conventional benchmark strategies across various numbers of UDs and underground conditions.",
        "tags": [
            "PPO",
            "RL"
        ]
    },
    {
        "id": "158",
        "title": "RegionE: Adaptive Region-Aware Generation for Efficient Image Editing",
        "author": [
            "Pengtao Chen",
            "Xianfang Zeng",
            "Maosen Zhao",
            "Mingzhu Shen",
            "Peng Ye",
            "Bangyin Xiang",
            "Zhibo Wang",
            "Wei Cheng",
            "Gang Yu",
            "Tao Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25590",
        "abstract": "Recently, instruction-based image editing (IIE) has received widespread attention. In practice, IIE often modifies only specific regions of an image, while the remaining areas largely remain unchanged. Although these two types of regions differ significantly in generation difficulty and computational redundancy, existing IIE models do not account for this distinction, instead applying a uniform generation process across the entire image. This motivates us to propose RegionE, an adaptive, region-aware generation framework that accelerates IIE tasks without additional training. Specifically, the RegionE framework consists of three main components: 1) Adaptive Region Partition. We observed that the trajectory of unedited regions is straight, allowing for multi-step denoised predictions to be inferred in a single step. Therefore, in the early denoising stages, we partition the image into edited and unedited regions based on the difference between the final estimated result and the reference image. 2) Region-Aware Generation. After distinguishing the regions, we replace multi-step denoising with one-step prediction for unedited areas. For edited regions, the trajectory is curved, requiring local iterative denoising. To improve the efficiency and quality of local iterative generation, we propose the Region-Instruction KV Cache, which reduces computational cost while incorporating global information. 3) Adaptive Velocity Decay Cache. Observing that adjacent timesteps in edited regions exhibit strong velocity similarity, we further propose an adaptive velocity decay cache to accelerate the local denoising process. We applied RegionE to state-of-the-art IIE base models, including Step1X-Edit, FLUX.1 Kontext, and Qwen-Image-Edit. RegionE achieved acceleration factors of 2.57, 2.41, and 2.06. Evaluations by GPT-4o confirmed that semantic and perceptual fidelity were well preserved.",
        "tags": [
            "FLUX",
            "GPT",
            "Image Editing",
            "Qwen"
        ]
    },
    {
        "id": "159",
        "title": "Communication and Verification in LLM Agents towards Collaboration under Information Asymmetry",
        "author": [
            "Run Peng",
            "Ziqiao Ma",
            "Amy Pang",
            "Sikai Li",
            "Zhang Xi-Jia",
            "Yingzhuo Yu",
            "Cristian-Paul Bara",
            "Joyce Chai"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25595",
        "abstract": "While Large Language Model (LLM) agents are often approached from the angle of action planning/generation to accomplish a goal (e.g., given by language descriptions), their abilities to collaborate with each other to achieve a joint goal are not well explored. To address this limitation, this paper studies LLM agents in task collaboration, particularly under the condition of information asymmetry, where agents have disparities in their knowledge and skills and need to work together to complete a shared task. We extend Einstein Puzzles, a classical symbolic puzzle, to a table-top game. In this game, two LLM agents must reason, communicate, and act to satisfy spatial and relational constraints required to solve the puzzle. We apply a fine-tuning-plus-verifier framework in which LLM agents are equipped with various communication strategies and verification signals from the environment. Empirical results highlight the critical importance of aligned communication, especially when agents possess both information-seeking and -providing capabilities. Interestingly, agents without communication can still achieve high task performance; however, further analysis reveals a lack of true rule understanding and lower trust from human evaluators. Instead, by integrating an environment-based verifier, we enhance agents' ability to comprehend task rules and complete tasks, promoting both safer and more interpretable collaboration in AI systems. https://github.com/Roihn/EinsteinPuzzles",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "160",
        "title": "INT v.s. FP: A Comprehensive Study of Fine-Grained Low-bit Quantization Formats",
        "author": [
            "Mengzhao Chen",
            "Meng Wu",
            "Hui Jin",
            "Zhihang Yuan",
            "Jing Liu",
            "Chaoyi Zhang",
            "Yunshui Li",
            "Jie Huang",
            "Jin Ma",
            "Zeyue Xue",
            "Zhiheng Liu",
            "Xingyan Bin",
            "Ping Luo"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25602",
        "abstract": "Modern AI hardware, such as Nvidia's Blackwell architecture, is increasingly embracing low-precision floating-point (FP) formats to handle the pervasive activation outliers in Large Language Models (LLMs). Despite this industry trend, a unified comparison of FP and integer (INT) quantization across varying granularities has been missing, leaving algorithm and hardware co-design without clear guidance. This paper fills that gap by systematically investigating the trade-offs between FP and INT formats. We reveal a critical performance crossover: while FP excels in coarse-grained quantization, the comparison at fine-grained (block-wise) levels is more nuanced. Our comprehensive comparison demonstrates that for popular 8-bit fine-grained formats (e.g., MX with block size 32), MXINT8 is superior to its FP counterpart in both algorithmic accuracy and hardware efficiency. However, for 4-bit formats, FP (e.g., MXFP4, NVFP4) often holds an accuracy advantage , though we show that NVINT4 can surpass NVFP4 when outlier-mitigation techniques like Hadamard rotation are applied. We also introduce a symmetric clipping method that resolves gradient bias in fine-grained low-bit INT training, enabling nearly lossless performance for MXINT8 training. These findings challenge the current hardware trajectory, demonstrating that a one-size-fits-all FP approach is suboptimal and advocating that fine-grained INT formats, particularly MXINT8, offer a better balance of accuracy, power, and efficiency for future AI accelerators.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "161",
        "title": "BOLT-GAN: Bayes-Optimal Loss for Stable GAN Training",
        "author": [
            "Mohammadreza Tavasoli Naeini",
            "Ali Bereyhi",
            "Morteza Noshad",
            "Ben Liang",
            "Alfred O. Hero III"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25609",
        "abstract": "We introduce BOLT-GAN, a simple yet effective modification of the WGAN framework inspired by the Bayes Optimal Learning Threshold (BOLT). We show that with a Lipschitz continuous discriminator, BOLT-GAN implicitly minimizes a different metric distance than the Earth Mover (Wasserstein) distance and achieves better training stability. Empirical evaluations on four standard image generation benchmarks (CIFAR-10, CelebA-64, LSUN Bedroom-64, and LSUN Church-64) show that BOLT-GAN consistently outperforms WGAN, achieving 10-60% lower Frechet Inception Distance (FID). Our results suggest that BOLT is a broadly applicable principle for enhancing GAN training.",
        "tags": [
            "GAN"
        ]
    },
    {
        "id": "162",
        "title": "Counterfactual-based Agent Influence Ranker for Agentic AI Workflows",
        "author": [
            "Amit Giloni",
            "Chiara Picardi",
            "Roy Betser",
            "Shamik Bose",
            "Aishvariya Priya Rathina Sabapathy",
            "Roman Vainshtein"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25612",
        "abstract": "An Agentic AI Workflow (AAW), also known as an LLM-based multi-agent system, is an autonomous system that assembles several LLM-based agents to work collaboratively towards a shared goal. The high autonomy, widespread adoption, and growing interest in such AAWs highlight the need for a deeper understanding of their operations, from both quality and security aspects. To this day, there are no existing methods to assess the influence of each agent on the AAW's final output. Adopting techniques from related fields is not feasible since existing methods perform only static structural analysis, which is unsuitable for inference time execution. We present Counterfactual-based Agent Influence Ranker (CAIR) - the first method for assessing the influence level of each agent on the AAW's output and determining which agents are the most influential. By performing counterfactual analysis, CAIR provides a task-agnostic analysis that can be used both offline and at inference time. We evaluate CAIR using an AAWs dataset of our creation, containing 30 different use cases with 230 different functionalities. Our evaluation showed that CAIR produces consistent rankings, outperforms baseline methods, and can easily enhance the effectiveness and relevancy of downstream tasks.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "163",
        "title": "Don't Blind Your VLA: Aligning Visual Representations for OOD Generalization",
        "author": [
            "Nikita Kachaev",
            "Mikhail Kolosov",
            "Daniil Zelezetsky",
            "Alexey K. Kovalev",
            "Aleksandr I. Panov"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25616",
        "abstract": "The growing success of Vision-Language-Action (VLA) models stems from the promise that pretrained Vision-Language Models (VLMs) can endow agents with transferable world knowledge and vision-language (VL) grounding, laying a foundation for action models with broader generalization. Yet when these VLMs are adapted to the action modality, it remains unclear to what extent their original VL representations and knowledge are preserved. In this work, we conduct a systematic study of representation retention during VLA fine-tuning, showing that naive action fine-tuning leads to degradation of visual representations. To characterize and measure these effects, we probe VLA's hidden representations and analyze attention maps, further, we design a set of targeted tasks and methods that contrast VLA models with their counterpart VLMs, isolating changes in VL capabilities induced by action fine-tuning. We further evaluate a range of strategies for aligning visual representations and introduce a simple yet effective method that mitigates degradation and yields improved generalization to out-of-distribution (OOD) scenarios. Taken together, our analysis clarifies the trade-off between action fine-tuning and the degradation of VL representations and highlights practical approaches to recover inherited VL capabilities. Code is publicly available: https://blind-vla-paper.github.io",
        "tags": [
            "VLM"
        ]
    },
    {
        "id": "164",
        "title": "FARSIQA: Faithful and Advanced RAG System for Islamic Question Answering",
        "author": [
            "Mohammad Aghajani Asl",
            "Behrooz Minaei Bidgoli"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25621",
        "abstract": "The advent of Large Language Models (LLMs) has revolutionized Natural Language Processing, yet their application in high-stakes, specialized domains like religious question answering is hindered by challenges like hallucination and unfaithfulness to authoritative sources. This issue is particularly critical for the Persian-speaking Muslim community, where accuracy and trustworthiness are paramount. Existing Retrieval-Augmented Generation (RAG) systems, relying on simplistic single-pass pipelines, fall short on complex, multi-hop queries requiring multi-step reasoning and evidence aggregation. To address this gap, we introduce FARSIQA, a novel, end-to-end system for Faithful Advanced Question Answering in the Persian Islamic domain. FARSIQA is built upon our innovative FAIR-RAG architecture: a Faithful, Adaptive, Iterative Refinement framework for RAG. FAIR-RAG employs a dynamic, self-correcting process: it adaptively decomposes complex queries, assesses evidence sufficiency, and enters an iterative loop to generate sub-queries, progressively filling information gaps. Operating on a curated knowledge base of over one million authoritative Islamic documents, FARSIQA demonstrates superior performance. Rigorous evaluation on the challenging IslamicPCQA benchmark shows state-of-the-art performance: the system achieves a remarkable 97.0% in Negative Rejection - a 40-point improvement over baselines - and a high Answer Correctness score of 74.3%. Our work establishes a new standard for Persian Islamic QA and validates that our iterative, adaptive architecture is crucial for building faithful, reliable AI systems in sensitive domains.",
        "tags": [
            "LLM",
            "RAG"
        ]
    },
    {
        "id": "165",
        "title": "Evaluating the Role of Verifiers in Test-Time Scaling for Legal Reasoning Tasks",
        "author": [
            "Davide Romano",
            "Jonathan Schwarz",
            "Daniele GiofrÃ©"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25623",
        "abstract": "Test-time scaling (TTS) techniques can improve the performance of large language models (LLMs) at the expense of additional computation and latency. While TTS has proven effective in formal domains such as mathematics and programming \\citep{snell2024scaling, chen2024more}, its value in argumentative domains such as law remains underexplored. We present an empirical study of verifier-based TTS methods for legal multiple-choice QA (MCQA) across five benchmarks. Using a family of 7 reward models, we evaluate both outcome-level (Best-of-$N$) and process-level (tree search) verification under realistic low-$N$ budgets. Our analysis systematically investigates how verifier utility is affected by key properties such as domain specialization, model size, and supervision type (process-supervised PRMs vs. outcome-only ORMs), even when applied across different roles.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "166",
        "title": "EHR-R1: A Reasoning-Enhanced Foundational Language Model for Electronic Health Record Analysis",
        "author": [
            "Yusheng Liao",
            "Chaoyi Wu",
            "Junwei Liu",
            "Shuyang Jiang",
            "Pengcheng Qiu",
            "Haowen Wang",
            "Yun Yue",
            "Shuai Zhen",
            "Jian Wang",
            "Qianrui Fan",
            "Jinjie Gu",
            "Ya Zhang",
            "Yanfeng Wang",
            "Yu Wang",
            "Weidi Xie"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25628",
        "abstract": "Electronic Health Records (EHRs) contain rich yet complex information, and their automated analysis is critical for clinical decision-making. Despite recent advances of large language models (LLMs) in clinical workflows, their ability to analyze EHRs remains limited due to narrow task coverage and lack of EHR-oriented reasoning capabilities. This paper aims to bridge the gap, specifically, we present EHR-Ins, a large-scale, comprehensive EHR reasoning instruction dataset, comprising 300k high-quality reasoning cases and 4M non-reasoning cases across 42 distinct EHR tasks. Its core innovation is a thinking-graph-driven framework that enables to generate high-quality reasoning data at scale. Based on it, we develop EHR-R1, a series of reasoning-enhanced LLMs with up to 72B parameters tailored for EHR analysis. Through a multi-stage training paradigm, including domain adaptation, reasoning enhancement, and reinforcement learning, EHR-R1 systematically acquires domain knowledge and diverse reasoning capabilities, enabling accurate and robust EHR analysis. Lastly, we introduce EHR-Bench, a new benchmark curated from MIMIC-IV, spanning 42 tasks, to comprehensively assess reasoning and prediction across EHR scenarios. In experiments, we show that the resulting EHR-R1 consistently outperforms state-of-the-art commercial and open-source LLMs (including DeepSeek-V3 and GPT-4o), surpassing GPT-4o by over 30 points on MIMIC-Bench and achieving a 10\\% higher zero-shot AUROC on EHRSHOT. Collectively, EHR-Ins, EHR-R1, and EHR-Bench have significantly advanced the development for more reliable and clinically relevant EHR analysis.",
        "tags": [
            "DeepSeek",
            "GPT",
            "LLM",
            "RL"
        ]
    },
    {
        "id": "167",
        "title": "Learning to Plan & Schedule with Reinforcement-Learned Bimanual Robot Skills",
        "author": [
            "Weikang Wan",
            "Fabio Ramos",
            "Xuning Yang",
            "Caelan Garrett"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25634",
        "abstract": "Long-horizon contact-rich bimanual manipulation presents a significant challenge, requiring complex coordination involving a mixture of parallel execution and sequential collaboration between arms. In this paper, we introduce a hierarchical framework that frames this challenge as an integrated skill planning & scheduling problem, going beyond purely sequential decision-making to support simultaneous skill invocation. Our approach is built upon a library of single-arm and bimanual primitive skills, each trained using Reinforcement Learning (RL) in GPU-accelerated simulation. We then train a Transformer-based planner on a dataset of skill compositions to act as a high-level scheduler, simultaneously predicting the discrete schedule of skills as well as their continuous parameters. We demonstrate that our method achieves higher success rates on complex, contact-rich tasks than end-to-end RL approaches and produces more efficient, coordinated behaviors than traditional sequential-only planners.",
        "tags": [
            "RL",
            "Robotics",
            "Transformer"
        ]
    },
    {
        "id": "168",
        "title": "User Misconceptions of LLM-Based Conversational Programming Assistants",
        "author": [
            "Gabrielle O'Brien",
            "Antonio Pedro Santos Alves",
            "Sebastian Baltes",
            "Grischa Liebel",
            "Mircea Lungu",
            "Marcos Kalinowski"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25662",
        "abstract": "Programming assistants powered by large language models (LLMs) have become widely available, with conversational assistants like ChatGPT proving particularly accessible to less experienced programmers. However, the varied capabilities of these tools across model versions and the mixed availability of extensions that enable web search, code execution, or retrieval-augmented generation create opportunities for user misconceptions about what systems can and cannot do. Such misconceptions may lead to over-reliance, unproductive practices, or insufficient quality control in LLM-assisted programming. Here, we aim to characterize misconceptions that users of conversational LLM-based assistants may have in programming contexts. Using a two-phase approach, we first brainstorm and catalog user misconceptions that may occur, and then conduct a qualitative analysis to examine whether these conceptual issues surface in naturalistic Python-programming conversations with an LLM-based chatbot drawn from an openly available dataset. Indeed, we see evidence that some users have misplaced expectations about the availability of LLM-based chatbot features like web access, code execution, or non-text output generation. We also see potential evidence for deeper conceptual issues around the scope of information required to debug, validate, and optimize programs. Our findings reinforce the need for designing LLM-based tools that more clearly communicate their programming capabilities to users.",
        "tags": [
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "169",
        "title": "ALDEN: Reinforcement Learning for Active Navigation and Evidence Gathering in Long Documents",
        "author": [
            "Tianyu Yang",
            "Terry Ruas",
            "Yijun Tian",
            "Jan Philip Wahle",
            "Daniel Kurzawe",
            "Bela Gipp"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25668",
        "abstract": "Vision-language models (VLMs) excel at interpreting text-rich images but struggle with long, visually complex documents that demand analysis and integration of information spread across multiple pages. Existing approaches typically rely on fixed reasoning templates or rigid pipelines, which force VLMs into a passive role and hinder both efficiency and generalization. We present Active Long-DocumEnt Navigation (ALDEN), a multi-turn reinforcement learning framework that fine-tunes VLMs as interactive agents capable of actively navigating long, visually rich documents. ALDEN introduces a novel fetch action that directly accesses the page by index, complementing the classic search action and better exploiting document structure. For dense process supervision and efficient training, we propose a rule-based cross-level reward that provides both turn- and token-level signals. To address the empirically observed training instability caused by numerous visual tokens from long documents, we further propose a visual-semantic anchoring mechanism that applies a dual-path KL-divergence constraint to stabilize visual and textual representations separately during training. Trained on a corpus constructed from three open-source datasets, ALDEN achieves state-of-the-art performance on five long-document benchmarks. Overall, ALDEN marks a step beyond passive document reading toward agents that autonomously navigate and reason across long, visually rich documents, offering a robust path to more accurate and efficient long-document understanding.",
        "tags": [
            "RL",
            "VLM"
        ]
    },
    {
        "id": "170",
        "title": "Navigation in a Three-Dimensional Urban Flow using Deep Reinforcement Learning",
        "author": [
            "Federica Tonti",
            "Ricardo Vinuesa"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25679",
        "abstract": "Unmanned Aerial Vehicles (UAVs) are increasingly populating urban areas for delivery and surveillance purposes. In this work, we develop an optimal navigation strategy based on Deep Reinforcement Learning. The environment is represented by a three-dimensional high-fidelity simulation of an urban flow, characterized by turbulence and recirculation zones. The algorithm presented here is a flow-aware Proximal Policy Optimization (PPO) combined with a Gated Transformer eXtra Large (GTrXL) architecture, giving the agent richer information about the turbulent flow field in which it navigates. The results are compared with a PPO+GTrXL without the secondary prediction tasks, a PPO combined with Long Short Term Memory (LSTM) cells and a traditional navigation algorithm. The obtained results show a significant increase in the success rate (SR) and a lower crash rate (CR) compared to a PPO+LSTM, PPO+GTrXL and the classical Zermelo's navigation algorithm, paving the way to a completely reimagined UAV landscape in complex urban environments.",
        "tags": [
            "PPO",
            "RL",
            "Transformer"
        ]
    },
    {
        "id": "171",
        "title": "PairUni: Pairwise Training for Unified Multimodal Language Models",
        "author": [
            "Jiani Zheng",
            "Zhiyang Teng",
            "Xiangtai Li",
            "Anran Wang",
            "Yu Tian",
            "Kunpeng Qiu",
            "Ye Tian",
            "Haochen Wang",
            "Zhuochen Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25682",
        "abstract": "Unified vision-language models (UVLMs) must perform both understanding and generation within a single architecture, but these tasks rely on heterogeneous data and supervision, making it difficult to balance them during reinforcement learning (RL). We propose PairUni, a unified framework that reorganizes data into understanding-generation (UG) pairs and aligns optimization accordingly. We first use GPT-o3 to augment single-task data, generating captions for understanding samples and question-answer (QA) pairs for generation samples, forming aligned pairs from the same instance. Additionally, for each generation sample, we retrieve a semantically related understanding example to form a retrieved pair, linking different but related data points. These paired structures expose cross-task semantic correspondences and support consistent policy learning. To leverage this structure, we present Pair-GPRO, a pair-aware variant based on Group Relative Policy Optimization. It assigns a similarity score to each pair to modulate the advantage, strengthening learning from well-aligned examples and reducing task interference. We curate a high-quality dataset of 16K UG pairs named PairUG for RL fine-tuning and evaluate PairUni on the powerful Janus-Pro UVLMs. Our approach achieves balanced improvements on various UVLMs, outperforming strong UVLM RL baselines. Code: \\href{https://github.com/Haochen-Wang409/PairUni}{http://github.com/Haochen-Wang409/PairUni}",
        "tags": [
            "GPT",
            "RL",
            "VLM"
        ]
    },
    {
        "id": "172",
        "title": "Process-Level Trajectory Evaluation for Environment Configuration in Software Engineering Agents",
        "author": [
            "Jiayi Kuang",
            "Yinghui Li",
            "Xin Zhang",
            "Yangning Li",
            "Di Yin",
            "Xing Sun",
            "Ying Shen",
            "Philip S. Yu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25694",
        "abstract": "Large language model-based agents show promise for software engineering, but environment configuration remains a bottleneck due to heavy manual effort and scarce large-scale, high-quality datasets. Existing benchmarks assess only end-to-end build/test success, obscuring where and why agents succeed or fail. We introduce the Environment Configuration Diagnosis Benchmark, Enconda-bench, which provides process-level trajectory assessment of fine-grained agent capabilities during environment setup-planning, perception-driven error diagnosis, feedback-driven repair, and action to execute final environment configuration. Our task instances are automatically constructed by injecting realistic README errors and are validated in Docker for scalable, high-quality evaluation. Enconda-bench combines process-level analysis with end-to-end executability to enable capability assessments beyond aggregate success rates. Evaluations across state-of-the-art LLMs and agent frameworks show that while agents can localize errors, they struggle to translate feedback into effective corrections, limiting end-to-end performance. To our knowledge, Enconda-bench is the first framework to provide process-level internal capability assessment for environment configuration, offering actionable insights for improving software engineering agents.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "173",
        "title": "MetaLore: Learning to Orchestrate Communication and Computation for Metaverse Synchronization",
        "author": [
            "Elif Ebru Ohri",
            "Qi Liao",
            "Anastasios Giovanidis",
            "Francesca Fossati",
            "Nour-El-Houda Yellas"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25705",
        "abstract": "As augmented and virtual reality evolve, achieving seamless synchronization between physical and digital realms remains a critical challenge, especially for real-time applications where delays affect the user experience. This paper presents MetaLore, a Deep Reinforcement Learning (DRL) based framework for joint communication and computational resource allocation in Metaverse or digital twin environments. MetaLore dynamically shares the communication bandwidth and computational resources among sensors and mobile devices to optimize synchronization, while offering high throughput performance. Special treatment is given in satisfying end-to-end delay guarantees. A key contribution is the introduction of two novel Age of Information (AoI) metrics: Age of Request Information (AoRI) and Age of Sensor Information (AoSI), integrated into the reward function to enhance synchronization quality. An open source simulator has been extended to incorporate and evaluate the approach. The DRL solution is shown to achieve the performance of full-enumeration brute-force solutions by making use of a small, task-oriented observation space of two queue lengths at the network side. This allows the DRL approach the flexibility to effectively and autonomously adapt to dynamic traffic conditions.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "174",
        "title": "Robotic Assistant: Completing Collaborative Tasks with Dexterous Vision-Language-Action Models",
        "author": [
            "Boshi An",
            "Chenyu Yang",
            "Robert Katzschmann"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25713",
        "abstract": "We adapt a pre-trained Vision-Language-Action (VLA) model (Open-VLA) for dexterous human-robot collaboration with minimal language prompting. Our approach adds (i) FiLM conditioning to visual backbones for task-aware perception, (ii) an auxiliary intent head that predicts collaborator hand pose and target cues, and (iii) action-space post-processing that predicts compact deltas (position/rotation) and PCA-reduced finger joints before mapping to full commands. Using a multi-view, teleoperated Franka and Mimic-hand dataset augmented with MediaPipe hand poses, we demonstrate that delta actions are well-behaved and that four principal components explain ~96% of hand-joint variance. Ablations identify action post-processing as the primary performance driver; auxiliary intent helps, FiLM is mixed, and a directional motion loss is detrimental. A real-time stack (~0.3 s latency on one RTX 4090) composes \"pick-up\" and \"pass\" into a long-horizon behavior. We surface \"trainer overfitting\" to specific demonstrators as the key limitation.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "175",
        "title": "Retrieval-Augmented Search for Large-Scale Map Collections with ColPali",
        "author": [
            "Jamie Mahowald",
            "Benjamin Charles Germain Lee"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25718",
        "abstract": "Multimodal approaches have shown great promise for searching and navigating digital collections held by libraries, archives, and museums. In this paper, we introduce map-RAS: a retrieval-augmented search system for historic maps. In addition to introducing our framework, we detail our publicly-hosted demo for searching 101,233 map images held by the Library of Congress. With our system, users can multimodally query the map collection via ColPali, summarize search results using Llama 3.2, and upload their own collections to perform inter-collection search. We articulate potential use cases for archivists, curators, and end-users, as well as future work with our system in both machine learning and the digital humanities. Our demo can be viewed at: http://www.mapras.com.",
        "tags": [
            "LLaMA"
        ]
    },
    {
        "id": "176",
        "title": "BambooKG: A Neurobiologically-inspired Frequency-Weight Knowledge Graph",
        "author": [
            "Vanya Arikutharam",
            "Arkadiy Ukolov"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25724",
        "abstract": "Retrieval-Augmented Generation allows LLMs to access external knowledge, reducing hallucinations and ageing-data issues. However, it treats retrieved chunks independently and struggles with multi-hop or relational reasoning, especially across documents. Knowledge graphs enhance this by capturing the relationships between entities using triplets, enabling structured, multi-chunk reasoning. However, these tend to miss information that fails to conform to the triplet structure. We introduce BambooKG, a knowledge graph with frequency-based weights on non-triplet edges which reflect link strength, drawing on the Hebbian principle of \"fire together, wire together\". This decreases information loss and results in improved performance on single- and multi-hop reasoning, outperforming the existing solutions.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "177",
        "title": "A Humanoid Visual-Tactile-Action Dataset for Contact-Rich Manipulation",
        "author": [
            "Eunju Kwon",
            "Seungwon Oh",
            "In-Chang Baek",
            "Yucheon Park",
            "Gyungbo Kim",
            "JaeYoung Moon",
            "Yunho Choi",
            "Kyung-Joong Kim"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25725",
        "abstract": "Contact-rich manipulation has become increasingly important in robot learning. However, previous studies on robot learning datasets have focused on rigid objects and underrepresented the diversity of pressure conditions for real-world manipulation. To address this gap, we present a humanoid visual-tactile-action dataset designed for manipulating deformable soft objects. The dataset was collected via teleoperation using a humanoid robot equipped with dexterous hands, capturing multi-modal interactions under varying pressure conditions. This work also motivates future research on models with advanced optimization strategies capable of effectively leveraging the complexity and diversity of tactile signals.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "178",
        "title": "The Tool Decathlon: Benchmarking Language Agents for Diverse, Realistic, and Long-Horizon Task Execution",
        "author": [
            "Junlong Li",
            "Wenshuo Zhao",
            "Jian Zhao",
            "Weihao Zeng",
            "Haoze Wu",
            "Xiaochen Wang",
            "Rui Ge",
            "Yuxuan Cao",
            "Yuzhen Huang",
            "Wei Liu",
            "Junteng Liu",
            "Zhaochen Su",
            "Yiyang Guo",
            "Fan Zhou",
            "Lueyang Zhang",
            "Juan Michelini",
            "Xingyao Wang",
            "Xiang Yue",
            "Shuyan Zhou",
            "Graham Neubig",
            "Junxian He"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25726",
        "abstract": "Real-world language agents must handle complex, multi-step workflows across diverse Apps. For instance, an agent may manage emails by coordinating with calendars and file systems, or monitor a production database to detect anomalies and generate reports following an operating manual. However, existing language agent benchmarks often focus on narrow domains or simplified tasks that lack the diversity, realism, and long-horizon complexity required to evaluate agents' real-world performance. To address this gap, we introduce the Tool Decathlon (dubbed as Toolathlon), a benchmark for language agents offering diverse Apps and tools, realistic environment setup, and reliable execution-based evaluation. Toolathlon spans 32 software applications and 604 tools, ranging from everyday platforms such as Google Calendar and Notion to professional ones like WooCommerce, Kubernetes, and BigQuery. Most of the tools are based on a high-quality set of Model Context Protocol (MCP) servers that we may have revised or implemented ourselves. Unlike prior works, which primarily ensure functional realism but offer limited environment state diversity, we provide realistic initial environment states from real software, such as Canvas courses with dozens of students or real financial spreadsheets. This benchmark includes 108 manually sourced or crafted tasks in total, requiring interacting with multiple Apps over around 20 turns on average to complete. Each task is strictly verifiable through dedicated evaluation scripts. Comprehensive evaluation of SOTA models highlights their significant shortcomings: the best-performing model, Claude-4.5-Sonnet, achieves only a 38.6% success rate with 20.2 tool calling turns on average, while the top open-weights model DeepSeek-V3.2-Exp reaches 20.1%. We expect Toolathlon to drive the development of more capable language agents for real-world, long-horizon task execution.",
        "tags": [
            "DeepSeek"
        ]
    },
    {
        "id": "179",
        "title": "Modeling Collapse of Steered Vine Robots Under Their Own Weight",
        "author": [
            "Ciera McFarland",
            "Margaret McGuinness"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25727",
        "abstract": "Soft, vine-inspired growing robots that move by eversion are highly mobile in confined environments, but, when faced with gaps in the environment, they may collapse under their own weight while navigating a desired path. In this work, we present a comprehensive collapse model that can predict the collapse length of steered robots in any shape using true shape information and tail tension. We validate this model by collapsing several unsteered robots without true shape information. The model accurately predicts the trends of those experiments. We then attempt to collapse a robot steered with a single actuator at different orientations. Our models accurately predict collapse when it occurs. Finally, we demonstrate how this could be used in the field by having a robot attempt a gap-crossing task with and without inflating its actuators. The robot needs its actuators inflated to cross the gap without collapsing, which our model supports. Our model has been specifically tested on straight and series pouch motor-actuated robots made of non-stretchable material, but it could be applied to other robot variations. This work enables us to model the robot's collapse behavior in any open environment and understand the parameters it needs to succeed in 3D navigation tasks.",
        "tags": [
            "3D",
            "Robotics"
        ]
    },
    {
        "id": "180",
        "title": "The Limits of Obliviate: Evaluating Unlearning in LLMs via Stimulus-Knowledge Entanglement-Behavior Framework",
        "author": [
            "Aakriti Shah",
            "Thai Le"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25732",
        "abstract": "Unlearning in large language models (LLMs) is crucial for managing sensitive data and correcting misinformation, yet evaluating its effectiveness remains an open problem. We investigate whether persuasive prompting can recall factual knowledge from deliberately unlearned LLMs across models ranging from 2.7B to 13B parameters (OPT-2.7B, LLaMA-2-7B, LLaMA-3.1-8B, LLaMA-2-13B). Drawing from ACT-R and Hebbian theory (spreading activation theories), as well as communication principles, we introduce Stimulus-Knowledge Entanglement-Behavior Framework (SKeB), which models information entanglement via domain graphs and tests whether factual recall in unlearned models is correlated with persuasive framing. We develop entanglement metrics to quantify knowledge activation patterns and evaluate factuality, non-factuality, and hallucination in outputs. Our results show persuasive prompts substantially enhance factual knowledge recall (14.8% baseline vs. 24.5% with authority framing), with effectiveness inversely correlated to model size (128% recovery in 2.7B vs. 15% in 13B). SKeB provides a foundation for assessing unlearning completeness, robustness, and overall behavior in LLMs.",
        "tags": [
            "LLM",
            "LLaMA"
        ]
    },
    {
        "id": "181",
        "title": "Hawk: Leveraging Spatial Context for Faster Autoregressive Text-to-Image Generation",
        "author": [
            "Zhi-Kai Chen",
            "Jun-Peng Jiang",
            "Han-Jia Ye",
            "De-Chuan Zhan"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25739",
        "abstract": "Autoregressive (AR) image generation models are capable of producing high-fidelity images but often suffer from slow inference due to their inherently sequential, token-by-token decoding process. Speculative decoding, which employs a lightweight draft model to approximate the output of a larger AR model, has shown promise in accelerating text generation without compromising quality. However, its application to image generation remains largely underexplored. The challenges stem from a significantly larger sampling space, which complicates the alignment between the draft and target model outputs, coupled with the inadequate use of the two-dimensional spatial structure inherent in images, thereby limiting the modeling of local dependencies. To overcome these challenges, we introduce Hawk, a new approach that harnesses the spatial structure of images to guide the speculative model toward more accurate and efficient predictions. Experimental results on multiple text-to-image benchmarks demonstrate a 1.71x speedup over standard AR models, while preserving both image fidelity and diversity.",
        "tags": [
            "Text-to-Image"
        ]
    },
    {
        "id": "182",
        "title": "Scaling Latent Reasoning via Looped Language Models",
        "author": [
            "Rui-Jie Zhu",
            "Zixuan Wang",
            "Kai Hua",
            "Tianyu Zhang",
            "Ziniu Li",
            "Haoran Que",
            "Boyi Wei",
            "Zixin Wen",
            "Fan Yin",
            "He Xing",
            "Lu Li",
            "Jiajun Shi",
            "Kaijing Ma",
            "Shanda Li",
            "Taylor Kergan",
            "Andrew Smith",
            "Xingwei Qu",
            "Mude Hui",
            "Bohong Wu",
            "Qiyang Min",
            "Hongzhi Huang",
            "Xun Zhou",
            "Wei Ye",
            "Jiaheng Liu",
            "Jian Yang",
            "Yunfeng Shi",
            "Chenghua Lin",
            "Enduo Zhao",
            "Tianle Cai",
            "Ge Zhang",
            "Wenhao Huang",
            "Yoshua Bengio",
            "Jason Eshraghian"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25741",
        "abstract": "Modern LLMs are trained to \"think\" primarily via explicit text generation, such as chain-of-thought (CoT), which defers reasoning to post-training and under-leverages pre-training data. We present and open-source Ouro, named after the recursive Ouroboros, a family of pre-trained Looped Language Models (LoopLM) that instead build reasoning into the pre-training phase through (i) iterative computation in latent space, (ii) an entropy-regularized objective for learned depth allocation, and (iii) scaling to 7.7T tokens. Ouro 1.4B and 2.6B models enjoy superior performance that match the results of up to 12B SOTA LLMs across a wide range of benchmarks. Through controlled experiments, we show this advantage stems not from increased knowledge capacity, but from superior knowledge manipulation capabilities. We also show that LoopLM yields reasoning traces more aligned with final outputs than explicit CoT. We hope our results show the potential of LoopLM as a novel scaling direction in the reasoning era. Our model could be found in: http://ouro-llm.github.io.",
        "tags": [
            "CoT",
            "LLM"
        ]
    },
    {
        "id": "183",
        "title": "GET-USE: Learning Generalized Tool Usage for Bimanual Mobile Manipulation via Simulated Embodiment Extensions",
        "author": [
            "Bohan Wu",
            "Paul de La Sayette",
            "Li Fei-Fei",
            "Roberto MartÃ­n-MartÃ­n"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25754",
        "abstract": "The ability to use random objects as tools in a generalizable manner is a missing piece in robots' intelligence today to boost their versatility and problem-solving capabilities. State-of-the-art robotic tool usage methods focused on procedurally generating or crowd-sourcing datasets of tools for a task to learn how to grasp and manipulate them for that task. However, these methods assume that only one object is provided and that it is possible, with the correct grasp, to perform the task; they are not capable of identifying, grasping, and using the best object for a task when many are available, especially when the optimal tool is absent. In this work, we propose GeT-USE, a two-step procedure that learns to perform real-robot generalized tool usage by learning first to extend the robot's embodiment in simulation and then transferring the learned strategies to real-robot visuomotor policies. Our key insight is that by exploring a robot's embodiment extensions (i.e., building new end-effectors) in simulation, the robot can identify the general tool geometries most beneficial for a task. This learned geometric knowledge can then be distilled to perform generalized tool usage tasks by selecting and using the best available real-world object as tool. On a real robot with 22 degrees of freedom (DOFs), GeT-USE outperforms state-of-the-art methods by 30-60% success rates across three vision-based bimanual mobile manipulation tool-usage tasks.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "184",
        "title": "TheraMind: A Strategic and Adaptive Agent for Longitudinal Psychological Counseling",
        "author": [
            "He Hu",
            "Yucheng Zhou",
            "Chiyuan Ma",
            "Qianning Wang",
            "Zheng Zhang",
            "Fei Ma",
            "Laizhong Cui",
            "Qi Tian"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25758",
        "abstract": "Large language models (LLMs) in psychological counseling have attracted increasing attention. However, existing approaches often lack emotional understanding, adaptive strategies, and the use of therapeutic methods across multiple sessions with long-term memory, leaving them far from real clinical practice. To address these critical gaps, we introduce TheraMind, a strategic and adaptive agent for longitudinal psychological counseling. The cornerstone of TheraMind is a novel dual-loop architecture that decouples the complex counseling process into an Intra-Session Loop for tactical dialogue management and a Cross-Session Loop for strategic therapeutic planning. The Intra-Session Loop perceives the patient's emotional state to dynamically select response strategies while leveraging cross-session memory to ensure continuity. Crucially, the Cross-Session Loop empowers the agent with long-term adaptability by evaluating the efficacy of the applied therapy after each session and adjusting the method for subsequent interactions. We validate our approach in a high-fidelity simulation environment grounded in real clinical cases. Extensive evaluations show that TheraMind outperforms other methods, especially on multi-session metrics like Coherence, Flexibility, and Therapeutic Attunement, validating the effectiveness of its dual-loop design in emulating strategic, adaptive, and longitudinal therapeutic behavior. The code is publicly available at https://0mwwm0.github.io/TheraMind/.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "185",
        "title": "Multimodal Spatial Reasoning in the Large Model Era: A Survey and Benchmarks",
        "author": [
            "Xu Zheng",
            "Zihao Dongfang",
            "Lutao Jiang",
            "Boyuan Zheng",
            "Yulong Guo",
            "Zhenquan Zhang",
            "Giuliano Albanese",
            "Runyi Yang",
            "Mengjiao Ma",
            "Zixin Zhang",
            "Chenfei Liao",
            "Dingcheng Zhen",
            "Yuanhuiyi Lyu",
            "Yuqian Fu",
            "Bin Ren",
            "Linfeng Zhang",
            "Danda Pani Paudel",
            "Nicu Sebe",
            "Luc Van Gool",
            "Xuming Hu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25760",
        "abstract": "Humans possess spatial reasoning abilities that enable them to understand spaces through multimodal observations, such as vision and sound. Large multimodal reasoning models extend these abilities by learning to perceive and reason, showing promising performance across diverse spatial tasks. However, systematic reviews and publicly available benchmarks for these models remain limited. In this survey, we provide a comprehensive review of multimodal spatial reasoning tasks with large models, categorizing recent progress in multimodal large language models (MLLMs) and introducing open benchmarks for evaluation. We begin by outlining general spatial reasoning, focusing on post-training techniques, explainability, and architecture. Beyond classical 2D tasks, we examine spatial relationship reasoning, scene and layout understanding, as well as visual question answering and grounding in 3D space. We also review advances in embodied AI, including vision-language navigation and action models. Additionally, we consider emerging modalities such as audio and egocentric video, which contribute to novel spatial understanding through new sensors. We believe this survey establishes a solid foundation and offers insights into the growing field of multimodal spatial reasoning. Updated information about this survey, codes and implementation of the open benchmarks can be found at https://github.com/zhengxuJosh/Awesome-Spatial-Reasoning.",
        "tags": [
            "3D",
            "LLM"
        ]
    },
    {
        "id": "186",
        "title": "DiagramEval: Evaluating LLM-Generated Diagrams via Graphs",
        "author": [
            "Chumeng Liang",
            "Jiaxuan You"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25761",
        "abstract": "Diagrams play a central role in research papers for conveying ideas, yet they are often notoriously complex and labor-intensive to create. Although diagrams are presented as images, standard image generative models struggle to produce clear diagrams with well-defined structure. We argue that a promising direction is to generate demonstration diagrams directly in textual form as SVGs, which can leverage recent advances in large language models (LLMs). However, due to the complexity of components and the multimodal nature of diagrams, sufficiently discriminative and explainable metrics for evaluating the quality of LLM-generated diagrams remain lacking. In this paper, we propose DiagramEval, a novel evaluation metric designed to assess demonstration diagrams generated by LLMs. Specifically, DiagramEval conceptualizes diagrams as graphs, treating text elements as nodes and their connections as directed edges, and evaluates diagram quality using two new groups of metrics: node alignment and path alignment. For the first time, we effectively evaluate diagrams produced by state-of-the-art LLMs on recent research literature, quantitatively demonstrating the validity of our metrics. Furthermore, we show how the enhanced explainability of our proposed metrics offers valuable insights into the characteristics of LLM-generated diagrams. Code: https://github.com/ulab-uiuc/diagram-eval.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "187",
        "title": "FreeArt3D: Training-Free Articulated Object Generation using 3D Diffusion",
        "author": [
            "Chuhao Chen",
            "Isabella Liu",
            "Xinyue Wei",
            "Hao Su",
            "Minghua Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25765",
        "abstract": "Articulated 3D objects are central to many applications in robotics, AR/VR, and animation. Recent approaches to modeling such objects either rely on optimization-based reconstruction pipelines that require dense-view supervision or on feed-forward generative models that produce coarse geometric approximations and often overlook surface texture. In contrast, open-world 3D generation of static objects has achieved remarkable success, especially with the advent of native 3D diffusion models such as Trellis. However, extending these methods to articulated objects by training native 3D diffusion models poses significant challenges. In this work, we present FreeArt3D, a training-free framework for articulated 3D object generation. Instead of training a new model on limited articulated data, FreeArt3D repurposes a pre-trained static 3D diffusion model (e.g., Trellis) as a powerful shape prior. It extends Score Distillation Sampling (SDS) into the 3D-to-4D domain by treating articulation as an additional generative dimension. Given a few images captured in different articulation states, FreeArt3D jointly optimizes the object's geometry, texture, and articulation parameters without requiring task-specific training or access to large-scale articulated datasets. Our method generates high-fidelity geometry and textures, accurately predicts underlying kinematic structures, and generalizes well across diverse object categories. Despite following a per-instance optimization paradigm, FreeArt3D completes in minutes and significantly outperforms prior state-of-the-art approaches in both quality and versatility.",
        "tags": [
            "3D",
            "Diffusion",
            "Robotics"
        ]
    },
    {
        "id": "188",
        "title": "Decomposition-Enhanced Training for Post-Hoc Attributions In Language Models",
        "author": [
            "Sriram Balasubramaniam",
            "Samyadeep Basu",
            "Koustava Goswami",
            "Ryan Rossi",
            "Varun Manjunatha",
            "Roshan Santhosh",
            "Ruiyi Zhang",
            "Soheil Feizi",
            "Nedim Lipka"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25766",
        "abstract": "Large language models (LLMs) are increasingly used for long-document question answering, where reliable attribution to sources is critical for trust. Existing post-hoc attribution methods work well for extractive QA but struggle in multi-hop, abstractive, and semi-extractive settings, where answers synthesize information across passages. To address these challenges, we argue that post-hoc attribution can be reframed as a reasoning problem, where answers are decomposed into constituent units, each tied to specific context. We first show that prompting models to generate such decompositions alongside attributions improves performance. Building on this, we introduce DecompTune, a post-training method that teaches models to produce answer decompositions as intermediate reasoning steps. We curate a diverse dataset of complex QA tasks, annotated with decompositions by a strong LLM, and post-train Qwen-2.5 (7B and 14B) using a two-stage SFT + GRPO pipeline with task-specific curated rewards. Across extensive experiments and ablations, DecompTune substantially improves attribution quality, outperforming prior methods and matching or exceeding state-of-the-art frontier models.",
        "tags": [
            "GRPO",
            "LLM",
            "Qwen"
        ]
    },
    {
        "id": "189",
        "title": "VFXMaster: Unlocking Dynamic Visual Effect Generation via In-Context Learning",
        "author": [
            "Baolu Li",
            "Yiming Zhang",
            "Qinghe Wang",
            "Liqian Ma",
            "Xiaoyu Shi",
            "Xintao Wang",
            "Pengfei Wan",
            "Zhenfei Yin",
            "Yunzhi Zhuge",
            "Huchuan Lu",
            "Xu Jia"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25772",
        "abstract": "Visual effects (VFX) are crucial to the expressive power of digital media, yet their creation remains a major challenge for generative AI. Prevailing methods often rely on the one-LoRA-per-effect paradigm, which is resource-intensive and fundamentally incapable of generalizing to unseen effects, thus limiting scalability and creation. To address this challenge, we introduce VFXMaster, the first unified, reference-based framework for VFX video generation. It recasts effect generation as an in-context learning task, enabling it to reproduce diverse dynamic effects from a reference video onto target content. In addition, it demonstrates remarkable generalization to unseen effect categories. Specifically, we design an in-context conditioning strategy that prompts the model with a reference example. An in-context attention mask is designed to precisely decouple and inject the essential effect attributes, allowing a single unified model to master the effect imitation without information leakage. In addition, we propose an efficient one-shot effect adaptation mechanism to boost generalization capability on tough unseen effects from a single user-provided video rapidly. Extensive experiments demonstrate that our method effectively imitates various categories of effect information and exhibits outstanding generalization to out-of-domain effects. To foster future research, we will release our code, models, and a comprehensive dataset to the community.",
        "tags": [
            "LoRA",
            "Video Generation"
        ]
    },
    {
        "id": "190",
        "title": "Modelling Real-Life Cycling Decisions in Real Urban Settings Through Psychophysiology and LLM-Derived Contextual Data",
        "author": [
            "Maximiliano Rosadio Z.",
            "Angel Jimenez-Molina",
            "BastiÃ¡n HenrÃ­quez",
            "Paulina Leiva",
            "Ricardo Hurtubia",
            "Ricardo De La Paz Guala",
            "Leandro Gayozo",
            "C. Angelo Guevara"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24726",
        "abstract": "Measuring emotional states in transportation contexts is an emerging field. Methods based on self-reported emotions are limited by their low granularity and their susceptibility to memory bias. In contrast, methods based on physiological indicators provide continuous data, enabling researchers to measure changes in emotional states with high detail and accuracy. Not only are emotions important in the analysis, but understanding what triggers emotional changes is equally important. Uncontrolled variables such as traffic conditions, pedestrian interactions, and infrastructure remain a significant challenge, as they can have a great impact on emotional states. Explaining the reasons behind these emotional states requires gathering sufficient and proper contextual data, which can be extremely difficult in real-world environments. This paper addresses these challenges by applying an innovative approach, extracting contextual data (expert annotator level) from recorded multimedia using large language models (LLMs). In this paper, data are collected from an urban cycling case study of the City of Santiago, Chile. The applied models focus on understanding how different environments and traffic situations affect the emotional states and behaviors of the participants using physiological data. Sequences of images, extracted from the recorded videos, are processed by LLMs to obtain semantic descriptions of the environment. These discrete, although dense and detailed, contextual data are integrated into a hybrid model, where fatigue and arousal serve as latent variables influencing observed cycling behaviors (inferred from GPS data) like waiting, accelerating, braking, etc. The study confirms that cycling decisions are influenced by stress-related emotions and highlights the strong impact of urban characteristics and traffic conditions on cyclist behavior.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "191",
        "title": "Decoding non-invasive brain activity with novel deep-learning approaches",
        "author": [
            "Richard Csaky"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24733",
        "abstract": "This thesis delves into the world of non-invasive electrophysiological brain signals like electroencephalography (EEG) and magnetoencephalography (MEG), focusing on modelling and decoding such data. The research aims to investigate what happens in the brain when we perceive visual stimuli or engage in covert speech (inner speech) and enhance the decoding performance of such stimuli. The thesis is divided into two main sections, methodological and experimental work. A central concern in both sections is the large variability present in electrophysiological recordings, whether it be within-subject or between-subject variability, and to a certain extent between-dataset variability. In the methodological sections, we explore the potential of deep learning for brain decoding. We present advancements in decoding visual stimuli using linear models at the individual subject level. We then explore how deep learning techniques can be employed for group decoding, introducing new methods to deal with between-subject variability. Finally, we also explores novel forecasting models of MEG data based on convolutional and Transformer-based architectures. In particular, Transformer-based models demonstrate superior capabilities in generating signals that closely match real brain data, thereby enhancing the accuracy and reliability of modelling the brain's electrophysiology. In the experimental section, we present a unique dataset containing high-trial inner speech EEG, MEG, and preliminary optically pumped magnetometer (OPM) data. Our aim is to investigate different types of inner speech and push decoding performance by collecting a high number of trials and sessions from a few participants. However, the decoding results are found to be mostly negative, underscoring the difficulty of decoding inner speech.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "192",
        "title": "StrikeWatch: Wrist-worn Gait Recognition with Compact Time-series Models on Low-power FPGAs",
        "author": [
            "Tianheng Ling",
            "Chao Qian",
            "Peter Zdankin",
            "Torben Weis",
            "Gregor Schiele"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24738",
        "abstract": "Running offers substantial health benefits, but improper gait patterns can lead to injuries, particularly without expert feedback. While prior gait analysis systems based on cameras, insoles, or body-mounted sensors have demonstrated effectiveness, they are often bulky and limited to offline, post-run analysis. Wrist-worn wearables offer a more practical and non-intrusive alternative, yet enabling real-time gait recognition on such devices remains challenging due to noisy Inertial Measurement Unit (IMU) signals, limited computing resources, and dependence on cloud connectivity. This paper introduces StrikeWatch, a compact wrist-worn system that performs entirely on-device, real-time gait recognition using IMU signals. As a case study, we target the detection of heel versus forefoot strikes to enable runners to self-correct harmful gait patterns through visual and auditory feedback during running. We propose four compact DL architectures (1D-CNN, 1D-SepCNN, LSTM, and Transformer) and optimize them for energy-efficient inference on two representative embedded Field-Programmable Gate Arrays (FPGAs): the AMD Spartan-7 XC7S15 and the Lattice iCE40UP5K. Using our custom-built hardware prototype, we collect a labeled dataset from outdoor running sessions and evaluate all models via a fully automated deployment pipeline. Our results reveal clear trade-offs between model complexity and hardware efficiency. Evaluated across 12 participants, 6-bit quantized 1D-SepCNN achieves the highest average F1 score of 0.847 while consuming just 0.350 {\\mu}J per inference with a latency of 0.140 ms on the iCE40UP5K running at 20 MHz. This configuration supports up to 13.6 days of continuous inference on a 320 mAh battery. All datasets and code are available in the GitHub repository https://github.com/tianheng-ling/StrikeWatch.",
        "tags": [
            "Detection",
            "Transformer"
        ]
    },
    {
        "id": "193",
        "title": "Sub-microsecond Transformers for Jet Tagging on FPGAs",
        "author": [
            "Lauri Laatu",
            "Chang Sun",
            "Arianna Cox",
            "Abhijith Gandrakota",
            "Benedikt Maier",
            "Jennifer Ngadiuba",
            "Zhiqiang Que",
            "Wayne Luk",
            "Maria Spiropulu",
            "Alexander Tapper"
        ],
        "pdf": "https://arxiv.org/pdf/2510.24784",
        "abstract": "We present the first sub-microsecond transformer implementation on an FPGA achieving competitive performance for state-of-the-art high-energy physics benchmarks. Transformers have shown exceptional performance on multiple tasks in modern machine learning applications, including jet tagging at the CERN Large Hadron Collider (LHC). However, their computational complexity prohibits use in real-time applications, such as the hardware trigger system of the collider experiments up until now. In this work, we demonstrate the first application of transformers for jet tagging on FPGAs, achieving $\\mathcal{O}(100)$ nanosecond latency with superior performance compared to alternative baseline models. We leverage high-granularity quantization and distributed arithmetic optimization to fit the entire transformer model on a single FPGA, achieving the required throughput and latency. Furthermore, we add multi-head attention and linear attention support to hls4ml, making our work accessible to the broader fast machine learning community. This work advances the next-generation trigger systems for the High Luminosity LHC, enabling the use of transformers for real-time applications in high-energy physics and beyond.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "194",
        "title": "State Space and Self-Attention Collaborative Network with Feature Aggregation for DOA Estimation",
        "author": [
            "Qi You",
            "Qinghua Huang",
            "Yi-Cheng Lin"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25193",
        "abstract": "Accurate direction-of-arrival (DOA) estimation for sound sources is challenging due to the continuous changes in acoustic characteristics across time and frequency. In such scenarios, accurate localization relies on the ability to aggregate relevant features and model temporal dependencies effectively. In time series modeling, achieving a balance between model performance and computational efficiency remains a significant challenge. To address this, we propose FA-Stateformer, a state space and self-attention collaborative network with feature aggregation. The proposed network first employs a feature aggregation module to enhance informative features across both temporal and spectral dimensions. This is followed by a lightweight Conformer architecture inspired by the squeeze-and-excitation mechanism, where the feedforward layers are compressed to reduce redundancy and parameter overhead. Additionally, a temporal shift mechanism is incorporated to expand the receptive field of convolutional layers while maintaining a compact kernel size. To further enhance sequence modeling capabilities, a bidirectional Mamba module is introduced, enabling efficient state-space-based representation of temporal dependencies in both forward and backward directions. The remaining self-attention layers are combined with the Mamba blocks, forming a collaborative modeling framework that achieves a balance between representation capacity and computational efficiency. Extensive experiments demonstrate that FA-Stateformer achieves superior performance and efficiency compared to conventional architectures.",
        "tags": [
            "Mamba"
        ]
    },
    {
        "id": "195",
        "title": "Generative Bayesian Optimization: Generative Models as Acquisition Functions",
        "author": [
            "Rafael Oliveira",
            "Daniel M. Steinberg",
            "Edwin V. Bonilla"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25240",
        "abstract": "We present a general strategy for turning generative models into candidate solution samplers for batch Bayesian optimization (BO). The use of generative models for BO enables large batch scaling as generative sampling, optimization of non-continuous design spaces, and high-dimensional and combinatorial design. Inspired by the success of direct preference optimization (DPO), we show that one can train a generative model with noisy, simple utility values directly computed from observations to then form proposal distributions whose densities are proportional to the expected utility, i.e., BO's acquisition function values. Furthermore, this approach is generalizable beyond preference-based feedback to general types of reward signals and loss functions. This perspective avoids the construction of surrogate (regression or classification) models, common in previous methods that have used generative models for black-box optimization. Theoretically, we show that the generative models within the BO process approximately follow a sequence of distributions which asymptotically concentrate at the global optima under certain conditions. We also demonstrate this effect through experiments on challenging optimization problems involving large batches in high dimensions.",
        "tags": [
            "DPO"
        ]
    },
    {
        "id": "196",
        "title": "Improving Temporal Consistency and Fidelity at Inference-time in Perceptual Video Restoration by Zero-shot Image-based Diffusion Models",
        "author": [
            "Nasrin Rahimi",
            "A. Murat Tekalp"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25420",
        "abstract": "Diffusion models have emerged as powerful priors for single-image restoration, but their application to zero-shot video restoration suffers from temporal inconsistencies due to the stochastic nature of sampling and complexity of incorporating explicit temporal modeling. In this work, we address the challenge of improving temporal coherence in video restoration using zero-shot image-based diffusion models without retraining or modifying their architecture. We propose two complementary inference-time strategies: (1) Perceptual Straightening Guidance (PSG) based on the neuroscience-inspired perceptual straightening hypothesis, which steers the diffusion denoising process towards smoother temporal evolution by incorporating a curvature penalty in a perceptual space to improve temporal perceptual scores, such as FrÃ©chet Video Distance (FVD) and perceptual straightness; and (2) Multi-Path Ensemble Sampling (MPES), which aims at reducing stochastic variation by ensembling multiple diffusion trajectories to improve fidelity (distortion) scores, such as PSNR and SSIM, without sacrificing sharpness. Together, these training-free techniques provide a practical path toward temporally stable high-fidelity perceptual video restoration using large pretrained diffusion models. We performed extensive experiments over multiple datasets and degradation types, systematically evaluating each strategy to understand their strengths and limitations. Our results show that while PSG enhances temporal naturalness, particularly in case of temporal blur, MPES consistently improves fidelity and spatio-temporal perception--distortion trade-off across all tasks.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "197",
        "title": "Error Bounds and Optimal Schedules for Masked Diffusions with Factorized Approximations",
        "author": [
            "Hugo Lavenant",
            "Giacomo Zanella"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25544",
        "abstract": "Recently proposed generative models for discrete data, such as Masked Diffusion Models (MDMs), exploit conditional independence approximations to reduce the computational cost of popular Auto-Regressive Models (ARMs), at the price of some bias in the sampling distribution. We study the resulting computation-vs-accuracy trade-off, providing general error bounds (in relative entropy) that depend only on the average number of tokens generated per iteration and are independent of the data dimensionality (i.e. sequence length), thus supporting the empirical success of MDMs. We then investigate the gain obtained by using non-constant schedule sizes (i.e. varying the number of unmasked tokens during the generation process) and identify the optimal schedule as a function of a so-called information profile of the data distribution, thus allowing for a principled optimization of schedule sizes. We define methods directly as sampling algorithms and do not use classical derivations as time-reversed diffusion processes, leading us to simple and transparent proofs.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "198",
        "title": "PitchFlower: A flow-based neural audio codec with pitch controllability",
        "author": [
            "Diego Torres",
            "Axel Roebel",
            "Nicolas Obin"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25566",
        "abstract": "We present PitchFlower, a flow-based neural audio codec with explicit pitch controllability. Our approach enforces disentanglement through a simple perturbation: during training, F0 contours are flattened and randomly shifted, while the true F0 is provided as conditioning. A vector-quantization bottleneck prevents pitch recovery, and a flow-based decoder generates high quality audio. Experiments show that PitchFlower achieves more accurate pitch control than WORLD at much higher audio quality, and outperforms SiFiGAN in controllability while maintaining comparable quality. Beyond pitch, this framework provides a simple and extensible path toward disentangling other speech attributes.",
        "tags": [
            "Vector Quantization"
        ]
    },
    {
        "id": "199",
        "title": "PyDPF: A Python Package for Differentiable Particle Filtering",
        "author": [
            "John-Joseph Brady",
            "Benjamin Cox",
            "VÃ­ctor Elvira",
            "Yunpeng Li"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25693",
        "abstract": "State-space models (SSMs) are a widely used tool in time series analysis. In the complex systems that arise from real-world data, it is common to employ particle filtering (PF), an efficient Monte Carlo method for estimating the hidden state corresponding to a sequence of observations. Applying particle filtering requires specifying both the parametric form and the parameters of the system, which are often unknown and must be estimated. Gradient-based optimisation techniques cannot be applied directly to standard particle filters, as the filters themselves are not differentiable. However, several recently proposed methods modify the resampling step to make particle filtering differentiable. In this paper, we present an implementation of several such differentiable particle filters (DPFs) with a unified API built on the popular PyTorch framework. Our implementation makes these algorithms easily accessible to a broader research community and facilitates straightforward comparison between them. We validate our framework by reproducing experiments from several existing studies and demonstrate how DPFs can be applied to address several common challenges with state space modelling.",
        "tags": [
            "SSMs"
        ]
    },
    {
        "id": "200",
        "title": "Physics-Guided Conditional Diffusion Networks for Microwave Image Reconstruction",
        "author": [
            "Shirin Chehelgami",
            "Joe LoVetri",
            "Vahab Khoshdel"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25729",
        "abstract": "A conditional latent-diffusion based framework for solving the electromagnetic inverse scattering problem associated with microwave imaging is introduced. This generative machine-learning model explicitly mirrors the non-uniqueness of the ill-posed inverse problem. Unlike existing inverse solvers utilizing deterministic machine learning techniques that produce a single reconstruction, the proposed latent-diffusion model generates multiple plausible permittivity maps conditioned on measured scattered-field data, thereby generating several potential instances in the range-space of the non-unique inverse mapping. A forward electromagnetic solver is integrated into the reconstruction pipeline as a physics-based evaluation mechanism. The space of candidate reconstructions form a distribution of possibilities consistent with the conditioning data and the member of this space yielding the lowest scattered-field data discrepancy between the predicted and measured scattered fields is reported as the final solution. Synthetic and experimental labeled datasets are used for training and evaluation of the model. An innovative labeled synthetic dataset is created that exemplifies a varied set of scattering features. Training of the model using this new dataset produces high quality permittivity reconstructions achieving improved generalization with excellent fidelity to shape recognition. The results highlight the potential of hybrid generative physics frameworks as a promising direction for robust, data-driven microwave imaging.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "201",
        "title": "E-Scores for (In)Correctness Assessment of Generative Model Outputs",
        "author": [
            "Guneet S. Dhillon",
            "Javier GonzÃ¡lez",
            "Teodora Pandeva",
            "Alicia Curth"
        ],
        "pdf": "https://arxiv.org/pdf/2510.25770",
        "abstract": "While generative models, especially large language models (LLMs), are ubiquitous in today's world, principled mechanisms to assess their (in)correctness are limited. Using the conformal prediction framework, previous works construct sets of LLM responses where the probability of including an incorrect response, or error, is capped at a desired user-defined tolerance level. However, since these methods are based on p-values, they are susceptible to p-hacking, i.e., choosing the tolerance level post-hoc can invalidate the guarantees. We therefore leverage e-values to complement generative model outputs with e-scores as a measure of incorrectness. In addition to achieving the same statistical guarantees as before, e-scores provide users flexibility in adaptively choosing tolerance levels after observing the e-scores themselves, by upper bounding a post-hoc notion of error called size distortion. We experimentally demonstrate their efficacy in assessing LLM outputs for different correctness types: mathematical factuality and property constraints satisfaction.",
        "tags": [
            "LLM"
        ]
    }
]