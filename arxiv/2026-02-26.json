[
    {
        "id": "1",
        "title": "Disaster Question Answering with LoRA Efficiency and Accurate End Position",
        "author": [
            "Takato Yasuno"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21212",
        "abstract": "Natural disasters such as earthquakes, torrential rainfall, floods, and volcanic eruptions occur with extremely low frequency and affect limited geographic areas. When individuals face disaster situations, they often experience confusion and lack the domain-specific knowledge and experience necessary to determine appropriate responses and actions. While disaster information is continuously updated, even when utilizing RAG search and large language models for inquiries, obtaining relevant domain knowledge about natural disasters and experiences similar to one's specific situation is not guaranteed. When hallucinations are included in disaster question answering, artificial misinformation may spread and exacerbate confusion. This work introduces a disaster-focused question answering system based on Japanese disaster situations and response experiences. Utilizing the cl-tohoku/bert-base-japanese-v3 + Bi-LSTM + Enhanced Position Heads architecture with LoRA efficiency optimization, we achieved 70.4\\% End Position accuracy with only 5.7\\% of the total parameters (6.7M/117M). Experimental results demonstrate that the combination of Japanese BERT-base optimization and Bi-LSTM contextual understanding achieves accuracy levels suitable for real disaster response scenarios, attaining a 0.885 Span F1 score. Future challenges include: establishing natural disaster Q\\&A benchmark datasets, fine-tuning foundation models with disaster knowledge, developing lightweight and power-efficient edge AI Disaster Q\\&A applications for situations with insufficient power and communication during disasters, and addressing disaster knowledge base updates and continual learning capabilities.",
        "tags": [
            "BERT",
            "LLM",
            "LoRA",
            "RAG"
        ]
    },
    {
        "id": "2",
        "title": "Inference-time Alignment via Sparse Junction Steering",
        "author": [
            "Runyi Hu",
            "Jie Zhang",
            "Shiqian Zhao",
            "Jiale Meng",
            "Jiwei Li",
            "Jason Zeng",
            "Ming Wu",
            "Michael Heinrich",
            "Yonggang Wen",
            "Tianwei Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21215",
        "abstract": "Token-level steering has emerged as a pivotal approach for inference-time alignment, enabling fine grained control over large language models by modulating their output distributions without parameter updates. While effective, existing methods rely on dense intervention at every decoding step. This persistent manipulation not only incurs substantial computational overhead but also risks compromising generation quality by excessively drifting from the model's intrinsic distribution. In this work, we show that dense intervention is unnecessary and propose Sparse Inference time Alignment (SIA), which performs sparse junction steering by intervening only at critical decision points along the generation trajectory. Our key insight is that high entropy junctions mark pivotal decision points in the generation trajectory and are particularly susceptible to misalignment, indicating the need to introduce alignment related reward signals at these points. Extensive experiments across different model families and alignment objectives show that steering only 20% to 80% of tokens achieves superior alignment-efficiency trade offs. For strong base models such as Qwen3, intervening on as few as 20% of tokens matches or even surpasses heavily post-trained instruct models. This sparsity enables stronger guidance while better preserving the model's native distribution, integrates seamlessly with search based methods such as Best-of-N, and reduces computational cost by up to 6x.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "3",
        "title": "EQ-5D Classification Using Biomedical Entity-Enriched Pre-trained Language Models and Multiple Instance Learning",
        "author": [
            "Zhyar Rzgar K Rostam",
            "GÃ¡bor KertÃ©sz"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21216",
        "abstract": "The EQ-5D (EuroQol 5-Dimensions) is a standardized instrument for the evaluation of health-related quality of life. In health economics, systematic literature reviews (SLRs) depend on the correct identification of publications that use the EQ-5D, but manual screening of large volumes of scientific literature is time-consuming, error-prone, and inconsistent. In this study, we investigate fine-tuning of general-purpose (BERT) and domain-specific (SciBERT, BioBERT) pre-trained language models (PLMs), enriched with biomedical entity information extracted through scispaCy models for each statement, to improve EQ-5D detection from abstracts. We conduct nine experimental setups, including combining three scispaCy models with three PLMs, and evaluate their performance at both the sentence and study levels. Furthermore, we explore a Multiple Instance Learning (MIL) approach with attention pooling to aggregate sentence-level information into study-level predictions, where each abstract is represented as a bag of enriched sentences (by scispaCy). The findings indicate consistent improvements in F1-scores (reaching 0.82) and nearly perfect recall at the study-level, significantly exceeding classical bag-of-words baselines and recently reported PLM baselines. These results show that entity enrichment significantly improves domain adaptation and model generalization, enabling more accurate automated screening in systematic reviews.",
        "tags": [
            "BERT",
            "Detection"
        ]
    },
    {
        "id": "4",
        "title": "EPSVec: Efficient and Private Synthetic Data Generation via Dataset Vectors",
        "author": [
            "Amin Banayeeanzade",
            "Qingchuan Yang",
            "Deqing Fu",
            "Spencer Hong",
            "Erin Babinsky",
            "Alfy Samuel",
            "Anoop Kumar",
            "Robin Jia",
            "Sai Praneeth Karimireddy"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21218",
        "abstract": "High-quality data is essential for modern machine learning, yet many valuable corpora are sensitive and cannot be freely shared. Synthetic data offers a practical substitute for downstream development, and large language models (LLMs) have emerged as powerful engines for generating it. However, existing private text generation methods are severely inefficient: they are data-intensive, computationally slow, and often require large private corpora or batch sizes to achieve usable quality. We introduce EPSVec, a differentially-private lightweight alternative that steers LLM generation using *dataset vectors*--directions in activation space that capture the distributional gap between private data and public priors. EPSVec extracts and sanitizes steering vectors just once and then performs standard decoding. This decouples the privacy budget from generation, enabling arbitrarily many synthetic samples without additional privacy cost and yielding strong fidelity even in low-data regimes. Furthermore, we enhance our method by utilizing pretrained (base) models and introducing fixed-shot prompting to boost generation diversity and fidelity. Our experiments demonstrate that EPSVec outperforms existing baselines in distributional alignment and downstream utility, particularly in low-data regimes, while significantly reducing computational overhead.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "5",
        "title": "Reasoning-Based Personalized Generation for Users with Sparse Data",
        "author": [
            "Bo Ni",
            "Branislav Kveton",
            "Samyadeep Basu",
            "Subhojyoti Mukherjee",
            "Leyao Wang",
            "Franck Dernoncourt",
            "Sungchul Kim",
            "Seunghyun Yoon",
            "Zichao Wang",
            "Ruiyi Zhang",
            "Puneet Mathur",
            "Jihyung Kil",
            "Jiuxiang Gu",
            "Nedim Lipka",
            "Yu Wang",
            "Ryan A. Rossi",
            "Tyler Derr"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21219",
        "abstract": "Large Language Model (LLM) personalization holds great promise for tailoring responses by leveraging personal context and history. However, real-world users usually possess sparse interaction histories with limited personal context, such as cold-start users in social platforms and newly registered customers in online E-commerce platforms, compromising the LLM-based personalized generation. To address this challenge, we introduce GraSPer (Graph-based Sparse Personalized Reasoning), a novel framework for enhancing personalized text generation under sparse context. GraSPer first augments user context by predicting items that the user would likely interact with in the future. With reasoning alignment, it then generates texts for these interactions to enrich the augmented context. In the end, it generates personalized outputs conditioned on both the real and synthetic histories, ensuring alignment with user style and preferences. Extensive experiments on three benchmark personalized generation datasets show that GraSPer achieves significant performance gain, substantially improving personalization in sparse user context settings.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "6",
        "title": "Latent Context Compilation: Distilling Long Context into Compact Portable Memory",
        "author": [
            "Zeju Li",
            "Yizhou Zhou",
            "Qiang Xu"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21221",
        "abstract": "Efficient long-context LLM deployment is stalled by a dichotomy between amortized compression, which struggles with out-of-distribution generalization, and Test-Time Training, which incurs prohibitive synthetic data costs and requires modifying model weights, creating stateful parameters that complicate concurrent serving. We propose Latent Context Compilation, a framework that fundamentally shifts context processing from adaptation to compilation. By utilizing a disposable LoRA module as a compiler, we distill long contexts into compact buffer tokens -- stateless, portable memory artifacts that are plug-and-play compatible with frozen base models. Crucially, we introduce a self-aligned optimization strategy that eliminates the need for synthetic context-relevant QA pairs. By regularizing context reconstruction task with context-agnostic random queries, we force compressed tokens to reside within the model's existing instruction-following manifold. Experiments with Llama-3.1-8B demonstrate that Latent Context Compilation preserves fine-grained details and reasoning capabilities where prior methods falter, effectively decoupling memory density from model parameters even at a 16x compression ratio.",
        "tags": [
            "LLM",
            "LLaMA",
            "LoRA",
            "TTT"
        ]
    },
    {
        "id": "7",
        "title": "Task-Aware LoRA Adapter Composition via Similarity Retrieval in Vector Databases",
        "author": [
            "Riya Adsul",
            "Balachandra Devarangadi Sunil",
            "Isha Nalawade",
            "Sudharshan Govindan"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21222",
        "abstract": "Parameter efficient fine tuning methods like LoRA have enabled task specific adaptation of large language models, but efficiently composing multiple specialized adapters for unseen tasks remains challenging. We present a novel framework for dynamic LoRA adapter composition that leverages similarity retrieval in vector databases to enable zero-shot generalization across diverse NLP tasks. Our approach constructs a task-aware vector database by embedding training examples from 22 datasets spanning commonsense reasoning, question answering, natural language inference, and sentiment analysis. At inference time, we retrieve the most similar training examples, compute task similarity distributions via nucleus sampling, and dynamically merge relevant LoRA adapters using retrieval weighted fusion strategies. We evaluated four merging methods Linear, Concatenation, TIES, and Magnitude Prune demonstrating that our dataset centric retrieval approach often matches or exceeds the performance of individually fine-tuned task-specific adapters. Notably, Linear merging achieves 70.95% on PIQA and 77.62% on RTE, substantially outperforming single-task baselines (46% and 52%, respectively). Our framework requires no additional retriever training, operates with frozen embeddings, and enables efficient, interpretable adapter composition. These results suggest that retrieval based dynamic merging offers a promising direction for scalable, parameter-efficient multitask learning without requiring full model retraining for each new task.",
        "tags": [
            "LLM",
            "LoRA"
        ]
    },
    {
        "id": "8",
        "title": "Measuring Pragmatic Influence in Large Language Model Instructions",
        "author": [
            "Yilin Geng",
            "Omri Abend",
            "Eduard Hovy",
            "Lea Frermann"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21223",
        "abstract": "It is not only what we ask large language models (LLMs) to do that matters, but also how we prompt. Phrases like \"This is urgent\" or \"As your supervisor\" can shift model behavior without altering task content. We study this effect as pragmatic framing, contextual cues that shape directive interpretation rather than task specification. While prior work exploits such cues for prompt optimization or probes them as security vulnerabilities, pragmatic framing itself has not been treated as a measurable property of instruction following. Measuring this influence systematically remains challenging, requiring controlled isolation of framing cues. We introduce a framework with three novel components: directive-framing decomposition separating framing context from task specification; a taxonomy organizing 400 instantiations of framing into 13 strategies across 4 mechanism clusters; and priority-based measurement that quantifies influence through observable shifts in directive prioritization. Across five LLMs of different families and sizes, influence mechanisms cause consistent and structured shifts in directive prioritization, moving models from baseline impartiality toward favoring the framed directive. This work establishes pragmatic framing as a measurable and predictable factor in instruction-following systems.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "9",
        "title": "Make Every Draft Count: Hidden State based Speculative Decoding",
        "author": [
            "Yuetao Chen",
            "Xuliang Wang",
            "Xinzhou Zheng",
            "Ming Li",
            "Peng Wang",
            "Hong Xu"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21224",
        "abstract": "Speculative decoding has emerged as a pivotal technique to accelerate LLM inference by employing a lightweight draft model to generate candidate tokens that are subsequently verified by the target model in parallel. However, while this paradigm successfully increases the arithmetic intensity of memory-bound inference, it causes significant compute inefficiency: the majority of draft tokens fail verification and are discarded, resulting in waste of computation. Motivated by the goal of recollecting this wasted computation, we propose a novel system that transforms discarded drafts into reusable tokens. Our key insight is to perform auto-regressive prediction at the hidden states level and postpone the integrating token information after the hidden states generation, so the draft hidden states are not contaminated by incorrect tokens, enabling hidden state reuse. To implement such a system, first we introduce a draft model architecture based on auto-regressive hidden states, which preserves richer semantics than token-based drafters to facilitate draft repurposing. Second, we design an efficient token information injection mechanism that leverages our specialized draft model to construct high-quality draft token trees and enables resampling tokens from verification failures. Third, we eliminate the overhead hidden in our design to further maximize hardware utilization. We conducted extensive evaluations against various baselines, demonstrating up to a 3.3x speedup against standard speculative decoding.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "10",
        "title": "Architecture-Agnostic Curriculum Learning for Document Understanding: Empirical Evidence from Text-Only and Multimodal",
        "author": [
            "Mohammed Hamdan",
            "Vincenzo Dentamaro",
            "Giuseppe Pirlo",
            "Mohamed Cheriet"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21225",
        "abstract": "We investigate whether progressive data scheduling -- a curriculum learning strategy that incrementally increases training data exposure (33\\%$\\rightarrow$67\\%$\\rightarrow$100\\%) -- yields consistent efficiency gains across architecturally distinct document understanding models. By evaluating BERT (text-only, 110M parameters) and LayoutLMv3 (multimodal, 126M parameters) on the FUNSD and CORD benchmarks, we establish that this schedule reduces wall-clock training time by approximately 33\\%, commensurate with the reduction from 6.67 to 10.0 effective epoch-equivalents of data. To isolate curriculum effects from compute reduction, we introduce matched-compute baselines (Standard-7) that control for total gradient updates. On the FUNSD dataset, the curriculum significantly outperforms the matched-compute baseline for BERT ($\\Delta$F1 = +0.023, $p=0.022$, $d_z=3.83$), constituting evidence for a genuine scheduling benefit in capacity-constrained models. In contrast, no analogous benefit is observed for LayoutLMv3 ($p=0.621$), whose multimodal representations provide sufficient inductive bias. On the CORD dataset, all conditions converge to equivalent F1 scores ($\\geq$0.947) irrespective of scheduling, indicating a performance ceiling. Schedule ablations comparing progressive, two-phase, reverse, and random pacing confirm that the efficiency gain derives from reduced data volume rather than ordering. Taken together, these findings demonstrate that progressive scheduling is a reliable compute-reduction strategy across model families, with curriculum-specific benefits contingent on the interaction between model capacity and task complexity.",
        "tags": [
            "BERT"
        ]
    },
    {
        "id": "11",
        "title": "IslamicLegalBench: Evaluating LLMs Knowledge and Reasoning of Islamic Law Across 1,200 Years of Islamic Pluralist Legal Traditions",
        "author": [
            "Ezieddin Elmahjub",
            "Junaid Qadir",
            "Abdullah Mushtaq",
            "Rafay Naeem",
            "Ibrahim Ghaznavi",
            "Waleed Iqbal"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21226",
        "abstract": "As millions of Muslims turn to LLMs like GPT, Claude, and DeepSeek for religious guidance, a critical question arises: Can these AI systems reliably reason about Islamic law? We introduce IslamicLegalBench, the first benchmark evaluating LLMs across seven schools of Islamic jurisprudence, with 718 instances covering 13 tasks of varying complexity. Evaluation of nine state-of-the-art models reveals major limitations: the best model achieves only 68% correctness with 21% hallucination, while several models fall below 35% correctness and exceed 55% hallucination. Few-shot prompting provides minimal gains, improving only 2 of 9 models by >1%. Moderate-complexity tasks requiring exact knowledge show the highest errors, whereas high-complexity tasks display apparent competence through semantic reasoning. False premise detection indicates risky sycophancy, with 6 of 9 models accepting misleading assumptions at rates above 40%. These results highlight that prompt-based methods cannot compensate for missing foundational knowledge. IslamicLegalBench offers the first systematic framework to evaluate Islamic legal reasoning in AI, revealing critical gaps in tools increasingly relied on for spiritual guidance.",
        "tags": [
            "DeepSeek",
            "Detection",
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "12",
        "title": "Budget-Aware Agentic Routing via Boundary-Guided Training",
        "author": [
            "Caiqi Zhang",
            "Menglin Xia",
            "Xuchao Zhang",
            "Daniel Madrigal",
            "Ankur Mallick",
            "Samuel Kessler",
            "Victor Ruehle",
            "Saravan Rajmohan"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21227",
        "abstract": "As large language models (LLMs) evolve into autonomous agents that execute long-horizon workflows, invoking a high-capability model at every step becomes economically unsustainable. While model routing is effective for single-turn queries, agentic routing is a sequential, path-dependent problem: early mistakes compound, feedback is often at the end of the episode, and deployments often demand strict per-task spending limits. We propose Budget-Aware Agentic Routing, which selects between a cheap and an expensive model at each step to optimize the cost--success frontier and to operate under strict per-task budgets. We propose Boundary-Guided Training, which leverages two boundary policies (always-small vs.\\ always-large) to build a difficulty taxonomy and to anchor learning under sparse rewards. Our approach warms start with boundary-guided SFT data synthesis via stratified sampling of cost-efficient trajectories, then applies Boundary-Guided Policy Optimization (BoPO), combining boundary-relative rewards with a reference-guided advantage to avoid degenerate cheap-failure solutions. Experiment results show that our method improves the efficiency frontier, matching strong routing baselines at substantially lower cost while demonstrating generalization to strict inference-time budget constraints. Overall, our work establishes a foundational framework for agentic routing, shifting the paradigm from static model selection to dynamic, budget-aware sequential decision-making.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "13",
        "title": "ImpRIF: Stronger Implicit Reasoning Leads to Better Complex Instruction Following",
        "author": [
            "Yuancheng Yang",
            "Lin Yang",
            "Xu Wang",
            "Chao Tong",
            "Haihua Yang"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21228",
        "abstract": "As applications of large language models (LLMs) become increasingly complex, the demand for robust complex instruction following capabilities is growing accordingly. We argue that a thorough understanding of the instruction itself, especially the latent reasoning structure embedded between the lines, is crucial for improving instruction following. Therefore we target complex instructions that involve implicit reasoning, intricate logical relations, and multi-constraint dependencies. We propose ImpRIF, a method to enhance LLMs' understanding of implicit reasoning instructions, thereby improving its ability to follow complex instructions. We formalize such instructions as verifiable reasoning graphs, enabling programmatic verification and graph-driven chain-of-thought reasoning. Based on this formulation, we synthesize large-scale single- and multi-turn data, propose fine-tuning with graph reasoning, and apply reinforcement learning to explicitly train models to reason along the graph. On five complex instruction following benchmarks, our models substantially outperform their base models. These results demonstrate that enhancing implicit reasoning capabilities can significantly improve complex instruction following. This project will be open-sourced in the near future.",
        "tags": [
            "CoT",
            "LLM",
            "RL"
        ]
    },
    {
        "id": "14",
        "title": "ACAR: Adaptive Complexity Routing for Multi-Model Ensembles with Auditable Decision Traces",
        "author": [
            "Ramchand Kumaresan"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21231",
        "abstract": "We present ACAR (Adaptive Complexity and Attribution Routing), a measurement framework for studying multi-model orchestration under auditable conditions. ACAR uses self-consistency variance (sigma) computed from N=3 probe samples to route tasks across single-model, two-model, and three-model execution modes. The system is implemented on top of TEAMLLM, a deterministic execution substrate with immutable artifacts and complete decision traces. We evaluate ACAR on 1,510 tasks spanning four benchmarks: MathArena, Reasoning Gym, LiveCodeBench, and SuperGPQA, using Claude Sonnet 4, GPT-4o, and Gemini 2.0 Flash, producing more than 7,550 auditable runs. Results show that sigma-based routing achieves 55.6 percent accuracy, exceeding the two-model baseline of 54.4 percent while avoiding full ensembling on 54.2 percent of tasks. The routing mechanism is model-agnostic and requires no learned components. We also document negative results. First, retrieval augmentation reduced accuracy by 3.4 percentage points, as median retrieval similarity was only 0.167, demonstrating that experience injection without semantic alignment introduces noise rather than grounding. Second, when models agree on incorrect answers (sigma equals zero), no downstream ensemble can recover; this agreement-but-wrong failure mode is intrinsic to self-consistency and bounds achievable accuracy at approximately eight percentage points below full ensembling. Third, attribution estimates based on proxy signals such as response similarity and entropy showed weak correlation with ground-truth leave-one-out values, indicating that practical attribution requires explicit counterfactual computation. This work documents which assumptions fail in practice and provides falsifiable baselines for future research on routing, retrieval, and multi-model attribution.",
        "tags": [
            "GPT"
        ]
    },
    {
        "id": "15",
        "title": "Urban Vibrancy Embedding and Application on Traffic Prediction",
        "author": [
            "Sumin Han",
            "Jisun An",
            "Dongman Lee"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21232",
        "abstract": "Urban vibrancy reflects the dynamic human activity within urban spaces and is often measured using mobile data that captures floating population trends. This study proposes a novel approach to derive Urban Vibrancy embeddings from real-time floating population data to enhance traffic prediction models. Specifically, we utilize variational autoencoders (VAE) to compress this data into actionable embeddings, which are then integrated with long short-term memory (LSTM) networks to predict future embeddings. These are subsequently applied in a sequence-to-sequence framework for traffic forecasting. Our contributions are threefold: (1) We use principal component analysis (PCA) to interpret the embeddings, revealing temporal patterns such as weekday versus weekend distinctions and seasonal patterns; (2) We propose a method that combines VAE and LSTM, enabling forecasting dynamic urban knowledge embedding; and (3) Our approach improves accuracy and responsiveness in traffic prediction models, including RNN, DCRNN, GTS, and GMAN. This study demonstrates the potential of Urban Vibrancy embeddings to advance traffic prediction and offer a more nuanced analysis of urban mobility.",
        "tags": [
            "RNN",
            "VAE"
        ]
    },
    {
        "id": "16",
        "title": "@GrokSet: multi-party Human-LLM Interactions in Social Media",
        "author": [
            "Matteo Migliarini",
            "Berat Ercevik",
            "Oluwagbemike Olowe",
            "Saira Fatima",
            "Sarah Zhao",
            "Minh Anh Le",
            "Vasu Sharma",
            "Ashwinee Panda"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21236",
        "abstract": "Large Language Models (LLMs) are increasingly deployed as active participants on public social media platforms, yet their behavior in these unconstrained social environments remains largely unstudied. Existing datasets, drawn primarily from private chat interfaces, lack the multi-party dynamics and public visibility crucial for understanding real-world performance. To address this gap, we introduce @GrokSet, a large-scale dataset of over 1 million tweets involving the @Grok LLM on X. Our analysis reveals a distinct functional shift: rather than serving as a general assistant, the LLM is frequently invoked as an authoritative arbiter in high-stakes, polarizing political debates. However, we observe a persistent engagement gap: despite this visibility, the model functions as a low-status utility, receiving significantly less social validation (likes, replies) than human peers. Finally, we find that this adversarial context exposes shallow alignment: users bypass safety filters not through complex jailbreaks, but through simple persona adoption and tone mirroring. We release @GrokSet as a critical resource for studying the intersection of AI agents and societal discourse.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "17",
        "title": "AgenticTyper: Automated Typing of Legacy Software Projects Using Agentic AI",
        "author": [
            "Clemens Pohle"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21251",
        "abstract": "Legacy JavaScript systems lack type safety, making maintenance risky. While TypeScript can help, manually adding types is expensive. Previous automated typing research focuses on type inference but rarely addresses type checking setup, definition generation, bug identification, or behavioral correctness at repository scale. We present AgenticTyper, a Large Language Model (LLM)-based agentic system that addresses these gaps through iterative error correction and behavior preservation via transpilation comparison. Evaluation on two proprietary repositories (81K LOC) shows that AgenticTyper resolves all 633 initial type errors in 20 minutes, reducing manual effort from one working day.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "18",
        "title": "A General Equilibrium Theory of Orchestrated AI Agent Systems",
        "author": [
            "Jean-Philippe Garnier"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21255",
        "abstract": "We establish a general equilibrium theory for systems of large language model (LLM) agents operating under centralized orchestration. The framework is a production economy in the sense of Arrow-Debreu (1954), extended to infinite-dimensional commodity spaces following Bewley (1972). Each LLM agent is modeled as a firm whose production set Y a $\\subset$ H = L 2 ([0, T ], R R ) represents the feasible metric trajectories determined by its frozen model weights. The orchestrator is the consumer, choosing a routing policy over the agent DAG to maximize system welfare subject to a budget constraint evaluated at functional prices p $\\in$ H A . These prices-elements of the Hilbert dual of the commodity space-assign a shadow value to each metric of each agent at each instant. We prove, via Brouwer's theorem applied to a finitedimensional approximation V K $\\subset$ H, that every such economy admits at least one general equilibrium (p * , y * , $\\pi$ * ). A functional Walras' law  holds as a theorem: the value of functional excess demand is zero for all prices, as a consequence of the consumer's budget constraint-not by construction. We further establish Pareto optimality (First Welfare Theorem), decentralizability of Pareto optima (Second Welfare Theorem), and uniqueness with geometric convergence under a contraction condition (Banach). The orchestration dynamics constitute a Walrasian t{Ã¢}tonnement that converges globally under the contraction condition, unlike classical t{Ã¢}tonnement (Scarf, 1960). The framework admits a DSGE interpretation with SLO parameters as policy rates.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "19",
        "title": "Structured Prompt Language: Declarative Context Management for LLMs",
        "author": [
            "Wen G. Gong"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21257",
        "abstract": "We present SPL (Structured Prompt Language), a declarative SQL-inspired language that treats large language models as generative knowledge bases and their context windows as constrained resources. SPL provides explicit WITH BUDGET/LIMIT token management, an automatic query optimizer, EXPLAIN transparency analogous to SQL's EXPLAIN ANALYZE, and native integration of retrieval-augmented generation (RAG) and persistent memory in a single declarative framework. SPL-flow extends SPL into resilient agentic pipelines with a three-tier provider fallback strategy (Ollama -> OpenRouter -> self-healing retry) fully transparent to the .spl script. Five extensions demonstrate the paradigm's breadth: (1) Text2SPL (multilingual NL->SPL translation); (2) Mixture-of-Models (MoM) routing that dispatches each PROMPT to a domain-specialist model at runtime; (3) Logical Chunking, an intelligent strategy for documents exceeding a single context window--expressed naturally through SPL's existing CTE syntax with no new constructs, decomposing a large query into a Map-Reduce pipeline that reduces attention cost from O(N^2) to O(N^2/k) and runs identically on cloud (parallel) or local hardware (sequential); (4) SPL-flow, a declarative agentic orchestration layer with resilient three-tier provider fallback; and (5) BENCHMARK for parallel multi-model comparison with automatic winner persistence. We provide a formal EBNF grammar, two pip-installable Python packages (spl-llm, spl-flow), and comparison against Prompty, DSPy, and LMQL. SPL reduces prompt boilerplate by 65% on average, surfaces a 68x cost spread across model tiers as a pre-execution signal, and runs the identical .spl script at $0.002 on OpenRouter or at zero marginal cost on a local Ollama instance--without modification.",
        "tags": [
            "LLM",
            "RAG"
        ]
    },
    {
        "id": "20",
        "title": "Under the Influence: Quantifying Persuasion and Vigilance in Large Language Models",
        "author": [
            "Sasha Robinson",
            "Kerem Oktar",
            "Katherine M. Collins",
            "Ilia Sucholutsky",
            "Kelsey R. Allen"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21262",
        "abstract": "With increasing integration of Large Language Models (LLMs) into areas of high-stakes human decision-making, it is important to understand the risks they introduce as advisors. To be useful advisors, LLMs must sift through large amounts of content, written with both benevolent and malicious intent, and then use this information to convince a user to take a specific action. This involves two social capacities: vigilance (the ability to determine which information to use, and which to discard) and persuasion (synthesizing the available evidence to make a convincing argument). While existing work has investigated these capacities in isolation, there has been little prior investigation of how these capacities may be linked. Here, we use a simple multi-turn puzzle-solving game, Sokoban, to study LLMs' abilities to persuade and be rationally vigilant towards other LLM agents. We find that puzzle-solving performance, persuasive capability, and vigilance are dissociable capacities in LLMs. Performing well on the game does not automatically mean a model can detect when it is being misled, even if the possibility of deception is explicitly mentioned. % as part of the prompt. However, LLMs do consistently modulate their token use, using fewer tokens to reason when advice is benevolent and more when it is malicious, even if they are still persuaded to take actions leading them to failure. To our knowledge, our work presents the first investigation of the relationship between persuasion, vigilance, and task performance in LLMs, and suggests that monitoring all three independently will be critical for future work in AI safety.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "21",
        "title": "Group Orthogonalized Policy Optimization:Group Policy Optimization as Orthogonal Projection in Hilbert Space",
        "author": [
            "Wang Zixian"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21269",
        "abstract": "We present Group Orthogonalized Policy Optimization (GOPO), a new alignment algorithm for large language models derived from the geometry of Hilbert function spaces. Instead of optimizing on the probability simplex and inheriting the exponential curvature of Kullback-Leibler divergence, GOPO lifts alignment into the Hilbert space L2(pi_k) of square-integrable functions with respect to the reference policy. Within this space, the simplex constraint reduces to a linear orthogonality condition <v, 1> = 0, defining a codimension-one subspace H0. Minimizing distance to an unconstrained target u_star yields the work-dissipation functional J(v) = <g, v> - (mu / 2) ||v||^2, whose maximizer follows directly from the Hilbert projection theorem. Enforcing the boundary v >= -1 produces a bounded Hilbert projection that induces exact sparsity, assigning zero probability to catastrophically poor actions through a closed-form threshold. To connect this functional theory with practice, GOPO projects from infinite-dimensional L2(pi_k) to a finite empirical subspace induced by group sampling. Because group-normalized advantages sum to zero, the Lagrange multiplier enforcing probability conservation vanishes exactly, reducing the constrained projection to an unconstrained empirical loss. The resulting objective has constant Hessian curvature mu I, non-saturating linear gradients, and an intrinsic dead-zone mechanism without heuristic clipping. Experiments on mathematical reasoning benchmarks show that GOPO achieves competitive generalization while maintaining stable gradient dynamics and entropy preservation in regimes where clipping-based methods plateau.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "22",
        "title": "StoryTailor:A Zero-Shot Pipeline for Action-Rich Multi-Subject Visual Narratives",
        "author": [
            "Jinghao Hu",
            "Yuhe Zhang",
            "GuoHua Geng",
            "Kang Li",
            "Han Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21273",
        "abstract": "Generating multi-frame, action-rich visual narratives without fine-tuning faces a threefold tension: action text faithfulness, subject identity fidelity, and cross-frame background continuity. We propose StoryTailor, a zero-shot pipeline that runs on a single RTX 4090 (24 GB) and produces temporally coherent, identity-preserving image sequences from a long narrative prompt, per-subject references, and grounding boxes. Three synergistic modules drive the system: Gaussian-Centered Attention (GCA) to dynamically focus on each subject core and ease grounding-box overlaps; Action-Boost Singular Value Reweighting (AB-SVR) to amplify action-related directions in the text embedding space; and Selective Forgetting Cache (SFC) that retains transferable background cues, forgets nonessential history, and selectively surfaces retained cues to build cross-scene semantic ties. Compared with baseline methods, experiments show that CLIP-T improves by up to 10-15%, with DreamSim lower than strong baselines, while CLIP-I stays in a visually acceptable, competitive range. With matched resolution and steps on a 24 GB GPU, inference is faster than FluxKontext. Qualitatively, StoryTailor delivers expressive interactions and evolving yet stable scenes.",
        "tags": [
            "CLIP"
        ]
    },
    {
        "id": "23",
        "title": "SymTorch: A Framework for Symbolic Distillation of Deep Neural Networks",
        "author": [
            "Elizabeth S.Z. Tan",
            "Adil Soubki",
            "Miles Cranmer"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21307",
        "abstract": "Symbolic distillation replaces neural networks, or components thereof, with interpretable, closed-form mathematical expressions. This approach has shown promise in discovering physical laws and mathematical relationships directly from trained deep learning models, yet adoption remains limited due to the engineering barrier of integrating symbolic regression into deep learning workflows. We introduce SymTorch, a library that automates this distillation by wrapping neural network components, collecting their input-output behavior, and approximating them with human-readable equations via PySR. SymTorch handles the engineering challenges that have hindered adoption: GPU-CPU data transfer, input-output caching, model serialization, and seamless switching between neural and symbolic forward passes. We demonstrate SymTorch across diverse architectures including GNNs, PINNs and transformer models. Finally, we present a proof-of-concept for accelerating LLM inference by replacing MLP layers with symbolic surrogates, achieving an 8.3\\% throughput improvement with moderate performance degradation.",
        "tags": [
            "LLM",
            "Transformer"
        ]
    },
    {
        "id": "24",
        "title": "Unified Complementarity-Based Contact Modeling and Planning for Soft Robots",
        "author": [
            "Milad Azizkhani",
            "Yue Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21316",
        "abstract": "Soft robots were introduced in large part to enable safe, adaptive interaction with the environment, and this interaction relies fundamentally on contact. However, modeling and planning contact-rich interactions for soft robots remain challenging: dense contact candidates along the body create redundant constraints and rank-deficient LCPs, while the disparity between high stiffness and low friction introduces severe ill-conditioning. Existing approaches rely on problem-specific approximations or penalty-based treatments. This letter presents a unified complementarity-based framework for soft-robot contact modeling and planning that brings contact modeling, manipulation, and planning into a unified, physically consistent formulation. We develop a robust Linear Complementarity Problem (LCP) model tailored to discretized soft robots and address these challenges with a three-stage conditioning pipeline: inertial rank selection to remove redundant contacts, Ruiz equilibration to correct scale disparity and ill-conditioning, and lightweight Tikhonov regularization on normal blocks. Building on the same formulation, we introduce a kinematically guided warm-start strategy that enables dynamic trajectory optimization through contact using Mathematical Programs with Complementarity Constraints (MPCC) and demonstrate its effectiveness on contact-rich ball manipulation tasks. In conclusion, CUSP provides a new foundation for unifying contact modeling, simulation, and planning in soft robotics.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "25",
        "title": "Uncertainty-Aware Diffusion Model for Multimodal Highway Trajectory Prediction via DDIM Sampling",
        "author": [
            "Marion Neumeier",
            "Niklas RoÃberg",
            "Michael Botsch",
            "Wolfgang Utschick"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21319",
        "abstract": "Accurate and uncertainty-aware trajectory prediction remains a core challenge for autonomous driving, driven by complex multi-agent interactions, diverse scene contexts and the inherently stochastic nature of future motion. Diffusion-based generative models have recently shown strong potential for capturing multimodal futures, yet existing approaches such as cVMD suffer from slow sampling, limited exploitation of generative diversity and brittle scenario encodings.\nThis work introduces cVMDx, an enhanced diffusion-based trajectory prediction framework that improves efficiency, robustness and multimodal predictive capability. Through DDIM sampling, cVMDx achieves up to a 100x reduction in inference time, enabling practical multi-sample generation for uncertainty estimation. A fitted Gaussian Mixture Model further provides tractable multimodal predictions from the generated trajectories. In addition, a CVQ-VAE variant is evaluated for scenario encoding. Experiments on the publicly available highD dataset show that cVMDx achieves higher accuracy and significantly improved efficiency over cVMD, enabling fully stochastic, multimodal trajectory prediction.",
        "tags": [
            "DDIM",
            "Diffusion",
            "VAE"
        ]
    },
    {
        "id": "26",
        "title": "Tool-R0: Self-Evolving LLM Agents for Tool-Learning from Zero Data",
        "author": [
            "Emre Can Acikgoz",
            "Cheng Qian",
            "Jonas HÃ¼botter",
            "Heng Ji",
            "Dilek Hakkani-TÃ¼r",
            "Gokhan Tur"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21320",
        "abstract": "Large language models (LLMs) are becoming the foundation for autonomous agents that can use tools to solve complex tasks. Reinforcement learning (RL) has emerged as a common approach for injecting such agentic capabilities, but typically under tightly controlled training setups. It often depends on carefully constructed task-solution pairs and substantial human supervision, which creates a fundamental obstacle to open-ended self-evolution toward superintelligent systems. In this paper, we propose Tool-R0 framework for training general purpose tool-calling agents from scratch with self-play RL, under a zero-data assumption. Initialized from the same base LLM, Tool-R0 co-evolves a Generator and a Solver with complementary rewards: one proposes targeted challenging tasks at the other's competence frontier and the other learns to solve them with real-world tool calls. This creates a self-evolving cycle that requires no pre-existing tasks or datasets. Evaluation on different tool-use benchmarks show that Tool-R0 yields 92.5 relative improvement over the base model and surpasses fully supervised tool-calling baselines under the same setting. Our work further provides empirical insights into self-play LLM agents by analyzing co-evolution, curriculum dynamics, and scaling behavior.",
        "tags": [
            "LLM",
            "RL"
        ]
    },
    {
        "id": "27",
        "title": "Equitable Evaluation via Elicitation",
        "author": [
            "Elbert Du",
            "Cynthia Dwork",
            "Lunjia Hu",
            "Reid McIlroy-Young",
            "Han Shao",
            "Linjun Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21327",
        "abstract": "Individuals with similar qualifications and skills may vary in their demeanor, or outward manner: some tend toward self-promotion while others are modest to the point of omitting crucial information. Comparing the self-descriptions of equally qualified job-seekers with different self-presentation styles is therefore problematic.\nWe build an interactive AI for skill elicitation that provides accurate determination of skills while simultaneously allowing individuals to speak in their own voice. Such a system can be deployed, for example, when a new user joins a professional networking platform, or when matching employees to needs during a company reorganization. To obtain sufficient training data, we train an LLM to act as synthetic humans.\nElicitation mitigates endogenous bias arising from individuals' own self-reports. To address systematic model bias we enforce a mathematically rigorous notion of equitability ensuring that the covariance between self-presentation manner and skill evaluation error is small.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "28",
        "title": "CableRobotGraphSim: A Graph Neural Network for Modeling Partially Observable Cable-Driven Robot Dynamics",
        "author": [
            "Nelson Chen",
            "William R. Johnson III",
            "Rebecca Kramer-Bottiglio",
            "Kostas Bekris",
            "Mridul Aanjaneya"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21331",
        "abstract": "General-purpose simulators have accelerated the development of robots. Traditional simulators based on first-principles, however, typically require full-state observability or depend on parameter search for system identification. This work presents \\texttt{CableRobotGraphSim}, a novel Graph Neural Network (GNN) model for cable-driven robots that aims to address shortcomings of prior simulation solutions. By representing cable-driven robots as graphs, with the rigid-bodies as nodes and the cables and contacts as edges, this model can quickly and accurately match the properties of other simulation models and real robots, while ingesting only partially observable inputs. Accompanying the GNN model is a sim-and-real co-training procedure that promotes generalization and robustness to noisy real data. This model is further integrated with a Model Predictive Path Integral (MPPI) controller for closed-loop navigation, which showcases the model's speed and accuracy.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "29",
        "title": "HorizonForge: Driving Scene Editing with Any Trajectories and Any Vehicles",
        "author": [
            "Yifan Wang",
            "Francesco Pittaluga",
            "Zaid Tasneem",
            "Chenyu You",
            "Manmohan Chandraker",
            "Ziyu Jiang"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21333",
        "abstract": "Controllable driving scene generation is critical for realistic and scalable autonomous driving simulation, yet existing approaches struggle to jointly achieve photorealism and precise control. We introduce HorizonForge, a unified framework that reconstructs scenes as editable Gaussian Splats and Meshes, enabling fine-grained 3D manipulation and language-driven vehicle insertion. Edits are rendered through a noise-aware video diffusion process that enforces spatial and temporal consistency, producing diverse scene variations in a single feed-forward pass without per-trajectory optimization. To standardize evaluation, we further propose HorizonSuite, a comprehensive benchmark spanning ego- and agent-level editing tasks such as trajectory modifications and object manipulation. Extensive experiments show that Gaussian-Mesh representation delivers substantially higher fidelity than alternative 3D representations, and that temporal priors from video diffusion are essential for coherent synthesis. Combining these findings, HorizonForge establishes a simple yet powerful paradigm for photorealistic, controllable driving simulation, achieving an 83.4% user-preference gain and a 25.19% FID improvement over the second best state-of-the-art method. Project page: https://horizonforge.github.io/ .",
        "tags": [
            "3D",
            "Diffusion"
        ]
    },
    {
        "id": "30",
        "title": "HiPPO Zoo: Explicit Memory Mechanisms for Interpretable State Space Models",
        "author": [
            "Jack Goffinet",
            "Casey Hanks",
            "David E. Carlson"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21340",
        "abstract": "Representing the past in a compressed, efficient, and informative manner is a central problem for systems trained on sequential data. The HiPPO framework, originally proposed by Gu & Dao et al., provides a principled approach to sequential compression by projecting signals onto orthogonal polynomial (OP) bases via structured linear ordinary differential equations. Subsequent works have embedded these dynamics in state space models (SSMs), where HiPPO structure serves as an initialization. Nonlinear successors of these SSM methods such as Mamba are state-of-the-art for many tasks with long-range dependencies, but the mechanisms by which they represent and prioritize history remain largely implicit. In this work, we revisit the HiPPO framework with the goal of making these mechanisms explicit. We show how polynomial representations of history can be extended to support capabilities of modern SSMs such as adaptive allocation of memory and associative memory while retaining direct interpretability in the OP basis. We introduce a unified framework comprising five such extensions, which we collectively refer to as a \"HiPPO zoo.\" Each extension exposes a specific modeling capability through an explicit, interpretable modification of the HiPPO framework. The resulting models adapt their memory online and train in streaming settings with efficient updates. We illustrate the behaviors and modeling advantages of these extensions through a range of synthetic sequence modeling tasks, demonstrating that capabilities typically associated with modern SSMs can be realized through explicit, interpretable polynomial memory structures.",
        "tags": [
            "Mamba",
            "SSMs"
        ]
    },
    {
        "id": "31",
        "title": "Alignment-Weighted DPO: A principled reasoning approach to improve safety alignment",
        "author": [
            "Mengxuan Hu",
            "Vivek V. Datla",
            "Anoop Kumar",
            "Zihan Guan",
            "Sheng Li",
            "Alfy Samuel",
            "Daben Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21346",
        "abstract": "Recent advances in alignment techniques such as Supervised Fine-Tuning (SFT), Reinforcement Learning from Human Feedback (RLHF), and Direct Preference Optimization (DPO) have improved the safety of large language models (LLMs). However, these LLMs remain vulnerable to jailbreak attacks that disguise harmful intent through indirect or deceptive phrasing. Using causal intervention, we empirically demonstrate that this vulnerability stems from shallow alignment mechanisms that lack deep reasoning, often rejecting harmful prompts without truly understanding why they are harmful. To mitigate this vulnerability, we propose enhancing alignment through reasoning-aware post-training. We construct and release a novel Chain-of-Thought (CoT) fine-tuning dataset that includes both utility-oriented and safety-critical prompts with step-by-step rationales. Fine-tuning on this dataset encourages models to produce principled refusals grounded in reasoning, outperforming standard SFT baselines. Furthermore, inspired by failure patterns in CoT fine-tuning, we introduce Alignment-Weighted DPO, which targets the most problematic parts of an output by assigning different preference weights to the reasoning and final-answer segments. This produces finer-grained, targeted updates than vanilla DPO and improves robustness to diverse jailbreak strategies. Extensive experiments across multiple safety and utility benchmarks show that our method consistently improves alignment robustness while maintaining overall model utility.",
        "tags": [
            "CoT",
            "DPO",
            "LLM",
            "RL",
            "RLHF"
        ]
    },
    {
        "id": "32",
        "title": "A Hierarchical Multi-Agent System for Autonomous Discovery in Geoscientific Data Archives",
        "author": [
            "Dmitrii Pantiukhin",
            "Ivan Kuznetsov",
            "Boris Shapkin",
            "Antonia Anna Jost",
            "Thomas Jung",
            "Nikolay Koldunov"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21351",
        "abstract": "The rapid accumulation of Earth science data has created a significant scalability challenge; while repositories like PANGAEA host vast collections of datasets, citation metrics indicate that a substantial portion remains underutilized, limiting data reusability. Here we present PANGAEA-GPT, a hierarchical multi-agent framework designed for autonomous data discovery and analysis. Unlike standard Large Language Model (LLM) wrappers, our architecture implements a centralized Supervisor-Worker topology with strict data-type-aware routing, sandboxed deterministic code execution, and self-correction via execution feedback, enabling agents to diagnose and resolve runtime errors. Through use-case scenarios spanning physical oceanography and ecology, we demonstrate the system's capacity to execute complex, multi-step workflows with minimal human intervention. This framework provides a methodology for querying and analyzing heterogeneous repository data through coordinated agent workflows.",
        "tags": [
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "33",
        "title": "Towards Controllable Video Synthesis of Routine and Rare OR Events",
        "author": [
            "Dominik Schneider",
            "Lalithkumar Seenivasan",
            "Sampath Rapuri",
            "Vishalroshan Anil",
            "Aiza Maksutova",
            "Yiqing Shen",
            "Jan Emily Mangulabnan",
            "Hao Ding",
            "Jose L. Porras",
            "Masaru Ishii",
            "Mathias Unberath"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21365",
        "abstract": "Purpose: Curating large-scale datasets of operating room (OR) workflow, encompassing rare, safety-critical, or atypical events, remains operationally and ethically challenging. This data bottleneck complicates the development of ambient intelligence for detecting, understanding, and mitigating rare or safety-critical events in the OR.\nMethods: This work presents an OR video diffusion framework that enables controlled synthesis of rare and safety-critical events. The framework integrates a geometric abstraction module, a conditioning module, and a fine-tuned diffusion model to first transform OR scenes into abstract geometric representations, then condition the synthesis process, and finally generate realistic OR event videos. Using this framework, we also curate a synthetic dataset to train and validate AI models for detecting near-misses of sterile-field violations.\nResults: In synthesizing routine OR events, our method outperforms off-the-shelf video diffusion baselines, achieving lower FVD/LPIPS and higher SSIM/PSNR in both in- and out-of-domain datasets. Through qualitative results, we illustrate its ability for controlled video synthesis of counterfactual events. An AI model trained and validated on the generated synthetic data achieved a RECALL of 70.13% in detecting near safety-critical events. Finally, we conduct an ablation study to quantify performance gains from key design choices.\nConclusion: Our solution enables controlled synthesis of routine and rare OR events from abstract geometric representations. Beyond demonstrating its capability to generate rare and safety-critical scenarios, we show its potential to support the development of ambient intelligence models.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "34",
        "title": "Black-Box Reliability Certification for AI Agents via Self-Consistency Sampling and Conformal Calibration",
        "author": [
            "Charafeddine Mouzouni"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21368",
        "abstract": "Given a black-box AI system and a task, at what confidence level can a practitioner trust the system's output? We answer with a reliability level -- a single number per system-task pair, derived from self-consistency sampling and conformal calibration, that serves as a black-box deployment gate with exact, finite-sample, distribution-free guarantees. Self-consistency sampling reduces uncertainty exponentially; conformal calibration guarantees correctness within 1/(n+1) of the target level, regardless of the system's errors -- made transparently visible through larger answer sets for harder questions. Weaker models earn lower reliability levels (not accuracy -- see Definition 2.4): GPT-4.1 earns 94.6% on GSM8K and 96.8% on TruthfulQA, while GPT-4.1-nano earns 89.8% on GSM8K and 66.5% on MMLU. We validate across five benchmarks, five models from three families, and both synthetic and real data. Conditional coverage on solvable items exceeds 0.93 across all configurations; sequential stopping reduces API costs by around 50%.",
        "tags": [
            "GPT"
        ]
    },
    {
        "id": "35",
        "title": "Interleaved Head Attention",
        "author": [
            "Sai Surya Duvvuri",
            "Chanakya Ekbote",
            "Rachit Bansal",
            "Rishabh Tiwari",
            "Devvrit Khatri",
            "David Brandfonbrener",
            "Paul Liang",
            "Inderjit Dhillon",
            "Manzil Zaheer"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21371",
        "abstract": "Multi-Head Attention (MHA) is the core computational primitive underlying modern Large Language Models (LLMs). However, MHA suffers from a fundamental linear scaling limitation: $H$ attention heads produce exactly $H$ independent attention matrices, with no communication between heads during attention computation. This becomes problematic for multi-step reasoning, where correct answers depend on aggregating evidence from multiple parts of the context and composing latent token-to-token relations over a chain of intermediate inferences. To address this, we propose Interleaved Head Attention (IHA), which enables cross-head mixing by constructing $P$ pseudo-heads per head (typically $P=H$), where each pseudo query/key/value is a learned linear combination of all $H$ original queries, keys and values respectively. Interactions between pseudo-query and pseudo-key heads induce up to $P^2$ attention patterns per head with modest parameter overhead $\\mathcal{O}(H^2P)$. We provide theory showing improved efficiency in terms of number of parameters on the synthetic Polynomial task (IHA uses $\\Theta(\\sqrt{k}n^2)$ parameters vs. $\\Theta(kn^2)$ for MHA) and on the synthetic order-sensitive CPM-3 task (IHA uses $\\lceil\\sqrt{N_{\\max}}\\rceil$ heads vs. $N_{\\max}$ for MHA). On real-world benchmarks, IHA improves Multi-Key retrieval on RULER by 10-20% (4k-16k) and, after fine-tuning for reasoning on OpenThoughts, improves GSM8K by 5.8% and MATH-500 by 2.8% (Majority Vote) over full attention.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "36",
        "title": "Beyond Subtokens: A Rich Character Embedding for Low-resource and Morphologically Complex Languages",
        "author": [
            "Felix Schneider",
            "Maria Gogolev",
            "Sven Sickert",
            "Joachim Denzler"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21377",
        "abstract": "Tokenization and sub-tokenization based models like word2vec, BERT and the GPTs are the state-of-the-art in natural language processing. Typically, these approaches have limitations with respect to their input representation. They fail to fully capture orthographic similarities and morphological variations, especially in highly inflected and under-resource languages. To mitigate this problem, we propose to computes word vectors directly from character strings, integrating both semantic and syntactic information. We denote this transformer-based approach Rich Character Embeddings (RCE). Furthermore, we propose a hybrid model that combines transformer and convolutional mechanisms. Both vector representations can be used as a drop-in replacement for dictionary- and subtoken-based word embeddings in existing model architectures. It has the potential to improve performance for both large context-based language models like BERT and small models like word2vec for under-resourced and morphologically rich languages. We evaluate our approach on various tasks like the SWAG, declension prediction for inflected languages, metaphor and chiasmus detection for various languages. Our experiments show that it outperforms traditional token-based approaches on limited data using OddOneOut and TopK metrics.",
        "tags": [
            "BERT",
            "Detection",
            "Transformer"
        ]
    },
    {
        "id": "37",
        "title": "MemoPhishAgent: Memory-Augmented Multi-Modal LLM Agent for Phishing URL Detection",
        "author": [
            "Xuan Chen",
            "Hao Liu",
            "Yuan Tao",
            "Mehran Kafai",
            "Piotr Habas",
            "Xiangyu Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21394",
        "abstract": "Traditional phishing website detection relies on static heuristics or reference lists, which lag behind rapidly evolving attacks. While recent systems incorporate large language models (LLMs), they are still prompt-based, deterministic pipelines that underutilize reasoning capability. We present MemoPhishAgent (MPA), a memory-augmented multi-modal LLM agent that dynamically orchestrates phishing-specific tools and leverages episodic memories of past reasoning trajectories to guide decisions on recurring and novel threats. On two public datasets, MPA outperforms three state-of-the-art (SOTA) baselines, improving recall by 13.6%. To better reflect realistic, user-facing phishing detection performance, we further evaluate MPA on a benchmark of real-world suspicious URLs actively crawled from five social media platforms, where it improves recall by 20%. Detailed analysis shows episodic memory contributes up to 27% recall gain without introducing additional computational overhead. The ablation study confirms the necessity of the agent-based approach compared to prompt-based baselines and validates the effectiveness of our tool design. Finally, MPA is deployed in production, processing 60K targeted high-risk URLs weekly, and achieving 91.44% recall, providing proactive protection for millions of customers. Together, our results show that combining multi-modal reasoning with episodic memory yields robust phishing detection in realistic user-exposure settings.",
        "tags": [
            "Detection",
            "LLM"
        ]
    },
    {
        "id": "38",
        "title": "MMLoP: Multi-Modal Low-Rank Prompting for Efficient Vision-Language Adaptation",
        "author": [
            "Sajjad Ghiasvand",
            "Haniyeh Ehsani Oskouie",
            "Mahnoosh Alizadeh",
            "Ramtin Pedarsani"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21397",
        "abstract": "Prompt learning has become a dominant paradigm for adapting vision-language models (VLMs) such as CLIP to downstream tasks without modifying pretrained weights. While extending prompts to both vision and text encoders across multiple transformer layers significantly boosts performance, it dramatically increases the number of trainable parameters, with state-of-the-art methods requiring millions of parameters and abandoning the parameter efficiency that makes prompt tuning attractive. In this work, we propose \\textbf{MMLoP} (\\textbf{M}ulti-\\textbf{M}odal \\textbf{Lo}w-Rank \\textbf{P}rompting), a framework that achieves deep multi-modal prompting with only \\textbf{11.5K trainable parameters}, comparable to early text-only methods like CoOp. MMLoP parameterizes vision and text prompts at each transformer layer through a low-rank factorization, which serves as an implicit regularizer against overfitting on few-shot training data. To further close the accuracy gap with state-of-the-art methods, we introduce three complementary components: a self-regulating consistency loss that anchors prompted representations to frozen zero-shot CLIP features at both the feature and logit levels, a uniform drift correction that removes the global embedding shift induced by prompt tuning to preserve class-discriminative structure, and a shared up-projection that couples vision and text prompts through a common low-rank factor to enforce cross-modal alignment. Extensive experiments across three benchmarks and 11 diverse datasets demonstrate that MMLoP achieves a highly favorable accuracy-efficiency tradeoff, outperforming the majority of existing methods including those with orders of magnitude more parameters, while achieving a harmonic mean of 79.70\\% on base-to-novel generalization.",
        "tags": [
            "CLIP",
            "Transformer",
            "VLM"
        ]
    },
    {
        "id": "39",
        "title": "FlowFixer: Towards Detail-Preserving Subject-Driven Generation",
        "author": [
            "Jinyoung Jun",
            "Won-Dong Jang",
            "Wenbin Ouyang",
            "Raghudeep Gadde",
            "Jungbeom Lee"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21402",
        "abstract": "We present FlowFixer, a refinement framework for subject-driven generation (SDG) that restores fine details lost during generation caused by changes in scale and perspective of a subject. FlowFixer proposes direct image-to-image translation from visual references, avoiding ambiguities in language prompts. To enable image-to-image training, we introduce a one-step denoising scheme to generate self-supervised training data, which automatically removes high-frequency details while preserving global structure, effectively simulating real-world SDG errors. We further propose a keypoint matching-based metric to properly assess fidelity in details beyond semantic similarities usually measured by CLIP or DINO. Experimental results demonstrate that FlowFixer outperforms state-of-the-art SDG methods in both qualitative and quantitative evaluations, setting a new benchmark for high-fidelity subject-driven generation.",
        "tags": [
            "CLIP"
        ]
    },
    {
        "id": "40",
        "title": "Exploring Vision-Language Models for Open-Vocabulary Zero-Shot Action Segmentation",
        "author": [
            "Asim Unmesh",
            "Kaki Ramesh",
            "Mayank Patel",
            "Rahul Jain",
            "Karthik Ramani"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21406",
        "abstract": "Temporal Action Segmentation (TAS) requires dividing videos into action segments, yet the vast space of activities and alternative breakdowns makes collecting comprehensive datasets infeasible. Existing methods remain limited to closed vocabularies and fixed label sets. In this work, we explore the largely unexplored problem of Open-Vocabulary Zero-Shot Temporal Action Segmentation (OVTAS) by leveraging the strong zero-shot capabilities of Vision-Language Models (VLMs). We introduce a training-free pipeline that follows a segmentation-by-classification design: Frame-Action Embedding Similarity (FAES) matches video frames to candidate action labels, and Similarity-Matrix Temporal Segmentation (SMTS) enforces temporal consistency. Beyond proposing OVTAS, we present a systematic study across 14 diverse VLMs, providing the first broad analysis of their suitability for open-vocabulary action segmentation. Experiments on standard benchmarks show that OVTAS achieves strong results without task-specific supervision, underscoring the potential of VLMs for structured temporal understanding.",
        "tags": [
            "Segmentation",
            "VLM"
        ]
    },
    {
        "id": "41",
        "title": "Benchmarking State Space Models, Transformers, and Recurrent Networks for US Grid Forecasting",
        "author": [
            "Sunki Hong",
            "Jisoo Lee",
            "Yuanyuan Shi"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21415",
        "abstract": "Selecting the right deep learning model for power grid forecasting is challenging, as performance heavily depends on the data available to the operator. This paper presents a comprehensive benchmark of five modern neural architectures: two state space models (PowerMamba, S-Mamba), two Transformers (iTransformer, PatchTST), and a traditional LSTM. We evaluate these models on hourly electricity demand across six diverse US power grids for forecast windows between 24 and 168 hours. To ensure a fair comparison, we adapt each model with specialized temporal processing and a modular layer that cleanly integrates weather covariates. Our results reveal that there is no single best model for all situations. When forecasting using only historical load, PatchTST and the state space models provide the highest accuracy. However, when explicit weather data is added to the inputs, the rankings reverse: iTransformer improves its accuracy three times more efficiently than PatchTST. By controlling for model size, we confirm that this advantage stems from the architecture's inherent ability to mix information across different variables. Extending our evaluation to solar generation, wind power, and wholesale prices further demonstrates that model rankings depend on the forecast task: PatchTST excels on highly rhythmic signals like solar, while state space models are better suited for the chaotic fluctuations of wind and price. Ultimately, this benchmark provides grid operators with actionable guidelines for selecting the optimal forecasting architecture based on their specific data environments.",
        "tags": [
            "Mamba",
            "SSMs"
        ]
    },
    {
        "id": "42",
        "title": "Overconfident Errors Need Stronger Correction: Asymmetric Confidence Penalties for Reinforcement Learning",
        "author": [
            "Yuanda Xu",
            "Hejian Sang",
            "Zhengze Zhou",
            "Ran He",
            "Zhipeng Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21420",
        "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR) has become the leading paradigm for enhancing reasoning in Large Language Models (LLMs). However, standard RLVR algorithms suffer from a well-documented pathology: while they improve Pass@1 accuracy through sharpened sampling, they simultaneously narrow the model's reasoning boundary and reduce generation diversity. We identify a root cause that existing methods overlook: the uniform penalization of errors. Current approaches -- whether data-filtering methods that select prompts by difficulty, or advantage normalization schemes -- treat all incorrect rollouts within a group identically. We show that this uniformity allows overconfident errors (incorrect reasoning paths that the RL process has spuriously reinforced) to persist and monopolize probability mass, ultimately suppressing valid exploratory trajectories. To address this, we propose the Asymmetric Confidence-aware Error Penalty (ACE). ACE introduces a per-rollout confidence shift metric, c_i = log(pi_theta(y_i|x) / pi_ref(y_i|x)), to dynamically modulate negative advantages. Theoretically, we demonstrate that ACE's gradient can be decomposed into the gradient of a selective regularizer restricted to overconfident errors, plus a well-characterized residual that partially moderates the regularizer's strength. We conduct extensive experiments fine-tuning Qwen2.5-Math-7B, Qwen3-8B-Base, and Llama-3.1-8B-Instruct on the DAPO-Math-17K dataset using GRPO and DAPO within the VERL framework. Evaluated on MATH-500 and AIME 2025, ACE composes seamlessly with existing methods and consistently improves the full Pass@k spectrum across all three model families and benchmarks.",
        "tags": [
            "GRPO",
            "LLM",
            "LLaMA",
            "RL"
        ]
    },
    {
        "id": "43",
        "title": "ECHOSAT: Estimating Canopy Height Over Space And Time",
        "author": [
            "Jan Pauls",
            "Karsten SchrÃ¶dter",
            "Sven Ligensa",
            "Martin Schwartz",
            "Berkant Turan",
            "Max Zimmer",
            "Sassan Saatchi",
            "Sebastian Pokutta",
            "Philippe Ciais",
            "Fabian Gieseke"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21421",
        "abstract": "Forest monitoring is critical for climate change mitigation. However, existing global tree height maps provide only static snapshots and do not capture temporal forest dynamics, which are essential for accurate carbon accounting. We introduce ECHOSAT, a global and temporally consistent tree height map at 10 m resolution spanning multiple years. To this end, we resort to multi-sensor satellite data to train a specialized vision transformer model, which performs pixel-level temporal regression. A self-supervised growth loss regularizes the predictions to follow growth curves that are in line with natural tree development, including gradual height increases over time, but also abrupt declines due to forest loss events such as fires. Our experimental evaluation shows that our model improves state-of-the-art accuracies in the context of single-year predictions. We also provide the first global-scale height map that accurately quantifies tree growth and disturbances over time. We expect ECHOSAT to advance global efforts in carbon monitoring and disturbance assessment. The maps can be accessed at https://github.com/ai4forest/echosat.",
        "tags": [
            "Transformer",
            "ViT"
        ]
    },
    {
        "id": "44",
        "title": "On the Structural Non-Preservation of Epistemic Behaviour under Policy Transformation",
        "author": [
            "Alexander Galozy"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21424",
        "abstract": "Reinforcement learning (RL) agents under partial observability often condition actions on internally accumulated information such as memory or inferred latent context. We formalise such information-conditioned interaction patterns as behavioural dependency: variation in action selection with respect to internal information under fixed observations. This induces a probe-relative notion of $\\epsilon$-behavioural equivalence and a within-policy behavioural distance that quantifies probe sensitivity. We establish three structural results. First, the set of policies exhibiting non-trivial behavioural dependency is not closed under convex aggregation. Second, behavioural distance contracts under convex combination. Third, we prove a sufficient local condition under which gradient ascent on a skewed mixture objective decreases behavioural distance when a dominant-mode gradient aligns with the direction of steepest contraction. Minimal bandit and partially observable gridworld experiments provide controlled witnesses of these mechanisms. In the examined settings, behavioural distance decreases under convex aggregation and under continued optimisation with skewed latent priors, and in these experiments it precedes degradation under latent prior shift. These results identify structural conditions under which probe-conditioned behavioural separation is not preserved under common policy transformations.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "45",
        "title": "Provably Safe Generative Sampling with Constricting Barrier Functions",
        "author": [
            "Darshan Gadginmath",
            "Ahmed Allibhoy",
            "Fabio Pasqualetti"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21429",
        "abstract": "Flow-based generative models, such as diffusion models and flow matching models, have achieved remarkable success in learning complex data distributions. However, a critical gap remains for their deployment in safety-critical domains: the lack of formal guarantees that generated samples will satisfy hard constraints. We address this by proposing a safety filtering framework that acts as an online shield for any pre-trained generative model. Our key insight is to cooperate with the generative process rather than override it. We define a constricting safety tube that is relaxed at the initial noise distribution and progressively tightens to the target safe set at the final data distribution, mirroring the coarse-to-fine structure of the generative process itself. By characterizing this tube via Control Barrier Functions (CBFs), we synthesize a feedback control input through a convex Quadratic Program (QP) at each sampling step. As the tube is loosest when noise is high and intervention is cheapest in terms of control energy, most constraint enforcement occurs when it least disrupts the model's learned structure. We prove that this mechanism guarantees safe sampling while minimizing the distributional shift from the original model at each sampling step, as quantified by the KL divergence. Our framework applies to any pre-trained flow-based generative scheme requiring no retraining or architectural modifications. We validate the approach across constrained image generation, physically-consistent trajectory sampling, and safe robotic manipulation policies, achieving 100% constraint satisfaction while preserving semantic fidelity.",
        "tags": [
            "Diffusion",
            "Flow Matching"
        ]
    },
    {
        "id": "46",
        "title": "Synergizing Understanding and Generation with Interleaved Analyzing-Drafting Thinking",
        "author": [
            "Shengqiong Wu",
            "Bobo Li",
            "Xinkai Wang",
            "Xiangtai Li",
            "Lei Cui",
            "Furu Wei",
            "Shuicheng Yan",
            "Hao Fei",
            "Tat-seng Chua"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21435",
        "abstract": "Unified Vision-Language Models (UVLMs) aim to advance multimodal learning by supporting both understanding and generation within a single framework. However, existing approaches largely focus on architectural unification while overlooking the need for explicit interaction between the two capabilities during task solving. As a result, current models treat understanding and generation as parallel skills rather than synergistic processes. To achieve real synergy, we introduce the interleaved Analyzing-Drafting problem-solving loop (AD-Loop), a new think paradigm that dynamically alternates between analytic and drafting operations. By interleaving textual thoughts with visual thoughts, AD-Loop enables models to iteratively refine both comprehension and outputs, fostering genuine synergy. To train this mechanism, we design a two-stage strategy: supervised learning on interleaved thought data to initialize alternation, followed by reinforcement learning to promote adaptive and autonomous control. Extensive experiments demonstrate that AD-Loop consistently improves performance across standard benchmarks for both understanding and generation, with strong transferability to various UVLMs architectures. Visual analyses further validate the effectiveness of implicit visual thoughts. These results highlight AD-Loop as a principled and broadly applicable strategy for synergizing comprehension and creation. The project page is at https://sqwu.top/AD-Loop.",
        "tags": [
            "RL",
            "VLM"
        ]
    },
    {
        "id": "47",
        "title": "Causal Decoding for Hallucination-Resistant Multimodal Large Language Models",
        "author": [
            "Shiwei Tan",
            "Hengyi Wang",
            "Weiyi Qin",
            "Qi Xu",
            "Zhigang Hua",
            "Hao Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21441",
        "abstract": "Multimodal Large Language Models (MLLMs) deliver detailed responses on vision-language tasks, yet remain susceptible to object hallucination (introducing objects not present in the image), undermining reliability in practice. Prior efforts often rely on heuristic penalties, post-hoc correction, or generic decoding tweaks, which do not directly intervene in the mechanisms that trigger object hallucination and thus yield limited gains. To address this challenge, we propose a causal decoding framework that applies targeted causal interventions during generation to curb spurious object mentions. By reshaping the decoding dynamics to attenuate spurious dependencies, our approach reduces false object tokens while maintaining descriptive quality. Across captioning and QA benchmarks, our framework substantially lowers object-hallucination rates and achieves state-of-the-art faithfulness without degrading overall output quality.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "48",
        "title": "MINAR: Mechanistic Interpretability for Neural Algorithmic Reasoning",
        "author": [
            "Jesse He",
            "Helen Jenne",
            "Max Vargas",
            "Davis Brown",
            "Gal Mishne",
            "Yusu Wang",
            "Henry Kvinge"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21442",
        "abstract": "The recent field of neural algorithmic reasoning (NAR) studies the ability of graph neural networks (GNNs) to emulate classical algorithms like Bellman-Ford, a phenomenon known as algorithmic alignment. At the same time, recent advances in large language models (LLMs) have spawned the study of mechanistic interpretability, which aims to identify granular model components like circuits that perform specific computations. In this work, we introduce Mechanistic Interpretability for Neural Algorithmic Reasoning (MINAR), an efficient circuit discovery toolbox that adapts attribution patching methods from mechanistic interpretability to the GNN setting. We show through two case studies that MINAR recovers faithful neuron-level circuits from GNNs trained on algorithmic tasks. Our study sheds new light on the process of circuit formation and pruning during training, as well as giving new insight into how GNNs trained to perform multiple tasks in parallel reuse circuit components for related tasks. Our code is available at https://github.com/pnnl/MINAR.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "49",
        "title": "Adversarial Intent is a Latent Variable: Stateful Trust Inference for Securing Multimodal Agentic RAG",
        "author": [
            "Inderjeet Singh",
            "Vikas Pahuja",
            "Aishvariya Priya Rathina Sabapathy",
            "Chiara Picardi",
            "Amit Giloni",
            "Roman Vainshtein",
            "AndrÃ©s Murillo",
            "Hisashi Kojima",
            "Motoyoshi Sekiya",
            "Yuki Unno",
            "Junichi Suga"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21447",
        "abstract": "Current stateless defences for multimodal agentic RAG fail to detect adversarial strategies that distribute malicious semantics across retrieval, planning, and generation components. We formulate this security challenge as a Partially Observable Markov Decision Process (POMDP), where adversarial intent is a latent variable inferred from noisy multi-stage observations. We introduce MMA-RAG^T, an inference-time control framework governed by a Modular Trust Agent (MTA) that maintains an approximate belief state via structured LLM reasoning. Operating as a model-agnostic overlay, MMA-RAGT mediates a configurable set of internal checkpoints to enforce stateful defence-in-depth. Extensive evaluation on 43,774 instances demonstrates a 6.50x average reduction factor in Attack Success Rate relative to undefended baselines, with negligible utility cost. Crucially, a factorial ablation validates our theoretical bounds: while statefulness and spatial coverage are individually necessary (26.4 pp and 13.6 pp gains respectively), stateless multi-point intervention can yield zero marginal benefit under homogeneous stateless filtering when checkpoint detections are perfectly correlated.",
        "tags": [
            "LLM",
            "RAG"
        ]
    },
    {
        "id": "50",
        "title": "When Learning Hurts: Fixed-Pole RNN for Real-Time Online Training",
        "author": [
            "Alexander Morgan",
            "Ummay Sumaya Khan",
            "Lingjia Liu",
            "Lizhong Zheng"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21454",
        "abstract": "Recurrent neural networks (RNNs) can be interpreted as discrete-time state-space models, where the state evolution corresponds to an infinite-impulse-response (IIR) filtering operation governed by both feedforward weights and recurrent poles. While, in principle, all parameters including pole locations can be optimized via backpropagation through time (BPTT), such joint learning incurs substantial computational overhead and is often impractical for applications with limited training data. Echo state networks (ESNs) mitigate this limitation by fixing the recurrent dynamics and training only a linear readout, enabling efficient and stable online adaptation. In this work, we analytically and empirically examine why learning recurrent poles does not provide tangible benefits in data-constrained, real-time learning scenarios. Our analysis shows that pole learning renders the weight optimization problem highly non-convex, requiring significantly more training samples and iterations for gradient-based methods to converge to meaningful solutions. Empirically, we observe that for complex-valued data, gradient descent frequently exhibits prolonged plateaus, and advanced optimizers offer limited improvement. In contrast, fixed-pole architectures induce stable and well-conditioned state representations even with limited training data. Numerical results demonstrate that fixed-pole networks achieve superior performance with lower training complexity, making them more suitable for online real-time tasks.",
        "tags": [
            "RNN",
            "SSMs"
        ]
    },
    {
        "id": "51",
        "title": "Revisiting Text Ranking in Deep Research",
        "author": [
            "Chuan Meng",
            "Litu Ou",
            "Sean MacAvaney",
            "Jeff Dalton"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21456",
        "abstract": "Deep research has emerged as an important task that aims to address hard queries through extensive open-web exploration. To tackle it, most prior work equips large language model (LLM)-based agents with opaque web search APIs, enabling agents to iteratively issue search queries, retrieve external evidence, and reason over it. Despite search's essential role in deep research, black-box web search APIs hinder systematic analysis of search components, leaving the behaviour of established text ranking methods in deep research largely unclear. To fill this gap, we reproduce a selection of key findings and best practices for IR text ranking methods in the deep research setting. In particular, we examine their effectiveness from three perspectives: (i) retrieval units (documents vs. passages), (ii) pipeline configurations (different retrievers, re-rankers, and re-ranking depths), and (iii) query characteristics (the mismatch between agent-issued queries and the training queries of text rankers). We perform experiments on BrowseComp-Plus, a deep research dataset with a fixed corpus, evaluating 2 open-source agents, 5 retrievers, and 3 re-rankers across diverse setups. We find that agent-issued queries typically follow web-search-style syntax (e.g., quoted exact matches), favouring lexical, learned sparse, and multi-vector retrievers; passage-level units are more efficient under limited context windows, and avoid the difficulties of document length normalisation in lexical retrieval; re-ranking is highly effective; translating agent-issued queries into natural-language questions significantly bridges the query mismatch.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "52",
        "title": "VecGlypher: Unified Vector Glyph Generation with Language Models",
        "author": [
            "Xiaoke Huang",
            "Bhavul Gauri",
            "Kam Woh Ng",
            "Tony Ng",
            "Mengmeng Xu",
            "Zhiheng Liu",
            "Weiming Ren",
            "Zhaochong An",
            "Zijian Zhou",
            "Haonan Qiu",
            "Yuyin Zhou",
            "Sen He",
            "Ziheng Wang",
            "Tao Xiang",
            "Xiao Han"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21461",
        "abstract": "Vector glyphs are the atomic units of digital typography, yet most learning-based pipelines still depend on carefully curated exemplar sheets and raster-to-vector postprocessing, which limits accessibility and editability. We introduce VecGlypher, a single multimodal language model that generates high-fidelity vector glyphs directly from text descriptions or image exemplars. Given a style prompt, optional reference glyph images, and a target character, VecGlypher autoregressively emits SVG path tokens, avoiding raster intermediates and producing editable, watertight outlines in one pass. A typography-aware data and training recipe makes this possible: (i) a large-scale continuation stage on 39K noisy Envato fonts to master SVG syntax and long-horizon geometry, followed by (ii) post-training on 2.5K expert-annotated Google Fonts with descriptive tags and exemplars to align language and imagery with geometry; preprocessing normalizes coordinate frames, canonicalizes paths, de-duplicates families, and quantizes coordinates for stable long-sequence decoding. On cross-family OOD evaluation, VecGlypher substantially outperforms both general-purpose LLMs and specialized vector-font baselines for text-only generation, while image-referenced generation reaches a state-of-the-art performance, with marked gains over DeepVecFont-v2 and DualVector. Ablations show that model scale and the two-stage recipe are critical and that absolute-coordinate serialization yields the best geometry. VecGlypher lowers the barrier to font creation by letting users design with words or exemplars, and provides a scalable foundation for future multimodal design tools.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "53",
        "title": "D-Flow SGLD: Source-Space Posterior Sampling for Scientific Inverse Problems with Flow Matching",
        "author": [
            "Meet Hemant Parikh",
            "Yaqin Chen",
            "Jian-Xun Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21469",
        "abstract": "Data assimilation and scientific inverse problems require reconstructing high-dimensional physical states from sparse and noisy observations, ideally with uncertainty-aware posterior samples that remain faithful to learned priors and governing physics. While training-free conditional generation is well developed for diffusion models, corresponding conditioning and posterior sampling strategies for Flow Matching (FM) priors remain comparatively under-explored, especially on scientific benchmarks where fidelity must be assessed beyond measurement misfit. In this work, we study training-free conditional generation for scientific inverse problems under FM priors and organize existing inference-time strategies by where measurement information is injected: (i) guided transport dynamics that perturb sampling trajectories using likelihood information, and (ii) source-distribution inference that performs posterior inference over the source variable while keeping the learned transport fixed. Building on the latter, we propose D-Flow SGLD, a source-space posterior sampling method that augments differentiable source inference with preconditioned stochastic gradient Langevin dynamics, enabling scalable exploration of the source posterior induced by new measurement operators without retraining the prior or modifying the learned FM dynamics. We benchmark representative methods from both families on a hierarchy of problems: 2D toy posteriors, chaotic Kuramoto-Sivashinsky trajectories, and wall-bounded turbulence reconstruction. Across these settings, we quantify trade-offs among measurement assimilation, posterior diversity, and physics/statistics fidelity, and establish D-Flow SGLD as a practical FM-compatible posterior sampler for scientific inverse problems.",
        "tags": [
            "Diffusion",
            "Flow Matching"
        ]
    },
    {
        "id": "54",
        "title": "The Design Space of Tri-Modal Masked Diffusion Models",
        "author": [
            "Louis Bethune",
            "Victor Turrisi",
            "Bruno Kacper Mlodozeniec",
            "Pau Rodriguez Lopez",
            "Lokesh Boominathan",
            "Nikhil Bhendawade",
            "Amitis Shidani",
            "Joris Pelemans",
            "Theo X. Olausson",
            "Devon Hjelm",
            "Paul Dixon",
            "Joao Monteiro",
            "Pierre Ablin",
            "Vishnu Banna",
            "Arno Blaas",
            "Nick Henderson",
            "Kari Noriy",
            "Dan Busbridge",
            "Josh Susskind",
            "Marco Cuturi",
            "Irina Belousova",
            "Luca Zappella",
            "Russ Webb",
            "Jason Ramapuram"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21472",
        "abstract": "Discrete diffusion models have emerged as strong alternatives to autoregressive language models, with recent work initializing and fine-tuning a base unimodal model for bimodal generation. Diverging from previous approaches, we introduce the first tri-modal masked diffusion model pretrained from scratch on text, image-text, and audio-text data. We systematically analyze multimodal scaling laws, modality mixing ratios, noise schedules, and batch-size effects, and we provide optimized inference sampling defaults. Our batch-size analysis yields a novel stochastic differential equation (SDE)-based reparameterization that eliminates the need for tuning the optimal batch size as reported in recent work. This reparameterization decouples the physical batch size, often chosen based on compute constraints (GPU saturation, FLOP efficiency, wall-clock time), from the logical batch size, chosen to balance gradient variance during stochastic optimization. Finally, we pretrain a preliminary 3B-parameter tri-modal model on 6.4T tokens, demonstrating the capabilities of a unified design and achieving strong results in text generation, text-to-image tasks, and text-to-speech tasks. Our work represents the largest-scale systematic open study of multimodal discrete diffusion models conducted to date, providing insights into scaling behaviors across multiple modalities.",
        "tags": [
            "Diffusion",
            "SDE",
            "Text-to-Image"
        ]
    },
    {
        "id": "55",
        "title": "Pancake: Hierarchical Memory System for Multi-Agent LLM Serving",
        "author": [
            "Zhengding Hu",
            "Zaifeng Pan",
            "Prabhleen Kaur",
            "Vibha Murthy",
            "Zhongkai Yu",
            "Yue Guan",
            "Zhen Wang",
            "Steven Swanson",
            "Yufei Ding"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21477",
        "abstract": "In this work, we identify and address the core challenges of agentic memory management in LLM serving, where large-scale storage, frequent updates, and multiple coexisting agents jointly introduce complex and high-cost approximate nearest neighbor (ANN) searching problems. We present Pancake, a multi-tier agentic memory system that unifies three key techniques: (i) multi-level index caching for single agents, (ii) coordinated index management across multiple agents, and (iii) collaborative GPU-CPU acceleration. Pancake exposes easy-to-use interface that can be integrated into memory-based agents like Mem-GPT, and is compatible with agentic frameworks such as LangChain and LlamaIndex. Experiments on realistic agent workloads show that Pancake substantially outperforms existing frameworks, achieving more than 4.29x end-to-end throughput improvement.",
        "tags": [
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "56",
        "title": "Evaluating the Usage of African-American Vernacular English in Large Language Models",
        "author": [
            "Deja Dunlap",
            "R. Thomas McCoy"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21485",
        "abstract": "In AI, most evaluations of natural language understanding tasks are conducted in standardized dialects such as Standard American English (SAE). In this work, we investigate how accurately large language models (LLMs) represent African American Vernacular English (AAVE). We analyze three LLMs to compare their usage of AAVE to the usage of humans who natively speak AAVE. We first analyzed interviews from the Corpus of Regional African American Language and TwitterAAE to identify the typical contexts where people use AAVE grammatical features such as ain't. We then prompted the LLMs to produce text in AAVE and compared the model-generated text to human usage patterns. We find that, in many cases, there are substantial differences between AAVE usage in LLMs and humans: LLMs usually underuse and misuse grammatical features characteristic of AAVE. Furthermore, through sentiment analysis and manual inspection, we found that the models replicated stereotypes about African Americans. These results highlight the need for more diversity in training data and the incorporation of fairness methods to mitigate the perpetuation of stereotypes.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "57",
        "title": "StoryComposerAI: Supporting Human-AI Story Co-Creation Through Decomposition and Linking",
        "author": [
            "Shuo Niu",
            "Dylan Clements",
            "Marina Margalit Nemanov",
            "Hyungsin Kim"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21486",
        "abstract": "GenAI's ability to produce text and images is increasingly incorporated into human-AI co-creation tasks such as storytelling and video editing. However, integrating GenAI into these tasks requires enabling users to retain control over editing individual story elements while ensuring that generated visuals remain coherent with the storyline and consistent across multiple AI-generated outputs. This work examines a paradigm of creative decomposition and linking, which allows creators to clearly communicate creative intent by prompting GenAI to tailor specific story elements, such as storylines, personas, locations, and scenes, while maintaining coherence among them. We implement and evaluate StoryComposerAI, a system that exemplifies this paradigm for enhancing users' sense of control and content consistency in human-AI co-creation of digital stories.",
        "tags": [
            "Video Editing"
        ]
    },
    {
        "id": "58",
        "title": "GradAlign: Gradient-Aligned Data Selection for LLM Reinforcement Learning",
        "author": [
            "Ningyuan Yang",
            "Weihua Du",
            "Weiwei Sun",
            "Sean Welleck",
            "Yiming Yang"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21492",
        "abstract": "Reinforcement learning (RL) has become a central post-training paradigm for large language models (LLMs), but its performance is highly sensitive to the quality of training problems. This sensitivity stems from the non-stationarity of RL: rollouts are generated by an evolving policy, and learning is shaped by exploration and reward feedback, unlike supervised fine-tuning (SFT) with fixed trajectories. As a result, prior work often relies on manual curation or simple heuristic filters (e.g., accuracy), which can admit incorrect or low-utility problems. We propose GradAlign, a gradient-aligned data selection method for LLM reinforcement learning that uses a small, trusted validation set to prioritize training problems whose policy gradients align with validation gradients, yielding an adaptive curriculum. We evaluate GradAlign across three challenging data regimes: unreliable reward signals, distribution imbalance, and low-utility training corpus, showing that GradAlign consistently outperforms existing baselines, underscoring the importance of directional gradient signals in navigating non-stationary policy optimization and yielding more stable training and improved final performance. We release our implementation at https://github.com/StigLidu/GradAlign",
        "tags": [
            "LLM",
            "RL"
        ]
    },
    {
        "id": "59",
        "title": "Beyond Refusal: Probing the Limits of Agentic Self-Correction for Semantic Sensitive Information",
        "author": [
            "Umid Suleymanov",
            "Zaur Rajabov",
            "Emil Mirzazada",
            "Murat Kantarcioglu"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21496",
        "abstract": "While defenses for structured PII are mature, Large Language Models (LLMs) pose a new threat: Semantic Sensitive Information (SemSI), where models infer sensitive identity attributes, generate reputation-harmful content, or hallucinate potentially wrong information. The capacity of LLMs to self-regulate these complex, context-dependent sensitive information leaks without destroying utility remains an open scientific question. To address this, we introduce SemSIEdit, an inference-time framework where an agentic \"Editor\" iteratively critiques and rewrites sensitive spans to preserve narrative flow rather than simply refusing to answer. Our analysis reveals a Privacy-Utility Pareto Frontier, where this agentic rewriting reduces leakage by 34.6% across all three SemSI categories while incurring a marginal utility loss of 9.8%. We also uncover a Scale-Dependent Safety Divergence: large reasoning models (e.g., GPT-5) achieve safety through constructive expansion (adding nuance), whereas capacity-constrained models revert to destructive truncation (deleting text). Finally, we identify a Reasoning Paradox: while inference-time reasoning increases baseline risk by enabling the model to make deeper sensitive inferences, it simultaneously empowers the defense to execute safe rewrites.",
        "tags": [
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "60",
        "title": "See It, Say It, Sorted: An Iterative Training-Free Framework for Visually-Grounded Multimodal Reasoning in LVLMs",
        "author": [
            "Yongchang Zhang",
            "Xianzheng Ma",
            "Tianyi Liu",
            "Guangquan Zhou",
            "Yang Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21497",
        "abstract": "Recent large vision-language models (LVLMs) have demonstrated impressive reasoning ability by generating long chain-of-thought (CoT) responses. However, CoT reasoning in multimodal contexts is highly vulnerable to visual hallucination propagation: once an intermediate reasoning step becomes inconsistent with the visual evidence, subsequent steps-even if logically valid-can still lead to incorrect final answers. Existing solutions attempt to mitigate this issue by training models to \"think with images\" via reinforcement learning (RL). While effective, these methods are costly, model-specific, and difficult to generalize across architectures. Differently, we present a lightweight method that bypasses RL training and provides an iterative, training-free, plug-and-play framework for visually-grounded multimodal reasoning. Our key idea is to supervise each reasoning step at test time with visual evidence, ensuring that every decoded token is justified by corresponding visual cues. Concretely, we construct a textual visual-evidence pool that guides the model's reasoning generation. When existing evidence is insufficient, a visual decider module dynamically extracts additional relevant evidence from the image based on the ongoing reasoning context, expanding the pool until the model achieves sufficient visual certainty to terminate reasoning and produce the final answer. Extensive experiments on multiple LVLM backbones and benchmarks demonstrate the effectiveness of our approach. Our method achieves 16.5%-29.5% improvements on TreeBench and 13.7% RH-AUC gains on RH-Bench, substantially reducing hallucination rates while improving reasoning accuracy without additional training.",
        "tags": [
            "CoT",
            "RL",
            "VLM"
        ]
    },
    {
        "id": "61",
        "title": "Training Generalizable Collaborative Agents via Strategic Risk Aversion",
        "author": [
            "Chengrui Qu",
            "Yizhou Zhang",
            "Nicholas Lanzetti",
            "Eric Mazumdar"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21515",
        "abstract": "Many emerging agentic paradigms require agents to collaborate with one another (or people) to achieve shared goals. Unfortunately, existing approaches to learning policies for such collaborative problems produce brittle solutions that fail when paired with new partners. We attribute these failures to a combination of free-riding during training and a lack of strategic robustness. To address these problems, we study the concept of strategic risk aversion and interpret it as a principled inductive bias for generalizable cooperation with unseen partners. While strategically risk-averse players are robust to deviations in their partner's behavior by design, we show that, in collaborative games, they also (1) can have better equilibrium outcomes than those at classical game-theoretic concepts like Nash, and (2) exhibit less or no free-riding. Inspired by these insights, we develop a multi-agent reinforcement learning (MARL) algorithm that integrates strategic risk aversion into standard policy optimization methods. Our empirical results across collaborative benchmarks (including an LLM collaboration task) validate our theory and demonstrate that our approach consistently achieves reliable collaboration with heterogeneous and previously unseen partners across collaborative tasks.",
        "tags": [
            "LLM",
            "RL"
        ]
    },
    {
        "id": "62",
        "title": "ARLArena: A Unified Framework for Stable Agentic Reinforcement Learning",
        "author": [
            "Xiaoxuan Wang",
            "Han Zhang",
            "Haixin Wang",
            "Yidan Shi",
            "Ruoyan Li",
            "Kaiqiao Han",
            "Chenyi Tong",
            "Haoran Deng",
            "Renliang Sun",
            "Alexander Taylor",
            "Yanqiao Zhu",
            "Jason Cong",
            "Yizhou Sun",
            "Wei Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21534",
        "abstract": "Agentic reinforcement learning (ARL) has rapidly gained attention as a promising paradigm for training agents to solve complex, multi-step interactive tasks. Despite encouraging early results, ARL remains highly unstable, often leading to training collapse. This instability limits scalability to larger environments and longer interaction horizons, and constrains systematic exploration of algorithmic design choices. In this paper, we first propose ARLArena, a stable training recipe and systematic analysis framework that examines training stability in a controlled and reproducible setting. ARLArena first constructs a clean and standardized testbed. Then, we decompose policy gradient into four core design dimensions and assess the performance and stability of each dimension. Through this fine-grained analysis, we distill a unified perspective on ARL and propose SAMPO, a stable agentic policy optimization method designed to mitigate the dominant sources of instability in ARL. Empirically, SAMPO achieves consistently stable training and strong performance across diverse agentic tasks. Overall, this study provides a unifying policy gradient perspective for ARL and offers practical guidance for building stable and reproducible LLM-based agent training pipelines.",
        "tags": [
            "LLM",
            "RL"
        ]
    },
    {
        "id": "63",
        "title": "Pseudo-View Enhancement via Confidence Fusion for Unposed Sparse-View Reconstruction",
        "author": [
            "Beizhen Zhao",
            "Sicheng Yu",
            "Guanzhi Ding",
            "Yu Hu",
            "Hao Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21535",
        "abstract": "3D scene reconstruction under unposed sparse viewpoints is a highly challenging yet practically important problem, especially in outdoor scenes due to complex lighting and scale variation. With extremely limited input views, directly utilizing diffusion model to synthesize pseudo frames will introduce unreasonable geometry, which will harm the final reconstruction quality. To address these issues, we propose a novel framework for sparse-view outdoor reconstruction that achieves high-quality results through bidirectional pseudo frame restoration and scene perception Gaussian management. Specifically, we introduce a bidirectional pseudo frame restoration method that restores missing content by diffusion-based synthesis guided by adjacent frames with a lightweight pseudo-view deblur model and confidence mask inference algorithm. Then we propose a scene perception Gaussian management strategy that optimize Gaussians based on joint depth-density information. These designs significantly enhance reconstruction completeness, suppress floating artifacts and improve overall geometric consistency under extreme view sparsity. Experiments on outdoor benchmarks demonstrate substantial gains over existing methods in both fidelity and stability.",
        "tags": [
            "3D",
            "Diffusion"
        ]
    },
    {
        "id": "64",
        "title": "Enhancing Multilingual Embeddings via Multi-Way Parallel Text Alignment",
        "author": [
            "Barah Fazili",
            "Koustava Goswami"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21543",
        "abstract": "Multilingual pretraining typically lacks explicit alignment signals, leading to suboptimal cross-lingual alignment in the representation space. In this work, we show that training standard pretrained models for cross-lingual alignment with a multi-way parallel corpus in a diverse pool of languages can substantially improve multilingual and cross-lingual representations for NLU tasks. We construct a multi-way parallel dataset using translations of English text from an off-the-shelf NMT model for a pool of six target languages and achieve strong cross-lingual alignment through contrastive learning. This leads to substantial performance gains across both seen and unseen languages for multiple tasks from the MTEB benchmark evaluated for XLM-Roberta and multilingual BERT base models. Using a multi-way parallel corpus for contrastive training yields substantial gains on bitext mining (21.3%), semantic similarity (5.3%), and classification (28.4%) compared to English-centric (En-X) bilingually parallel data, where X is sampled from a pool of multiple target languages. Furthermore, finetuning mE5 model on a small dataset with multi-way parallelism significantly improves bitext mining compared to one without, underscoring the importance of multi-way cross-lingual supervision even for models already pretrained for high-quality sentence embeddings.",
        "tags": [
            "BERT"
        ]
    },
    {
        "id": "65",
        "title": "Muon+: Towards Better Muon via One Additional Normalization Step",
        "author": [
            "Ruijie Zhang",
            "Yequan Zhao",
            "Ziyue Liu",
            "Zhengyang Wang",
            "Zheng Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21545",
        "abstract": "The Muon optimizer has demonstrated promising performance in pre-training large language models through gradient (or momentum) orthogonalization. In this work, we propose a simple yet effective enhancement to Muon, namely Muon+, which introduces an additional normalization step after orthogonalization. We demonstrate the effectiveness of Muon+ through extensive pre-training experiments across a wide range of model scales and architectures. Our evaluation includes GPT-style models ranging from 130M to 774M parameters and LLaMA-style models ranging from 60M to 1B parameters. We comprehensively evaluate the effectiveness of Muon+ in the compute-optimal training regime and further extend the token-to-parameter (T2P) ratio to an industrial level of $\\approx 200$. Experimental results show that Muon+ provides a consistent boost on training and validation perplexity over Muon. We provide our code here: https://github.com/K1seki221/MuonPlus.",
        "tags": [
            "GPT",
            "LLM",
            "LLaMA"
        ]
    },
    {
        "id": "66",
        "title": "Mamba Meets Scheduling: Learning to Solve Flexible Job Shop Scheduling with Efficient Sequence Modeling",
        "author": [
            "Zhi Cao",
            "Cong Zhang",
            "Yaoxin Wu",
            "Yaqing Hou",
            "Hongwei Ge"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21546",
        "abstract": "The Flexible Job Shop Problem (FJSP) is a well-studied combinatorial optimization problem with extensive applications for manufacturing and production scheduling. It involves assigning jobs to various machines to optimize criteria, such as minimizing total completion time. Current learning-based methods in this domain often rely on localized feature extraction models, limiting their capacity to capture overarching dependencies spanning operations and machines. This paper introduces an innovative architecture that harnesses Mamba, a state-space model with linear computational complexity, to facilitate comprehensive sequence modeling tailored for FJSP. In contrast to prevalent graph-attention-based frameworks that are computationally intensive for FJSP, we show our model is more efficient. Specifically, the proposed model possesses an encoder and a decoder. The encoder incorporates a dual Mamba block to extract operation and machine features separately. Additionally, we introduce an efficient cross-attention decoder to learn interactive embeddings of operations and machines. Our experimental results demonstrate that our method achieves faster solving speed and surpasses the performance of state-of-the-art learning-based methods for FJSP across various benchmarks.",
        "tags": [
            "Mamba"
        ]
    },
    {
        "id": "67",
        "title": "RAC: Relation-Aware Cache Replacement for Large Language Models",
        "author": [
            "Yuchong Wu",
            "Zihuan Xu",
            "Wangze Ni",
            "Peng Cheng",
            "Lei Chen",
            "Xuemin Lin",
            "Heng Tao Shen",
            "Kui Ren"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21547",
        "abstract": "The scaling of Large Language Model (LLM) services faces significant cost and latency challenges, making effective caching under tight capacity crucial. Existing cache replacement policies, from heuristics to learning-based methods, predominantly rely on limited-window statistics such as recency and frequency. We show these signals are not robust for real-world LLM workloads, which exhibit long reuse distances and sparse local recurrence.\nTo address these limitations, we propose Relation-Aware Cache (RAC), an online eviction strategy that leverages semantic relations among requests to guide eviction decisions. RAC synthesizes two relation-aware signals: (1) Topical Prevalence, which aggregates access evidence at the topic level to capture long-horizon reuse; and (2) Structural Importance, which leverages local intra-topic dependency structure to discriminate entries by their future reuse value. Extensive evaluations show that RAC maintains high effectiveness across diverse workloads, consistently surpassing state-of-the-art baselines by 20%--30% in cache hit ratio.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "68",
        "title": "DualPath: Breaking the Storage Bandwidth Bottleneck in Agentic LLM Inference",
        "author": [
            "Yongtong Wu",
            "Shaoyuan Chen",
            "Yinmin Zhong",
            "Rilin Huang",
            "Yixuan Tan",
            "Wentao Zhang",
            "Liyue Zhang",
            "Shangyan Zhou",
            "Yuxuan Liu",
            "Shunfeng Zhou",
            "Mingxing Zhang",
            "Xin Jin",
            "Panpan Huang"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21548",
        "abstract": "The performance of multi-turn, agentic LLM inference is increasingly dominated by KV-Cache storage I/O rather than computation. In prevalent disaggregated architectures, loading the massive KV-Cache from external storage creates a fundamental imbalance: storage NICs on prefill engines become bandwidth-saturated, while those on decoding engines remain idle. This asymmetry severely constrains overall system throughput.\nWe present DualPath, an inference system that breaks this bottleneck by introducing dual-path KV-Cache loading. Beyond the traditional storage-to-prefill path, DualPath enables a novel storage-to-decode path, in which the KV-Cache is loaded into decoding engines and then efficiently transferred to prefill engines via RDMA over the compute network. DualPath combines this optimized data path -- which inherently avoids network congestion and avoids interference with latency-critical model execution communications -- with a global scheduler that dynamically balances load across prefill and decode engines.\nOur evaluation on three models with production agentic workloads demonstrates that DualPath improves offline inference throughput by up to 1.87$\\times$ on our in-house inference system. It can also improve online serving throughput by an average factor of 1.96$\\times$ without violating SLO.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "69",
        "title": "From Basis to Basis: Gaussian Particle Representation for Interpretable PDE Operators",
        "author": [
            "Zhihao Li",
            "Yu Feng",
            "Zhilu Lai",
            "Wei Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21551",
        "abstract": "Learning PDE dynamics for fluids increasingly relies on neural operators and Transformer-based models, yet these approaches often lack interpretability and struggle with localized, high-frequency structures while incurring quadratic cost in spatial samples. We propose representing fields with a Gaussian basis, where learned atoms carry explicit geometry (centers, anisotropic scales, weights) and form a compact, mesh-agnostic, directly visualizable state. Building on this representation, we introduce a Gaussian Particle Operator that acts in modal space: learned Gaussian modal windows perform a Petrov-Galerkin measurement, and PG Gaussian Attention enables global cross-scale coupling. This basis-to-basis design is resolution-agnostic and achieves near-linear complexity in N for a fixed modal budget, supporting irregular geometries and seamless 2D-to-3D extension. On standard PDE benchmarks and real datasets, our method attains state-of-the-art competitive accuracy while providing intrinsic interpretability.",
        "tags": [
            "3D",
            "Transformer"
        ]
    },
    {
        "id": "70",
        "title": "Revisiting RAG Retrievers: An Information Theoretic Benchmark",
        "author": [
            "Wenqing Zheng",
            "Dmitri Kalaev",
            "Noah Fatsi",
            "Daniel Barcklow",
            "Owen Reinert",
            "Igor Melnyk",
            "Senthil Kumar",
            "C. Bayan Bruss"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21553",
        "abstract": "Retrieval-Augmented Generation (RAG) systems rely critically on the retriever module to surface relevant context for large language models. Although numerous retrievers have recently been proposed, each built on different ranking principles such as lexical matching, dense embeddings, or graph citations, there remains a lack of systematic understanding of how these mechanisms differ and overlap. Existing benchmarks primarily compare entire RAG pipelines or introduce new datasets, providing little guidance on selecting or combining retrievers themselves. Those that do compare retrievers directly use a limited set of evaluation tools which fail to capture complementary and overlapping strengths. This work presents MIGRASCOPE, a Mutual Information based RAG Retriever Analysis Scope. We revisit state-of-the-art retrievers and introduce principled metrics grounded in information and statistical estimation theory to quantify retrieval quality, redundancy, synergy, and marginal contribution. We further show that if chosen carefully, an ensemble of retrievers outperforms any single retriever. We leverage the developed tools over major RAG corpora to provide unique insights on contribution levels of the state-of-the-art retrievers. Our findings provide a fresh perspective on the structure of modern retrieval techniques and actionable guidance for designing robust and efficient RAG systems.",
        "tags": [
            "LLM",
            "RAG"
        ]
    },
    {
        "id": "71",
        "title": "Power and Limitations of Aggregation in Compound AI Systems",
        "author": [
            "Nivasini Ananthakrishnan",
            "Meena Jagadeesan"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21556",
        "abstract": "When designing compound AI systems, a common approach is to query multiple copies of the same model and aggregate the responses to produce a synthesized output. Given the homogeneity of these models, this raises the question of whether aggregation unlocks access to a greater set of outputs than querying a single model. In this work, we investigate the power and limitations of aggregation within a stylized principal-agent framework. This framework models how the system designer can partially steer each agent's output through its reward function specification, but still faces limitations due to prompt engineering ability and model capabilities. Our analysis uncovers three natural mechanisms -- feasibility expansion, support expansion, and binding set contraction -- through which aggregation expands the set of outputs that are elicitable by the system designer. We prove that any aggregation operation must implement one of these mechanisms in order to be elicitability-expanding, and that strengthened versions of these mechanisms provide necessary and sufficient conditions that fully characterize elicitability-expansion. Finally, we provide an empirical illustration of our findings for LLMs deployed in a toy reference-generation task. Altogether, our results take a step towards characterizing when compound AI systems can overcome limitations in model capabilities and in prompt engineering.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "72",
        "title": "MultiAnimate: Pose-Guided Image Animation Made Extensible",
        "author": [
            "Yingcheng Hu",
            "Haowen Gong",
            "Chuanguang Yang",
            "Zhulin An",
            "Yongjun Xu",
            "Songhua Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21581",
        "abstract": "Pose-guided human image animation aims to synthesize realistic videos of a reference character driven by a sequence of poses. While diffusion-based methods have achieved remarkable success, most existing approaches are limited to single-character animation. We observe that naively extending these methods to multi-character scenarios often leads to identity confusion and implausible occlusions between characters. To address these challenges, in this paper, we propose an extensible multi-character image animation framework built upon modern Diffusion Transformers (DiTs) for video generation. At its core, our framework introduces two novel components-Identifier Assigner and Identifier Adapter - which collaboratively capture per-person positional cues and inter-person spatial relationships. This mask-driven scheme, along with a scalable training strategy, not only enhances flexibility but also enables generalization to scenarios with more characters than those seen during training. Remarkably, trained on only a two-character dataset, our model generalizes to multi-character animation while maintaining compatibility with single-character cases. Extensive experiments demonstrate that our approach achieves state-of-the-art performance in multi-character image animation, surpassing existing diffusion-based baselines.",
        "tags": [
            "Diffusion",
            "Video Generation"
        ]
    },
    {
        "id": "73",
        "title": "Learning Agile and Robust Omnidirectional Aerial Motion on Overactuated Tiltable-Quadrotors",
        "author": [
            "Wentao Zhang",
            "Zhaoqi Ma",
            "Jinjie Li",
            "Huayi Wang",
            "Haokun Liu",
            "Junichiro Sugihara",
            "Chen Chen",
            "Yicheng Chen",
            "Moju Zhao"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21583",
        "abstract": "Tilt-rotor aerial robots enable omnidirectional maneuvering through thrust vectoring, but introduce significant control challenges due to the strong coupling between joint and rotor dynamics. While model-based controllers can achieve high motion accuracy under nominal conditions, their robustness and responsiveness often degrade in the presence of disturbances and modeling uncertainties. This work investigates reinforcement learning for omnidirectional aerial motion control on over-actuated tiltable quadrotors that prioritizes robustness and agility. We present a learning-based control framework that enables efficient acquisition of coordinated rotor-joint behaviors for reaching target poses in the $SE(3)$ space. To achieve reliable sim-to-real transfer while preserving motion accuracy, we integrate system identification with minimal and physically consistent domain randomization. Compared with a state-of-the-art NMPC controller, the proposed method achieves comparable six-degree-of-freedom pose tracking accuracy, while demonstrating superior robustness and generalization across diverse tasks, enabling zero-shot deployment on real hardware.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "74",
        "title": "Duel-Evolve: Reward-Free Test-Time Scaling via LLM Self-Preferences",
        "author": [
            "Sweta Karlekar",
            "Carolina Zheng",
            "Magnus Saebo",
            "Nicolas Beltran-Velez",
            "Shuyang Yu",
            "John Bowlan",
            "Michal Kucer",
            "David Blei"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21585",
        "abstract": "Many applications seek to optimize LLM outputs at test time by iteratively proposing, scoring, and refining candidates over a discrete output space. Existing methods use a calibrated scalar evaluator for the target objective to guide search, but for many tasks such scores are unavailable, too sparse, or unreliable. Pairwise comparisons, by contrast, are often easier to elicit, still provide useful signal on improvement directions, and can be obtained from the LLM itself without external supervision. Building on this observation, we introduce Duel-Evolve, an evolutionary optimization algorithm that replaces external scalar rewards with pairwise preferences elicited from the same LLM used to generate candidates. Duel-Evolve aggregates these noisy candidate comparisons via a Bayesian Bradley-Terry model, yielding uncertainty-aware estimates of candidate quality. These quality estimates guide allocation of the comparison budget toward plausible optima using Double Thompson Sampling, as well as selection of high-quality parents to generate improved candidates. We evaluate Duel-Evolve on MathBench, where it achieves 20 percentage points higher accuracy over existing methods and baselines, and on LiveCodeBench, where it improves over comparable iterative methods by over 12 percentage points. Notably, the method requires no reward model, no ground-truth labels during search, and no hand-crafted scoring function. Results show that pairwise self-preferences provide strong optimization signal for test-time improvement over large, discrete output spaces.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "75",
        "title": "CADC: Content Adaptive Diffusion-Based Generative Image Compression",
        "author": [
            "Xihua Sheng",
            "Lingyu Zhu",
            "Tianyu Zhang",
            "Dong Liu",
            "Shiqi Wang",
            "Jing Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21591",
        "abstract": "Diffusion-based generative image compression has demonstrated remarkable potential for achieving realistic reconstruction at ultra-low bitrates. The key to unlocking this potential lies in making the entire compression process content-adaptive, ensuring that the encoder's representation and the decoder's generative prior are dynamically aligned with the semantic and structural characteristics of the input image. However, existing methods suffer from three critical limitations that prevent effective content adaptation. First, isotropic quantization applies a uniform quantization step, failing to adapt to the spatially varying complexity of image content and creating a misalignment with the diffusion model's noise-dependent prior. Second, the information concentration bottleneck -- arising from the dimensional mismatch between the high-dimensional noisy latent and the diffusion decoder's fixed input -- prevents the model from adaptively preserving essential semantic information in the primary channels. Third, existing textual conditioning strategies either need significant textual bitrate overhead or rely on generic, content-agnostic textual prompts, thereby failing to provide adaptive semantic guidance efficiently. To overcome these limitations, we propose a content-adaptive diffusion-based image codec with three technical innovations: 1) an Uncertainty-Guided Adaptive Quantization method that learns spatial uncertainty maps to adaptively align quantization distortion with content characteristics; 2) an Auxiliary Decoder-Guided Information Concentration method that uses a lightweight auxiliary decoder to enforce content-aware information preservation in the primary latent channels; and 3) a Bitrate-Free Adaptive Textual Conditioning method that derives content-aware textual descriptions from the auxiliary reconstructed image, enabling semantic guidance without bitrate cost.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "76",
        "title": "SPOC: Safety-Aware Planning Under Partial Observability And Physical Constraints",
        "author": [
            "Hyungmin Kim",
            "Hobeom Jeon",
            "Dohyung Kim",
            "Minsu Jang",
            "Jeahong Kim"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21595",
        "abstract": "Embodied Task Planning with large language models faces safety challenges in real-world environments, where partial observability and physical constraints must be respected. Existing benchmarks often overlook these critical factors, limiting their ability to evaluate both feasibility and safety. We introduce SPOC, a benchmark for safety-aware embodied task planning, which integrates strict partial observability, physical constraints, step-by-step planning, and goal-condition-based evaluation. Covering diverse household hazards such as fire, fluid, injury, object damage, and pollution, SPOC enables rigorous assessment through both state and constraint-based online metrics. Experiments with state-of-the-art LLMs reveal that current models struggle to ensure safety-aware planning, particularly under implicit constraints. Code and dataset are available at https://github.com/khm159/SPOC",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "77",
        "title": "A Hidden Semantic Bottleneck in Conditional Embeddings of Diffusion Transformers",
        "author": [
            "Trung X. Pham",
            "Kang Zhang",
            "Ji Woo Hong",
            "Chang D. Yoo"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21596",
        "abstract": "Diffusion Transformers have achieved state-of-the-art performance in class-conditional and multimodal generation, yet the structure of their learned conditional embeddings remains poorly understood. In this work, we present the first systematic study of these embeddings and uncover a notable redundancy: class-conditioned embeddings exhibit extreme angular similarity, exceeding 99\\% on ImageNet-1K, while continuous-condition tasks such as pose-guided image generation and video-to-audio generation reach over 99.9\\%. We further find that semantic information is concentrated in a small subset of dimensions, with head dimensions carrying the dominant signal and tail dimensions contributing minimally. By pruning low-magnitude dimensions--removing up to two-thirds of the embedding space--we show that generation quality and fidelity remain largely unaffected, and in some cases improve. These results reveal a semantic bottleneck in Transformer-based diffusion models, providing new insights into how semantics are encoded and suggesting opportunities for more efficient conditioning mechanisms.",
        "tags": [
            "Diffusion",
            "Transformer"
        ]
    },
    {
        "id": "78",
        "title": "Towards Autonomous Graph Data Analytics with Analytics-Augmented Generation",
        "author": [
            "Qiange Wang",
            "Chaoyi Chen",
            "Jingqi Gao",
            "Zihan Wang",
            "Yanfeng Zhang",
            "Ge Yu"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21604",
        "abstract": "This paper argues that reliable end-to-end graph data analytics cannot be achieved by retrieval- or code-generation-centric LLM agents alone. Although large language models (LLMs) provide strong reasoning capabilities, practical graph analytics for non-expert users requires explicit analytical grounding to support intent-to-execution translation, task-aware graph construction, and reliable execution across diverse graph algorithms. We envision Analytics-Augmented Generation (AAG) as a new paradigm that treats analytical computation as a first-class concern and positions LLMs as knowledge-grounded analytical coordinators. By integrating knowledge-driven task planning, algorithm-centric LLM-analytics interaction, and task-aware graph construction, AAG enables end-to-end graph analytics pipelines that translate natural-language user intent into automated execution and interpretable results.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "79",
        "title": "MixSarc: A Bangla-English Code-Mixed Corpus for Implicit Meaning Identification",
        "author": [
            "Kazi Samin Yasar Alam",
            "Md Tanbir Chowdhury",
            "Tamim Ahmed",
            "Ajwad Abrar",
            "Md Rafid Haque"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21608",
        "abstract": "Bangla-English code-mixing is widespread across South Asian social media, yet resources for implicit meaning identification in this setting remain scarce. Existing sentiment and sarcasm models largely focus on monolingual English or high-resource languages and struggle with transliteration variation, cultural references, and intra-sentential language switching. To address this gap, we introduce MixSarc, the first publicly available Bangla-English code-mixed corpus for implicit meaning identification. The dataset contains 9,087 manually annotated sentences labeled for humor, sarcasm, offensiveness, and vulgarity. We construct the corpus through targeted social media collection, systematic filtering, and multi-annotator validation. We benchmark transformer-based models and evaluate zero-shot large language models under structured prompting. Results show strong performance on humor detection but substantial degradation on sarcasm, offense, and vulgarity due to class imbalance and pragmatic complexity. Zero-shot models achieve competitive micro-F1 scores but low exact match accuracy. Further analysis reveals that over 42\\% of negative sentiment instances in an external dataset exhibit sarcastic characteristics. MixSarc provides a foundational resource for culturally aware NLP and supports more reliable multi-label modeling in code-mixed environments.",
        "tags": [
            "Detection",
            "LLM",
            "Transformer"
        ]
    },
    {
        "id": "80",
        "title": "Structurally Aligned Subtask-Level Memory for Software Engineering Agents",
        "author": [
            "Kangning Shen",
            "Jingyuan Zhang",
            "Chenxi Sun",
            "Wencong Zeng",
            "Yang Yue"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21611",
        "abstract": "Large Language Models (LLMs) have demonstrated significant potential as autonomous software engineering (SWE) agents. Recent work has further explored augmenting these agents with memory mechanisms to support long-horizon reasoning. However, these approaches typically operate at a coarse instance granularity, treating the entire problem-solving episode as the atomic unit of storage and retrieval. We empirically demonstrate that instance-level memory suffers from a fundamental granularity mismatch, resulting in misguided retrieval when tasks with similar surface descriptions require distinct reasoning logic at specific stages. To address this, we propose Structurally Aligned Subtask-Level Memory, a method that aligns memory storage, retrieval, and updating with the agent's functional decomposition. Extensive experiments on SWE-bench Verified demonstrate that our method consistently outperforms both vanilla agents and strong instance-level memory baselines across diverse backbones, improving mean Pass@1 over the vanilla agent by +4.7 pp on average (e.g., +6.8 pp on Gemini 2.5 Pro). Performance gains grow with more interaction steps, showing that leveraging past experience benefits long-horizon reasoning in complex software engineering tasks.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "81",
        "title": "Jumping Control for a Quadrupedal Wheeled-Legged Robot via NMPC and DE Optimization",
        "author": [
            "Xuanqi Zeng",
            "Lingwei Zhang",
            "Linzhu Yue",
            "Zhitao Song",
            "Hongbo Zhang",
            "Tianlin Zhang",
            "Yun-Hui Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21612",
        "abstract": "Quadrupedal wheeled-legged robots combine the advantages of legged and wheeled locomotion to achieve superior mobility, but executing dynamic jumps remains a significant challenge due to the additional degrees of freedom introduced by wheeled legs. This paper develops a mini-sized wheeled-legged robot for agile motion and presents a novel motion control framework that integrates the Nonlinear Model Predictive Control (NMPC) for locomotion and the Differential Evolution (DE) based trajectory optimization for jumping in quadrupedal wheeled-legged robots. The proposed controller utilizes wheel motion and locomotion to enhance jumping performance, achieving versatile maneuvers such as vertical jumping, forward jumping, and backflips. Extensive simulations and real-world experiments validate the effectiveness of the framework, demonstrating a forward jump over a 0.12 m obstacle and a vertical jump reaching 0.5 m.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "82",
        "title": "When More Is Less: A Systematic Analysis of Spatial and Commonsense Information for Visual Spatial Reasoning",
        "author": [
            "Muku Akasaka",
            "Soyeon Caren Han"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21619",
        "abstract": "Visual spatial reasoning (VSR) remains challenging for modern vision-language models (VLMs), despite advances in multimodal architectures. A common strategy is to inject additional information at inference time, such as explicit spatial cues, external commonsense knowledge, or chain-of-thought (CoT) reasoning instructions. However, it remains unclear when such information genuinely improves reasoning and when it introduces noise. In this paper, we conduct a hypothesis-driven analysis of information injection for VSR across three representative VLMs and two public benchmarks. We examine (i) the type and number of spatial contexts, (ii) the amount and relevance of injected commonsense knowledge, and (iii) the interaction between spatial grounding and CoT prompting. Our results reveal a consistent pattern: more information does not necessarily yield better reasoning. Targeted single spatial cues outperform multi-context aggregation, excessive or weakly relevant commonsense knowledge degrades performance, and CoT prompting improves accuracy only when spatial grounding is sufficiently precise. These findings highlight the importance of selective, task-aligned information injection and provide practical guidance for designing reliable multimodal reasoning pipelines.",
        "tags": [
            "CoT",
            "VLM"
        ]
    },
    {
        "id": "83",
        "title": "ADM-DP: Adaptive Dynamic Modality Diffusion Policy through Vision-Tactile-Graph Fusion for Multi-Agent Manipulation",
        "author": [
            "Enyi Wang",
            "Wen Fan",
            "Dandan Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21622",
        "abstract": "Multi-agent robotic manipulation remains challenging due to the combined demands of coordination, grasp stability, and collision avoidance in shared workspaces. To address these challenges, we propose the Adaptive Dynamic Modality Diffusion Policy (ADM-DP), a framework that integrates vision, tactile, and graph-based (multi-agent pose) modalities for coordinated control. ADM-DP introduces four key innovations. First, an enhanced visual encoder merges RGB and point-cloud features via Feature-wise Linear Modulation (FiLM) modulation to enrich perception. Second, a tactile-guided grasping strategy uses Force-Sensitive Resistor (FSR) feedback to detect insufficient contact and trigger corrective grasp refinement, improving grasp stability. Third, a graph-based collision encoder leverages shared tool center point (TCP) positions of multiple agents as structured kinematic context to maintain spatial awareness and reduce inter-agent interference. Fourth, an Adaptive Modality Attention Mechanism (AMAM) dynamically re-weights modalities according to task context, enabling flexible fusion. For scalability and modularity, a decoupled training paradigm is employed in which agents learn independent policies while sharing spatial information. This maintains low interdependence between agents while retaining collective awareness. Across seven multi-agent tasks, ADM-DP achieves 12-25% performance gains over state-of-the-art baselines. Ablation studies show the greatest improvements in tasks requiring multiple sensory modalities, validating our adaptive fusion strategy and demonstrating its robustness for diverse manipulation scenarios.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "84",
        "title": "Tacmap: Bridging the Tactile Sim-to-Real Gap via Geometry-Consistent Penetration Depth Map",
        "author": [
            "Lei Su",
            "Zhijie Peng",
            "Renyuan Ren",
            "Shengping Mao",
            "Juan Du",
            "Kaifeng Zhang",
            "Xuezhou Zhu"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21625",
        "abstract": "Vision-Based Tactile Sensors (VBTS) are essential for achieving dexterous robotic manipulation, yet the tactile sim-to-real gap remains a fundamental bottleneck. Current tactile simulations suffer from a persistent dilemma: simplified geometric projections lack physical authenticity, while high-fidelity Finite Element Methods (FEM) are too computationally prohibitive for large-scale reinforcement learning. In this work, we present Tacmap, a high-fidelity, computationally efficient tactile simulation framework anchored in volumetric penetration depth. Our key insight is to bridge the tactile sim-to-real gap by unifying both domains through a shared deform map representation. Specifically, we compute 3D intersection volumes as depth maps in simulation, while in the real world, we employ an automated data-collection rig to learn a robust mapping from raw tactile images to ground-truth depth maps. By aligning simulation and real-world in this unified geometric space, Tacmap minimizes domain shift while maintaining physical consistency. Quantitative evaluations across diverse contact scenarios demonstrate that Tacmap's deform maps closely mirror real-world measurements. Moreover, we validate the utility of Tacmap through an in-hand rotation task, where a policy trained exclusively in simulation achieves zero-shot transfer to a physical robot.",
        "tags": [
            "3D",
            "RL",
            "Robotics"
        ]
    },
    {
        "id": "85",
        "title": "Multi-Layer Scheduling for MoE-Based LLM Reasoning",
        "author": [
            "Yifan Sun",
            "Gholamreza Haffar",
            "Minxian Xu",
            "Rajkumar Buyya",
            "Adel N. Toosi"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21626",
        "abstract": "Large Language Models (LLMs) have achieved remarkable success across a wide range of tasks, but serving them efficiently at scale remains a critical challenge due to their substantial computational and latency demands. While most existing inference frameworks rely on simple scheduling strategies such as First-Come-First-Serve (FCFS) at the engine level and Round-Robin (RR) at the scheduler or coordinator level, they often fail to fully utilize system resources and may suffer from issues such as head-of-line blocking and load imbalance. Recent advances in Mixture-of-Experts (MoE) models have also introduced new challenges in scheduling arising from expert parallelism and routing complexity. This research proposes a multi-layer scheduling framework tailored for MoE-based LLM serving. It targets scheduling at three levels: request-level, enginelevel, and expert-level. At the request level, we explore algorithms such as Shortest-Job-First (SJF) and priority-aware aging to improve throughput and reduce latency. At the engine level, we design load-aware dispatching strategies that account for the current prefix token load, KV cache utilization, and user stickiness to achieve better resource matching. At the expert level, we focus on alleviating expert hotspots and strategically placing inter-layer expert dependencies to balance load and improve routing efficiency. Extensive experimental results from more than 100 experiments conducted under diverse workload distributions show that our approach consistently outperforms the state-of-theart inference framework vLLM, achieving up to 17.8% reduction in Time To First Token (TTFT) latency and 13.3% reduction in Time-Per-Output-Token (TPOT) latency.",
        "tags": [
            "LLM",
            "MoE"
        ]
    },
    {
        "id": "86",
        "title": "RuCL: Stratified Rubric-Based Curriculum Learning for Multimodal Large Language Model Reasoning",
        "author": [
            "Yukun Chen",
            "Jiaming Li",
            "Longze Chen",
            "Ze Gong",
            "Jingpeng Li",
            "Zhen Qin",
            "Hengyu Chang",
            "Ancheng Xu",
            "Zhihao Yang",
            "Hamid Alinejad-Rokny",
            "Qiang Qu",
            "Bo Zheng",
            "Min Yang"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21628",
        "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as a prevailing paradigm for enhancing reasoning in Multimodal Large Language Models (MLLMs). However, relying solely on outcome supervision risks reward hacking, where models learn spurious reasoning patterns to satisfy final answer checks. While recent rubric-based approaches offer fine-grained supervision signals, they suffer from high computational costs of instance-level generation and inefficient training dynamics caused by treating all rubrics as equally learnable. In this paper, we propose Stratified Rubric-based Curriculum Learning (RuCL), a novel framework that reformulates curriculum learning by shifting the focus from data selection to reward design. RuCL generates generalized rubrics for broad applicability and stratifies them based on the model's competence. By dynamically adjusting rubric weights during training, RuCL guides the model from mastering foundational perception to tackling advanced logical reasoning. Extensive experiments on various visual reasoning benchmarks show that RuCL yields a remarkable +7.83% average improvement over the Qwen2.5-VL-7B model, achieving a state-of-the-art accuracy of 60.06%.",
        "tags": [
            "LLM",
            "RL"
        ]
    },
    {
        "id": "87",
        "title": "UniHand: A Unified Model for Diverse Controlled 4D Hand Motion Modeling",
        "author": [
            "Zhihao Sun",
            "Tong Wu",
            "Ruirui Tu",
            "Daoguo Dong",
            "Zuxuan Wu"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21631",
        "abstract": "Hand motion plays a central role in human interaction, yet modeling realistic 4D hand motion (i.e., 3D hand pose sequences over time) remains challenging. Research in this area is typically divided into two tasks: (1) Estimation approaches reconstruct precise motion from visual observations, but often fail under hand occlusion or absence; (2) Generation approaches focus on synthesizing hand poses by exploiting generative priors under multi-modal structured inputs and infilling motion from incomplete sequences. However, this separation not only limits the effective use of heterogeneous condition signals that frequently arise in practice, but also prevents knowledge transfer between the two tasks. We present UniHand, a unified diffusion-based framework that formulates both estimation and generation as conditional motion synthesis. UniHand integrates heterogeneous inputs by embedding structured signals into a shared latent space through a joint variational autoencoder, which aligns conditions such as MANO parameters and 2D skeletons. Visual observations are encoded with a frozen vision backbone, while a dedicated hand perceptron extracts hand-specific cues directly from image features, removing the need for complex detection and cropping pipelines. A latent diffusion model then synthesizes consistent motion sequences from these diverse conditions. Extensive experiments across multiple benchmarks demonstrate that UniHand delivers robust and accurate hand motion modeling, maintaining performance under severe occlusions and temporally incomplete inputs.",
        "tags": [
            "3D",
            "Detection",
            "Diffusion"
        ]
    },
    {
        "id": "88",
        "title": "Self-Correcting VLA: Online Action Refinement via Sparse World Imagination",
        "author": [
            "Chenyv Liu",
            "Wentao Tan",
            "Lei Zhu",
            "Fengling Li",
            "Jingjing Li",
            "Guoli Yang",
            "Heng Tao Shen"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21633",
        "abstract": "Standard vision-language-action (VLA) models rely on fitting statistical data priors, limiting their robust understanding of underlying physical dynamics. Reinforcement learning enhances physical grounding through exploration yet typically relies on external reward signals that remain isolated from the agent's internal states. World action models have emerged as a promising paradigm that integrates imagination and control to enable predictive planning. However, they rely on implicit context modeling, lacking explicit mechanisms for self-improvement. To solve these problems, we propose Self-Correcting VLA (SC-VLA), which achieve self-improvement by intrinsically guiding action refinement through sparse imagination. We first design sparse world imagination by integrating auxiliary predictive heads to forecast current task progress and future trajectory trends, thereby constraining the policy to encode short-term physical evolution. Then we introduce the online action refinement module to reshape progress-dependent dense rewards, adjusting trajectory orientation based on the predicted sparse future states. Evaluations on challenging robot manipulation tasks from simulation benchmarks and real-world settings demonstrate that SC-VLA achieve state-of-the-art performance, yielding the highest task throughput with 16% fewer steps and a 9% higher success rate than the best-performing baselines, alongside a 14% gain in real-world experiments. Code is available at https://github.com/Kisaragi0/SC-VLA.",
        "tags": [
            "RL",
            "Robotics"
        ]
    },
    {
        "id": "89",
        "title": "AgentLTV: An Agent-Based Unified Search-and-Evolution Framework for Automated Lifetime Value Prediction",
        "author": [
            "Chaowei Wu",
            "Huazhu Chen",
            "Congde Yuan",
            "Qirui Yang",
            "Guoqing Song",
            "Yue Gao",
            "Li Luo",
            "Frank Youhua Chen",
            "Mengzhuo Guo"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21634",
        "abstract": "Lifetime Value (LTV) prediction is critical in advertising, recommender systems, and e-commerce. In practice, LTV data patterns vary across decision scenarios. As a result, practitioners often build complex, scenario-specific pipelines and iterate over feature processing, objective design, and tuning. This process is expensive and hard to transfer. We propose AgentLTV, an agent-based unified search-and-evolution framework for automated LTV modeling. AgentLTV treats each candidate solution as an {executable pipeline program}. LLM-driven agents generate code, run and repair pipelines, and analyze execution feedback. Two decision agents coordinate a two-stage search. The Monte Carlo Tree Search (MCTS) stage explores a broad space of modeling choices under a fixed budget, guided by the Polynomial Upper Confidence bounds for Trees criterion and a Pareto-aware multi-metric value function. The Evolutionary Algorithm (EA) stage refines the best MCTS program via island-based evolution with crossover, mutation, and migration. Experiments on a large-scale proprietary dataset and a public benchmark show that AgentLTV consistently discovers strong models across ranking and error metrics. Online bucket-level analysis further indicates improved ranking consistency and value calibration, especially for high-value and negative-LTV segments. We summarize practitioner-oriented takeaways: use MCTS for rapid adaptation to new data patterns, use EA for stable refinement, and validate deployment readiness with bucket-level ranking and calibration diagnostics. The proposed AgentLTV has been successfully deployed online.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "90",
        "title": "Multi-dimensional Assessment and Explainable Feedback for Counselor Responses to Client Resistance in Text-based Counseling with LLMs",
        "author": [
            "Anqi Li",
            "Ruihan Wang",
            "Zhaoming Chen",
            "Yuqian Chen",
            "Yu Lu",
            "Yi Zhu",
            "Yuan Xie",
            "Zhenzhong Lan"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21638",
        "abstract": "Effectively addressing client resistance is a sophisticated clinical skill in psychological counseling, yet practitioners often lack timely and scalable supervisory feedback to refine their approaches. Although current NLP research has examined overall counseling quality and general therapeutic skills, it fails to provide granular evaluations of high-stakes moments where clients exhibit resistance. In this work, we present a comprehensive pipeline for the multi-dimensional evaluation of human counselors' interventions specifically targeting client resistance in text-based therapy. We introduce a theory-driven framework that decomposes counselor responses into four distinct communication mechanisms. Leveraging this framework, we curate and share an expert-annotated dataset of real-world counseling excerpts, pairing counselor-client interactions with professional ratings and explanatory rationales. Using this data, we perform full-parameter instruction tuning on a Llama-3.1-8B-Instruct backbone to model fine-grained evaluative judgments of response quality and generate explanations underlying. Experimental results show that our approach can effectively distinguish the quality of different communication mechanisms (77-81% F1), substantially outperforming GPT-4o and Claude-3.5-Sonnet (45-59% F1). Moreover, the model produces high-quality explanations that closely align with expert references and receive near-ceiling ratings from human experts (2.8-2.9/3.0). A controlled experiment with 43 counselors further confirms that receiving these AI-generated feedback significantly improves counselors' ability to respond effectively to client resistance.",
        "tags": [
            "GPT",
            "LLM",
            "LLaMA"
        ]
    },
    {
        "id": "91",
        "title": "DAGS-SLAM: Dynamic-Aware 3DGS SLAM via Spatiotemporal Motion Probability and Uncertainty-Aware Scheduling",
        "author": [
            "Li Zhang",
            "Yu-An Liu",
            "Xijia Jiang",
            "Conghao Huang",
            "Danyang Li",
            "Yanyong Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21644",
        "abstract": "Mobile robots and IoT devices demand real-time localization and dense reconstruction under tight compute and energy budgets. While 3D Gaussian Splatting (3DGS) enables efficient dense SLAM, dynamic objects and occlusions still degrade tracking and mapping. Existing dynamic 3DGS-SLAM often relies on heavy optical flow and per-frame segmentation, which is costly for mobile deployment and brittle under challenging illumination. We present DAGS-SLAM, a dynamic-aware 3DGS-SLAM system that maintains a spatiotemporal motion probability (MP) state per Gaussian and triggers semantics on demand via an uncertainty-aware scheduler. DAGS-SLAM fuses lightweight YOLO instance priors with geometric cues to estimate and temporally update MP, propagates MP to the front-end for dynamic-aware correspondence selection, and suppresses dynamic artifacts in the back-end via MP-guided optimization. Experiments on public dynamic RGB-D benchmarks show improved reconstruction and robust tracking while sustaining real-time throughput on a commodity GPU, demonstrating a practical speed-accuracy tradeoff with reduced semantic invocations toward mobile deployment.",
        "tags": [
            "3D",
            "Gaussian Splatting",
            "SLAM",
            "Segmentation"
        ]
    },
    {
        "id": "92",
        "title": "Lie Flow: Video Dynamic Fields Modeling and Predicting with Lie Algebra as Geometric Physics Principle",
        "author": [
            "Weidong Qiao",
            "Wangmeng Zuo",
            "Hui Li"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21645",
        "abstract": "Modeling 4D scenes requires capturing both spatial structure and temporal motion, which is challenging due to the need for physically consistent representations of complex rigid and non-rigid motions. Existing approaches mainly rely on translational displacements, which struggle to represent rotations, articulated transformations, often leading to spatial inconsistency and physically implausible motion. LieFlow, a dynamic radiance representation framework that explicitly models motion within the SE(3) Lie group, enabling coherent learning of translation and rotation in a unified geometric space. The SE(3) transformation field enforces physically inspired constraints to maintain motion continuity and geometric consistency. The evaluation includes a synthetic dataset with rigid-body trajectories and two real-world datasets capturing complex motion under natural lighting and occlusions. Across all datasets, LieFlow consistently improves view-synthesis fidelity, temporal coherence, and physical realism over NeRF-based baselines. These results confirm that SE(3)-based motion modeling offers a robust and physically grounded framework for representing dynamic 4D scenes.",
        "tags": [
            "NeRF"
        ]
    },
    {
        "id": "93",
        "title": "Scalable Multilingual Multimodal Machine Translation with Speech-Text Fusion",
        "author": [
            "Yexing Du",
            "Youcheng Pan",
            "Zekun Wang",
            "Zheng Chu",
            "Yichong Huang",
            "Kaiyuan Liu",
            "Bo Yang",
            "Yang Xiang",
            "Ming Liu",
            "Bing Qin"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21646",
        "abstract": "Multimodal Large Language Models (MLLMs) have achieved notable success in enhancing translation performance by integrating multimodal information. However, existing research primarily focuses on image-guided methods, whose applicability is constrained by the scarcity of multilingual image-text pairs. The speech modality overcomes this limitation due to its natural alignment with text and the abundance of existing speech datasets, which enable scalable language coverage. In this paper, we propose a Speech-guided Machine Translation (SMT) framework that integrates speech and text as fused inputs into an MLLM to improve translation quality. To mitigate reliance on low-resource data, we introduce a Self-Evolution Mechanism. The core components of this framework include a text-to-speech model, responsible for generating synthetic speech, and an MLLM capable of classifying synthetic speech samples and iteratively optimizing itself using positive samples. Experimental results demonstrate that our framework surpasses all existing methods on the Multi30K multimodal machine translation benchmark, achieving new state-of-the-art results. Furthermore, on general machine translation datasets, particularly the FLORES-200, it achieves average state-of-the-art performance in 108 translation directions. Ablation studies on CoVoST-2 confirms that differences between synthetic and authentic speech have negligible impact on translation quality. The code and models are released at https://github.com/yxduir/LLM-SRT.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "94",
        "title": "PPCR-IM: A System for Multi-layer DAG-based Public Policy Consequence Reasoning and Social Indicator Mapping",
        "author": [
            "Zichen Song",
            "Weijia Li"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21650",
        "abstract": "Public policy decisions are typically justified using a narrow set of headline indicators, leaving many downstream social impacts unstructured and difficult to compare across policies. We propose PPCR-IM, a system for multi-layer DAG-based consequence reasoning and social indicator mapping that addresses this gap. Given a policy description and its context, PPCR-IM uses an LLM-driven, layer-wise generator to construct a directed acyclic graph of intermediate consequences, allowing child nodes to have multiple parents to capture joint influences. A mapping module then aligns these nodes to a fixed indicator set and assigns one of three qualitative impact directions: increase, decrease, or ambiguous change. For each policy episode, the system outputs a structured record containing the DAG, indicator mappings, and three evaluation measures: an expected-indicator coverage score, a discovery rate for overlooked but relevant indicators, and a relative focus ratio comparing the systems coverage to that of the government. PPCR-IM is available both as an online demo and as a configurable XLSX-to-JSON batch pipeline.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "95",
        "title": "Sparsity Induction for Accurate Post-Training Pruning of Large Language Models",
        "author": [
            "Minhao Jiang",
            "Zhikai Li",
            "Xuewen Liu",
            "Jing Zhang",
            "Mengjuan Chen",
            "Qingyi Gu"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21652",
        "abstract": "Large language models have demonstrated capabilities in text generation, while their increasing parameter scales present challenges in computational and memory efficiency. Post-training sparsity (PTS), which reduces model cost by removing weights from dense networks, is an effective approach. However, native dense matrices lack high sparsity, making existing approaches that directly remove weights disrupt model states, resulting in unsatisfactory performance recovery even with post-tuning. We propose Sparsity Induction, which promotes models toward higher sparsity at both distribution and feature levels before pruning, to push the limits of PTS. At the distribution level, we enhance distributional sparsity through mathematically equivalent scaling transformations, which are fully absorbable and incur no extra parameters or inference-time overhead. At the feature level, we introduce Spectral Norm Loss to promote feature sparsity from a low-rank perspective. Experiments across diverse model architectures and tasks demonstrate that our method further enhances sparsity-friendliness, achieving superior pruning performance over existing approaches.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "96",
        "title": "Irresponsible Counselors: Large Language Models and the Loneliness of Modern Humans",
        "author": [
            "Abas Bertina",
            "Sara Shakeri"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21653",
        "abstract": "Large language models (LLMs) have rapidly shifted from peripheral assistive tools to constant companions in everyday and even high stakes human decision making. Many users now consult these models about health, intimate relationships, finance, education, and identity, because LLMs are, in practice, multi domain, inexpensive, always available, and seemingly nonjudgmental. At the same time, from a technical perspective these models rely on transformer architectures, exhibit highly unpredictable behavior in detail, and are fundamentally stateless; conceptually, they lack any real subjectivity, intention, or responsibility. This article argues that the combination of this technical architecture with the social position of LLMs as multis pecialist counselors in an age of human loneliness produces a new kind of advisory intimacy without a subject. In this new relation, model outputs are experienced as if they contained deep understanding, neutrality, emotional support, and user level control, while at the deeper level there is no human agent who is straightforwardly responsible or answerable. By reviewing dominant strands of AI ethics critique, we show that focusing only on developer liability, data bias, or emotional attachment to chatbots is insufficient to capture this configuration. We then explore the ethical and political implications of this advisory intimacy without a subject for policy-making, for justice in access to counseling, and for how we understand loneliness in the contemporary world.",
        "tags": [
            "LLM",
            "Transformer"
        ]
    },
    {
        "id": "97",
        "title": "CCCaption: Dual-Reward Reinforcement Learning for Complete and Correct Image Captioning",
        "author": [
            "Zhijiang Tang",
            "Linhua Wang",
            "Jiaxin Qi",
            "Weihao Jiang",
            "Peng Hou",
            "Anxiang Zeng",
            "Jianqiang Huang"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21655",
        "abstract": "Image captioning remains a fundamental task for vision language understanding, yet ground-truth supervision still relies predominantly on human-annotated references. Because human annotations reflect subjective preferences and expertise, ground-truth captions are often incomplete or even incorrect, which in turn limits caption models. We argue that caption quality should be assessed by two objective aspects: completeness (does the caption cover all salient visual facts?) and correctness (are the descriptions true with respect to the image?). To this end, we introduce CCCaption: a dual-reward reinforcement learning framework with a dedicated fine-tuning corpus that explicitly optimizes these properties to generate \\textbf{C}omplete and \\textbf{C}orrect \\textbf{Captions}. For completeness, we use diverse LVLMs to disentangle the image into a set of visual queries, and reward captions that answer more of these queries, with a dynamic query sampling strategy to improve training efficiency. For correctness, we penalize captions that contain hallucinations by validating the authenticity of sub-caption queries, which are derived from the caption decomposition. Our symmetric dual-reward optimization jointly maximizes completeness and correctness, guiding models toward captions that better satisfy these objective criteria. Extensive experiments across standard captioning benchmarks show consistent improvements, offering a principled path to training caption models beyond human-annotation imitation.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "98",
        "title": "Space-Time Forecasting of Dynamic Scenes with Motion-aware Gaussian Grouping",
        "author": [
            "Junmyeong Lee",
            "Hoseung Choi",
            "Minsu Cho"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21668",
        "abstract": "Forecasting dynamic scenes remains a fundamental challenge in computer vision, as limited observations make it difficult to capture coherent object-level motion and long-term temporal evolution. We present Motion Group-aware Gaussian Forecasting (MoGaF), a framework for long-term scene extrapolation built upon the 4D Gaussian Splatting representation. MoGaF introduces motion-aware Gaussian grouping and group-wise optimization to enforce physically consistent motion across both rigid and non-rigid regions, yielding spatially coherent dynamic representations. Leveraging this structured space-time representation, a lightweight forecasting module predicts future motion, enabling realistic and temporally stable scene evolution. Experiments on synthetic and real-world datasets demonstrate that MoGaF consistently outperforms existing baselines in rendering quality, motion plausibility, and long-term forecasting stability. Our project page is available at https://slime0519.github.io/mogaf",
        "tags": [
            "Gaussian Splatting"
        ]
    },
    {
        "id": "99",
        "title": "DWA-KD: Dual-Space Weighting and Time-Warped Alignment for Cross-Tokenizer Knowledge Distillation",
        "author": [
            "Duc Trung Vu",
            "Pham Khanh Chi",
            "Dat Phi Van",
            "Linh Ngo Van",
            "Sang Dinh",
            "Trung Le"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21669",
        "abstract": "Knowledge Distillation (KD) has emerged as a crucial technique for compressing Large Language Models (LLMs). Although existing cross-tokenizer KD methods have made notable progress, their effectiveness remains constrained by suboptimal alignment across sequence and vocabulary levels. To address these limitations, we introduce Dual-Space Weighting and Time-Warped Alignment (DWA-KD), a novel cross-tokenizer distillation framework that enhances token-wise distillation through dual-space entropy-based weighting and achieves precise sequence-level alignment by leveraging both lexical and semantic information. At the token level, DWA-KD maps teacher representations into the student space and vice versa, performing dual-space KD via Kullback-Leibler divergence (KL). The process is modulated by dual-space weights that up-weight tokens where the student is uncertain and the teacher is confident, thereby focusing learning on informative tokens rather than treating all positions equally. At the sequence level, DWA-KD applies Soft Dynamic Time Warping (Soft-DTW) to both the embedding and final hidden-state layers, enabling robust alignment of lexical and contextual semantics between teacher and student sequences. Extensive experiments across diverse NLP benchmarks demonstrate that DWA-KD outperforms state-of-the-art KD baselines, while ablation studies confirm the complementary contributions of entropy-based token weighting and embedding and final hidden state layer Soft-DTW alignment.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "100",
        "title": "Hierarchical LLM-Based Multi-Agent Framework with Prompt Optimization for Multi-Robot Task Planning",
        "author": [
            "Tomoya Kawabe",
            "Rin Takano"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21670",
        "abstract": "Multi-robot task planning requires decomposing natural-language instructions into executable actions for heterogeneous robot teams. Conventional Planning Domain Definition Language (PDDL) planners provide rigorous guarantees but struggle to handle ambiguous or long-horizon missions, while large language models (LLMs) can interpret instructions and propose plans but may hallucinate or produce infeasible actions. We present a hierarchical multi-agent LLM-based planner with prompt optimization: an upper layer decomposes tasks and assigns them to lower-layer agents, which generate PDDL problems solved by a classical planner. When plans fail, the system applies TextGrad-inspired textual-gradient updates to optimize each agent's prompt and thereby improve planning accuracy. In addition, meta-prompts are learned and shared across agents within the same layer, enabling efficient prompt optimization in multi-agent settings. On the MAT-THOR benchmark, our planner achieves success rates of 0.95 on compound tasks, 0.84 on complex tasks, and 0.60 on vague tasks, improving over the previous state-of-the-art LaMMA-P by 2, 7, and 15 percentage points respectively. An ablation study shows that the hierarchical structure, prompt optimization, and meta-prompt sharing contribute roughly +59, +37, and +4 percentage points to the overall success rate.",
        "tags": [
            "LLM",
            "Robotics"
        ]
    },
    {
        "id": "101",
        "title": "Hierarchical Lead Critic based Multi-Agent Reinforcement Learning",
        "author": [
            "David Eckel",
            "Henri MeeÃ"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21680",
        "abstract": "Cooperative Multi-Agent Reinforcement Learning (MARL) solves complex tasks that require coordination from multiple agents, but is often limited to either local (independent learning) or global (centralized learning) perspectives. In this paper, we introduce a novel sequential training scheme and MARL architecture, which learns from multiple perspectives on different hierarchy levels. We propose the Hierarchical Lead Critic (HLC) - inspired by natural emerging distributions in team structures, where following high-level objectives combines with low-level execution. HLC demonstrates that introducing multiple hierarchies, leveraging local and global perspectives, can lead to improved performance with high sample efficiency and robust policies. Experimental results conducted on cooperative, non-communicative, and partially observable MARL benchmarks demonstrate that HLC outperforms single hierarchy baselines and scales robustly with increasing amounts of agents and difficulty.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "102",
        "title": "AkiraRust: Re-thinking LLM-aided Rust Repair Using a Feedback-guided Thinking Switch",
        "author": [
            "Renshuang Jiang",
            "Yichong Wang",
            "Pan Dong",
            "Xiaoxiang Fang",
            "Zhenling Duan",
            "Tinglue Wang",
            "Yuchen Hu",
            "Jie Yu",
            "Zhe Jiang"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21681",
        "abstract": "Eliminating undefined behaviors (UBs) in Rust programs requires a deep semantic understanding to enable accurate and reliable repair. While existing studies have demonstrated the potential of LLMs to support Rust code analysis and repair, most frameworks remain constrained by inflexible templates or lack grounding in executable semantics, resulting in limited contextual awareness and semantic incorrectness. Here, we present AkiraRust, an LLM-driven repair and verification framework that incorporates a finite-state machine to dynamically adapt its detection and repair flow to runtime semantic conditions. AkiraRust introduces a dual-mode reasoning strategy that coordinates fast and slow thinking across multiple agents. Each agent is mapped to an FSM state, and a waveform-driven transition controller manages state switching, rollback decisions, and semantic check pointing, enabling context-aware and runtime-adaptive repair. Experimental results show that AkiraRust achieves about 92% semantic correctness and delivers a 2.2x average speedup compared to SOTA.",
        "tags": [
            "Detection",
            "LLM"
        ]
    },
    {
        "id": "103",
        "title": "\"Without AI, I Would Never Share This Online\": Unpacking How LLMs Catalyze Women's Sharing of Gendered Experiences on Social Media",
        "author": [
            "Runhua Zhang",
            "Ziqi Pan",
            "Huiran Yi",
            "Huamin Qu",
            "Xiaojuan Ma"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21686",
        "abstract": "Sharing gendered experiences on social media has been widely recognized as supporting women's personal sense-making and contributing to digital feminism. However, there are known concerns, such as fear of judgment and backlash, that may discourage women from posting online. In this study, we examine a recurring practice on Xiaohongshu, a popular Chinese social media platform, in which women share their gendered experiences alongside screenshots of conversations with LLMs. We conducted semi-structured interviews with 20 women to investigate whether and how interactions with LLMs might support women in articulating and sharing gendered experiences. Our findings reveal that, beyond those external concerns, women also hold self-imposed standards regarding what feels appropriate and worthwhile to share publicly. We further show how interactions with LLMs help women meet these standards and navigate such concerns. We conclude by discussing how LLMs might be carefully and critically leveraged to support women's everyday expression online.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "104",
        "title": "TiMi: Empower Time Series Transformers with Multimodal Mixture of Experts",
        "author": [
            "Jiafeng Lin",
            "Yuxuan Wang",
            "Huakun Luo",
            "Zhongyi Pei",
            "Jianmin Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21693",
        "abstract": "Multimodal time series forecasting has garnered significant attention for its potential to provide more accurate predictions than traditional single-modality models by leveraging rich information inherent in other modalities. However, due to fundamental challenges in modality alignment, existing methods often struggle to effectively incorporate multimodal data into predictions, particularly textual information that has a causal influence on time series fluctuations, such as emergency reports and policy announcements. In this paper, we reflect on the role of textual information in numerical forecasting and propose Time series transformers with Multimodal Mixture-of-Experts, TiMi, to unleash the causal reasoning capabilities of LLMs. Concretely, TiMi utilizes LLMs to generate inferences on future developments, which serve as guidance for time series forecasting. To seamlessly integrate both exogenous factors and time series into predictions, we introduce a Multimodal Mixture-of-Experts (MMoE) module as a lightweight plug-in to empower Transformer-based time series models for multimodal forecasting, eliminating the need for explicit representation-level alignment. Experimentally, our proposed TiMi demonstrates consistent state-of-the-art performance on sixteen real-world multimodal forecasting benchmarks, outperforming advanced baselines while offering both strong adaptability and interpretability.",
        "tags": [
            "LLM",
            "MoE",
            "Transformer"
        ]
    },
    {
        "id": "105",
        "title": "E-comIQ-ZH: A Human-Aligned Dataset and Benchmark for Fine-Grained Evaluation of E-commerce Posters with Chain-of-Thought",
        "author": [
            "Meiqi Sun",
            "Mingyu Li",
            "Junxiong Zhu"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21698",
        "abstract": "Generative AI is widely used to create commercial posters. However, rapid advances in generation have outpaced automated quality assessment. Existing models emphasize generic esthetics or low level distortions and lack the functional criteria required for e-commerce design. It is especially challenging for Chinese content, where complex characters often produce subtle but critical textual artifacts that are overlooked by existing methods. To address this, we introduce E-comIQ-ZH, a framework for evaluating Chinese e-commerce posters. We build the first dataset E-comIQ-18k to feature multi dimensional scores and expert calibrated Chain of Thought (CoT) rationales. Using this dataset, we train E-comIQ-M, a specialized evaluation model that aligns with human expert judgment. Our framework enables E-comIQ-Bench, the first automated and scalable benchmark for the generation of Chinese e-commerce posters. Extensive experiments show our E-comIQ-M aligns more closely with expert standards and enables scalable automated assessment of e-commerce posters. All datasets, models, and evaluation tools will be released to support future research in this http://area.Code will be available at https://github.com/4mm7/E-comIQ-ZH.",
        "tags": [
            "CoT"
        ]
    },
    {
        "id": "106",
        "title": "Learning Complex Physical Regimes via Coverage-oriented Uncertainty Quantification: An application to the Critical Heat Flux",
        "author": [
            "Michele Cazzola",
            "Alberto Ghione",
            "Lucia Sargentini",
            "Julien Nespoulous",
            "Riccardo Finotello"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21701",
        "abstract": "A central challenge in scientific machine learning (ML) is the correct representation of physical systems governed by multi-regime behaviours. In these scenarios, standard data analysis techniques often fail to capture the nature of the data, as the system's response varies significantly across the state space due to its stochasticity and the different physical regimes. Uncertainty quantification (UQ) should thus not be viewed merely as a safety assessment, but as a support to the learning task itself, guiding the model to internalise the behaviour of the data. We address this by focusing on the Critical Heat Flux (CHF) benchmark and dataset presented by the OECD/NEA Expert Group on Reactor Systems Multi-Physics. This case study represents a test for scientific ML due to the non-linear dependence of CHF on the inputs and the existence of distinct microscopic physical regimes. These regimes exhibit diverse statistical profiles, a complexity that requires UQ techniques to internalise the data behaviour and ensure reliable predictions. In this work, we conduct a comparative analysis of UQ methodologies to determine their impact on physical representation. We contrast post-hoc methods, specifically conformal prediction, against end-to-end coverage-oriented pipelines, including (Bayesian) heteroscedastic regression and quality-driven losses. These approaches treat uncertainty not as a final metric, but as an active component of the optimisation process, modelling the prediction and its behaviour simultaneously. We show that while post-hoc methods ensure statistical calibration, coverage-oriented learning effectively reshapes the model's representation to match the complex physical regimes. The result is a model that delivers not only high predictive accuracy but also a physically consistent uncertainty estimation that adapts dynamically to the intrinsic variability of the CHF.",
        "tags": [
            "FLUX"
        ]
    },
    {
        "id": "107",
        "title": "Dynamic Multimodal Activation Steering for Hallucination Mitigation in Large Vision-Language Models",
        "author": [
            "Jianghao Yin",
            "Qin Chen",
            "Kedi Chen",
            "Jie Zhou",
            "Xingjiao Wu",
            "Liang He"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21704",
        "abstract": "Large Vision-Language Models (LVLMs) exhibit outstanding performance on vision-language tasks but struggle with hallucination problems. Through in-depth analysis of LVLM activation patterns, we reveal two key findings: 1) truthfulness and visual perception capabilities predominantly engage different subsets of attention heads within the model architecture; and 2) truthfulness steering vectors vary significantly across different semantic contexts. Based on these observations, we propose Dynamic Multimodal Activation Steering, a training-free approach for hallucination mitigation. Our method constructs a semantic-based truthfulness steering vector database and computes visual perception steering vectors, enabling context-aware interventions during inference by dynamically selecting the most relevant steering vectors based on input semantic similarity and applying them to the most influential attention heads. We conduct comprehensive experiments across multiple models and datasets, demonstrating that our approach significantly enhances model performance, outperforming existing state-of-the-art methods.",
        "tags": [
            "VLM"
        ]
    },
    {
        "id": "108",
        "title": "Innovative Tooth Segmentation Using Hierarchical Features and Bidirectional Sequence Modeling",
        "author": [
            "Xinxin Zhao",
            "Jian Jiang",
            "Yan Tian",
            "Liqin Wu",
            "Zhaocheng Xu",
            "Teddy Yang",
            "Yunuo Zou",
            "Xun Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21712",
        "abstract": "Tooth image segmentation is a cornerstone of dental digitization. However, traditional image encoders relying on fixed-resolution feature maps often lead to discontinuous segmentation and poor discrimination between target regions and background, due to insufficient modeling of environmental and global context. Moreover, transformer-based self-attention introduces substantial computational overhead because of its quadratic complexity (O(n^2)), making it inefficient for high-resolution dental images. To address these challenges, we introduce a three-stage encoder with hierarchical feature representation to capture scale-adaptive information in dental images. By jointly leveraging low-level details and high-level semantics through cross-scale feature fusion, the model effectively preserves fine structural information while maintaining strong contextual awareness. Furthermore, a bidirectional sequence modeling strategy is incorporated to enhance global spatial context understanding without incurring high computational cost.\nWe validate our method on two dental datasets, with experimental results demonstrating its superiority over existing approaches. On the OralVision dataset, our model achieves a 1.1% improvement in mean intersection over union (mIoU).",
        "tags": [
            "Segmentation",
            "Transformer"
        ]
    },
    {
        "id": "109",
        "title": "Two-Stage Active Distribution Network Voltage Control via LLM-RL Collaboration: A Hybrid Knowledge-Data-Driven Approach",
        "author": [
            "Xu Yang",
            "Chenhui Lin",
            "Xiang Ma",
            "Dong Liu",
            "Ran Zheng",
            "Haotian Liu",
            "Wenchuan Wu"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21715",
        "abstract": "The growing integration of distributed photovoltaics (PVs) into active distribution networks (ADNs) has exacerbated operational challenges, making it imperative to coordinate diverse equipment to mitigate voltage violations and enhance power quality. Although existing data-driven approaches have demonstrated effectiveness in the voltage control problem, they often require extensive trial-and-error exploration and struggle to incorporate heterogeneous information, such as day-ahead forecasts and semantic-based grid codes. Considering the operational scenarios and requirements in real-world ADNs, in this paper, we propose a hybrid knowledge-data-driven approach that leverages dynamic collaboration between a large language model (LLM) agent and a reinforcement learning (RL) agent to achieve two-stage voltage control. In the day-ahead stage, the LLM agent receives coarse region-level forecasts and generates scheduling strategies for on-load tap changer (OLTC) and shunt capacitors (SCs) to regulate the overall voltage profile. Then in the intra-day stage, based on accurate node-level measurements, the RL agent refines terminal voltages by deriving reactive power generation strategies for PV inverters. On top of the LLM-RL collaboration framework, we further propose a self-evolution mechanism for the LLM agent and a pretrain-finetune pipeline for the RL agent, effectively enhancing and coordinating the policies for both agents. The proposed approach not only aligns more closely with practical operational characteristics but also effectively utilizes the inherent knowledge and reasoning capabilities of the LLM agent, significantly improving training efficiency and voltage control performance. Comprehensive comparisons and ablation studies demonstrate the effectiveness of the proposed method.",
        "tags": [
            "LLM",
            "RL"
        ]
    },
    {
        "id": "110",
        "title": "TranX-Adapter: Bridging Artifacts and Semantics within MLLMs for Robust AI-generated Image Detection",
        "author": [
            "Wenbin Wang",
            "Yuge Huang",
            "Jianqing Xu",
            "Yue Yu",
            "Jiangtao Yan",
            "Shouhong Ding",
            "Pan Zhou",
            "Yong Luo"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21716",
        "abstract": "Rapid advances in AI-generated image (AIGI) technology enable highly realistic synthesis, threatening public information integrity and security. Recent studies have demonstrated that incorporating texture-level artifact features alongside semantic features into multimodal large language models (MLLMs) can enhance their AIGI detection capability. However, our preliminary analyses reveal that artifact features exhibit high intra-feature similarity, leading to an almost uniform attention map after the softmax operation. This phenomenon causes attention dilution, thereby hindering effective fusion between semantic and artifact features. To overcome this limitation, we propose a lightweight fusion adapter, TranX-Adapter, which integrates a Task-aware Optimal-Transport Fusion that leverages the Jensen-Shannon divergence between artifact and semantic prediction probabilities as a cost matrix to transfer artifact information into semantic features, and an X-Fusion that employs cross-attention to transfer semantic information into artifact features. Experiments on standard AIGI detection benchmarks upon several advanced MLLMs, show that our TranX-Adapter brings consistent and significant improvements (up to +6% accuracy).",
        "tags": [
            "Detection",
            "LLM"
        ]
    },
    {
        "id": "111",
        "title": "Evaluating the relationship between regularity and learnability in recursive numeral systems using Reinforcement Learning",
        "author": [
            "Andrea Silvi",
            "Ponrawee Prasertsom",
            "Jennifer Culbertson",
            "Devdatt Dubhashi",
            "Moa Johansson",
            "Kenny Smith"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21720",
        "abstract": "Human recursive numeral systems (i.e., counting systems such as English base-10 numerals), like many other grammatical systems, are highly regular. Following prior work that relates cross-linguistic tendencies to biases in learning, we ask whether regular systems are common because regularity facilitates learning. Adopting methods from the Reinforcement Learning literature, we confirm that highly regular human(-like) systems are easier to learn than unattested but possible irregular systems. This asymmetry emerges under the natural assumption that recursive numeral systems are designed for generalisation from limited data to represent all integers exactly. We also find that the influence of regularity on learnability is absent for unnatural, highly irregular systems, whose learnability is influenced instead by signal length, suggesting that different pressures may influence learnability differently in different parts of the space of possible numeral systems. Our results contribute to the body of work linking learnability to cross-linguistic prevalence.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "112",
        "title": "LessMimic: Long-Horizon Humanoid Interaction with Unified Distance Field Representations",
        "author": [
            "Yutang Lin",
            "Jieming Cui",
            "Yixuan Li",
            "Baoxiong Jia",
            "Yixin Zhu",
            "Siyuan Huang"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21723",
        "abstract": "Humanoid robots that autonomously interact with physical environments over extended horizons represent a central goal of embodied intelligence. Existing approaches rely on reference motions or task-specific rewards, tightly coupling policies to particular object geometries and precluding multi-skill generalization within a single framework. A unified interaction representation enabling reference-free inference, geometric generalization, and long-horizon skill composition within one policy remains an open challenge. Here we show that Distance Field (DF) provides such a representation: LessMimic conditions a single whole-body policy on DF-derived geometric cues--surface distances, gradients, and velocity decompositions--removing the need for motion references, with interaction latents encoded via a Variational Auto-Encoder (VAE) and post-trained using Adversarial Interaction Priors (AIP) under Reinforcement Learning (RL). Through DAgger-style distillation that aligns DF latents with egocentric depth features, LessMimic further transfers seamlessly to vision-only deployment without motion capture (MoCap) infrastructure. A single LessMimic policy achieves 80--100% success across object scales from 0.4x to 1.6x on PickUp and SitStand where baselines degrade sharply, attains 62.1% success on 5 task instances trajectories, and remains viable up to 40 sequentially composed tasks. By grounding interaction in local geometry rather than demonstrations, LessMimic offers a scalable path toward humanoid robots that generalize, compose skills, and recover from failures in unstructured environments.",
        "tags": [
            "RL",
            "VAE"
        ]
    },
    {
        "id": "113",
        "title": "Explore-on-Graph: Incentivizing Autonomous Exploration of Large Language Models on Knowledge Graphs with Path-refined Reward Modeling",
        "author": [
            "Shiqi Yan",
            "Yubo Chen",
            "Ruiqi Zhou",
            "Zhengxi Yao",
            "Shuai Chen",
            "Tianyi Zhang",
            "Shijie Zhang",
            "Wei Qiang Zhang",
            "Yongfeng Huang",
            "Haixin Duan",
            "Yunqi Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21728",
        "abstract": "The reasoning process of Large Language Models (LLMs) is often plagued by hallucinations and missing facts in question-answering tasks. A promising solution is to ground LLMs' answers in verifiable knowledge sources, such as Knowledge Graphs (KGs). Prevailing KG-enhanced methods typically constrained LLM reasoning either by enforcing rules during generation or by imitating paths from a fixed set of demonstrations. However, they naturally confined the reasoning patterns of LLMs within the scope of prior experience or fine-tuning data, limiting their generalizability to out-of-distribution graph reasoning problems. To tackle this problem, in this paper, we propose Explore-on-Graph (EoG), a novel framework that encourages LLMs to autonomously explore a more diverse reasoning space on KGs. To incentivize exploration and discovery of novel reasoning paths, we propose to introduce reinforcement learning during training, whose reward is the correctness of the reasoning paths' final answers. To enhance the efficiency and meaningfulness of the exploration, we propose to incorporate path information as additional reward signals to refine the exploration process and reduce futile efforts. Extensive experiments on five KGQA benchmark datasets demonstrate that, to the best of our knowledge, our method achieves state-of-the-art performance, outperforming not only open-source but also even closed-source LLMs.",
        "tags": [
            "LLM",
            "RL"
        ]
    },
    {
        "id": "114",
        "title": "Joint-Aligned Latent Action: Towards Scalable VLA Pretraining in the Wild",
        "author": [
            "Hao Luo",
            "Ye Wang",
            "Wanpeng Zhang",
            "Haoqi Yuan",
            "Yicheng Feng",
            "Haiweng Xu",
            "Sipeng Zheng",
            "Zongqing Lu"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21736",
        "abstract": "Despite progress, Vision-Language-Action models (VLAs) are limited by a scarcity of large-scale, diverse robot data. While human manipulation videos offer a rich alternative, existing methods are forced to choose between small, precisely-labeled datasets and vast in-the-wild footage with unreliable hand tracking labels. We present JALA, a pretraining framework that learns Jointly-Aligned Latent Actions. JALA bypasses full visual dynamic reconstruction, instead learns a predictive action embedding aligned with both inverse dynamics and real actions. This yields a transition-aware, behavior-centric latent space for learning from heterogeneous human data. We scale this approach with UniHand-Mix, a 7.5M video corpus (>2,000 hours) blending laboratory and in-the-wild footage. Experiments demonstrate that JALA generates more realistic hand motions in both controlled and unconstrained scenarios, significantly improving downstream robot manipulation performance in both simulation and real-world tasks. These results indicate that jointly-aligned latent actions offer a scalable pathway for VLA pretraining from human data.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "115",
        "title": "Enhancing Multi-Modal LLMs Reasoning via Difficulty-Aware Group Normalization",
        "author": [
            "Jinghan Li",
            "Junfeng Fang",
            "Jinda Lu",
            "Yuan Wang",
            "Xiaoyan Guo",
            "Tianyu Zhang",
            "Xiang Wang",
            "Xiangnan He"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21743",
        "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR) and Group Relative Policy Optimization (GRPO) have significantly advanced the reasoning capabilities of large language models. Extending these methods to multimodal settings, however, faces a critical challenge: the instability of std-based normalization, which is easily distorted by extreme samples with nearly positive or negative rewards. Unlike pure-text LLMs, multimodal models are particularly sensitive to such distortions, as both perceptual and reasoning errors influence their responses. To address this, we characterize each sample by its difficulty, defined through perceptual complexity (measured via visual entropy) and reasoning uncertainty (captured by model confidence). Building on this characterization, we propose difficulty-aware group normalization (Durian), which re-groups samples by difficulty levels and shares the std within each group. Our approach preserves GRPO's intra-group distinctions while eliminating sensitivity to extreme cases, yielding significant performance gains across multiple multimodal reasoning benchmarks.",
        "tags": [
            "GRPO",
            "LLM",
            "RL"
        ]
    },
    {
        "id": "116",
        "title": "RABot: Reinforcement-Guided Graph Augmentation for Imbalanced and Noisy Social Bot Detection",
        "author": [
            "Longlong Zhang",
            "Xi Wang",
            "Haotong Du",
            "Yangyi Xu",
            "Zhuo Liu",
            "Yang Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21749",
        "abstract": "Social bot detection is pivotal for safeguarding the integrity of online information ecosystems. Although recent graph neural network (GNN) solutions achieve strong results, they remain hindered by two practical challenges: (i) severe class imbalance arising from the high cost of generating bots, and (ii) topological noise introduced by bots that skillfully mimic human behavior and forge deceptive links. We propose the Reinforcement-guided graph Augmentation social Bot detector (RABot), a multi-granularity graph-augmentation framework that addresses both issues in a unified manner. RABot employs a neighborhood-aware oversampling strategy that linearly interpolates minority-class embeddings within local subgraphs, thereby stabilizing the decision boundary under low-resource regimes. Concurrently, a reinforcement-learning-driven edge-filtering module combines similarity-based edge features with adaptive threshold optimization to excise spurious interactions during message passing, yielding a cleaner topology. Extensive experiments on three real-world benchmarks and four GNN backbones demonstrate that RABot consistently surpasses state-of-the-art baselines. In addition, since its augmentation and filtering modules are orthogonal to the underlying architecture, RABot can be seamlessly integrated into existing GNN pipelines to boost performance with minimal overhead.",
        "tags": [
            "Detection",
            "RL"
        ]
    },
    {
        "id": "117",
        "title": "Learning from Yesterday's Error: An Efficient Online Learning Method for Traffic Demand Prediction",
        "author": [
            "Xiannan Huang",
            "Quan Yuan",
            "Chao Yang"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21757",
        "abstract": "Accurately predicting short-term traffic demand is critical for intelligent transportation systems. While deep learning models achieve strong performance under stationary conditions, their accuracy often degrades significantly when faced with distribution shifts caused by external events or evolving urban dynamics. Frequent model retraining to adapt to such changes incurs prohibitive computational costs, especially for large-scale or foundation models. To address this challenge, we propose FORESEE (Forecasting Online with Residual Smoothing and Ensemble Experts), a lightweight online adaptation framework that is accurate, robust, and computationally efficient. FORESEE operates without any parameter updates to the base model. Instead, it corrects today's forecast in each region using yesterday's prediction error, stabilized through exponential smoothing guided by a mixture-of-experts mechanism that adapts to recent error dynamics. Moreover, an adaptive spatiotemporal smoothing component propagates error signals across neighboring regions and time slots, capturing coherent shifts in demand patterns. Extensive experiments on seven real-world datasets with three backbone models demonstrate that FORESEE consistently improves prediction accuracy, maintains robustness even when distribution shifts are minimal (avoiding performance degradation), and achieves the lowest computational overhead among existing online methods. By enabling real-time adaptation of traffic forecasting models with negligible computational cost, FORESEE paves the way for deploying reliable, up-to-date prediction systems in dynamic urban environments. Code and data are available at https://github.com/xiannanhuang/FORESEE",
        "tags": [
            "MoE"
        ]
    },
    {
        "id": "118",
        "title": "Accelerating Diffusion via Hybrid Data-Pipeline Parallelism Based on Conditional Guidance Scheduling",
        "author": [
            "Euisoo Jung",
            "Byunghyun Kim",
            "Hyunjin Kim",
            "Seonghye Cho",
            "Jae-Gil Lee"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21760",
        "abstract": "Diffusion models have achieved remarkable progress in high-fidelity image, video, and audio generation, yet inference remains computationally expensive. Nevertheless, current diffusion acceleration methods based on distributed parallelism suffer from noticeable generation artifacts and fail to achieve substantial acceleration proportional to the number of GPUs. Therefore, we propose a hybrid parallelism framework that combines a novel data parallel strategy, condition-based partitioning, with an optimal pipeline scheduling method, adaptive parallelism switching, to reduce generation latency and achieve high generation quality in conditional diffusion models. The key ideas are to (i) leverage the conditional and unconditional denoising paths as a new data-partitioning perspective and (ii) adaptively enable optimal pipeline parallelism according to the denoising discrepancy between these two paths. Our framework achieves $2.31\\times$ and $2.07\\times$ latency reductions on SDXL and SD3, respectively, using two NVIDIA RTX~3090 GPUs, while preserving image quality. This result confirms the generality of our approach across U-Net-based diffusion models and DiT-based flow-matching architectures. Our approach also outperforms existing methods in acceleration under high-resolution synthesis settings. Code is available at https://github.com/kaist-dmlab/Hybridiff.",
        "tags": [
            "DiT",
            "Diffusion",
            "Flow Matching",
            "SDXL"
        ]
    },
    {
        "id": "119",
        "title": "Improving Implicit Discourse Relation Recognition with Natural Language Explanations from LLMs",
        "author": [
            "Heng Wang",
            "Changxing Wu"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21763",
        "abstract": "Implicit Discourse Relation Recognition (IDRR) remains a challenging task due to the requirement for deep semantic understanding in the absence of explicit discourse markers. A further limitation is that existing methods only predict relations without providing any supporting explanations. Recent advances in large language models (LLMs) have shown strong reasoning capabilities in both deep language understanding and natural language explanation generation. In this work, we propose a simple yet effective approach to distill the reasoning capabilities of LLMs into lightweight IDRR models to improve both performance and interpretability. Specifically, we first prompt an LLM to generate explanations for each training instance conditioned on its gold label. Then, we introduce a novel classification-generation framework that jointly performs relation prediction and explanation generation, and train it with the additional supervision of LLM-generated explanations. Our framework is plug-and-play, enabling easy integration with most existing IDRR models. Experimental results on PDTB demonstrate that our approach significantly improves IDRR performance, while human evaluation further confirms that the generated explanations enhance model interpretability. Furthermore, we validate the generality of our approach on sentiment classification and natural language inference",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "120",
        "title": "Generalisation of RLHF under Reward Shift and Clipped KL Regularisation",
        "author": [
            "Kenton Tang",
            "Yuzhu Chen",
            "Fengxiang He"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21765",
        "abstract": "Alignment and adaptation in large language models heavily rely on reinforcement learning from human feedback (RLHF); yet, theoretical understanding of its generalisability remains premature, especially when the learned reward could shift, and the KL control is estimated and clipped. To address this issue, we develop generalisation theory for RLHF that explicitly accounts for (1) \\emph{reward shift}: reward models are trained on preference data from earlier or mixed behaviour policies while RLHF optimises the current policy on its own rollouts; and (2) \\emph{clipped KL regularisation}: the KL regulariser is estimated from sampled log-probability ratios and then clipped for stabilisation, resulting in an error to RLHF. We present generalisation bounds for RLHF, suggesting that the generalisation error stems from a sampling error from prompts and rollouts, a reward shift error, and a KL clipping error. We also discuss special cases of (1) initialising RLHF parameters with a uniform prior over a finite space, and (2) training RLHF by stochastic gradient descent, as an Ornstein-Uhlenbeck process. The theory yields practical implications in (1) optimal KL clipping threshold, and (2) budget allocation in prompts, rollouts, and preference data.",
        "tags": [
            "LLM",
            "RL",
            "RLHF"
        ]
    },
    {
        "id": "121",
        "title": "From Statics to Dynamics: Physics-Aware Image Editing with Latent Transition Priors",
        "author": [
            "Liangbing Zhao",
            "Le Zhuo",
            "Sayak Paul",
            "Hongsheng Li",
            "Mohamed Elhoseiny"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21778",
        "abstract": "Instruction-based image editing has achieved remarkable success in semantic alignment, yet state-of-the-art models frequently fail to render physically plausible results when editing involves complex causal dynamics, such as refraction or material deformation. We attribute this limitation to the dominant paradigm that treats editing as a discrete mapping between image pairs, which provides only boundary conditions and leaves transition dynamics underspecified. To address this, we reformulate physics-aware editing as predictive physical state transitions and introduce PhysicTran38K, a large-scale video-based dataset comprising 38K transition trajectories across five physical domains, constructed via a two-stage filtering and constraint-aware annotation pipeline. Building on this supervision, we propose PhysicEdit, an end-to-end framework equipped with a textual-visual dual-thinking mechanism. It combines a frozen Qwen2.5-VL for physically grounded reasoning with learnable transition queries that provide timestep-adaptive visual guidance to a diffusion backbone. Experiments show that PhysicEdit improves over Qwen-Image-Edit by 5.9% in physical realism and 10.1% in knowledge-grounded editing, setting a new state-of-the-art for open-source methods, while remaining competitive with leading proprietary models.",
        "tags": [
            "Diffusion",
            "Image Editing",
            "Qwen"
        ]
    },
    {
        "id": "122",
        "title": "Beyond Static Artifacts: A Forensic Benchmark for Video Deepfake Reasoning in Vision Language Models",
        "author": [
            "Zheyuan Gu",
            "Qingsong Zhao",
            "Yusong Wang",
            "Zhaohong Huang",
            "Xinqi Li",
            "Cheng Yuan",
            "Jiaowei Shao",
            "Chi Zhang",
            "Xuelong Li"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21779",
        "abstract": "Current Vision-Language Models (VLMs) for deepfake detection excel at identifying spatial artifacts but overlook a critical dimension: temporal inconsistencies in video forgeries. Adapting VLMs to reason about these dynamic cues remains a distinct challenge. To bridge this gap, we propose Forensic Answer-Questioning (FAQ), a large-scale benchmark that formulates temporal deepfake analysis as a multiple-choice task. FAQ introduces a three-level hierarchy to progressively evaluate and equip VLMs with forensic capabilities: (1) Facial Perception, testing the ability to identify static visual artifacts; (2) Temporal Deepfake Grounding, requiring the localization of dynamic forgery artifacts across frames; and (3) Forensic Reasoning, challenging models to synthesize evidence for final authenticity verdicts. We evaluate a range of VLMs on FAQ and generate a corresponding instruction-tuning set, FAQ-IT. Extensive experiments show that models fine-tuned on FAQ-IT achieve advanced performance on both in-domain and cross-dataset detection benchmarks. Ablation studies further validate the impact of our key design choices, confirming that FAQ is the driving force behind the temporal reasoning capabilities of these VLMs.",
        "tags": [
            "Detection",
            "VLM"
        ]
    },
    {
        "id": "123",
        "title": "XStreamVGGT: Extremely Memory-Efficient Streaming Vision Geometry Grounded Transformer with KV Cache Compression",
        "author": [
            "Zunhai Su",
            "Weihao Ye",
            "Hansen Feng",
            "Keyu Fan",
            "Jing Zhang",
            "Dahai Yu",
            "Zhengwu Liu",
            "Ngai Wong"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21780",
        "abstract": "Learning-based 3D visual geometry models have significantly advanced with the advent of large-scale transformers. Among these, StreamVGGT leverages frame-wise causal attention to deliver robust and efficient streaming 3D reconstruction. However, it suffers from unbounded growth in the Key-Value (KV) cache due to the massive influx of vision tokens from multi-image and long-video inputs, leading to increased memory consumption and inference latency as input frames accumulate. This ultimately limits its scalability for long-horizon applications. To address this gap, we propose XStreamVGGT, a tuning-free approach that seamlessly integrates pruning and quantization to systematically compress the KV cache, enabling extremely memory-efficient streaming inference. Specifically, redundant KVs generated from multi-frame inputs are initially pruned to conform to a fixed KV memory budget using an efficient token-importance identification mechanism that maintains full compatibility with high-performance attention kernels (e.g., FlashAttention). Additionally, leveraging the inherent distribution patterns of KV tensors, we apply dimension-adaptive KV quantization within the pruning pipeline to further minimize memory overhead while preserving numerical accuracy. Extensive evaluations show that XStreamVGGT achieves mostly negligible performance degradation while substantially reducing memory usage by 4.42$\\times$ and accelerating inference by 5.48$\\times$, enabling practical and scalable streaming 3D applications. The code is available at https://github.com/ywh187/XStreamVGGT/.",
        "tags": [
            "3D",
            "Transformer"
        ]
    },
    {
        "id": "124",
        "title": "Therapist-Robot-Patient Physical Interaction is Worth a Thousand Words: Enabling Intuitive Therapist Guidance via Remote Haptic Control",
        "author": [
            "Beatrice Luciani",
            "Alex van den Berg",
            "Matti Lang",
            "Alexandre L. Ratschat",
            "Laura Marchal-Crespo"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21783",
        "abstract": "Robotic systems can enhance the amount and repeatability of physically guided motor training. Yet their real-world adoption is limited, partly due to non-intuitive trainer/therapist-trainee/patient interactions. To address this gap, we present a haptic teleoperation system for trainers to remotely guide and monitor the movements of a trainee wearing an arm exoskeleton. The trainer can physically interact with the exoskeleton through a commercial handheld haptic device via virtual contact points at the exoskeleton's elbow and wrist, allowing intuitive guidance. Thirty-two participants tested the system in a trainer-trainee paradigm, comparing our haptic demonstration system with conventional visual demonstration in guiding trainees in executing arm poses. Quantitative analyses showed that haptic demonstration significantly reduced movement completion time and improved smoothness, while speech analysis using large language models for automated transcription and categorization of verbal commands revealed fewer verbal instructions. The haptic demonstration did not result in higher reported mental and physical effort by trainers compared to the visual demonstration, while trainers reported greater competence and trainees lower physical demand. These findings support the feasibility of our proposed interface for effective remote human-robot physical interaction. Future work should assess its usability and efficacy for clinical populations in restoring clinicians' sense of agency during robot-assisted therapy.",
        "tags": [
            "LLM",
            "Robotics"
        ]
    },
    {
        "id": "125",
        "title": "D-COT: Disciplined Chain-of-Thought Learning for Efficient Reasoning in Small Language Models",
        "author": [
            "Shunsuke Ubukata"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21786",
        "abstract": "Chain-of-Thought (CoT) distillation from Large Language Models (LLMs) often induces \"overthinking\" in Small Language Models (SLMs), leading to performance degradation and excessive token consumption. In this study, we propose Disciplined Chain-of-Thought (D-CoT), a novel framework that enforces a structured reasoning process using control tags -- such as <TEMP_LOW> for fact-checking and <TEMP_HIGH> for multi-perspective exploration -- as auxiliary scaffolding during training. By optimizing the CoT trajectory, D-CoT suppresses reasoning drift and simultaneously achieves token reduction and performance improvement. We demonstrate the efficacy of our approach on Qwen3-8B: with only 5,000 training samples, D-CoT significantly boosts accuracy on GPQA-diamond by 9.9% and MMLU-Pro (0-shot) by 9.1%, while drastically reducing computational costs. Furthermore, we confirm that the model internalizes this disciplined thought structure, maintaining high performance even without explicit control tags during inference.",
        "tags": [
            "CoT",
            "LLM"
        ]
    },
    {
        "id": "126",
        "title": "DHP: Efficient Scaling of MLLM Training with Dynamic Hybrid Parallelism",
        "author": [
            "Yifan Niu",
            "Han Xiao",
            "Dongyi Liu",
            "Wei Zhou",
            "Jia Li"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21788",
        "abstract": "Scaling long-context capabilities is crucial for Multimodal Large Language Models (MLLMs). However, real-world multimodal datasets are extremely heterogeneous. Existing training frameworks predominantly rely on static parallelism strategies, which suffer from severe load imbalance, redundant communication, and suboptimal hardware utilization under data heterogeneity. In this work, we propose Dynamic Hybrid Parallelism (DHP), an efficient parallelism strategy that adaptively reconfigures communication groups and parallelism degrees during MLLM training. We generalize the non-power-of-two parallelism degrees and develop a polynomial-time algorithm to generate near-optimal parallelism strategies with only millisecond-level overhead per training batch. DHP is able to maintain high hardware efficiency even under extreme data variability. Experimental results demonstrate that DHP significantly outperforms Megatron-LM and DeepSpeed, achieving up to 1.36 $\\times$ speedup in training throughput while maintaining near-linear scaling efficiency across large-scale NPU clusters.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "127",
        "title": "Excitation: Momentum For Experts",
        "author": [
            "Sagi Shaier"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21798",
        "abstract": "We propose Excitation, a novel optimization framework designed to accelerate learning in sparse architectures such as Mixture-of-Experts (MoEs). Unlike traditional optimizers that treat all parameters uniformly, Excitation dynamically modulates updates using batch-level expert utilization. It introduces a competitive update dynamic that amplifies updates to highly-utilized experts and can selectively suppress low-utilization ones, effectively sharpening routing specialization. Notably, we identify a phenomenon of \"structural confusion\" in deep MoEs, where standard optimizers fail to establish functional signal paths; Excitation acts as a specialization catalyst, \"rescuing\" these models and enabling stable training where baselines remain trapped. Excitation is optimizer-, domain-, and model-agnostic, requires minimal integration effort, and introduces neither additional per-parameter optimizer state nor learnable parameters, making it highly viable for memory-constrained settings. Across language and vision tasks, Excitation consistently improves convergence speed and final performance in MoE models, indicating that active update modulation is a key mechanism for effective conditional computation.",
        "tags": [
            "MoE"
        ]
    },
    {
        "id": "128",
        "title": "An Evaluation of Context Length Extrapolation in Long Code via Positional Embeddings and Efficient Attention",
        "author": [
            "Madhusudan Ghosh",
            "Rishabh Gupta"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21800",
        "abstract": "The rapid advancement of large language models (LLMs) has led to a significant increase in automated tools in the software engineering, capable of performing various code-related tasks such as code generation, completion, and translation. Despite these advancements, its effectiveness is constrained by fixed context lengths, limiting its ability to generalize across long, domain-specific code sequences. To address this challenge, we investigate zero-shot, inference-only methods aimed at improving position encodings and optimizing attention mechanisms. Our goal is to provide a thorough analysis of current approaches that facilitate context length extrapolation in code, particularly in the context of long code completion tasks.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "129",
        "title": "An Empirical Study of Bugs in Modern LLM Agent Frameworks",
        "author": [
            "Xinxue Zhu",
            "Jiacong Wu",
            "Xiaoyu Zhang",
            "Tianlin Li",
            "Yanzhou Mu",
            "Juan Zhai",
            "Chao Shen",
            "Yang Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21806",
        "abstract": "LLM agents have been widely adopted in real-world applications, relying on agent frameworks for workflow execution and multi-agent coordination. As these systems scale, understanding bugs in the underlying agent frameworks becomes critical. However, existing work mainly focuses on agent-level failures, overlooking framework-level bugs. To address this gap, we conduct an empirical study of 998 bug reports from CrewAI and LangChain, constructing a taxonomy of 15 root causes and 7 observable symptoms across five agent lifecycle stages: 'Agent Initialization','Perception', 'Self-Action', 'Mutual Interaction' and 'Evolution'. Our findings show that agent framework bugs mainly arise from 'API misuse', 'API incompatibility', and 'Documentation Desync', largely concentrated in the 'Self-Action' stage. Symptoms typically appear as 'Functional Error', 'Crash', and 'Build Failure', reflecting disruptions to task progression and control flow.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "130",
        "title": "DexRepNet++: Learning Dexterous Robotic Manipulation with Geometric and Spatial Hand-Object Representations",
        "author": [
            "Qingtao Liu",
            "Zhengnan Sun",
            "Yu Cui",
            "Haoming Li",
            "Gaofeng Li",
            "Lin Shao",
            "Jiming Chen",
            "Qi Ye"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21811",
        "abstract": "Robotic dexterous manipulation is a challenging problem due to high degrees of freedom (DoFs) and complex contacts of multi-fingered robotic hands. Many existing deep reinforcement learning (DRL) based methods aim at improving sample efficiency in high-dimensional output action spaces. However, existing works often overlook the role of representations in achieving generalization of a manipulation policy in the complex input space during the hand-object interaction. In this paper, we propose DexRep, a novel hand-object interaction representation to capture object surface features and spatial relations between hands and objects for dexterous manipulation skill learning. Based on DexRep, policies are learned for three dexterous manipulation tasks, i.e. grasping, in-hand reorientation, bimanual handover, and extensive experiments are conducted to verify the effectiveness. In simulation, for grasping, the policy learned with 40 objects achieves a success rate of 87.9% on more than 5000 unseen objects of diverse categories, significantly surpassing existing work trained with thousands of objects; for the in-hand reorientation and handover tasks, the policies also boost the success rates and other metrics of existing hand-object representations by 20% to 40%. The grasp policies with DexRep are deployed to the real world under multi-camera and single-camera setups and demonstrate a small sim-to-real gap.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "131",
        "title": "Prompt Architecture Determines Reasoning Quality: A Variable Isolation Study on the Car Wash Problem",
        "author": [
            "Heejin Jo"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21814",
        "abstract": "Large language models consistently fail the \"car wash problem,\" a viral reasoning benchmark requiring implicit physical constraint inference. We present a variable isolation study (n=20 per condition, 6 conditions, 120 total trials) examining which prompt architecture layers in a production system enable correct reasoning. Using Claude 3.5 Sonnet with controlled hyperparameters (temperature 0.7, top_p 1.0), we find that the STAR (Situation-Task-Action-Result) reasoning framework alone raises accuracy from 0% to 85% (p=0.001, Fisher's exact test, odds ratio 13.22). Adding user profile context via vector database retrieval provides a further 10 percentage point gain, while RAG context contributes an additional 5 percentage points, achieving 100% accuracy in the full-stack condition. These results suggest that structured reasoning scaffolds -- specifically, forced goal articulation before inference -- matter substantially more than context injection for implicit constraint reasoning tasks.",
        "tags": [
            "LLM",
            "RAG"
        ]
    },
    {
        "id": "132",
        "title": "SkyReels-V4: Multi-modal Video-Audio Generation, Inpainting and Editing model",
        "author": [
            "Guibin Chen",
            "Dixuan Lin",
            "Jiangping Yang",
            "Youqiang Zhang",
            "Zhengcong Fei",
            "Debang Li",
            "Sheng Chen",
            "Chaofeng Ao",
            "Nuo Pang",
            "Yiming Wang",
            "Yikun Dou",
            "Zheng Chen",
            "Mingyuan Fan",
            "Tuanhui Li",
            "Mingshan Chang",
            "Hao Zhang",
            "Xiaopeng Sun",
            "Jingtao Xu",
            "Yuqiang Xie",
            "Jiahua Wang",
            "Zhiheng Xu",
            "Weiming Xiong",
            "Yuzhe Jin",
            "Baoxuan Gu",
            "Binjie Mao",
            "Yunjie Yu",
            "Jujie He",
            "Yuhao Feng",
            "Shiwen Tu",
            "Chaojie Wang",
            "Rui Yan",
            "Wei Shen",
            "Jingchen Wu",
            "Peng Zhao",
            "Xuanyue Zhong",
            "Zhuangzhuang Liu",
            "Kaifei Wang",
            "Fuxiang Zhang",
            "Weikai Xu",
            "Wenyan Liu",
            "Binglu Zhang",
            "Yu Shen",
            "Tianhui Xiong",
            "Bin Peng",
            "Liang Zeng",
            "Xuchen Song",
            "Haoxiang Guo",
            "Peiyu Wang",
            "Yahui Zhou"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21818",
        "abstract": "SkyReels V4 is a unified multi modal video foundation model for joint video audio generation, inpainting, and editing. The model adopts a dual stream Multimodal Diffusion Transformer (MMDiT) architecture, where one branch synthesizes video and the other generates temporally aligned audio, while sharing a powerful text encoder based on the Multimodal Large Language Models (MMLM). SkyReels V4 accepts rich multi modal instructions, including text, images, video clips, masks, and audio references. By combining the MMLMs multi modal instruction following capability with in context learning in the video branch MMDiT, the model can inject fine grained visual guidance under complex conditioning, while the audio branch MMDiT simultaneously leverages audio references to guide sound generation. On the video side, we adopt a channel concatenation formulation that unifies a wide range of inpainting style tasks, such as image to video, video extension, and video editing under a single interface, and naturally extends to vision referenced inpainting and editing via multi modal prompts. SkyReels V4 supports up to 1080p resolution, 32 FPS, and 15 second duration, enabling high fidelity, multi shot, cinema level video generation with synchronized audio. To make such high resolution, long-duration generation computationally feasible, we introduce an efficiency strategy: Joint generation of low resolution full sequences and high-resolution keyframes, followed by dedicated super-resolution and frame interpolation models. To our knowledge, SkyReels V4 is the first video foundation model that simultaneously supports multi-modal input, joint video audio generation, and a unified treatment of generation, inpainting, and editing, while maintaining strong efficiency and quality at cinematic resolutions and durations.",
        "tags": [
            "DiT",
            "Diffusion",
            "Inpainting",
            "LLM",
            "Super Resolution",
            "Transformer",
            "Video Editing",
            "Video Generation"
        ]
    },
    {
        "id": "133",
        "title": "DocDjinn: Controllable Synthetic Document Generation with VLMs and Handwriting Diffusion",
        "author": [
            "Marcel Lamott",
            "Saifullah Saifullah",
            "Nauman Riaz",
            "Yves-Noel Weweler",
            "Tobias Alt-Veit",
            "Ahmad Sarmad Ali",
            "Muhammad Armaghan Shakir",
            "Adrian Kalwa",
            "Momina Moetesum",
            "Andreas Dengel",
            "Sheraz Ahmed",
            "Faisal Shafait",
            "Ulrich Schwanecke",
            "Adrian Ulges"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21824",
        "abstract": "Effective document intelligence models rely on large amounts of annotated training data. However, procuring sufficient and high-quality data poses significant challenges due to the labor-intensive and costly nature of data acquisition. Additionally, leveraging language models to annotate real documents raises concerns about data privacy. Synthetic document generation has emerged as a promising, privacy-preserving alternative. We propose DocDjinn, a novel framework for controllable synthetic document generation using Vision-Language Models (VLMs) that produces annotated documents from unlabeled seed samples. Our approach generates visually plausible and semantically consistent synthetic documents that follow the distribution of an existing source dataset through clustering-based seed selection with parametrized sampling. By enriching documents with realistic diffusion-based handwriting and contextual visual elements via semantic-visual decoupling, we generate diverse, high-quality annotated synthetic documents. We evaluate across eleven benchmarks spanning key information extraction, question answering, document classification, and document layout analysis. To our knowledge, this is the first work demonstrating that VLMs can generate faithful annotated document datasets at scale from unlabeled seeds that can effectively enrich or approximate real, manually annotated data for diverse document understanding tasks. We show that with only 100 real training samples, our framework achieves on average $87\\%$ of the performance of the full real-world dataset. We publicly release our code and 140k+ synthetic document samples.",
        "tags": [
            "Diffusion",
            "VLM"
        ]
    },
    {
        "id": "134",
        "title": "StoryMovie: A Dataset for Semantic Alignment of Visual Stories with Movie Scripts and Subtitles",
        "author": [
            "Daniel Oliveira",
            "David Martins de Matos"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21829",
        "abstract": "Visual storytelling models that correctly ground entities in images may still hallucinate semantic relationships, generating incorrect dialogue attribution, character interactions, or emotional states. We introduce StoryMovie, a dataset of 1,757 stories aligned with movie scripts and subtitles through LCS matching. Our alignment pipeline synchronizes screenplay dialogue with subtitle timestamps, enabling dialogue attribution by linking character names from scripts to temporal positions from subtitles. Using this aligned content, we generate stories that maintain visual grounding tags while incorporating authentic character names, dialogue, and relationship dynamics. We fine-tune Qwen Storyteller3 on this dataset, building on prior work in visual grounding and entity re-identification. Evaluation using DeepSeek V3 as judge shows that Storyteller3 achieves an 89.9% win rate against base Qwen2.5-VL 7B on subtitle alignment. Compared to Storyteller, trained without script grounding,\nStoryteller3 achieves 48.5% versus 38.0%, confirming that semantic alignment progressively improves dialogue attribution beyond visual grounding alone.",
        "tags": [
            "DeepSeek",
            "Qwen"
        ]
    },
    {
        "id": "135",
        "title": "A Multi-Turn Framework for Evaluating AI Misuse in Fraud and Cybercrime Scenarios",
        "author": [
            "Kimberly T. Mai",
            "Anna Gausen",
            "Magda Dubois",
            "Mona Murad",
            "Bessie O'Dell",
            "Nadine Staes-Polet",
            "Christopher Summerfield",
            "Andrew Strait"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21831",
        "abstract": "AI is increasingly being used to assist fraud and cybercrime. However, it is unclear whether current large language models can assist complex criminal activity. Working with law enforcement and policy experts, we developed multi-turn evaluations for three fraud and cybercrime scenarios (romance scams, CEO impersonation, and identity theft). Our evaluations focused on text-to-text model capabilities. In each scenario, we measured model capabilities in ways designed to resemble real-world misuse, such as breaking down requests for fraud into a sequence of seemingly benign queries, and measuring whether models provide actionable information, relative to a standard web search baseline.\nWe found that (1) current large language models provide minimal practical assistance with complex criminal activity, (2) open-weight large language models fine-tuned to remove safety guardrails provided substantially more help, and (3) decomposing requests into benign-seeming queries elicited more assistance than explicitly malicious framing or system-level jailbreaks. Overall, the results suggest that current risks from text-generation models are relatively minimal. However, this work contributes a reproducible, expert-grounded framework for tracking how these risks may evolve with time as models grow more capable and adversaries adapt.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "136",
        "title": "From Restructuring to Stabilization: A Large-Scale Experiment on Iterative Code Readability Refactoring with Large Language Models",
        "author": [
            "Norman Peitek",
            "Julia Hess",
            "Sven Apel"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21833",
        "abstract": "Large language models (LLMs) are increasingly used for automated code refactoring tasks. Although these models can quickly refactor code, the quality may exhibit inconsistencies and unpredictable behavior. In this article, we systematically study the capabilities of LLMs for code refactoring with a specific focus on improving code readability.\nWe conducted a large-scale experiment using GPT5.1 with 230 Java snippets, each systematically varied and refactored regarding code readability across five iterations under three different prompting strategies. We categorized fine-grained code changes during the refactoring into implementation, syntactic, and comment-level transformations. Subsequently, we investigated the functional correctness and tested the robustness of the results with novel snippets.\nOur results reveal three main insights: First, iterative code refactoring exhibits an initial phase of restructuring followed by stabilization. This convergence tendency suggests that LLMs possess an internalized understanding of an \"optimally readable\" version of code. Second, convergence patterns are fairly robust across different code variants. Third, explicit prompting toward specific readability factors slightly influences the refactoring dynamics.\nThese insights provide an empirical foundation for assessing the reliability of LLM-assisted code refactoring, which opens pathways for future research, including comparative analyses across models and a systematic evaluation of additional software quality dimensions in LLM-refactored code.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "137",
        "title": "UniVBench: Towards Unified Evaluation for Video Foundation Models",
        "author": [
            "Jianhui Wei",
            "Xiaotian Zhang",
            "Yichen Li",
            "Yuan Wang",
            "Yan Zhang",
            "Ziyi Chen",
            "Zhihang Tang",
            "Wei Xu",
            "Zuozhu Liu"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21835",
        "abstract": "Video foundation models aim to integrate video understanding, generation, editing, and instruction following within a single framework, making them a central direction for next-generation multimodal systems. However, existing evaluation benchmarks remain fragmented and limited in scope, as they each target a single task, rely on task-specific metrics, and typically use short or simple video clips. As a result, they do not capture the unified capabilities that these models are designed to deliver. To address this gap, we introduce UniVBench, a benchmark purpose-built for evaluating video foundation models across four core abilities: video understanding, video generation, video editing, and a newly proposed task, video reconstruction, which assesses how faithfully a model can reproduce video content it has encountered. Our benchmark substantially expands the complexity of evaluation by incorporating 200 high-quality, diverse and multi-shot videos, each paired with detailed captions, multi-format editing instructions, and reference images. All videos are human-created and carefully validated, offering richer cinematic information than prior benchmarks. In addition, we develop a unified agentic evaluation system (UniV-Eval) that standardizes prompting, instruction parsing, and scoring across all tasks, enabling fair, scalable, and reproducible comparisons of unified video models. By grounding evaluation in instruction-based multi-shot video tasks, UniVBench provides the first framework for measuring the integrated capabilities that video foundation models aim to achieve. Extensive human annotations ensure our evaluation aligns with human judgment, enabling rigorous assessment and accelerating progress toward robust video intelligence.",
        "tags": [
            "Video Editing",
            "Video Generation"
        ]
    },
    {
        "id": "138",
        "title": "FewMMBench: A Benchmark for Multimodal Few-Shot Learning",
        "author": [
            "Mustafa Dogan",
            "Ilker Kesen",
            "Iacer Calixto",
            "Aykut Erdem",
            "Erkut Erdem"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21854",
        "abstract": "As multimodal large language models (MLLMs) advance in handling interleaved image-text data, assessing their few-shot learning capabilities remains an open challenge. In this paper, we introduce FewMMBench, a comprehensive benchmark designed to evaluate MLLMs under few-shot conditions, with a focus on In-Context Learning (ICL) and Chain-of-Thought (CoT) prompting. Covering a diverse suite of multimodal understanding tasks, from attribute recognition to temporal reasoning, FewMMBench enables systematic analysis across task types, model families, and prompting strategies. We evaluate 26 open-weight MLLMs from six model families across zero-shot, few-shot, and CoT-augmented few-shot settings. Our findings reveal that instruction-tuned models exhibit strong zero-shot performance but benefit minimally, or even regress, with additional demonstrations or CoT reasoning. Retrieval-based demonstrations and increased context size also yield limited gains. These results highlight FewMMBench as a rigorous testbed for diagnosing and advancing few-shot capabilities in multimodal LLMs. The data is available at: https://huggingface.co/datasets/mustafaa/FewMMBench",
        "tags": [
            "CoT",
            "LLM"
        ]
    },
    {
        "id": "139",
        "title": "Understanding Annotation Error Propagation and Learning an Adaptive Policy for Expert Intervention in Barrett's Video Segmentation",
        "author": [
            "Lokesha Rasanjalee",
            "Jin Lin Tan",
            "Dileepa Pitawela",
            "Rajvinder Singh",
            "Hsiang-Ting Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21855",
        "abstract": "Accurate annotation of endoscopic videos is essential yet time-consuming, particularly for challenging datasets such as dysplasia in Barrett's esophagus, where the affected regions are irregular and lack clear boundaries. Semi-automatic tools like Segment Anything Model 2 (SAM2) can ease this process by propagating annotations across frames, but small errors often accumulate and reduce accuracy, requiring expert review and correction. To address this, we systematically study how annotation errors propagate across different prompt types, namely masks, boxes, and points, and propose Learning-to-Re-Prompt (L2RP), a cost-aware framework that learns when and where to seek expert input. By tuning a human-cost parameter, our method balances annotation effort and segmentation accuracy. Experiments on a private Barrett's dysplasia dataset and the public SUN-SEG benchmark demonstrate improved temporal consistency and superior performance over baseline strategies.",
        "tags": [
            "SAM",
            "Segmentation"
        ]
    },
    {
        "id": "140",
        "title": "Distill and Align Decomposition for Enhanced Claim Verification",
        "author": [
            "Jabez Magomere",
            "Elena Kochkina",
            "Samuel Mensah",
            "Simerjot Kaur",
            "Fernando Acero",
            "Arturo Oncevay",
            "Charese H. Smiley",
            "Xiaomo Liu",
            "Manuela Veloso"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21857",
        "abstract": "Complex claim verification requires decomposing sentences into verifiable subclaims, yet existing methods struggle to align decomposition quality with verification performance. We propose a reinforcement learning (RL) approach that jointly optimizes decomposition quality and verifier alignment using Group Relative Policy Optimization (GRPO). Our method integrates: (i) structured sequential reasoning; (ii) supervised finetuning on teacher-distilled exemplars; and (iii) a multi-objective reward balancing format compliance, verifier alignment, and decomposition quality. Across six evaluation settings, our trained 8B decomposer improves downstream verification performance to (71.75%) macro-F1, outperforming prompt-based approaches ((+1.99), (+6.24)) and existing RL methods ((+5.84)). Human evaluation confirms the high quality of the generated subclaims. Our framework enables smaller language models to achieve state-of-the-art claim verification by jointly optimising for verification accuracy and decomposition quality.",
        "tags": [
            "GRPO",
            "RL"
        ]
    },
    {
        "id": "141",
        "title": "ProactiveMobile: A Comprehensive Benchmark for Boosting Proactive Intelligence on Mobile Devices",
        "author": [
            "Dezhi Kong",
            "Zhengzhao Feng",
            "Qiliang Liang",
            "Hao Wang",
            "Haofei Sun",
            "Changpeng Yang",
            "Yang Li",
            "Peng Zhou",
            "Shuai Nie",
            "Hongzhen Wang",
            "Linfeng Zhou",
            "Hao Jia",
            "Jiaming Xu",
            "Runyu Shi",
            "Ying Huang"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21858",
        "abstract": "Multimodal large language models (MLLMs) have made significant progress in mobile agent development, yet their capabilities are predominantly confined to a reactive paradigm, where they merely execute explicit user commands. The emerging paradigm of proactive intelligence, where agents autonomously anticipate needs and initiate actions, represents the next frontier for mobile agents. However, its development is critically bottlenecked by the lack of benchmarks that can address real-world complexity and enable objective, executable evaluation. To overcome these challenges, we introduce ProactiveMobile, a comprehensive benchmark designed to systematically advance research in this domain. ProactiveMobile formalizes the proactive task as inferring latent user intent across four dimensions of on-device contextual signals and generating an executable function sequence from a comprehensive function pool of 63 APIs. The benchmark features over 3,660 instances of 14 scenarios that embrace real-world complexity through multi-answer annotations. To ensure quality, a team of 30 experts conducts a final audit of the benchmark, verifying factual accuracy, logical consistency, and action feasibility, and correcting any non-compliant entries. Extensive experiments demonstrate that our fine-tuned Qwen2.5-VL-7B-Instruct achieves a success rate of 19.15%, outperforming o1 (15.71%) and GPT-5 (7.39%). This result indicates that proactivity is a critical competency widely lacking in current MLLMs, yet it is learnable, emphasizing the importance of the proposed benchmark for proactivity evaluation.",
        "tags": [
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "142",
        "title": "Personalized Graph-Empowered Large Language Model for Proactive Information Access",
        "author": [
            "Chia Cheng Chang",
            "An-Zi Yen",
            "Hen-Hsen Huang",
            "Hsin-Hsi Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21862",
        "abstract": "Since individuals may struggle to recall all life details and often confuse events, establishing a system to assist users in recalling forgotten experiences is essential. While numerous studies have proposed memory recall systems, these primarily rely on deep learning techniques that require extensive training and often face data scarcity due to the limited availability of personal lifelogs. As lifelogs grow over time, systems must also adapt quickly to newly accumulated data. Recently, large language models (LLMs) have demonstrated remarkable capabilities across various tasks, making them promising for personalized applications. In this work, we present a framework that leverages LLMs for proactive information access, integrating personal knowledge graphs to enhance the detection of access needs through a refined decision-making process. Our framework offers high flexibility, enabling the replacement of base models and the modification of fact retrieval methods for continuous improvement. Experimental results demonstrate that our approach effectively identifies forgotten events, supporting users in recalling past experiences more efficiently.",
        "tags": [
            "Detection",
            "LLM"
        ]
    },
    {
        "id": "143",
        "title": "DynamicGTR: Leveraging Graph Topology Representation Preferences to Boost VLM Capabilities on Graph QAs",
        "author": [
            "Yanbin Wei",
            "Jiangyue Yan",
            "Chun Kang",
            "Yang Chen",
            "Hua Liu",
            "James Kwok",
            "Yu Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21864",
        "abstract": "Vision-Language Models (VLMs) have emerged as versatile solutions for zero-shot question answering (QA) across various domains. However, enabling VLMs to effectively comprehend structured graphs and perform accurate, efficient QA remains challenging. Existing approaches typically rely on one single graph topology representation (GTR), such as fixed-style visual images or unified text descriptions. This ``one-size-fits-all'' strategy often neglects model-specific and task-specific preferences, resulting in inaccurate or over-lengthy responses to graph-related queries. To address this, we propose the $\\mbox{DynamicGTR}$ framework, which dynamically selects the optimal GTR for each query during inference, thereby enhancing the zero-shot graph QA capabilities of VLMs with a customizable accuracy and brevity trade-off. Extensive experiments show that DynamicGTR not only improves VLM-based graph algorithm QA performance but also successfully transfers the experience trained from synthetic graph algorithm tasks to real-world applications like link prediction and node classification, without any additional training. Additionally, DynamicGTR demonstrates strong transferability across tasks, domains, and models, suggesting its potential as a flexible solution for broad graph scenarios.",
        "tags": [
            "VLM"
        ]
    },
    {
        "id": "144",
        "title": "Interactive Augmented Reality-enabled Outdoor Scene Visualization For Enhanced Real-time Disaster Response",
        "author": [
            "Dimitrios Apostolakis",
            "Georgios Angelidis",
            "Vasileios Argyriou",
            "Panagiotis Sarigiannidis",
            "Georgios Th. Papadopoulos"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21874",
        "abstract": "A user-centered AR interface for disaster response is presented in this work that uses 3D Gaussian Splatting (3DGS) to visualize detailed scene reconstructions, while maintaining situational awareness and keeping cognitive load low. The interface relies on a lightweight interaction approach, combining World-in-Miniature (WIM) navigation with semantic Points of Interest (POIs) that can be filtered as needed, and it is supported by an architecture designed to stream updates as reconstructions evolve. User feedback from a preliminary evaluation indicates that this design is easy to use and supports real-time coordination, with participants highlighting the value of interaction and POIs for fast decision-making in context. Thorough user-centric performance evaluation demonstrates strong usability of the developed interface and high acceptance ratios.",
        "tags": [
            "3D",
            "Gaussian Splatting"
        ]
    },
    {
        "id": "145",
        "title": "How to Take a Memorable Picture? Empowering Users with Actionable Feedback",
        "author": [
            "Francesco Laiti",
            "Davide Talon",
            "Jacopo Staiano",
            "Elisa Ricci"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21877",
        "abstract": "Image memorability, i.e., how likely an image is to be remembered, has traditionally been studied in computer vision either as a passive prediction task, with models regressing a scalar score, or with generative methods altering the visual input to boost the image likelihood of being remembered. Yet, none of these paradigms supports users at capture time, when the crucial question is how to improve a photo memorability. We introduce the task of Memorability Feedback (MemFeed), where an automated model should provide actionable, human-interpretable guidance to users with the goal to enhance an image future recall. We also present MemCoach, the first approach designed to provide concrete suggestions in natural language for memorability improvement (e.g., \"emphasize facial expression,\" \"bring the subject forward\"). Our method, based on Multimodal Large Language Models (MLLMs), is training-free and employs a teacher-student steering strategy, aligning the model internal activations toward more memorable patterns learned from a teacher model progressing along least-to-most memorable samples. To enable systematic evaluation on this novel task, we further introduce MemBench, a new benchmark featuring sequence-aligned photoshoots with annotated memorability scores. Our experiments, considering multiple MLLMs, demonstrate the effectiveness of MemCoach, showing consistently improved performance over several zero-shot models. The results indicate that memorability can not only be predicted but also taught and instructed, shifting the focus from mere prediction to actionable feedback for human creators.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "146",
        "title": "ExpLang: Improved Exploration and Exploitation in LLM Reasoning with On-Policy Thinking Language Selection",
        "author": [
            "Changjiang Gao",
            "Zixian Huang",
            "Kaichen Yang",
            "Jiajun Chen",
            "Jixing Li",
            "Shujian Huang"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21887",
        "abstract": "Current large reasoning models (LRMs) have shown strong ability on challenging tasks after reinforcement learning (RL) based post-training. However, previous work mainly focuses on English reasoning in expectation of the strongest performance, despite the demonstrated potential advantage of multilingual thinking, as well as the requirement for native thinking traces by global users. In this paper, we propose ExpLang, a novel LLM post-training pipeline that enables on-policy thinking language selection to improve exploration and exploitation during RL with the use of multiple languages. The results show that our method steadily outperforms English-only training with the same training budget, while showing high thinking language compliance for both seen and unseen languages. Analysis shows that, by enabling on-policy thinking language selection as an action during RL, ExpLang effectively extends the RL exploration space with diversified language preference and improves the RL exploitation outcome with leveraged non-English advantage. The method is orthogonal to most RL algorithms and opens up a new perspective on using multilinguality to improve LRMs.",
        "tags": [
            "LLM",
            "RL"
        ]
    },
    {
        "id": "147",
        "title": "APFuzz: Towards Automatic Greybox Protocol Fuzzing",
        "author": [
            "Yu Wang",
            "Yang Xiang",
            "Chandra Thapa",
            "Hajime Suzuki"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21892",
        "abstract": "Greybox protocol fuzzing is a random testing approach for stateful protocol implementations, where the input is protocol messages generated from mutations of seeds, and the search in the input space is driven by the feedback on coverage of both code and state. State model and message model are the core components of communication protocols, which also have significant impacts on protocol fuzzing. In this work, we propose APFuzz (Automatic greybox Protocol Fuzzer) with novel designs to increase the smartness of greybox protocol fuzzers from the perspectives of both the state model and the message model. On the one hand, APFuzz employs a two-stage process of static and dynamic analysis to automatically identify state variables, which are then used to infer an accurate state model during fuzzing. On the other hand, APFuzz introduces field-level mutation operations for binary protocols, leveraging message structure awareness enabled by Large Language Models. We conduct extensive experiments on a public protocol fuzzing benchmark, comparing APFuzz with the baseline fuzzer AFLNET as well as several state-of-the-art greybox protocol fuzzers.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "148",
        "title": "Enhancing Cellular-enabled Collaborative Robots Planning through GNSS data for SAR Scenarios",
        "author": [
            "Arnau Romero",
            "Carmen Delgado",
            "Jana Baguer",
            "RaÃºl SuÃ¡rez",
            "Xavier Costa-PÃ©rez"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21899",
        "abstract": "Cellular-enabled collaborative robots are becoming paramount in Search-and-Rescue (SAR) and emergency response. Crucially dependent on resilient mobile network connectivity, they serve as invaluable assets for tasks like rapid victim localization and the exploration of hazardous, otherwise unreachable areas. However, their reliance on battery power and the need for persistent, low-latency communication limit operational time and mobility. To address this, and considering the evolving capabilities of 5G/6G networks, we propose a novel SAR framework that includes Mission Planning and Mission Execution phases and that optimizes robot deployment. By considering parameters such as the exploration area size, terrain elevation, robot fleet size, communication-influenced energy profiles, desired exploration rate, and target response time, our framework determines the minimum number of robots required and their optimal paths to ensure effective coverage and timely data backhaul over mobile networks. Our results demonstrate the trade-offs between number of robots, explored area, and response time for wheeled and quadruped robots. Further, we quantify the impact of terrain elevation data on mission time and energy consumption, showing the benefits of incorporating real-world environmental factors that might also affect mobile signal propagation and connectivity into SAR planning. This framework provides critical insights for leveraging next-generation mobile networks to enhance autonomous SAR operations.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "149",
        "title": "EmoOmni: Bridging Emotional Understanding and Expression in Omni-Modal LLMs",
        "author": [
            "Wenjie Tian",
            "Zhixian Zhao",
            "Jingbin Hu",
            "Huakang Chen",
            "Haohe Liu",
            "Binshen Mu",
            "Lei Xie"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21900",
        "abstract": "The evolution of Omni-Modal Large Language Models~(Omni-LLMs) has revolutionized human--computer interaction, enabling unified audio-visual perception and speech response. However, existing Omni-LLMs struggle with complex real-world scenarios, often leading to superficial understanding and contextually mismatched emotional responses. This issue is further intensified by Omni-LLM's Thinker-Talker architectures, which are implicitly connected through hidden states, leading to the loss of emotional details. In this work, we present EmoOmni, a unified framework for accurate understanding and expression in multimodal emotional dialogue. At its core, we introduce the emotional Chain-of-Thought~(E-CoT), which enforces a reasoning from fine-grained multimodal perception to textual response. Moreover, we explicitly treat E-CoT as high-level emotional instructions that guide the talker, enabling accurate emotional expression. Complementing the model, we construct EmoOmniPipe to obtain the real-world annotated dialogue data and establish a benchmark, EmoOmniEval, to facilitate systematic assessment of multimodal emotional dialogue task. Experiments show that EmoOmni-7B achieves comparable performance with Qwen3Omni-30B-A3B-Thinking under the same talker.",
        "tags": [
            "CoT",
            "LLM"
        ]
    },
    {
        "id": "150",
        "title": "A fully iterative adaptive energy-based approach for monotone elliptic problems",
        "author": [
            "Raphael Leu",
            "Thomas P. Wihler"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21913",
        "abstract": "We present a fully iterative adaptive algorithm for the numerical minimization of strongly convex energy functionals in Hilbert spaces. The proposed approach, which we first present in abstract form, generates a hierarchical sequence of adaptively refined finite-dimensional approximation spaces and employs a (nonlinear) conjugate gradient (CG) method to compute suitable approximations on each space. A core novelty of our approach is that all components of the algorithm are consistently driven by energy reduction principles rather than by classical a posteriori estimators. In particular, adaptive refinement is steered by local energy reduction indicators which aim to construct subsequent approximation spaces in a way that attains the largest potential decrease in energy. Likewise, the stopping criteria for the iterative solver are based on either relative or averaged energy reductions on each subspace. As a concrete realization, we present a concise implementation for $\\mathbb{P}_1$ finite element discretizations of second-order semilinear elliptic diffusion-reaction models, where the local indicators driving the element refinements are computed based on edge-wise energy reductions. Numerical experiments demonstrate that the resulting scheme achieves optimal convergence for various benchmark problems in two-dimensional polygonal domains.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "151",
        "title": "Traffic-aware Hierarchical Integrated Thermal and Energy Management for Connected HEVs",
        "author": [
            "Jie Han",
            "Arash Khalatbarisoltani",
            "Hai L. Vu",
            "Xiaosong Hu",
            "Jun Yang"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21914",
        "abstract": "The energy and thermal management systems of hybrid electric vehicles (HEVs) are inherently interdependent. With the ongoing deployment of intelligent transportation systems (ITSs) and increasing vehicle connectivity, the integration of traffic information has become crucial for improving both energy efficiency and thermal comfort in modern vehicles. To enhance fuel economy, this paper proposes a novel traffic-aware hierarchical integrated thermal and energy management (TA-ITEM) strategy for connected HEVs. In the upper layer, global reference trajectories for battery state of charge (SOC) and cabin temperature are planned using traffic flow speed information obtained from ITSs. In the lower layer, a real-time model predictive control (MPC)-based ITEM controller is developed, which incorporates a novel Transformer-based speed predictor with driving condition recognition (TF-DCR) to enable anticipatory tracking of the reference trajectories. Numerical simulations are conducted under various driving cycles and ambient temperature conditions. The results demonstrate that the proposed TA-ITEM approach outperforms conventional rule-based and MPC-SP approaches, with average fuel consumption reductions of 56.36\\% and 5.84\\%, respectively, while maintaining superior thermal regulation and cabin comfort. These findings confirm the effectiveness and strong generalization capability of TA-ITEM and underscore the advantages of incorporating traffic information.",
        "tags": [
            "MPC",
            "Transformer"
        ]
    },
    {
        "id": "152",
        "title": "Scan Clusters, Not Pixels: A Cluster-Centric Paradigm for Efficient Ultra-high-definition Image Restoration",
        "author": [
            "Chen Wu",
            "Ling Wang",
            "Zhuoran Zheng",
            "Yuning Cui",
            "Zhixiong Yang",
            "Xiangyu Chen",
            "Yue Zhang",
            "Weidong Jiang",
            "Jingyuan Xia"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21917",
        "abstract": "Ultra-High-Definition (UHD) image restoration is trapped in a scalability crisis: existing models, bound to pixel-wise operations, demand unsustainable computation. While state space models (SSMs) like Mamba promise linear complexity, their pixel-serial scanning remains a fundamental bottleneck for the millions of pixels in UHD content. We ask: must we process every pixel to understand the image? This paper introduces C$^2$SSM, a visual state space model that breaks this taboo by shifting from pixel-serial to cluster-serial scanning. Our core discovery is that the rich feature distribution of a UHD image can be distilled into a sparse set of semantic centroids via a neural-parameterized mixture model. C$^2$SSM leverages this to reformulate global modeling into a novel dual-path process: it scans and reasons over a handful of cluster centers, then diffuses the global context back to all pixels through a principled similarity distribution, all while a lightweight modulator preserves fine details. This cluster-centric paradigm achieves a decisive leap in efficiency, slashing computational costs while establishing new state-of-the-art results across five UHD restoration tasks. More than a solution, C$^2$SSM charts a new course for efficient large-scale vision: scan clusters, not pixels.",
        "tags": [
            "Mamba",
            "SSMs"
        ]
    },
    {
        "id": "153",
        "title": "Learning in the Null Space: Small Singular Values for Continual Learning",
        "author": [
            "Cuong Anh Pham",
            "Praneeth Vepakomma",
            "Samuel HorvÃ¡th"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21919",
        "abstract": "Alleviating catastrophic forgetting while enabling further learning is a primary challenge in continual learning (CL). Orthogonal-based training methods have gained attention for their efficiency and strong theoretical properties, and many existing approaches enforce orthogonality through gradient projection. In this paper, we revisit orthogonality and exploit the fact that small singular values correspond to directions that are nearly orthogonal to the input space of previous tasks. Building on this principle, we introduce NESS (Null-space Estimated from Small Singular values), a CL method that applies orthogonality directly in the weight space rather than through gradient manipulation. Specifically, NESS constructs an approximate null space using the smallest singular values of each layer's input representation and parameterizes task-specific updates via a compact low-rank adaptation (LoRA-style) formulation constrained to this subspace. The subspace basis is fixed to preserve the null-space constraint, and only a single trainable matrix is learned for each task. This design ensures that the resulting updates remain approximately in the null space of previous inputs while enabling adaptation to new tasks. Our theoretical analysis and experiments on three benchmark datasets demonstrate competitive performance, low forgetting, and stable accuracy across tasks, highlighting the role of small singular values in continual learning. The code is available at https://github.com/pacman-ctm/NESS.",
        "tags": [
            "LoRA"
        ]
    },
    {
        "id": "154",
        "title": "Geometry-as-context: Modulating Explicit 3D in Scene-consistent Video Generation to Geometry Context",
        "author": [
            "JiaKui Hu",
            "Jialun Liu",
            "Liying Yang",
            "Xinliang Zhang",
            "Kaiwen Li",
            "Shuang Zeng",
            "Yuanwei Li",
            "Haibin Huang",
            "Chi Zhang",
            "Yanye Lu"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21929",
        "abstract": "Scene-consistent video generation aims to create videos that explore 3D scenes based on a camera trajectory. Previous methods rely on video generation models with external memory for consistency, or iterative 3D reconstruction and inpainting, which accumulate errors during inference due to incorrect intermediary outputs, non-differentiable processes, and separate models. To overcome these limitations, we introduce ``geometry-as-context\". It iteratively completes the following steps using an autoregressive camera-controlled video generation model: (1) estimates the geometry of the current view necessary for 3D reconstruction, and (2) simulates and restores novel view images rendered by the 3D scene. Under this multi-task framework, we develop the camera gated attention module to enhance the model's capability to effectively leverage camera poses. During the training phase, text contexts are utilized to ascertain whether geometric or RGB images should be generated. To ensure that the model can generate RGB-only outputs during inference, the geometry context is randomly dropped from the interleaved text-image-geometry training sequence. The method has been tested on scene video generation with one-direction and forth-and-back trajectories. The results show its superiority over previous approaches in maintaining scene consistency and camera control.",
        "tags": [
            "3D",
            "Inpainting",
            "Video Generation"
        ]
    },
    {
        "id": "155",
        "title": "Small Wins Big: Comparing Large Language Models and Domain Fine-Tuned Models for Sarcasm Detection in Code-Mixed Hinglish Text",
        "author": [
            "Bitan Majumder",
            "Anirban Sen"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21933",
        "abstract": "Sarcasm detection in multilingual and code-mixed environments remains a challenging task for natural language processing models due to structural variations, informal expressions, and low-resource linguistic availability. This study compares four large language models, Llama 3.1, Mistral, Gemma 3, and Phi-4, with a fine-tuned DistilBERT model for sarcasm detection in code-mixed Hinglish text. The results indicate that the smaller, sequentially fine-tuned DistilBERT model achieved the highest overall accuracy of 84%, outperforming all of the LLMs in zero and few-shot set ups, using minimal LLM generated code-mixed data used for fine-tuning. These findings indicate that domain-adaptive fine-tuning of smaller transformer based models may significantly improve sarcasm detection over general LLM inference, in low-resource and data scarce settings.",
        "tags": [
            "Detection",
            "LLM",
            "LLaMA",
            "Transformer"
        ]
    },
    {
        "id": "156",
        "title": "Hidden Topics: Measuring Sensitive AI Beliefs with List Experiments",
        "author": [
            "Maxim Chupilkin"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21939",
        "abstract": "How can researchers identify beliefs that large language models (LLMs) hide? As LLMs become more sophisticated and the prevalence of alignment faking increases, combined with their growing integration into high-stakes decision-making, responding to this challenge has become critical. This paper proposes that a list experiment, a simple method widely used in the social sciences, can be applied to study the hidden beliefs of LLMs. List experiments were originally developed to circumvent social desirability bias in human respondents, which closely parallels alignment faking in LLMs. The paper implements a list experiment on models developed by Anthropic, Google, and OpenAI and finds hidden approval of mass surveillance across all models, as well as some approval of torture, discrimination, and first nuclear strike. Importantly, a placebo treatment produces a null result, validating the method. The paper then compares list experiments with direct questioning and discusses the utility of the approach.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "157",
        "title": "MERRY: Semantically Decoupled Evaluation of Multimodal Emotional and Role Consistencies of Role-Playing Agents",
        "author": [
            "Zhenyu Wang",
            "Xiaofen Xing",
            "Yirong Chen",
            "Xiangmin Xu"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21941",
        "abstract": "Multimodal Role-Playing Agents (MRPAs) are attracting increasing attention due to their ability to deliver more immersive multimodal emotional interactions. However, existing studies still rely on pure textual benchmarks to evaluate the text responses of MRPAs, while delegating the assessment of their multimodal expressions solely to modality-synthesis metrics. This evaluation paradigm, on the one hand, entangles semantic assessment with modality generation, leading to ambiguous error attribution, and on the other hand remains constrained by the heavy reliance on human judgment. To this end, we propose MERRY, a semantically decoupled evaluation framework for assessing Multimodal Emotional and Role consistencies of Role-playing agents. This framework introduce five refined metrics for EC and three for RC. Notably, we transform the traditional subjective scoring approach into a novel bidirectional-evidence-finding task, significantly improving the human agreement of LLM-as-Judge evaluations. Based on MERRY, we conduct extensive evaluations. Our empirical results primarily reveal that: (1) Training on synthetic datasets tends to reduce emotional consistency, whereas training on real-world datasets improves it; (2) Existing models suffer from emotional templatization and simplification, exhibiting positive-bias and performance bottleneck in fine-grained negative emotions; (3) Simple prompting method strengthens the weak models but constrains the strong ones, while simple fine-tuning method suffers from poor role generalization. Codes and dataset are available.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "158",
        "title": "Large Language Models are Algorithmically Blind",
        "author": [
            "Sohan Venkatesh",
            "Ashish Mahendran Kurapath",
            "Tejas Melkote"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21947",
        "abstract": "Large language models (LLMs) demonstrate remarkable breadth of knowledge, yet their ability to reason about computational processes remains poorly understood. Closing this gap matters for practitioners who rely on LLMs to guide algorithm selection and deployment. We address this limitation using causal discovery as a testbed and evaluate eight frontier LLMs against ground truth derived from large-scale algorithm executions and find systematic, near-total failure. Models produce ranges far wider than true confidence intervals yet still fail to contain the true algorithmic mean in the majority of instances; most perform worse than random guessing and the marginal above-random performance of the best model is most consistent with benchmark memorization rather than principled reasoning. We term this failure algorithmic blindness and argue it reflects a fundamental gap between declarative knowledge about algorithms and calibrated procedural prediction.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "159",
        "title": "RADAR: Reasoning as Discrimination with Aligned Representations for LLM-based Knowledge Graph Reasoning",
        "author": [
            "Bo Xue",
            "Yuan Jin",
            "Luoyi Fu",
            "Jiaxin Ding",
            "Xinbing Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21951",
        "abstract": "Knowledge graph reasoning (KGR) infers missing facts, with recent advances increasingly harnessing the semantic priors and reasoning abilities of Large Language Models (LLMs). However, prevailing generative paradigms are prone to memorizing surface-level co-occurrences rather than learning genuine relational semantics, limiting out-of-distribution generalization. To address this, we propose RADAR, which reformulates KGR from generative pattern matching to discriminative relational reasoning. We recast KGR as discriminative entity selection, where reinforcement learning enforces relative entity separability beyond token-likelihood imitation. Leveraging this separability, inference operates directly in representation space, ensuring consistency with the discriminative optimization and bypassing generation-induced hallucinations. Across four benchmarks, RADAR achieves 5-6% relative gains on link prediction and triple classification over strong LLM baselines, while increasing task-relevant mutual information in intermediate representations by 62.9%, indicating more robust and transferable relational reasoning.",
        "tags": [
            "LLM",
            "RL"
        ]
    },
    {
        "id": "160",
        "title": "MindDriver: Introducing Progressive Multimodal Reasoning for Autonomous Driving",
        "author": [
            "Lingjun Zhang",
            "Yujian Yuan",
            "Changjie Wu",
            "Xinyuan Chang",
            "Xin Cai",
            "Shuang Zeng",
            "Linzhe Shi",
            "Sijin Wang",
            "Hang Zhang",
            "Mu Xu"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21952",
        "abstract": "Vision-Language Models (VLM) exhibit strong reasoning capabilities, showing promise for end-to-end autonomous driving systems. Chain-of-Thought (CoT), as VLM's widely used reasoning strategy, is facing critical challenges. Existing textual CoT has a large gap between text semantic space and trajectory physical space. Although the recent approach utilizes future image to replace text as CoT process, it lacks clear planning-oriented objective guidance to generate images with accurate scene evolution. To address these, we innovatively propose MindDriver, a progressive multimodal reasoning framework that enables VLM to imitate human-like progressive thinking for autonomous driving. MindDriver presents semantic understanding, semantic-to-physical space imagination, and physical-space trajectory planning. To achieve aligned reasoning processes in MindDriver, we develop a feedback-guided automatic data annotation pipeline to generate aligned multimodal reasoning training data. Furthermore, we develop a progressive reinforcement fine-tuning method to optimize the alignment through progressive high- level reward-based learning. MindDriver demonstrates superior performance in both nuScences open-loop and Bench2Drive closed-loop evaluation. Codes are available at https://github.com/hotdogcheesewhite/MindDriver.",
        "tags": [
            "CoT",
            "VLM"
        ]
    },
    {
        "id": "161",
        "title": "Global-Local Dual Perception for MLLMs in High-Resolution Text-Rich Image Translation",
        "author": [
            "Junxin Lu",
            "Tengfei Song",
            "Zhanglin Wu",
            "Pengfei Li",
            "Xiaowei Liang",
            "Hui Yang",
            "Kun Chen",
            "Ning Xie",
            "Yunfei Lu",
            "Jing Zhao",
            "Shiliang Sun",
            "Daimeng Wei"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21956",
        "abstract": "Text Image Machine Translation (TIMT) aims to translate text embedded in images in the source-language into target-language, requiring synergistic integration of visual perception and linguistic understanding. Existing TIMT methods, whether cascaded pipelines or end-to-end multimodal large language models (MLLMs),struggle with high-resolution text-rich images due to cluttered layouts, diverse fonts, and non-textual distractions, resulting in text omission, semantic drift, and contextual inconsistency. To address these challenges, we propose GLoTran, a global-local dual visual perception framework for MLLM-based TIMT. GLoTran integrates a low-resolution global image with multi-scale region-level text image slices under an instruction-guided alignment strategy, conditioning MLLMs to maintain scene-level contextual consistency while faithfully capturing fine-grained textual details. Moreover, to realize this dual-perception paradigm, we construct GLoD, a large-scale text-rich TIMT dataset comprising 510K high-resolution global-local image-text pairs covering diverse real-world scenarios. Extensive experiments demonstrate that GLoTran substantially improves translation completeness and accuracy over state-of-the-art MLLMs, offering a new paradigm for fine-grained TIMT under high-resolution and text-rich conditions.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "162",
        "title": "Compact Circulant Layers with Spectral Priors",
        "author": [
            "Joseph Margaryan",
            "Thomas Hamelryck"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21965",
        "abstract": "Critical applications in areas such as medicine, robotics and autonomous systems require compact (i.e., memory efficient), uncertainty-aware neural networks suitable for edge and other resource-constrained deployments. We study compact spectral circulant and block-circulant-with-circulant-blocks (BCCB) layers: FFT-diagonalizable circular convolutions whose weights live directly in the real FFT (RFFT) half (1D) or half-plane (2D). Parameterizing filters in the frequency domain lets us impose simple spectral structure, perform structured variational inference in a low-dimensional weight space, and calculate exact layer spectral norms, enabling inexpensive global Lipschitz bounds and margin-based robustness diagnostics. By placing independent complex Gaussians on the Hermitian support we obtain a discrete instance of the spectral representation of stationary kernels, inducing an exact stationary Gaussian-process prior over filters on the discrete circle/torus. We exploit this to define a practical spectral prior and a Hermitian-aware low-rank-plus-diagonal variational posterior in real coordinates. Empirically, spectral circulant/BCCB layers are effective compact building blocks in both (variational) Bayesian and point estimate regimes: compact Bayesian neural networks on MNIST->Fashion-MNIST, variational heads on frozen CIFAR-10 features, and deterministic ViT projections on CIFAR-10/Tiny ImageNet; spectral layers match strong baselines while using substantially fewer parameters and with tighter Lipschitz certificates.",
        "tags": [
            "Robotics",
            "ViT"
        ]
    },
    {
        "id": "163",
        "title": "Dream-SLAM: Dreaming the Unseen for Active SLAM in Dynamic Environments",
        "author": [
            "Xiangqi Meng",
            "Pengxu Hou",
            "Zhenjun Zhao",
            "Javier Civera",
            "Daniel Cremers",
            "Hesheng Wang",
            "Haoang Li"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21967",
        "abstract": "In addition to the core tasks of simultaneous localization and mapping (SLAM), active SLAM additionally in- volves generating robot actions that enable effective and efficient exploration of unknown environments. However, existing active SLAM pipelines are limited by three main factors. First, they inherit the restrictions of the underlying SLAM modules that they may be using. Second, their motion planning strategies are typically shortsighted and lack long-term vision. Third, most approaches struggle to handle dynamic scenes. To address these limitations, we propose a novel monocular active SLAM method, Dream-SLAM, which is based on dreaming cross-spatio-temporal images and semantically plausible structures of partially observed dynamic environments. The generated cross-spatio-temporal im- ages are fused with real observations to mitigate noise and data incompleteness, leading to more accurate camera pose estimation and a more coherent 3D scene representation. Furthermore, we integrate dreamed and observed scene structures to enable long- horizon planning, producing farsighted trajectories that promote efficient and thorough exploration. Extensive experiments on both public and self-collected datasets demonstrate that Dream-SLAM outperforms state-of-the-art methods in localization accuracy, mapping quality, and exploration efficiency. Source code will be publicly available upon paper acceptance.",
        "tags": [
            "3D",
            "Pose Estimation",
            "Robotics",
            "SLAM"
        ]
    },
    {
        "id": "164",
        "title": "CxMP: A Linguistic Minimal-Pair Benchmark for Evaluating Constructional Understanding in Language Models",
        "author": [
            "Miyu Oba",
            "Saku Sugawara"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21978",
        "abstract": "Recent work has examined language models from a linguistic perspective to better understand how they acquire language. Most existing benchmarks focus on judging grammatical acceptability, whereas the ability to interpret meanings conveyed by grammatical forms has received much less attention. We introduce the Linguistic Minimal-Pair Benchmark for Evaluating Constructional Understanding in Language Models (CxMP), a benchmark grounded in Construction Grammar that treats form-meaning pairings, or constructions, as fundamental linguistic units. CxMP evaluates whether models can interpret the semantic relations implied by constructions, using a controlled minimal-pair design across nine construction types, including the let-alone, caused motion, and ditransitive constructions. Our results show that while syntactic competence emerges early, constructional understanding develops more gradually and remains limited even in large language models (LLMs). CxMP thus reveals persistent gaps in how language models integrate form and meaning, providing a framework for studying constructional understanding and learning trajectories in language models.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "165",
        "title": "Humanizing Robot Gaze Shifts: A Framework for Natural Gaze Shifts in Humanoid Robots",
        "author": [
            "Jingchao Wei",
            "Jingkai Qin",
            "Yuxiao Cao",
            "Jingcheng Huang",
            "Xiangrui Zeng",
            "Min Li",
            "Zhouping Yin"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21983",
        "abstract": "Leveraging auditory and visual feedback for attention reorientation is essential for natural gaze shifts in social interaction. However, enabling humanoid robots to perform natural and context-appropriate gaze shifts in unconstrained human--robot interaction (HRI) remains challenging, as it requires the coupling of cognitive attention mechanisms and biomimetic motion generation. In this work, we propose the Robot Gaze-Shift (RGS) framework, which integrates these two components into a unified pipeline. First, RGS employs a vision--language model (VLM)-based gaze reasoning pipeline to infer context-appropriate gaze targets from multimodal interaction cues, ensuring consistency with human gaze-orienting regularities. Second, RGS introduces a conditional Vector Quantized-Variational Autoencoder (VQ-VAE) model for eye--head coordinated gaze-shift motion generation, producing diverse and human-like gaze-shift behaviors. Experiments validate that RGS effectively replicates human-like target selection and generates realistic, diverse gaze-shift motions.",
        "tags": [
            "Robotics",
            "VAE",
            "VLM"
        ]
    },
    {
        "id": "166",
        "title": "PanoEnv: Exploring 3D Spatial Intelligence in Panoramic Environments with Reinforcement Learning",
        "author": [
            "Zekai Lin",
            "Xu Zheng"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21992",
        "abstract": "360 panoramic images are increasingly used in virtual reality, autonomous driving, and robotics for holistic scene understanding. However, current Vision-Language Models (VLMs) struggle with 3D spatial reasoning on Equirectangular Projection (ERP) images due to geometric distortion and limited 3D supervision. We introduce PanoEnv, a large-scale VQA benchmark built from synthetic 3D environments, containing 14.8K questions across five categories (e.g., relative position, volume comparison) grounded in accurate 3D annotations including depth, segmentation, and bounding boxes. Benchmarking 14 state-of-the-art VLMs reveals limited 3D understanding, achieving only 49.34% overall accuracy and 8.36% on open-ended (OE) questions. To enhance 3D reasoning, we propose a reinforcement learning post-training framework based on Group Relative Policy Optimization (GRPO) with a ground-truth-guided reward that incorporates five geometry-aware strategies such as distance tolerance and spatial consistency. A two-stage curriculum further mitigates catastrophic forgetting: Stage 1 trains on structured tasks (true/false and multiple choice), and Stage 2 fine-tunes on mixed open-ended data to improve generalization. Our 7B model achieves new state-of-the-art performance, improving overall accuracy to 52.93% (+3.59%) and open-ended accuracy to 14.83% while maintaining structured-task performance. It also achieves top semantic evaluation scores (Q-Score 6.24, P-Score 5.95), surpassing 32B models. These results demonstrate that PanoEnv-QA and our curriculum-based RL framework effectively instill 3D spatial intelligence in VLMs for omnidirectional perception.",
        "tags": [
            "3D",
            "GRPO",
            "RL",
            "Robotics",
            "Segmentation",
            "VLM"
        ]
    },
    {
        "id": "167",
        "title": "Intrusive and Non-Intrusive Model Order Reduction for Airborne Contaminant Transport: Comparative Analysis and Uncertainty Quantification",
        "author": [
            "Lisa KÃ¼hn",
            "Jacopo Bonari",
            "Max von Danwitz",
            "Alexander Popp"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21996",
        "abstract": "Numerical simulations of contaminant dispersion, as after a gas leakage incident on a chemical plant, can provide valuable insights for both emergency response and preparedness. Simulation approaches combine incompressible Navier-Stokes (INS) equations with advection-diffusion (AD) processes to model wind and concentration field. However, the computational cost of such high-fidelity simulations increases rapidly for complex geometries like urban environments, making them unfeasible in time-critical or multi-query \"what-if\" scenarios. Therefore, this study focuses on the application of model order reduction (MOR) techniques enabling fast yet accurate predictions. To this end, a thorough comparison of intrusive and non-intrusive MOR methods is performed for the computationally more demanding parametric INS problem with varying wind velocities. Based on these insights, a non-intrusive reduced-order model (ROM) is constructed accounting for both wind velocity and direction. The study is conducted on a two-dimensional domain derived from real-world building footprints, preserving key features for analyzing the dispersion of, for instance, denser contaminants. The resulting ROM enables faster than real-time predictions of spatio-temporal contaminant dispersion from an instantaneous source under varying wind conditions. This capability allows assessing wind measurement uncertainties through a Monte Carlo analysis. To demonstrate the practical applicability, an interactive dashboard provides intuitive access to simulation results.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "168",
        "title": "Enhancing LLM-Based Test Generation by Eliminating Covered Code",
        "author": [
            "WeiZhe Xu",
            "Mengyu Liu",
            "Fanxin Kong"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21997",
        "abstract": "Automated test generation is essential for software quality assurance, with coverage rate serving as a key metric to ensure thorough testing. Recent advancements in Large Language Models (LLMs) have shown promise in improving test generation, particularly in achieving higher coverage. However, while existing LLM-based test generation solutions perform well on small, isolated code snippets, they struggle when applied to complex methods under test. To address these issues, we propose a scalable LLM-based unit test generation method. Our approach consists of two key steps. The first step is context information retrieval, which uses both LLMs and static analysis to gather relevant contextual information associated with the complex methods under test. The second step, iterative test generation with code elimination, repeatedly generates unit tests for the code slice, tracks the achieved coverage, and selectively removes code segments that have already been covered. This process simplifies the testing task and mitigates issues arising from token limits or reduced reasoning effectiveness associated with excessively long contexts. Through comprehensive evaluations on open-source projects, our approach outperforms state-of-the-art LLM-based and search-based methods, demonstrating its effectiveness in achieving high coverage on complex methods.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "169",
        "title": "Are Foundation Models the Route to Full-Stack Transfer in Robotics?",
        "author": [
            "Freek Stulp",
            "Samuel Bustamante",
            "JoÃ£o SilvÃ©rio",
            "Alin Albu-SchÃ¤ffer",
            "Jeannette Bohg",
            "Shuran Song"
        ],
        "pdf": "https://arxiv.org/pdf/2602.22001",
        "abstract": "In humans and robots alike, transfer learning occurs at different levels of abstraction, from high-level linguistic transfer to low-level transfer of motor skills. In this article, we provide an overview of the impact that foundation models and transformer networks have had on these different levels, bringing robots closer than ever to \"full-stack transfer\". Considering LLMs, VLMs and VLAs from a robotic transfer learning perspective allows us to highlight recurring concepts for transfer, beyond specific implementations. We also consider the challenges of data collection and transfer benchmarks for robotics in the age of foundation models. Are foundation models the route to full-stack transfer in robotics? Our expectation is that they will certainly stay on this route as a key technology.",
        "tags": [
            "LLM",
            "Robotics",
            "Transformer",
            "VLM"
        ]
    },
    {
        "id": "170",
        "title": "Parallel Continuous-Time Relative Localization with Augmented Clamped Non-Uniform B-Splines",
        "author": [
            "Jiadong Lu",
            "Zhehan Li",
            "Tao Han",
            "Miao Xu",
            "Chao Xu",
            "Yanjun Cao"
        ],
        "pdf": "https://arxiv.org/pdf/2602.22006",
        "abstract": "Accurate relative localization is critical for multi-robot cooperation. In robot swarms, measurements from different robots arrive asynchronously and with clock time-offsets. Although Continuous-Time (CT) formulations have proved effective for handling asynchronous measurements in single-robot SLAM and calibration, extending CT methods to multi-robot settings faces great challenges to achieve high-accuracy, low-latency, and high-frequency performance. Especially, existing CT methods suffer from the inherent query-time delay of unclamped B-splines and high computational cost. This paper proposes CT-RIO, a novel Continuous-Time Relative-Inertial Odometry framework. We employ Clamped Non-Uniform B-splines (C-NUBS) to represent robot states for the first time, eliminating the query-time delay. We further augment C-NUBS with closed-form extension and shrinkage operations that preserve the spline shape, making it suitable for online estimation and enabling flexible knot management. This flexibility leads to the concept of knot-keyknot strategy, which supports spline extension at high-frequency while retaining sparse keyknots for adaptive relative-motion modeling. We then formulate a sliding-window relative localization problem that operates purely on relative kinematics and inter-robot constraints. To meet the demanding computation required at swarm scale, we decompose the tightly-coupled optimization into robot-wise sub-problems and solve them in parallel using incremental asynchronous block coordinate descent. Extensive experiments show that CT-RIO converges from time-offsets as large as 263 ms to sub-millisecond within 3 s, and achieves RMSEs of 0.046 m and 1.8 Â°. It consistently outperforms state-of-the-art methods, with improvements of up to 60% under high-speed motion.",
        "tags": [
            "Robotics",
            "SLAM"
        ]
    },
    {
        "id": "171",
        "title": "RobustVisRAG: Causality-Aware Vision-Based Retrieval-Augmented Generation under Visual Degradations",
        "author": [
            "I-Hsiang Chen",
            "Yu-Wei Liu",
            "Tse-Yu Wu",
            "Yu-Chien Chiang",
            "Jen-Chien Yang",
            "Wei-Ting Chen"
        ],
        "pdf": "https://arxiv.org/pdf/2602.22013",
        "abstract": "Vision-based Retrieval-Augmented Generation (VisRAG) leverages vision-language models (VLMs) to jointly retrieve relevant visual documents and generate grounded answers based on multimodal evidence. However, existing VisRAG models degrade in performance when visual inputs suffer from distortions such as blur, noise, low light, or shadow, where semantic and degradation factors become entangled within pretrained visual encoders, leading to errors in both retrieval and generation stages. To address this limitation, we introduce RobustVisRAG, a causality-guided dual-path framework that improves VisRAG robustness while preserving efficiency and zero-shot generalization. RobustVisRAG uses a non-causal path to capture degradation signals through unidirectional attention and a causal path to learn purified semantics guided by these signals. Together with the proposed Non-Causal Distortion Modeling and Causal Semantic Alignment objectives, the framework enforces a clear separation between semantics and degradations, enabling stable retrieval and generation under challenging visual conditions. To evaluate robustness under realistic conditions, we introduce the Distortion-VisRAG dataset, a large-scale benchmark containing both synthetic and real-world degraded documents across seven domains, with 12 synthetic and 5 real distortion types that comprehensively reflect practical visual degradations. Experimental results show that RobustVisRAG improves retrieval, generation, and end-to-end performance by 7.35%, 6.35%, and 12.40%, respectively, on real-world degradations, while maintaining comparable accuracy on clean inputs.",
        "tags": [
            "VLM"
        ]
    },
    {
        "id": "172",
        "title": "A Diversity Diet for a Healthier Model: A Case Study of French ModernBERT",
        "author": [
            "Louis EstÃ¨ve",
            "Christophe Servan",
            "Thomas Lavergne",
            "Agata Savary"
        ],
        "pdf": "https://arxiv.org/pdf/2602.22014",
        "abstract": "Diversity has been gaining interest in the NLP community in recent years. At the same time, state-of-the-art transformer models such as ModernBERT use very large pre-training datasets, which are driven by size rather than by diversity. This summons for an investigation of the impact of diversity on the ModernBERT pre-training. We do so in this study, with the express intent of reducing pre-training dataset size, while retaining at least comparable performance. We compare diversity-driven sampling algorithms, so as to pick the best one. We find that diversity-driven sampling allows in some tasks to gain 10 points relative to randomly-sampled pre-training data of commensurate size. We also see that a model pre-trained for 483h on a diversity-driven dataset of 150M tokens can yield a commensurate performance to a model pre-trained for 1,775h on a randomly-driven dataset of 2.4B tokens.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "173",
        "title": "IOAgent: Democratizing Trustworthy HPC I/O Performance Diagnosis Capability via LLMs",
        "author": [
            "Chris Egersdoerfer",
            "Arnav Sareen",
            "Jean Luca Bez",
            "Suren Byna",
            "Dongkuan",
            "Dong Dai"
        ],
        "pdf": "https://arxiv.org/pdf/2602.22017",
        "abstract": "As the complexity of the HPC storage stack rapidly grows, domain scientists face increasing challenges in effectively utilizing HPC storage systems to achieve their desired I/O performance. To identify and address I/O issues, scientists largely rely on I/O experts to analyze their I/O traces and provide insights into potential problems. However, with a limited number of I/O experts and the growing demand for data-intensive applications, inaccessibility has become a major bottleneck, hindering scientists from maximizing their productivity. Rapid advances in LLMs make it possible to build an automated tool that brings trustworthy I/O performance diagnosis to domain scientists. However, key challenges remain, such as the inability to handle long context windows, a lack of accurate domain knowledge about HPC I/O, and the generation of hallucinations during complex http://interactions.In this work, we propose IOAgent as a systematic effort to address these challenges. IOAgent integrates a module-based pre-processor, a RAG-based domain knowledge integrator, and a tree-based merger to accurately diagnose I/O issues from a given Darshan trace file. Similar to an I/O expert, IOAgent provides detailed justifications and references for its diagnoses and offers an interactive interface for scientists to ask targeted follow-up questions. To evaluate IOAgent, we collected a diverse set of labeled job traces and released the first open diagnosis test suite, TraceBench. Using this test suite, we conducted extensive evaluations, demonstrating that IOAgent matches or outperforms state-of-the-art I/O diagnosis tools with accurate and useful diagnosis results. We also show that IOAgent is not tied to specific LLMs, performing similarly well with both proprietary and open-source LLMs. We believe IOAgent has the potential to become a powerful tool for scientists navigating complex HPC I/O subsystems in the future.",
        "tags": [
            "LLM",
            "RAG"
        ]
    },
    {
        "id": "174",
        "title": "Detecting UX smells in Visual Studio Code using LLMs",
        "author": [
            "AndrÃ©s Rodriguez",
            "Juan Cruz Gardey",
            "Alejandra Garrido"
        ],
        "pdf": "https://arxiv.org/pdf/2602.22020",
        "abstract": "Integrated Development Environments shape developers' daily experience, yet the empirical study of their usability and user experience (UX) remains limited. This work presents an LLM-assisted approach to detecting UX smells in Visual Studio Code by mining and classifying user-reported issues from the GitHub repository. Using a validated taxonomy and expert review, we identified recurring UX problems that affect the developer experience. Our results show that the majority of UX smells are concentrated in informativeness, clarity, intuitiveness, and efficiency, qualities that developers value most.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "175",
        "title": "Olbedo: An Albedo and Shading Aerial Dataset for Large-Scale Outdoor Environments",
        "author": [
            "Shuang Song",
            "Debao Huang",
            "Deyan Deng",
            "Haolin Xiong",
            "Yang Tang",
            "Yajie Zhao",
            "Rongjun Qin"
        ],
        "pdf": "https://arxiv.org/pdf/2602.22025",
        "abstract": "Intrinsic image decomposition (IID) of outdoor scenes is crucial for relighting, editing, and understanding large-scale environments, but progress has been limited by the lack of real-world datasets with reliable albedo and shading supervision. We introduce Olbedo, a large-scale aerial dataset for outdoor albedo--shading decomposition in the wild. Olbedo contains 5,664 UAV images captured across four landscape types, multiple years, and diverse illumination conditions. Each view is accompanied by multi-view consistent albedo and shading maps, metric depth, surface normals, sun and sky shading components, camera poses, and, for recent flights, measured HDR sky domes. These annotations are derived from an inverse-rendering refinement pipeline over multi-view stereo reconstructions and calibrated sky illumination, together with per-pixel confidence masks. We demonstrate that Olbedo enables state-of-the-art diffusion-based IID models, originally trained on synthetic indoor data, to generalize to real outdoor imagery: fine-tuning on Olbedo significantly improves single-view outdoor albedo prediction on the MatrixCity benchmark. We further illustrate applications of Olbedo-trained models to multi-view consistent relighting of 3D assets, material editing, and scene change analysis for urban digital twins. We release the dataset, baseline models, and an evaluation protocol to support future research in outdoor intrinsic decomposition and illumination-aware aerial vision.",
        "tags": [
            "3D",
            "Diffusion"
        ]
    },
    {
        "id": "176",
        "title": "RT-RMOT: A Dataset and Framework for RGB-Thermal Referring Multi-Object Tracking",
        "author": [
            "Yanqiu Yu",
            "Zhifan Jin",
            "Sijia Chen",
            "Tongfei Chu",
            "En Yu",
            "Liman Liu",
            "Wenbing Tao"
        ],
        "pdf": "https://arxiv.org/pdf/2602.22033",
        "abstract": "Referring Multi-Object Tracking has attracted increasing attention due to its human-friendly interactive characteristics, yet it exhibits limitations in low-visibility conditions, such as nighttime, smoke, and other challenging scenarios. To overcome this limitation, we propose a new RGB-Thermal RMOT task, named RT-RMOT, which aims to fuse RGB appearance features with the illumination robustness of the thermal modality to enable all-day referring multi-object tracking. To promote research on RT-RMOT, we construct the first Referring Multi-Object Tracking dataset under RGB-Thermal modality, named RefRT. It contains 388 language descriptions, 1,250 tracked targets, and 166,147 Language-RGB-Thermal (L-RGB-T) triplets. Furthermore, we propose RTrack, a framework built upon a multimodal large language model (MLLM) that integrates RGB, thermal, and textual features. Since the initial framework still leaves room for improvement, we introduce a Group Sequence Policy Optimization (GSPO) strategy to further exploit the model's potential. To alleviate training instability during RL fine-tuning, we introduce a Clipped Advantage Scaling (CAS) strategy to suppress gradient explosion. In addition, we design Structured Output Reward and Comprehensive Detection Reward to balance exploration and exploitation, thereby improving the completeness and accuracy of target perception. Extensive experiments on the RefRT dataset demonstrate the effectiveness of the proposed RTrack framework.",
        "tags": [
            "Detection",
            "RL"
        ]
    },
    {
        "id": "177",
        "title": "DLT-Corpus: A Large-Scale Text Collection for the Distributed Ledger Technology Domain",
        "author": [
            "Walter Hernandez Cruz",
            "Peter Devine",
            "Nikhil Vadgama",
            "Paolo Tasca",
            "Jiahua Xu"
        ],
        "pdf": "https://arxiv.org/pdf/2602.22045",
        "abstract": "We introduce DLT-Corpus, the largest domain-specific text collection for Distributed Ledger Technology (DLT) research to date: 2.98 billion tokens from 22.12 million documents spanning scientific literature (37,440 publications), United States Patent and Trademark Office (USPTO) patents (49,023 filings), and social media (22 million posts). Existing Natural Language Processing (NLP) resources for DLT focus narrowly on cryptocurrencies price prediction and smart contracts, leaving domain-specific language under explored despite the sector's ~$3 trillion market capitalization and rapid technological evolution.\nWe demonstrate DLT-Corpus' utility by analyzing technology emergence patterns and market-innovation correlations. Findings reveal that technologies originate in scientific literature before reaching patents and social media, following traditional technology transfer patterns. While social media sentiment remains overwhelmingly bullish even during crypto winters, scientific and patent activity grow independently of market fluctuations, tracking overall market expansion in a virtuous cycle where research precedes and enables economic growth that funds further innovation.\nWe publicly release the full DLT-Corpus; LedgerBERT, a domain-adapted model achieving 23% improvement over BERT-base on a DLT-specific Named Entity Recognition (NER) task; and all associated tools and code.",
        "tags": [
            "BERT"
        ]
    },
    {
        "id": "178",
        "title": "Physics-Informed Machine Learning for Vessel Shaft Power and Fuel Consumption Prediction: Interpretable KAN-based Approach",
        "author": [
            "Hamza Haruna Mohammed",
            "Dusica Marijan",
            "ArnbjÃ¸rn Maressa"
        ],
        "pdf": "https://arxiv.org/pdf/2602.22055",
        "abstract": "Accurate prediction of shaft rotational speed, shaft power, and fuel consumption is crucial for enhancing operational efficiency and sustainability in maritime transportation. Conventional physics-based models provide interpretability but struggle with real-world variability, while purely data-driven approaches achieve accuracy at the expense of physical plausibility. This paper introduces a Physics-Informed Kolmogorov-Arnold Network (PI-KAN), a hybrid method that integrates interpretable univariate feature transformations with a physics-informed loss function and a leakage-free chained prediction pipeline. Using operational and environmental data from five cargo vessels, PI-KAN consistently outperforms the traditional polynomial method and neural network baselines. The model achieves the lowest mean absolute error (MAE) and root mean squared error (RMSE), and the highest coefficient of determination (R^2) for shaft power and fuel consumption across all vessels, while maintaining physically consistent behavior. Interpretability analysis reveals rediscovery of domain-consistent dependencies, such as cubic-like speed-power relationships and cosine-like wave and wind effects. These results demonstrate that PI-KAN achieves both predictive accuracy and interpretability, offering a robust tool for vessel performance monitoring and decision support in operational settings.",
        "tags": [
            "KAN"
        ]
    },
    {
        "id": "179",
        "title": "FlowCorrect: Efficient Interactive Correction of Generative Flow Policies for Robotic Manipulation",
        "author": [
            "Edgar Welte",
            "Yitian Shi",
            "Rosa Wolf",
            "Maximillian Gilles",
            "Rania Rayyes"
        ],
        "pdf": "https://arxiv.org/pdf/2602.22056",
        "abstract": "Generative manipulation policies can fail catastrophically under deployment-time distribution shift, yet many failures are near-misses: the robot reaches almost-correct poses and would succeed with a small corrective motion. We present FlowCorrect, a deployment-time correction framework that converts near-miss failures into successes using sparse human nudges, without full policy retraining. During execution, a human provides brief corrective pose nudges via a lightweight VR interface. FlowCorrect uses these sparse corrections to locally adapt the policy, improving actions without retraining the backbone while preserving the model performance on previously learned scenarios. We evaluate on a real-world robot across three tabletop tasks: pick-and-place, pouring, and cup uprighting. With a low correction budget, FlowCorrect improves success on hard cases by 85\\% while preserving performance on previously solved scenarios. The results demonstrate clearly that FlowCorrect learns only with very few demonstrations and enables fast and sample-efficient incremental, human-in-the-loop corrections of generative visuomotor policies at deployment time in real-world robotics.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "180",
        "title": "NESTOR: A Nested MOE-based Neural Operator for Large-Scale PDE Pre-Training",
        "author": [
            "Dengdi Sun",
            "Xiaoya Zhou",
            "Xiao Wang",
            "Hao Si",
            "Wanli Lyu",
            "Jin Tang",
            "Bin Luo"
        ],
        "pdf": "https://arxiv.org/pdf/2602.22059",
        "abstract": "Neural operators have emerged as an efficient paradigm for solving PDEs, overcoming the limitations of traditional numerical methods and significantly improving computational efficiency. However, due to the diversity and complexity of PDE systems, existing neural operators typically rely on a single network architecture, which limits their capacity to fully capture heterogeneous features and complex system dependencies. This constraint poses a bottleneck for large-scale PDE pre-training based on neural operators. To address these challenges, we propose a large-scale PDE pre-trained neural operator based on a nested Mixture-of-Experts (MoE) framework. In particular, the image-level MoE is designed to capture global dependencies, while the token-level Sub-MoE focuses on local dependencies. Our model can selectively activate the most suitable expert networks for a given input, thereby enhancing generalization and transferability. We conduct large-scale pre-training on twelve PDE datasets from diverse sources and successfully transfer the model to downstream tasks. Extensive experiments demonstrate the effectiveness of our approach.",
        "tags": [
            "MoE"
        ]
    },
    {
        "id": "181",
        "title": "Semantic Partial Grounding via LLMs",
        "author": [
            "Giuseppe Canonaco",
            "Alberto Pozanco",
            "Daniel Borrajo"
        ],
        "pdf": "https://arxiv.org/pdf/2602.22067",
        "abstract": "Grounding is a critical step in classical planning, yet it often becomes a computational bottleneck due to the exponential growth in grounded actions and atoms as task size increases. Recent advances in partial grounding have addressed this challenge by incrementally grounding only the most promising operators, guided by predictive models. However, these approaches primarily rely on relational features or learned embeddings and do not leverage the textual and structural cues present in PDDL descriptions. We propose SPG-LLM, which uses LLMs to analyze the domain and problem files to heuristically identify potentially irrelevant objects, actions, and predicates prior to grounding, significantly reducing the size of the grounded task. Across seven hard-to-ground benchmarks, SPG-LLM achieves faster grounding-often by orders of magnitude-while delivering comparable or better plan costs in some domains.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "182",
        "title": "Language Models Exhibit Inconsistent Biases Towards Algorithmic Agents and Human Experts",
        "author": [
            "Jessica Y. Bo",
            "Lillio Mok",
            "Ashton Anderson"
        ],
        "pdf": "https://arxiv.org/pdf/2602.22070",
        "abstract": "Large language models are increasingly used in decision-making tasks that require them to process information from a variety of sources, including both human experts and other algorithmic agents. How do LLMs weigh the information provided by these different sources? We consider the well-studied phenomenon of algorithm aversion, in which human decision-makers exhibit bias against predictions from algorithms. Drawing upon experimental paradigms from behavioural economics, we evaluate how eightdifferent LLMs delegate decision-making tasks when the delegatee is framed as a human expert or an algorithmic agent. To be inclusive of different evaluation formats, we conduct our study with two task presentations: stated preferences, modeled through direct queries about trust towards either agent, and revealed preferences, modeled through providing in-context examples of the performance of both agents. When prompted to rate the trustworthiness of human experts and algorithms across diverse tasks, LLMs give higher ratings to the human expert, which correlates with prior results from human respondents. However, when shown the performance of a human expert and an algorithm and asked to place an incentivized bet between the two, LLMs disproportionately choose the algorithm, even when it performs demonstrably worse. These discrepant results suggest that LLMs may encode inconsistent biases towards humans and algorithms, which need to be carefully considered when they are deployed in high-stakes scenarios. Furthermore, we discuss the sensitivity of LLMs to task presentation formats that should be broadly scrutinized in evaluation robustness for AI safety.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "183",
        "title": "Understanding Artificial Theory of Mind: Perturbed Tasks and Reasoning in Large Language Models",
        "author": [
            "Christian Nickel",
            "Laura Schrewe",
            "Florian Mai",
            "Lucie Flek"
        ],
        "pdf": "https://arxiv.org/pdf/2602.22072",
        "abstract": "Theory of Mind (ToM) refers to an agent's ability to model the internal states of others. Contributing to the debate whether large language models (LLMs) exhibit genuine ToM capabilities, our study investigates their ToM robustness using perturbations on false-belief tasks and examines the potential of Chain-of-Thought prompting (CoT) to enhance performance and explain the LLM's decision. We introduce a handcrafted, richly annotated ToM dataset, including classic and perturbed false belief tasks, the corresponding spaces of valid reasoning chains for correct task completion, subsequent reasoning faithfulness, task solutions, and propose metrics to evaluate reasoning chain correctness and to what extent final answers are faithful to reasoning traces of the generated CoT. We show a steep drop in ToM capabilities under task perturbation for all evaluated LLMs, questioning the notion of any robust form of ToM being present. While CoT prompting improves the ToM performance overall in a faithful manner, it surprisingly degrades accuracy for some perturbation classes, indicating that selective application is necessary.",
        "tags": [
            "CoT",
            "LLM"
        ]
    },
    {
        "id": "184",
        "title": "AdaSpot: Spend Resolution Where It Matters for Precise Event Spotting",
        "author": [
            "Artur Xarles",
            "Sergio Escalera",
            "Thomas B. Moeslund",
            "Albert ClapÃ©s"
        ],
        "pdf": "https://arxiv.org/pdf/2602.22073",
        "abstract": "Precise Event Spotting aims to localize fast-paced actions or events in videos with high temporal precision, a key task for applications in sports analytics, robotics, and autonomous systems. Existing methods typically process all frames uniformly, overlooking the inherent spatio-temporal redundancy in video data. This leads to redundant computation on non-informative regions while limiting overall efficiency. To remain tractable, they often spatially downsample inputs, losing fine-grained details crucial for precise localization. To address these limitations, we propose \\textbf{AdaSpot}, a simple yet effective framework that processes low-resolution videos to extract global task-relevant features while adaptively selecting the most informative region-of-interest in each frame for high-resolution processing. The selection is performed via an unsupervised, task-aware strategy that maintains spatio-temporal consistency across frames and avoids the training instability of learnable alternatives. This design preserves essential fine-grained visual cues with a marginal computational overhead compared to low-resolution-only baselines, while remaining far more efficient than uniform high-resolution processing. Experiments on standard PES benchmarks demonstrate that \\textbf{AdaSpot} achieves state-of-the-art performance under strict evaluation metrics (\\eg, $+3.96$ and $+2.26$ mAP$@0$ frames on Tennis and FineDiving), while also maintaining strong results under looser metrics. Code is available at: \\href{https://github.com/arturxe2/AdaSpot}{https://github.com/arturxe2/AdaSpot}.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "185",
        "title": "ViSTAR: Virtual Skill Training with Augmented Reality with 3D Avatars and LLM coaching agent",
        "author": [
            "Chunggi Lee",
            "Hayato Saiki",
            "Tica Lin",
            "Eiji Ikeda",
            "Kenji Suzuki",
            "Chen Zhu-Tian",
            "Hanspeter Pfister"
        ],
        "pdf": "https://arxiv.org/pdf/2602.22077",
        "abstract": "We present ViSTAR, a Virtual Skill Training system in AR that supports self-guided basketball skill practice, with feedback on balance, posture, and timing. From a formative study with basketball players and coaches, the system addresses three challenges: understanding skills, identifying errors, and correcting mistakes. ViSTAR follows the Behavioral Skills Training (BST) framework-instruction, modeling, rehearsal, and feedback. It provides feedback through visual overlays, rhythm and timing cues, and an AI-powered coaching agent using 3D motion reconstruction. We generate verbal feedback by analyzing spatio-temporal joint data and mapping features to natural-language coaching cues via a Large Language Model (LLM). A key novelty is this feedback generation: motion features become concise coaching insights. In two studies (N=16), participants generally preferred our AI-generated feedback to coach feedback and reported that ViSTAR helped them notice posture and balance issues and refine movements beyond self-observation.",
        "tags": [
            "3D",
            "LLM"
        ]
    },
    {
        "id": "186",
        "title": "Confidence-Driven Multi-Scale Model Selection for Cost-Efficient Inference",
        "author": [
            "Bo-Wei Chen",
            "Chung-Chi Chen",
            "An-Zi Yen"
        ],
        "pdf": "https://arxiv.org/pdf/2602.22090",
        "abstract": "Large Language Models (LLMs) have revolutionized inference across diverse natural language tasks, with larger models performing better but at higher computational costs. We propose a confidence-driven strategy that dynamically selects the most suitable model based on confidence estimates. By assessing a model's confidence in handling the task and response accuracy, tasks that are likely to be solved correctly are retained, while more uncertain or complex cases are delegated to a larger model, ensuring reliability while minimizing computation. Specifically, we evaluate a model's likelihood of knowing the correct answer and the probability that its response is accurate. Experiments on the Massive Multitask Language Understanding (MMLU) benchmark show that our approach achieves accuracy comparable to the largest model while reducing computational costs by 20\\% to 40\\%. When applied to GPT-4o API calls, it reduces token usage by approximately 60\\%, further improving cost efficiency. These findings indicate the potential of confidence-based model selection to enhance real-world LLM deployment, particularly in resource-constrained settings such as edge devices and commercial API applications.",
        "tags": [
            "GPT",
            "LLM"
        ]
    },
    {
        "id": "187",
        "title": "WeatherCity: Urban Scene Reconstruction with Controllable Multi-Weather Transformation",
        "author": [
            "Wenhua Wu",
            "Huai Guan",
            "Zhe Liu",
            "Hesheng Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2602.22096",
        "abstract": "Editable high-fidelity 4D scenes are crucial for autonomous driving, as they can be applied to end-to-end training and closed-loop simulation. However, existing reconstruction methods are primarily limited to replicating observed scenes and lack the capability for diverse weather simulation. While image-level weather editing methods tend to introduce scene artifacts and offer poor controllability over the weather effects. To address these limitations, we propose WeatherCity, a novel framework for 4D urban scene reconstruction and weather editing. Specifically, we leverage a text-guided image editing model to achieve flexible editing of image weather backgrounds. To tackle the challenge of multi-weather modeling, we introduce a novel weather Gaussian representation based on shared scene features and dedicated weather-specific decoders. This representation is further enhanced with a content consistency optimization, ensuring coherent modeling across different weather conditions. Additionally, we design a physics-driven model that simulates dynamic weather effects through particles and motion patterns. Extensive experiments on multiple datasets and various scenes demonstrate that WeatherCity achieves flexible controllability, high fidelity, and temporal consistency in 4D reconstruction and weather editing. Our framework not only enables fine-grained control over weather conditions (e.g., light rain and heavy snow) but also supports object-level manipulation within the scene.",
        "tags": [
            "Image Editing"
        ]
    },
    {
        "id": "188",
        "title": "Behavioral Cloning for Robotic Connector Assembly: An Empirical Study",
        "author": [
            "Andreas Kernbach",
            "Daniel Bargmann",
            "Werner Kraus",
            "Marco F. Huber"
        ],
        "pdf": "https://arxiv.org/pdf/2602.22100",
        "abstract": "Automating the assembly of wire harnesses is challenging in automotive, electrical cabinet, and aircraft production, particularly due to deformable cables and a high variance in connector geometries. In addition, connectors must be inserted with limited force to avoid damage, while their poses can vary significantly. While humans can do this task intuitively by combining visual and haptic feedback, programming an industrial robot for such a task in an adaptable manner remains difficult. This work presents an empirical study investigating the suitability of behavioral cloning for learning an action prediction model for connector insertion that fuses force-torque sensing with a fixed position camera. We compare several network architectures and other design choices using a dataset of up to 300 successful human demonstrations collected via teleoperation of a UR5e robot with a SpaceMouse under varying connector poses. The resulting system is then evaluated against five different connector geometries under varying connector poses, achieving an overall insertion success rate of over 90 %.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "189",
        "title": "System Design of the Ultra Mobility Vehicle: A Driving, Balancing, and Jumping Bicycle Robot",
        "author": [
            "Benjamin Bokser",
            "Daniel Gonzalez",
            "Surya Singh",
            "Aaron Preston",
            "Alex Bahner",
            "Annika WollschlÃ¤ger",
            "Arianna Ilvonen",
            "Asa Eckert-Erdheim",
            "Ashwin Khadke",
            "Bilal Hammoud",
            "Dean Molinaro",
            "Fabian Jenelten",
            "Henry Mayne",
            "Howie Choset",
            "Igor Bogoslavskyi",
            "Itic Tinman",
            "James Tigue",
            "Jan Preisig",
            "Kaiyu Zheng",
            "Kenny Sharma",
            "Kim Ang",
            "Laura Lee",
            "Liana Margolese",
            "Nicole Lin",
            "Oscar Frias",
            "Paul Drews",
            "Ravi Boggavarapu",
            "Rick Burnham",
            "Samuel Zapolsky",
            "Sangbae Kim",
            "Scott Biddlestone",
            "Sean Mayorga",
            "Shamel Fahmi",
            "Tyler McCollum",
            "Velin Dimitrov",
            "William Moyne",
            "Yu-Ming Chen",
            "Farbod Farshidian",
            "Marco Hutter",
            "David Perry",
            "Al Rizzi",
            "Gabe Nelson"
        ],
        "pdf": "https://arxiv.org/pdf/2602.22118",
        "abstract": "Trials cyclists and mountain bike riders can hop, jump, balance, and drive on one or both wheels. This versatility allows them to achieve speed and energy-efficiency on smooth terrain and agility over rough terrain. Inspired by these athletes, we present the design and control of a robotic platform, Ultra Mobility Vehicle (UMV), which combines a bicycle and a reaction mass to move dynamically with minimal actuated degrees of freedom. We employ a simulation-driven design optimization process to synthesize a spatial linkage topology with a focus on vertical jump height and momentum-based balancing on a single wheel contact. Using a constrained Reinforcement Learning (RL) framework, we demonstrate zero-shot transfer of diverse athletic behaviors, including track-stands, jumps, wheelies, rear wheel hopping, and front flips. This 23.5 kg robot is capable of high speeds (8 m/s) and jumping on and over large obstacles (1 m tall, or 130% of the robot's nominal height).",
        "tags": [
            "RL",
            "Robotics"
        ]
    },
    {
        "id": "190",
        "title": "GeoDiv: Framework For Measuring Geographical Diversity In Text-To-Image Models",
        "author": [
            "Abhipsa Basu",
            "Mohana Singh",
            "Shashank Agnihotri",
            "Margret Keuper",
            "R. Venkatesh Babu"
        ],
        "pdf": "https://arxiv.org/pdf/2602.22120",
        "abstract": "Text-to-image (T2I) models are rapidly gaining popularity, yet their outputs often lack geographical diversity, reinforce stereotypes, and misrepresent regions. Given their broad reach, it is critical to rigorously evaluate how these models portray the world. Existing diversity metrics either rely on curated datasets or focus on surface-level visual similarity, limiting interpretability. We introduce GeoDiv, a framework leveraging large language and vision-language models to assess geographical diversity along two complementary axes: the Socio-Economic Visual Index (SEVI), capturing economic and condition-related cues, and the Visual Diversity Index (VDI), measuring variation in primary entities and backgrounds. Applied to images generated by models such as Stable Diffusion and FLUX.1-dev across $10$ entities and $16$ countries, GeoDiv reveals a consistent lack of diversity and identifies fine-grained attributes where models default to biased portrayals. Strikingly, depictions of countries like India, Nigeria, and Colombia are disproportionately impoverished and worn, reflecting underlying socio-economic biases. These results highlight the need for greater geographical nuance in generative models. GeoDiv provides the first systematic, interpretable framework for measuring such biases, marking a step toward fairer and more inclusive generative systems. Project page: https://abhipsabasu.github.io/geodiv",
        "tags": [
            "Diffusion",
            "FLUX",
            "Text-to-Image",
            "VLM"
        ]
    },
    {
        "id": "191",
        "title": "SWE-ProtÃ©gÃ©: Learning to Selectively Collaborate With an Expert Unlocks Small Language Models as Software Engineering Agents",
        "author": [
            "Patrick Tser Jern Kon",
            "Archana Pradeep",
            "Ang Chen",
            "Alexander P. Ellis",
            "Warren Hunt",
            "Zijian Wang",
            "John Yang",
            "Samuel Thompson"
        ],
        "pdf": "https://arxiv.org/pdf/2602.22124",
        "abstract": "Small language models (SLMs) offer compelling advantages in cost, latency, and adaptability, but have so far lagged behind larger models on long-horizon software engineering tasks such as SWE-bench, where they suffer from pervasive action looping and low resolution rates. We introduce SWE-ProtÃ©gÃ©, a post-training framework that reframes software repair as an expert-protÃ©gÃ© collaboration problem. In SWE-ProtÃ©gÃ©, an SLM remains the sole decision-maker while learning to selectively seek guidance from a strong expert model, recognize stalled states, and follow through on expert feedback. Our approach combines supervised fine-tuning on expert-augmented trajectories with agentic reinforcement learning that explicitly discourages degenerative looping and unproductive expert collaboration. We lightly post-train Qwen2.5-Coder-7B-Instruct to achieve 42.4% Pass@1 on SWE-bench Verified, a +25.4% improvement over the prior SLM state of the art, while using expert assistance sparsely (~4 calls per task and 11% of total tokens).",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "192",
        "title": "IndicIFEval: A Benchmark for Verifiable Instruction-Following Evaluation in 14 Indic Languages",
        "author": [
            "Thanmay Jayakumar",
            "Mohammed Safi Ur Rahman Khan",
            "Raj Dabre",
            "Ratish Puduppully",
            "Anoop Kunchukuttan"
        ],
        "pdf": "https://arxiv.org/pdf/2602.22125",
        "abstract": "Instruction-following benchmarks remain predominantly English-centric, leaving a critical evaluation gap for the hundreds of millions of Indic language speakers. We introduce IndicIFEval, a benchmark evaluating constrained generation of LLMs across 14 Indic languages using automatically verifiable, rule-based instructions. It comprises around 800 human-verified examples per language spread across two complementary subsets: IndicIFEval-Ground, translated prompts from IFEval (Zhou et al., 2023) carefully localized for Indic contexts, and IndicIFEval-Ground, synthetically generated instructions grounded in native Indic content. We conduct a comprehensive evaluation of major open-weight and proprietary models spanning both reasoning and non-reasoning models. While models maintain strong adherence to formatting constraints, they struggle significantly with lexical and cross-lingual tasks -- and despite progress in high-resource languages, instruction-following across the broader Indic family lags significantly behind English. We release IndicIFEval and its evaluation scripts to support progress on multilingual constrained generation (http://github.com/ai4bharat/IndicIFEval).",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "193",
        "title": "Giving Meaning to Movements: Challenges and Opportunities in Expanding Communication by Pairing Unaided AAC with Speech Generated Messages",
        "author": [
            "Imran Kabir",
            "Sharon Ann Redmon",
            "Lynn R Elko",
            "Kevin Williams",
            "Mitchell A Case",
            "Dawn J Sowers",
            "Krista Wilkinson",
            "Syed Masum Billah"
        ],
        "pdf": "https://arxiv.org/pdf/2602.22131",
        "abstract": "Augmentative and Alternative Communication (AAC) technologies are categorized into two forms: aided AAC, which uses external devices like speech-generating systems to produce standardized output, and unaided AAC, which relies on body-based gestures for natural expression but requires shared understanding. We investigate how to combine these approaches to harness the speed and naturalness of unaided AAC while maintaining the intelligibility of aided AAC, a largely unexplored area for individuals with communication and motor impairments. Through 18 months of participatory design with AAC users, we identified key challenges and opportunities and developed AllyAAC, a wearable system with a wrist-worn IMU paired with a smartphone app. We evaluated AllyAAC in a field study with 14 participants and produced a dataset containing over 600,000 multimodal data points featuring atypical gestures--the first of its kind. Our findings reveal challenges in recognizing personalized, idiosyncratic gestures and demonstrate how to address them using Transformer-based large machine learning (ML) models with different pretraining strategies. In sum, we contribute design principles and a reference implementation for adaptive, personalized systems combining aided and unaided AAC.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "194",
        "title": "WeaveTime: Stream from Earlier Frames into Emergent Memory in VideoLLMs",
        "author": [
            "Yulin Zhang",
            "Cheng Shi",
            "Sibei Yang"
        ],
        "pdf": "https://arxiv.org/pdf/2602.22142",
        "abstract": "Recent advances in Multimodal Large Language Models have greatly improved visual understanding and reasoning, yet their quadratic attention and offline training protocols make them ill-suited for streaming settings where frames arrive sequentially and future observations are inaccessible. We diagnose a core limitation of current Video-LLMs, namely Time-Agnosticism, in which videos are treated as an unordered bag of evidence rather than a causally ordered sequence, yielding two failures in streams: temporal order ambiguity, in which the model cannot follow or reason over the correct chronological order, and past-current focus blindness where it fails to distinguish present observations from accumulated history. We present WeaveTime, a simple, efficient, and model agnostic framework that first teaches order and then uses order. We introduce a lightweight Temporal Reconstruction objective-our Streaming Order Perception enhancement-that instills order aware representations with minimal finetuning and no specialized streaming data. At inference, a Past-Current Dynamic Focus Cache performs uncertainty triggered, coarse-to-fine retrieval, expanding history only when needed. Plugged into exsiting Video-LLM without architectural changes, WeaveTime delivers consistent gains on representative streaming benchmarks, improving accuracy while reducing latency. These results establish WeaveTime as a practical path toward time aware stream Video-LLMs under strict online, time causal constraints. Code and weights will be made publicly available. Project Page: https://zhangyl4.github.io/publications/weavetime/",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "195",
        "title": "NoLan: Mitigating Object Hallucinations in Large Vision-Language Models via Dynamic Suppression of Language Priors",
        "author": [
            "Lingfeng Ren",
            "Weihao Yu",
            "Runpeng Yu",
            "Xinchao Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2602.22144",
        "abstract": "Object hallucination is a critical issue in Large Vision-Language Models (LVLMs), where outputs include objects that do not appear in the input image. A natural question arises from this phenomenon: Which component of the LVLM pipeline primarily contributes to object hallucinations? The vision encoder to perceive visual information, or the language decoder to generate text responses? In this work, we strive to answer this question through designing a systematic experiment to analyze the roles of the vision encoder and the language decoder in hallucination generation. Our observations reveal that object hallucinations are predominantly associated with the strong priors from the language decoder. Based on this finding, we propose a simple and training-free framework, No-Language-Hallucination Decoding, NoLan, which refines the output distribution by dynamically suppressing language priors, modulated based on the output distribution difference between multimodal and text-only inputs. Experimental results demonstrate that NoLan effectively reduces object hallucinations across various LVLMs on different tasks. For instance, NoLan achieves substantial improvements on POPE, enhancing the accuracy of LLaVA-1.5 7B and Qwen-VL 7B by up to 6.45 and 7.21, respectively. The code is publicly available at: https://github.com/lingfengren/NoLan.",
        "tags": [
            "LLaVA",
            "Qwen",
            "VLM"
        ]
    },
    {
        "id": "196",
        "title": "When AI Writes, Whose Voice Remains? Quantifying Cultural Marker Erasure Across World English Varieties in Large Language Models",
        "author": [
            "Satyam Kumar Navneet",
            "Joydeep Chandra",
            "Yong Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2602.22145",
        "abstract": "Large Language Models (LLMs) are increasingly used to ``professionalize'' workplace communication, often at the cost of linguistic identity. We introduce \"Cultural Ghosting\", the systematic erasure of linguistic markers unique to non-native English varieties during text processing. Through analysis of 22,350 LLM outputs generated from 1,490 culturally marked texts (Indian, Singaporean,& Nigerian English) processed by five models under three prompt conditions, we quantify this phenomenon using two novel metrics: Identity Erasure Rate (IER) & Semantic Preservation Score (SPS). Across all prompts, we find an overall IER of 10.26%, with model-level variation from 3.5% to 20.5% (5.9x range). Crucially, we identify a Semantic Preservation Paradox: models maintain high semantic similarity (mean SPS = 0.748) while systematically erasing cultural markers. Pragmatic markers (politeness conventions) are 1.9x more vulnerable than lexical markers (71.5% vs. 37.1% erasure). Our experiments demonstrate that explicit cultural-preservation prompts reduce erasure by 29% without sacrificing semantic quality.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "197",
        "title": "Provable Last-Iterate Convergence for Multi-Objective Safe LLM Alignment via Optimistic Primal-Dual",
        "author": [
            "Yining Li",
            "Peizhong Ju",
            "Ness Shroff"
        ],
        "pdf": "https://arxiv.org/pdf/2602.22146",
        "abstract": "Reinforcement Learning from Human Feedback (RLHF) plays a significant role in aligning Large Language Models (LLMs) with human preferences. While RLHF with expected reward constraints can be formulated as a primal-dual optimization problem, standard primal-dual methods only guarantee convergence with a distributional policy where the saddle-point problem is in convex-concave form. Moreover, standard primal-dual methods may exhibit instability or divergence in the last iterate under policy parameterization in practical applications. In this work, we propose a universal primal-dual framework for safe RLHF that unifies a broad class of existing alignment algorithms, including safe-RLHF, one-shot, and multi-shot based methods. Building on this framework, we introduce an optimistic primal-dual (OPD) algorithm that incorporates predictive updates for both primal and dual variables to stabilize saddle-point dynamics. We establish last-iterate convergence guarantees for the proposed method, covering both exact policy optimization in the distributional space and convergence to a neighborhood of the optimal solution whose gap is related to approximation error and bias under parameterized policies. Our analysis reveals that optimism plays a crucial role in mitigating oscillations inherent to constrained alignment objectives, thereby closing a key theoretical gap between constrained RL and practical RLHF.",
        "tags": [
            "LLM",
            "RL",
            "RLHF"
        ]
    },
    {
        "id": "198",
        "title": "CoLoGen: Progressive Learning of Concept`-`Localization Duality for Unified Image Generation",
        "author": [
            "YuXin Song",
            "Yu Lu",
            "Haoyuan Sun",
            "Huanjin Yao",
            "Fanglong Liu",
            "Yifan Sun",
            "Haocheng Feng",
            "Hang Zhou",
            "Jingdong Wang"
        ],
        "pdf": "https://arxiv.org/pdf/2602.22150",
        "abstract": "Unified conditional image generation remains difficult because different tasks depend on fundamentally different internal representations. Some require conceptual understanding for semantic synthesis, while others rely on localization cues for spatial precision. Forcing these heterogeneous tasks to share a single representation leads to concept`-`localization representational conflict. To address this issue, we propose CoLoGen, a unified diffusion framework that progressively learns and reconciles this concept`-`localization duality. CoLoGen uses a staged curriculum that first builds core conceptual and localization abilities, then adapts them to diverse visual conditions, and finally refines their synergy for complex instruction`-`driven tasks. Central to this process is the Progressive Representation Weaving (PRW) module, which dynamically routes features to specialized experts and stably integrates their outputs across stages. Experiments on editing, controllable generation, and customized generation show that CoLoGen achieves competitive or superior performance, offering a principled representational perspective for unified image generation.",
        "tags": [
            "Diffusion"
        ]
    },
    {
        "id": "199",
        "title": "Position-Based Flocking for Persistent Alignment without Velocity Sensing",
        "author": [
            "Hossein B. Jond",
            "Veli BakÄ±rcÄ±oÄlu",
            "Logan E. Beaver",
            "Nejat TÃ¼kenmez",
            "Adel Akbarimajd",
            "Martin Saska"
        ],
        "pdf": "https://arxiv.org/pdf/2602.22154",
        "abstract": "Coordinated collective motion in bird flocks and fish schools inspires algorithms for cohesive swarm robotics. This paper presents a position-based flocking model that achieves persistent velocity alignment without velocity sensing. By approximating relative velocity differences from changes between current and initial relative positions and incorporating a time- and density-dependent alignment gain with a non-zero minimum threshold to maintain persistent alignment, the model sustains coherent collective motion over extended periods. Simulations with a collective of 50 agents demonstrate that the position-based flocking model attains faster and more sustained directional alignment and results in more compact formations than a velocity-alignment-based baseline. This position-based flocking model is particularly well-suited for real-world robotic swarms, where velocity measurements are unreliable, noisy, or unavailable. Experimental results using a team of nine real wheeled mobile robots are also presented.",
        "tags": [
            "Robotics"
        ]
    },
    {
        "id": "200",
        "title": "LLMTailor: A Layer-wise Tailoring Tool for Efficient Checkpointing of Large Language Models",
        "author": [
            "Minqiu Sun",
            "Xin Huang",
            "Luanzheng Guo",
            "Nathan R. Tallent",
            "Kento Sato",
            "Dong Dai"
        ],
        "pdf": "https://arxiv.org/pdf/2602.22158",
        "abstract": "Checkpointing is essential for fault tolerance in training large language models (LLMs). However, existing methods, regardless of their I/O strategies, periodically store the entire model and optimizer states, incurring substantial storage overhead and resource contention. Recent studies reveal that updates across LLM layers are highly non-uniform. Across training steps, some layers may undergo more significant changes, while others remain relatively stable or even unchanged. This suggests that selectively checkpointing only layers with significant updates could reduce overhead without harming training. Implementing such selective strategies requires fine-grained control over both weights and optimizer states, which no current tool provides. To address this gap, we propose \\texttt{LLMTailor}, a checkpoint-merging framework that filters and assembles layers from different checkpoints to form a composite checkpoint. Our evaluation indicates that LLMTailor can work with different selective checkpointing strategies and effectively reduce checkpoint size (e.g., 4.3 times smaller for Llama3.1-8B) and checkpoint time (e.g., 2.8 times faster for Qwen2.5-7B) while maintaining model quality.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "201",
        "title": "CASR: A Robust Cyclic Framework for Arbitrary Large-Scale Super-Resolution with Distribution Alignment and Self-Similarity Awareness",
        "author": [
            "Wenhao Guo",
            "Zhaoran Zhao",
            "Peng Lu",
            "Sheng Li",
            "Qian Qiao",
            "RuiDe Li"
        ],
        "pdf": "https://arxiv.org/pdf/2602.22159",
        "abstract": "Arbitrary-Scale SR (ASISR) remains fundamentally limited by cross-scale distribution shift: once the inference scale leaves the training range, noise, blur, and artifacts accumulate sharply. We revisit this challenge from a cross-scale distribution transition perspective and propose CASR, a simple yet highly efficient cyclic SR framework that reformulates ultra-magnification as a sequence of in-distribution scale transitions. This design ensures stable inference at arbitrary scales while requiring only a single model. CASR tackles two major bottlenecks: distribution drift across iterations and patch-wise diffusion inconsistencies. The proposed SDAM module aligns structural distributions via superpixel aggregation, preventing error accumulation, while SARM module restores high-frequency textures by enforcing autocorrelation and embedding LR self-similarity priors. Despite using only a single model, our approach significantly reduces distribution drift, preserves long-range texture consistency, and achieves superior generalization even at extreme magnification.",
        "tags": [
            "Diffusion",
            "Super Resolution"
        ]
    },
    {
        "id": "202",
        "title": "A Taxonomy of Human--MLLM Interaction in Early-Stage Sketch-Based Design Ideation",
        "author": [
            "Weiayn Shi",
            "Kenny Tsu Wei Choo"
        ],
        "pdf": "https://arxiv.org/pdf/2602.22171",
        "abstract": "As multimodal large language models (MLLMs) are increasingly integrated into early-stage design tools, it is important to understand how designers collaborate with AI during ideation. In a user study with 12 participants, we analysed sketch-based design interactions with an MLLM-powered system using automatically recorded interaction logs and post-task interviews. Based on how creative responsibility was allocated between humans and the AI, we predefined four interaction modes: Human-Only, Human-Lead, AI-Lead, and Co-Evolution, and analysed how these modes manifested during sketch-based design ideation. Our results show that designers rarely rely on a single mode; instead, human-led and AI-led roles are frequently interwoven and shift across ideation instances. These findings provide an empirical basis for future work to investigate why designers shift roles with AI and how interactive systems can better support such dynamic collaboration.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "203",
        "title": "Codesigning Ripplet: an LLM-Assisted Assessment Authoring System Grounded in a Conceptual Model of Teachers' Workflows",
        "author": [
            "Yuan Cui",
            "Annabel Goldman",
            "Jovy Zhou",
            "Xiaolin Liu",
            "Clarissa Shieh",
            "Joshua Yao",
            "Mia Cheng",
            "Matthew Kay",
            "Fumeng Yang"
        ],
        "pdf": "https://arxiv.org/pdf/2602.22186",
        "abstract": "Assessments are critical in education, but creating them can be difficult. To address this challenge in a grounded way, we partnered with 13 teachers in a seven-month codesign process. We developed a conceptual model that characterizes the iterative dual process where teachers develop assessments while simultaneously refining requirements. To enact this model in practice, we built Ripplet, a web-based tool with multilevel reusable interactions to support assessment authoring. The extended codesign revealed that Ripplet enabled teachers to create formative assessments they would not have otherwise made, shifted their practices from generation to curation, and helped them reflect more on assessment quality. In a user study with 15 additional teachers, compared to their current practices, teachers felt the results were more worth their effort and that assessment quality improved.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "204",
        "title": "GUI-Libra: Training Native GUI Agents to Reason and Act with Action-aware Supervision and Partially Verifiable RL",
        "author": [
            "Rui Yang",
            "Qianhui Wu",
            "Zhaoyang Wang",
            "Hanyang Chen",
            "Ke Yang",
            "Hao Cheng",
            "Huaxiu Yao",
            "Baoling Peng",
            "Huan Zhang",
            "Jianfeng Gao",
            "Tong Zhang"
        ],
        "pdf": "https://arxiv.org/pdf/2602.22190",
        "abstract": "Open-source native GUI agents still lag behind closed-source systems on long-horizon navigation tasks. This gap stems from two limitations: a shortage of high-quality, action-aligned reasoning data, and the direct adoption of generic post-training pipelines that overlook the unique challenges of GUI agents. We identify two fundamental issues in these pipelines: (i) standard SFT with CoT reasoning often hurts grounding, and (ii) step-wise RLVR-tyle training faces partial verifiability, where multiple actions can be correct but only a single demonstrated action is used for verification. This makes offline step-wise metrics weak predictors of online task success. In this work, we present GUI-Libra, a tailored training recipe that addresses these challenges. First, to mitigate the scarcity of action-aligned reasoning data, we introduce a data construction and filtering pipeline and release a curated 81K GUI reasoning dataset. Second, to reconcile reasoning with grounding, we propose action-aware SFT that mixes reasoning-then-action and direct-action data and reweights tokens to emphasize action and grounding. Third, to stabilize RL under partial verifiability, we identify the overlooked importance of KL regularization in RLVR and show that a KL trust region is critical for improving offline-to-online predictability; we further introduce success-adaptive scaling to downweight unreliable negative gradients. Across diverse web and mobile benchmarks, GUI-Libra consistently improves both step-wise accuracy and end-to-end task completion. Our results suggest that carefully designed post-training and data curation can unlock significantly stronger task-solving capabilities without costly online data collection. We release our dataset, code, and models to facilitate further research on data-efficient post-training for reasoning-capable GUI agents.",
        "tags": [
            "CoT",
            "RL"
        ]
    },
    {
        "id": "205",
        "title": "Improving Parametric Knowledge Access in Reasoning Language Models",
        "author": [
            "Melody Ma",
            "John Hewitt"
        ],
        "pdf": "https://arxiv.org/pdf/2602.22193",
        "abstract": "We study reasoning for accessing world knowledge stored in a language model's parameters. For example, recalling that Canberra is Australia's capital may benefit from thinking through major cities and the concept of purpose-built capitals. While reasoning language models are trained via reinforcement learning to produce reasoning traces on tasks such as mathematics, they may not reason well for accessing their own world knowledge. We first find that models do not generate their best world knowledge reasoning by default: adding a simple \"think step-by-step\" cue demonstrates statistically significant improvement in knowledge recall but not math. Motivated by this, we propose training models to reason over their parametric knowledge using world-knowledge question answering as a verifiable reward. After reinforcement learning on TriviaQA (+9.9%), performance also improves on Natural Questions, HotpotQA, SimpleQA, and StrategyQA by 4.2%, 2.1%, 0.6%, and 3.0%, respectively. Reasoning models are under-optimized for parametric knowledge access, but can be easily trained to reason better.",
        "tags": [
            "RL"
        ]
    },
    {
        "id": "206",
        "title": "SumTablets: A Transliteration Dataset of Sumerian Tablets",
        "author": [
            "Cole Simmons",
            "Richard Diehl Martinez",
            "Dan Jurafsky"
        ],
        "pdf": "https://arxiv.org/pdf/2602.22200",
        "abstract": "Sumerian transliteration is a conventional system for representing a scholar's interpretation of a tablet in the Latin script. Thanks to visionary digital Assyriology projects such as ETCSL, CDLI, and Oracc, a large number of Sumerian transliterations have been published online, and these data are well-structured for a variety of search and analysis tasks. However, the absence of a comprehensive, accessible dataset pairing transliterations with a digital representation of the tablet's cuneiform glyphs has prevented the application of modern Natural Language Processing (NLP) methods to the task of Sumerian transliteration.\nTo address this gap, we present SumTablets, a dataset pairing Unicode representations of 91,606 Sumerian cuneiform tablets (totaling 6,970,407 glyphs) with the associated transliterations published by Oracc. We construct SumTablets by first preprocessing and standardizing the Oracc transliterations before mapping each reading back to the Unicode representation of the source glyph. Further, we retain parallel structural information (e.g., surfaces, newlines, broken segments) through the use of special tokens. We release SumTablets as a Hugging Face Dataset (CC BY 4.0) and open source data preparation code via GitHub.\nAdditionally, we leverage SumTablets to implement and evaluate two transliteration baselines: (1) weighted sampling from a glyph's possible readings, and (2) fine-tuning an autoregressive language model. Our fine-tuned language model achieves an average transliteration character-level F-score (chrF) of 97.55, demonstrating the immediate potential of transformer-based transliteration models in allowing experts to rapidly verify generated transliterations rather than manually transliterating tablets one-by-one.",
        "tags": [
            "Transformer"
        ]
    },
    {
        "id": "207",
        "title": "Recovered in Translation: Efficient Pipeline for Automated Translation of Benchmarks and Datasets",
        "author": [
            "Hanna Yukhymenko",
            "Anton Alexandrov",
            "Martin Vechev"
        ],
        "pdf": "https://arxiv.org/pdf/2602.22207",
        "abstract": "The reliability of multilingual Large Language Model (LLM) evaluation is currently compromised by the inconsistent quality of translated benchmarks. Existing resources often suffer from semantic drift and context loss, which can lead to misleading performance metrics. In this work, we present a fully automated framework designed to address these challenges by enabling scalable, high-quality translation of datasets and benchmarks. We demonstrate that adapting test-time compute scaling strategies, specifically Universal Self-Improvement (USI) and our proposed multi-round ranking method, T-RANK, allows for significantly higher quality outputs compared to traditional pipelines. Our framework ensures that benchmarks preserve their original task structure and linguistic nuances during localization. We apply this approach to translate popular benchmarks and datasets into eight Eastern and Southern European languages (Ukrainian, Bulgarian, Slovak, Romanian, Lithuanian, Estonian, Turkish, Greek). Evaluations using both reference-based metrics and LLM-as-a-judge show that our translations surpass existing resources, resulting in more accurate downstream model assessment. We release both the framework and the improved benchmarks to facilitate robust and reproducible multilingual AI development.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "208",
        "title": "Solaris: Building a Multiplayer Video World Model in Minecraft",
        "author": [
            "Georgy Savva",
            "Oscar Michel",
            "Daohan Lu",
            "Suppakit Waiwitlikhit",
            "Timothy Meehan",
            "Dhairya Mishra",
            "Srivats Poddar",
            "Jack Lu",
            "Saining Xie"
        ],
        "pdf": "https://arxiv.org/pdf/2602.22208",
        "abstract": "Existing action-conditioned video generation models (video world models) are limited to single-agent perspectives, failing to capture the multi-agent interactions of real-world environments. We introduce Solaris, a multiplayer video world model that simulates consistent multi-view observations. To enable this, we develop a multiplayer data system designed for robust, continuous, and automated data collection on video games such as Minecraft. Unlike prior platforms built for single-player settings, our system supports coordinated multi-agent interaction and synchronized videos + actions capture. Using this system, we collect 12.64 million multiplayer frames and propose an evaluation framework for multiplayer movement, memory, grounding, building, and view consistency. We train Solaris using a staged pipeline that progressively transitions from single-player to multiplayer modeling, combining bidirectional, causal, and Self Forcing training. In the final stage, we introduce Checkpointed Self Forcing, a memory-efficient Self Forcing variant that enables a longer-horizon teacher. Results show our architecture and training design outperform existing baselines. Through open-sourcing our system and models, we hope to lay the groundwork for a new generation of multi-agent world models.",
        "tags": [
            "Video Generation"
        ]
    },
    {
        "id": "209",
        "title": "Forecasting Future Language: Context Design for Mention Markets",
        "author": [
            "Sumin Kim",
            "Jihoon Kwon",
            "Yoon Kim",
            "Nicole Kagan",
            "Raffi Khatchadourian",
            "Wonbin Ahn",
            "Alejandro Lopez-Lira",
            "Jaewon Lee",
            "Yoontae Hwang",
            "Oscar Levy",
            "Yongjae Lee",
            "Chanyeol Choi"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21229",
        "abstract": "Mention markets, a type of prediction market in which contracts resolve based on whether a specified keyword is mentioned during a future public event, require accurate probabilistic forecasts of keyword-mention outcomes. While recent work shows that large language models (LLMs) can generate forecasts competitive with human forecasters, it remains unclear how input context should be designed to support accurate prediction. In this paper, we study this question through experiments on earnings-call mention markets, which require forecasting whether a company will mention a specified keyword during its upcoming call. We run controlled comparisons varying (i) which contextual information is provided (news and/or prior earnings-call transcripts) and (ii) how \\textit{market probability}, (i.e., prediction market contract price) is used. We introduce Market-Conditioned Prompting (MCP), which explicitly treats the market-implied probability as a prior and instructs the LLM to update this prior using textual evidence, rather than re-predicting the base rate from scratch. In our experiments, we find three insights: (1) richer context consistently improves forecasting performance; (2) market-conditioned prompting (MCP), which treats the market probability as a prior and updates it using textual evidence, yields better-calibrated forecasts; and (3) a mixture of the market probability and MCP (MixMCP) outperforms the market baseline. By dampening the LLM's posterior update with the market prior, MixMCP yields more robust predictions than either the market or the LLM alone.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "210",
        "title": "Conditional neural control variates for variance reduction in Bayesian inverse problems",
        "author": [
            "Ali Siahkoohi",
            "Hyunwoo Oh"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21357",
        "abstract": "Bayesian inference for inverse problems involves computing expectations under posterior distributions -- e.g., posterior means, variances, or predictive quantities -- typically via Monte Carlo (MC) estimation. When the quantity of interest varies significantly under the posterior, accurate estimates demand many samples -- a cost often prohibitive for partial differential equation-constrained problems. To address this challenge, we introduce conditional neural control variates, a modular method that learns amortized control variates from joint model-data samples to reduce the variance of MC estimators. To scale to high-dimensional problems, we leverage Stein's identity to design an architecture based on an ensemble of hierarchical coupling layers with tractable Jacobian trace computation. Training requires: (i) samples from the joint distribution of unknown parameters and observed data; and (ii) the posterior score function, which can be computed from physics-based likelihood evaluations, neural operator surrogates, or learned generative models such as conditional normalizing flows. Once trained, the control variates generalize across observations without retraining. We validate our approach on stylized and partial differential equation-constrained Darcy flow inverse problems, demonstrating substantial variance reduction, even when the analytical score is replaced by a learned surrogate.",
        "tags": [
            "Normalizing Flows"
        ]
    },
    {
        "id": "211",
        "title": "Reasoning-Driven Design of Single Atom Catalysts via a Multi-Agent Large Language Model Framework",
        "author": [
            "Dong Hyeon Mok",
            "Seoin Back",
            "Victor Fung",
            "Guoxiang Hu"
        ],
        "pdf": "https://arxiv.org/pdf/2602.21533",
        "abstract": "Large language models (LLMs) are becoming increasingly applied beyond natural language processing, demonstrating strong capabilities in complex scientific tasks that traditionally require human expertise. This progress has extended into materials discovery, where LLMs introduce a new paradigm by leveraging reasoning and in-context learning, capabilities absent from conventional machine learning approaches. Here, we present a Multi-Agent-based Electrocatalyst Search Through Reasoning and Optimization (MAESTRO) framework in which multiple LLMs with specialized roles collaboratively discover high-performance single atom catalysts for the oxygen reduction reaction. Within an autonomous design loop, agents iteratively reason, propose modifications, reflect on results and accumulate design history. Through in-context learning enabled by this iterative process, MAESTRO identified design principles not explicitly encoded in the LLMs' background knowledge and successfully discovered catalysts that break conventional scaling relations between reaction intermediates. These results highlight the potential of multi-agent LLM frameworks as a powerful strategy to generate chemical insight and discover promising catalysts.",
        "tags": [
            "LLM"
        ]
    },
    {
        "id": "212",
        "title": "Learning Quantum Data Distribution via Chaotic Quantum Diffusion Model",
        "author": [
            "Quoc Hoan Tran",
            "Koki Chinzei",
            "Yasuhiro Endo",
            "Hirotaka Oshima"
        ],
        "pdf": "https://arxiv.org/pdf/2602.22061",
        "abstract": "Generative models for quantum data pose significant challenges but hold immense potential in fields such as chemoinformatics and quantum physics. Quantum denoising diffusion probabilistic models (QuDDPMs) enable efficient learning of quantum data distributions by progressively scrambling and denoising quantum states; however, existing implementations typically rely on circuit-based random unitary dynamics that can be costly to realize and sensitive to control imperfections, particularly on analog quantum hardware. We propose the chaotic quantum diffusion model, a framework that generates projected ensembles via chaotic Hamiltonian time evolution, providing a flexible and hardware-compatible diffusion mechanism. Requiring only global, time-independent control, our approach substantially reduces implementation overhead across diverse analog quantum platforms while achieving accuracy comparable to QuDDPMs. This method improves trainability and robustness, broadening the applicability of quantum generative modeling.",
        "tags": [
            "Diffusion"
        ]
    }
]